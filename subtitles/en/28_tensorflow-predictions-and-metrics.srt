1
00:00:05,600 --> 00:00:10,080
In our other videos, and as always, there'll 
be links below if you want to check those out,  

2
00:00:10,640 --> 00:00:15,600
we showed you how to initialize and 
fine-tune a transformer model in TensorFlow,  

3
00:00:15,600 --> 00:00:20,800
so the question now is: What can we do with a 
model after we train it? The obvious thing to  

4
00:00:20,800 --> 00:00:26,080
try is to use it to get predictions for new 
data, so let's see how to do that. Again,  

5
00:00:26,080 --> 00:00:31,120
if you're familiar with Keras, the good news is 
that because there are just standard Keras models,  

6
00:00:31,680 --> 00:00:35,440
we can use the standard Keras 
predict() method, as shown here.  

7
00:00:36,800 --> 00:00:42,800
You simply pass in tokenized text to this method, 
like you'd get from a tokenizer, and you get your  

8
00:00:42,800 --> 00:00:48,320
results. Our models can output several different 
things, depending on the options you set,  

9
00:00:48,320 --> 00:00:53,280
but most of the time the thing you want is the 
output logits. If you haven’t come across them  

10
00:00:53,280 --> 00:01:02,960
before, logits are the outputs of the last layer 
of the network, before a softmax has been applied.  

11
00:01:02,960 --> 00:01:08,400
So if you want to turn the logits into the model’s 
probability outputs, you just apply a softmax,  

12
00:01:08,400 --> 00:01:13,840
like so. What if we want to turn those 
probabilities into class predictions?  

13
00:01:14,853 --> 00:01:20,960
Simple, we just pick the biggest probability for 
each output! The easiest way to do that is with  

14
00:01:20,960 --> 00:01:26,960
the argmax function. Argmax will return the 
index of the largest probability in each row,  

15
00:01:26,960 --> 00:01:36,400
which means in this case that we’ll 
get a vector of 0 and 1 values.  

16
00:01:37,360 --> 00:01:45,440
Those are our class predictions! In fact, if 
class predictions are all you want, you can skip  

17
00:01:45,440 --> 00:01:50,240
the softmax step entirely, because the largest 
logit will always be the largest probability  

18
00:01:52,400 --> 00:01:56,800
too. If probabilities and class predictions are 
all you want, then you’ve seen everything you  

19
00:01:56,800 --> 00:02:02,000
need at this point! But if you’re interested in 
benchmarking your model or using it for research,  

20
00:02:02,000 --> 00:02:06,320
you might want to delve deeper into the results 
you get. And one way to do that is to compute  

21
00:02:06,320 --> 00:02:10,880
some metrics for the model’s predictions. If 
you're following along with our datasets and  

22
00:02:10,880 --> 00:02:16,400
fine-tuning videos, we got our data from the MRPC 
dataset, which is part of the GLUE benchmark.  

23
00:02:16,960 --> 00:02:24,480
Each of the GLUE datasets, as well as many of 
our other datasets, has some predefined metrics,  

24
00:02:24,480 --> 00:02:31,520
and we can load them easily with the datasets 
load_metric() function. For the MRPC dataset,  

25
00:02:31,520 --> 00:02:36,080
the built-in metrics are accuracy, which just 
measures the percentage of the time the model’s  

26
00:02:36,080 --> 00:02:42,160
prediction was correct, and the F1 score, which is 
a slightly more complex measure that measures how  

27
00:02:42,160 --> 00:02:48,960
well the model trades off precision and recall. 
To compute those metrics to benchmark our model,  

28
00:02:48,960 --> 00:02:54,000
we just pass them the model’s predictions, and 
the ground truth labels, and we get our results.  

29
00:02:56,720 --> 00:03:01,120
If you’re familiar with Keras, though, you’ll 
notice that this is a weird way to compute  

30
00:03:01,120 --> 00:03:06,880
metrics - we’re only computing metrics at the end 
of training, but Keras has the built-in ability to  

31
00:03:06,880 --> 00:03:14,960
compute a wide range of metrics on the fly while 
you're training. If you want to use built-in  

32
00:03:14,960 --> 00:03:21,920
metric computations, it's very straightforward - 
you just pass a 'metric' argument to compile().  

33
00:03:22,960 --> 00:03:28,240
As with things like loss and optimizer, you 
can specify the metrics you want by string,  

34
00:03:28,240 --> 00:03:33,520
or you can import the actual metric objects if you 
want to pass specific arguments to them, but note  

35
00:03:33,520 --> 00:03:40,880
that unlike loss and accuracy, you have to supply 
a list of metrics, even if you only have one. Once  

36
00:03:40,880 --> 00:03:46,320
a model has been compiled with a metric, it will 
report that metric for training, validation and  

37
00:03:49,840 --> 00:03:54,880
predictions. You can even write your own Metric 
classes. Though this is a bit beyond the scope  

38
00:03:54,880 --> 00:03:59,440
of this course, I'll link to the relevant 
TF docs below because it can be very handy  

39
00:03:59,440 --> 00:04:10,800
if you want a metric that isn't supported 
by default in Keras, such as the F1 score.
