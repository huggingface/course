1
00:00:05,200 --> 00:00:11,680
Datasets and DataFrames equals love. Although the 
processing functions of Datasets will cover most  

2
00:00:11,680 --> 00:00:15,600
the cases needed to train a model, there are 
times when you’ll need to switch to a library  

3
00:00:15,600 --> 00:00:21,840
like Pandas to access more powerful features or 
high-level APIs for visualisation. Fortunately,  

4
00:00:21,840 --> 00:00:25,520
Datasets is designed to be interoperable 
with libraries like Pandas,  

5
00:00:25,520 --> 00:00:30,560
as well as NumPy, PyTorch, TensorFlow, 
and JAX. In this video, we'll take a  

6
00:00:30,560 --> 00:00:33,920
look at how we can quickly switch our 
data to Pandas DataFrames and back.  

7
00:00:35,920 --> 00:00:41,280
As an example, let's suppose we're analysing 
Supreme Court cases from Switzerland. As usual  

8
00:00:41,280 --> 00:00:45,440
we download our dataset from the Hub using the 
load_dataset() function, and you can see that the  

9
00:00:45,440 --> 00:00:49,600
first element of the training set is an ordinary 
Python dictionary with various fields of interest.  

10
00:00:51,440 --> 00:00:54,800
Now suppose that before we train any 
models, we'd like to explore the data a bit.  

11
00:00:55,360 --> 00:00:58,720
For example we might be interested in 
knowing which legal area is most common  

12
00:00:59,600 --> 00:01:02,480
or we might want to know how the 
languages are distributed across regions.  

13
00:01:04,320 --> 00:01:07,920
Answering these questions with the native 
Arrow format isn't easy, but we can easily  

14
00:01:07,920 --> 00:01:13,280
switch to Pandas to get our answers! The way 
this works is by using the set_format() method,  

15
00:01:13,280 --> 00:01:17,600
which will change the output format of the dataset 
from Python dictionaries to Pandas DataFrames.  

16
00:01:18,720 --> 00:01:22,720
As you can see in this example, each row in 
the dataset is represented as a DataFrame,  

17
00:01:22,720 --> 00:01:26,160
so we can slice the whole dataset to 
get a single DataFrame of the dataset.  

18
00:01:27,840 --> 00:01:31,040
The way this works under the hood is 
that the Datasets library changes the  

19
00:01:31,040 --> 00:01:35,440
magic __getitem__() method of the dataset. 
The __getitem__() method is a special method  

20
00:01:35,440 --> 00:01:40,320
for Python containers that allows you to 
specify how indexing works. In this case,  

21
00:01:40,320 --> 00:01:44,320
the __getitem__() method of the raw dataset 
starts off by returning Python dictionaries  

22
00:01:45,120 --> 00:01:49,920
and then after applying set_format() we change 
__getitem__() to return DataFrames instead.  

23
00:01:51,840 --> 00:01:56,240
The Datasets library also provides a to_pandas() 
method if you want to do the format conversion and  

24
00:01:56,240 --> 00:02:02,640
slicing of the dataset in one go. And once you 
have a DataFrame, you can find answers to all  

25
00:02:02,640 --> 00:02:07,840
sorts of complex questions or make plots with your 
favourite visualisation library and so on. The  

26
00:02:07,840 --> 00:02:10,800
only thing to remember is that once 
you are done with your Pandas analysis,  

27
00:02:10,800 --> 00:02:16,240
you should reset the output format back to Arrow 
tables. If you don't, you can run into problems if  

28
00:02:16,240 --> 00:02:20,240
you try to tokenize your text because it is no 
longer represented as strings in a dictionary.  

29
00:02:21,520 --> 00:02:32,160
By resetting the output format, we get back 
Arrow tables and can tokenize without problem!
