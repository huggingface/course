1
00:00:03,840 --> 00:00:09,200
In these few videos, we'll take a look at the 
tokenizers. In Natural Language Processing,  

2
00:00:09,200 --> 00:00:14,880
most of the data that we handle consists of raw 
text. However, machine learning models cannot read  

3
00:00:14,880 --> 00:00:23,200
and understand text in its raw form they can only 
work with numbers. The tokenizer's objective will  

4
00:00:23,200 --> 00:00:30,080
be to translate the text into numbers. There are 
several possible approaches to this conversion,  

5
00:00:30,080 --> 00:00:33,120
and the objective is to find the 
most meaningful representation.  

6
00:00:36,000 --> 00:00:40,400
We'll take a look at three distinct tokenization 
algorithms. We compare them one to one,  

7
00:00:40,400 --> 00:00:44,880
so we recommend you look at the videos 
in the following order: Word-based,  

8
00:00:45,680 --> 00:00:55,680
Character-based, and Subword-based.
