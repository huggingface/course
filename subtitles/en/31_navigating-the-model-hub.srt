1
00:00:04,000 --> 00:00:07,760
In this video, we're going to go over 
the HuggingFace Model Hub navigation.  

2
00:00:10,080 --> 00:00:16,160
This is the huggingface.co landing page. To access 
the model hub, click on the "Models" tab in the  

3
00:00:16,160 --> 00:00:22,720
upper right corner. You should be facing this web 
interface, which can be split into several parts.  

4
00:00:24,240 --> 00:00:28,560
On the left, you'll find categories, which 
you can use to tailor your model search.  

5
00:00:29,760 --> 00:00:35,840
The first category is the "Tasks". Models on 
the hub may be used for a wide variety of tasks.  

6
00:00:36,480 --> 00:00:41,440
These include natural language processing tasks, 
such as question answering or text classification,  

7
00:00:41,440 --> 00:00:47,600
but it isn't only limited to NLP. Other 
tasks from other fields are also available,  

8
00:00:47,600 --> 00:00:52,240
such as image classification for computer vision, 
or automatic speech recognition for speech.  

9
00:00:54,720 --> 00:01:00,400
The second category is the "libraries". Models 
on the hub usually share one of three backbones:  

10
00:01:01,040 --> 00:01:07,040
PyTorch, TensorFlow, or JAX. However, other 
backbones, such as rust or ONNX also exist.  

11
00:01:09,440 --> 00:01:14,720
Finally, this tab can also be used to specify 
from which high-level framework the model comes.  

12
00:01:15,920 --> 00:01:20,880
This includes Transformers, but it isn't 
limited to it. The model Hub is used to host  

13
00:01:20,880 --> 00:01:25,840
a lot of different frameworks' models, and we are 
actively looking to host other frameworks' models.  

14
00:01:28,400 --> 00:01:33,440
The third category is the "Datasets" 
tab. Selecting a dataset from this tab  

15
00:01:33,440 --> 00:01:37,360
means filtering the models so that they 
were trained on that specific dataset.  

16
00:01:39,040 --> 00:01:43,600
The fourth category is the "Languages" 
tab. Selecting a language from this tab  

17
00:01:43,600 --> 00:01:46,800
means filtering the models so that 
they handle the language selected.  

18
00:01:48,480 --> 00:01:53,840
Finally, the last category allows to choose 
the license with which the model is shared.  

19
00:01:56,480 --> 00:01:59,440
On the right, you'll find the 
models available on the model Hub!  

20
00:02:00,320 --> 00:02:06,400
The models are ordered by downloads. When clicking 
on a model, you should be facing its model card.  

21
00:02:07,040 --> 00:02:11,520
The model card contains information about 
the model: its description, intended use,  

22
00:02:11,520 --> 00:02:18,240
limitations and biases. It can also show code 
snippets on how to use the model, as well as  

23
00:02:18,240 --> 00:02:23,840
any relevant information: training procedure, 
data processing, evaluation results, copyrights.  

24
00:02:25,440 --> 00:02:30,160
This information is crucial for the model to 
be used. The better crafted a model card is,  

25
00:02:30,160 --> 00:02:34,000
the easier it will be for other users to 
leverage your model in their applications.  

26
00:02:35,600 --> 00:02:41,440
On the right of the model card is the inference 
API. This inference API can be used to play with  

27
00:02:41,440 --> 00:02:46,640
the model directly. Feel free to modify the text 
and click on compute to see how would the model  

28
00:02:46,640 --> 00:02:55,200
behave to your inputs. At the top of the screen 
lie the model tags. These include the model task,  

29
00:02:55,200 --> 00:02:58,640
as well as any other tag that is relevant 
to the categories we have just seen.  

30
00:03:01,200 --> 00:03:05,920
The "Files & Versions tab" displays the 
architecture of the repository of that model.  

31
00:03:07,120 --> 00:03:12,080
Here, we can see all the files that define 
this model. You'll see all usual features  

32
00:03:12,080 --> 00:03:22,320
of a git repository: the branches available, 
the commit history as well as the commit diff.  

33
00:03:25,600 --> 00:03:28,800
Three different buttons are available 
at the top of the model card.  

34
00:03:29,600 --> 00:03:32,800
The first one shows how to use the 
inference API programmatically.  

35
00:03:35,760 --> 00:03:38,640
The second one shows how to 
train this model in SageMaker,  

36
00:03:42,720 --> 00:03:45,840
and the last one shows how to load that 
model within the appropriate library.  

37
00:03:46,720 --> 00:03:54,480
For BERT, this is transformers.
