1
00:00:05,760 --> 00:00:08,560
The post-processing step in 
a question answering task.  

2
00:00:10,640 --> 00:00:14,640
When doing question answering, the 
processing of the initial dataset  

3
00:00:14,640 --> 00:00:20,960
implies splitting examples in several features, 
which may or may not contain the answer. Passing  

4
00:00:20,960 --> 00:00:25,680
those features through the model will give 
us logits for the start and end positions,  

5
00:00:25,680 --> 00:00:30,640
since our labels are the indices of the tokens 
that correspond to the start and end the answer.  

6
00:00:31,600 --> 00:00:36,560
We must then somehow convert those logits into an 
answer, and then pick one of the various answers  

7
00:00:36,560 --> 00:00:43,280
each feature gives to be THE answer for a given 
example. For the processing step, you should  

8
00:00:43,280 --> 00:00:47,840
refer to the video linked below. It's not very 
different for validation, we just need to add a  

9
00:00:47,840 --> 00:00:53,520
few lines to keep track of two things: instead 
of discarding the offset mapping, we keep them,  

10
00:00:53,520 --> 00:00:58,240
and also include in them the information of 
where the context is by setting the offsets  

11
00:00:58,240 --> 00:01:04,240
of the special tokens and the question to None. 
Then we also keep track of the example ID for  

12
00:01:04,240 --> 00:01:08,880
each feature, to be able to map back feature 
to the examples that they originated from.  

13
00:01:10,240 --> 00:01:14,400
If you don't want to compute the validation loss, 
you won't need to include all the special code  

14
00:01:14,400 --> 00:01:19,840
that we used to create the labels. With this done, 
we can apply that preprocessing function using the  

15
00:01:19,840 --> 00:01:26,160
map method. We take the SQUAD dataset like in 
the preprocessing for question-answering video.  

16
00:01:26,160 --> 00:01:30,560
Once this is done, the next step is to create 
our model. We use the default model behind the  

17
00:01:30,560 --> 00:01:34,560
question-answering pipeline here, but you 
should use any model you want to evaluate.  

18
00:01:35,600 --> 00:01:40,560
With the to_tf_dataset method, we can just 
sent our processed dataset to model.predict,  

19
00:01:41,120 --> 00:01:44,880
and we directly get our start and end logits 
for the whole dataset as NumPy arrays.  

20
00:01:45,600 --> 00:01:51,040
With this done, we can really dive into the 
post-processing. We will need a map from examples  

21
00:01:51,040 --> 00:01:57,040
to features, which we can create like this. Now, 
for the main part of the post-processing, let's  

22
00:01:57,040 --> 00:02:02,080
see how to extract an answer from the logits. We 
could just take the best index for the start and  

23
00:02:02,080 --> 00:02:07,680
end logits and be done, but if our model predicts 
something impossible, like tokens in the question,  

24
00:02:07,680 --> 00:02:13,040
we will look at more of the logits. Note that in 
the question-answering pipeline, we attributed  

25
00:02:13,040 --> 00:02:18,560
score to each answer based on the probabilities, 
which we did not compute here. In terms of logits,  

26
00:02:18,560 --> 00:02:24,080
the multiplication we had in the scores becomes 
an addition. To go fast, we don't look at all  

27
00:02:24,080 --> 00:02:29,040
possible start and end logits, but the twenty 
best ones. We ignore the logits that spawn  

28
00:02:29,040 --> 00:02:34,240
impossible answers or answer that are too long. 
As we saw in the preprocessing, the labels (0,  

29
00:02:34,240 --> 00:02:38,880
0) correspond to no answer, otherwise we use the 
offsets to get the answer inside the context.  

30
00:02:39,920 --> 00:02:43,760
Let's have a look at the predicted answer 
for the first feature, which is the answer  

31
00:02:43,760 --> 00:02:47,680
with the best score (or the best logit score 
since the SoftMax is an increasing function).  

32
00:02:48,480 --> 00:02:54,000
The model got it right! Next we just 
have to loop this for every example,  

33
00:02:54,000 --> 00:02:58,880
picking for each the answer with the best logit 
score in all the features the example generated.  

34
00:02:59,840 --> 00:03:03,840
Now you know how to get answers 
from your model predictions!
