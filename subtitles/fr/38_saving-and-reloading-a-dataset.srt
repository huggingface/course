1
00:00:06,560 --> 00:00:11,600
Enregistrement et rechargement d'un jeu de données. Dans cette vidéo, nous allons examiner l'enregistrement d'un jeu de données dans différents

2
00:00:11,600 --> 00:00:19,200
formats et explorer les moyens de recharger les données enregistrées. Lorsque vous téléchargez un jeu de données, les

3
00:00:19,200 --> 00:00:23,920
scripts de traitement et les données sont stockés localement sur votre ordinateur. Le cache permet à la bibliothèque Datasets

4
00:00:23,920 --> 00:00:29,600
d'éviter de retélécharger ou de traiter l'intégralité du jeu de données à chaque fois que vous l'utilisez. Les données sont stockées

5
00:00:29,600 --> 00:00:34,080
sous la forme d'Arrow tables dont l'emplacement peut être trouvé en accédant à l'attribut `cache_files`.

6
00:00:34,080 --> 00:00:39,360
Dans cet exemple, nous avons téléchargé le jeu de données allocine à partir du Hub d'Hugging Face

7
00:00:39,360 --> 00:00:43,840
et vous pouvez voir qu'il y a trois fichiers Arrow stockés dans le cache, un pour chaque échantillon.

8
00:00:45,120 --> 00:00:48,720
Mais dans de nombreux cas, vous souhaiterez enregistrer votre jeu de données dans un emplacement ou un format différent.

9
00:00:49,600 --> 00:00:53,760
Comme indiqué dans le tableau, la bibliothèque Datasets fournit quatre fonctions principales pour y parvenir.

10
00:00:54,880 --> 00:00:59,040
Vous connaissez probablement les formats CSV et JSON , qui sont tous deux parfaits si vous

11
00:00:59,040 --> 00:01:04,800
souhaitez enregistrer des jeux de données de petite à moyenne taille. Mais si votre jeu de données est volumineux, vous souhaiterez

12
00:01:04,800 --> 00:01:09,520
l'enregistrer au format Arrow ou Parquet. Les fichiers Arrow sont parfaits si vous prévoyez de recharger

13
00:01:09,520 --> 00:01:14,080
ou de traiter les données dans un avenir proche. Les fichiers Parquet sont conçus pour un stockage sur disque à long terme

14
00:01:14,080 --> 00:01:17,440
et sont très économes en espace. Examinons de plus près chaque format.

15
00:01:19,520 --> 00:01:25,520
Pour enregistrer un jeu de données ou un objet DatasetDict au format Arrow, nous utilisons la fonction `save_to_disk`. Comme

16
00:01:25,520 --> 00:01:30,240
vous pouvez le voir dans cet exemple, nous fournissons simplement le chemin dans lequel nous souhaitons enregistrer les données, et la bibliothèque Datasets

17
00:01:30,240 --> 00:01:34,720
créera automatiquement un dépôt pour chaque échantillon afin de stocker l'Arrow table et les métadonnées.

18
00:01:35,600 --> 00:01:38,880
Étant donné que nous avons affaire à un objet DatasetDict comportant plusieurs divisions,

19
00:01:38,880 --> 00:01:41,920
ces informations sont également stockées dans le fichier `dataset_dict.json`.

20
00:01:44,160 --> 00:01:48,000
Désormais, lorsque nous souhaitons recharger les jeux de données Arrow, nous utilisons la fonction `load_from_disk`.

21
00:01:48,640 --> 00:01:53,840
Nous passons simplement le chemin de notre dépôt de jeu de données et voilà ! Le jeu de données d'origine est récupéré.

22
00:01:55,760 --> 00:01:59,920
Si nous voulons enregistrer nos jeux de données au format CSV, nous utilisons la fonction `to_csv`.

23
00:02:00,800 --> 00:02:05,280
Dans ce cas, vous devrez boucler sur les échantillons de l'objet DatasetDict et enregistrer chaque jeu de données en tant

24
00:02:05,280 --> 00:02:11,280
que fichier CSV individuel. Étant donné que le fichier `to_csv` est basé sur celui de Pandas, vous pouvez transmettre

25
00:02:11,280 --> 00:02:16,240
des arguments mots clés pour configurer la sortie. Dans cet exemple, nous avons défini l'argument `index` sur

26
00:02:16,240 --> 00:02:23,440
`None` pour empêcher la colonne d'index du jeu de données d'être incluse dans les fichiers CSV. Pour recharger nos

27
00:02:23,440 --> 00:02:29,760
fichiers CSV, nous utilisons la fonction familière `load_dataset` avec le script de chargement csv et

28
00:02:29,760 --> 00:02:35,120
l'argument `data_files` qui spécifie les noms de fichiers associés à chaque échantillon. Comme vous pouvez le voir dans cet exemple,

29
00:02:35,120 --> 00:02:39,280
en fournissant toutes les échantillons et leurs noms de fichiers, nous avons récupéré l'objet DatasetDict d'origine.

30
00:02:41,840 --> 00:02:45,920
L'enregistrement d'un jeu de données aux formats JSON ou Parquet est très similaire au cas CSV.

31
00:02:46,480 --> 00:02:52,720
Nous utilisons soit la fonction `to_json` pour les fichiers JSON, soit la fonction `to_parquet` pour les fichiers Parquet. Et

32
00:02:52,720 --> 00:02:57,440
tout comme dans le cas CSV, nous devons boucler sur les échantillons et enregistrer chacune dans un fichier individuel.

33
00:02:59,680 --> 00:03:03,760
Une fois que nos jeux de données sont enregistrés en tant que fichiers JSON ou Parquet, nous pouvons les recharger à nouveau

34
00:03:03,760 --> 00:03:09,680
avec le script approprié dans la fonction `load_dataset` et nous devons juste donner l'argument `data_files` comme auparavant.

35
00:03:10,640 --> 00:03:14,160
Cet exemple montre comment recharger nos jeux de données enregistrés dans l'un ou l'autre format.

36
00:03:16,400 --> 00:03:26,000
Et avec cela, vous savez maintenant comment enregistrer vos jeux de données dans différents formats !