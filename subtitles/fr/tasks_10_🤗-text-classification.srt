1
00:00:00,840 --> 00:00:06,420
Bienvenue dans la série d'Hugging Face sur les tâches ! Dans cette vidéo, nous allons nous pencher sur la classification de texte. 

2
00:00:08,940 --> 00:00:12,180
Dans la classification de texte, les modèles reçoivent un texte  

3
00:00:12,180 --> 00:00:16,500
en entrée et renvoient des étiquettes de classe et leurs probabilités associées. 

4
00:00:19,740 --> 00:00:23,220
Il existe de nombreuses variantes de cette tâche qui vous permettent d'analyser les sentiments,  

5
00:00:23,220 --> 00:00:29,520
d'évaluer l'exactitude grammaticale, de déterminer si une question est une paraphrase d'une autre ou  

6
00:00:29,520 --> 00:00:35,400
déterminer si une affirmation est correcte au regard d'un texte donné. Nous ne les aborderons pas tous dans  

7
00:00:35,400 --> 00:00:40,020
Vous pouvez consulter la page sur la tâche de classification de textes pour plus de détails. 

8
00:00:43,020 --> 00:00:47,340
L'analyse des sentiments consiste à déterminer le sentiment d'un texte donné. 

9
00:00:48,300 --> 00:00:53,640
Ce modèle reçoit un texte et renvoie la polarité ou l'émotion qu'il contient. 

10
00:00:56,340 --> 00:01:03,120
Une autre variante est l'inférence en langage naturel. Les modèles d'inférence en langage naturel prennent une prémisse et une hypothèse et renvoient  

11
00:01:03,120 --> 00:01:11,160
une étiquette. Si l'hypothèse est vraie le modèle de NLI renvoie "entailment", si l'hypothèse est fausse,  

12
00:01:11,160 --> 00:01:15,900
il renvoie "contradiction" ou s'il n'y a pas de relation il renvoie "neutral". 

13
00:01:19,140 --> 00:01:23,460
Les modèles de question de NLI prennent un texte et une question et renvoient une implication. 

14
00:01:24,000 --> 00:01:29,280
si la réponse à la question peut être trouvée dans un texte, et ne renvoient pas d'implication dans le cas contraire.  

15
00:01:30,000 --> 00:01:34,200
Ce modèle peut être utilisé pour modéliser les problèmes de recherche d'information. 

16
00:01:37,500 --> 00:01:45,060
GLUE est un benchmark utilisé pour mesurer les performances des modèles de NLP sur 10 tâches de classification de texte différents.  

17
00:01:45,060 --> 00:01:50,280
Ces jeux de données sont également utiles pour finetuner les modèles de classification de texte ! 

18
00:01:52,620 --> 00:01:56,040
Les modèles de classification de texte sont évalués en fonction de leur précision,  

19
00:01:56,040 --> 00:02:01,200
et du score F1. Les métriques sont calculées pour chacune des étiquettes de classe prédites pour  

20
00:02:01,200 --> 00:02:05,700
les textes et la moyenne est utilisée pour mesurer la performance globale du modèle. 

21
00:02:08,820 --> 00:02:14,160
Dans un exemple de cas d'utilisation, vous pouvez classer les commentaires de vos clients à partir du produit  

22
00:02:14,160 --> 00:02:19,560
ou des tweets à l'aide de modèles d'analyse des sentiments afin de prendre de meilleures décisions commerciales. 

23
00:02:22,740 --> 00:02:26,940
Pour plus d'informations sur la classification de textes, consultez la page consacrée aux tâches.