1
00:00:05,600 --> 00:00:10,080
Dans nos autres vidéos, et comme toujours, il y aura des liens ci-dessous si vous souhaitez les consulter,

2
00:00:10,640 --> 00:00:15,600
nous vous avons montré comment initialiser et finetuner un transformer dans TensorFlow.

3
00:00:15,600 --> 00:00:20,800
Donc la question est maintenant : que pouvons-nous faire avec un modèle après l'avoir entraîné ? La chose évidente à

4
00:00:20,800 --> 00:00:26,080
essayer est de l'utiliser pour obtenir des prédictions pour de nouvelles données, alors voyons comment procéder. Encore une fois,

5
00:00:26,080 --> 00:00:31,120
si vous connaissez Keras, la bonne nouvelle est que, comme il n'y a que des modèles Keras standard,

6
00:00:31,680 --> 00:00:35,440
nous pouvons utiliser la méthode Keras `predict()` standard, comme illustré ici.

7
00:00:36,800 --> 00:00:42,800
Vous transmettez simplement du texte tokenisé à cette méthode, comme vous le feriez avec un tokenizer, et vous obtenez vos

8
00:00:42,800 --> 00:00:48,320
résultats. Nos modèles peuvent produire plusieurs choses différentes, selon les options que vous définissez,

9
00:00:48,320 --> 00:00:53,280
mais la plupart du temps, ce que vous voulez, ce sont les logits de sortie. Si vous ne les avez jamais rencontrés

10
00:00:53,280 --> 00:01:02,960
auparavant, les logits sont les sorties de la dernière couche du réseau, avant l'application d'une softmax.

11
00:01:02,960 --> 00:01:08,400
Donc, si vous voulez transformer les logits en sorties de probabilité du modèle, il vous suffit d'appliquer une softmax

12
00:01:08,400 --> 00:01:13,840
comme ceci. Et si nous voulions transformer ces probabilités en prédictions de classe ?

13
00:01:14,853 --> 00:01:20,960
C'est simple : nous sélectionnons simplement la probabilité la plus élevée pour chaque sortie ! Pour ce faire, le moyen le plus simple consiste à utiliser

14
00:01:20,960 --> 00:01:26,960
la fonction argmax. Argmax renverra l'indice de la probabilité la plus élevée dans chaque ligne,

15
00:01:26,960 --> 00:01:36,400
ce qui signifie dans ce cas que nous obtiendrons un 0 si la probabilité est la plus évelée à l'indice 0, un 1 si la probabilité est la plus évelée à l'indice 0, etc.

16
00:01:37,360 --> 00:01:45,440
Ce sont des prédictions de classes : classe 0, classe 1, etc. En fait, si les prédictions de classe sont tout ce que vous voulez, vous pouvez

17
00:01:45,440 --> 00:01:50,240
entièrement ignorer l'étape softmax, car le logit le plus grand sera toujours la probabilité la plus élevée

18
00:01:52,400 --> 00:01:56,800
également. Si les probabilités et les prédictions de classe sont tout ce que vous voulez, alors vous avez vu tout ce dont vous   avez

19
00:01:56,800 --> 00:02:02,000
besoin à ce stade ! Mais si vous souhaitez comparer votre modèle ou l'utiliser pour la recherche,

20
00:02:02,000 --> 00:02:06,320
vous voudrez peut-être approfondir les résultats que vous obtenez. Et l'une des manières d'y parvenir consiste à calculer

21
00:02:06,320 --> 00:02:10,880
des métriques pour les prédictions du modèle. Si vous suivez nos vidéos sur Datasets

22
00:02:10,880 --> 00:02:16,400
et le finetuning, nous avons obtenu nos données à partir du jeu de données MRPC, qui fait partie du benchmark GLUE.

23
00:02:16,960 --> 00:02:24,480
Chacun des jeux de données GLUE, ainsi que bon nombre de nos autres jeux de données sur le Hub, possède des métriques prédéfinies,

24
00:02:24,480 --> 00:02:31,520
et nous pouvons les charger facilement avec la fonction `load_metric()`. Pour le jeu de données MRPC,

25
00:02:31,520 --> 00:02:36,080
les métriques intégrées sont la précision, qui mesure simplement le pourcentage de fois où la prédiction du modèle

26
00:02:36,080 --> 00:02:42,160
était correcte, et le score F1, qui est une mesure légèrement plus complexe qui mesure à quel

27
00:02:42,160 --> 00:02:48,960
point le modèle compense précision et rappel. Pour calculer ces métriques afin de comparer notre modèle,

28
00:02:48,960 --> 00:02:54,000
nous leur transmettons simplement les prédictions du modèle et les étiquettes de vérité terrain, et nous obtenons nos résultats simplement avec `.predict()`.

29
00:02:56,720 --> 00:03:01,120
Si vous connaissez Keras, vous remarquerez qu'il s'agit d'une façon étrange de calculer les

30
00:03:01,120 --> 00:03:06,880
métriques : nous ne calculons les métriques qu'à la fin de l'entraînement, mais Keras a la capacité intégrée de

31
00:03:06,880 --> 00:03:14,960
calculer un large éventail de statistiques à la volée pendant votre entraînement. Si vous souhaitez utiliser

32
00:03:14,960 --> 00:03:21,920
des calculs de métriques intégrés, c'est très simple et vous utilisez à nouveau l'approche standard de Keras. Il vous suffit de transmettre un argument `metric` à la méthode `compile()`.

33
00:03:22,960 --> 00:03:28,240
Comme pour des choses comme la perte et l'optimiseur, vous pouvez spécifier les métriques que vous voulez par chaîne,

34
00:03:28,240 --> 00:03:33,520
ou vous pouvez importer les objets de métrique réels si vous souhaitez leur transmettre des arguments spécifiques, mais notez

35
00:03:33,520 --> 00:03:40,880
que contrairement à la perte et à la précision, vous devez fournir les métriques comme une liste, même si vous n'en avez qu'une. Une fois

36
00:03:40,880 --> 00:03:46,320
qu'un modèle a été compilé avec une métrique, cela rapporte cette métrique pour l'entraînement, la validation et les

37
00:03:49,840 --> 00:03:54,880
prédictions en assumant avoir des étiquettes pour les prédictions. Vous pouvez même écrire vos propres classes de métriques. Bien que cela dépasse un peu le cadre

38
00:03:54,880 --> 00:03:59,440
de ce cours, je vais créer un lien vers les documents TF pertinents ci-dessous, car cela peut être très pratique

39
00:03:59,440 --> 00:04:10,800
si vous souhaitez une statistique qui n'est pas prise en charge par défaut dans Keras, comme le score F1.