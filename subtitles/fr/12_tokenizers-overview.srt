1
00:00:03,840 --> 00:00:09,200
Dans ces quelques vidéos, nous allons jeter un œil aux tokenizers. Dans le traitement du langage naturel, la

2
00:00:09,200 --> 00:00:14,880
plupart des données que nous traitons sont constituées de texte brut. Cependant, les modèles d'apprentissage automatique ne peuvent pas lire

3
00:00:14,880 --> 00:00:23,200
et comprendre le texte dans sa forme brute, ils ne peuvent travailler qu'avec des nombres. L'objectif du tokenizer

4
00:00:23,200 --> 00:00:30,080
sera de traduire le texte en chiffres. Il existe plusieurs approches possibles pour cette conversion,

5
00:00:30,080 --> 00:00:33,120
et l'objectif est de trouver la représentation la plus significative.

6
00:00:36,000 --> 00:00:40,400
Nous allons examiner trois algorithmes de tokenisation distincts. Nous les comparons un à un,

7
00:00:40,400 --> 00:00:44,880
nous vous recommandons donc de regarder les vidéos dans l'ordre suivant : basé sur les mots, basé sur les

8
00:00:45,680 --> 00:00:55,680
caractères et enfin basé sur les sous-mots.