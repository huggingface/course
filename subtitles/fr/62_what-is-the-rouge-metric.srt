1
00:00:05,520 --> 00:00:12,080
Qu'est-ce que la métrique ROUGE ? Pour de nombreuses tâches de NLP, nous pouvons utiliser des métriques courantes telles que la précision ou le score F1,

2
00:00:12,080 --> 00:00:15,920
mais que faites-vous lorsque vous souhaitez mesurer la qualité d'un résumé à partir d'un modèle comme T5 ?

3
00:00:16,720 --> 00:00:20,265
Dans cette vidéo, nous allons examiner une métrique largement utilisée pour la synthèse de texte appelée ROUGE.

4
00:00:20,265 --> 00:00:23,360
Il existe en fait plusieurs

5
00:00:23,360 --> 00:00:27,280
variantes de ROUGE mais l'idée de base derrière chacune d'elles est d'attribuer un seul

6
00:00:27,280 --> 00:00:31,360
score numérique à un résumé qui nous indique à quel point il est bon par rapport à un ou plusieurs résumés de référence.

7
00:00:32,320 --> 00:00:35,360
Dans cet exemple, nous avons une critique de livre qui a été résumée par un modèle.

8
00:00:36,400 --> 00:00:39,600
Si nous comparons le résumé généré à certains résumés humains de référence,

9
00:00:39,600 --> 00:00:43,840
nous pouvons voir que le modèle est plutôt bon et ne diffère que d'un mot ou deux.

10
00:00:44,800 --> 00:00:48,000
Alors, comment mesurer automatiquement la qualité d'un résumé généré ?

11
00:00:48,800 --> 00:00:52,880
L'approche adoptée par ROUGE consiste à comparer les n-grammes du résumé généré aux

12
00:00:52,880 --> 00:00:58,400
n-grammes des références. Un n-gramme n'est qu'une façon élégante de dire « un morceau de n mots ».

13
00:00:58,400 --> 00:01:02,080
Donc commençons par les unigrammes, qui correspondent aux mots individuels d'une phrase.

14
00:01:03,600 --> 00:01:07,760
Dans cet exemple, vous pouvez voir que six des mots du résumé généré se retrouvent également dans l'un des

15
00:01:07,760 --> 00:01:11,840
résumés de référence. La métrique ROUGE qui compare les unigrammes est appelée ROUGE-1.

16
00:01:14,000 --> 00:01:18,000
Maintenant que nous avons trouvé nos correspondances, une façon d'attribuer un score au résumé consiste à calculer le

17
00:01:18,000 --> 00:01:22,880
rappel des unigrammes. Cela signifie que nous comptons simplement le nombre de mots correspondants dans les résumés générés et de

18
00:01:22,880 --> 00:01:27,040
référence et normalisons le nombre en divisant par le nombre de mots dans la référence.

19
00:01:28,000 --> 00:01:31,920
Dans cet exemple, nous avons trouvé 6 mots correspondants et notre référence a 6 mots,

20
00:01:31,920 --> 00:01:36,240
donc notre rappel d'unigramme est parfait ! Cela signifie que tous les mots du

21
00:01:36,240 --> 00:01:42,320
résumé de référence ont été produits dans celui généré. Un rappel parfait sonne bien mais imaginez si

22
00:01:42,320 --> 00:01:47,120
notre résumé généré avait été « J'ai vraiment vraiment vraiment adoré lire Hunger Games ».

23
00:01:47,920 --> 00:01:52,240
Cela aurait également un rappel parfait mais c'est sans doute un pire résumé car il est verbeux.

24
00:01:53,280 --> 00:01:57,840
Pour gérer ces scénarios, nous pouvons également calculer la précision, qui dans le contexte ROUGE mesure

25
00:01:57,840 --> 00:02:01,200
la proportion du résumé généré qui était pertinente. Dans cet exemple, la précision est de 6/7. En pratique,

26
00:02:01,200 --> 00:02:05,200
la précision et le rappel sont généralement calculés, puis le score F1 est rapporté.

27
00:02:07,360 --> 00:02:12,000
Nous pouvons modifier la granularité de la comparaison en comparant des bigrammes au lieu d'unigrammes.

28
00:02:12,800 --> 00:02:17,760
Avec les bigrammes, nous décomposons la phrase en paires de mots consécutifs puis comptons le nombre de paires dans

29
00:02:17,760 --> 00:02:23,600
le résumé généré qui sont présentes dans celui de référence. Cela nous donne une précision et un rappel ROUGE-2,

30
00:02:23,600 --> 00:02:28,800
dont nous pouvons constater qu'ils sont inférieurs aux scores ROUGE-1 que nous avons vus précédemment. Notez que si les résumés sont

31
00:02:28,800 --> 00:02:34,560
longs, le score ROUGE-2 sera faible car il y a généralement moins de bigrammes à faire correspondre. Cela est

32
00:02:34,560 --> 00:02:39,680
également vrai pour la synthèse abstraite, donc les scores ROUGE-1 et ROUGE-2 sont généralement rapportés.

33
00:02:41,760 --> 00:02:46,880
La dernière variante ROUGE dont nous parlerons est ROUGE-L. ROUGE-L ne compare pas les n-grammes,

34
00:02:46,880 --> 00:02:51,360
mais traite plutôt chaque résumé comme une séquence de mots, puis recherche la plus longue sous-séquence

35
00:02:51,360 --> 00:02:57,280
commune ou « LCS ». Une sous-séquence est une séquence qui apparaît dans le même ordre relatif,

36
00:02:57,280 --> 00:03:03,280
mais pas nécessairement contiguë. Ainsi, dans cet exemple, « J'ai adoré lire Hunger Games » est la sous-

37
00:03:03,280 --> 00:03:11,120
séquence commune la plus longue. Le principal avantage de ROUGE-L par rapport à ROUGE-1 ou ROUGE-2 est qu'il ne

38
00:03:11,120 --> 00:03:18,400
dépend pas de correspondances consécutives de n-grammes, il a donc tendance à capturer la structure de la phrase avec plus de précision.

39
00:03:18,400 --> 00:03:23,200
Calculer les scores ROUGE dans Datasets d'Hugging Face est très simple : utilisez simplement la fonction `load_metric()`,

40
00:03:23,760 --> 00:03:26,960
fournissez les résumés de votre modèle avec les références et vous êtes prêt !

41
00:03:28,560 --> 00:03:32,480
Le résultat du calcul contient de nombreuses informations ! La première chose que nous

42
00:03:32,480 --> 00:03:36,880
pouvons voir ici est que les intervalles de confiance de chaque score ROUGE sont fournis dans les champs `low`,

43
00:03:36,880 --> 00:03:41,680
`mid` et `high`. Ceci est très utile si vous voulez connaître la répartition de vos scores ROUGE lorsque vous

44
00:03:41,680 --> 00:03:48,080
comparez deux modèles ou plus. La deuxième chose à remarquer est que nous avons quatre types de score ROUGE.

45
00:03:48,080 --> 00:03:53,840
Nous avons déjà vu ROUGE-1, ROUGE-2 et ROUGE-L, alors qu'est-ce que ROUGE-LSUM ? Eh bien,

46
00:03:53,840 --> 00:03:58,800
la somme dans ROUGE-LSUM fait référence au fait que cette métrique est calculée sur l'ensemble d'un résumé,

47
00:03:58,800 --> 00:04:08,480
tandis que ROUGE-L est calculée comme la moyenne sur des phrases individuelles.