1
00:00:05,440 --> 00:00:11,760
Comment prétraiter des paires de phrases ? Nous avons vu comment tokeniser des phrases simples et

2
00:00:11,760 --> 00:00:17,280
les regrouper dans la vidéo « Regroupement des entrées ». Si ce code ne vous semble pas familier,

3
00:00:17,840 --> 00:00:23,680
assurez-vous de revoir cette vidéo ! Ici, nous nous concentrerons sur les tâches qui classent des paires de phrases.

4
00:00:24,720 --> 00:00:30,400
Par exemple, nous pouvons vouloir classer si deux textes sont des paraphrases ou non. Voici un exemple

5
00:00:30,400 --> 00:00:35,520
tiré du jeu de données Quora Question Pairs, qui se concentre sur l'identification de questions en double.

6
00:00:36,960 --> 00:00:39,760
Dans la première paire, les deux questions sont des doublons ;

7
00:00:40,400 --> 00:00:45,520
dans la seconde, elles ne le sont pas. Un autre problème de classification de paires est lorsque nous voulons savoir

8
00:00:45,520 --> 00:00:51,920
si deux phrases sont logiquement liées ou non (un problème appelé « Natural Language Inference » ou NLI).

9
00:00:52,880 --> 00:00:58,480
Dans cet exemple tiré du jeu de données MultiNLI, nous avons une paire de phrases pour chaque

10
00:00:58,480 --> 00:01:04,560
étiquette possible : contradiction, neutre ou implication (ce qui est une façon élégante de dire que la première phrase

11
00:01:04,560 --> 00:01:12,240
implique la seconde). Ainsi, classer des paires de phrases est un problème qui mérite d'être étudié. En fait,

12
00:01:12,240 --> 00:01:15,840
dans le benchmark GLUE (qui est un benchmark académique pour la classification de texte),

13
00:01:16,640 --> 00:01:20,800
8 des 10 ensembles de données sont axés sur des tâches utilisant des paires de phrases.

14
00:01:21,920 --> 00:01:26,320
C'est pourquoi les modèles comme BERT sont souvent pré-entraînés avec un double objectif :

15
00:01:26,320 --> 00:01:31,040
en plus de l'objectif de modélisation du langage, ils ont souvent un objectif lié aux paires de phrases.

16
00:01:31,840 --> 00:01:37,520
Par exemple, lors de la pré-entraînement, BERT voit des paires de phrases et doit prédire à la fois la

17
00:01:37,520 --> 00:01:42,080
valeur des tokens masqués de manière aléatoire et si la deuxième phrase découle de la première.

18
00:01:43,840 --> 00:01:47,920
Heureusement, le tokenizer de la bibliothèque Transformers dispose d'une API sympa

19
00:01:47,920 --> 00:01:53,840
pour gérer les paires de phrases : il vous suffit de les passer en tant que deux arguments au tokenizer.

20
00:01:54,640 --> 00:01:59,040
En plus des ID d'entrée et du masque d'attention que nous avons déjà étudiés, il renvoie un nouveau

21
00:01:59,040 --> 00:02:04,320
champ appelé `token_type_ids`, qui indique au modèle quels tokens appartiennent à la première phrase

22
00:02:04,880 --> 00:02:11,280
et lesquels appartiennent à la deuxième phrase. En zoomant un peu, voici les `input_ids`,

23
00:02:11,280 --> 00:02:16,800
alignés sur les tokens auxquels ils correspondent, leur `token_type_ids` et leur `attention_mask` respectifs.

24
00:02:18,240 --> 00:02:23,440
Nous pouvons voir que le tokenizer a également ajouté des tokens spéciaux, nous avons donc un token [CLS], les tokens

25
00:02:23,440 --> 00:02:29,920
de la première phrase, un token [SEP], les tokens de la deuxième phrase et un token [SEP] final.

26
00:02:31,440 --> 00:02:36,640
Si nous avons plusieurs paires de phrases, nous pouvons les tokeniser ensemble en passant la liste des

27
00:02:36,640 --> 00:02:42,880
premières phrases, puis la liste des secondes phrases et tous les arguments mots-clés que nous avons déjà étudiés,

28
00:02:42,880 --> 00:02:48,800
comme `padding=True`. En zoomant sur le résultat, nous pouvons voir comment le tokenizer a ajouté un rembourrage

29
00:02:48,800 --> 00:02:52,480
à la deuxième paire de phrases, pour faire en sorte que les deux sorties aient la même longueur,

30
00:02:53,440 --> 00:02:57,280
et traiter correctement les `token_type_ids` et les `attention_mask` pour les deux phrases.

31
00:02:58,720 --> 00:03:03,840
Tout est alors prêt à passer dans notre modèle !