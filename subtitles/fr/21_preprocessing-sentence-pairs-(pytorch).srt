1
00:00:05,200 --> 00:00:11,680
Comment prétraiter des paires de phrases ? Nous avons vu comment tokeniser des phrases simples et

2
00:00:11,680 --> 00:00:18,080
les regrouper dans la vidéo « Regroupement des entrées ». Si ce code ne vous semble pas familier,

3
00:00:18,080 --> 00:00:24,160
assurez-vous de revoir cette vidéo ! Ici, nous nous concentrerons sur les tâches qui classent des paires de phrases.

4
00:00:25,440 --> 00:00:30,960
Par exemple, nous pouvons vouloir classer si deux textes sont des paraphrases ou non. Voici un exemple

5
00:00:30,960 --> 00:00:36,320
tiré du jeu de données Quora Question Pairs, qui se concentre sur l'identification de questions en double.

6
00:00:37,360 --> 00:00:42,200
Dans la première paire, les deux questions sont des doublons ; dans la seconde, elles

7
00:00:43,360 --> 00:00:47,120
ne le sont pas. Un autre problème de classification de paires est lorsque nous voulons savoir si deux phrases

8
00:00:47,120 --> 00:00:54,000
sont logiquement liées ou non (un problème appelé « Natural Language Inference » ou NLI). Dans cet

9
00:00:54,000 --> 00:00:59,680
exemple tiré du jeu de données MultiNLI, nous avons une paire de phrases pour chaque étiquette possible :

10
00:00:59,680 --> 00:01:04,560
contradiction, neutre ou implication (ce qui est une façon élégante de dire que la première phrase

11
00:01:04,560 --> 00:01:09,280
implique la seconde). La classification des paires de phrases est donc un problème qui mérite d'être étudié.

12
00:01:10,080 --> 00:01:14,880
En fait, dans le benchmark GLUE (qui est un benchmark académique pour la classification de texte),

13
00:01:15,600 --> 00:01:19,600
8 des 10 ensembles de données sont axés sur des tâches utilisant des paires de phrases.

14
00:01:20,720 --> 00:01:24,240
C'est pourquoi les modèles comme BERT sont souvent pré-entraînés avec un double objectif :

15
00:01:25,120 --> 00:01:29,920
en plus de l'objectif de modélisation du langage, ils ont souvent un objectif lié aux paires de phrases.

16
00:01:31,040 --> 00:01:36,720
Par exemple, lors de la pré-entraînement, BERT voit des paires de phrases et doit prédire à la fois la

17
00:01:36,720 --> 00:01:41,040
valeur des tokens masqués de manière aléatoire et si la deuxième phrase découle de la première.

18
00:01:42,800 --> 00:01:46,640
Heureusement, le tokenizer de la bibliothèque Transformers dispose d'une API sympa

19
00:01:46,640 --> 00:01:52,000
pour gérer les paires de phrases : il vous suffit de les passer en tant que deux arguments au tokenizer.

20
00:01:53,200 --> 00:01:57,600
En plus des ID d'entrée et du masque d'attention que nous avons déjà étudiés, il renvoie un nouveau

21
00:01:57,600 --> 00:02:02,800
champ appelé `token_type_ids`, qui indique au modèle quels tokens appartiennent à la première phrase

22
00:02:03,440 --> 00:02:09,680
et lesquels appartiennent à la deuxième phrase. En zoomant un peu, voici les `input_ids`,

23
00:02:09,680 --> 00:02:14,480
alignés avec les tokens auxquels ils correspondent, leur `token_type_ids` et `attention_mask`

24
00:02:14,480 --> 00:02:21,360
respectifs. Nous pouvons voir que le tokenizer a également ajouté des tokens spéciaux, nous avons donc un token [CLS], les tokens de la

25
00:02:21,360 --> 00:02:28,720
première phrase, un token [SEP], les tokens de la deuxième phrase et un token [SEP] final. Si nous avons

26
00:02:28,720 --> 00:02:33,760
plusieurs paires de phrases, nous pouvons les tokeniser ensemble en passant la liste des premières phrases,

27
00:02:34,480 --> 00:02:39,360
puis la liste des secondes phrases et tous les arguments mots-clés que nous avons déjà étudiés, comme

28
00:02:39,360 --> 00:02:45,600
`padding=True`. En zoomant sur le résultat, nous pouvons voir comment le tokenizer a ajouté un rembourrage à la deuxième paire

29
00:02:45,600 --> 00:02:51,200
de phrases, pour que les deux sorties aient la même longueur, et ait correctement traité les `token_type_ids` 

30
00:02:51,200 --> 00:03:03,520
et les `attention_mask` pour les deux phrases. Tout est alors prêt à passer par notre modèle !