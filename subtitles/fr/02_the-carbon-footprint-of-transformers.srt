1
00:00:05,580 --> 00:00:08,820
Parlons donc de l'empreinte carbone des transformers.

2
00:00:08,820 --> 00:00:10,530
Vous avez peut-être vu des titres tels que celui-ci

3
00:00:10,530 --> 00:00:13,530
indiquant qu'entraîner un seul modèle d'IA peut entraîner autant d'émissions de CO2

4
00:00:13,530 --> 00:00:16,020
que cinq voitures dans leur vie.

5
00:00:16,020 --> 00:00:19,440
Alors quand est-ce vrai et est-ce toujours vrai ?

6
00:00:19,440 --> 00:00:21,803
En fait, cela dépend de plusieurs choses.

7
00:00:21,803 --> 00:00:23,430
Le plus important, c'est que cela dépend
8
00:00:23,430 --> 00:00:24,960
sur le type d'énergie que vous utilisez.

9
00:00:24,960 --> 00:00:26,267
Si vous utilisez une énergie renouvelable telle que le

10
00:00:26,267 --> 00:00:30,670
solaire, l'éolien, l'hydroélectrique, vous n'éméttez

11
00:00:30,670 --> 00:00:33,810
pas vraiment de carbone du tout. Très, très peu.

12
00:00:33,810 --> 00:00:36,769
Si vous utilisez des sources d'énergie non renouvelables telles que le charbon

13
00:00:36,769 --> 00:00:39,570
alors l'empreinte carbone est beaucoup plus élevée

14
00:00:39,570 --> 00:00:43,260
parce qu'en fait, vous émettez beaucoup de gaz à effet de serre.

15
00:00:43,260 --> 00:00:44,670
Un autre aspect est le temps d'entraînement.

16
00:00:44,670 --> 00:00:47,232
Donc, plus vous entraînez longtemps, plus vous dépensez d'énergie.

17
00:00:47,232 --> 00:00:50,250
Plus vous utilisez d'énergie, plus vous émettez de carbone.

18
00:00:50,250 --> 00:00:51,270
Donc, cela s'additionne.

19
00:00:51,270 --> 00:00:53,520
Surtout si vous entraînez de grands modèles

20
00:00:53,520 --> 00:00:56,460
pendant des heures, des jours et des semaines.

21
00:00:56,460 --> 00:00:58,380
Le matériel que vous utilisez a également son importance

22
00:00:58,380 --> 00:01:00,930
car certains GPU, par exemple, sont plus efficaces

23
00:01:00,930 --> 00:01:05,460
que d'autres et donc utiliser des GPU

24
00:01:05,460 --> 00:01:07,500
efficiement, correctement, à 100% tout le temps,

25
00:01:07,500 --> 00:01:10,650
peut vraiment réduire la consommation d'énergie que vous avez.

26
00:01:10,650 --> 00:01:13,290
Et encore une fois, réduire votre empreinte carbone.

27
00:01:13,290 --> 00:01:15,870
Il y a aussi d'autres aspects comme l'IO

28
00:01:15,870 --> 00:01:17,730
comme les données, etc., etc.

29
00:01:17,730 --> 00:01:20,940
Mais ce sont les trois principaux sur lesquels vous devez vous concentrer.

30
00:01:20,940 --> 00:01:23,340
Donc quand je parle de sources d'énergie et d'intensité de carbone

31
00:01:23,340 --> 00:01:24,420
Qu'est-ce que cela signifie vraiment ?

32
00:01:24,420 --> 00:01:27,480
Donc si vous regardez en haut de l'écran

33
00:01:27,480 --> 00:01:30,480
vous avez une empreinte carbone

34
00:01:30,480 --> 00:01:33,860
d'une instance de cloud computing à Mumbai en Inde

35
00:01:33,860 --> 00:01:38,700
qui émet 920 grammes de CO2 par kilowattheure.

36
00:01:38,700 --> 00:01:40,110
C'est presque un kilo

37
00:01:40,110 --> 00:01:43,680
de CO2 par kilowattheure d'électricité utilisé.

38
00:01:43,680 --> 00:01:45,150
Si vous comparez cela avec Montréal au Canada, 

39
00:01:45,150 --> 00:01:48,720
où je suis en ce moment, 20 grammes de CO2 par kilo heure.

40
00:01:48,720 --> 00:01:50,040
C'est donc une très, très grande différence.

41
00:01:50,040 --> 00:01:54,240
Près de 40 fois plus de carbone émis

42
00:01:54,240 --> 00:01:55,950
à Mumbai qu'à Montréal.

43
00:01:55,950 --> 00:01:57,720
Et donc cela peut vraiment, vraiment s'accumuler.

44
00:01:57,720 --> 00:01:59,820
Si vous entraînez un modèle pendant plusieurs semaines, par exemple

45
00:01:59,820 --> 00:02:01,920
vous multipliez par 40

46
00:02:01,920 --> 00:02:03,450
le carbone que vous émettez.

47
00:02:03,450 --> 00:02:05,070
Donc, choisir la bonne instance,

48
00:02:05,070 --> 00:02:07,080
choisir une instance de calcul à faible émission de carbone,

49
00:02:07,080 --> 00:02:09,690
est vraiment la chose la plus importante que vous puissiez faire.

50
00:02:09,690 --> 00:02:13,020
Et c'est là que cela peut vraiment s'accumuler

51
00:02:13,020 --> 00:02:15,930
si vous vous entrainez de manière très intensive

52
00:02:15,930 --> 00:02:17,580
dans une région à forte intensité de carbone.

53
00:02:19,170 --> 00:02:21,750
D'autres éléments à prendre en compte, par exemple

54
00:02:21,750 --> 00:02:22,770
utiliser des modèles pré-entraînés.

55
00:02:22,770 --> 00:02:25,590
C'est l'équivalent du recyclage pour l'apprentissage automatique.

56
00:02:25,590 --> 00:02:28,292
Lorsque vous disposez de modèles pré-entraînés, vous pouvez les utiliser.

57
00:02:28,292 --> 00:02:30,120
Vous n'émettez pas de carbone du tout.

58
00:02:30,120 --> 00:02:31,230
Vous ne ré-entraînez rien.

59
00:02:31,230 --> 00:02:33,450
Donc c'est aussi faire ses devoirs

60
00:02:33,450 --> 00:02:35,574
de regarder ce qui existe déjà.

61
00:02:35,574 --> 00:02:37,890
Finetuner au lieu d'entraîner à partir de zéro.

62
00:02:37,890 --> 00:02:38,723
Donc, une fois de plus,

63
00:02:38,723 --> 00:02:40,590
si vous trouvez un modèle qui correspond presque à ce dont vous avez besoin

64
00:02:40,590 --> 00:02:43,530
mais pas tout à fait, finetunez les dernières couches

65
00:02:43,530 --> 00:02:45,210
pour qu'il corresponde vraiment à votre objectif.

66
00:02:45,210 --> 00:02:46,500
au lieu d'entrâiner un gros transformer

67
00:02:46,500 --> 00:02:48,810
à partir de zéro. Cela peut vraiment aider.

68
00:02:48,810 --> 00:02:51,270
Commencer par de petites expériences

69
00:02:51,270 --> 00:02:52,800
et déboguer au fur et à mesure.

70
00:02:52,800 --> 00:02:54,630
Cela signifie, par exemple, 

71
00:02:54,630 --> 00:02:58,770
comprendre l'encodage des données,

72
00:02:58,770 --> 00:03:01,170
s'assurer qu'il n'y a pas de petits bugs, que vous allez

73
00:03:01,170 --> 00:03:03,840
réalisez, après 16 heures d'entraînement.

74
00:03:03,840 --> 00:03:05,820
Commencer petit et vraiment s'assurer

75
00:03:05,820 --> 00:03:08,760
de ce que vous faites, que votre code est stable.

76
00:03:08,760 --> 00:03:11,430
Et enfin, faire une revue de la littérature pour

77
00:03:11,430 --> 00:03:13,740
choisir des plages d'hyperparamètres pour ensuite poursuivre

78
00:03:13,740 --> 00:03:15,900
avec une recherche aléatoire au lieu d'une recherche par grille.

79
00:03:15,900 --> 00:03:18,420
Les recherches de combinaisons d'hyperparamètres

80
00:03:18,420 --> 00:03:21,300
aléatoires se sont avérés être aussi efficaces

81
00:03:21,300 --> 00:03:24,000
pour trouver la configuration optimale, que la recherche par grille.

82
00:03:24,000 --> 00:03:27,510
Mais évidemment, vous n'essayez pas toutes les combinaisons possibles,

83
00:03:27,510 --> 00:03:29,520
vous n'en essayez qu'un sous-ensemble.

84
00:03:29,520 --> 00:03:31,800
Cela peut donc être très utile.

85
00:03:31,800 --> 00:03:32,760
Donc maintenant, nous revenons

86
00:03:32,760 --> 00:03:36,300
à l'article original de Strubell et al. de 2019,

87
00:03:36,300 --> 00:03:39,180
l'infâme papier sur la vie des cinq voitures.

88
00:03:39,180 --> 00:03:40,013
Si vous regardez

89
00:03:40,013 --> 00:03:43,606
un transformer de 200 millions de paramètres,

90
00:03:43,606 --> 00:03:46,950
son empreinte carbone est d'environ 200 livres [87 kg] de CO2,

91
00:03:46,950 --> 00:03:47,940
ce qui est important.

92
00:03:47,940 --> 00:03:49,980
Mais c'est loin des cinq voitures.

93
00:03:49,980 --> 00:03:52,893
Ce n'est même pas un vol transatlantique.

94
00:03:52,893 --> 00:03:55,020
Ce qui compte vraiment, c'est lorsque vous faites

95
00:03:55,020 --> 00:03:56,190
vos recherches d'architectures neuronales,

96
00:03:56,190 --> 00:03:58,560
quand vous faites le réglage des hyperparamétres,

97
00:03:58,560 --> 00:04:00,930
en essayant toutes les combinaisons possibles,

98
00:04:00,930 --> 00:04:01,763
etc., etc.

99
00:04:01,763 --> 00:04:02,596
Et c'est là que

100
00:04:02,596 --> 00:04:05,400
d'où proviennent les 600 000 livres [272,16 t] de CO2.

101
00:04:05,400 --> 00:04:08,490
C'est donc là que les choses s'additionnent.

102
00:04:08,490 --> 00:04:11,880
Mais si vous faites les choses consciemment et consciencieusement,

103
00:04:11,880 --> 00:04:16,410
alors votre empreinte carbone ne sera pas aussi importante,

104
00:04:16,410 --> 00:04:20,040
comme le laissait entendre le papier. Quelques outils

105
00:04:20,040 --> 00:04:22,111
pour savoir combien de CO2 exactement vous émettez.

106
00:04:22,111 --> 00:04:24,270
Il y a un outil en ligne appelé « machine

107
00:04:24,270 --> 00:04:26,430
learning submissions calculator » qui vous permet

108
00:04:26,430 --> 00:04:29,010
de saisir manuellement, par exemple, le matériel que vous avez utilisé,

109
00:04:29,010 --> 00:04:30,488
le nombre d'heures pendant lesquelles vous l'avez utilisé,

110
00:04:30,488 --> 00:04:34,260
où il était situé : localement ou dans le cloud.

111
00:04:34,260 --> 00:04:35,640
Et puis il va vous donner une estimation

112
00:04:35,640 --> 00:04:37,560
de la quantité de CO2 que vous avez émise.

113
00:04:37,560 --> 00:04:40,200
Un autre outil qui fait cela de manière programmatique,

114
00:04:40,200 --> 00:04:41,190
s'appelle codecarbon.

115
00:04:41,190 --> 00:04:45,112
Vous pouvez l'installer avec pip, vous pouvez aller sur leur GitHub,

116
00:04:45,112 --> 00:04:48,120
et essentiellement il s'exécute en parallèle de votre code.

117
00:04:48,120 --> 00:04:49,085
Donc, vous l'appelez

118
00:04:49,085 --> 00:04:51,060
et ensuite vous faites tous vos entraînements.

119
00:04:51,060 --> 00:04:53,760
Et puis à la fin, il va vous donner une estimation :

120
00:04:53,760 --> 00:04:57,210
un fichier CSV contenant une estimation de vos émissions.

121
00:04:57,210 --> 00:04:59,250
Et ça va vous permettre de faire des comparaisons.

122
00:04:59,250 --> 00:05:01,230
Il y a une interface visuelle où vous pouvez

123
00:05:01,230 --> 00:05:04,680
comparer avec la conduite d'une voiture ou la télévision.

124
00:05:04,680 --> 00:05:06,060
Ainsi, cela peut vous donner une idée

125
00:05:06,060 --> 00:05:07,740
de la portée de vos émissions également.

126
00:05:07,740 --> 00:05:09,930
Et en fait, codecarbon est déjà intégré dans AutoNLP.

127
00:05:09,930 --> 00:05:12,270
et j'espère que les gens l'utiliseront

128
00:05:12,270 --> 00:05:15,240
pour suivre facilement leurs émissions tout au long

129
00:05:15,240 --> 00:05:17,523
de l'entraînement et le déploiement des transformers.