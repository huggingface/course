Bienvenue au cours d‚ÄôHugging Face

Ceci est une introduction au cours d‚ÄôHugging Face : http://huggingface.co/course/fr
Intervenants : Matthew Carrigan,  Lysandre Debut, Sylvain Gugger, Sacha Luccioni, Merve Noyan, Lucile Saulnier, Lewis Tunstall, Leandro von Werra
Traduction : Lo√Øck Bourdois
Vous voulez commencer par des vid√©os ? Pourquoi ne pas essayer :
- Qu'est-ce que l'apprentissage par transfert ? https://youtu.be/BqqfQnyjmgg
- La fonction pipeline : https://youtu.be/tiZFewofSLM
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



La fonction pipeline

La fonction pipeline et toutes les t√¢ches NLP qu'elle peut effectuer.
Intervenant : Sylvain Gugger 
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter1
Ouvrir les codes de la vid√©o dans Colab : 
- En anglais : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter1/section3.ipynb
- En fran√ßais : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/fr/chapter1/section3.ipynb
Vid√©os connexes :
- Derri√®re la fonction pipeline : https://youtu.be/1pedAIvTWXk
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



L'empreinte carbone des transformers

Vous √™tes-vous d√©j√† demand√© quelle √©tait l'empreinte carbone de l'entra√Ænement d'un transformers ? Et comment vous pouvez la r√©duire ? Alors ne cherchez pas plus loin que cette vid√©o.
Intervenant : Sacha Luccioni
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter1
Vid√©os connexes :
- Qu'est-ce que l'apprentissage par transfert ? https://youtu.be/BqqfQnyjmgg
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Qu'est-ce que l'apprentissage par transfert ?

Qu'est-ce que l'apprentissage par transfert, pourquoi et quand est-il utile ?
Intervenant : Sylvain Gugger 
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter1
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/training_loop.ipynb
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



L'architecture du transformer

Une introduction g√©n√©rale de haut niveau √† l'architecture du transformer.
Intervenant : Lysandre Debut
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter1
Vid√©os connexes :
- Mod√®les encodeur : https://youtu.be/MUqNwgPjJvQ
- Mod√®les d√©codeur : https://youtu.be/d_ixlCubqQw
- Mod√®les encodeur-d√©codeur : https://youtu.be/0_4KEb08xrE
Pour mieux comprendre ce qui se passe √† l'int√©rieur du transformer, nous vous recommandons les articles de blog suivants de Jay Alammar :
- Le Transformateur illustr√© : https://jalammar.github.io/illustrated-transformer/
- Le GPT-2 illustr√© : https://jalammar.github.io/illustrated-gpt2/
- Comprendre l'attention : https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/
En outre, pour une perspective ax√©e sur le code, nous vous recommandons de jeter un coup d'≈ìil √† l'article suivant :
- The Annotated Transformer, par Harvard NLP : https://nlp.seas.harvard.edu/2018/04/03/attention.html 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Transformer : l‚Äôencodeur

Une introduction g√©n√©rale de haut niveau √† la partie Encodeur du transformer.
Qu'est-ce que c'est, quand faut-il l'utiliser ?
Intervenant : Lysandre Debut
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter1
Vid√©os connexes :
- Mod√®les encodeur : https://youtu.be/MUqNwgPjJvQ
- Mod√®les d√©codeur : https://youtu.be/d_ixlCubqQw
- Mod√®les encodeur-d√©codeur : https://youtu.be/0_4KEb08xrE
Pour mieux comprendre ce qui se passe √† l'int√©rieur du transformer, nous vous recommandons les articles de blog suivants de Jay Alammar :
- Le Transformateur illustr√© : https://jalammar.github.io/illustrated-transformer/
- Le GPT-2 illustr√© : https://jalammar.github.io/illustrated-gpt2/
- Comprendre l'attention : https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/
En outre, pour une perspective ax√©e sur le code, nous vous recommandons de jeter un coup d'≈ìil √† l'article suivant :
- The Annotated Transformer, par Harvard NLP : https://nlp.seas.harvard.edu/2018/04/03/attention.html 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Transformer : l‚Äôencodeur

Une introduction g√©n√©rale de haut niveau √† la partie Encodeur du transformer.
Qu'est-ce que c'est, quand faut-il l'utiliser ?
Intervenant : Lysandre Debut
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter1
Vid√©os connexes :
- Mod√®les encodeur : https://youtu.be/MUqNwgPjJvQ
- Mod√®les d√©codeur : https://youtu.be/d_ixlCubqQw
- Mod√®les encodeur-d√©codeur : https://youtu.be/0_4KEb08xrE
Pour mieux comprendre ce qui se passe √† l'int√©rieur du transformer, nous vous recommandons les articles de blog suivants de Jay Alammar :
- Le Transformateur illustr√© : https://jalammar.github.io/illustrated-transformer/
- Le GPT-2 illustr√© : https://jalammar.github.io/illustrated-gpt2/
- Comprendre l'attention : https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/
En outre, pour une perspective ax√©e sur le code, nous vous recommandons de jeter un coup d'≈ìil √† l'article suivant :
- The Annotated Transformer, par Harvard NLP : https://nlp.seas.harvard.edu/2018/04/03/attention.html 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join


Transformer : le d√©codeur
Une introduction g√©n√©rale de haut niveau √† la partie d√©codeur du transformer.
Qu'est-ce que c'est, quand faut-il l'utiliser ?
Intervenant : Lysandre Debut
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter1
Vid√©os connexes :
- Mod√®les encodeur : https://youtu.be/MUqNwgPjJvQ
- Mod√®les d√©codeur : https://youtu.be/d_ixlCubqQw
- Mod√®les encodeur-d√©codeur : https://youtu.be/0_4KEb08xrE
Pour mieux comprendre ce qui se passe √† l'int√©rieur du transformer, nous vous recommandons les articles de blog suivants de Jay Alammar :
- Le Transformateur illustr√© : https://jalammar.github.io/illustrated-transformer/
- Le GPT-2 illustr√© : https://jalammar.github.io/illustrated-gpt2/
- Comprendre l'attention : https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/
En outre, pour une perspective ax√©e sur le code, nous vous recommandons de jeter un coup d'≈ìil √† l'article suivant :
- The Annotated Transformer, par Harvard NLP : https://nlp.seas.harvard.edu/2018/04/03/attention.html 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Transformer : l‚Äôencodeur-d√©codeur
Une introduction g√©n√©rale de haut niveau √† l'encodeur-d√©codeur, ou mod√®les de s√©quence √† s√©quence utilisant l'architecture Transformer. Qu'est-ce que c'est, quand faut-il l'utiliser ?
Intervenant : Lysandre Debut
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter1
Vid√©os connexes :
- Mod√®les encodeur : https://youtu.be/MUqNwgPjJvQ
- Mod√®les d√©codeur : https://youtu.be/d_ixlCubqQw
- Mod√®les encodeur-d√©codeur : https://youtu.be/0_4KEb08xrE
Pour mieux comprendre ce qui se passe √† l'int√©rieur du transformer, nous vous recommandons les articles de blog suivants de Jay Alammar :
- Le Transformateur illustr√© : https://jalammar.github.io/illustrated-transformer/
- Le GPT-2 illustr√© : https://jalammar.github.io/illustrated-gpt2/
- Comprendre l'attention : https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/
En outre, pour une perspective ax√©e sur le code, nous vous recommandons de jeter un coup d'≈ìil √† l'article suivant :
- The Annotated Transformer, par Harvard NLP : https://nlp.seas.harvard.edu/2018/04/03/attention.html 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Que se passe-t-il dans la fonction pipeline ? (PyTorch) 

Que se passe-t-il vraiment lorsque nous ex√©cutons un texte dans un pipeline cr√©√© avec la biblioth√®que ü§ó Transformers ? 
Intervenant : Sylvain Gugger
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter2
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/inside_pipeline_pt.ipynb 
Version TensorFlow : https://youtu.be/wVN12smEvqg 
Vid√©os connexes : 
- La fonction pipeline : https://youtu.be/tiZFewofSLM 
- En savoir plus sur le pipeline de tokenization : https://youtu.be/Yffk5aydLzg 
- En savoir plus sur l'instanciation d'un transformer : https://youtu.be/AhChOFRegn4 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Que se passe-t-il dans la fonction pipeline ? (TensorFlow) 

Que se passe-t-il vraiment lorsque nous ex√©cutons un texte dans un pipeline cr√©√© avec la biblioth√®que ü§ó Transformers ? 
Intervenant : Sylvain Gugger
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter2
Ouvrir les codes de la vid√©o dans Colab : Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/inside_pipeline_pt.ipynb 
Version PyTorch : https://youtu.be/1pedAIvTWXk
Vid√©os connexes :
- La fonction pipeline : https://youtu.be/tiZFewofSLM
- En savoir plus sur le pipeline de tok√©nisation : https://youtu.be/Yffk5aydLzg
- En savoir plus sur l'instanciation d'un transformer : https://youtu.be/d3JVgghSOew
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Instancier un transformer (PyTorch) 

Instanciez n'importe quel mod√®le de la biblioth√®que ü§ó Transformers, en utilisant un checkpoint pr√©-entra√Æn√© ou simplement des poids al√©atoires.
Intervenant : Sylvain Gugger
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter2
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/model_api_pt.ipynb
Version TensorFlow : https://youtu.be/d3JVgghSOew 
Vid√©os connexes : 
- La fonction pipeline : https://youtu.be/tiZFewofSLM 
- L'API push_to_hub : https://youtu.be/A5IWIxsHLUw
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Instancier un transformers (TensorFlow) 

Instanciez n'importe quel mod√®le de la biblioth√®que ü§ó Transformers, en utilisant un checkpoint pr√©-entra√Æn√© ou simplement des poids al√©atoires.
Intervenant : Sylvain Gugger
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter2
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/model_api_pt.ipynb
Version PyTorch : https://youtu.be/AhChOFRegn4
Vid√©os connexes : 
- La fonction pipeline : https://youtu.be/tiZFewofSLM 
- L'API push_to_hub : https://youtu.be/A5IWIxsHLUw
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Vue d'ensemble des tokenizers 

Une introduction g√©n√©rale sur les diff√©rents types de tokenizers. 
Intervenant : Lysandre Debut
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter2
Vid√©os connexes : 
- Tokenizers √† base de mots : https://youtu.be/nhJxYji1aho 
- Tokenizers √† base de caract√®res : https://youtu.be/ssLq_EK2jLE 
- Tokenizers √† base de sous-mots : https://youtu.be/zHvTiHr506c
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Tokenizers √† base de mots 

Qu'est-ce qu'un tokenizer √† base de mots, et quelles sont les forces et les faiblesses de ces tokenizers. Une introduction g√©n√©rale sur les diff√©rents types de tokenizers. 
Intervenant : Lysandre Debut
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter2
Vid√©os connexes : 
- Tokenizers √† base de mots : https://youtu.be/nhJxYji1aho 
- Tokenizers √† base de caract√®res : https://youtu.be/ssLq_EK2jLE 
- Tokenizers √† base de sous-mots : https://youtu.be/zHvTiHr506c
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Tokenizers √† base de caract√®res 

Qu'est-ce qu'un tokenizer √† base de caract√®res, et quelles sont les forces et les faiblesses de ces tokenizers. 
Intervenant : Lysandre Debut
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter2
Vid√©os connexes : 
- Tokenizers √† base de mots : https://youtu.be/nhJxYji1aho 
- Tokenizers √† base de caract√®res : https://youtu.be/ssLq_EK2jLE 
- Tokenizers √† base de sous-mots : https://youtu.be/zHvTiHr506c
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Tokenizers √† base de sous-mots

Qu'est-ce qu'un tokenizer √† base de sous-mots, et quelles sont les forces et les faiblesses de ces tokenizers. 
Intervenant : Lysandre Debut
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter2
Vid√©os connexes : 
- Tokenizers √† base de mots : https://youtu.be/nhJxYji1aho 
- Tokenizers √† base de caract√®res : https://youtu.be/ssLq_EK2jLE 
- Tokenizers √† base de sous-mots : https://youtu.be/zHvTiHr506c
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Le pipeline de tok√©nisation 

Que se passe-t-il lorsque nous appelons un tokenizer sur certains textes et comment calcule-t-il les nombres qu'il produit ? 
Intervenant : Sylvain Gugger
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter2
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/tokenizer_pipeline.ipynb
Vid√©os connexes : 
- La fonction pipeline : https://youtu.be/tiZFewofSLM 
- En savoir plus sur les algorithmes du tokenizer : https://youtu.be/VFp38yj8h3A 
- En savoir plus sur les masques d'attention : https://youtu.be/M6adb1j2jPI 
- En savoir plus sur les token de type identifiant : https://youtu.be/0u3ioSwev3s
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Regroupement des entr√©es (PyTorch) 

Comment pouvons-nous regrouper diff√©rentes phrases de diff√©rentes longueurs et nous assurer que nous obtenons le m√™me r√©sultat lorsque nous les passons dans le mod√®le sous forme de batch ou de phrases individuelles. 
Intervenant : Sylvain Gugger
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter2
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/batch_inputs_pt.ipynb
Version TensorFlow : https://youtu.be/ROxrFOEbsQE 
Vid√©os connexes : 
- La fonction pipeline : https://youtu.be/tiZFewofSLM 
- Le pipeline de tokenisation : https://youtu.be/Yffk5aydLzg
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Regroupement des entr√©es (TensorFlow) 

Comment pouvons-nous regrouper diff√©rentes phrases de diff√©rentes longueurs et nous assurer que nous obtenons le m√™me r√©sultat lorsque nous les passons dans le mod√®le sous forme de batch ou de phrases individuelles. 
Intervenant : Sylvain Gugger
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter2
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/batch_inputs_pt.ipynb
Version PyTorch : https://youtu.be/M6adb1j2jPI
Vid√©os connexes : 
- La fonction pipeline : https://youtu.be/tiZFewofSLM 
- Le pipeline de tokenisation : https://youtu.be/Yffk5aydLzg
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Vue d'ensemble de Datasets d'Hugging Face (PyTorch) 

Une introduction rapide √† la biblioth√®que ü§ó Datasets : comment l'utiliser pour t√©l√©charger et pr√©traiter un jeu de donn√©es. 
Intervenant : Sylvain Gugger
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter3
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/datasets_overview_pt.ipynb
TensorFlow version: https://youtu.be/W_gMJF0xomE 
Vid√©os connexes : 
- Comment pr√©traiter des paires de phrases : https://youtu.be/0u3ioSwev3s ü§ó
- Documentation de Datasets: https://huggingface.co/docs/datasets/
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Vue d'ensemble de Datasets d'Hugging Face (Tensorflow) 

Une introduction rapide √† la biblioth√®que ü§ó Datasets : comment l'utiliser pour t√©l√©charger et pr√©traiter un jeu de donn√©es. 
Intervenant : Sylvain Gugger
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter3
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/datasets_overview_pt.ipynb
Version PyTorch : https://youtu.be/_BZearw7f0w
Vid√©os connexes : 
- Comment pr√©traiter des paires de phrases : https://youtu.be/0u3ioSwev3s ü§ó
- Documentation de Datasets: https://huggingface.co/docs/datasets/
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Pr√©traitement de paires de phrases (PyTorch) 

Beaucoup de probl√®mes de classification de textes traitent de paires de phrases, comment utiliser la biblioth√®que Transformers et ses tokenizers pour les pr√©traiter ? 
Intervenant : Sylvain Gugger
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter3
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/sentence_pairs_pt.ipynb
Version TensorFlow : https://youtu.be/P-rZWqcB6CE 
Vid√©os connexes : 
- Le pipeline de tokenisation : https://youtu.be/Yffk5aydLzg 
- Comment regrouper les entr√©es : https://youtu.be/M6adb1j2jPI
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Pr√©traitement de paires de phrases (TensorFlow) 

Beaucoup de probl√®mes de classification de textes traitent de paires de phrases, comment utiliser la biblioth√®que Transformers et ses tokenizers pour les pr√©traiter ? 
Intervenant : Sylvain Gugger
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter3
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/sentence_pairs_pt.ipynb
Version PyTorch : https://youtu.be/0u3ioSwev3s
Vid√©os connexes : 
- Le pipeline de tokenisation : https://youtu.be/Yffk5aydLzg 
- Comment regrouper les entr√©es : https://youtu.be/M6adb1j2jPI
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Qu'est-ce que le rembourrage dynamique ? 

Qu'est-ce que le rembourrage dynamique et diff√®re-t-il du rembourrage fixe traditionnel ?
Intervenant : Sylvain Gugger
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter3
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/dynamic_padding.ipynb
Vid√©os connexes : 
- Comment pr√©traiter des paires de phrases : https://youtu.be/0u3ioSwev3s 
- La biblioth√®que ü§ó Datasets : https://youtu.be/_BZearw7f0w
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



L'API Trainer 

L'API Trainer de la biblioth√®que Transformers, et comment l'utiliser pour affiner un mod√®le. 
Intervenant : Sylvain Gugger
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter3
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/trainer_api.ipynb
Vid√©os connexes : 
- Comment instancier un transformer : https://youtu.be/AhChOFRegn4 
- Comment pr√©traiter des paires de phrases : https://youtu.be/0u3ioSwev3s 
- La biblioth√®que ü§ó Datasets : https://youtu.be/_BZearw7f0w 
- Qu'est-ce que le rembourrage dynamique : https://youtu.be/7q5NyFT8REg
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Introduction √† Keras 

Qu'est-ce que Keras et comment l'utiliser avec les transformers. 
Intervenant : Matthew Carrigan
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter3
Vid√©os connexes : 
- Vue d‚Äôensemble de Datasets : https://youtu.be/W_gMJF0xomE 
- Finetuning avec TensorFlow : https://youtu.be/alq1l8Lv9GA 
- Plannification du taux d'apprentissage dans TensorFlow : https://youtu.be/eKv4rRcCNX0 
- Pr√©diction et m√©triques : https://youtu.be/nx10eh4CoOs
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Finetuning avec TensorFlow 

Finetunons un transformer dans TensorFlow, en utilisant Keras. 
Intervenant : Matthew Carrigan
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter3
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/tensorflow_finetuning.ipynb
Vid√©os connexes : 
- Qu'est-ce que l'apprentissage par transfert : https://youtu.be/BqqfQnyjmgg 
- Que se passe-t-il dans la fonction pipeline ? : https://youtu.be/wVN12smEvqg 
- Le pipeline de tokenization : https://youtu.be/Yffk5aydLzg
- Vue d‚Äôensemble de Datasets : https://youtu.be/W_gMJF0xomE 
- Introduction √† Keras : https://youtu.be/rnTGBy2ax1c 
- Planification du taux d'apprentissage dans TensorFlow : https://youtu.be/eKv4rRcCNX0 
- Pr√©diction et m√©triques : https://youtu.be/nx10eh4CoOs
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Planification du taux d'apprentissage avec TensorFlow 

Comment planifier le taux d'apprentissage en utilisant TensorFlow et Keras. 
Intervenant : Matthew Carrigan
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter3
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/tf_lr_scheduling.ipynb
Vid√©os connexes : 
- Introduction √† Keras: https://youtu.be/rnTGBy2ax1c
- Finetuning avec TensorFlow: https://youtu.be/alq1l8Lv9GA 
- Prediction et m√©triques : https://youtu.be/nx10eh4CoOs
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Pr√©dictions et m√©triques TensorFlow 

Utilisez TensorFlow et Keras pour calculer des pr√©dictions avec notre mod√®le finetun√©, et l'√©valuer. 
Intervenant : Matthew Carrigan
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter3
Vid√©os connexes : 
- Vue d‚Äôensemble de Datasets : https://youtu.be/W_gMJF0xomE 
- Introduction √† Keras: https://youtu.be/rnTGBy2ax1c 
- Finetuning avec TensorFlow: https://youtu.be/alq1l8Lv9GA 
- Planification du taux d'apprentissage avec TensorFlow : https://youtu.be/eKv4rRcCNX0
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



√âcrire votre boucle d'entra√Ænement dans PyTorch 

Finetunons un transformer avec PyTorch sans utiliser d'outils sp√©ciaux. 
Intervenant : Sylvain Gugger
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter3
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/training_loop.ipynb
Vid√©os connexes : 
- Comment instancier un transformer : https://youtu.be/AhChOFRegn4 
- Comment pr√©traiter des paires de phrases : https://youtu.be/0u3ioSwev3s 
- La biblioth√®que ü§ó Datasets : https://youtu.be/_BZearw7f0w 
- Qu'est-ce que le rembourrage dynamique : https://youtu.be/7q5NyFT8REg 
- L'API Trainer : https://youtu.be/nvBXf7s7vTI
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Optimisez votre boucle d'entra√Ænement PyTorch avec Accelerate 

Comment faire fonctionner une boucle d'entra√Ænement sur n'importe quelle configuration distribu√©e avec ü§ó Accelerate. 
Intervenant : Sylvain Gugger
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter3
Vid√©os connexes : 
- L‚ÄôAPI Trainer : https://youtu.be/nvBXf7s7vTI 
- √âcrire votre boucle d'entra√Ænement en PyTorch : https://youtu.be/Dh9CL8fyG80 
- Documentation d‚Äôü§ó Accelerate: https://huggingface.co/docs/accelerate/
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Naviguer sur le Hub des mod√®les

Visitez le Hub des mod√®les d‚ÄôHugging Face ! 
Intervenant : Lysandre Debut
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter4
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/git... You will need a Hugging Face account to manage a repo on the Model Hub. Join now: http://huggingface.co/join Vid√©os connexes : - The push to hub API: https://youtu.be/A5IWIxsHLUw - Managing a repo on the Model Hub: https://youtu.be/rkCly_cbMBk
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Gestion d'un d√©p√¥t sur le Hub des mod√®les

Apprenez √† g√©rer un d√©p√¥t sur le Hub de mod√®les d'Hugging Face. Cette vid√©o couvre la cr√©ation d'un d√©p√¥t, les ajouts de fichiers via l'interface web ainsi que via la ligne de commande. 
Intervenant : Lysandre Debut
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter4
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/training_loop.ipynb
Afin de pouvoir suivre cette vid√©o, nous vous recommandons de vous familiariser au pr√©alable avec git et git-lfs. Installation de git : https://git-scm.com/book/en/v2/Gettin... Installer git-lfs : https://git-lfs.github.com/ Tutoriel Git : https://git-scm.com/docs/gittutorial 
Vid√©os connexes : 
- L'API push to hub : https://youtu.be/A5IWIxsHLUw 
- Naviguer dans le Hub des mod√®les : https://youtu.be/XvSGPZFEjDY
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



L'API Push to Hub (PyTorch) 

Partagez facilement vos mod√®les finetun√©s sur le Hub d‚ÄôHugging Face en utilisant l'API push to hub. 
Intervenant : Sylvain Gugger
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter4
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/push_to_hub_pt.ipynb
 Version TensorFlow : https://youtu.be/pUh5cGmNV8Y 
Vid√©os connexes : 
- Naviguez dans le Hub des mod√®les : https://youtu.be/XvSGPZFEjDY 
- Comment instancier un transformer : https://youtu.be/AhChOFRegn4 
- L‚ÄôAPI Trainer : https://youtu.be/nvBXf7s7vTI
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



L'API Push to Hub (TensorFlow) 

Partagez facilement vos mod√®les finetun√©s sur le Hub d‚ÄôHugging Face en utilisant l'API push to hub. 
Intervenant : Matthew Carrigan
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter4
Version PyTorch : https://youtu.be/Zh0FfmVrKX0 
Vid√©os connexes : 
- Naviguez dans le Hub des mod√®les : https://youtu.be/XvSGPZFEjDY 
- Comment instancier un transformer : https://youtu.be/AhChOFRegn4 
- L‚ÄôAPI Trainer : https://youtu.be/nvBXf7s7vTI
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Chargement d'un jeu de donn√©es personnalis√© 

D√©couvrez comment charger un jeu de donn√©es personnalis√© avec la biblioth√®que ü§ó Datasets. 
Intervenant : Lewis Tunstall
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter5
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/load_custom_dataset.ipynb
Vid√©os connexes : 
- Sauvegarde et rechargement d'un jeu de donn√©es : https://youtu.be/blF9uxYcKHo 
- D√©couper et trancher un jeu de donn√©es üî™ : https://youtu.be/tqfSFcPMgOI 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



D√©couper et trancher un jeu de donn√©es üî™ 

Cette vid√©o vous apprendra toutes les op√©rations de base √† conna√Ætre pour pr√©parer vos donn√©es pour l'entra√Ænement avec la biblioth√®que ü§ó Datasets. 
Intervenant : Lewis Tunstall
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter5
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/slice_and_dice.ipynb
Vid√©os connexes : 
- Chargement d'un jeu de donn√©es personnalis√© : https://youtu.be/HyQgpJTkRdE 
- Sauvegarde et rechargement d'un jeu de donn√©es : https://youtu.be/blF9uxYcKHo 
- Datasets + DataFrames = ‚ù§Ô∏è : https://youtu.be/tfcY1067A5Q 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Datasets + DataFrames = ‚ù§Ô∏è 

Convertir un jeu de donn√©es de la biblioth√®que ü§ó Datasets en un DataFrame pandas et inversement est tr√®s facile ! Cette vid√©o vous montrera comment ces deux classes interagissent entre elles de mani√®re transparente. 
Intervenant : Lewis Tunstall
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter5
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/datasets_and_dataframes.ipynb
Vid√©os connexes : 
- Chargement d'un jeu de donn√©es personnalis√© : https://youtu.be/HyQgpJTkRdE 
- D√©couper et trancher un jeu de donn√©es üî™ : https://youtu.be/tqfSFcPMgOI 
- Sauvegarde et rechargement d'un jeu de donn√©es : https://youtu.be/blF9uxYcKHo 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Sauvegarde et rechargement d'un jeu de donn√©es 

Apprenez √† enregistrer votre jeu de donn√©es et √† le recharger ult√©rieurement avec la biblioth√®que ü§ó Datasets. 
Intervenant : Lewis Tunstall
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter5
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/save_load_dataset.ipynb
Vid√©os connexes :
- Chargement d'un jeu de donn√©es personnalis√© : https://youtu.be/HyQgpJTkRdE 
- D√©couper et trancher un jeu de donn√©es üî™ : https://youtu.be/tqfSFcPMgOI 
- T√©l√©chargement d'un jeu de donn√©es sur le Hub : https://youtu.be/HaN6qCr_Afc 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Association de la m√©moire et streaming 

La biblioth√®que ü§ó Datasets vous permet d'utiliser et de traiter des jeux de donn√©es qui ne tiennent pas dans la m√©moire vive. D√©couvrez comment elle peut le faire gr√¢ce √† l‚Äôassociation m√©moire et comment utiliser la fonctionnalit√© de streaming. 
Intervenant : Lewis Tunstall
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter5
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/memory_mapping_streaming.ipynb
Vid√©os connexes : 
- Chargement d'un jeu de donn√©es personnalis√© : https://youtu.be/HyQgpJTkRdE 
- D√©couper et trancher un jeu de donn√©es üî™ : https://youtu.be/tqfSFcPMgOI 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



T√©l√©chargement d'un jeu de donn√©es vers le Hub 

Dans cette vid√©o, vous apprendrez √† t√©l√©charger vos propres jeux de donn√©es sur le Hub.
Intervenant : Lewis Tunstall
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter5
Vid√©os connexes : 
- Chargement d'un jeu de donn√©es personnalis√© : https://youtu.be/HyQgpJTkRdE 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Ench√¢ssement de texte et recherche s√©mantique 

D√©couvrez comment les transformers peuvent √™tre utilis√©s pour repr√©senter des documents et des requ√™tes sous forme de vecteurs appel√©s ench√¢ssements. Dans cette vid√©o, nous appliquons cette technique pour cr√©er un moteur de recherche s√©mantique ! 
Intervenant : Lewis Tunstall
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter5
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/semantic_search.ipynb
Vid√©os connexes : 
- Chargement d'un jeu de donn√©es personnalis√© : https://youtu.be/HyQgpJTkRdE 
- D√©couper et trancher un jeu de donn√©es üî™ : https://youtu.be/tqfSFcPMgOI 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Entra√Æner un nouveau tokenizer

Vous √™tes-vous d√©j√† demand√© comment cr√©er un tokenizer BERT ou GPT2 dans votre propre langue ou sur votre propre corpus ? Cette vid√©o vous apprendra √† le faire avec n'importe quel tokenizer de la biblioth√®que ü§ó Transformers. 
Intervenant : Lucile Saulnier
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter5
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/train_new_tokenizer.ipynb
Vid√©os connexes : 
- Construire un nouveau tokenizer : https://youtu.be/MR8tZm5ViWU
Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Pourquoi les tokenizers rapides sont-ils appel√©s rapides ? 

Les tokenizers rapides sont rapides, mais de combien exactement ? Cette vid√©o vous le dira. 
Intervenant : Sylvain Gugger
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter6
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/fast_tokenizers.ipynb
Vid√©os connexes : 
- Les superpouvoirs des tokenizers rapides : https://youtu.be/3umI3tm27Vw 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Les superpouvoirs des tokenizers rapides 

Les tokenizers rapides sont rapides, mais ils disposent √©galement de fonctionnalit√©s suppl√©mentaires permettant de faire correspondre les tokens aux mots dont ils proviennent ou √† la port√©e originale des caract√®res dans le texte brut. Cette vid√©o explore ces fonctionnalit√©s. 
Intervenant : Sylvain Gugger
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter6
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/offset_mapping.ipynb
Vid√©os connexes : 
- Pourquoi les tokenizers rapides sont-ils appel√©s rapides ? : https://youtu.be/g8quOxoqhHQ 
- Entra√Æner un nouveau tokenizer: https://youtu.be/DJimQynXZsQ 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Dans le pipeline de classification de tokens (PyTorch) 

Que se passe-t-il dans le pipeline de classification de tokens, et comment passe-t-on des logits aux √©tiquettes d'entit√©s ? Cette vid√©o vous le montrera. 
Intervenant : Sylvain Gugger
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter6
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/token_pipeline_pt.ipynb
Version TensorFlow : https://youtu.be/0E7ltQB7fM8 
Vid√©os connexes : 
- Que se passe-t-il √† l'int√©rieur de la fonction pipeline ? : https://youtu.be/1pedAIvTWXk 
- Les superpouvoirs des tokenizers rapides : https://youtu.be/3umI3tm27Vw 
- Traitement des donn√©es pour la classification de tokens : https://youtu.be/iY2AZYdZAr0 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Dans le pipeline de classification de tokens (TensorFlow) 

Que se passe-t-il dans le pipeline de classification de tokens, et comment passe-t-on des logits aux √©tiquettes d'entit√©s ? Cette vid√©o vous le montrera. 
Intervenant : Sylvain Gugger
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter6
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/token_pipeline_pt.ipynb
Version PyTorch : https://youtu.be/0E7ltQB7fM8 
Vid√©os connexes : 	
- Que se passe-t-il √† l'int√©rieur de la fonction pipeline ? : https://youtu.be/1pedAIvTWXk 
- Les superpouvoirs des tokenizers rapides : https://youtu.be/3umI3tm27Vw 
- Traitement des donn√©es pour la classification de tokens : https://youtu.be/iY2AZYdZAr0 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Dans le pipeline de r√©ponse aux questions (PyTorch) 

Comment le pipeline de r√©ponse aux questions fonctionne-t-il r√©ellement ? Dans cette vid√©o, nous explorons comment nous passons des pr√©dictions du mod√®le √† la recherche de la r√©ponse dans le contexte initial. 
Intervenant : Sylvain Gugger
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter6
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/git... 
Version TensorFlow : https://youtu.be/b3u8RzBCX9Y 
Vid√©os connexes : 
- Que se passe-t-il √† l'int√©rieur de la fonction pipeline ? : https://youtu.be/1pedAIvTWXk 
- Les superpouvoirs des tokenizers rapides : https://youtu.be/3umI3tm27Vw 
- Traitement des donn√©es pour la r√©ponse aux questions : https://youtu.be/qgaM0weJHpA 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



A l'int√©rieur du pipeline de r√©ponse aux questions (TensorFlow) 

Comment le pipeline de r√©ponse aux questions fonctionne-t-il r√©ellement ? Dans cette vid√©o, nous explorons comment nous passons des pr√©dictions du mod√®le √† la recherche de la r√©ponse dans le contexte initial. 
Intervenant : Sylvain Gugger
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter6
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/git... 
Version PyTorch : https://youtu.be/_wxyB3j3mk4 
Vid√©os connexes :
- Que se passe-t-il √† l'int√©rieur de la fonction pipeline ? : https://youtu.be/1pedAIvTWXk 
- Les superpouvoirs des tokenizers rapides : https://youtu.be/3umI3tm27Vw 
- Traitement des donn√©es pour la r√©ponse aux questions : https://youtu.be/qgaM0weJHpA 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Qu'est-ce que la normalisation ? 

La premi√®re √©tape de la tokenisation des textes est appel√©e normalisation. Mais qu'est-ce que cela signifie ? Cette vid√©o vous dira tout √† ce sujet. 
Intervenant : Lucile Saulnier
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter6
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/normalization.ipynb
Vid√©os connexes : 
- Qu'est-ce que la pr√©tok√©nisation ? https://youtu.be/grlLV8AIXug 
- Entra√Æner un nouveau tokenizer : https://youtu.be/DJimQynXZsQ 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Qu'est-ce que la pr√©tok√©nisation ? 

La pr√©tok√©nisation est la deuxi√®me √©tape de la tok√©nisation des textes. Mais qu'est-ce que cela signifie ? Cette vid√©o vous dira tout √† ce sujet. 
Intervenant : Lucile Saulnier
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter6
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/pre_tokenization.ipynb
Vid√©os connexes : 
- Qu‚Äôest-ce que la normalization ? https://youtu.be/4IIC2jI9CaU 
- Entra√Æner un nouveau tokenizer : https://youtu.be/DJimQynXZsQ 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Tokenisation Byte Pair Encoding

Cette vid√©o vous apprendra tout ce qu'il y a √† savoir sur l'algorithme de tokenisation Byte Pair Encoding. Comment il est entra√Æn√© sur un corpus de textes et comment il est appliqu√© pour tokeniser des textes. 
Intervenant : Lucile Saulnier
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter6
Vid√©os connexes : 
- Tokenisation Unigram : https://youtu.be/TGZfZVuF9Yc 
- Tokenisation WordPiece : https://youtu.be/qpv6ms_t_1A 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Tok√©nisation WordPiece
  
Cette vid√©o vous apprendra tout ce qu'il y a √† savoir sur l'algorithme de tokenisation WordPiece. Comment il est entra√Æn√© sur un corpus de textes et comment il est appliqu√© pour tokeniser des textes. 
Intervenant : Lucile Saulnier
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter6
Vid√©os connexes : 
- Tokenisation Byte Pair Encoding : https://youtu.be/HEikzVL-lZU 
- Tokenisation Unigram : https://youtu.be/TGZfZVuF9Yc 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Tokenization Unigram 

Cette vid√©o vous apprendra tout ce qu'il y a √† savoir sur l'algorithme de tokenisation Unigram. Comment il est entra√Æn√© sur un corpus de textes et comment il est appliqu√© pour tokeniser des textes. 
Intervenant : Lucile Saulnier
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter6
Vid√©os connexes :
- Tokenisation Byte Pair Encoding : https://youtu.be/HEikzVL-lZU 
- Tokenisation  WordPiece : https://youtu.be/qpv6ms_t_1A 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Construction d'un nouveau tokenizer 

D√©couvrez comment utiliser la biblioth√®que ü§ó Tokenizers pour construire votre propre tokenizer, l'entra√Æner, puis comment l'utiliser dans la biblioth√®que ü§ó Transformers. 
Intervenant : Lucile Saulnier
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter6
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/building_tokenizer.ipynb
Vid√©os connexes : 
- Entra√Æner un nouveau tokenizer : https://youtu.be/DJimQynXZsQ
- Tokenisation Byte Pair Encoding : https://youtu.be/HEikzVL-lZU 
- Tokenisation  WordPiece : https://youtu.be/qpv6ms_t_1A 
- Tokenisation Unigram : https://youtu.be/TGZfZVuF9Yc 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Traitement des donn√©es pour la classification de tokens 

Cette vid√©o vous explique comment pr√©traiter un jeu de donn√©es pour une t√¢che de classification de tokens. 
Intervenant : Sylvain Gugger
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter7
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/token_processing.ipynb
Vid√©os connexes : 
- ü§ó T√¢ches : classification de tokens : https://youtu.be/wVHdVlPScxA 
- √Ä l'int√©rieur du pipeline de classification de tokens (PyTorch): https://youtu.be/0E7ltQB7fM8 
- √Ä l'int√©rieur du pipeline de classification de tokens (TensorFlow): https://youtu.be/PrX4CjrVnNc 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Traitement des donn√©es pour la mod√©lisation du langage masqu√© 

Comment pr√©traiter un jeu de donn√©es pour une t√¢che de mod√©lisation du langage masqu√©, par exemple pour remplir les blancs d'une phrase. 
Intervenant : Sylvain Gugger
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter7
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/mlm_processing.ipynb
Vid√©os connexes : 
- ü§ó T√¢ches : mod√©lisation du langage masqu√© : https://youtu.be/mqElG5QJWUg 
- Finetuning avec TensorFlow: https://youtu.be/AUozVp78dhk 
- L‚ÄôAPI Trainer : https://youtu.be/nvBXf7s7vTI 
- √âcrire votre boucle d'entra√Ænement en PyTorch: https://youtu.be/Dh9CL8fyG80 
- Optimisez votre boucle d'entra√Ænement PyTorch avec Accelerate : https://youtu.be/s7dy8QRgjJ0 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Qu'est-ce que la perplexit√© ? 

Les mod√®les de langage sont souvent √©valu√©s √† l'aide d'une m√©trique appel√©e perplexit√©. Vous vous sentez perplexe √† ce sujet ? Regardez cette vid√©o pour tout savoir. 
Intervenant : Leandro von Werra
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter7
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/perplexity.ipynb
Vid√©os connexes : 
- ü§ó T√¢ches : mod√©lisation du langage causal : https://youtu.be/Vpjb1lu0MDk 
- ü§ó T√¢ches : mod√©lisation du langage masqu√© : https://youtu.be/mqElG5QJWUg
- Traitement des donn√©es pour la mod√©lisation du langage causal: https://youtu.be/ma1TrR7gE7I 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Qu'est-ce que l'adaptation au domaine ? 

Dans cette vid√©o, nous expliquons ce qu'est l'adaptation au domaine et nous examinons des exemples de versions finetun√©es de mod√®les qui se sont adapt√©s √† leur corpus de finetuning. 
Intervenant : Sylvain Gugger
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter7
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/domain_adaptation.ipynb
Vid√©os connexes : 
- Qu'est-ce que l'apprentissage par transfert ? : https://youtu.be/BqqfQnyjmgg 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Traitement des donn√©es pour la traduction 

Comment pr√©traiter un jeu de donn√©es pour une t√¢che de traduction ? Cette vid√©o vous aidera √† le faire. 
Intervenant : Sylvain Gugger
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter7
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/translation_processing.ipynb
Vid√©os connexes :
- ü§ó T√¢ches : traduction : https://youtu.be/1JvfrvZgi6c 
- Traitement des donn√©es pour le r√©sum√© de texte : https://youtu.be/1m7BerpSq8A 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Qu'est-ce que la m√©trique BLEU ? 

La m√©trique BLEU est souvent utilis√©e pour √©valuer les mod√®les de traduction. Cette vid√©o vous explique comment elle fonctionne. 
Intervenant : Lewis Tunstall
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter7
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/bleu_metric.ipynb
Vid√©os connexes : 
- ü§ó T√¢ches : traduction : https://youtu.be/1JvfrvZgi6c 
- Traitement des donn√©es pour la traduction : https://youtu.be/XAR8jnZZuUs 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Traitement des donn√©es pour le r√©sum√© 

Cette vid√©o montre comment pr√©traiter des donn√©es pour une t√¢che de r√©sum√©. 
Intervenant : Sylvain Gugger
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter7
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/summarization_processing.ipynb
Vid√©os connexes : 
- ü§ó T√¢ches : R√©sum√© de textes : https://youtu.be/yHnr5Dk2zCI 
- Traitement des donn√©es pour la traduction : https://youtu.be/XAR8jnZZuUs
 Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Qu'est-ce que la m√©trique ROUGE ? 

La m√©trique ROUGE est souvent utilis√©e dans les t√¢ches de compression, mais comment est-elle calcul√©e exactement ? 
Intervenant : Lewis Tunstall
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter7
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/rouge_metric.ipynb
Vid√©os connexes : 
- ü§ó T√¢ches : R√©sum√© de textes : https://youtu.be/yHnr5Dk2zCI 
- Traitement des donn√©es pour la traduction : https://youtu.be/XAR8jnZZuUs
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Traitement des donn√©es pour la mod√©lisation causale du langage 

Dans cette vid√©o, nous allons voir comment pr√©traiter un jeu de donn√©es pour une t√¢che de mod√©lisation causale du langage. 
Intervenant : Leandro von Werra
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter7
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/clm_processing.ipynb
Vid√©os connexes :
- Finetuning avec TensorFlow : https://youtu.be/AUozVp78dhk 
- L‚ÄôAPI Trainer : https://youtu.be/nvBXf7s7vTI 
- √âcrivez votre boucle d'entra√Ænement dans PyTorch : https://youtu.be/Dh9CL8fyG80 
- Optimisez votre boucle d'entra√Ænement PyTorch avec Accelerate : https://youtu.be/s7dy8QRgjJ0 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Utilisation d'une fonction de perte personnalis√©e

Dans cette vid√©o, nous allons voir comment utiliser une fonction de perte personnalis√©e. La plupart des mod√®les de ü§ó Transformers renvoient automatiquement la perte lorsque vous leur fournissez des √©tiquettes, mais parfois, vous ne voulez pas la perte par d√©faut. Nous montrons ici comment pond√©rer dynamiquement les √©chantillons dans la perte en utilisant l'API Trainer et ü§ó Accelerate. 
Intervenant : Leandro von Werra
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter7
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/custom_loss.ipynb
Vid√©os connexes : 
- L‚ÄôAPI Trainer : https://youtu.be/nvBXf7s7vTI 
- √âcrivez votre boucle d'entra√Ænement dans PyTorch : https://youtu.be/Dh9CL8fyG80 
- Optimisez votre boucle d'entra√Ænement PyTorch avec Accelerate : https://youtu.be/s7dy8QRgjJ0 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Traitement des donn√©es pour la r√©ponse aux questions 

Cette vid√©o explore comment pr√©traiter un jeu de donn√©es pour la r√©ponse aux questions et le pr√©parer pour un transformer. 
Intervenant : Sylvain Gugger
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter7
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/qa_processing.ipynb
Vid√©os connexes : 
- ü§ó T√¢ches : R√©ponse aux questions : https://youtu.be/ajPx5LwJD-I 
- L'√©tape de post-traitement dans la r√©ponse aux questions (PyTorch) : https://youtu.be/BNy08iIWVJM 
- L'√©tape de post-traitement dans la r√©ponse aux questions (TensorFlow) : https://youtu.be/VN67ZpN33Ss 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



L'√©tape de post-traitement en r√©ponse aux questions (PyTorch) 

L'√©valuation dans les t√¢ches de r√©ponse aux questions peut √™tre d√©licate car il est difficile de convertir la sortie du mod√®le en r√©ponses dans les contextes originaux. Cette vid√©o va (esp√©rons-le) rendre les choses plus claires ! 
Intervenant : Sylvain Gugger
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter7
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/qa_postprocessing_pt.ipynb
Version TensorFlow: https://youtu.be/VN67ZpN33Ss 
Vid√©os connexes : 
- Traitement des donn√©es pour la r√©ponse aux questions : https://youtu.be/qgaM0weJHpA 
- Dans le pipeline de r√©ponse aux questions : https://youtu.be/_wxyB3j3mk4 
- Les superpouvoirs des tokenizers rapides : https://youtu.be/3umI3tm27Vw 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



L'√©tape de post-traitement en r√©ponse aux questions (TensorFlow) 

L'√©valuation dans les t√¢ches de r√©ponse aux questions peut √™tre d√©licate car il est difficile de convertir la sortie du mod√®le en r√©ponses dans les contextes originaux. Cette vid√©o va (esp√©rons-le) rendre les choses plus claires ! 
Intervenant : Sylvain Gugger
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter7
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/qa_postprocessing_tf.ipynb
Version PyTorch : https://youtu.be/BNy08iIWVJM
Vid√©os connexes : 
- Traitement des donn√©es pour la r√©ponse aux questions : https://youtu.be/qgaM0weJHpA 
- Dans le pipeline de r√©ponse aux questions : https://youtu.be/_wxyB3j3mk4 
- Les superpouvoirs des tokenizers rapides : https://youtu.be/3umI3tm27Vw 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Assembleurs de donn√©es : une visite 

La biblioth√®que ü§ó Transformers fournit de nombreux assembleurs de donn√©es que vous pouvez utiliser pour regrouper vos √©chantillons dans un batch. Si vous √™tes perdu entre toutes les possibilit√©s, cette vid√©o est pour vous ! 
Intervenant : Matthew Carrigan
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter7
Vid√©os connexes : 
- Finetuning avec TensorFlow : https://youtu.be/AUozVp78dhk 
- L‚ÄôAPI Trainer : https://youtu.be/nvBXf7s7vTI 
- √âcrivez votre boucle d'entra√Ænement dans PyTorch : https://youtu.be/Dh9CL8fyG80 
- Optimisez votre boucle d'entra√Ænement PyTorch avec Accelerate : https://youtu.be/s7dy8QRgjJ0 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Que faire lorsque vous obtenez une erreur ?

Vous vous sentez d√©pass√© par ce message d'erreur que Python vient de vous envoyer ? Pas de panique, nous allons y voir plus clair ensemble. 
Intervenant : Sylvain Gugger
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter8
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/debug_error.ipynb
Vid√©os connexes : 
- Utilisation d'un d√©bogueur dans un notebook : https://youtu.be/rSPyvPw0p9k 
- Utilisation d'un d√©bogueur dans un terminal : https://youtu.be/5PkZ4rbHL6c 
- D√©boguer le pipeline d'entra√Ænement (PyTorch): https://youtu.be/L-WSwUWde1U 
- D√©boguer le pipeline d'entra√Ænement (TensorFlow): https://youtu.be/N9kO52itd0Q 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Utilisation d'un d√©bogueur dans un notebook 

Saviez-vous qu'il existe un d√©bogueur Python que vous pouvez facilement utiliser dans un Jupyter Notebook ou un Google Colab ? Laissez-nous vous montrer comment l'utiliser. 
Intervenant : Sylvain Gugger
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter8
Ouvrir les codes de la vid√©o dans Colab : https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/debug_notebook.ipynb
Vid√©os connexes : 
- Que faire lorsque vous obtenez une erreur ? https://youtu.be/DQ-CpJn6Rc4 
- Utilisation d'un d√©bogueur dans un terminal : https://youtu.be/5PkZ4rbHL6c 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Utiliser un d√©bogueur dans un terminal 

Saviez-vous qu'il existe un d√©bogueur Python que vous pouvez facilement utiliser en ligne de commande ? Laissez-nous vous montrer comment l'utiliser. 
Intervenant : Sylvain Gugger
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter8
Vid√©os connexes : 
- Que faire lorsque vous obtenez une erreur ? https://youtu.be/DQ-CpJn6Rc4 
- Utilisation d'un d√©bogueur dans un notebook : https://youtu.be/rSPyvPw0p9k 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



Demander de l'aide sur les forums 

Cette vid√©o vous montrera comment poser au mieux une question sur les ü§ó Forums, et maximiser les chances d'obtenir une r√©ponse rapide. 
Intervenant : Sylvain Gugger
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter8
Vid√©os connexes : 
- Que faire lorsque vous obtenez une erreur ? https://youtu.be/DQ-CpJn6Rc4 
- Ouvrir un bon ticket : https://youtu.be/_PAli-V4wj0 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



D√©boguer le pipeline d'entra√Ænement (PyTorch) 

Vous obtenez une erreur lorsque vous appelez Trainer.train() ? Dans cette vid√©o, nous allons vous apprendre √† d√©boguer l'ensemble du pipeline d'entra√Ænement, et nous esp√©rons faire dispara√Ætre cette erreur. 
Intervenant : Sylvain Gugger
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter8
Version TensorFlow : https://youtu.be/N9kO52itd0Q 
Vid√©os connexes : 
- L‚ÄôAPI Trainer : https://youtu.be/nvBXf7s7vTI 
- Que faire lorsque vous obtenez une erreur ? https://youtu.be/DQ-CpJn6Rc4 
- Utilisation d'un d√©bogueur dans un notebook : https://youtu.be/rSPyvPw0p9k 
- Utilisation d'un d√©bogueur dans un terminal: https://youtu.be/5PkZ4rbHL6c 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



D√©boguer le pipeline d'entra√Ænement (TensorFlow) 

Vous obtenez une erreur lorsque vous appelez model.fit() ? Dans cette vid√©o, nous allons vous apprendre √† d√©boguer l'ensemble du pipeline d'entra√Ænement et, si possible, √† faire dispara√Ætre cette erreur. 
Intervenant : Matthew Carrigan
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter8
Version PyTorch : https://youtu.be/L-WSwUWde1U 
Vid√©os connexes : 
- Finetuning avec TensorFlow: https://youtu.be/AUozVp78dhk
- Que faire lorsque vous obtenez une erreur ? https://youtu.be/DQ-CpJn6Rc4 
- Utilisation d'un d√©bogueur dans un notebook : https://youtu.be/rSPyvPw0p9k
- Utilisation d'un d√©bogueur dans un terminal : https://youtu.be/5PkZ4rbHL6c 
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join



R√©diger un bon ticket

Dans cette vid√©o, nous allons vous montrer comment r√©diger un bon ticket sur GitHub, afin de maximiser les chances que quelqu'un vous aide et r√©solve votre bug le plus rapidement possible. 
Intervenant : Sylvain Gugger
Traduction : Lo√Øck Bourdois
Cette vid√©o fait partie du cours Hugging Face : http://huggingface.co/course/fr/chapter8
Vid√©os connexes : 
- Que faire lorsque vous obtenez une erreur ? https://youtu.be/DQ-CpJn6Rc4 
- Utilisation d'un d√©bogueur dans un notebook : https://youtu.be/rSPyvPw0p9k
- Utilisation d'un d√©bogueur dans un terminal : https://youtu.be/5PkZ4rbHL6c 
- Demander de l'aide sur les forums : https://youtu.be/S2EEG3JIt2A
Vous avez une question ? Consultez le forum d‚ÄôHugging Face : https://discuss.huggingface.co/c/course/20 
Vous n'avez pas de compte Hugging Face ? Inscrivez-vous maintenant : http://huggingface.co/join