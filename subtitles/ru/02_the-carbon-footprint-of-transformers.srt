1
00:00:00.000 --> 00:00:08.000
Итак, давайте поговорим об углеродном следе трансформаторов.

2
00:00:08.000 --> 00:00:15.000
Возможно, вы видели заголовки, подобные этому, о том, что обучение одной модели искусственного интеллекта может выбросить столько углерода, сколько пять автомобилей за всю свою жизнь.

3
00:00:15.000 --> 00:00:19.000
Так когда это правда и всегда ли это так?

4
00:00:19.000 --> 00:00:21.000
На самом деле, это зависит от нескольких вещей.

5
00:00:21.000 --> 00:00:24.000
Самое главное, это зависит от типа энергии, которую вы используете.

6
00:00:24.000 --> 00:00:33.000
Если вы используете возобновляемые источники энергии, такие как солнце, ветер, гидроэлектроэнергия, вы действительно не выбрасываете углерод вообще или выбрасываете очень, очень мало.

7
00:00:33.000 --> 00:00:42.000
Если вы используете невозобновляемые источники энергии, такие как уголь, то их углеродный след намного выше, потому что, по сути, вы выделяете большое количество парниковых газов.

8
00:00:42.000 --> 00:00:44.000
Другой аспект - время обучения.

9
00:00:44.000 --> 00:00:50.000
Поэтому чем дольше вы обучаете, тем больше энергии вы используете, тем больше углерода вы выбрасываете.

10
00:00:50.000 --> 00:00:55.000
Это очень много, особенно если вы обучаете большие модели в течение нескольких часов, дней и недель.

11
00:00:55.000 --> 00:01:01.000
Используемое вами оборудование также имеет значение, поскольку некоторые GPU, например, более эффективны, чем другие.

12
00:01:01.000 --> 00:01:13.000
Правильное использование эффективных GPU, то есть использование их на 100 процентов все время, может действительно снизить потребление энергии, а также уменьшить углеродный след.

13
00:01:13.000 --> 00:01:17.000
Есть и другие аспекты, такие как ввод-вывод, данные и т.д.

14
00:01:17.000 --> 00:01:20.000
Но это основные три, на которых вам следует сосредоточиться.

15
00:01:20.000 --> 00:01:24.000
Поэтому, когда я говорю об источниках энергии и углеродоемкости, что это на самом деле означает?

16
00:01:24.000 --> 00:01:38.000
Так, если вы посмотрите на верхнюю часть экрана, то увидите углеродный след экземпляра облачного вычисления в Мумбаи, Индия, который выделяет 920 граммов CO2 на киловатт-час.

17
00:01:38.000 --> 00:01:43.000
Это почти один килограмм CO2 на киловатт-час используемой электроэнергии.

18
00:01:43.000 --> 00:01:48.000
Если сравнить с Канадой, Монреалем, где я сейчас нахожусь, то это 20 граммов CO2 на киловатт-час.

19
00:01:48.000 --> 00:01:56.000
Это очень, очень большая разница, почти в 40 раз больше выбросов углерода в Мумбаи по сравнению с Монреалем.

20
00:01:56.000 --> 00:01:57.000
Так что все это может очень, очень сильно увеличиться.

21
00:01:57.000 --> 00:02:03.000
Если вы, например, обучаете модель в течение нескольких недель, вы умножаете на 40 количество углерода, которое вы выбрасываете в атмосферу.

22
00:02:03.000 --> 00:02:18.000
Поэтому выбор правильного экземпляра, выбор экземпляра вычислительной машины с низким уровнем выбросов углекислого газа - это действительно самая важная вещь, которую вы можете сделать, и именно здесь это может действительно увеличиться, если вы проводите обучение в регионе с высоким уровнем выбросов углекислого газа.

23
00:02:18.000 --> 00:02:25.000
Другие элементы, которые следует учитывать, например, использование предварительно обученных моделей. Это эквивалент вторичного использования машинного обучения.

24
00:02:25.000 --> 00:02:30.000
Когда у вас есть предварительно обученные модели, используя их, вы вообще не выбрасываете углерод.

25
00:02:30.000 --> 00:02:31.000
Вы ничего не переобучаете.

26
00:02:31.000 --> 00:02:35.000
Так что это еще и выполнение домашней работы и изучение того, что уже существует.

27
00:02:35.000 --> 00:02:37.000
Тонкая настройка вместо обучения с нуля.

28
00:02:37.000 --> 00:02:48.000
Поэтому еще раз повторюсь, если вы нашли модель, которая почти соответствует вашим потребностям, но не совсем, то тонкая настройка последней пары слоев, чтобы она действительно соответствовала вашим целям, вместо того, чтобы обучать большой трансформер с нуля, может действительно помочь.

29
00:02:48.000 --> 00:02:52.000
Начинайте с небольших экспериментов и отлаживайте их по ходу дела.

30
00:02:52.000 --> 00:03:03.000
Это означает, например, что нужно разобраться с кодировкой данных, убедиться в отсутствии мелких ошибок, о которых вы узнаете через 16 часов обучения.

31
00:03:03.000 --> 00:03:06.000
Начните с малого и убедитесь в стабильности того, что вы делаете, что ваш код стабилен.

32
00:03:08.000 --> 00:03:15.000
И, наконец, проведение обзора литературы для выбора диапазонов гиперпараметров и последующий случайный поиск вместо поиска по сетке.

33
00:03:15.000 --> 00:03:23.000
Так, случайный поиск комбинаций гиперпараметров оказался не менее эффективным в поиске оптимальной конфигурации, чем поиск по сетке.

34
00:03:23.000 --> 00:03:29.000
Но очевидно, что вы не пробуете все возможные комбинации, а только их подмножество.

35
00:03:29.000 --> 00:03:31.000
Так что это тоже может помочь.

36
00:03:31.000 --> 00:03:39.000
Итак, если мы вернемся к оригинальной статье Струбелла и др. в 2019 году, печально известной статье о пяти автомобилях в течение их срока службы.

37
00:03:39.000 --> 00:03:49.000
Если вы просто посмотрите на трансформер, 200 миллионов параметров трансформера, то его углеродный след составляет около 200 фунтов CO2, что является значительным, но это не сравнится с пятью автомобилями.

38
00:03:49.000 --> 00:03:52.000
Это даже не трансатлантический перелет.

39
00:03:52.000 --> 00:04:01.000
В действительности все это складывается, когда вы выполняете поиск нейронной архитектуры, когда вы выполняете настройку гиперпараметров, а это перебор всех возможных комбинаций и т.д.

40
00:04:01.000 --> 00:04:05.000
Вот откуда взялись 600 000 фунтов CO2.

41
00:04:05.000 --> 00:04:08.000
Так что здесь все действительно складывается.

42
00:04:08.000 --> 00:04:18.000
Так что если вы поступаете разумно и осознанно, то ваш углеродный след будет настолько большим, насколько это подразумевает статья.

43
00:04:18.000 --> 00:04:22.000
Некоторые инструменты, позволяющие определить, сколько CO2 выбрасываете именно вы.

44
00:04:22.000 --> 00:04:37.000
Существует веб-инструмент под названием Machine Learning Submissions Calculator, который позволяет вам вручную ввести, например, какое оборудование вы используете, сколько часов вы его использовали, где оно было расположено локально или в облаке, а затем он выдаст вам оценку того, сколько CO2 вы выбросили.

45
00:04:37.000 --> 00:04:41.000
Другой инструмент, который делает это программно, называется CodeCarbon.

46
00:04:41.000 --> 00:04:48.000
Вы можете установить его с помощью pip, зайти на GitHub, и, по сути, он будет работать параллельно с вашим кодом.

47
00:04:48.000 --> 00:04:59.000
То есть, по сути, вы вызываете его, затем проводите все свое обучение, и в конце он предоставит вам оценку, CSV-файл с оценкой ваших выбросов, и даст вам некоторые сравнения.

48
00:04:59.000 --> 00:05:04.000
У него есть визуальный пользовательский интерфейс, где вы можете реально посмотреть, как это сравнимо с вождением автомобиля или просмотром телевизора.

49
00:05:04.000 --> 00:05:07.000
Таким образом, это может дать вам представление о масштабах ваших выбросов.

50
00:05:07.000 --> 00:05:40.000
На самом деле, CodeCarbon уже интегрирован в AutoNLP, и, надеюсь, люди будут использовать его из коробки и легко отслеживать свои выбросы на протяжении всего процесса обучения и внедрения трансформеров.