1
00:00:00,069 --> 00:00:01,341


2
00:00:01,341 --> 00:00:02,449


3
00:00:02,449 --> 00:00:05,880


4
00:00:05,880 --> 00:00:07,080
- Функция pipeline (конвеер).

5
00:00:09,540 --> 00:00:12,020
Функция pipeline является наиболее высокоуровневым API

6
00:00:12,020 --> 00:00:14,010
библиотеки Transformers.

7
00:00:14,010 --> 00:00:16,050
Она объединяет все шаги

8
00:00:16,050 --> 00:00:18,873
перехода от необработанных текстов к пригодным для использования прогнозам.

9
00:00:20,228 --> 00:00:22,980
Используемая модель лежит в основе конвейера,

10
00:00:22,980 --> 00:00:24,390
но конвейер также включает 

11
00:00:24,390 --> 00:00:26,610
всю необходимую пред-обработку,

12
00:00:26,610 --> 00:00:30,240
поскольку модель ожидает не тексты, а числа,

13
00:00:30,240 --> 00:00:32,040
а также некоторую постобработку, 

14
00:00:32,040 --> 00:00:34,533
чтобы сделать вывод модели человекочитаемым.

15
00:00:35,910 --> 00:00:37,593
Давайте рассмотрим первый пример

16
00:00:37,593 --> 00:00:39,693
с конвейером анализа настроений.

17
00:00:40,740 --> 00:00:44,670
Этот конвейер выполняет классификацию текста на заданном входе

18
00:00:44,670 --> 00:00:46,953
и определяет, является ли он позитивным или негативным.

19
00:00:47,910 --> 00:00:51,750
Здесь он приписывает положительную оценку данному тексту

20
00:00:51,750 --> 00:00:54,413
с достоверностью 95%.

21
00:00:55,650 --> 00:00:58,470
Вы можете передать множество текстов в один конвейер,

22
00:00:58,470 --> 00:01:00,270
которые будут обработаны и переданы

23
00:01:00,270 --> 00:01:02,673
через модель вместе как батч (пакет).

24
00:01:03,570 --> 00:01:05,970
На выходе получается список отдельных результатов

25
00:01:05,970 --> 00:01:07,923
в том же порядке, что и входные тексты.

26
00:01:08,790 --> 00:01:12,270
Здесь мы находим ту же метку и оценку для первого текста,

27
00:01:12,270 --> 00:01:14,443
а второй текст оценивается как отрицательный

28
00:01:14,443 --> 00:01:17,243
с достоверностью 99,9%.

29
00:01:18,720 --> 00:01:20,700
Конвейер zero-shot классификации

30
00:01:20,700 --> 00:01:23,610
это более общий конвейер классификации текста,

31
00:01:23,610 --> 00:01:26,370
он позволяет вам предоставлять нужные метки.

32
00:01:26,370 --> 00:01:29,850
Здесь мы хотим классифицировать наш входной текст по меткам,

33
00:01:29,850 --> 00:01:32,643
образование, политика и бизнес.

34
00:01:33,540 --> 00:01:35,580
Конвейер успешно распознает

35
00:01:35,580 --> 00:01:38,280
это скорее образование, чем другие метки,

36
00:01:38,280 --> 00:01:40,643
с достоверностью 84%.

37
00:01:41,670 --> 00:01:43,110
Переходим к другим задачам,

38
00:01:43,110 --> 00:01:45,030
конвейер генерации текста будет

39
00:01:45,030 --> 00:01:46,533
автоматически заполнять заданную подсказку.

40
00:01:47,460 --> 00:01:49,980
Вывод генерируется с некоторой долей случайности,

41
00:01:49,980 --> 00:01:52,800
поэтому он меняется каждый раз, когда вы вызываете объект генератора

42
00:01:52,800 --> 00:01:53,763
для заданной строки.

43
00:01:54,990 --> 00:01:57,123
До сих пор мы использовали API конвейера

44
00:01:57,123 --> 00:02:00,360
с моделью по умолчанию, связанной с каждой задачей,

45
00:02:00,360 --> 00:02:02,880
но вы можете использовать его с любой моделью, которая была предварительно обучена

46
00:02:02,880 --> 00:02:04,263
или дообучена на этой задаче.

47
00:02:06,540 --> 00:02:10,350
Зайдя в хаб моделей, huggingface.co/models

48
00:02:10,350 --> 00:02:13,350
вы можете отфильтровать доступные модели по задаче.

49
00:02:13,350 --> 00:02:17,190
Модель по умолчанию, использованная в нашем предыдущем примере, была gpt2,

50
00:02:17,190 --> 00:02:19,290
но существует множество других моделей,

51
00:02:19,290 --> 00:02:20,523
и не только на английском языке.

52
00:02:21,450 --> 00:02:23,670
Давайте вернемся к конвейеру генерации текста

53
00:02:23,670 --> 00:02:26,193
и загрузим в него другую модель, distilgpt2.

54
00:02:27,060 --> 00:02:28,950
Это облегченная версия gpt2

55
00:02:28,950 --> 00:02:30,603
созданная командой Hugging Face.

56
00:02:31,740 --> 00:02:34,110
При применении конвейера к данной строке,

57
00:02:34,110 --> 00:02:36,360
мы можем указать несколько аргументов

58
00:02:36,360 --> 00:02:39,240
такие как максимальная длина генерируемых текстов,

59
00:02:39,240 --> 00:02:41,700
или количество предложений, которые мы хотим вернуть,

60
00:02:41,700 --> 00:02:44,150
поскольку в процессе генерации присутствует некоторая случайность.

61
00:02:46,080 --> 00:02:48,750
Генерирование текстов путем угадывания следующего слова в предложении

62
00:02:48,750 --> 00:02:51,450
было целью предварительного обучения в GPT-2.

63
00:02:51,450 --> 00:02:55,140
Конвейер заполнения маски является целью предварительного обучения BERT,

64
00:02:55,140 --> 00:02:57,363
которая заключается в угадывании значения замаскированного слова.

65
00:02:58,260 --> 00:03:01,020
В этом случае мы спрашиваем два наиболее вероятных значения

66
00:03:01,020 --> 00:03:03,660
для пропущенных слов, согласно модели,

67
00:03:03,660 --> 00:03:07,053
и получаем в качестве возможных вариантов ответов "mathematical" или "computational".

68
00:03:08,280 --> 00:03:10,170
Еще одна задача, которую может выполнить модель Transformers

69
00:03:10,170 --> 00:03:12,660
классифицировать каждое слово в предложении

70
00:03:12,660 --> 00:03:14,970
вместо предложения в целом.

71
00:03:14,970 --> 00:03:18,390
Одним из примеров этого является Named Entity Recognition (распознавание именованных сущностей),

72
00:03:18,390 --> 00:03:20,820
которая представляет собой задачу идентификации сущностей,

73
00:03:20,820 --> 00:03:25,323
таких как люди, организации или места в предложении.

74
00:03:26,400 --> 00:03:30,570
Здесь модель правильно находит персону, "Sylvain",

75
00:03:30,570 --> 00:03:32,453
организацию, "Hugging Face",

76
00:03:32,453 --> 00:03:35,010
а также местоположение, "Brooklyn",

77
00:03:35,010 --> 00:03:36,303
внутри входного текста.

78
00:03:37,661 --> 00:03:40,230
Аргумент grouped_entities=True используется 

79
00:03:40,230 --> 00:03:42,330
для того, чтобы заставить конвейер сгруппировать

80
00:03:42,330 --> 00:03:44,790
различные слова, связанные с одним и тем же объектом,

81
00:03:44,790 --> 00:03:46,353
например, "Hugging" и "Face".

82
00:03:48,270 --> 00:03:50,670
Еще одна задача, доступная с помощью API конвейера

83
00:03:50,670 --> 00:03:52,920
является extractive question answering (экстрактивный ответ на вопрос).

84
00:03:52,920 --> 00:03:55,380
Предоставляется контекст и вопрос,

85
00:03:55,380 --> 00:03:58,290
модель определит участок текста в контексте

86
00:03:58,290 --> 00:04:00,190
содержащий ответ на вопрос.

87
00:04:01,650 --> 00:04:03,960
Получение кратких резюме очень длинных статей

88
00:04:03,960 --> 00:04:06,540
это то, с чем также может помочь библиотека Transformers,

89
00:04:06,540 --> 00:04:08,140
с конвейером суммаризации.

90
00:04:09,480 --> 00:04:12,570
Наконец, последняя задача, поддерживаемая API конвейера

91
00:04:12,570 --> 00:04:14,130
это перевод.

92
00:04:14,130 --> 00:04:16,170
Здесь мы используем французско-английскую модель

93
00:04:16,170 --> 00:04:17,460
найденную в хабе моделей

94
00:04:17,460 --> 00:04:19,893
для получения английской версии нашего входного текста.

95
00:04:21,600 --> 00:04:23,490
Вот краткий обзор всех задач

96
00:04:23,490 --> 00:04:25,500
которые мы рассмотрели в этом видео.

97
00:04:25,500 --> 00:04:27,390
Попробуйте использовать виджеты инференса

98
00:04:27,390 --> 00:04:28,327
в хабе моделей.

99
00:04:30,459 --> 00:04:33,475


100
00:04:33,475 --> 00:04:35,175


