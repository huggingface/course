1
00:00:05,540 --> 00:00:07,870
Как инстанцировать модель Transformers?

2
00:00:07,870 --> 00:00:14,800
В этом видео мы рассмотрим, как можно создать и использовать модель из библиотеки Transformers.

3
00:00:14,800 --> 00:00:23,490
Как мы уже видели, класс TFAutoModel позволяет вам создать предварительно обученную модель из любой контрольной точки на хабе Hugging Face.

4
00:00:23,490 --> 00:00:31,310
Он выберет нужный класс модели из библиотеки, чтобы создать правильную архитектуру и загрузить в нее веса предварительно обученной модели.

5
00:00:31,310 --> 00:00:39,890
Как мы видим, при задании контрольной точки BERT мы получаем модель TFBertModel, и аналогично для GPT-2 или BART.

6
00:00:39,890 --> 00:00:49,649
За кулисами этот API может принимать имя контрольной точки на хабе, в этом случае он будет загружать и кэшировать файл конфигурации, а также файл весов модели.

7
00:00:49,649 --> 00:00:56,739
Вы также можете указать путь к локальной папке, содержащей действительный файл конфигурации и весовой файл модели.

8
00:00:56,739 --> 00:01:06,409
Чтобы создать предварительно обученную модель, AutoModel API сначала откроет файл конфигурации, чтобы посмотреть класс конфигурации, который должен быть использован.

9
00:01:06,409 --> 00:01:13,509
Класс конфигурации зависит от типа модели (например, BERT, GPT-2 или BART).

10
00:01:13,509 --> 00:01:20,420
Как только у него есть соответствующий класс конфигурации, он может инстанцировать эту конфигурацию, которая представляет собой чертеж, позволяющий узнать, как создать модель.

11
00:01:20,420 --> 00:01:28,470
Он также использует этот класс конфигурации для поиска подходящего класса модели, который в сочетании с загруженной конфигурацией загружает модель.

12
00:01:28,470 --> 00:01:34,759
Эта модель еще не является нашей предварительно обученной моделью, поскольку она только что была инициализирована со случайными весами.

13
00:01:34,759 --> 00:01:40,299
Последним шагом является загрузка весов из файла модели в эту модель.

14
00:01:40,299 --> 00:01:48,100
Чтобы легко загрузить конфигурацию модели из любой контрольной точки или папки, содержащей папку конфигурации, мы можем использовать класс AutoConfig.

15
00:01:48,100 --> 00:01:54,270
Как и класс TFAutoModel, он выберет нужный класс конфигурации из библиотеки.

16
00:01:54,270 --> 00:02:03,280
Мы также можем использовать конкретный класс, соответствующий контрольной точке, но нам придется менять код каждый раз, когда мы хотим попробовать другую модель.

17
00:02:03,280 --> 00:02:11,190
Как мы уже говорили, конфигурация модели - это чертеж, который содержит всю информацию, необходимую для создания архитектуры модели.

18
00:02:11,190 --> 00:02:21,790
Например, модель BERT, связанная с контрольной точкой bert-base-cased, имеет 12 слоев, скрытый размер 768 и размер словаря 28 996.

19
00:02:21,790 --> 00:02:31,420
Получив конфигурацию, мы можем создать модель, которая имеет ту же архитектуру, что и наша контрольная точка, но инициализируется случайным образом.

20
00:02:31,420 --> 00:02:36,080
Затем мы можем обучить её с нуля, как любой модуль PyTorch/TensorFlow модель.

21
00:02:36,080 --> 00:02:40,870
Мы также можем изменить любую часть конфигурации, используя ключевые слова аргументов.

22
00:02:40,870 --> 00:02:48,379
Второй фрагмент кода создает случайную инициализированную модель BERT с десятью слоями вместо 12.

23
00:02:48,379 --> 00:02:54,019
Сохранить модель после ее обучения или тонкой настройки очень просто: нужно использовать метод save_pretrained.

24
00:02:54,019 --> 00:03:00,510
Здесь модель будет сохранена в папке с именем my-bert-model внутри текущего рабочего каталога.

25
00:03:00,510 --> 00:03:13,120
Затем такая модель может быть повторно загружена с помощью метода from_pretrained.