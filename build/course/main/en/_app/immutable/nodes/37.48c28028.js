import{s as hl,o as bl}from"../chunks/scheduler.37c15a92.js";import{S as yl,i as wl,g as d,s as c,r as y,A as _l,h,f as a,c as f,j as ml,u as w,x as b,k as pl,y as Ml,a as o,v as _,t as m,b as ve,d as p,w as M,p as Je}from"../chunks/index.2bf4358c.js";import{Y as ul}from"../chunks/Youtube.1e50a667.js";import{C as g}from"../chunks/CodeBlock.4f5fc1ad.js";import{C as dl}from"../chunks/CourseFloatingBanner.15ba07e6.js";import{F as $l}from"../chunks/FrameworkSwitchCourse.8d4d4ab6.js";import{H as Re}from"../chunks/Heading.8ada512a.js";function kl(u){let l,s;return l=new dl({props:{chapter:2,classNames:"absolute z-10 right-0 top-0",notebooks:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter2/section3_tf.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter2/section3_tf.ipynb"}]}}),{c(){y(l.$$.fragment)},l(t){w(l.$$.fragment,t)},m(t,i){_(l,t,i),s=!0},i(t){s||(p(l.$$.fragment,t),s=!0)},o(t){m(l.$$.fragment,t),s=!1},d(t){M(l,t)}}}function gl(u){let l,s;return l=new dl({props:{chapter:2,classNames:"absolute z-10 right-0 top-0",notebooks:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter2/section3_pt.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter2/section3_pt.ipynb"}]}}),{c(){y(l.$$.fragment)},l(t){w(l.$$.fragment,t)},m(t,i){_(l,t,i),s=!0},i(t){s||(p(l.$$.fragment,t),s=!0)},o(t){m(l.$$.fragment,t),s=!1},d(t){M(l,t)}}}function Tl(u){let l,s;return l=new ul({props:{id:"d3JVgghSOew"}}),{c(){y(l.$$.fragment)},l(t){w(l.$$.fragment,t)},m(t,i){_(l,t,i),s=!0},i(t){s||(p(l.$$.fragment,t),s=!0)},o(t){m(l.$$.fragment,t),s=!1},d(t){M(l,t)}}}function vl(u){let l,s;return l=new ul({props:{id:"AhChOFRegn4"}}),{c(){y(l.$$.fragment)},l(t){w(l.$$.fragment,t)},m(t,i){_(l,t,i),s=!0},i(t){s||(p(l.$$.fragment,t),s=!0)},o(t){m(l.$$.fragment,t),s=!1},d(t){M(l,t)}}}function Jl(u){let l,s="In this section we‚Äôll take a closer look at creating and using a model. We‚Äôll use the <code>TFAutoModel</code> class, which is handy when you want to instantiate any model from a checkpoint.",t,i,$="The <code>TFAutoModel</code> class and all of its relatives are actually simple wrappers over the wide variety of models available in the library. It‚Äôs a clever wrapper as it can automatically guess the appropriate model architecture for your checkpoint, and then instantiates a model with this architecture.";return{c(){l=d("p"),l.innerHTML=s,t=c(),i=d("p"),i.innerHTML=$},l(r){l=h(r,"P",{"data-svelte-h":!0}),b(l)!=="svelte-1f7w3iq"&&(l.innerHTML=s),t=f(r),i=h(r,"P",{"data-svelte-h":!0}),b(i)!=="svelte-1jmx5y3"&&(i.innerHTML=$)},m(r,k){o(r,l,k),o(r,t,k),o(r,i,k)},d(r){r&&(a(l),a(t),a(i))}}}function jl(u){let l,s="In this section we‚Äôll take a closer look at creating and using a model. We‚Äôll use the <code>AutoModel</code> class, which is handy when you want to instantiate any model from a checkpoint.",t,i,$="The <code>AutoModel</code> class and all of its relatives are actually simple wrappers over the wide variety of models available in the library. It‚Äôs a clever wrapper as it can automatically guess the appropriate model architecture for your checkpoint, and then instantiates a model with this architecture.";return{c(){l=d("p"),l.innerHTML=s,t=c(),i=d("p"),i.innerHTML=$},l(r){l=h(r,"P",{"data-svelte-h":!0}),b(l)!=="svelte-1gmoaxc"&&(l.innerHTML=s),t=f(r),i=h(r,"P",{"data-svelte-h":!0}),b(i)!=="svelte-g3gnjp"&&(i.innerHTML=$)},m(r,k){o(r,l,k),o(r,t,k),o(r,i,k)},d(r){r&&(a(l),a(t),a(i))}}}function Cl(u){let l,s;return l=new g({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEJlcnRDb25maWclMkMlMjBURkJlcnRNb2RlbCUwQSUwQSUyMyUyMEJ1aWxkaW5nJTIwdGhlJTIwY29uZmlnJTBBY29uZmlnJTIwJTNEJTIwQmVydENvbmZpZygpJTBBJTBBJTIzJTIwQnVpbGRpbmclMjB0aGUlMjBtb2RlbCUyMGZyb20lMjB0aGUlMjBjb25maWclMEFtb2RlbCUyMCUzRCUyMFRGQmVydE1vZGVsKGNvbmZpZyk=",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertConfig, TFBertModel

<span class="hljs-comment"># Building the config</span>
config = BertConfig()

<span class="hljs-comment"># Building the model from the config</span>
model = TFBertModel(config)`,wrap:!1}}),{c(){y(l.$$.fragment)},l(t){w(l.$$.fragment,t)},m(t,i){_(l,t,i),s=!0},i(t){s||(p(l.$$.fragment,t),s=!0)},o(t){m(l.$$.fragment,t),s=!1},d(t){M(l,t)}}}function Wl(u){let l,s;return l=new g({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEJlcnRDb25maWclMkMlMjBCZXJ0TW9kZWwlMEElMEElMjMlMjBCdWlsZGluZyUyMHRoZSUyMGNvbmZpZyUwQWNvbmZpZyUyMCUzRCUyMEJlcnRDb25maWcoKSUwQSUwQSUyMyUyMEJ1aWxkaW5nJTIwdGhlJTIwbW9kZWwlMjBmcm9tJTIwdGhlJTIwY29uZmlnJTBBbW9kZWwlMjAlM0QlMjBCZXJ0TW9kZWwoY29uZmlnKQ==",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertConfig, BertModel

<span class="hljs-comment"># Building the config</span>
config = BertConfig()

<span class="hljs-comment"># Building the model from the config</span>
model = BertModel(config)`,wrap:!1}}),{c(){y(l.$$.fragment)},l(t){w(l.$$.fragment,t)},m(t,i){_(l,t,i),s=!0},i(t){s||(p(l.$$.fragment,t),s=!0)},o(t){m(l.$$.fragment,t),s=!1},d(t){M(l,t)}}}function Ul(u){let l,s;return l=new g({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEJlcnRDb25maWclMkMlMjBURkJlcnRNb2RlbCUwQSUwQWNvbmZpZyUyMCUzRCUyMEJlcnRDb25maWcoKSUwQW1vZGVsJTIwJTNEJTIwVEZCZXJ0TW9kZWwoY29uZmlnKSUwQSUwQSUyMyUyME1vZGVsJTIwaXMlMjByYW5kb21seSUyMGluaXRpYWxpemVkIQ==",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertConfig, TFBertModel

config = BertConfig()
model = TFBertModel(config)

<span class="hljs-comment"># Model is randomly initialized!</span>`,wrap:!1}}),{c(){y(l.$$.fragment)},l(t){w(l.$$.fragment,t)},m(t,i){_(l,t,i),s=!0},i(t){s||(p(l.$$.fragment,t),s=!0)},o(t){m(l.$$.fragment,t),s=!1},d(t){M(l,t)}}}function Bl(u){let l,s;return l=new g({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEJlcnRDb25maWclMkMlMjBCZXJ0TW9kZWwlMEElMEFjb25maWclMjAlM0QlMjBCZXJ0Q29uZmlnKCklMEFtb2RlbCUyMCUzRCUyMEJlcnRNb2RlbChjb25maWcpJTBBJTBBJTIzJTIwTW9kZWwlMjBpcyUyMHJhbmRvbWx5JTIwaW5pdGlhbGl6ZWQh",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertConfig, BertModel

config = BertConfig()
model = BertModel(config)

<span class="hljs-comment"># Model is randomly initialized!</span>`,wrap:!1}}),{c(){y(l.$$.fragment)},l(t){w(l.$$.fragment,t)},m(t,i){_(l,t,i),s=!0},i(t){s||(p(l.$$.fragment,t),s=!0)},o(t){m(l.$$.fragment,t),s=!1},d(t){M(l,t)}}}function Zl(u){let l,s,t,i="As you saw earlier, we could replace <code>TFBertModel</code> with the equivalent <code>TFAutoModel</code> class. We‚Äôll do this from now on as this produces checkpoint-agnostic code; if your code works for one checkpoint, it should work seamlessly with another. This applies even if the architecture is different, as long as the checkpoint was trained for a similar task (for example, a sentiment analysis task).",$;return l=new g({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQmVydE1vZGVsJTBBJTBBbW9kZWwlMjAlM0QlMjBURkJlcnRNb2RlbC5mcm9tX3ByZXRyYWluZWQoJTIyYmVydC1iYXNlLWNhc2VkJTIyKQ==",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFBertModel

model = TFBertModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)`,wrap:!1}}),{c(){y(l.$$.fragment),s=c(),t=d("p"),t.innerHTML=i},l(r){w(l.$$.fragment,r),s=f(r),t=h(r,"P",{"data-svelte-h":!0}),b(t)!=="svelte-gweb15"&&(t.innerHTML=i)},m(r,k){_(l,r,k),o(r,s,k),o(r,t,k),$=!0},i(r){$||(p(l.$$.fragment,r),$=!0)},o(r){m(l.$$.fragment,r),$=!1},d(r){r&&(a(s),a(t)),M(l,r)}}}function Il(u){let l,s,t,i="As you saw earlier, we could replace <code>BertModel</code> with the equivalent <code>AutoModel</code> class. We‚Äôll do this from now on as this produces checkpoint-agnostic code; if your code works for one checkpoint, it should work seamlessly with another. This applies even if the architecture is different, as long as the checkpoint was trained for a similar task (for example, a sentiment analysis task).",$;return l=new g({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEJlcnRNb2RlbCUwQSUwQW1vZGVsJTIwJTNEJTIwQmVydE1vZGVsLmZyb21fcHJldHJhaW5lZCglMjJiZXJ0LWJhc2UtY2FzZWQlMjIp",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertModel

model = BertModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)`,wrap:!1}}),{c(){y(l.$$.fragment),s=c(),t=d("p"),t.innerHTML=i},l(r){w(l.$$.fragment,r),s=f(r),t=h(r,"P",{"data-svelte-h":!0}),b(t)!=="svelte-uopal9"&&(t.innerHTML=i)},m(r,k){_(l,r,k),o(r,s,k),o(r,t,k),$=!0},i(r){$||(p(l.$$.fragment,r),$=!0)},o(r){m(l.$$.fragment,r),$=!1},d(r){r&&(a(s),a(t)),M(l,r)}}}function xl(u){let l,s;return l=new g({props:{code:"bHMlMjBkaXJlY3Rvcnlfb25fbXlfY29tcHV0ZXIlMEElMEFjb25maWcuanNvbiUyMHRmX21vZGVsLmg1",highlighted:`ls <span class="hljs-keyword">directory_on_my_computer
</span>
<span class="hljs-built_in">config</span>.<span class="hljs-keyword">json </span>tf_model.h5`,wrap:!1}}),{c(){y(l.$$.fragment)},l(t){w(l.$$.fragment,t)},m(t,i){_(l,t,i),s=!0},i(t){s||(p(l.$$.fragment,t),s=!0)},o(t){m(l.$$.fragment,t),s=!1},d(t){M(l,t)}}}function El(u){let l,s;return l=new g({props:{code:"bHMlMjBkaXJlY3Rvcnlfb25fbXlfY29tcHV0ZXIlMEElMEFjb25maWcuanNvbiUyMHB5dG9yY2hfbW9kZWwuYmlu",highlighted:`ls <span class="hljs-keyword">directory_on_my_computer
</span>
<span class="hljs-built_in">config</span>.<span class="hljs-keyword">json </span>pytorch_model.<span class="hljs-keyword">bin</span>`,wrap:!1}}),{c(){y(l.$$.fragment)},l(t){w(l.$$.fragment,t)},m(t,i){_(l,t,i),s=!0},i(t){s||(p(l.$$.fragment,t),s=!0)},o(t){m(l.$$.fragment,t),s=!1},d(t){M(l,t)}}}function Rl(u){let l,s="The <em>tf_model.h5</em> file is known as the <em>state dictionary</em>; it contains all your model‚Äôs weights. The two files go hand in hand; the configuration is necessary to know your model‚Äôs architecture, while the model weights are your model‚Äôs parameters.";return{c(){l=d("p"),l.innerHTML=s},l(t){l=h(t,"P",{"data-svelte-h":!0}),b(l)!=="svelte-phe9t5"&&(l.innerHTML=s)},m(t,i){o(t,l,i)},d(t){t&&a(l)}}}function Hl(u){let l,s="The <em>pytorch_model.bin</em> file is known as the <em>state dictionary</em>; it contains all your model‚Äôs weights. The two files go hand in hand; the configuration is necessary to know your model‚Äôs architecture, while the model weights are your model‚Äôs parameters.";return{c(){l=d("p"),l.innerHTML=s},l(t){l=h(t,"P",{"data-svelte-h":!0}),b(l)!=="svelte-fa4pia"&&(l.innerHTML=s)},m(t,i){o(t,l,i)},d(t){t&&a(l)}}}function Vl(u){let l,s;return l=new g({props:{code:"aW1wb3J0JTIwdGVuc29yZmxvdyUyMGFzJTIwdGYlMEElMEFtb2RlbF9pbnB1dHMlMjAlM0QlMjB0Zi5jb25zdGFudChlbmNvZGVkX3NlcXVlbmNlcyk=",highlighted:`<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

model_inputs = tf.constant(encoded_sequences)`,wrap:!1}}),{c(){y(l.$$.fragment)},l(t){w(l.$$.fragment,t)},m(t,i){_(l,t,i),s=!0},i(t){s||(p(l.$$.fragment,t),s=!0)},o(t){m(l.$$.fragment,t),s=!1},d(t){M(l,t)}}}function Gl(u){let l,s;return l=new g({props:{code:"aW1wb3J0JTIwdG9yY2glMEElMEFtb2RlbF9pbnB1dHMlMjAlM0QlMjB0b3JjaC50ZW5zb3IoZW5jb2RlZF9zZXF1ZW5jZXMp",highlighted:`<span class="hljs-keyword">import</span> torch

model_inputs = torch.tensor(encoded_sequences)`,wrap:!1}}),{c(){y(l.$$.fragment)},l(t){w(l.$$.fragment,t)},m(t,i){_(l,t,i),s=!0},i(t){s||(p(l.$$.fragment,t),s=!0)},o(t){m(l.$$.fragment,t),s=!1},d(t){M(l,t)}}}function zl(u){let l,s,t,i,$,r,k,Ve,T,v,je,J,j,Ce,We,z,jt="However, if you know the type of model you want to use, you can use the class that defines its architecture directly. Let‚Äôs take a look at how this works with a BERT model.",Ge,N,ze,L,Ct="The first thing we‚Äôll need to do to initialize a BERT model is load a configuration object:",Ne,C,W,Ue,q,Wt="The configuration contains many attributes that are used to build the model:",Le,A,qe,Q,Ae,F,Ut="While you haven‚Äôt seen what all of these attributes do yet, you should recognize some of them: the <code>hidden_size</code> attribute defines the size of the <code>hidden_states</code> vector, and <code>num_hidden_layers</code> defines the number of layers the Transformer model has.",Qe,Y,Fe,X,Bt="Creating a model from the default configuration initializes it with random values:",Ye,U,B,Be,P,Zt='The model can be used in this state, but it will output gibberish; it needs to be trained first. We could train the model from scratch on the task at hand, but as you saw in <a href="/course/chapter1">Chapter 1</a>, this would require a long time and a lot of data, and it would have a non-negligible environmental impact. To avoid unnecessary and duplicated effort, it‚Äôs imperative to be able to share and reuse models that have already been trained.',Xe,S,It="Loading a Transformer model that is already trained is simple ‚Äî we can do this using the <code>from_pretrained()</code> method:",Pe,Z,I,Ze,D,xt='In the code sample above we didn‚Äôt use <code>BertConfig</code>, and instead loaded a pretrained model via the <code>bert-base-cased</code> identifier. This is a model checkpoint that was trained by the authors of BERT themselves; you can find more details about it in its <a href="https://huggingface.co/bert-base-cased" rel="nofollow">model card</a>.',Se,K,Et="This model is now initialized with all the weights of the checkpoint. It can be used directly for inference on the tasks it was trained on, and it can also be fine-tuned on a new task. By training with pretrained weights rather than from scratch, we can quickly achieve good results.",De,O,Rt="The weights have been downloaded and cached (so future calls to the <code>from_pretrained()</code> method won‚Äôt re-download them) in the cache folder, which defaults to <em>~/.cache/huggingface/transformers</em>. You can customize your cache folder by setting the <code>HF_HOME</code> environment variable.",Ke,ee,Ht='The identifier used to load the model can be the identifier of any model on the Model Hub, as long as it is compatible with the BERT architecture. The entire list of available BERT checkpoints can be found <a href="https://huggingface.co/models?filter=bert" rel="nofollow">here</a>.',Oe,te,et,le,Vt="Saving a model is as easy as loading one ‚Äî we use the <code>save_pretrained()</code> method, which is analogous to the <code>from_pretrained()</code> method:",tt,ne,lt,se,Gt="This saves two files to your disk:",nt,x,E,Ie,ae,zt="If you take a look at the <em>config.json</em> file, you‚Äôll recognize the attributes necessary to build the model architecture. This file also contains some metadata, such as where the checkpoint originated and what ü§ó Transformers version you were using when you last saved the checkpoint.",st,xe,oe,at,ie,Nt="Now that you know how to load and save a model, let‚Äôs try using it to make some predictions. Transformer models can only process numbers ‚Äî numbers that the tokenizer generates. But before we discuss tokenizers, let‚Äôs explore what inputs the model accepts.",ot,re,Lt="Tokenizers can take care of casting the inputs to the appropriate framework‚Äôs tensors, but to help you understand what‚Äôs going on, we‚Äôll take a quick look at what must be done before sending the inputs to the model.",it,ce,qt="Let‚Äôs say we have a couple of sequences:",rt,fe,ct,me,At="The tokenizer converts these to vocabulary indices which are typically called <em>input IDs</em>. Each sequence is now a list of numbers! The resulting output is:",ft,pe,mt,ue,Qt="This is a list of encoded sequences: a list of lists. Tensors only accept rectangular shapes (think matrices). This ‚Äúarray‚Äù is already of rectangular shape, so converting it to a tensor is easy:",pt,R,H,Ee,de,ut,he,Ft="Making use of the tensors with the model is extremely simple ‚Äî we just call the model with the inputs:",dt,be,ht,ye,Yt=`While the model accepts a lot of different arguments, only the input IDs are necessary. We‚Äôll explain what the other arguments do and when they are required later,
but first we need to take a closer look at the tokenizers that build the inputs that a Transformer model can understand.`,bt,He,yt;$=new $l({props:{fw:u[0]}}),k=new Re({props:{title:"Models",local:"models",headingTag:"h1"}});const Xt=[gl,kl],we=[];function Pt(e,n){return e[0]==="pt"?0:1}T=Pt(u),v=we[T]=Xt[T](u);const St=[vl,Tl],_e=[];function Dt(e,n){return e[0]==="pt"?0:1}J=Dt(u),j=_e[J]=St[J](u);function Kt(e,n){return e[0]==="pt"?jl:Jl}let wt=Kt(u),V=wt(u);N=new Re({props:{title:"Creating a Transformer",local:"creating-a-transformer",headingTag:"h2"}});const Ot=[Wl,Cl],Me=[];function el(e,n){return e[0]==="pt"?0:1}C=el(u),W=Me[C]=Ot[C](u),A=new g({props:{code:"cHJpbnQoY29uZmlnKQ==",highlighted:'<span class="hljs-built_in">print</span>(config)',wrap:!1}}),Q=new g({props:{code:"QmVydENvbmZpZyUyMCU3QiUwQSUyMCUyMCU1Qi4uLiU1RCUwQSUyMCUyMCUyMmhpZGRlbl9zaXplJTIyJTNBJTIwNzY4JTJDJTBBJTIwJTIwJTIyaW50ZXJtZWRpYXRlX3NpemUlMjIlM0ElMjAzMDcyJTJDJTBBJTIwJTIwJTIybWF4X3Bvc2l0aW9uX2VtYmVkZGluZ3MlMjIlM0ElMjA1MTIlMkMlMEElMjAlMjAlMjJudW1fYXR0ZW50aW9uX2hlYWRzJTIyJTNBJTIwMTIlMkMlMEElMjAlMjAlMjJudW1faGlkZGVuX2xheWVycyUyMiUzQSUyMDEyJTJDJTBBJTIwJTIwJTVCLi4uJTVEJTBBJTdE",highlighted:`BertConfig {
  [...]
  <span class="hljs-string">&quot;hidden_size&quot;</span>: <span class="hljs-number">768</span>,
  <span class="hljs-string">&quot;intermediate_size&quot;</span>: <span class="hljs-number">3072</span>,
  <span class="hljs-string">&quot;max_position_embeddings&quot;</span>: <span class="hljs-number">512</span>,
  <span class="hljs-string">&quot;num_attention_heads&quot;</span>: <span class="hljs-number">12</span>,
  <span class="hljs-string">&quot;num_hidden_layers&quot;</span>: <span class="hljs-number">12</span>,
  [...]
}`,wrap:!1}}),Y=new Re({props:{title:"Different loading methods",local:"different-loading-methods",headingTag:"h3"}});const tl=[Bl,Ul],$e=[];function ll(e,n){return e[0]==="pt"?0:1}U=ll(u),B=$e[U]=tl[U](u);const nl=[Il,Zl],ke=[];function sl(e,n){return e[0]==="pt"?0:1}Z=sl(u),I=ke[Z]=nl[Z](u),te=new Re({props:{title:"Saving methods",local:"saving-methods",headingTag:"h3"}}),ne=new g({props:{code:"bW9kZWwuc2F2ZV9wcmV0cmFpbmVkKCUyMmRpcmVjdG9yeV9vbl9teV9jb21wdXRlciUyMik=",highlighted:'model.save_pretrained(<span class="hljs-string">&quot;directory_on_my_computer&quot;</span>)',wrap:!1}});const al=[El,xl],ge=[];function ol(e,n){return e[0]==="pt"?0:1}x=ol(u),E=ge[x]=al[x](u);function il(e,n){return e[0]==="pt"?Hl:Rl}let _t=il(u),G=_t(u);oe=new Re({props:{title:"Using a Transformer model for inference",local:"using-a-transformer-model-for-inference",headingTag:"h2"}}),fe=new g({props:{code:"c2VxdWVuY2VzJTIwJTNEJTIwJTVCJTIySGVsbG8hJTIyJTJDJTIwJTIyQ29vbC4lMjIlMkMlMjAlMjJOaWNlISUyMiU1RA==",highlighted:'sequences = [<span class="hljs-string">&quot;Hello!&quot;</span>, <span class="hljs-string">&quot;Cool.&quot;</span>, <span class="hljs-string">&quot;Nice!&quot;</span>]',wrap:!1}}),pe=new g({props:{code:"ZW5jb2RlZF9zZXF1ZW5jZXMlMjAlM0QlMjAlNUIlMEElMjAlMjAlMjAlMjAlNUIxMDElMkMlMjA3NTkyJTJDJTIwOTk5JTJDJTIwMTAyJTVEJTJDJTBBJTIwJTIwJTIwJTIwJTVCMTAxJTJDJTIwNDY1OCUyQyUyMDEwMTIlMkMlMjAxMDIlNUQlMkMlMEElMjAlMjAlMjAlMjAlNUIxMDElMkMlMjAzODM1JTJDJTIwOTk5JTJDJTIwMTAyJTVEJTJDJTBBJTVE",highlighted:`encoded_sequences = [
    [<span class="hljs-number">101</span>, <span class="hljs-number">7592</span>, <span class="hljs-number">999</span>, <span class="hljs-number">102</span>],
    [<span class="hljs-number">101</span>, <span class="hljs-number">4658</span>, <span class="hljs-number">1012</span>, <span class="hljs-number">102</span>],
    [<span class="hljs-number">101</span>, <span class="hljs-number">3835</span>, <span class="hljs-number">999</span>, <span class="hljs-number">102</span>],
]`,wrap:!1}});const rl=[Gl,Vl],Te=[];function cl(e,n){return e[0]==="pt"?0:1}return R=cl(u),H=Te[R]=rl[R](u),de=new Re({props:{title:"Using the tensors as inputs to the model",local:"using-the-tensors-as-inputs-to-the-model",headingTag:"h3"}}),be=new g({props:{code:"b3V0cHV0JTIwJTNEJTIwbW9kZWwobW9kZWxfaW5wdXRzKQ==",highlighted:"output = model(model_inputs)",wrap:!1}}),{c(){l=d("meta"),s=c(),t=d("p"),i=c(),y($.$$.fragment),r=c(),y(k.$$.fragment),Ve=c(),v.c(),je=c(),j.c(),Ce=c(),V.c(),We=c(),z=d("p"),z.textContent=jt,Ge=c(),y(N.$$.fragment),ze=c(),L=d("p"),L.textContent=Ct,Ne=c(),W.c(),Ue=c(),q=d("p"),q.textContent=Wt,Le=c(),y(A.$$.fragment),qe=c(),y(Q.$$.fragment),Ae=c(),F=d("p"),F.innerHTML=Ut,Qe=c(),y(Y.$$.fragment),Fe=c(),X=d("p"),X.textContent=Bt,Ye=c(),B.c(),Be=c(),P=d("p"),P.innerHTML=Zt,Xe=c(),S=d("p"),S.innerHTML=It,Pe=c(),I.c(),Ze=c(),D=d("p"),D.innerHTML=xt,Se=c(),K=d("p"),K.textContent=Et,De=c(),O=d("p"),O.innerHTML=Rt,Ke=c(),ee=d("p"),ee.innerHTML=Ht,Oe=c(),y(te.$$.fragment),et=c(),le=d("p"),le.innerHTML=Vt,tt=c(),y(ne.$$.fragment),lt=c(),se=d("p"),se.textContent=Gt,nt=c(),E.c(),Ie=c(),ae=d("p"),ae.innerHTML=zt,st=c(),G.c(),xe=c(),y(oe.$$.fragment),at=c(),ie=d("p"),ie.textContent=Nt,ot=c(),re=d("p"),re.textContent=Lt,it=c(),ce=d("p"),ce.textContent=qt,rt=c(),y(fe.$$.fragment),ct=c(),me=d("p"),me.innerHTML=At,ft=c(),y(pe.$$.fragment),mt=c(),ue=d("p"),ue.textContent=Qt,pt=c(),H.c(),Ee=c(),y(de.$$.fragment),ut=c(),he=d("p"),he.textContent=Ft,dt=c(),y(be.$$.fragment),ht=c(),ye=d("p"),ye.textContent=Yt,bt=c(),He=d("p"),this.h()},l(e){const n=_l("svelte-u9bgzb",document.head);l=h(n,"META",{name:!0,content:!0}),n.forEach(a),s=f(e),t=h(e,"P",{}),ml(t).forEach(a),i=f(e),w($.$$.fragment,e),r=f(e),w(k.$$.fragment,e),Ve=f(e),v.l(e),je=f(e),j.l(e),Ce=f(e),V.l(e),We=f(e),z=h(e,"P",{"data-svelte-h":!0}),b(z)!=="svelte-y76c08"&&(z.textContent=jt),Ge=f(e),w(N.$$.fragment,e),ze=f(e),L=h(e,"P",{"data-svelte-h":!0}),b(L)!=="svelte-191c2e"&&(L.textContent=Ct),Ne=f(e),W.l(e),Ue=f(e),q=h(e,"P",{"data-svelte-h":!0}),b(q)!=="svelte-18mjodf"&&(q.textContent=Wt),Le=f(e),w(A.$$.fragment,e),qe=f(e),w(Q.$$.fragment,e),Ae=f(e),F=h(e,"P",{"data-svelte-h":!0}),b(F)!=="svelte-1bluqdr"&&(F.innerHTML=Ut),Qe=f(e),w(Y.$$.fragment,e),Fe=f(e),X=h(e,"P",{"data-svelte-h":!0}),b(X)!=="svelte-zv5p9a"&&(X.textContent=Bt),Ye=f(e),B.l(e),Be=f(e),P=h(e,"P",{"data-svelte-h":!0}),b(P)!=="svelte-exuiya"&&(P.innerHTML=Zt),Xe=f(e),S=h(e,"P",{"data-svelte-h":!0}),b(S)!=="svelte-6s4zap"&&(S.innerHTML=It),Pe=f(e),I.l(e),Ze=f(e),D=h(e,"P",{"data-svelte-h":!0}),b(D)!=="svelte-1lo0d64"&&(D.innerHTML=xt),Se=f(e),K=h(e,"P",{"data-svelte-h":!0}),b(K)!=="svelte-27fgem"&&(K.textContent=Et),De=f(e),O=h(e,"P",{"data-svelte-h":!0}),b(O)!=="svelte-xgdpbx"&&(O.innerHTML=Rt),Ke=f(e),ee=h(e,"P",{"data-svelte-h":!0}),b(ee)!=="svelte-xpbcp2"&&(ee.innerHTML=Ht),Oe=f(e),w(te.$$.fragment,e),et=f(e),le=h(e,"P",{"data-svelte-h":!0}),b(le)!=="svelte-v1sy0v"&&(le.innerHTML=Vt),tt=f(e),w(ne.$$.fragment,e),lt=f(e),se=h(e,"P",{"data-svelte-h":!0}),b(se)!=="svelte-1ooq8p2"&&(se.textContent=Gt),nt=f(e),E.l(e),Ie=f(e),ae=h(e,"P",{"data-svelte-h":!0}),b(ae)!=="svelte-2wqlmq"&&(ae.innerHTML=zt),st=f(e),G.l(e),xe=f(e),w(oe.$$.fragment,e),at=f(e),ie=h(e,"P",{"data-svelte-h":!0}),b(ie)!=="svelte-6brd07"&&(ie.textContent=Nt),ot=f(e),re=h(e,"P",{"data-svelte-h":!0}),b(re)!=="svelte-1yge08u"&&(re.textContent=Lt),it=f(e),ce=h(e,"P",{"data-svelte-h":!0}),b(ce)!=="svelte-8nofwm"&&(ce.textContent=qt),rt=f(e),w(fe.$$.fragment,e),ct=f(e),me=h(e,"P",{"data-svelte-h":!0}),b(me)!=="svelte-1635jd"&&(me.innerHTML=At),ft=f(e),w(pe.$$.fragment,e),mt=f(e),ue=h(e,"P",{"data-svelte-h":!0}),b(ue)!=="svelte-y3q2fn"&&(ue.textContent=Qt),pt=f(e),H.l(e),Ee=f(e),w(de.$$.fragment,e),ut=f(e),he=h(e,"P",{"data-svelte-h":!0}),b(he)!=="svelte-1et2den"&&(he.textContent=Ft),dt=f(e),w(be.$$.fragment,e),ht=f(e),ye=h(e,"P",{"data-svelte-h":!0}),b(ye)!=="svelte-1suqc52"&&(ye.textContent=Yt),bt=f(e),He=h(e,"P",{}),ml(He).forEach(a),this.h()},h(){pl(l,"name","hf:doc:metadata"),pl(l,"content",Nl)},m(e,n){Ml(document.head,l),o(e,s,n),o(e,t,n),o(e,i,n),_($,e,n),o(e,r,n),_(k,e,n),o(e,Ve,n),we[T].m(e,n),o(e,je,n),_e[J].m(e,n),o(e,Ce,n),V.m(e,n),o(e,We,n),o(e,z,n),o(e,Ge,n),_(N,e,n),o(e,ze,n),o(e,L,n),o(e,Ne,n),Me[C].m(e,n),o(e,Ue,n),o(e,q,n),o(e,Le,n),_(A,e,n),o(e,qe,n),_(Q,e,n),o(e,Ae,n),o(e,F,n),o(e,Qe,n),_(Y,e,n),o(e,Fe,n),o(e,X,n),o(e,Ye,n),$e[U].m(e,n),o(e,Be,n),o(e,P,n),o(e,Xe,n),o(e,S,n),o(e,Pe,n),ke[Z].m(e,n),o(e,Ze,n),o(e,D,n),o(e,Se,n),o(e,K,n),o(e,De,n),o(e,O,n),o(e,Ke,n),o(e,ee,n),o(e,Oe,n),_(te,e,n),o(e,et,n),o(e,le,n),o(e,tt,n),_(ne,e,n),o(e,lt,n),o(e,se,n),o(e,nt,n),ge[x].m(e,n),o(e,Ie,n),o(e,ae,n),o(e,st,n),G.m(e,n),o(e,xe,n),_(oe,e,n),o(e,at,n),o(e,ie,n),o(e,ot,n),o(e,re,n),o(e,it,n),o(e,ce,n),o(e,rt,n),_(fe,e,n),o(e,ct,n),o(e,me,n),o(e,ft,n),_(pe,e,n),o(e,mt,n),o(e,ue,n),o(e,pt,n),Te[R].m(e,n),o(e,Ee,n),_(de,e,n),o(e,ut,n),o(e,he,n),o(e,dt,n),_(be,e,n),o(e,ht,n),o(e,ye,n),o(e,bt,n),o(e,He,n),yt=!0},p(e,[n]){const fl={};n&1&&(fl.fw=e[0]),$.$set(fl);let Mt=T;T=Pt(e),T!==Mt&&(Je(),m(we[Mt],1,1,()=>{we[Mt]=null}),ve(),v=we[T],v||(v=we[T]=Xt[T](e),v.c()),p(v,1),v.m(je.parentNode,je));let $t=J;J=Dt(e),J!==$t&&(Je(),m(_e[$t],1,1,()=>{_e[$t]=null}),ve(),j=_e[J],j||(j=_e[J]=St[J](e),j.c()),p(j,1),j.m(Ce.parentNode,Ce)),wt!==(wt=Kt(e))&&(V.d(1),V=wt(e),V&&(V.c(),V.m(We.parentNode,We)));let kt=C;C=el(e),C!==kt&&(Je(),m(Me[kt],1,1,()=>{Me[kt]=null}),ve(),W=Me[C],W||(W=Me[C]=Ot[C](e),W.c()),p(W,1),W.m(Ue.parentNode,Ue));let gt=U;U=ll(e),U!==gt&&(Je(),m($e[gt],1,1,()=>{$e[gt]=null}),ve(),B=$e[U],B||(B=$e[U]=tl[U](e),B.c()),p(B,1),B.m(Be.parentNode,Be));let Tt=Z;Z=sl(e),Z!==Tt&&(Je(),m(ke[Tt],1,1,()=>{ke[Tt]=null}),ve(),I=ke[Z],I||(I=ke[Z]=nl[Z](e),I.c()),p(I,1),I.m(Ze.parentNode,Ze));let vt=x;x=ol(e),x!==vt&&(Je(),m(ge[vt],1,1,()=>{ge[vt]=null}),ve(),E=ge[x],E||(E=ge[x]=al[x](e),E.c()),p(E,1),E.m(Ie.parentNode,Ie)),_t!==(_t=il(e))&&(G.d(1),G=_t(e),G&&(G.c(),G.m(xe.parentNode,xe)));let Jt=R;R=cl(e),R!==Jt&&(Je(),m(Te[Jt],1,1,()=>{Te[Jt]=null}),ve(),H=Te[R],H||(H=Te[R]=rl[R](e),H.c()),p(H,1),H.m(Ee.parentNode,Ee))},i(e){yt||(p($.$$.fragment,e),p(k.$$.fragment,e),p(v),p(j),p(N.$$.fragment,e),p(W),p(A.$$.fragment,e),p(Q.$$.fragment,e),p(Y.$$.fragment,e),p(B),p(I),p(te.$$.fragment,e),p(ne.$$.fragment,e),p(E),p(oe.$$.fragment,e),p(fe.$$.fragment,e),p(pe.$$.fragment,e),p(H),p(de.$$.fragment,e),p(be.$$.fragment,e),yt=!0)},o(e){m($.$$.fragment,e),m(k.$$.fragment,e),m(v),m(j),m(N.$$.fragment,e),m(W),m(A.$$.fragment,e),m(Q.$$.fragment,e),m(Y.$$.fragment,e),m(B),m(I),m(te.$$.fragment,e),m(ne.$$.fragment,e),m(E),m(oe.$$.fragment,e),m(fe.$$.fragment,e),m(pe.$$.fragment,e),m(H),m(de.$$.fragment,e),m(be.$$.fragment,e),yt=!1},d(e){e&&(a(s),a(t),a(i),a(r),a(Ve),a(je),a(Ce),a(We),a(z),a(Ge),a(ze),a(L),a(Ne),a(Ue),a(q),a(Le),a(qe),a(Ae),a(F),a(Qe),a(Fe),a(X),a(Ye),a(Be),a(P),a(Xe),a(S),a(Pe),a(Ze),a(D),a(Se),a(K),a(De),a(O),a(Ke),a(ee),a(Oe),a(et),a(le),a(tt),a(lt),a(se),a(nt),a(Ie),a(ae),a(st),a(xe),a(at),a(ie),a(ot),a(re),a(it),a(ce),a(rt),a(ct),a(me),a(ft),a(mt),a(ue),a(pt),a(Ee),a(ut),a(he),a(dt),a(ht),a(ye),a(bt),a(He)),a(l),M($,e),M(k,e),we[T].d(e),_e[J].d(e),V.d(e),M(N,e),Me[C].d(e),M(A,e),M(Q,e),M(Y,e),$e[U].d(e),ke[Z].d(e),M(te,e),M(ne,e),ge[x].d(e),G.d(e),M(oe,e),M(fe,e),M(pe,e),Te[R].d(e),M(de,e),M(be,e)}}}const Nl='{"title":"Models","local":"models","sections":[{"title":"Creating a Transformer","local":"creating-a-transformer","sections":[{"title":"Different loading methods","local":"different-loading-methods","sections":[],"depth":3},{"title":"Saving methods","local":"saving-methods","sections":[],"depth":3}],"depth":2},{"title":"Using a Transformer model for inference","local":"using-a-transformer-model-for-inference","sections":[{"title":"Using the tensors as inputs to the model","local":"using-the-tensors-as-inputs-to-the-model","sections":[],"depth":3}],"depth":2}],"depth":1}';function Ll(u,l,s){let t="pt";return bl(()=>{const i=new URLSearchParams(window.location.search);s(0,t=i.get("fw")||"pt")}),[t]}class Sl extends yl{constructor(l){super(),wl(this,l,Ll,zl,hl,{})}}export{Sl as component};
