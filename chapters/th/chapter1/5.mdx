# โมเดล Encoder

<CourseFloatingBanner
    chapter={1}
    classNames="absolute z-10 right-0 top-0"
/>

<Youtube id="MUqNwgPjJvQ" />

โมเดล encoder ใช้เพียงส่วน encoder จากโมเดล Transformer เท่านั้น ในแต่ละชั้น attention layer สามารถเข้าถึงคำทุกคำในประโยคได้ โมเดลเหล่านี้ส่วนใหญ่จะใช้ attention แบบสองทาง (หรือเรียกว่า bi-directional attention) และถูกเรียกว่า *โมเดล auto-encoding*

โมเดล pretrain ในกลุ่มนี้จะเทรนโดยการให้ประโยคเริ่มต้นและประโยควิบัติ(เช่น เว้นว่างคำบางคำในประโยค) และเป้าหมายของโมเดลคือหาวิธีสร้างประโยคเริ่มต้นให้ดีดังเดิม

โมเดล encoder เหมาะกับงานแบบนี้ที่สุด เพราะงานเหล่านี้ต้องการความเข้าใจประโยคทั้งประโยค ตัวอย่างงานแบบนี้เช่น การแยกแยะประโยค, การระบุคำเฉพาะในประโยค (รวมถึงการแยกแยะประเภทคำ), และการสกัดคำถามคำตอบ

ตัวแทนโมเดลในกลุ่มนี้ได้แก่:

- [ALBERT](https://huggingface.co/transformers/model_doc/albert.html)
- [BERT](https://huggingface.co/transformers/model_doc/bert.html)
- [DistilBERT](https://huggingface.co/transformers/model_doc/distilbert.html)
- [ELECTRA](https://huggingface.co/transformers/model_doc/electra.html)
- [RoBERTa](https://huggingface.co/transformers/model_doc/roberta.html)
