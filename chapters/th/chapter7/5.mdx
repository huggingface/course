<FrameworkSwitchCourse {fw} />

# ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢[[‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢]]

{#if fw === 'pt'}

<CourseFloatingBanner chapter={7}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter7/section5_pt.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter7/section5_pt.ipynb"},
]} />

{:else}

<CourseFloatingBanner chapter={7}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter7/section5_tf.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter7/section5_tf.ipynb"},
]} />

{/if}


‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏°‡∏≤‡∏î‡∏π‡∏Å‡∏±‡∏ô‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏• Transformer ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏¢‡πà‡∏≠‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏Ç‡∏ô‡∏≤‡∏î‡∏¢‡∏≤‡∏ß‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏ó‡∏™‡∏£‡∏∏‡∏õ‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£ ‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ß‡πà‡∏≤ _text summarization_ ‡∏ô‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á‡πÉ‡∏ô‡∏á‡∏≤‡∏ô NLP ‡∏ó‡∏µ‡πà‡∏ó‡πâ‡∏≤‡∏ó‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢ ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏¢‡∏≤‡∏ß ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏ã‡∏∂‡πà‡∏á‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏´‡∏•‡∏±‡∏Å‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡∏Å‡πá‡∏ï‡∏≤‡∏° ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡πÑ‡∏î‡πâ‡∏î‡∏µ ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏≠‡∏±‡∏ô‡∏ó‡∏£‡∏á‡∏û‡∏•‡∏±‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÉ‡∏´‡πâ‡∏Å‡∏±‡∏ö‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≤‡∏á‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡πÇ‡∏î‡∏¢‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏ö‡∏≤‡∏†‡∏≤‡∏£‡∏∞‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡πÇ‡∏î‡πÄ‡∏°‡∏ô‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏Ç‡∏ô‡∏≤‡∏î‡∏¢‡∏≤‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î

<Youtube id="yHnr5Dk2zCI"/>

‡πÅ‡∏°‡πâ‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏°‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß‡∏ö‡∏ô [Hugging Face Hub](https://huggingface.co/models?pipeline_tag=summarization&sort=downloads) ‡πÅ‡∏ï‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏Å‡∏∑‡∏≠‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏õ‡∏•‡∏Å‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≠‡∏á‡∏†‡∏≤‡∏©‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡πÅ‡∏•‡∏∞‡∏™‡πÄ‡∏õ‡∏ô ‡πÉ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡πâ‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ ‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡∏°‡∏µ [model](https://huggingface.co/huggingface-course/mt5-small-finetuned-amazon-en-es) ‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡∏∏‡∏õ‡∏ö‡∏ó‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡πå‡∏Ç‡∏≠‡∏á‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÑ‡∏î‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà :

<iframe src="https://course-demos-mt5-small-finetuned-amazon-en-es.hf.space" frameBorder="0" height="400" title="Gradio app" class="block dark:hidden container p-0 flex-grow space-iframe" allow="accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking" sandbox="allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"></iframe>

‡∏î‡∏±‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏£‡∏∞‡∏ö‡∏∏‡πÑ‡∏ß‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡πå‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏Ç‡∏≠‡∏á‡∏ï‡∏ô ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏Ñ‡∏•‡∏±‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≠‡∏á‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏ô‡∏µ‡πâ

## ‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ñ‡∏•‡∏±‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤[[‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ñ‡∏•‡∏±‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤]]

‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ [Multilingual Amazon Reviews Corpus](https://huggingface.co/datasets/amazon_reviews_multi) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏≠‡∏á‡∏†‡∏≤‡∏©‡∏≤‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤ ‡∏Ñ‡∏•‡∏±‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏µ‡πâ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡∏ö‡∏ó‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡πå‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏Ç‡∏≠‡∏á Amazon ‡πÉ‡∏ô‡∏´‡∏Å‡∏†‡∏≤‡∏©‡∏≤ ‡πÅ‡∏•‡∏∞‡πÇ‡∏î‡∏¢‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ï‡∏±‡∏ß‡πÅ‡∏¢‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤ ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡∏Å‡πá‡∏ï‡∏≤‡∏° ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡∏¢‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö ‡πÄ‡∏£‡∏≤‡∏à‡∏∂‡∏á‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠‡∏î‡∏±‡∏á‡∏Å‡∏•‡πà‡∏≤‡∏ß‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏ó‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÑ‡∏î‡πâ! ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô ‡πÉ‡∏´‡πâ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ä‡∏∏‡∏î‡∏¢‡πà‡∏≠‡∏¢‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡πÅ‡∏•‡∏∞‡∏™‡πÄ‡∏õ‡∏ô‡∏à‡∏≤‡∏Å Hugging Face Hub:

```python
from datasets import load_dataset

spanish_dataset = load_dataset("amazon_reviews_multi", "es")
english_dataset = load_dataset("amazon_reviews_multi", "en")
english_dataset
```

```python out
DatasetDict({
    train: Dataset({
        features: ['review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],
        num_rows: 200000
    })
    validation: Dataset({
        features: ['review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],
        num_rows: 5000
    })
    test: Dataset({
        features: ['review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],
        num_rows: 5000
    })
})
```

‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏´‡πá‡∏ô ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏†‡∏≤‡∏©‡∏≤ ‡∏°‡∏µ‡∏ö‡∏ó‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡πå 200,000 ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å 'train' ‡πÅ‡∏•‡∏∞ 5,000 ‡∏ö‡∏ó‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å `validation` ‡πÅ‡∏•‡∏∞ `test` ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏ó‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏™‡∏ô‡πÉ‡∏à‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå `review_body` ‡πÅ‡∏•‡∏∞ `review_title` ‡∏•‡∏≠‡∏á‡∏°‡∏≤‡∏î‡∏π‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏á‡πà‡∏≤‡∏¢‡πÜ ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏™‡∏∏‡πà‡∏°‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏ä‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÉ‡∏ô [‡∏ö‡∏ó‡∏ó‡∏µ‡πà 5](/course/th/chapter5):

```python
def show_samples(dataset, num_samples=3, seed=42):
    sample = dataset["train"].shuffle(seed=seed).select(range(num_samples))
    for example in sample:
        print(f"\n'>> Title: {example['review_title']}'")
        print(f"'>> Review: {example['review_body']}'")


show_samples(english_dataset)
```

```python out
'>> Title: Worked in front position, not rear'
'>> Review: 3 stars because these are not rear brakes as stated in the item description. At least the mount adapter only worked on the front fork of the bike that I got it for.'

'>> Title: meh'
'>> Review: Does it‚Äôs job and it‚Äôs gorgeous but mine is falling apart, I had to basically put it together again with hot glue'

'>> Title: Can\'t beat these for the money'
'>> Review: Bought this for handling miscellaneous aircraft parts and hanger "stuff" that I needed to organize; it really fit the bill. The unit arrived quickly, was well packaged and arrived intact (always a good sign). There are five wall mounts-- three on the top and two on the bottom. I wanted to mount it on the wall, so all I had to do was to remove the top two layers of plastic drawers, as well as the bottom corner drawers, place it when I wanted and mark it; I then used some of the new plastic screw in wall anchors (the 50 pound variety) and it easily mounted to the wall. Some have remarked that they wanted dividers for the drawers, and that they made those. Good idea. My application was that I needed something that I can see the contents at about eye level, so I wanted the fuller-sized drawers. I also like that these are the new plastic that doesn\'t get brittle and split like my older plastic drawers did. I like the all-plastic construction. It\'s heavy duty enough to hold metal parts, but being made of plastic it\'s not as heavy as a metal frame, so you can easily mount it to the wall and still load it up with heavy stuff, or light stuff. No problem there. For the money, you can\'t beat it. Best one of these I\'ve bought to date-- and I\'ve been using some version of these for over forty years.'
```

<Tip>

‚úèÔ∏è **‡∏•‡∏≠‡∏á‡∏î‡∏π‡∏™‡∏¥!** ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏∏‡πà‡∏° seed ‡πÉ‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á `Dataset.shuffle()` ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏≥‡∏£‡∏ß‡∏à‡∏ö‡∏ó‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡πå‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡πÉ‡∏ô‡∏Ñ‡∏•‡∏±‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏´‡∏≤‡∏Å‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏û‡∏π‡∏î‡∏†‡∏≤‡∏©‡∏≤‡∏™‡πÄ‡∏õ‡∏ô ‡∏•‡∏≠‡∏á‡∏î‡∏π‡∏ö‡∏ó‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡πå‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏ô `spanish_dataset` ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏ß‡πà‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏î‡∏π‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏ó‡∏™‡∏£‡∏∏‡∏õ‡∏ó‡∏µ‡πà‡∏™‡∏°‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏°‡∏ú‡∏•‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà

</Tip>

‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏ö‡∏ó‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏°‡∏±‡∏Å‡∏û‡∏ö‡∏ó‡∏≤‡∏á‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå ‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡πÄ‡∏ä‡∏¥‡∏á‡∏ö‡∏ß‡∏Å‡πÑ‡∏õ‡∏à‡∏ô‡∏ñ‡∏∂‡∏á‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏ö (‡πÅ‡∏•‡∏∞‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ô‡∏±‡πâ‡∏ô!) ‡πÅ‡∏°‡πâ‡∏ß‡πà‡∏≤‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠ "meh" ‡∏à‡∏∞‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏≤‡∏Å‡∏ô‡∏±‡∏Å ‡πÅ‡∏ï‡πà‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏Å‡πá‡∏î‡∏π‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡∏ö‡∏ó‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏û‡∏≠‡∏™‡∏°‡∏Ñ‡∏ß‡∏£ ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏≠‡∏ö‡∏£‡∏°‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î 400,000 ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏≠‡∏≤‡∏à‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏≤‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ‡∏ö‡∏ô GPU ‡∏ï‡∏±‡∏ß‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏°‡∏∏‡πà‡∏á‡πÄ‡∏ô‡πâ‡∏ô‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏î‡πÄ‡∏°‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Ç‡∏≠‡∏á‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡πÅ‡∏ó‡∏ô ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏î‡πÄ‡∏°‡∏ô‡πÉ‡∏î‡πÑ‡∏î‡πâ ‡πÉ‡∏´‡πâ‡πÅ‡∏õ‡∏•‡∏á `english_dataset` ‡πÄ‡∏õ‡πá‡∏ô `pandas.DataFrame` ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ö‡∏ó‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡πå‡∏ï‡πà‡∏≠‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå:

```python
english_dataset.set_format("pandas")
english_df = english_dataset["train"][:]
# Show counts for top 20 products
english_df["product_category"].value_counts()[:20]
```

```python out
home                      17679
apparel                   15951
wireless                  15717
other                     13418
beauty                    12091
drugstore                 11730
kitchen                   10382
toy                        8745
sports                     8277
automotive                 7506
lawn_and_garden            7327
home_improvement           7136
pet_products               7082
digital_ebook_purchase     6749
pc                         6401
electronics                6186
office_product             5521
shoes                      5197
grocery                    4730
book                       3756
Name: product_category, dtype: int64
```

‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏¢‡∏≠‡∏î‡∏ô‡∏¥‡∏¢‡∏°‡πÉ‡∏ô‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡∏Ñ‡∏∑‡∏≠‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡πÉ‡∏ô‡∏Ñ‡∏£‡∏±‡∏ß‡πÄ‡∏£‡∏∑‡∏≠‡∏ô ‡πÄ‡∏™‡∏∑‡πâ‡∏≠‡∏ú‡πâ‡∏≤ ‡πÅ‡∏•‡∏∞‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏≠‡∏¥‡πÄ‡∏•‡πá‡∏Å‡∏ó‡∏£‡∏≠‡∏ô‡∏¥‡∏Å‡∏™‡πå‡πÑ‡∏£‡πâ‡∏™‡∏≤‡∏¢ ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡∏Å‡πá‡∏ï‡∏≤‡∏° ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏¢‡∏∂‡∏î‡∏ñ‡∏∑‡∏≠‡∏ò‡∏µ‡∏°‡∏Ç‡∏≠‡∏á Amazon ‡∏ï‡πà‡∏≠‡πÑ‡∏õ ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏°‡∏∏‡πà‡∏á‡πÄ‡∏ô‡πâ‡∏ô‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡∏ö‡∏ó‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡πå‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠ ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏Å‡πà‡∏≠‡∏ï‡∏±‡πâ‡∏á‡∏Ç‡∏∂‡πâ‡∏ô! ‡πÄ‡∏£‡∏≤‡πÄ‡∏´‡πá‡∏ô‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏™‡∏≠‡∏á‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡πÉ‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏á‡∏¥‡∏ô (`‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠` ‡πÅ‡∏•‡∏∞ `digital_ebook_purchase`) ‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô ‡πÄ‡∏£‡∏≤‡∏°‡∏≤‡∏Å‡∏£‡∏≠‡∏á‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á‡∏†‡∏≤‡∏©‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡∏î‡∏±‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÄ‡∏´‡πá‡∏ô‡πÉ‡∏ô [‡∏ö‡∏ó‡∏ó‡∏µ‡πà 5](/course/th/chapter5) ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô `Dataset.filter()` ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏ö‡πà‡∏á‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏°‡∏≤‡∏Å ‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô‡πÄ‡∏£‡∏≤‡∏à‡∏∂‡∏á‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏á‡πà‡∏≤‡∏¢‡πÜ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡∏™‡∏¥‡πà‡∏á‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ:

```python
def filter_books(example):
    return (
        example["product_category"] == "book"
        or example["product_category"] == "digital_ebook_purchase"
    )
```

‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏≤‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏Å‡∏±‡∏ö `english_dataset` ‡πÅ‡∏•‡∏∞ `spanish_dataset` ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏∞‡∏°‡∏µ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠ ‡∏Å‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á ‡∏°‡∏≤‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡∏≠‡∏á `english_dataset` ‡∏à‡∏≤‡∏Å `"pandas"` ‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡πÄ‡∏õ‡πá‡∏ô `"arrow"`:

```python
english_dataset.reset_format()
```

‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô ‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á ‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ö‡∏ó‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏ß‡πà‡∏≤‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡∏à‡∏£‡∏¥‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà:

```python
spanish_books = spanish_dataset.filter(filter_books)
english_books = english_dataset.filter(filter_books)
show_samples(english_books)
```

```python out
'>> Title: I\'m dissapointed.'
'>> Review: I guess I had higher expectations for this book from the reviews. I really thought I\'d at least like it. The plot idea was great. I loved Ash but, it just didnt go anywhere. Most of the book was about their radio show and talking to callers. I wanted the author to dig deeper so we could really get to know the characters. All we know about Grace is that she is attractive looking, Latino and is kind of a brat. I\'m dissapointed.'

'>> Title: Good art, good price, poor design'
'>> Review: I had gotten the DC Vintage calendar the past two years, but it was on backorder forever this year and I saw they had shrunk the dimensions for no good reason. This one has good art choices but the design has the fold going through the picture, so it\'s less aesthetically pleasing, especially if you want to keep a picture to hang. For the price, a good calendar'

'>> Title: Helpful'
'>> Review: Nearly all the tips useful and. I consider myself an intermediate to advanced user of OneNote. I would highly recommend.'
```

‡πÇ‡∏≠‡πÄ‡∏Ñ ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤‡∏ö‡∏ó‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡πå‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏Ñ‡∏£‡πà‡∏á‡∏Ñ‡∏£‡∏±‡∏î ‡πÅ‡∏•‡∏∞‡∏≠‡∏≤‡∏à‡∏≠‡πâ‡∏≤‡∏á‡∏ñ‡∏∂‡∏á‡∏™‡∏¥‡πà‡∏á‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡πÄ‡∏ä‡πà‡∏ô ‡∏õ‡∏è‡∏¥‡∏ó‡∏¥‡∏ô‡πÅ‡∏•‡∏∞‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô‡∏≠‡∏¥‡πÄ‡∏•‡πá‡∏Å‡∏ó‡∏£‡∏≠‡∏ô‡∏¥‡∏Å‡∏™‡πå ‡πÄ‡∏ä‡πà‡∏ô OneNote ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡∏Å‡πá‡∏ï‡∏≤‡∏° ‡∏î‡∏π‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏ß‡πà‡∏≤‡πÇ‡∏î‡πÄ‡∏°‡∏ô‡∏à‡∏∞‡∏°‡∏µ‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏≠‡∏ö‡∏£‡∏°‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ ‡∏Å‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏î‡∏π‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏ô‡∏µ‡πâ ‡πÄ‡∏£‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥: ‡∏£‡∏ß‡∏°‡∏ö‡∏ó‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡πå‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡πÅ‡∏•‡∏∞‡∏™‡πÄ‡∏õ‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏≠‡∏ö‡πÄ‡∏à‡πá‡∏Å‡∏ï‡πå `DatasetDict` ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ü§ó Dataset ‡∏°‡∏µ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô `concatenate_datasets()` ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå ‡∏ã‡∏∂‡πà‡∏á (‡∏ï‡∏≤‡∏°‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥) ‡∏à‡∏∞‡∏ã‡πâ‡∏≠‡∏ô‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏ `Dataset` ‡∏™‡∏≠‡∏á‡∏ä‡∏¥‡πâ‡∏ô‡πÑ‡∏ß‡πâ‡∏ã‡πâ‡∏≠‡∏ô‡∏Å‡∏±‡∏ô ‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≠‡∏á‡∏†‡∏≤‡∏©‡∏≤ ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏ß‡∏ô‡∏ã‡πâ‡∏≥‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å‡∏ô‡∏±‡πâ‡∏ô ‡πÅ‡∏•‡∏∞‡∏™‡∏±‡∏ö‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÑ‡∏°‡πà‡∏û‡∏≠‡∏î‡∏µ‡∏Å‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß:

```python
from datasets import concatenate_datasets, DatasetDict

books_dataset = DatasetDict()

for split in english_books.keys():
    books_dataset[split] = concatenate_datasets(
        [english_books[split], spanish_books[split]]
    )
    books_dataset[split] = books_dataset[split].shuffle(seed=42)

# Peek at a few examples
show_samples(books_dataset)
```

```python out
'>> Title: Easy to follow!!!!'
'>> Review: I loved The dash diet weight loss Solution. Never hungry. I would recommend this diet. Also the menus are well rounded. Try it. Has lots of the information need thanks.'

'>> Title: PARCIALMENTE DA√ëADO'
'>> Review: Me lleg√≥ el d√≠a que tocaba, junto a otros libros que ped√≠, pero la caja lleg√≥ en mal estado lo cual da√±√≥ las esquinas de los libros porque ven√≠an sin protecci√≥n (forro).'

'>> Title: no lo he podido descargar'
'>> Review: igual que el anterior'
```

‡∏î‡∏π‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏ß‡πà‡∏≤‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ú‡∏™‡∏°‡∏ú‡∏™‡∏≤‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡πÅ‡∏•‡∏∞‡∏™‡πÄ‡∏õ‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô! ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏°‡∏µ‡∏Ñ‡∏•‡∏±‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏≠‡∏ö‡∏£‡∏°‡πÅ‡∏•‡πâ‡∏ß ‡∏™‡∏¥‡πà‡∏á‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡∏Å‡πÅ‡∏à‡∏á‡∏Ñ‡∏≥‡πÉ‡∏ô‡∏ö‡∏ó‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡πå‡πÅ‡∏•‡∏∞‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á ‡∏ô‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏¥‡πà‡∏á‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏¢‡∏¥‡πà‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ ‡πÇ‡∏î‡∏¢‡∏ó‡∏µ‡πà‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏ô‡πâ‡∏°‡∏ô‡πâ‡∏≤‡∏ß‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡πâ‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏≠‡∏á‡∏Ñ‡∏≥‡πÉ‡∏ô‡∏™‡∏£‡∏∏‡∏õ‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡πÑ‡∏î‡πâ ‡πÇ‡∏Ñ‡∏£‡∏á‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡∏Å‡πÅ‡∏à‡∏á‡∏Ñ‡∏≥ ‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ö‡∏¥‡∏î‡πÄ‡∏ö‡∏∑‡∏≠‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏≤‡∏Å‡πÑ‡∏õ‡πÄ‡∏û‡∏µ‡∏¢‡∏á 1-2 ‡∏Ñ‡∏≥:

<div class="flex justify-center">
<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/review-lengths.svg" alt="Word count distributions for the review titles and texts."/>
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/review-lengths-dark.svg" alt="Word count distributions for the review titles and texts."/>
</div>

‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏±‡∏ö‡∏™‡∏¥‡πà‡∏á‡∏ô‡∏µ‡πâ ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏Å‡∏£‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏±‡πâ‡∏ô‡∏°‡∏≤‡∏Å‡∏≠‡∏≠‡∏Å ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ö‡∏ó‡∏™‡∏£‡∏∏‡∏õ‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à‡∏¢‡∏¥‡πà‡∏á‡∏Ç‡∏∂‡πâ‡∏ô ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏£‡∏≤‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡πÅ‡∏•‡∏∞‡∏™‡πÄ‡∏õ‡∏ô ‡πÄ‡∏£‡∏≤‡∏à‡∏∂‡∏á‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏û‡∏§‡∏ï‡∏¥‡∏Å‡∏£‡∏£‡∏°‡∏Ñ‡∏£‡πà‡∏≤‡∏ß‡πÜ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏¢‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏ô‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡πÉ‡∏ä‡πâ‡πÄ‡∏°‡∏ò‡∏≠‡∏î `Dataset.filter()` ‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠‡πÑ‡∏î‡πâ‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ:

```python
books_dataset = books_dataset.filter(lambda x: len(x["review_title"].split()) > 2)
```

‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ñ‡∏•‡∏±‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡πÅ‡∏•‡πâ‡∏ß ‡πÄ‡∏£‡∏≤‡∏°‡∏≤‡∏î‡∏π‡πÇ‡∏°‡πÄ‡∏î‡∏• Transformer ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ‡∏™‡∏≠‡∏á‡∏™‡∏≤‡∏°‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÑ‡∏î‡πâ!

## ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°[[‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°]]

‡∏´‡∏≤‡∏Å‡∏Ñ‡∏∏‡∏ì‡∏•‡∏≠‡∏á‡∏Ñ‡∏¥‡∏î‡∏î‡∏π ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏á‡∏≤‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå ‡πÄ‡∏£‡∏≤‡∏°‡∏µ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡πà‡∏ô‡∏ö‡∏ó‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ "translate" ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏±‡πâ‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡∏ã‡∏∂‡πà‡∏á‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡πÄ‡∏î‡πà‡∏ô‡∏Ç‡∏≠‡∏á‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï ‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô ‡πÇ‡∏°‡πÄ‡∏î‡∏• Transformer ‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏´‡∏ç‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏∂‡∏á‡πÉ‡∏ä‡πâ‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏°‡∏ï‡∏±‡∏ß‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡∏´‡∏±‡∏™-‡∏ï‡∏±‡∏ß‡∏ñ‡∏≠‡∏î‡∏£‡∏´‡∏±‡∏™‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏û‡∏ö‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å‡πÉ‡∏ô [‡∏ö‡∏ó‡∏ó‡∏µ‡πà 1](/course/th/chapter1) ‡πÅ‡∏°‡πâ‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô‡∏ö‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏£ ‡πÄ‡∏ä‡πà‡∏ô ‡∏ï‡∏£‡∏∞‡∏Å‡∏π‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏• GPT ‡∏ã‡∏∂‡πà‡∏á‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡πÑ‡∏°‡πà‡∏Å‡∏µ‡πà- ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ä‡πá‡∏≠‡∏ï ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏¢‡∏≠‡∏î‡∏ô‡∏¥‡∏¢‡∏°‡∏ö‡∏≤‡∏á‡∏£‡∏∏‡πà‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡πÑ‡∏î‡πâ

| Transformer model | Description                                                                                                                                                                                                    | Multilingual? |
| :---------: | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-----------: |
|    [GPT-2](https://huggingface.co/gpt2-xl)    | Although trained as an auto-regressive language model, you can make GPT-2 generate summaries by appending "TL;DR" at the end of the input text.                                                                          |      ‚ùå       |
|   [PEGASUS](https://huggingface.co/google/pegasus-large)   | Uses a pretraining objective to predict masked sentences in multi-sentence texts. This pretraining objective is closer to summarization than vanilla language modeling and scores highly on popular benchmarks. |      ‚ùå       |
|     [T5](https://huggingface.co/t5-base)      | A universal Transformer architecture that formulates all tasks in a text-to-text framework; e.g., the input format for the model to summarize a document is `summarize: ARTICLE`.                              |      ‚ùå       |
|     [mT5](https://huggingface.co/google/mt5-base)     | A multilingual version of T5, pretrained on the multilingual Common Crawl corpus (mC4), covering 101 languages.                                                                                                |      ‚úÖ       |
|    [BART](https://huggingface.co/facebook/bart-base)     | A novel Transformer architecture with both an encoder and a decoder stack trained to reconstruct corrupted input that combines the pretraining schemes of BERT and GPT-2.                                    |      ‚ùå       |
|  [mBART-50](https://huggingface.co/facebook/mbart-large-50)   | A multilingual version of BART, pretrained on 50 languages.                                                                                                                                                     |      ‚úÖ       |

‡∏î‡∏±‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏´‡πá‡∏ô‡∏à‡∏≤‡∏Å‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ô‡∏µ‡πâ ‡πÇ‡∏°‡πÄ‡∏î‡∏• Transformer ‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏´‡∏ç‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ (‡πÅ‡∏•‡∏∞‡∏á‡∏≤‡∏ô NLP ‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏´‡∏ç‡πà) ‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏ö‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏î‡∏µ‡∏°‡∏≤‡∏Å‡∏´‡∏≤‡∏Å‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ "‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏™‡∏π‡∏á" ‡πÄ‡∏ä‡πà‡∏ô ‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏¢‡∏≠‡∏£‡∏°‡∏±‡∏ô ‡πÅ‡∏ï‡πà‡∏à‡∏∞‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏´‡∏•‡∏≤‡∏¢‡∏û‡∏±‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ó‡∏±‡πà‡∏ß‡πÇ‡∏•‡∏Å ‡πÇ‡∏ä‡∏Ñ‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏£‡∏∏‡πà‡∏ô Transformer ‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤ ‡πÄ‡∏ä‡πà‡∏ô mT5 ‡πÅ‡∏•‡∏∞ mBART ‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠ ‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏≠‡∏ö‡∏£‡∏°‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏†‡∏≤‡∏©‡∏≤ ‡πÅ‡∏ï‡πà‡∏°‡∏µ‡∏à‡∏∏‡∏î‡∏´‡∏±‡∏Å‡∏°‡∏∏‡∏°: ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ù‡∏∂‡∏Å‡∏≠‡∏ö‡∏£‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Ñ‡∏•‡∏±‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏©‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏≠‡∏ö‡∏£‡∏°‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ô‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏ô‡∏Å‡∏ß‡πà‡∏≤ 50 ‡∏†‡∏≤‡∏©‡∏≤‡πÉ‡∏ô‡∏Ñ‡∏£‡∏≤‡∏ß‡πÄ‡∏î‡∏µ‡∏¢‡∏ß!

‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏°‡∏∏‡πà‡∏á‡πÄ‡∏ô‡πâ‡∏ô‡πÑ‡∏õ‡∏ó‡∏µ‡πà mT5 ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏°‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à‡∏ã‡∏∂‡πà‡∏á‡πÉ‡∏ä‡πâ T5 ‡∏ã‡∏∂‡πà‡∏á‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏ù‡∏ô‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏Å‡∏£‡∏≠‡∏ö‡∏á‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÉ‡∏ô T5 ‡∏á‡∏≤‡∏ô NLP ‡∏ó‡∏∏‡∏Å‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÑ‡∏ß‡πâ‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ô‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ó‡πå ‡πÄ‡∏ä‡πà‡∏ô `summarize:` ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ó‡πå ‡∏î‡∏±‡∏á‡πÅ‡∏™‡∏î‡∏á‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á ‡∏™‡∏¥‡πà‡∏á‡∏ô‡∏µ‡πâ‡∏ó‡∏≥‡πÉ‡∏´‡πâ T5 ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏¢‡∏¥‡πà‡∏á ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏á‡∏≤‡∏ô‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏°‡∏≤‡∏Å‡∏°‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏î‡∏µ‡∏¢‡∏ß!

<div class="flex justify-center">
<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/t5.svg" alt="Different tasks performed by the T5 architecture."/>
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/t5-dark.svg" alt="Different tasks performed by the T5 architecture."/>
</div>

mT5 ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏ô‡∏≥‡∏´‡∏ô‡πâ‡∏≤ ‡πÅ‡∏ï‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡πÄ‡∏ô‡∏Å‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ö T5 ‡∏≠‡∏¢‡∏π‡πà‡∏°‡∏≤‡∏Å ‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏î‡∏µ‡∏Ñ‡∏∑‡∏≠‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏û‡∏π‡∏î‡πÑ‡∏î‡πâ‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤ ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á‡πÅ‡∏•‡πâ‡∏ß ‡∏°‡∏≤‡∏î‡∏π‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏≠‡∏ö‡∏£‡∏°‡∏Å‡∏±‡∏ô‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤


<Tip>

‚úèÔ∏è **‡∏•‡∏≠‡∏á‡∏î‡∏π‡∏™‡∏¥!** ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏î‡πâ‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡πÅ‡∏•‡πâ‡∏ß ‡∏°‡∏≤‡∏î‡∏π‡∏Å‡∏±‡∏ô‡∏ß‡πà‡∏≤ mT5 ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö mBART ‡πÑ‡∏î‡πâ‡∏î‡∏µ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÉ‡∏î‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏™‡πà‡∏ß‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÇ‡∏ö‡∏ô‡∏±‡∏™ ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏•‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á T5 ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ö‡∏ó‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡πå‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡πÑ‡∏î‡πâ ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å T5 ‡∏°‡∏µ‡∏û‡∏£‡∏≠‡∏°‡∏ï‡πå‡∏Ñ‡∏≥‡∏ô‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡∏û‡∏¥‡πÄ‡∏®‡∏© ‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ï‡∏¥‡∏° `summarize:` ‡πÑ‡∏ß‡πâ‡∏Ç‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï‡πÉ‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á

</Tip>

## ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤[[‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤]]

<Youtube id="1m7BerpSq8A"/>

‡∏†‡∏≤‡∏£‡∏Å‡∏¥‡∏à‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ó‡πÄ‡∏Ñ‡πá‡∏ô‡πÅ‡∏•‡∏∞‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡∏´‡∏±‡∏™‡∏ö‡∏ó‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡πå‡πÅ‡∏•‡∏∞‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤ ‡∏ï‡∏≤‡∏°‡∏õ‡∏Å‡∏ï‡∏¥ ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏ó‡πÄ‡∏Ñ‡πá‡∏ô‡πÑ‡∏ô‡πÄ‡∏ã‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏à‡∏∏‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤ ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ `mt5-small` ‡πÄ‡∏õ‡πá‡∏ô‡∏à‡∏∏‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏≤‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÉ‡∏ô‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°:

```python
from transformers import AutoTokenizer

model_checkpoint = "google/mt5-small"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)
```

<Tip>

üí° ‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÅ‡∏£‡∏Å‡∏Ç‡∏≠‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£ NLP ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏≠‡∏ö‡∏£‡∏°‡∏Ñ‡∏•‡∏≤‡∏™‡πÇ‡∏°‡πÄ‡∏î‡∏• "small" ‡∏ö‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å ‡∏ã‡∏∂‡πà‡∏á‡∏à‡∏∞‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏à‡∏∏‡∏î‡∏ö‡∏Å‡∏û‡∏£‡πà‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏ã‡πâ‡∏≥‡πÑ‡∏î‡πâ‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô‡πÉ‡∏ô‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏Å‡πÇ‡∏ü‡∏•‡∏ß‡πå‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏ï‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡∏ñ‡∏∂‡∏á‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ñ‡∏∏‡∏ì‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÉ‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÅ‡∏•‡πâ‡∏ß ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ç‡∏¢‡∏≤‡∏¢‡∏Ç‡∏ô‡∏≤‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ‡∏ï‡∏•‡∏≠‡∏î‡πÄ‡∏ß‡∏•‡∏≤‡πÇ‡∏î‡∏¢‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÅ‡∏Ñ‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏à‡∏∏‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•!

</Tip>

‡∏°‡∏≤‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏ó‡πÄ‡∏Ñ‡πá‡∏ô mT5 ‡∏î‡πâ‡∏ß‡∏¢‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏•‡πá‡∏Å‡πÜ ‡∏ô‡πâ‡∏≠‡∏¢‡πÜ:

```python
inputs = tokenizer("I loved reading the Hunger Games!")
inputs
```

```python out
{'input_ids': [336, 259, 28387, 11807, 287, 62893, 295, 12507, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}
```

‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÄ‡∏´‡πá‡∏ô `input_ids` ‡πÅ‡∏•‡∏∞ `attention_mask` ‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡πâ‡∏ô‡πÄ‡∏Ñ‡∏¢‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏£‡∏≤‡∏û‡∏ö‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å‡πÉ‡∏ô [‡∏ö‡∏ó‡∏ó‡∏µ‡πà 3](/course/th/chapter3) ‡∏°‡∏≤‡∏ñ‡∏≠‡∏î‡∏£‡∏´‡∏±‡∏™ ID ‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏î‡πâ‡∏ß‡∏¢‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô `convert_ids_to_tokens()` ‡∏Ç‡∏≠‡∏á‡πÇ‡∏ó‡πÄ‡∏Ñ‡πá‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏ß‡πà‡∏≤‡πÇ‡∏ó‡πÄ‡∏Ñ‡πá‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏±‡∏ö‡∏≠‡∏¢‡∏π‡πà‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÉ‡∏î:

```python
tokenizer.convert_ids_to_tokens(inputs.input_ids)
```

```python out
['‚ñÅI', '‚ñÅ', 'loved', '‚ñÅreading', '‚ñÅthe', '‚ñÅHung', 'er', '‚ñÅGames', '</s>']
```

‡∏≠‡∏±‡∏Å‡∏Ç‡∏£‡∏∞ Unicode ‡∏û‡∏¥‡πÄ‡∏®‡∏© `‚ñÅ` ‡πÅ‡∏•‡∏∞‡πÇ‡∏ó‡πÄ‡∏Ñ‡πá‡∏ô‡∏à‡∏∏‡∏î‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö `</s>` ‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡πà‡∏≤‡πÄ‡∏£‡∏≤‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏±‡∏ö‡πÇ‡∏ó‡πÄ‡∏Ñ‡πá‡∏ô Sentence Piece ‡∏ã‡∏∂‡πà‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏±‡∏ö‡∏≠‡∏±‡∏•‡∏Å‡∏≠‡∏£‡∏¥‡∏ò‡∏∂‡∏°‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡∏™‡πà‡∏ß‡∏ô Unigram ‡∏ó‡∏µ‡πà‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏ñ‡∏∂‡∏á‡πÉ‡∏ô [‡∏ö‡∏ó‡∏ó‡∏µ‡πà 6](/course/th/chapter6 ). Unigram ‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏¢‡∏¥‡πà‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏•‡∏±‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤ ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏ó‡∏≥‡πÉ‡∏´‡πâ Sentence Piece ‡πÑ‡∏°‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏≥‡πÄ‡∏ô‡∏µ‡∏¢‡∏á ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢‡∏ß‡∏£‡∏£‡∏Ñ‡∏ï‡∏≠‡∏ô ‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡πÄ‡∏ó‡πá‡∏à‡∏à‡∏£‡∏¥‡∏á‡∏ó‡∏µ‡πà‡∏ß‡πà‡∏≤‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤ ‡πÄ‡∏ä‡πà‡∏ô ‡∏†‡∏≤‡∏©‡∏≤‡∏ç‡∏µ‡πà‡∏õ‡∏∏‡πà‡∏ô ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏±‡∏Å‡∏Ç‡∏£‡∏∞‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á

‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ó‡πÄ‡∏Ñ‡πá‡∏ô‡∏Ñ‡∏•‡∏±‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤ ‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏±‡∏ö‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏õ‡∏•‡∏µ‡∏Å‡∏¢‡πà‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏õ‡πâ‡∏≤‡∏¢‡∏Å‡∏≥‡∏Å‡∏±‡∏ö‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡πâ‡∏ß‡∏¢ ‡∏à‡∏∂‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà‡∏õ‡πâ‡∏≤‡∏¢‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏Å‡∏¥‡∏ô‡∏Ç‡∏ô‡∏≤‡∏î‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡∏ã‡∏∂‡πà‡∏á‡∏´‡∏°‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ß‡πà‡∏≤‡πÄ‡∏£‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏ó‡∏≠‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏ö‡∏ó‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡πå‡πÅ‡∏•‡∏∞‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÑ‡∏°‡πà‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏¢‡∏≤‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤ ‡πÇ‡∏ó‡πÄ‡∏Ñ‡πá‡∏ô‡πÑ‡∏ô‡πÄ‡∏ã‡∏≠‡∏£‡πå‡πÉ‡∏ô ü§ó Transformers ‡∏°‡∏µ‡∏≠‡∏≤‡∏£‡πå‡∏Å‡∏¥‡∏ß‡πÄ‡∏°‡∏ô‡∏ï‡πå `text_target` ‡∏ó‡∏µ‡πà‡∏î‡∏µ ‡∏ã‡∏∂‡πà‡∏á‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ó‡πÄ‡∏Ñ‡πá‡∏ô‡∏õ‡πâ‡∏≤‡∏¢‡∏Å‡∏≥‡∏Å‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏ô‡∏Å‡∏±‡∏ö‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï‡πÑ‡∏î‡πâ ‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ß‡∏¥‡∏ò‡∏µ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö mT5:

```python
max_input_length = 512
max_target_length = 30


def preprocess_function(examples):
    model_inputs = tokenizer(
        examples["review_body"],
        max_length=max_input_length,
        truncation=True,
    )
    labels = tokenizer(
        examples["review_title"], max_length=max_target_length, truncation=True
    )
    model_inputs["labels"] = labels["input_ids"]
    return model_inputs
```

‡∏°‡∏≤‡∏î‡∏π‡πÇ‡∏Ñ‡πâ‡∏î‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÄ‡∏Å‡∏¥‡∏î‡∏≠‡∏∞‡πÑ‡∏£‡∏Ç‡∏∂‡πâ‡∏ô ‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏ó‡∏≥‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö `max_input_length` ‡πÅ‡∏•‡∏∞ `max_target_length` ‡∏ã‡∏∂‡πà‡∏á‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡πå‡πÅ‡∏•‡∏∞‡∏ä‡∏∑‡πà‡∏≠‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤ ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÇ‡∏î‡∏¢‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ö‡∏ó‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡πå‡∏à‡∏∞‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà‡∏Å‡∏ß‡πà‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏≤‡∏Å ‡πÄ‡∏£‡∏≤‡∏à‡∏∂‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ñ‡πà‡∏≤‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô

‡∏î‡πâ‡∏ß‡∏¢ `preprocess_function()` ‡∏à‡∏∂‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏á‡πà‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ó‡πÄ‡∏Ñ‡πá‡∏ô‡∏Ñ‡∏•‡∏±‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô `Dataset.map()` ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏£‡∏≤‡πÉ‡∏ä‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏ß‡πâ‡∏≤‡∏á‡∏Ç‡∏ß‡∏≤‡∏á‡∏ï‡∏•‡∏≠‡∏î‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£‡∏ô‡∏µ‡πâ:

```python
tokenized_datasets = books_dataset.map(preprocess_function, batched=True)
```

‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡∏±‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏•‡πâ‡∏ß ‡πÄ‡∏£‡∏≤‡∏°‡∏≤‡∏î‡∏π‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏ß‡∏±‡∏î‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ô‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏±‡∏ô ‡∏î‡∏±‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÄ‡∏´‡πá‡∏ô‡πÅ‡∏•‡πâ‡∏ß‡∏ß‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏ß‡∏±‡∏î‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡∏ô‡∏±‡πâ‡∏ô‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡πÄ‡∏•‡∏¢

<Tip>

üí° ‡∏Ñ‡∏∏‡∏ì‡∏≠‡∏≤‡∏à‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤‡πÄ‡∏£‡∏≤‡πÉ‡∏ä‡πâ `batched=True` ‡πÉ‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô `Dataset.map()` ‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡∏´‡∏±‡∏™‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏•‡∏∞ 1,000 ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ (‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô) ‡πÅ‡∏•‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏ö‡∏ö‡∏°‡∏±‡∏•‡∏ï‡∏¥‡πÄ‡∏ò‡∏£‡∏î‡∏Ç‡∏≠‡∏á‡πÇ‡∏ó‡πÄ‡∏Ñ‡πá‡∏ô‡πÑ‡∏ô‡πÄ‡∏ã‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß‡πÉ‡∏ô ü§ó Transformers ‡∏´‡∏≤‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ `batched=True` ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì!

</Tip>


## ‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°[[‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°]]

<Youtube id="TMshhnrEXlg"/>

‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏´‡∏ç‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏ñ‡∏∂‡∏á‡πÉ‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£‡∏ô‡∏µ‡πâ ‡∏Å‡∏≤‡∏£‡∏ß‡∏±‡∏î‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏ô‡∏±‡πâ‡∏ô‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏£‡∏á‡πÑ‡∏õ‡∏ï‡∏£‡∏á‡∏°‡∏≤‡∏°‡∏≤‡∏Å‡∏ô‡∏±‡∏Å ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏ä‡πà‡∏ô ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏ö‡∏ó‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡πå‡πÄ‡∏ä‡πà‡∏ô "‡∏â‡∏±‡∏ô‡∏ä‡∏≠‡∏ö‡∏≠‡πà‡∏≤‡∏ô Hunger Games" ‡∏°‡∏µ‡∏ö‡∏ó‡∏™‡∏£‡∏∏‡∏õ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ ‡πÄ‡∏ä‡πà‡∏ô "‡∏â‡∏±‡∏ô‡∏ä‡∏≠‡∏ö Hunger Games" ‡∏´‡∏£‡∏∑‡∏≠ "Hunger Games ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏≠‡πà‡∏≤‡∏ô" ‡πÄ‡∏´‡πá‡∏ô‡πÑ‡∏î‡πâ‡∏ä‡∏±‡∏î‡∏ß‡πà‡∏≤‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà‡πÅ‡∏ö‡∏ö‡∏ï‡∏£‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ö‡∏ó‡∏™‡∏£‡∏∏‡∏õ‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡∏±‡∏ö‡∏õ‡πâ‡∏≤‡∏¢‡∏Å‡∏≥‡∏Å‡∏±‡∏ö‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏î‡∏µ ‡πÅ‡∏°‡πâ‡πÅ‡∏ï‡πà‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå‡∏Å‡πá‡∏¢‡∏±‡∏á‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏ú‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏î‡∏µ‡∏´‡∏≤‡∏Å‡πÉ‡∏ä‡πâ‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å‡∏î‡∏±‡∏á‡∏Å‡∏•‡πà‡∏≤‡∏ß ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏£‡∏≤‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ô‡∏°‡∏µ‡∏™‡πÑ‡∏ï‡∏•‡πå‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á

‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ ‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ö‡πà‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏£‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏Ñ‡∏∑‡∏≠ [‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô ROUGE](https://en.wikipedia.org/wiki/ROUGE_(metric)) (‡∏¢‡πà‡∏≠‡∏°‡∏≤‡∏à‡∏≤‡∏Å Recall-Oriented Understudy for Gisting Evaling) ‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏á‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏ß‡∏±‡∏î‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏£‡∏∏‡∏õ‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡∏±‡∏ö‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏£‡∏∏‡∏õ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏ó‡∏µ‡πà‡πÇ‡∏î‡∏¢‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡πÅ‡∏•‡πâ‡∏ß‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏¢‡∏¥‡πà‡∏á‡∏Ç‡∏∂‡πâ‡∏ô ‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ß‡πà‡∏≤‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏≠‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:

```python
generated_summary = "I absolutely loved reading the Hunger Games"
reference_summary = "I loved reading the Hunger Games"
```

‡∏ß‡∏¥‡∏ò‡∏µ‡∏´‡∏ô‡∏∂‡πà‡∏á‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ó‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏Å‡∏±‡∏ô ‡∏ã‡∏∂‡πà‡∏á‡πÉ‡∏ô‡∏Å‡∏£‡∏ì‡∏µ‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠ 6 ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡∏Å‡πá‡∏ï‡∏≤‡∏° ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ô‡∏µ‡πâ‡∏Ñ‡πà‡∏≠‡∏ô‡∏Ç‡πâ‡∏≤‡∏á‡∏´‡∏¢‡∏≤‡∏ö ‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô ROUGE ‡∏à‡∏∂‡∏á‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô _precision_ ‡πÅ‡∏•‡∏∞ _recall_ ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡πÅ‡∏ó‡∏ô

<Tip>

üôã ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏á‡∏ß‡∏•‡∏´‡∏≤‡∏Å‡∏ô‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏î‡πâ‡∏¢‡∏¥‡∏ô‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ (precision) ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏à‡∏î‡∏à‡∏≥ (recall) ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏°‡∏±‡∏Å‡∏à‡∏∞‡∏û‡∏ö‡πÉ‡∏ô‡∏á‡∏≤‡∏ô‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó ‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô‡∏´‡∏≤‡∏Å‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏ß‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏à‡∏î‡∏à‡∏≥‡∏ñ‡∏π‡∏Å‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÑ‡∏ß‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ô‡∏±‡πâ‡∏ô ‡πÄ‡∏£‡∏≤‡∏Ç‡∏≠‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö [‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥](https://scikit-learn.org/stable) `scikit-learn` /auto_examples/model_selection/plot_precision_recall.html)

</Tip>

‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ROUGE ‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏Ñ‡∏∑‡∏ô‡∏à‡∏∞‡∏ß‡∏±‡∏î‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏£‡∏∏‡∏õ‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÉ‡∏î ‡∏´‡∏≤‡∏Å‡πÄ‡∏£‡∏≤‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå ‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏™‡∏π‡∏ï‡∏£‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:

$$ \mathrm{Recall} = \frac{\mathrm{Number\,of\,overlapping\, words}}{\mathrm{Total\, number\, of\, words\, in\, reference\, summary}} $$

‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏á‡πà‡∏≤‡∏¢‡πÜ ‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô ‡∏™‡∏π‡∏ï‡∏£‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÑ‡∏î‡πâ‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏∑‡∏≠ 6/6 = 1; ‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏Ñ‡∏∑‡∏≠ ‡∏Ñ‡∏≥‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏£‡∏∏‡∏õ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡πÇ‡∏î‡∏¢‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á ‡∏≠‡∏≤‡∏à‡∏ü‡∏±‡∏á‡∏î‡∏π‡∏î‡∏µ ‡πÅ‡∏ï‡πà‡∏•‡∏≠‡∏á‡∏à‡∏¥‡∏ô‡∏ï‡∏ô‡∏≤‡∏Å‡∏≤‡∏£‡∏î‡∏π‡∏ß‡πà‡∏≤‡∏ö‡∏ó‡∏™‡∏£‡∏∏‡∏õ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡∏Ñ‡∏∑‡∏≠ "‡∏â‡∏±‡∏ô‡∏ä‡∏≠‡∏ö‡∏≠‡πà‡∏≤‡∏ô Hunger Games ‡∏ó‡∏±‡πâ‡∏á‡∏Ñ‡∏∑‡∏ô‡∏à‡∏£‡∏¥‡∏á‡πÜ" ‡∏™‡∏¥‡πà‡∏á‡∏ô‡∏µ‡πâ‡∏ô‡πà‡∏≤‡∏à‡∏∞‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏Ñ‡∏∑‡∏ô‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÅ‡∏ö‡∏ö ‡πÅ‡∏ï‡πà‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏ó‡∏™‡∏£‡∏∏‡∏õ‡∏ó‡∏µ‡πà‡πÅ‡∏¢‡πà‡∏Å‡∏ß‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏°‡∏≤‡∏Å ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏±‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ ‡πÄ‡∏£‡∏≤‡∏¢‡∏±‡∏á‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏î‡πâ‡∏ß‡∏¢ ‡∏ã‡∏∂‡πà‡∏á‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó ROUGE ‡∏à‡∏∞‡∏ß‡∏±‡∏î‡∏ß‡πà‡∏≤‡∏™‡∏£‡∏∏‡∏õ‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏°‡∏≤‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÉ‡∏î:

$$ \mathrm{Precision} = \frac{\mathrm{Number\,of\,overlapping\, words}}{\mathrm{Total\, number\, of\, words\, in\, generated\, summary}} $$

‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏™‡∏¥‡πà‡∏á‡∏ô‡∏µ‡πâ‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏ö‡∏ö‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ 6/10 = 0.6 ‡∏ã‡∏∂‡πà‡∏á‡πÅ‡∏¢‡πà‡∏Å‡∏ß‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏ó‡∏µ‡πà 6/7 = 0.86 ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å‡∏≠‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏±‡πâ‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏≤‡∏Å ‡πÉ‡∏ô‡∏ó‡∏≤‡∏á‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥ ‡∏°‡∏±‡∏Å‡∏à‡∏∞‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ó‡∏±‡πâ‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏Ñ‡∏∑‡∏ô ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡∏à‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô F1 (‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Æ‡∏≤‡∏£‡πå‡∏°‡∏≠‡∏ô‡∏¥‡∏Å‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏Ñ‡∏∑‡∏ô) ‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢‡πÜ ‡πÉ‡∏ô ü§ó ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏û‡πá‡∏Ñ‡πÄ‡∏Å‡∏à `rouge_score` ‡∏Å‡πà‡∏≠‡∏ô:

```py
!pip install rouge_score
```

‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å ROUGE ‡∏î‡∏±‡∏á‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:

```python
import evaluate

rouge_score = evaluate.load("rouge")
```

‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô `rouge_score.compute()` ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏Ñ‡∏£‡∏≤‡∏ß‡πÄ‡∏î‡∏µ‡∏¢‡∏ß:

```python
scores = rouge_score.compute(
    predictions=[generated_summary], references=[reference_summary]
)
scores
```

```python out
{'rouge1': AggregateScore(low=Score(precision=0.86, recall=1.0, fmeasure=0.92), mid=Score(precision=0.86, recall=1.0, fmeasure=0.92), high=Score(precision=0.86, recall=1.0, fmeasure=0.92)),
 'rouge2': AggregateScore(low=Score(precision=0.67, recall=0.8, fmeasure=0.73), mid=Score(precision=0.67, recall=0.8, fmeasure=0.73), high=Score(precision=0.67, recall=0.8, fmeasure=0.73)),
 'rougeL': AggregateScore(low=Score(precision=0.86, recall=1.0, fmeasure=0.92), mid=Score(precision=0.86, recall=1.0, fmeasure=0.92), high=Score(precision=0.86, recall=1.0, fmeasure=0.92)),
 'rougeLsum': AggregateScore(low=Score(precision=0.86, recall=1.0, fmeasure=0.92), mid=Score(precision=0.86, recall=1.0, fmeasure=0.92), high=Score(precision=0.86, recall=1.0, fmeasure=0.92))}
```

‡πÇ‡∏≠‡πâ ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏≤‡∏Å‡∏°‡∏≤‡∏¢‡πÉ‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ô‡∏±‡πâ‡∏ô ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ô‡∏µ‡πâ‡∏´‡∏°‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ß‡πà‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£ ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡πÅ‡∏£‡∏Å ü§ó Datasets ‡∏à‡∏∞‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ä‡πà‡∏ß‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏±‡πà‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ ‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏Ñ‡∏∑‡∏ô ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô F1 ‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞ `low`, `mid`, ‡πÅ‡∏•‡∏∞ `high` ‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏´‡πá‡∏ô‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà ‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ô‡∏µ‡πâ ü§ó Datasets ‡∏¢‡∏±‡∏á‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô ROUGE ‡∏ó‡∏µ‡πà‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢ ‡∏ã‡∏∂‡πà‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ú‡∏•‡∏™‡∏£‡∏∏‡∏õ‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏ú‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö `rouge1` ‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ó‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏Ç‡∏≠‡∏á‡∏¢‡∏π‡∏ô‡∏¥‡πÅ‡∏Å‡∏£‡∏° ‡∏ô‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà‡∏´‡∏£‡∏π‡∏´‡∏£‡∏≤‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥ ‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏ô‡πà‡∏ß‡∏¢‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏ñ‡∏∂‡∏á‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏Å‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏£ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏™‡∏¥‡πà‡∏á‡∏ô‡∏µ‡πâ ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤ `mid` ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏≠‡∏≠‡∏Å‡∏°‡∏≤:

```python
scores["rouge1"].mid
```

```python out
Score(precision=0.86, recall=1.0, fmeasure=0.92)
```

‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°‡∏°‡∏≤‡∏Å ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏à‡∏î‡∏à‡∏≥‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô! ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô ROUGE ‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô‡∏•‡πà‡∏∞? `rouge2` ‡∏ß‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ö‡∏¥‡πä‡∏Å‡πÅ‡∏Å‡∏£‡∏° (‡∏•‡∏≠‡∏á‡∏ô‡∏∂‡∏Å‡∏ñ‡∏∂‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏π‡πà‡∏Ñ‡∏≥) ‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ó‡∏µ‡πà `rougeL` ‡πÅ‡∏•‡∏∞ `rougeLsum` ‡∏ß‡∏±‡∏î‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà‡∏ó‡∏µ‡πà‡∏¢‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏™‡∏ï‡∏£‡∏¥‡∏á‡∏¢‡πà‡∏≠‡∏¢‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡∏¢‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏£‡∏∏‡∏õ‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á "‡∏ú‡∏•‡∏£‡∏ß‡∏°" ‡πÉ‡∏ô `rougeLsum` ‡∏´‡∏°‡∏≤‡∏¢‡∏ñ‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡πÄ‡∏ó‡πá‡∏à‡∏à‡∏£‡∏¥‡∏á‡∏ó‡∏µ‡πà‡∏ß‡πà‡∏≤‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å‡∏ô‡∏µ‡πâ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏≤‡∏Å‡∏ú‡∏•‡∏™‡∏£‡∏∏‡∏õ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ó‡∏µ‡πà `rougeL` ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ

<Tip>

‚úèÔ∏è **‡∏•‡∏≠‡∏á‡∏î‡∏π‡∏™‡∏¥!** ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á ‡πÅ‡∏•‡∏∞‡∏î‡∏π‡∏ß‡πà‡∏≤‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô ROUGE ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏ô‡∏±‡πâ‡∏ô‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏î‡πâ‡∏ß‡∏¢‡∏ï‡∏ô‡πÄ‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏™‡∏π‡∏ï‡∏£‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏à‡∏î‡∏à‡∏≥‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÇ‡∏ö‡∏ô‡∏±‡∏™ ‡πÉ‡∏´‡πâ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏¥‡πä‡∏Å‡πÅ‡∏Å‡∏£‡∏°‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏à‡∏î‡∏à‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å `rouge2`

</Tip>

‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô ROUGE ‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤ ‡πÅ‡∏ï‡πà‡∏Å‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ó‡∏≥‡πÄ‡∏ä‡πà‡∏ô‡∏ô‡∏±‡πâ‡∏ô ‡πÄ‡∏£‡∏≤‡∏°‡∏≤‡∏ó‡∏≥‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏á‡∏≤‡∏ô NLP ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ô‡∏Ñ‡∏ß‡∏£‡∏ó‡∏≥: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ê‡∏≤‡∏ô (baseline) ‡∏ó‡∏µ‡πà‡πÅ‡∏Ç‡πá‡∏á‡πÅ‡∏Å‡∏£‡πà‡∏á‡πÅ‡∏ï‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏á‡πà‡∏≤‡∏¢!

### ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏Ç‡πá‡∏á‡πÅ‡∏Å‡∏£‡πà‡∏á[[‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏Ç‡πá‡∏á‡πÅ‡∏Å‡∏£‡πà‡∏á]]

‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ê‡∏≤‡∏ô‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏™‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÅ‡∏£‡∏Å‡∏Ç‡∏≠‡∏á‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏° ‡∏ã‡∏∂‡πà‡∏á‡∏°‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ß‡πà‡∏≤‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ê‡∏≤‡∏ô _lead-3_ ‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏à‡∏∏‡∏î‡∏´‡∏¢‡∏∏‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏Ç‡∏≠‡∏ö‡πÄ‡∏Ç‡∏ï‡∏Ç‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÑ‡∏î‡πâ ‡πÅ‡∏ï‡πà‡∏à‡∏∞‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡∏¢‡πà‡∏≠‡πÄ‡∏ä‡πà‡∏ô "U.S." ‡∏´‡∏£‡∏∑‡∏≠ "U.N." -- ‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ `nltk` ‡πÅ‡∏ó‡∏ô ‡∏ã‡∏∂‡πà‡∏á‡∏°‡∏µ‡∏≠‡∏±‡∏•‡∏Å‡∏≠‡∏£‡∏¥‡∏ò‡∏∂‡∏°‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏ì‡∏µ‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏û‡πá‡∏Ñ‡πÄ‡∏Å‡∏à‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ `pip` ‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ:

```python
!pip install nltk
```

‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏Å‡∏é‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢‡∏ß‡∏£‡∏£‡∏Ñ‡∏ï‡∏≠‡∏ô:

```python
import nltk

nltk.download("punkt")
```

‡∏ï‡πà‡∏≠‡πÑ‡∏õ ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤ tokenizer ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏à‡∏≤‡∏Å `nltk` ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏á‡πà‡∏≤‡∏¢‡πÜ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏¢‡∏Å‡∏™‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÅ‡∏£‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏ö‡∏ó‡∏ß‡∏ô ‡πÅ‡∏ö‡∏ö‡πÅ‡∏ú‡∏ô‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡∏£‡∏∏‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡∏∂‡πâ‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÉ‡∏´‡∏°‡πà ‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô‡πÄ‡∏£‡∏≤‡∏°‡∏≤‡∏£‡∏ß‡∏°‡∏™‡∏¥‡πà‡∏á‡∏ô‡∏µ‡πâ‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏≠‡∏ö‡∏£‡∏°:

```python
from nltk.tokenize import sent_tokenize


def three_sentence_summary(text):
    return "\n".join(sent_tokenize(text)[:3])


print(three_sentence_summary(books_dataset["train"][1]["review_body"]))
```

```python out
'I grew up reading Koontz, and years ago, I stopped,convinced i had "outgrown" him.'
'Still,when a friend was looking for something suspenseful too read, I suggested Koontz.'
'She found Strangers.'
```

‡∏î‡∏π‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÑ‡∏î‡πâ‡∏ú‡∏• ‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏°‡∏≤‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏¢‡∏Å "summaries" ‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏à‡∏≤‡∏Å‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô ROUGE ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô:

```python
def evaluate_baseline(dataset, metric):
    summaries = [three_sentence_summary(text) for text in dataset["review_body"]]
    return metric.compute(predictions=summaries, references=dataset["review_title"])
```

‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô ROUGE ‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏ä‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á ‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏™‡∏ß‡∏¢‡∏á‡∏≤‡∏°‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Pandas:

```python
import pandas as pd

score = evaluate_baseline(books_dataset["validation"], rouge_score)
rouge_names = ["rouge1", "rouge2", "rougeL", "rougeLsum"]
rouge_dict = dict((rn, round(score[rn].mid.fmeasure * 100, 2)) for rn in rouge_names)
rouge_dict
```

```python out
{'rouge1': 16.74, 'rouge2': 8.83, 'rougeL': 15.6, 'rougeLsum': 15.96}
```

‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÄ‡∏´‡πá‡∏ô‡πÑ‡∏î‡πâ‡∏ß‡πà‡∏≤‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô `rouge2` ‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏≤‡∏Å ‡∏™‡∏¥‡πà‡∏á‡∏ô‡∏µ‡πâ‡∏ô‡πà‡∏≤‡∏à‡∏∞‡∏™‡∏∞‡∏ó‡πâ‡∏≠‡∏ô‡∏ñ‡∏∂‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏£‡∏¥‡∏á‡∏ó‡∏µ‡πà‡∏ß‡πà‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏ó‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡πå‡∏°‡∏±‡∏Å‡∏à‡∏∞‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á Lead-3 ‡∏à‡∏∂‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏°‡∏µ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏î‡∏µ‡πÅ‡∏•‡πâ‡∏ß ‡πÄ‡∏£‡∏≤‡∏°‡∏≤‡∏°‡∏∏‡πà‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ô‡πÉ‡∏à‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á mT5 ‡∏Å‡∏±‡∏ô‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤!

{#if fw === 'pt'}

## ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á mT5 ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏î‡πâ‡∏ß‡∏¢ `Trainer` API[[‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á-mT5-‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏î‡πâ‡∏ß‡∏¢-trainer-api]]

‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏∞‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏ñ‡∏∂‡∏á‡πÉ‡∏ô‡∏ö‡∏ó‡∏ô‡∏µ‡πâ‡∏°‡∏≤‡∏Å ‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡∏Ñ‡∏∑‡∏≠‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡∏à‡∏∏‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö `mt5-small` ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏õ‡πá‡∏ô‡∏á‡∏≤‡∏ô‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö ‡πÄ‡∏£‡∏≤‡∏à‡∏∂‡∏á‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏•‡∏≤‡∏™ `AutoModelForSeq2SeqLM` ‡∏ã‡∏∂‡πà‡∏á‡∏à‡∏∞‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡πÅ‡∏Ñ‡∏ä‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÇ‡∏î‡∏¢‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥:

```python
from transformers import AutoModelForSeq2SeqLM

model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)
```

{:else}

## ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á mT5 ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏î‡πâ‡∏ß‡∏¢ Keras[[‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á-mt5-‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏î‡πâ‡∏ß‡∏¢-keras]]

‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏∞‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏ñ‡∏∂‡∏á‡πÉ‡∏ô‡∏ö‡∏ó‡∏ô‡∏µ‡πâ‡∏°‡∏≤‡∏Å ‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡∏Ñ‡∏∑‡∏≠‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡∏à‡∏∏‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö `mt5-small` ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏õ‡πá‡∏ô‡∏á‡∏≤‡∏ô‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö ‡πÄ‡∏£‡∏≤‡∏à‡∏∂‡∏á‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏•‡∏≤‡∏™ `TFAutoModelForSeq2SeqLM` ‡∏ã‡∏∂‡πà‡∏á‡∏à‡∏∞‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡πÅ‡∏Ñ‡∏ä‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÇ‡∏î‡∏¢‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥:

```python
from transformers import TFAutoModelForSeq2SeqLM

model = TFAutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)
```

{/if}

<Tip>

üí° ‡∏´‡∏≤‡∏Å‡∏Ñ‡∏∏‡∏ì‡∏™‡∏á‡∏™‡∏±‡∏¢‡∏ß‡πà‡∏≤‡πÄ‡∏´‡∏ï‡∏∏‡πÉ‡∏î‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏°‡πà‡πÄ‡∏´‡πá‡∏ô‡∏Ñ‡∏≥‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡πÉ‡∏î‡πÜ ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏ô‡∏á‡∏≤‡∏ô‡∏î‡∏≤‡∏ß‡∏ô‡πå‡∏™‡∏ï‡∏£‡∏µ‡∏° ‡∏ô‡∏±‡πà‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ß‡πà‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ï‡πà‡∏≠‡∏•‡∏≥‡∏î‡∏±‡∏ö ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÄ‡∏Å‡πá‡∏ö‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Ç‡∏≠‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡∏≠‡∏Ç‡πà‡∏≤‡∏¢‡πÑ‡∏ß‡πâ ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏™‡∏¥‡πà‡∏á‡∏ô‡∏µ‡πâ‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡πÉ‡∏ô [‡∏ö‡∏ó‡∏ó‡∏µ‡πà 3](/course/th/chapter3) ‡πÇ‡∏î‡∏¢‡∏ó‡∏µ‡πà‡∏™‡πà‡∏ß‡∏ô‡∏´‡∏±‡∏ß‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ù‡∏∂‡∏Å‡πÑ‡∏ß‡πâ‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏ñ‡∏π‡∏Å‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏Ñ‡∏£‡∏∑‡∏≠‡∏Ç‡πà‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÅ‡∏ö‡∏ö‡∏™‡∏∏‡πà‡∏°

</Tip>

‡∏™‡∏¥‡πà‡∏á‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡∏Ñ‡∏∑‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö Hugging Face Hub ‡∏´‡∏≤‡∏Å‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏ä‡πâ‡πÇ‡∏Ñ‡πâ‡∏î‡∏ô‡∏µ‡πâ‡πÉ‡∏ô‡πÇ‡∏ô‡πâ‡∏ï‡∏ö‡∏∏‡πä‡∏Å ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏¢‡∏π‡∏ó‡∏¥‡∏•‡∏¥‡∏ï‡∏µ‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:

```python
from huggingface_hub import notebook_login

notebook_login()
```

‡∏ã‡∏∂‡πà‡∏á‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏ß‡∏¥‡∏î‡πÄ‡∏à‡πá‡∏ï‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡πâ‡∏≠‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏±‡∏ö‡∏£‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏î‡πâ ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏±‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ô‡∏µ‡πâ‡πÉ‡∏ô‡πÄ‡∏ó‡∏≠‡∏£‡πå‡∏°‡∏¥‡∏ô‡∏±‡∏•‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÅ‡∏•‡∏∞‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏ô‡∏±‡πà‡∏ô:

```
huggingface-cli login
```

{#if fw === 'pt'}

‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô ROUGE ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏≠‡∏ö‡∏£‡∏° ‡πÇ‡∏ä‡∏Ñ‡∏î‡∏µ‡∏ó‡∏µ‡πà ü§ó Transformers ‡∏°‡∏µ‡∏Ñ‡∏•‡∏≤‡∏™ `Seq2SeqTrainingArguments` ‡πÅ‡∏•‡∏∞ `Seq2SeqTrainer` ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡∏™‡∏¥‡πà‡∏á‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥! ‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏î‡∏π‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô ‡∏Ç‡∏±‡πâ‡∏ô‡πÅ‡∏£‡∏Å‡πÄ‡∏£‡∏≤‡∏°‡∏≤‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÑ‡∏Æ‡πÄ‡∏õ‡∏≠‡∏£‡πå‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡πÇ‡∏ï‡πâ‡πÅ‡∏¢‡πâ‡∏á‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏Å‡∏±‡∏ô‡∏Å‡πà‡∏≠‡∏ô:

```python
from transformers import Seq2SeqTrainingArguments

batch_size = 8
num_train_epochs = 8
# Show the training loss with every epoch
logging_steps = len(tokenized_datasets["train"]) // batch_size
model_name = model_checkpoint.split("/")[-1]

args = Seq2SeqTrainingArguments(
    output_dir=f"{model_name}-finetuned-amazon-en-es",
    evaluation_strategy="epoch",
    learning_rate=5.6e-5,
    per_device_train_batch_size=batch_size,
    per_device_eval_batch_size=batch_size,
    weight_decay=0.01,
    save_total_limit=3,
    num_train_epochs=num_train_epochs,
    predict_with_generate=True,
    logging_steps=logging_steps,
    push_to_hub=True,
)
```

‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πâ ‡∏≠‡∏≤‡∏£‡πå‡∏Å‡∏¥‡∏ß‡πÄ‡∏°‡∏ô‡∏ï‡πå `predict_with_generate` ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡πà‡∏≤‡πÄ‡∏£‡∏≤‡∏Ñ‡∏ß‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ö‡∏ó‡∏™‡∏£‡∏∏‡∏õ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô ROUGE ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏¢‡∏∏‡∏Ñ‡πÑ‡∏î‡πâ ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Å‡∏•‡πà‡∏≤‡∏ß‡πÑ‡∏ß‡πâ‡πÉ‡∏ô [‡∏ö‡∏ó‡∏ó‡∏µ‡πà 1](/course/th/chapter1) ‡∏ï‡∏±‡∏ß‡∏ñ‡∏≠‡∏î‡∏£‡∏´‡∏±‡∏™‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏≠‡∏ô‡∏∏‡∏°‡∏≤‡∏ô‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÇ‡∏ó‡πÄ‡∏Ñ‡πá‡∏ô‡∏ó‡∏µ‡∏•‡∏∞‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ ‡πÅ‡∏•‡∏∞‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡πÄ‡∏°‡∏ò‡∏≠‡∏î `generate()` ‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ `predict_with_generate=True` ‡∏à‡∏∞‡∏ö‡∏≠‡∏Å `Seq2SeqTrainer` ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ô‡∏±‡πâ‡∏ô‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô ‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏î‡πâ‡∏õ‡∏£‡∏±‡∏ö‡πÑ‡∏Æ‡πÄ‡∏õ‡∏≠‡∏£‡πå‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô‡∏î‡πâ‡∏ß‡∏¢ ‡πÄ‡∏ä‡πà‡∏ô ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏¢‡∏∏‡∏Ñ ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏•‡∏î‡∏•‡∏á‡∏Ç‡∏≠‡∏á‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å ‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å `save_total_limit` ‡πÉ‡∏´‡πâ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏à‡∏∏‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏î‡πâ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 3 ‡∏à‡∏∏‡∏î‡πÉ‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡∏ó‡∏±‡πâ‡∏á‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÅ‡∏°‡πâ‡πÅ‡∏ï‡πà mT5 ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô "small" ‡πÉ‡∏ä‡πâ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏Æ‡∏≤‡∏£‡πå‡∏î‡πÑ‡∏î‡∏£‡∏ü‡πå‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì GB ‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏≥‡πÄ‡∏ô‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å

‡∏≠‡∏≤‡∏£‡πå‡∏Å‡∏¥‡∏ß‡πÄ‡∏°‡∏ô‡∏ï‡πå `push_to_hub=True` ‡∏à‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ú‡∏•‡∏±‡∏Å‡∏î‡∏±‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏õ‡∏ó‡∏µ‡πà Hub ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏≠‡∏ö‡∏£‡∏° ‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡∏û‡∏ö‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ï‡πâ‡πÇ‡∏õ‡∏£‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏ô‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÇ‡∏î‡∏¢ `output_dir` ‡πÇ‡∏õ‡∏£‡∏î‡∏ó‡∏£‡∏≤‡∏ö‡∏ß‡πà‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠‡∏Ç‡∏≠‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏û‡∏∏‡∏ä‡πÑ‡∏õ‡πÑ‡∏î‡πâ‡∏î‡πâ‡∏ß‡∏¢‡∏≠‡∏≤‡∏£‡πå‡∏Å‡∏¥‡∏ß‡πÄ‡∏°‡∏ô‡∏ï‡πå `hub_model_id` (‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞ ‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏≠‡∏≤‡∏£‡πå‡∏Å‡∏¥‡∏ß‡πÄ‡∏°‡∏ô‡∏ï‡πå‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏û‡∏∏‡∏ä‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£) ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏ä‡πà‡∏ô ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏≤‡∏ú‡∏•‡∏±‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏õ‡∏ó‡∏µ‡πà [`huggingface-course` Organization](https://huggingface.co/huggingface-course) ‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡πÄ‡∏û‡∏¥‡πà‡∏° `hub_model_id="huggingface-course/mt5-finetuned-amazon-en- es"` ‡∏ñ‡∏∂‡∏á `Seq2SeqTrainingArguments`

‡∏™‡∏¥‡πà‡∏á‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡∏Ñ‡∏∑‡∏≠‡∏à‡∏±‡∏î‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô `compute_metrics()` ‡πÉ‡∏´‡πâ‡∏Å‡∏±‡∏ö‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏ô‡∏≠‡∏£‡πå ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÑ‡∏î‡πâ ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ ‡∏™‡∏¥‡πà‡∏á‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å `rouge_score.compute()` ‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏£‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á _decode_ ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÅ‡∏•‡∏∞‡∏õ‡πâ‡∏≤‡∏¢‡∏Å‡∏≥‡∏Å‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡πà‡∏≠‡∏ô‡∏à‡∏∂‡∏á‡∏à‡∏∞‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô ROUGE ‡πÑ‡∏î‡πâ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡∏ó‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏î‡∏±‡∏á‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏ó‡∏∏‡∏Å‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏£ ‡πÅ‡∏•‡∏∞‡∏¢‡∏±‡∏á‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô `sent_tokenize()` ‡∏à‡∏≤‡∏Å `nltk` ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏¢‡∏Å‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏™‡∏£‡∏∏‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡∏∂‡πâ‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÉ‡∏´‡∏°‡πà:

```python
import numpy as np


def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    # Decode generated summaries into text
    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)
    # Replace -100 in the labels as we can't decode them
    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)
    # Decode reference summaries into text
    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)
    # ROUGE expects a newline after each sentence
    decoded_preds = ["\n".join(sent_tokenize(pred.strip())) for pred in decoded_preds]
    decoded_labels = ["\n".join(sent_tokenize(label.strip())) for label in decoded_labels]
    # Compute ROUGE scores
    result = rouge_score.compute(
        predictions=decoded_preds, references=decoded_labels, use_stemmer=True
    )
    # Extract the median scores
    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}
    return {k: round(v, 4) for k, v in result.items()}
```

{/if}

‡∏ï‡πà‡∏≠‡πÑ‡∏õ ‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ï‡∏±‡∏ß‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ï‡πà‡∏≠‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤ ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å mT5 ‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• Transformer ‡∏ï‡∏±‡∏ß‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡∏´‡∏±‡∏™-‡∏ï‡∏±‡∏ß‡∏ñ‡∏≠‡∏î‡∏£‡∏´‡∏±‡∏™ (encoder-decoder) ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏≠‡πà‡∏≠‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏´‡∏ô‡∏∂‡πà‡∏á‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÅ‡∏ö‡∏ó‡∏ä‡πå‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏Å‡πá‡∏Ñ‡∏∑‡∏≠‡πÉ‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ñ‡∏≠‡∏î‡∏£‡∏´‡∏±‡∏™ ‡πÄ‡∏£‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏õ‡πâ‡∏≤‡∏¢‡∏Å‡∏≥‡∏Å‡∏±‡∏ö‡πÑ‡∏õ‡∏ó‡∏≤‡∏á‡∏Ç‡∏ß‡∏≤‡∏ó‡∏µ‡∏•‡∏∞‡∏õ‡πâ‡∏≤‡∏¢ ‡∏™‡∏¥‡πà‡∏á‡∏ô‡∏µ‡πâ‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡∏ï‡∏±‡∏ß‡∏ñ‡∏≠‡∏î‡∏£‡∏´‡∏±‡∏™‡∏à‡∏∞‡πÄ‡∏´‡πá‡∏ô‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏õ‡πâ‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏£‡∏¥‡∏á‡∏†‡∏≤‡∏Ñ‡∏û‡∏∑‡πâ‡∏ô‡∏î‡∏¥‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏õ‡πâ‡∏≤‡∏¢‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï ‡∏ã‡∏∂‡πà‡∏á‡∏à‡∏∞‡∏á‡πà‡∏≤‡∏¢‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏à‡∏î‡∏à‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á ‡∏™‡∏¥‡πà‡∏á‡∏ô‡∏µ‡πâ‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏≠‡∏≤‡πÅ‡∏ï‡πà‡∏™‡∏ô‡πÉ‡∏à‡∏ï‡∏ô‡πÄ‡∏≠‡∏á‡∏°‡∏≤‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï‡πÉ‡∏ô‡∏á‡∏≤‡∏ô ‡πÄ‡∏ä‡πà‡∏ô [‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏†‡∏≤‡∏©‡∏≤‡πÄ‡∏ä‡∏¥‡∏á‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏](/course/th/chapter7/6)

‡πÇ‡∏ä‡∏Ñ‡∏î‡∏µ‡∏ó‡∏µ‡πà ü§ó Transformers ‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö `DataCollatorForSeq2Seq` ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÅ‡∏û‡∏î‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï‡πÅ‡∏•‡∏∞‡∏õ‡πâ‡∏≤‡∏¢‡∏Å‡∏≥‡∏Å‡∏±‡∏ö‡πÅ‡∏ö‡∏ö‡πÑ‡∏î‡∏ô‡∏≤‡∏°‡∏¥‡∏Å‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏≤ ‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á collator ‡∏ô‡∏µ‡πâ ‡πÄ‡∏£‡∏≤‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÅ‡∏Ñ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏à‡∏±‡∏î‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° `tokenizer` ‡πÅ‡∏•‡∏∞ `model`:

{#if fw === 'pt'}

```python
from transformers import DataCollatorForSeq2Seq

data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)
```

{:else}

```python
from transformers import DataCollatorForSeq2Seq

data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors="tf")
```

{/if}

‡∏°‡∏≤‡∏î‡∏π‡∏Å‡∏±‡∏ô‡∏ß‡πà‡∏≤‡∏ï‡∏±‡∏ß‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ô‡∏µ‡πâ‡∏ú‡∏•‡∏¥‡∏ï‡∏≠‡∏∞‡πÑ‡∏£‡πÑ‡∏î‡πâ‡∏ö‡πâ‡∏≤‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏∏‡∏î‡πÄ‡∏•‡πá‡∏Å‡πÜ ‡∏Ç‡∏±‡πâ‡∏ô‡πÅ‡∏£‡∏Å ‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏•‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏™‡∏ï‡∏£‡∏¥‡∏á‡∏≠‡∏≠‡∏Å ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏ï‡∏±‡∏ß‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÑ‡∏°‡πà‡∏ó‡∏£‡∏≤‡∏ö‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏û‡∏î‡∏≠‡∏á‡∏Ñ‡πå‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ:

```python
tokenized_datasets = tokenized_datasets.remove_columns(
    books_dataset["train"].column_names
)
```

‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ `dict`s ‡πÇ‡∏î‡∏¢‡∏ó‡∏µ‡πà `dict` ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ñ‡∏∂‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÉ‡∏ô‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÄ‡∏£‡∏≤‡∏à‡∏∂‡∏á‡∏ï‡πâ‡∏≠‡∏á‡πÇ‡∏ï‡πâ‡πÅ‡∏¢‡πâ‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á‡∏Å‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏™‡πà‡∏á‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:

```python
features = [tokenized_datasets["train"][i] for i in range(2)]
data_collator(features)
```

```python out
{'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'input_ids': tensor([[  1494,    259,   8622,    390,    259,    262,   2316,   3435,    955,
            772,    281,    772,   1617,    263,    305,  14701,    260,   1385,
           3031,    259,  24146,    332,   1037,    259,  43906,    305,    336,
            260,      1,      0,      0,      0,      0,      0,      0],
        [   259,  27531,  13483,    259,   7505,    260, 112240,  15192,    305,
          53198,    276,    259,  74060,    263,    260,    459,  25640,    776,
           2119,    336,    259,   2220,    259,  18896,    288,   4906,    288,
           1037,   3931,    260,   7083, 101476,   1143,    260,      1]]), 'labels': tensor([[ 7483,   259,  2364, 15695,     1,  -100],
        [  259, 27531, 13483,   259,  7505,     1]]), 'decoder_input_ids': tensor([[    0,  7483,   259,  2364, 15695,     1],
        [    0,   259, 27531, 13483,   259,  7505]])}
```

‡∏™‡∏¥‡πà‡∏á‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏£‡∏Å‡∏¢‡∏≤‡∏ß‡∏Å‡∏ß‡πà‡∏≤‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á ‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô `input_ids` ‡πÅ‡∏•‡∏∞ `attention_mask` ‡∏Ç‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á‡∏à‡∏∂‡∏á‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏™‡∏£‡∏¥‡∏°‡πÑ‡∏ß‡πâ‡∏ó‡∏≤‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏Ç‡∏ß‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏ó‡πÄ‡∏Ñ‡πá‡∏ô `[PAD]` (‡∏ã‡∏∂‡πà‡∏á‡∏°‡∏µ ID ‡πÄ‡∏õ‡πá‡∏ô ` 0`) ‡πÉ‡∏ô‡∏ó‡∏≥‡∏ô‡∏≠‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤ `labels` ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏™‡∏£‡∏¥‡∏°‡∏î‡πâ‡∏ß‡∏¢ `-100`s ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÇ‡∏ó‡πÄ‡∏Ñ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏™‡∏£‡∏¥‡∏°‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏•‡∏∞‡πÄ‡∏ß‡πâ‡∏ô‡πÇ‡∏î‡∏¢‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏π‡∏ç‡πÄ‡∏™‡∏µ‡∏¢ ‡πÅ‡∏•‡∏∞‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÄ‡∏´‡πá‡∏ô `decoder_input_ids` ‡πÉ‡∏´‡∏°‡πà ‡∏ã‡∏∂‡πà‡∏á‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏õ‡πâ‡∏≤‡∏¢‡∏Å‡∏≥‡∏Å‡∏±‡∏ö‡πÑ‡∏õ‡∏ó‡∏≤‡∏á‡∏Ç‡∏ß‡∏≤‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏™‡πà‡πÇ‡∏ó‡πÄ‡∏Ñ‡πá‡∏ô `[PAD]` ‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÅ‡∏£‡∏Å

{#if fw === 'pt'}

‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÄ‡∏£‡∏≤‡∏Å‡πá‡∏°‡∏µ‡∏™‡πà‡∏ß‡∏ô‡∏ú‡∏™‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÅ‡∏•‡πâ‡∏ß! ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÅ‡∏Ñ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏¢‡∏Å‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ú‡∏π‡πâ‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏≠‡∏≤‡∏£‡πå‡∏Å‡∏¥‡∏ß‡πÄ‡∏°‡∏ô‡∏ï‡πå‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô:

```python
from transformers import Seq2SeqTrainer

trainer = Seq2SeqTrainer(
    model,
    args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
)
```

and launch our training run:

```python
trainer.train()
```

‡πÉ‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å ‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏ß‡∏£‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏™‡∏π‡∏ç‡πÄ‡∏™‡∏µ‡∏¢‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏•‡∏î‡∏•‡∏á‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô ROUGE ‡∏à‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏¢‡∏∏‡∏Ñ ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏≠‡∏ö‡∏£‡∏°‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏π‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô ROUGE ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ `Trainer.evaluate()`:

```python
trainer.evaluate()
```

```python out
{'eval_loss': 3.028524398803711,
 'eval_rouge1': 16.9728,
 'eval_rouge2': 8.2969,
 'eval_rougeL': 16.8366,
 'eval_rougeLsum': 16.851,
 'eval_gen_len': 10.1597,
 'eval_runtime': 6.1054,
 'eval_samples_per_second': 38.982,
 'eval_steps_per_second': 4.914}
```

‡∏à‡∏≤‡∏Å‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô lead-3 ‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ñ‡∏•‡πà‡∏≠‡∏á‡πÅ‡∏Ñ‡∏•‡πà‡∏ß ‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°‡∏°‡∏≤‡∏Å! ‡∏™‡∏¥‡πà‡∏á‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡∏Ñ‡∏∑‡∏≠‡∏î‡∏±‡∏ô‡∏ï‡∏∏‡πâ‡∏°‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡∏Æ‡∏±‡∏ö ‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ:

```
trainer.push_to_hub(commit_message="Training complete", tags="summarization")
```

```python out
'https://huggingface.co/huggingface-course/mt5-finetuned-amazon-en-es/commit/aa0536b829b28e73e1e4b94b8a5aacec420d40e0'
```

‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏à‡∏∏‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå‡∏Å‡∏≤‡∏£‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡πÑ‡∏õ‡∏ó‡∏µ‡πà `output_dir` ‡∏Å‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÑ‡∏õ‡∏¢‡∏±‡∏á Hub ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏£‡∏∞‡∏ö‡∏∏‡∏≠‡∏≤‡∏£‡πå‡∏Å‡∏¥‡∏ß‡πÄ‡∏°‡∏ô‡∏ï‡πå `tags` ‡πÄ‡∏£‡∏≤‡∏¢‡∏±‡∏á‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÑ‡∏î‡πâ‡∏ß‡πà‡∏≤‡∏ß‡∏¥‡∏î‡πÄ‡∏à‡πá‡∏ï‡∏ö‡∏ô Hub ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏±‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÑ‡∏õ‡∏õ‡πå‡πÑ‡∏•‡∏ô‡πå‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡∏Å‡∏±‡∏ö‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏° mT5 (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÅ‡∏ó‡πá‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÇ‡∏õ‡∏£‡∏î‡∏î‡∏π [ü§ó ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö Hub ](https://huggingface.co/docs/hub/main#how-is-a-models-type-of-inference-api-and-widget-determined)) ‡πÄ‡∏≠‡∏≤‡∏ï‡πå‡∏û‡∏∏‡∏ï‡∏à‡∏≤‡∏Å `trainer.push_to_hub()` ‡∏Ñ‡∏∑‡∏≠ URL ‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡∏Ñ‡∏≠‡∏°‡∏°‡∏¥‡∏ï‡πÅ‡∏Æ‡∏ä‡∏Ç‡∏≠‡∏á Git ‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∂‡∏á‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏π‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏á‡πà‡∏≤‡∏¢‡∏î‡∏≤‡∏¢!

‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡∏∏‡∏õ‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ ‡πÄ‡∏£‡∏≤‡∏°‡∏≤‡∏î‡∏π‡∏Å‡∏±‡∏ô‡∏ß‡πà‡∏≤‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á mT5 ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ï‡πà‡∏≥‡∏ó‡∏µ‡πà ü§ó Accelerate ‡∏°‡∏≠‡∏ö‡πÉ‡∏´‡πâ

{:else}

‡πÄ‡∏£‡∏≤‡πÄ‡∏Å‡∏∑‡∏≠‡∏ö‡∏à‡∏∞‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ù‡∏∂‡∏Å‡πÅ‡∏•‡πâ‡∏ß! ‡πÄ‡∏£‡∏≤‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÅ‡∏Ñ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏õ‡∏•‡∏á‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡πÄ‡∏õ‡πá‡∏ô `tf.data.Dataset`s ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÑ‡∏ß‡πâ‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡∏à‡∏∂‡∏á `compile()` ‡πÅ‡∏•‡∏∞ `fit()` ‡πÇ‡∏°‡πÄ‡∏î‡∏•, ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡πÅ‡∏£‡∏Å datasets:

```python
tf_train_dataset = model.prepare_tf_dataset(
    tokenized_datasets["train"],
    collate_fn=data_collator,
    shuffle=True,
    batch_size=8,
)
tf_eval_dataset = model.prepare_tf_dataset(
    tokenized_datasets["validation"],
    collate_fn=data_collator,
    shuffle=False,
    batch_size=8,
)
```

‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ ‡πÄ‡∏£‡∏≤‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÑ‡∏Æ‡πÄ‡∏õ‡∏≠‡∏£‡πå‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏≠‡∏ö‡∏£‡∏°‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≠‡∏°‡πÑ‡∏û‡∏•‡πå:

```python
from transformers import create_optimizer
import tensorflow as tf

# The number of training steps is the number of samples in the dataset, divided by the batch size then multiplied
# by the total number of epochs. Note that the tf_train_dataset here is a batched tf.data.Dataset,
# not the original Hugging Face Dataset, so its len() is already num_samples // batch_size.
num_train_epochs = 8
num_train_steps = len(tf_train_dataset) * num_train_epochs
model_name = model_checkpoint.split("/")[-1]

optimizer, schedule = create_optimizer(
    init_lr=5.6e-5,
    num_warmup_steps=0,
    num_train_steps=num_train_steps,
    weight_decay_rate=0.01,
)

model.compile(optimizer=optimizer)

# Train in mixed-precision float16
tf.keras.mixed_precision.set_global_policy("mixed_float16")
```

‡πÅ‡∏•‡∏∞‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ ‡πÄ‡∏£‡∏≤‡∏Å‡πá‡∏û‡∏≠‡∏î‡∏µ‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÄ‡∏£‡∏≤‡πÉ‡∏ä‡πâ `PushToHubCallback` ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏•‡∏á‡πÉ‡∏ô Hub ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡πÅ‡∏ï‡πà‡∏•‡∏∞ epoch ‡∏ã‡∏∂‡πà‡∏á‡∏à‡∏∞‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏≤‡πÉ‡∏ä‡πâ‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏ô‡∏±‡πâ‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏≠‡∏ô‡∏∏‡∏°‡∏≤‡∏ô‡πÉ‡∏ô‡∏†‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏á:

```python
from transformers.keras_callbacks import PushToHubCallback

callback = PushToHubCallback(
    output_dir=f"{model_name}-finetuned-amazon-en-es", tokenizer=tokenizer
)

model.fit(
    tf_train_dataset, validation_data=tf_eval_dataset, callbacks=[callback], epochs=8
)
```

‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏™‡∏π‡∏ç‡πÄ‡∏™‡∏µ‡∏¢‡πÑ‡∏õ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å ‡πÅ‡∏ï‡πà‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏´‡πá‡∏ô‡∏´‡∏ô‡πà‡∏ß‡∏¢‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å ROUGE ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÑ‡∏ß‡πâ‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ö‡∏´‡∏ô‡πà‡∏ß‡∏¢‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏≠‡∏≤‡∏ï‡πå‡∏û‡∏∏‡∏ï‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏ï‡∏£‡∏¥‡∏á ‡∏°‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏õ‡πâ‡∏≤‡∏¢‡∏Å‡∏≥‡∏Å‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≤‡∏î‡∏Ñ‡∏∞‡πÄ‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å ROUGE ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ô (‡πÇ‡∏õ‡∏£‡∏î‡∏ó‡∏£‡∏≤‡∏ö‡∏ß‡πà‡∏≤‡∏´‡∏≤‡∏Å‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ ‡∏Ñ‡∏∏‡∏ì‡∏≠‡∏≤‡∏à‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏±‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á `!pip install tqdm`) ‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏¢‡∏±‡∏á‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÄ‡∏Ñ‡∏•‡πá‡∏î‡∏•‡∏±‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏≤‡∏Å ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≠‡∏°‡πÑ‡∏û‡∏•‡πå‡πÇ‡∏Ñ‡πâ‡∏î‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏î‡πâ‡∏ß‡∏¢ [XLA](https://www.tensorflow.org/xla) ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≠‡∏°‡πÑ‡∏û‡πÄ‡∏•‡∏≠‡∏£‡πå‡∏û‡∏µ‡∏ä‡∏Ñ‡∏ì‡∏¥‡∏ï‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏™‡πâ‡∏ô‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡πà‡∏á‡∏Ç‡∏≠‡∏á TensorFlow XLA ‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏Å‡∏±‡∏ö‡∏Å‡∏£‡∏≤‡∏ü‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á‡∏ú‡∏•‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏ô‡∏±‡∏¢‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÑ‡∏ß‡πâ‡πÉ‡∏ô Hugging Face [‡∏ö‡∏•‡πá‡∏≠‡∏Å](https://huggingface.co/blog/tf-xla-generate) XLA ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏£‡∏π‡∏õ‡∏£‡πà‡∏≤‡∏á‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡πÑ‡∏°‡πà‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏°‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏™‡∏¥‡πà‡∏á‡∏ô‡∏µ‡πâ ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÅ‡∏û‡∏î‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏ß‡∏µ‡∏Ñ‡∏π‡∏ì‡∏Ç‡∏≠‡∏á 128 ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡∏î‡πâ‡∏ß‡∏¢‡∏ï‡∏±‡∏ß‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏î ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ decorator `@tf.function(jit_compile=True)` ‡∏Å‡∏±‡∏ö‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤ ‡∏ã‡∏∂‡πà‡∏á ‡∏ó‡∏≥‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≠‡∏°‡πÑ‡∏û‡∏•‡πå‡∏î‡πâ‡∏ß‡∏¢ XLA

```python
from tqdm import tqdm
import numpy as np

generation_data_collator = DataCollatorForSeq2Seq(
    tokenizer, model=model, return_tensors="tf", pad_to_multiple_of=320
)

tf_generate_dataset = model.prepare_tf_dataset(
    tokenized_datasets["validation"],
    collate_fn=generation_data_collator,
    shuffle=False,
    batch_size=8,
    drop_remainder=True,
)


@tf.function(jit_compile=True)
def generate_with_xla(batch):
    return model.generate(
        input_ids=batch["input_ids"],
        attention_mask=batch["attention_mask"],
        max_new_tokens=32,
    )


all_preds = []
all_labels = []
for batch, labels in tqdm(tf_generate_dataset):
    predictions = generate_with_xla(batch)
    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)
    labels = labels.numpy()
    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)
    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)
    decoded_preds = ["\n".join(sent_tokenize(pred.strip())) for pred in decoded_preds]
    decoded_labels = ["\n".join(sent_tokenize(label.strip())) for label in decoded_labels]
    all_preds.extend(decoded_preds)
    all_labels.extend(decoded_labels)
```

‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏≤‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏õ‡πâ‡∏≤‡∏¢‡∏Å‡∏≥‡∏Å‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡∏™‡∏ï‡∏£‡∏¥‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÅ‡∏•‡πâ‡∏ß ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô ROUGE ‡∏Å‡πá‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏á‡πà‡∏≤‡∏¢:

```python
result = rouge_score.compute(
    predictions=decoded_preds, references=decoded_labels, use_stemmer=True
)
result = {key: value.mid.fmeasure * 100 for key, value in result.items()}
{k: round(v, 4) for k, v in result.items()}
```

```
{'rouge1': 31.4815, 'rouge2': 25.4386, 'rougeL': 31.4815, 'rougeLsum': 31.4815}
```


{/if}

{#if fw === 'pt'}

## ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á mT5 ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏î‡πâ‡∏ß‡∏¢ ü§ó Accelerate[[‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á-mT5-‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏î‡πâ‡∏ß‡∏¢-accelerate]]

‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏î‡πâ‡∏ß‡∏¢ ü§ó Accelerate ‡∏ô‡∏±‡πâ‡∏ô‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á‡∏Å‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏û‡∏ö‡πÉ‡∏ô [‡∏ö‡∏ó‡∏ó‡∏µ‡πà 3](/course/th/chapter3) ‡∏°‡∏≤‡∏Å ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ñ‡∏∑‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏£‡∏∏‡∏õ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏≠‡∏ö‡∏£‡∏°‡πÅ‡∏•‡∏∞‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô ROUGE (‡πÇ‡∏õ‡∏£‡∏î‡∏à‡∏≥‡πÑ‡∏ß‡πâ‡∏ß‡πà‡∏≤ `Seq2SeqTrainer` ‡∏î‡∏π‡πÅ‡∏•‡∏£‡∏∏‡πà‡∏ô‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤) ‡∏°‡∏≤‡∏î‡∏π‡∏Å‡∏±‡∏ô‡∏ß‡πà‡∏≤‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏ô‡∏≥‡∏Ç‡πâ‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á‡∏ô‡∏µ‡πâ‡πÑ‡∏õ‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡∏†‡∏≤‡∏¢‡πÉ‡∏ô ü§ó ‡πÄ‡∏£‡πà‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß!

### ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•[[‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•]]

‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡∏Ñ‡∏∑‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á `DataLoader` ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤ ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏ï‡∏±‡∏ß‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PyTorch ‡∏Ñ‡∏≤‡∏î‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏°‡∏µ‡πÄ‡∏ó‡∏ô‡πÄ‡∏ã‡∏≠‡∏£‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∏‡∏î ‡πÄ‡∏£‡∏≤‡∏à‡∏∂‡∏á‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÄ‡∏õ‡πá‡∏ô `"torch"` ‡πÉ‡∏ô‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤:

```python
tokenized_datasets.set_format("torch")
```

‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏°‡∏µ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏ó‡∏ô‡πÄ‡∏ã‡∏≠‡∏£‡πå‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡∏™‡∏¥‡πà‡∏á‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡∏Ñ‡∏∑‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏ô‡∏™‡πÅ‡∏ï‡∏ô‡∏ã‡πå `DataCollatorForSeq2Seq` ‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏¥‡πà‡∏á‡∏ô‡∏µ‡πâ ‡πÄ‡∏£‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏à‡∏±‡∏î‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà ‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô‡∏°‡∏≤‡πÇ‡∏´‡∏•‡∏î‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏à‡∏≤‡∏Å‡πÅ‡∏Ñ‡∏ä‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤:

```python
model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)
```

‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏™‡∏¥‡πà‡∏á‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ï‡∏±‡∏ß‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤:

```python
from torch.utils.data import DataLoader

batch_size = 8
train_dataloader = DataLoader(
    tokenized_datasets["train"],
    shuffle=True,
    collate_fn=data_collator,
    batch_size=batch_size,
)
eval_dataloader = DataLoader(
    tokenized_datasets["validation"], collate_fn=data_collator, batch_size=batch_size
)
```

‡∏™‡∏¥‡πà‡∏á‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ ‡πÄ‡∏ä‡πà‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ `AdamW` ‡∏ã‡∏∂‡πà‡∏á‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Å‡∏±‡∏ö‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏´‡∏ç‡πà:

```python
from torch.optim import AdamW

optimizer = AdamW(model.parameters(), lr=2e-5)
```

‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏ô‡∏µ‡πâ ‡πÄ‡∏£‡∏≤‡∏õ‡πâ‡∏≠‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û ‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏Å‡∏±‡∏ö‡πÄ‡∏°‡∏ò‡∏≠‡∏î `accelerator.prepare()`:

```python
from accelerate import Accelerator

accelerator = Accelerator()
model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(
    model, optimizer, train_dataloader, eval_dataloader
)
```

<Tip>

üö® ‡∏´‡∏≤‡∏Å‡∏Ñ‡∏∏‡∏ì‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ù‡∏∂‡∏Å‡∏ö‡∏ô TPU ‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡∏¢‡πâ‡∏≤‡∏¢‡πÇ‡∏Ñ‡πâ‡∏î‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞ ‡∏î‡∏π [‡∏ö‡∏ó‡∏ó‡∏µ‡πà 3](/course/th/chapter3) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°

</Tip>

‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡πÅ‡∏•‡πâ‡∏ß ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏≠‡∏µ‡∏Å 3 ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥:

* ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ (learning rate schedule)
* ‡∏™‡∏£‡πâ‡πâ‡∏≤‡∏á‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏£‡∏∏‡∏õ‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•
* ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏ô Hub ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ú‡∏•‡∏±‡∏Å‡∏î‡∏±‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡πÑ‡∏õ‡πÑ‡∏î‡πâ

‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏™‡πâ‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏à‡∏≤‡∏Å‡∏™‡πà‡∏ß‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤:

```python
from transformers import get_scheduler

num_train_epochs = 10
num_update_steps_per_epoch = len(train_dataloader)
num_training_steps = num_train_epochs * num_update_steps_per_epoch

lr_scheduler = get_scheduler(
    "linear",
    optimizer=optimizer,
    num_warmup_steps=0,
    num_training_steps=num_training_steps,
)
```

‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• ‡πÄ‡∏£‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏£‡∏∏‡∏õ‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ó‡∏µ‡πà‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡∏∂‡πâ‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÉ‡∏´‡∏°‡πà ‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏´‡∏ô‡πà‡∏ß‡∏¢‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å ROUGE ‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á ‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏Ñ‡πâ‡∏î‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:

```python
def postprocess_text(preds, labels):
    preds = [pred.strip() for pred in preds]
    labels = [label.strip() for label in labels]

    # ROUGE expects a newline after each sentence
    preds = ["\n".join(nltk.sent_tokenize(pred)) for pred in preds]
    labels = ["\n".join(nltk.sent_tokenize(label)) for label in labels]

    return preds, labels
```

‡∏™‡∏¥‡πà‡∏á‡∏ô‡∏µ‡πâ‡∏ô‡πà‡∏≤‡∏à‡∏∞‡∏î‡∏π‡∏Ñ‡∏∏‡πâ‡∏ô‡πÄ‡∏Ñ‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏∏‡∏ì ‡∏´‡∏≤‡∏Å‡∏Ñ‡∏∏‡∏ì‡∏à‡∏≥‡πÑ‡∏î‡πâ‡∏ß‡πà‡∏≤‡πÄ‡∏£‡∏≤‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô `compute_metrics()` ‡∏Ç‡∏≠‡∏á `Seq2SeqTrainer` ‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£

‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ ‡πÄ‡∏£‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏ö‡∏ô Hugging Face Hub ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏¥‡πà‡∏á‡∏ô‡∏µ‡πâ ‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ ü§ó Hub ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡πÑ‡∏î‡πâ ‡πÄ‡∏£‡∏≤‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÅ‡∏Ñ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤ ‡πÅ‡∏•‡∏∞‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏Å‡πá‡∏°‡∏µ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏¢‡∏π‡∏ó‡∏¥‡∏•‡∏¥‡∏ï‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏ß‡∏°‡∏£‡∏´‡∏±‡∏™‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö‡πÇ‡∏õ‡∏£‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ:

```python
from huggingface_hub import get_full_repo_name

model_name = "test-bert-finetuned-squad-accelerate"
repo_name = get_full_repo_name(model_name)
repo_name
```

```python out
'lewtun/mt5-finetuned-amazon-en-es-accelerate'
```

‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÇ‡∏Ñ‡∏•‡∏ô‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡πÉ‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÑ‡∏î‡πÄ‡∏£‡πá‡∏Å‡∏ó‡∏≠‡∏£‡∏µ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏ã‡∏∂‡πà‡∏á‡∏à‡∏∞‡∏à‡∏±‡∏î‡πÄ‡∏Å‡πá‡∏ö‡∏™‡∏¥‡πà‡∏á‡∏õ‡∏£‡∏∞‡∏î‡∏¥‡∏©‡∏ê‡πå‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏≠‡∏ö‡∏£‡∏°:

```python
from huggingface_hub import Repository

output_dir = "results-mt5-finetuned-squad-accelerate"
repo = Repository(output_dir, clone_from=repo_name)
```

‡∏™‡∏¥‡πà‡∏á‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ú‡∏•‡∏±‡∏Å‡∏î‡∏±‡∏ô‡∏™‡∏¥‡πà‡∏á‡∏õ‡∏£‡∏∞‡∏î‡∏¥‡∏©‡∏ê‡πå‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏ó‡∏µ‡πà Hub ‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÄ‡∏°‡∏ò‡∏≠‡∏î `repo.push_to_hub()` ‡πÉ‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏≠‡∏ö‡∏£‡∏°! ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏°‡∏≤‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡πÇ‡∏î‡∏¢‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏•‡∏π‡∏õ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏≠‡∏ö‡∏£‡∏°‡∏≠‡∏≠‡∏Å‡πÑ‡∏õ

### ‡∏•‡∏π‡∏õ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏≠‡∏ö‡∏£‡∏°[[‡∏•‡∏π‡∏õ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏≠‡∏ö‡∏£‡∏°]]

‡∏•‡∏π‡∏õ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏≠‡∏ö‡∏£‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡∏Ñ‡πà‡∏≠‡∏ô‡∏Ç‡πâ‡∏≤‡∏á‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏≠‡∏∑‡πà‡∏ô‡πÜ‡∏Ç‡∏≠‡∏á ü§ó Accelerate ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÄ‡∏Ñ‡∏¢‡∏û‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏ö‡πà‡∏á‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏µ‡πà‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏Ñ‡∏£‡πà‡∏≤‡∏ß‡πÜ:

1. ‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÇ‡∏î‡∏¢‡∏ß‡∏ô‡∏ã‡πâ‡∏≥‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô `train_dataloader` ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ epoch
2. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡πâ‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ epoch ‡πÇ‡∏î‡∏¢‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ó‡πÄ‡∏Ñ‡πá‡∏ô‡∏Å‡πà‡∏≠‡∏ô ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡∏à‡∏∂‡∏á‡∏ñ‡∏≠‡∏î‡∏£‡∏´‡∏±‡∏™‡πÇ‡∏ó‡πÄ‡∏Ñ‡πá‡∏ô (‡πÅ‡∏•‡∏∞‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á) ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
3. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô ROUGE ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÄ‡∏´‡πá‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ
4. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏à‡∏∏‡∏î‡∏ï‡∏£‡∏ß‡∏à‡πÅ‡∏•‡∏∞‡∏ú‡∏•‡∏±‡∏Å‡∏î‡∏±‡∏ô‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏Å‡∏•‡∏≤‡∏á ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏≠‡∏≤‡∏®‡∏±‡∏¢‡∏≠‡∏≤‡∏£‡πå‡∏Å‡∏¥‡∏ß‡πÄ‡∏°‡∏ô‡∏ï‡πå `blocking=False` ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏Ç‡∏≠‡∏á‡∏≠‡πá‡∏≠‡∏ö‡πÄ‡∏à‡πá‡∏Å‡∏ï‡πå `Repository` ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ú‡∏•‡∏±‡∏Å‡∏î‡∏±‡∏ô‡∏à‡∏∏‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ï‡πà‡∏≠‡∏¢‡∏∏‡∏Ñ _asynchronously_ ‡πÑ‡∏î‡πâ ‡∏™‡∏¥‡πà‡∏á‡∏ô‡∏µ‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ù‡∏∂‡∏Å‡∏≠‡∏ö‡∏£‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏≠‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏ó‡∏µ‡πà‡∏Ñ‡πà‡∏≠‡∏ô‡∏Ç‡πâ‡∏≤‡∏á‡∏ä‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏ô‡∏≤‡∏î GB!

‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏π‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏ö‡∏•‡πá‡∏≠‡∏Ñ‡πÇ‡∏Ñ‡πâ‡∏î‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:

```python
from tqdm.auto import tqdm
import torch
import numpy as np

progress_bar = tqdm(range(num_training_steps))

for epoch in range(num_train_epochs):
    # Training
    model.train()
    for step, batch in enumerate(train_dataloader):
        outputs = model(**batch)
        loss = outputs.loss
        accelerator.backward(loss)

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(1)

    # Evaluation
    model.eval()
    for step, batch in enumerate(eval_dataloader):
        with torch.no_grad():
            generated_tokens = accelerator.unwrap_model(model).generate(
                batch["input_ids"],
                attention_mask=batch["attention_mask"],
            )

            generated_tokens = accelerator.pad_across_processes(
                generated_tokens, dim=1, pad_index=tokenizer.pad_token_id
            )
            labels = batch["labels"]

            # If we did not pad to max length, we need to pad the labels too
            labels = accelerator.pad_across_processes(
                batch["labels"], dim=1, pad_index=tokenizer.pad_token_id
            )

            generated_tokens = accelerator.gather(generated_tokens).cpu().numpy()
            labels = accelerator.gather(labels).cpu().numpy()

            # Replace -100 in the labels as we can't decode them
            labels = np.where(labels != -100, labels, tokenizer.pad_token_id)
            if isinstance(generated_tokens, tuple):
                generated_tokens = generated_tokens[0]
            decoded_preds = tokenizer.batch_decode(
                generated_tokens, skip_special_tokens=True
            )
            decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)

            decoded_preds, decoded_labels = postprocess_text(
                decoded_preds, decoded_labels
            )

            rouge_score.add_batch(predictions=decoded_preds, references=decoded_labels)

    # Compute metrics
    result = rouge_score.compute()
    # Extract the median ROUGE scores
    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}
    result = {k: round(v, 4) for k, v in result.items()}
    print(f"Epoch {epoch}:", result)

    # Save and upload
    accelerator.wait_for_everyone()
    unwrapped_model = accelerator.unwrap_model(model)
    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)
    if accelerator.is_main_process:
        tokenizer.save_pretrained(output_dir)
        repo.push_to_hub(
            commit_message=f"Training in progress epoch {epoch}", blocking=False
        )
```

```python out
Epoch 0: {'rouge1': 5.6351, 'rouge2': 1.1625, 'rougeL': 5.4866, 'rougeLsum': 5.5005}
Epoch 1: {'rouge1': 9.8646, 'rouge2': 3.4106, 'rougeL': 9.9439, 'rougeLsum': 9.9306}
Epoch 2: {'rouge1': 11.0872, 'rouge2': 3.3273, 'rougeL': 11.0508, 'rougeLsum': 10.9468}
Epoch 3: {'rouge1': 11.8587, 'rouge2': 4.8167, 'rougeL': 11.7986, 'rougeLsum': 11.7518}
Epoch 4: {'rouge1': 12.9842, 'rouge2': 5.5887, 'rougeL': 12.7546, 'rougeLsum': 12.7029}
Epoch 5: {'rouge1': 13.4628, 'rouge2': 6.4598, 'rougeL': 13.312, 'rougeLsum': 13.2913}
Epoch 6: {'rouge1': 12.9131, 'rouge2': 5.8914, 'rougeL': 12.6896, 'rougeLsum': 12.5701}
Epoch 7: {'rouge1': 13.3079, 'rouge2': 6.2994, 'rougeL': 13.1536, 'rougeLsum': 13.1194}
Epoch 8: {'rouge1': 13.96, 'rouge2': 6.5998, 'rougeL': 13.9123, 'rougeLsum': 13.7744}
Epoch 9: {'rouge1': 14.1192, 'rouge2': 7.0059, 'rougeL': 14.1172, 'rougeLsum': 13.9509}
```

‡πÅ‡∏Ñ‡πà‡∏ô‡∏±‡πâ‡∏ô‡πÅ‡∏´‡∏•‡∏∞! ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ñ‡∏∏‡∏ì‡∏£‡∏±‡∏ô‡∏™‡∏¥‡πà‡∏á‡∏ô‡∏µ‡πâ ‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡∏°‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏Ñ‡πà‡∏≠‡∏ô‡∏Ç‡πâ‡∏≤‡∏á‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏à‡∏≤‡∏Å `Trainer`.

{/if}

## ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì[[‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì]]

‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ñ‡∏∏‡∏ì‡∏ú‡∏•‡∏±‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡∏Æ‡∏±‡∏ö‡πÅ‡∏•‡πâ‡∏ß ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏•‡πà‡∏ô‡∏Å‡∏±‡∏ö‡∏°‡∏±‡∏ô‡∏ú‡πà‡∏≤‡∏ô‡∏ß‡∏¥‡∏î‡πÄ‡∏à‡πá‡∏ï‡∏Å‡∏≤‡∏£‡∏≠‡∏ô‡∏∏‡∏°‡∏≤‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡∏î‡πâ‡∏ß‡∏¢‡∏≠‡πá‡∏≠‡∏ö‡πÄ‡∏à‡πá‡∏Å‡∏ï‡πå `pipeline` ‡∏î‡∏±‡∏á‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:

```python
from transformers import pipeline

hub_model_id = "huggingface-course/mt5-small-finetuned-amazon-en-es"
summarizer = pipeline("summarization", model=hub_model_id)
```

‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡πâ‡∏≠‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏ä‡∏∏‡∏î‡∏ó‡∏î‡∏™‡∏≠‡∏ö (‡∏ã‡∏∂‡πà‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡πÄ‡∏´‡πá‡∏ô) ‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÑ‡∏õ‡∏õ‡πå‡πÑ‡∏•‡∏ô‡πå‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏ñ‡∏∂‡∏á‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡∏™‡∏£‡∏∏‡∏õ ‡∏Ç‡∏±‡πâ‡∏ô‡πÅ‡∏£‡∏Å ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏á‡πà‡∏≤‡∏¢‡πÜ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏™‡∏î‡∏á‡∏ö‡∏ó‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡πå ‡∏ä‡∏∑‡πà‡∏≠ ‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏£‡∏∏‡∏õ‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô:

```python
def print_summary(idx):
    review = books_dataset["test"][idx]["review_body"]
    title = books_dataset["test"][idx]["review_title"]
    summary = summarizer(books_dataset["test"][idx]["review_body"])[0]["summary_text"]
    print(f"'>>> Review: {review}'")
    print(f"\n'>>> Title: {title}'")
    print(f"\n'>>> Summary: {summary}'")
```

‡∏•‡∏≠‡∏á‡∏°‡∏≤‡∏î‡∏π‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö:

```python
print_summary(100)
```

```python out
'>>> Review: Nothing special at all about this product... the book is too small and stiff and hard to write in. The huge sticker on the back doesn‚Äôt come off and looks super tacky. I would not purchase this again. I could have just bought a journal from the dollar store and it would be basically the same thing. It‚Äôs also really expensive for what it is.'

'>>> Title: Not impressed at all... buy something else'

'>>> Summary: Nothing special at all about this product'
```

‡∏ô‡∏µ‡πà‡∏Å‡πá‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÅ‡∏¢‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ! ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÄ‡∏´‡πá‡∏ô‡πÑ‡∏î‡πâ‡∏ß‡πà‡∏≤‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ _abstractive_ ‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏ö‡∏ó‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡πå‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡πÉ‡∏´‡∏°‡πà ‡πÅ‡∏•‡∏∞‡∏ö‡∏≤‡∏á‡∏ó‡∏µ‡πÅ‡∏á‡πà‡∏°‡∏∏‡∏°‡∏ó‡∏µ‡πà‡∏¢‡∏≠‡∏î‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏Å‡πá‡∏Ñ‡∏∑‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏ö‡∏ö‡∏™‡∏≠‡∏á‡∏†‡∏≤‡∏©‡∏≤ ‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô‡πÄ‡∏£‡∏≤‡∏à‡∏∂‡∏á‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ö‡∏ó‡∏™‡∏£‡∏∏‡∏õ‡∏ö‡∏ó‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡πå‡∏†‡∏≤‡∏©‡∏≤‡∏™‡πÄ‡∏õ‡∏ô‡πÑ‡∏î‡πâ:

```python
print_summary(0)
```

```python out
'>>> Review: Es una trilogia que se hace muy facil de leer. Me ha gustado, no me esperaba el final para nada'

'>>> Title: Buena literatura para adolescentes'

'>>> Summary: Muy facil de leer'
```

‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏õ‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡∏ß‡πà‡∏≤ "Very easy to read" ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏£‡∏≤‡πÄ‡∏´‡πá‡∏ô‡πÉ‡∏ô‡∏Å‡∏£‡∏ì‡∏µ‡∏ô‡∏µ‡πâ‡∏Å‡πá‡∏î‡∏∂‡∏á‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡∏Å‡πá‡∏ï‡∏≤‡∏° ‡∏™‡∏¥‡πà‡∏á‡∏ô‡∏µ‡πâ‡πÅ‡∏™‡∏î‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏´‡πá‡∏ô‡∏ñ‡∏∂‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡πÄ‡∏ô‡∏Å‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå‡∏Ç‡∏≠‡∏á‡∏£‡∏∏‡πà‡∏ô mT5 ‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏î‡πâ‡∏™‡∏±‡∏°‡∏ú‡∏±‡∏™‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏±‡∏ö‡∏Ñ‡∏•‡∏±‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏û‡∏π‡∏î‡πÑ‡∏î‡πâ‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤!

‡∏ï‡πà‡∏≠‡πÑ‡∏õ ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏´‡∏±‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ô‡πÉ‡∏à‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢: ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏†‡∏≤‡∏©‡∏≤‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
