<FrameworkSwitchCourse {fw} />

<!-- DISABLE-FRONTMATTER-SECTIONS -->

# คำถามท้ายบท[[คำถามท้ายบท]]

<CourseFloatingBanner
    chapter={7}
    classNames="absolute z-10 right-0 top-0"
/>

มาทดสอบสิ่งที่คุณเรียนรู้ในบทนี้กัน!

### 1. งานใดต่อไปนี้สามารถจัดว่าเป็นปัญหาการจำแนกโทเค็นได้?

<Question
	choices={[
		{
			text: "ค้นหาส่วนประกอบทางไวยากรณ์ในประโยค",
			explain: "ถูกต้อง! จากนั้นเราสามารถตั้งชื่อแต่ละคำเป็นคำนาม กริยา ฯลฯ",
			correct: true
		},
		{
			text: "ค้นหาว่าประโยคมีความถูกต้องตามหลักไวยากรณ์หรือไม่",
			explain: "ไม่ไช่ นี่เป็นปัญหาการจำแนกลำดับ"
		},
		{
			text: "ค้นหาบุคคลที่กล่าวถึงในประโยค",
			explain: "ถูกต้อง! เราสามารถติดป้ายกำกับแต่ละคำว่าเป็นบุคคลหรือไม่ใช่บุคคลได้",
            correct: true
		},
        {
			text: "ค้นหากลุ่มคำในประโยคที่ตอบคำถาม",
			explain: "ไม่ไช่ นั่นจะเป็นการตอบคำถาม"
		}
	]}
/>

### 2. ส่วนใดของการประมวลผลล่วงหน้าสำหรับการจัดประเภทโทเค็นที่แตกต่างจากไปป์ไลน์การประมวลผลล่วงหน้าอื่นๆ?

<Question
	choices={[
		{
			text: "ไม่จำเป็นต้องทำอะไรเลย ข้อความได้รับโทเค็นแล้ว",
			explain: "ข้อความเหล่านี้ถูกกำหนดให้เป็นคำที่แยกจากกันจริงๆ แต่เรายังจำเป็นต้องใช้โมเดลโทเค็นไนเซชันของคำย่อย"
		},
		{
			text: "ข้อความถูกกำหนดไว้เป็นคำ ดังนั้นเราจึงจำเป็นต้องใช้โทเค็นย่อยของคำเท่านั้น",
			explain: "ถูกต้อง! สิ่งนี้แตกต่างจากการประมวลผลล่วงหน้าตามปกติ ซึ่งเราจำเป็นต้องใช้ไปป์ไลน์โทเค็นแบบเต็ม คุณนึกถึงความแตกต่างอื่นได้ไหม?",
			correct: true
		},
		{
			text: "เราใช้ <code>-100</code> เพื่อติดป้ายกำกับโทเค็นพิเศษ",
			explain: "นั่นไม่ได้เฉพาะเจาะจงกับการจำแนกโทเค็น - เราจะใช้ <code>-100</code> เป็นป้ายกำกับสำหรับโทเค็นที่เราต้องการเพิกเฉยใน loss"
		},
		{
			text: "เราจำเป็นต้องตรวจสอบให้แน่ใจว่าได้ตัดหรือแพดฉลากให้มีขนาดเดียวกันกับอินพุต เมื่อใช้การตัดทอน/แพดดิ้ง",
			explain: "อย่างแท้จริง! นั่นไม่ใช่ความแตกต่างเพียงอย่างเดียว",
			correct: true
		}
	]}
/>

### 3. ปัญหาอะไรเกิดขึ้นเมื่อเราโทเค็นคำในปัญหาการจำแนกโทเค็นและต้องการติดป้ายกำกับโทเค็น?

<Question
	choices={[
		{
			text: "โทเค็นเซอร์เพิ่มโทเค็นพิเศษและเราไม่มีป้ายกำกับสำหรับโทเค็นเหล่านั้น",
			explain: "เราติดป้ายกำกับ <code>-100</code> เหล่านี้เพื่อที่พวกมันจะถูกละเว้นใน loss"
		},
		{
			text: "แต่ละคำสามารถสร้างโทเค็นได้หลายรายการ ดังนั้นเราจึงมีโทเค็นมากกว่าที่เรามีป้ายกำกับ",
			explain: "นั่นคือปัญหาหลัก และเราจำเป็นต้องปรับป้ายกำกับเดิมให้ตรงกับโทเค็น",
			correct: true
		},
		{
			text: "โทเค็นที่เพิ่มไม่มีป้ายกำกับ ดังนั้นจึงไม่มีปัญหา",
			explain: "นั่นไม่ถูกต้อง เราต้องการป้ายกำกับให้มากที่สุดเท่าที่เรามีโทเค็น ไม่เช่นนั้นแบบจำลองของเราจะเกิดข้อผิดพลาด"
		}
	]}
/>

### 4. "การปรับโดเมน (domain adaptation)" หมายถึงอะไร?

<Question
	choices={[
		{
			text: "ถึงเวลาที่เรารันโมเดลบนชุดข้อมูลและรับการคาดการณ์สำหรับแต่ละตัวอย่างในชุดข้อมูลนั้น",
			explain: "ไม่ นี่เป็นเพียงการอนุมานที่กำลังรันอยู่"
		},
		{
			text: "ถึงเวลาที่เราฝึกโมเดลบนชุดข้อมูล",
			explain: "ไม่ นี่คือการฝึกโมเดล ไม่มีการปรับตัวที่นี่"
		},
		{
			text: "ถึงเวลาที่เราปรับแต่งโมเดลที่ได้รับการฝึกล่วงหน้าบนชุดข้อมูลใหม่ และให้การคาดการณ์ที่ปรับให้เข้ากับชุดข้อมูลนั้นได้มากขึ้น",
			explain: "ถูกต้อง! โมเดลได้ปรับความรู้ให้เข้ากับชุดข้อมูลใหม่",
            correct: true
		},
        {
			text: "ถึงเวลาที่เราเพิ่มตัวอย่างที่จัดประเภทไม่ถูกต้องลงในชุดข้อมูลเพื่อทำให้แบบจำลองของเรามีประสิทธิภาพมากขึ้น",
			explain: "นั่นเป็นสิ่งที่คุณควรทำอย่างแน่นอนหากคุณฝึกโมเดลของคุณใหม่เป็นประจำ แต่ไม่ใช่การปรับโดเมน"
		}
	]}
/>

### 5. อะไรคือป้ายกำกับ (label) ในปัญหาการสร้างแบบจำลองภาษาที่ปกปิด (masked language modeling)?

<Question
	choices={[
		{
			text: "โทเค็นบางส่วนในประโยคอินพุตจะถูกปกปิดแบบสุ่ม และป้ายกำกับเป็นโทเค็นอินพุตดั้งเดิม",
			explain: "ไช่เลย!",
            correct: true
		},
		{
			text: "โทเค็นบางส่วนในประโยคอินพุตจะถูกปกปิดแบบสุ่ม และป้ายกำกับเป็นโทเค็นอินพุตดั้งเดิม โดยเลื่อนไปทางซ้าย",
			explain: "ไม่ การเลื่อนป้ายกำกับไปทางซ้ายสอดคล้องกับการคาดเดาคำถัดไป ซึ่งเป็นการสร้างแบบจำลองภาษาเชิงสาเหตุ"
		},
		{
			text: "โทเค็นบางส่วนในประโยคอินพุตจะถูกปกปิดแบบสุ่ม และป้ายกำกับจะระบุว่าประโยคนั้นเป็นบวกหรือลบ",
			explain: "นั่นเป็นปัญหาการจำแนกลำดับในการเพิ่มข้อมูล ไม่ใช่การสร้างแบบจำลองภาษาที่ปกปิด"
		},
        {
			text: "โทเค็นบางส่วนในประโยคอินพุตทั้งสองประโยคจะถูกปกปิดแบบสุ่ม และป้ายกำกับคือว่าทั้งสองประโยคคล้ายกันหรือไม่",
			explain: "นั่นเป็นปัญหาการจำแนกลำดับในการเพิ่มข้อมูล ไม่ใช่การสร้างแบบจำลองภาษาที่ปกปิด"
		}
	]}
/>

### 6. งานใดต่อไปนี้ที่สามารถมองได้ว่าเป็นปัญหาแบบลำดับต่อลำดับ (sequence-to-sequence)?

<Question
	choices={[
		{
			text: "การเขียนบทวิจารณ์สั้น ๆ เกี่ยวกับเอกสารขนาดยาว",
			explain: "ใช่ นั่นเป็นปัญหาในการสรุป ลองคำตอบอื่น!",
            correct: true
		},
		{
			text: "ตอบคำถามเกี่ยวกับเอกสาร",
			explain: "สิ่งนี้สามารถถูกวางกรอบเป็นปัญหาแบบลำดับต่อลำดับได้ มันไม่ใช่คำตอบเดียวที่ถูกต้อง",
            correct: true
		},
		{
			text: "รับแปลข้อความภาษาจีนเป็นภาษาอังกฤษ",
			explain: "นั่นเป็นปัญหาลำดับต่อลำดับอย่างแน่นอน คุณช่วยมองเห็นอีกอันหนึ่งได้ไหม?",
            correct: true
		},
        {
			text: "แก้ไขข้อความที่หลานชาย/เพื่อนของฉันส่งให้เป็นภาษาอังกฤษที่เหมาะสม",
			explain: "นั่นเป็นปัญหาการแปล ดังนั้นงานจะต้องเรียงลำดับตามลำดับอย่างแน่นอน นี่ไม่ใช่คำตอบเดียวที่ถูกต้อง!",
			correct: true
		}
	]}
/>

### 7. วิธีที่เหมาะสมในการประมวลผลข้อมูลล่วงหน้าสำหรับปัญหาตามลำดับ (sequence-to-sequence) คืออะไร?

<Question
	choices={[
		{
			text: "อินพุตและเป้าหมายจะต้องถูกส่งไปยังโทเค็นไนเซอร์ด้วย <code>inputs=...</code> และ <code>targets=...</code>",
			explain: "นี่อาจเป็น API ที่เราเพิ่มในอนาคต แต่ตอนนี้ไม่สามารถทำได้"
		},
		{
			text: "อินพุตและเป้าหมายทั้งสองจะต้องได้รับการประมวลผลล่วงหน้า โดยเรียกโทเค็นไนเซอร์แยกกันสองครั้ง",
			explain: "นั่นเป็นเรื่องจริงแต่ไม่สมบูรณ์ มีสิ่งที่คุณต้องทำเพื่อให้แน่ใจว่า tokenizer ประมวลผลทั้งสองอย่างถูกต้อง"
		},
		{
			text: "ตามปกติเราเพียงแค่ต้องโทเค็นอินพุต",
			explain: "ไม่อยู่ในปัญหาการจำแนกลำดับ เป้าหมายก็คือข้อความที่เราต้องแปลงเป็นตัวเลขด้วย!"
		},
        {
			text: "อินพุตจะต้องถูกส่งไปยัง tokenizer และเป้าหมายด้วย แต่อยู่ภายใต้ตัวจัดการบริบทพิเศษ",
			explain: "ถูกต้อง โทเค็นไนเซอร์จะต้องถูกใส่เข้าสู่โหมดเป้าหมายโดยตัวจัดการบริบทนั้น",
			correct: true
		}
	]}
/>

{#if fw === 'pt'}

### 8. เหตุใดจึงมีคลาสย่อยเฉพาะของ 'Trainer' สำหรับปัญหาตามลำดับ (sequence-to-sequence)?

<Question
	choices={[
		{
			text: "เนื่องจากปัญหาแบบเรียงลำดับต่อลำดับใช้การสูญเสียแบบกำหนดเอง เพื่อละเว้นป้ายกำกับที่ตั้งค่าเป็น <code>-100</code>",
			explain: "นั่นไม่ใช่การสูญเสียที่กำหนดเอง แต่เป็นวิธีการคำนวณการสูญเสีย (loss) เสมอ"
		},
		{
			text: "เนื่องจากปัญหาแบบลำดับต่อลำดับจำเป็นต้องมีการวนรอบการประเมินพิเศษ",
			explain: "ถูกต้อง. การคาดการณ์ของโมเดลแบบเรียงลำดับตามลำดับมักจะทำงานโดยใช้เมธอด <code>generate()</code>",
			correct: true
		},
		{
			text: "เพราะเป้าหมายคือข้อความในโจทย์ปัญหาตามลำดับ",
			explain: "<code>Trainer</code> ไม่สนใจเรื่องนี้มากนัก เนื่องจากเคยได้รับการประมวลผลมาก่อนแล้ว"
		},
        {
			text: "เนื่องจากเราใช้สองแบบจำลองในการแก้ปัญหาตามลำดับ",
			explain: "เราใช้โมเดลสองแบบในวิธีหนึ่ง นั่นคือตัวเข้ารหัสและตัวถอดรหัส แต่จะรวมกลุ่มเข้าด้วยกันเป็นโมเดลเดียว"
		}
	]}
/>

{:else}

### 9. เหตุใดจึงมักไม่จำเป็นต้องระบุการสูญเสีย (loss) เมื่อเรียก `compile()` ในโมเดล Transformer?

<Question
	choices={[
		{
			text: "เนื่องจากโมเดล Transformer ได้รับการฝึกฝนด้วยการเรียนรู้แบบไม่มีผู้ดูแล",
			explain: "ไม่ไช่ แม้แต่การเรียนรู้แบบไม่มีผู้ดูแลก็ยังจำเป็นต้องมีฟังก์ชันการสูญเสีย!"
		},
		{
			text: "เนื่องจากเอาต์พุตการสูญเสียภายในของโมเดลถูกใช้เป็นค่าเริ่มต้น",
			explain: "ถูกต้อง!",
			correct: true
		},
		{
			text: "เพราะเราคำนวณเมตริกหลังการฝึกแทน",
			explain: "เราทำอย่างนั้นบ่อยครั้ง แต่ไม่ได้อธิบายว่าเราได้รับค่าการสูญเสียจากจุดใดที่เราปรับให้เหมาะสมในการฝึกซ้อม"
		},
        {
			text: "เพราะการสูญเสียถูกระบุไว้ใน `model.fit()` แทน",
			explain: "ไม่ ฟังก์ชันการสูญเสียจะได้รับการแก้ไขเสมอเมื่อคุณเรียกใช้ `model.compile()` และไม่สามารถเปลี่ยนแปลงใน `model.fit()`"
		}
	]}
/>

{/if}

### 10. เมื่อใดที่คุณควรฝึกโมเดลใหม่ล่วงหน้า?

<Question
	choices={[
		{
			text: "เมื่อไม่มีโมเดลที่ได้รับการฝึกล่วงหน้าสำหรับภาษาเฉพาะของคุณ",
			explain: "ถูกต้อง",
			correct: true
		},
		{
			text: "เมื่อคุณมีข้อมูลจำนวนมาก แม้ว่าจะมีแบบจำลองที่ได้รับการฝึกไว้ล่วงหน้าที่สามารถใช้งานได้ก็ตาม",
			explain: "ในกรณีนี้ คุณควรใช้โมเดลที่ได้รับการฝึกอบรมมาล่วงหน้าและปรับแต่งข้อมูลของคุณอย่างละเอียด เพื่อหลีกเลี่ยงต้นทุนการประมวลผลจำนวนมาก"
		},
		{
			text: "เมื่อคุณมีความกังวลเกี่ยวกับอคติของแบบจำลองที่ฝึกไว้ล่วงหน้าที่คุณใช้อยู่",
			explain: "นั่นเป็นเรื่องจริง แต่คุณต้องแน่ใจว่าข้อมูลที่คุณจะใช้สำหรับการฝึกอบรมนั้นดีกว่าจริงๆ",
			correct: true
		},
        {
			text: "เมื่อรุ่นที่เตรียมไว้นั้นยังไม่ดีพอ",
			explain: "คุณแน่ใจหรือว่าคุณได้แก้ไขข้อบกพร่องในการฝึกของคุณอย่างถูกต้องแล้ว?"
		}
	]}
/>

### 11. เหตุใดจึงเป็นเรื่องง่ายที่จะฝึกโมเดลภาษาล่วงหน้ากับข้อความจำนวนมาก?

<Question
	choices={[
		{
			text: "เนื่องจากมีข้อความมากมายบนอินเทอร์เน็ต",
			explain: "แม้ว่าจะเป็นเรื่องจริง แต่ก็ไม่ได้ตอบคำถามจริงๆ ลองอีกครั้ง!"
		},
		{
			text: "เนื่องจากวัตถุประสงค์ในการฝึกอบรมล่วงหน้าไม่จำเป็นต้องให้มนุษย์ติดป้ายกำกับข้อมูล",
			explain: "ถูกต้อง การสร้างแบบจำลองภาษาเป็นปัญหาที่มีการดูแลตนเอง",
			correct: true
		},
		{
			text: "เนื่องจากไลบรารี 🤗 Transformers ต้องการโค้ดเพียงไม่กี่บรรทัดเพื่อเริ่มการฝึกอบรม",
			explain: "แม้ว่าจะเป็นเรื่องจริง แต่ก็ไม่ได้ตอบคำถามที่ถามจริงๆ ลองคำตอบอื่น!"
		}
	]}
/>

### 12. อะไรคือความท้าทายหลักเมื่อประมวลผลข้อมูลล่วงหน้าสำหรับงานตอบคำถาม (question-answering task)?

<Question
	choices={[
		{
			text: "คุณต้องการโทเค็นอินพุต",
			explain: "ถูกต้อง แต่มันเป็นความท้าทายหลักจริงๆ หรือ?"
		},
		{
			text: "คุณต้องจัดการกับบริบทที่ยาวมาก ซึ่งมีฟีเจอร์การฝึกอบรมหลายประการที่อาจมีหรือไม่มีคำตอบอยู่ในนั้น",
			explain: "นี่เป็นหนึ่งในความท้าทายอย่างแน่นอน",
			correct: true
		},
		{
			text: "คุณต้องทำการโทเค็นคำตอบสำหรับคำถามและอินพุต",
			explain: "ไม่ เว้นแต่คุณจะกำหนดกรอบคำถามในการตอบปัญหาเป็นงานตามลำดับ"
		},
       {
			text: "จากช่วงคำตอบในข้อความ คุณต้องค้นหาโทเค็นเริ่มต้นและสิ้นสุดในอินพุตโทเค็น",
			explain: "นั่นเป็นหนึ่งในส่วนที่ยาก ใช่แล้ว!",
			correct: true
		}
	]}
/>

### 13. โดยทั่วไปแล้วการประมวลผลภายหลังจะตอบคำถามอย่างไร?

<Question
	choices={[
		{
			text: "แบบจำลองจะให้ตำแหน่งเริ่มต้นและจุดสิ้นสุดของคำตอบแก่คุณ และคุณเพียงแค่ต้องถอดรหัสช่วงโทเค็นที่เกี่ยวข้อง",
			explain: "นั่นอาจเป็นวิธีหนึ่งที่จะทำได้ แต่มันง่ายเกินไปหน่อย"
		},
		{
			text: "แบบจำลองนี้ให้ตำแหน่งเริ่มต้นและจุดสิ้นสุดของคำตอบสำหรับแต่ละคุณลักษณะที่สร้างขึ้นโดยตัวอย่างเดียว และคุณเพียงแค่ต้องถอดรหัสช่วงโทเค็นที่เกี่ยวข้องในอันที่มีคะแนนดีที่สุด",
			explain: "นั่นใกล้เคียงกับขั้นตอนหลังการประมวลผลที่เราศึกษา แต่ก็ไม่ถูกต้องทั้งหมด"
		},
		{
			text: "แบบจำลองจะให้ตำแหน่งเริ่มต้นและจุดสิ้นสุดของคำตอบสำหรับแต่ละคุณลักษณะที่สร้างขึ้นจากตัวอย่างเดียว และคุณเพียงแค่ต้องจับคู่คุณลักษณะเหล่านั้นกับช่วงในบริบทของคุณลักษณะที่มีคะแนนดีที่สุด",
			explain: "สั้นๆ แค่นั้นเอง!",
			correct: true
		},
        {
			text: "โมเดลจะสร้างคำตอบ และคุณเพียงแค่ต้องถอดรหัสมัน",
			explain: "ไม่ เว้นแต่คุณจะกำหนดกรอบคำถามในการตอบปัญหาเป็นงานตามลำดับ"
		}
	]}
/>
