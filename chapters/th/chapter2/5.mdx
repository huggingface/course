<FrameworkSwitchCourse {fw} />

# ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡πÜ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ(multiple sequences)

{#if fw === 'pt'}

<CourseFloatingBanner chapter={2}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/th/chapter2/section5_pt.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/th/chapter2/section5_pt.ipynb"},
]} />

{:else}

<CourseFloatingBanner chapter={2}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/th/chapter2/section5_tf.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/th/chapter2/section5_tf.ipynb"},
]} />

{/if}

{#if fw === 'pt'}
<Youtube id="M6adb1j2jPI"/>
{:else}
<Youtube id="ROxrFOEbsQE"/>
{/if}

‡πÉ‡∏ô section ‡∏ó‡∏µ‡πà‡πÅ‡∏•‡πâ‡∏ß ‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡∏•‡∏≠‡∏á‡∏ó‡∏≥‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏á‡πà‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î: ‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏≠‡∏ô‡∏∏‡∏°‡∏≤‡∏ô(inference)‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡∏Å‡πá‡∏ï‡∏≤‡∏° ‡∏Å‡πá‡∏°‡∏µ‡∏ö‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤:

- ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏´‡∏•‡∏≤‡∏¢‡πÜ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£?
- ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏´‡∏•‡∏≤‡∏¢‡πÜ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ó‡∏µ‡πà‡∏°‡∏µ *‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô* ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£?
- ‡∏î‡∏±‡∏ä‡∏ô‡∏µ‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå(vocabulary indices) ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà?
- ‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ó‡∏µ‡πà‡∏¢‡∏≤‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà?

‡∏°‡∏≤‡∏î‡∏π‡∏Å‡∏±‡∏ô‡∏ß‡πà‡∏≤‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÉ‡∏î‡∏ö‡πâ‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ ‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏°‡∏±‡∏ô‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ ü§ó Transformers API ‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£

## ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÑ‡∏î‡πâ‡∏ä‡∏∏‡∏î(batch)‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï

‡πÉ‡∏ô‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏°‡∏≤‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏î‡πâ‡πÄ‡∏´‡πá‡∏ô‡πÅ‡∏•‡πâ‡∏ß‡∏ß‡πà‡∏≤‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ñ‡∏π‡∏Å‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏õ‡πÄ‡∏õ‡πá‡∏ô‡∏•‡∏¥‡∏™‡∏ó‡πå‡∏Ç‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£ ‡∏ó‡∏µ‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏°‡∏≤‡∏•‡∏≠‡∏á‡πÅ‡∏õ‡∏•‡∏á‡∏•‡∏¥‡∏™‡∏ó‡πå‡∏Ç‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ô‡∏µ‡πâ‡πÑ‡∏õ‡πÄ‡∏õ‡πá‡∏ô tensor ‡πÅ‡∏•‡∏∞‡πÉ‡∏™‡πà‡∏°‡∏±‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•:

{#if fw === 'pt'}
```py
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = AutoModelForSequenceClassification.from_pretrained(checkpoint)

sequence = "I've been waiting for a HuggingFace course my whole life."

tokens = tokenizer.tokenize(sequence)
ids = tokenizer.convert_tokens_to_ids(tokens)
input_ids = torch.tensor(ids)
# This line will fail.
model(input_ids)
```

```python out
IndexError: Dimension out of range (expected to be in range of [-1, 0], but got 1)
```
{:else}
```py
import tensorflow as tf
from transformers import AutoTokenizer, TFAutoModelForSequenceClassification

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)

sequence = "I've been waiting for a HuggingFace course my whole life."

tokens = tokenizer.tokenize(sequence)
ids = tokenizer.convert_tokens_to_ids(tokens)
input_ids = tf.constant(ids)
# This line will fail.
model(input_ids)
```

```py out
InvalidArgumentError: Input to reshape is a tensor with 14 values, but the requested shape has 196 [Op:Reshape]
```
{/if}

‡πÇ‡∏≠‡πâ‡∏ß‡πÑ‡∏°‡πà‡∏ô‡∏∞! ‡∏ó‡∏≥‡πÑ‡∏°‡∏°‡∏±‡∏ô‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏•‡∏∞? ‡πÉ‡∏ô‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏≤‡∏Å‡πá‡∏ó‡∏≥‡∏ï‡∏≤‡∏°‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏à‡∏≤‡∏Å pipeline ‡πÉ‡∏ô section 2

‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Å‡πá‡∏Ñ‡∏∑‡∏≠‡πÄ‡∏£‡∏≤‡πÉ‡∏™‡πà‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÅ‡∏ï‡πà‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏• ü§ó Transformers ‡∏ô‡∏±‡πâ‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏´‡∏•‡∏≤‡∏¢‡πÜ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ ‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡∏•‡∏≠‡∏á‡∏ó‡∏≥‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà tokenizer ‡∏ó‡∏≥‡∏≠‡∏¢‡∏π‡πà‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏≤‡πÉ‡∏ä‡πâ‡∏°‡∏±‡∏ô‡∏Å‡∏±‡∏ö `‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ(sequence)` ‡πÅ‡∏ï‡πà‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏•‡∏≠‡∏á‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡∏∏‡∏î‡∏µ‡πÜ ‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤‡∏°‡∏±‡∏ô‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÅ‡∏Ñ‡πà‡πÅ‡∏õ‡∏•‡∏á input IDs ‡πÑ‡∏õ‡πÄ‡∏õ‡πá‡∏ô tensor ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡πÅ‡∏ï‡πà‡∏°‡∏±‡∏ô‡∏¢‡∏±‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏°‡∏¥‡∏ï‡∏¥(dimension) ‡∏Ç‡∏≠‡∏á tensor ‡∏≠‡∏µ‡∏Å‡∏î‡πâ‡∏ß‡∏¢:

{#if fw === 'pt'}
```py
tokenized_inputs = tokenizer(sequence, return_tensors="pt")
print(tokenized_inputs["input_ids"])
```

```python out
tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,
          2607,  2026,  2878,  2166,  1012,   102]])
```
{:else}
```py
tokenized_inputs = tokenizer(sequence, return_tensors="tf")
print(tokenized_inputs["input_ids"])
```

```py out
<tf.Tensor: shape=(1, 16), dtype=int32, numpy=
array([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662,
        12172,  2607,  2026,  2878,  2166,  1012,   102]], dtype=int32)>
```
{/if}

‡∏•‡∏≠‡∏á‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏°‡∏¥‡∏ï‡∏¥(dimension)‡πÉ‡∏´‡∏°‡πà‡∏î‡πâ‡∏ß‡∏¢:

{#if fw === 'pt'}
```py
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = AutoModelForSequenceClassification.from_pretrained(checkpoint)

sequence = "I've been waiting for a HuggingFace course my whole life."

tokens = tokenizer.tokenize(sequence)
ids = tokenizer.convert_tokens_to_ids(tokens)

input_ids = torch.tensor([ids])
print("Input IDs:", input_ids)

output = model(input_ids)
print("Logits:", output.logits)
```
{:else}
```py
import tensorflow as tf
from transformers import AutoTokenizer, TFAutoModelForSequenceClassification

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)

sequence = "I've been waiting for a HuggingFace course my whole life."

tokens = tokenizer.tokenize(sequence)
ids = tokenizer.convert_tokens_to_ids(tokens)

input_ids = tf.constant([ids])
print("Input IDs:", input_ids)

output = model(input_ids)
print("Logits:", output.logits)
```
{/if}

‡πÄ‡∏£‡∏≤‡πÅ‡∏™‡∏î‡∏á input IDs ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏ú‡∏• logits ‡πÅ‡∏•‡∏∞‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:

{#if fw === 'pt'}
```python out
Input IDs: [[ 1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,  2607, 2026,  2878,  2166,  1012]]
Logits: [[-2.7276,  2.8789]]
```
{:else}
```py out
Input IDs: tf.Tensor(
[[ 1045  1005  2310  2042  3403  2005  1037 17662 12172  2607  2026  2878
   2166  1012]], shape=(1, 14), dtype=int32)
Logits: tf.Tensor([[-2.7276208  2.8789377]], shape=(1, 2), dtype=float32)
```
{/if}

*Batching* ‡∏Ñ‡∏∑‡∏≠ ‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏´‡∏•‡∏≤‡∏¢‡πÜ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÜ‡∏Å‡∏±‡∏ô‡∏ó‡∏µ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ‡πÅ‡∏Ñ‡πà‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ ‡∏Ñ‡∏∏‡∏ì‡∏Å‡πá‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∏‡∏î(batch)‡∏Ç‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÅ‡∏Ñ‡πà‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÑ‡∏î‡πâ:

```
batched_ids = [ids, ids]
```

‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏ä‡∏∏‡∏î(batch)‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏î‡πâ‡∏ß‡∏¢‡∏™‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô!

<Tip>

‚úèÔ∏è **Try it out!** ‡πÅ‡∏õ‡∏•‡∏á‡∏•‡∏¥‡∏™‡∏ó‡πå‡∏Ç‡∏≠‡∏á `batched_ids` ‡∏ô‡∏µ‡πâ‡πÑ‡∏õ‡πÄ‡∏õ‡πá‡∏ô tensor ‡πÅ‡∏•‡∏∞‡πÉ‡∏™‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì ‡πÅ‡∏•‡πâ‡∏ß‡∏•‡∏≠‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏î‡∏π‡∏ß‡πà‡∏≤‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏î‡πâ logits ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ‡πÑ‡∏´‡∏°(‡πÅ‡∏ï‡πà‡πÑ‡∏î‡πâ‡∏™‡∏≠‡∏á‡∏Ñ‡πà‡∏≤)!

</Tip>

‡∏∫Batching ‡∏ô‡∏±‡πâ‡∏ô‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏™‡πà‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏´‡∏•‡∏≤‡∏¢‡πÜ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏´‡∏•‡∏≤‡∏¢‡πÜ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ô‡∏±‡πâ‡∏ô‡∏Å‡πá‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏Å‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡πÅ‡∏ï‡πà‡∏Å‡πá‡∏¢‡∏±‡∏á‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ñ‡∏∏‡∏ì‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏£‡∏ß‡∏°‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏™‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏Ç‡∏∂‡πâ‡∏ô‡πÑ‡∏õ‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô ‡πÅ‡∏ï‡πà‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏Ñ‡∏¢‡∏ó‡∏≥ tensors ‡∏°‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ ‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡∏£‡∏π‡πâ‡∏ß‡πà‡∏≤‡∏°‡∏±‡∏ô‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î‡∏à‡∏ï‡∏∏‡∏£‡∏±‡∏™(rectangular) ‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏õ‡∏•‡∏á‡∏•‡∏¥‡∏™‡∏ó‡πå‡∏Ç‡∏≠‡∏á input IDs ‡πÑ‡∏õ‡πÄ‡∏õ‡πá‡∏ô tensor ‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á ‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£ *pad* ‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï

## ‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏¥‡∏°(Padding) ‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï

‡∏•‡∏¥‡∏™‡∏ó‡πå‡∏Ç‡∏≠‡∏á‡∏•‡∏¥‡∏™‡∏ó‡πå‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ñ‡∏π‡∏Å‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏õ‡πÄ‡∏õ‡πá‡∏ô tensor ‡πÑ‡∏î‡πâ:

```py no-format
batched_ids = [
    [200, 200, 200],
    [200, 200]
]
```

‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ô‡∏µ‡πâ ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ *padding* ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡πÉ‡∏´‡πâ tensor ‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏õ‡πá‡∏ô‡∏à‡∏ï‡∏∏‡∏£‡∏±‡∏™ Padding ‡∏à‡∏∞‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏ó‡∏∏‡∏Å‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≥‡∏û‡∏¥‡πÄ‡∏®‡∏© ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ß‡πà‡∏≤ *padding token* ‡πÑ‡∏õ‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ ‡∏¢‡∏Å‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏ä‡πà‡∏ô ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ 10 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏°‡∏µ 10 ‡∏Ñ‡∏≥ ‡πÅ‡∏•‡∏∞‡∏°‡∏µ 1 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ó‡∏µ‡πà‡∏°‡∏µ 20 ‡∏Ñ‡∏≥ padding ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏ó‡∏∏‡∏Å‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ô‡∏±‡πâ‡∏ô‡∏°‡∏µ 20 ‡∏Ñ‡∏≥‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô ‡πÉ‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤ tensor ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ó‡πå‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏ö‡∏ö‡∏ô‡∏µ‡πâ:

```py no-format
padding_id = 100

batched_ids = [
    [200, 200, 200],
    [200, 200, padding_id],
]
```

padding token ID ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏´‡∏≤‡πÑ‡∏î‡πâ‡πÉ‡∏ô `tokenizer.pad_token_id` ‡πÄ‡∏£‡∏≤‡∏°‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏°‡∏±‡∏ô‡∏î‡∏π‡πÅ‡∏•‡∏∞‡πÉ‡∏™‡πà‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏™‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡∏•‡∏∞‡∏≠‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡πÉ‡∏™‡πà‡πÅ‡∏ö‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∏‡∏î(batch)‡∏î‡πâ‡∏ß‡∏¢:

{#if fw === 'pt'}
```py no-format
model = AutoModelForSequenceClassification.from_pretrained(checkpoint)

sequence1_ids = [[200, 200, 200]]
sequence2_ids = [[200, 200]]
batched_ids = [
    [200, 200, 200],
    [200, 200, tokenizer.pad_token_id],
]

print(model(torch.tensor(sequence1_ids)).logits)
print(model(torch.tensor(sequence2_ids)).logits)
print(model(torch.tensor(batched_ids)).logits)
```

```python out
tensor([[ 1.5694, -1.3895]], grad_fn=<AddmmBackward>)
tensor([[ 0.5803, -0.4125]], grad_fn=<AddmmBackward>)
tensor([[ 1.5694, -1.3895],
        [ 1.3373, -1.2163]], grad_fn=<AddmmBackward>)
```
{:else}
```py no-format
model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)

sequence1_ids = [[200, 200, 200]]
sequence2_ids = [[200, 200]]
batched_ids = [
    [200, 200, 200],
    [200, 200, tokenizer.pad_token_id],
]

print(model(tf.constant(sequence1_ids)).logits)
print(model(tf.constant(sequence2_ids)).logits)
print(model(tf.constant(batched_ids)).logits)
```

```py out
tf.Tensor([[ 1.5693678 -1.3894581]], shape=(1, 2), dtype=float32)
tf.Tensor([[ 0.5803005  -0.41252428]], shape=(1, 2), dtype=float32)
tf.Tensor(
[[ 1.5693681 -1.3894582]
 [ 1.3373486 -1.2163193]], shape=(2, 2), dtype=float32)
```
{/if}

‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡∏≤‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡∏±‡∏ö logits ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÅ‡∏ö‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∏‡∏î(batch) ‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤: ‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á‡∏Ñ‡∏ß‡∏£‡∏à‡∏∞‡πÑ‡∏î‡πâ logits ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡∏Å‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á ‡πÅ‡∏ï‡πà‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡πÇ‡∏î‡∏¢‡∏™‡∏¥‡πâ‡∏ô‡πÄ‡∏ä‡∏¥‡∏á!

‡∏ô‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ß‡πà‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• Transformer ‡∏Ñ‡∏∑‡∏≠ attention layers ‡∏ó‡∏µ‡πà‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ token ‡πÇ‡∏î‡∏¢‡∏à‡∏∞‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤ padding token ‡∏î‡πâ‡∏ß‡∏¢ ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å attention layers ‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏ó‡∏∏‡∏Å tokens ‡∏Ç‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ó‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÉ‡∏™‡πà‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡∏ó‡∏µ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏™‡πà‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£ padding ‡πÑ‡∏õ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô‡∏ó‡∏µ‡∏•‡∏∞‡∏´‡∏•‡∏≤‡∏¢‡πÜ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ(batch) ‡πÄ‡∏£‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡∏ö‡∏≠‡∏Å attention layers ‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô‡πÉ‡∏´‡πâ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤ padding tokens ‡πÇ‡∏î‡∏¢‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡πÑ‡∏î‡πâ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ attention mask

## Attention masks

*Attention masks* ‡∏Ñ‡∏∑‡∏≠ tensors ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö tensor ‡∏Ç‡∏≠‡∏á input IDs ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢ 0 ‡πÅ‡∏•‡∏∞ 1: 1 ‡∏ö‡πà‡∏á‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤ tokens ‡πÉ‡∏ô‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ô‡∏±‡πâ‡∏ô‡πÜ ‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤, ‡πÅ‡∏•‡∏∞ 0 ‡∏ö‡πà‡∏á‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤ tokens ‡πÉ‡∏ô‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ô‡∏±‡πâ‡∏ô‡πÜ ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤(‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏Ñ‡∏∑‡∏≠ ‡∏°‡∏±‡∏ô‡∏Ñ‡∏ß‡∏£‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏•‡∏∞‡πÄ‡∏•‡∏¢‡πÇ‡∏î‡∏¢ attention layers ‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•)

‡∏°‡∏≤‡∏ó‡∏≥‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÅ‡∏•‡πâ‡∏ß‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ attention mask ‡∏Å‡∏±‡∏ô:

{#if fw === 'pt'}
```py no-format
batched_ids = [
    [200, 200, 200],
    [200, 200, tokenizer.pad_token_id],
]

attention_mask = [
    [1, 1, 1],
    [1, 1, 0],
]

outputs = model(torch.tensor(batched_ids), attention_mask=torch.tensor(attention_mask))
print(outputs.logits)
```

```python out
tensor([[ 1.5694, -1.3895],
        [ 0.5803, -0.4125]], grad_fn=<AddmmBackward>)
```
{:else}
```py no-format
batched_ids = [
    [200, 200, 200],
    [200, 200, tokenizer.pad_token_id],
]

attention_mask = [
    [1, 1, 1],
    [1, 1, 0],
]

outputs = model(tf.constant(batched_ids), attention_mask=tf.constant(attention_mask))
print(outputs.logits)
```

```py out
tf.Tensor(
[[ 1.5693681  -1.3894582 ]
 [ 0.5803021  -0.41252586]], shape=(2, 2), dtype=float32)
```
{/if}

‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ logits ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á‡πÉ‡∏ô‡∏ä‡∏∏‡∏î(batch) ‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•

‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡∏∏‡∏ß‡πà‡∏≤‡∏Ñ‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á‡∏ô‡∏±‡πâ‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡πÉ‡∏ô padding ID ‡∏ã‡∏∂‡πà‡∏á‡∏Å‡πá‡∏Ñ‡∏∑‡∏≠‡∏Ñ‡πà‡∏≤ 0 ‡πÉ‡∏ô attention mask

<Tip>

‚úèÔ∏è **‡∏•‡∏≠‡∏á‡πÄ‡∏•‡∏¢!** ‡∏ó‡∏≥ tokenization ‡∏Å‡∏±‡∏ö‡∏™‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÉ‡∏ô section 2 ("I've been waiting for a HuggingFace course my whole life." ‡πÅ‡∏•‡∏∞ "I hate this so much!") ‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏™‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏î‡∏π‡∏ß‡πà‡∏≤‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏î‡πâ logits ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ö‡πÉ‡∏ô section 2 ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡πÉ‡∏´‡πâ‡∏à‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∏‡∏î(batch) ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ padding token ‡πÅ‡∏•‡πâ‡∏ß‡∏™‡∏£‡πâ‡∏≤‡∏á attention mask ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á ‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏î‡∏π‡∏ß‡πà‡∏≤‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏î‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ó‡πå‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡πÉ‡∏™‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡πâ‡∏ß!

</Tip>

## ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ó‡∏µ‡πà‡∏¢‡∏≤‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô

‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• Transformer ‡∏ô‡∏±‡πâ‡∏ô‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏Ç‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏™‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÑ‡∏î‡πâ ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏´‡∏ç‡πà‡∏à‡∏∞‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏≤‡∏Å 512 ‡∏´‡∏£‡∏∑‡∏≠ 1024 tokens ‡πÅ‡∏•‡∏∞‡∏Å‡πá‡∏à‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ñ‡πâ‡∏≤‡πÉ‡∏´‡πâ‡∏°‡∏±‡∏ô‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ó‡∏µ‡πà‡∏¢‡∏≤‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô ‡∏°‡∏µ‡∏ß‡∏µ‡∏ò‡∏µ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ô‡∏µ‡πâ‡∏≠‡∏¢‡∏π‡πà 2 ‡∏ß‡∏¥‡∏ò‡∏µ:

- ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ó‡∏µ‡πà‡∏¢‡∏≤‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô
- ‡∏ï‡∏±‡∏î‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏´‡πâ‡∏™‡∏±‡πâ‡∏ô‡∏•‡∏á

‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏Ç‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô ‡πÅ‡∏•‡∏∞‡∏ö‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ô‡∏±‡πâ‡∏ô‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ó‡∏µ‡πà‡∏¢‡∏≤‡∏ß‡πÜ [Longformer](https://huggingface.co/transformers/model_doc/longformer.html) ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á ‡πÅ‡∏•‡∏∞‡∏≠‡∏µ‡∏Å‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡πá‡∏Ñ‡∏∑‡∏≠ [LED](https://huggingface.co/transformers/model_doc/led.html) ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ó‡∏µ‡πà‡∏¢‡∏≤‡∏ß‡∏°‡∏≤‡∏Å‡πÜ ‡πÄ‡∏£‡∏≤‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡∏ì‡∏•‡∏≠‡∏á‡∏î‡∏π‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô

‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ô‡∏ó‡∏≤‡∏á‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô‡∏Ç‡πâ‡∏≤‡∏° ‡πÄ‡∏£‡∏≤‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡∏ì‡∏ï‡∏±‡∏î‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏´‡πâ‡∏™‡∏±‡πâ‡∏ô‡∏•‡∏á‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£‡∏£‡∏∞‡∏ö‡∏∏‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ `max_sequence_length: 

```py
sequence = sequence[:max_sequence_length]
```
