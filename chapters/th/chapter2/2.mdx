<FrameworkSwitchCourse {fw} />

# ‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏á‡∏Ç‡∏≠‡∏á pipeline

{#if fw === 'pt'}

<CourseFloatingBanner chapter={2}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/th/chapter2/section2_pt.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/th/chapter2/section2_pt.ipynb"},
]} />

{:else}

<CourseFloatingBanner chapter={2}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/th/chapter2/section2_tf.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/th/chapter2/section2_tf.ipynb"},
]} />

{/if}

<Tip>
Section ‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô Section ‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏à‡∏∞‡∏Ñ‡πà‡∏≠‡∏ô‡∏Ç‡πâ‡∏≤‡∏á‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏±‡∏ö‡∏ß‡πà‡∏≤‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏ä‡πâ PyTorch ‡∏´‡∏£‡∏∑‡∏≠ TensorFlow ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å plateform ‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å‡∏õ‡∏∏‡πà‡∏°‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô‡∏Ç‡∏≠‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠!
</Tip>

{#if fw === 'pt'}
<Youtube id="1pedAIvTWXk"/>
{:else}
<Youtube id="wVN12smEvqg"/>
{/if}

‡πÄ‡∏£‡∏≤‡∏°‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏±‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ ‡πÇ‡∏î‡∏¢‡πÄ‡∏£‡∏≤‡∏°‡∏≤‡∏î‡∏π‡∏Å‡∏±‡∏ô‡∏ß‡πà‡∏≤‡πÄ‡∏Å‡∏¥‡∏î‡∏≠‡∏∞‡πÑ‡∏£‡∏Ç‡∏∂‡πâ‡∏ô‡πÉ‡∏ô‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏≤‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏™‡∏±‡πà‡∏á‡∏Å‡∏≤‡∏£(executed) ‡πÇ‡∏Ñ‡πâ‡∏î‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡∏à‡∏≤‡∏Å [Chapter 1](/course/chapter1):

```python
from transformers import pipeline

classifier = pipeline("sentiment-analysis")
classifier(
    [
        "I've been waiting for a HuggingFace course my whole life.",
        "I hate this so much!",
    ]
)
```

‡πÅ‡∏•‡∏∞ ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ:

```python out
[{'label': 'POSITIVE', 'score': 0.9598047137260437},
 {'label': 'NEGATIVE', 'score': 0.9994558095932007}]
```

‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÄ‡∏´‡πá‡∏ô‡πÉ‡∏ô [Chapter 1](/course/chapter1), pipeline ‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°‡πÄ‡∏≠‡∏≤ 3 ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô : ‡πÅ(preprocessing), ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•, ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• (postprocessing)

<div class="flex justify-center">
<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/full_nlp_pipeline.svg" alt="The full NLP pipeline: tokenization of text, conversion to IDs, and inference through the Transformer model and the model head."/>
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/full_nlp_pipeline-dark.svg" alt="The full NLP pipeline: tokenization of text, conversion to IDs, and inference through the Transformer model and the model head."/>
</div>

‡πÄ‡∏£‡∏≤‡∏°‡∏≤‡∏î‡∏π‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏Å‡∏±‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏•‡∏¢‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤

## ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πâ‡∏ô(Preprocessing) ‡∏î‡πâ‡∏ß‡∏¢ tokenizer

‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏Ç‡πà‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó(neural networks) ‡∏≠‡∏∑‡πà‡∏ô‡πÜ, ‡πÇ‡∏°‡πÄ‡∏î‡∏• Transformer ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°(text) ‡πÑ‡∏î‡πâ‡∏ï‡∏£‡∏á‡πÜ ‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡πÅ‡∏£‡∏Å‡∏Ç‡∏≠‡∏á pipeline ‡∏Å‡πá‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç(numbers) ‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ô‡∏±‡πâ‡∏ô‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏î‡πâ ‡πÉ‡∏ô‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ *tokenizer* ‡∏ã‡∏∂‡πà‡∏á‡∏à‡∏∞‡∏£‡∏±‡∏ö‡∏ú‡∏¥‡∏î‡∏ä‡∏≠‡∏ö‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ :

- ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô ‡∏Ñ‡∏≥(words), ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏¢‡πà‡∏≠‡∏¢‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥ (subwords), ‡∏´‡∏£‡∏∑‡∏≠ ‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå (‡πÄ‡∏ä‡πà‡∏ô ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢‡∏ß‡∏£‡∏£‡∏Ñ‡∏ï‡∏≠‡∏ô (punctuation)) ‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ß‡πà‡∏≤ *token*
- ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á (Mapping) ‡πÅ‡∏ï‡πà‡∏•‡∏∞ token ‡πÑ‡∏õ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç (integer)
- ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•

‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πâ‡∏ô(preprocessing) ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ô‡∏µ‡πâ‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÉ‡∏ô‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ö‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡∏°‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ(pretrained), ‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡∏Ñ‡∏∑‡∏≠‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å [Model Hub](https://huggingface.co/models) ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ô‡∏µ‡πâ ‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Ñ‡∏•‡∏≤‡∏™ `AutoTokenizer` ‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÄ‡∏°‡∏ò‡∏≠‡∏î `from_pretrained()` ‡πÇ‡∏î‡∏¢‡∏´‡∏≤‡∏Å‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠ checkpoint ‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÄ‡∏°‡∏ò‡∏≠‡∏î `from_pretrained()` ‡∏à‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö tokenizer ‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏°‡∏≤‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ(‡∏à‡∏∞‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏£‡∏±‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô)

‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å checkpoint ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô(default) ‡∏Ç‡∏≠‡∏á `sentiment-analysis` pipeline ‡∏Ñ‡∏∑‡∏≠  `distilbert-base-uncased-finetuned-sst-2-english` (‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏π model card [‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)), ‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏£‡∏±‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏ô‡∏µ‡πâ:

```python
from transformers import AutoTokenizer

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
```

‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏≤‡∏°‡∏µ tokenizer ‡πÅ‡∏•‡πâ‡∏ß ‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏™‡πà‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÑ‡∏î‡πâ‡∏™‡∏≤‡∏£‡∏≤‡∏ô‡∏∏‡∏Å‡∏£‡∏°(dictionary) ‡∏ó‡∏µ‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ô‡∏≥‡πÑ‡∏õ‡πÉ‡∏™‡πà‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏≠‡∏Å‡∏°‡∏≤! ‡∏™‡∏¥‡πà‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥ ‡∏Ñ‡∏∑‡∏≠ ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏±‡∏ï‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå(IDs) ‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏™‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ(input) ‡πÑ‡∏õ‡πÄ‡∏õ‡πá‡∏ô tensors

‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ ü§ó Transformers ‡πÇ‡∏î‡∏¢‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏á‡∏ß‡∏•‡πÄ‡∏•‡∏¢‡∏ß‡πà‡∏≤ ML framework ‡∏ï‡∏±‡∏ß‡πÑ‡∏´‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô backend; ‡∏°‡∏±‡∏ô‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô PyTorch ‡∏´‡∏£‡∏∑‡∏≠ TensorFlow, ‡∏´‡∏£‡∏∑‡∏≠ Flax ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÅ‡∏ï‡πà‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡∏Å‡πá‡∏ï‡∏≤‡∏°‡πÇ‡∏°‡πÄ‡∏î‡∏• Transformer ‡∏à‡∏∞‡∏£‡∏±‡∏ö‡πÄ‡∏û‡∏µ‡∏¢‡∏á *tensor* ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏™‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ(input) ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡∏ñ‡πâ‡∏≤‡∏ô‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏î‡πâ‡∏¢‡∏¥‡∏ô‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ tensor ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏°‡∏±‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô NumPy arrays ‡πÅ‡∏ó‡∏ô‡∏Å‡πá‡πÑ‡∏î‡πâ ‡πÇ‡∏î‡∏¢‡∏ó‡∏µ‡πà NumPy array ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏î‡πâ‡∏ó‡∏±‡πâ‡∏á scalar (0D), vector (1D), matrix (2D), ‡∏´‡∏£‡∏∑‡∏≠‡∏°‡∏µ‡∏´‡∏•‡∏≤‡∏¢‡πÜ‡∏°‡∏¥‡∏ï‡∏¥. ‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏Å‡πá‡∏Ñ‡∏∑‡∏≠ tensor ‡∏î‡∏µ‡πÜ‡∏ô‡∏µ‡πà‡πÄ‡∏≠‡∏á  tensor ‡∏Ç‡∏≠‡∏á ML frameworks ‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏Å‡πá‡∏°‡∏µ‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡πÜ‡∏Å‡∏±‡∏ô ‡πÅ‡∏•‡∏∞‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô NumPy arrays 

‡∏Å‡∏≤‡∏£‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á tensor ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÑ‡∏î‡πâ‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤ (PyTorch, TensorFlow, ‡∏´‡∏£‡∏∑‡∏≠ NumPy) ‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£(argument) `return_tensors`:

{#if fw === 'pt'}
```python
raw_inputs = [
    "I've been waiting for a HuggingFace course my whole life.",
    "I hate this so much!",
]
inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors="pt")
print(inputs)
```
{:else}
```python
raw_inputs = [
    "I've been waiting for a HuggingFace course my whole life.",
    "I hate this so much!",
]
inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors="tf")
print(inputs)
```
{/if}

‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏á‡∏ß‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°(padding) ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏≠‡∏≠‡∏Å(truncation) ‡πÉ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á ‡∏™‡∏¥‡πà‡∏á‡∏´‡∏•‡∏±‡∏Å‡πÜ ‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏à‡∏≥‡∏Ñ‡∏∑‡∏≠ ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏™‡πà‡∏á‡∏ú‡πà‡∏≤‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ ‡∏´‡∏£‡∏∑‡∏≠ ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£(list)‡∏Ç‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏£‡∏∞‡∏ö‡∏∏‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á tensor ‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÑ‡∏î‡πâ‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤(‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó ‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡πÑ‡∏î‡πâ‡∏ú‡∏•‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô list of lists)

{#if fw === 'pt'}

‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô tensor ‡∏Ç‡∏≠‡∏á PyTorch ‡∏Å‡πá‡∏à‡∏∞‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏≤‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏ô‡∏µ‡πâ

```python out
{
    'input_ids': tensor([
        [  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172, 2607,  2026,  2878,  2166,  1012,   102],
        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,     0,     0,     0,     0,     0,     0]
    ]), 
    'attention_mask': tensor([
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]
    ])
}
```
{:else}

‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô tensor ‡∏Ç‡∏≠‡∏á PyTorch ‡∏Å‡πá‡∏à‡∏∞‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏≤‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏ô‡∏µ‡πâ

```python out
{
    'input_ids': <tf.Tensor: shape=(2, 16), dtype=int32, numpy=
        array([
            [  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,  2607,  2026,  2878,  2166,  1012,   102],
            [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,     0,     0,     0,     0,     0,     0]
        ], dtype=int32)>, 
    'attention_mask': <tf.Tensor: shape=(2, 16), dtype=int32, numpy=
        array([
            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
            [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]
        ], dtype=int32)>
}
```
{/if}

‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≤‡∏£‡∏≤‡∏ô‡∏∏‡∏Å‡∏£‡∏°(dictionary) ‡∏ó‡∏µ‡πà‡∏°‡∏µ 2 ‡∏Ñ‡∏µ‡∏¢‡πå(keys), `input_ids` ‡πÅ‡∏•‡∏∞ `attention_mask` ‡πÇ‡∏î‡∏¢‡∏ó‡∏µ‡πà `input_ids` ‡∏à‡∏∞‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç(integers)‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏≠‡∏á‡πÅ‡∏ñ‡∏ß (‡∏´‡∏ô‡∏∂‡πà‡∏á‡πÅ‡∏ñ‡∏ß‡∏ï‡πà‡∏≠‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ) ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏±‡∏ï‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á‡∏Ç‡∏≠‡∏á token ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ ‡∏™‡πà‡∏ß‡∏ô `attention_mask` ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÉ‡∏ô‡∏ö‡∏ó‡∏ô‡∏µ‡πâ‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏ô‡∏µ‡πâ

## ‡∏°‡∏≤‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Å‡∏±‡∏ô

{#if fw === 'pt'}
‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß(pretrained) ‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏ó‡∏≥‡∏Å‡∏±‡∏ö tokenizer ‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤ ü§ó Transformers ‡∏°‡∏µ‡∏Ñ‡∏•‡∏≤‡∏™ `AutoModel` ‡∏ã‡∏∂‡πà‡∏á‡∏Å‡πá‡∏°‡∏µ‡πÄ‡∏°‡∏ò‡∏≠‡∏î `from_pretrained()` ‡πÄ‡∏ä‡πà‡∏ô‡∏Å‡∏±‡∏ô:

```python
from transformers import AutoModel

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
model = AutoModel.from_pretrained(checkpoint)
```
{:else}
‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß(pretrained) ‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏ó‡∏≥‡∏Å‡∏±‡∏ö tokenizer ‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤ ü§ó Transformers ‡∏°‡∏µ‡∏Ñ‡∏•‡∏≤‡∏™ `TFAutoModel` ‡∏ã‡∏∂‡πà‡∏á‡∏Å‡πá‡∏°‡∏µ‡πÄ‡∏°‡∏ò‡∏≠‡∏î `from_pretrained()` ‡πÄ‡∏ä‡πà‡∏ô‡∏Å‡∏±‡∏ô:

```python
from transformers import TFAutoModel

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
model = TFAutoModel.from_pretrained(checkpoint)
```
{/if}

‡πÉ‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÇ‡∏Ñ‡πâ‡∏î‡∏ô‡∏µ‡πâ ‡πÄ‡∏£‡∏≤‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î checkpoint ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÉ‡∏ä‡πâ‡πÉ‡∏ô pipeline ‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ (‡∏°‡∏±‡∏ô‡∏ô‡πà‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡πá‡∏ö(cached)‡πÑ‡∏ß‡πâ‡πÅ‡∏•‡πâ‡∏ß) ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô

‡πÉ‡∏ô‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏°‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏°‡∏µ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÇ‡∏°‡∏î‡∏π‡∏• Transformer ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô: ‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ ‡πÅ‡∏•‡∏∞‡∏°‡∏±‡∏ô‡πÉ‡∏´‡πâ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ß‡πà‡∏≤ *hidden states* ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤ ‡∏´‡∏£‡∏∑‡∏≠‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å‡∏Å‡∏±‡∏ô‡πÉ‡∏ô‡∏ô‡∏≤‡∏° *features* ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏´‡∏≤‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏´‡∏•‡∏≤‡∏¢‡∏°‡∏¥‡∏ï‡∏¥(high-dimensional vector) ‡∏ó‡∏µ‡πà‡∏ö‡πà‡∏á‡∏ö‡∏≠‡∏Å **‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏™‡∏†‡∏≤‡∏ß‡∏∞‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏±‡πâ‡∏ô‡πÇ‡∏î‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• Transformer**

‡∏ñ‡πâ‡∏≤‡∏ô‡∏µ‡πâ‡∏ü‡∏±‡∏á‡∏î‡∏π‡πÑ‡∏°‡πà‡∏™‡∏°‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏°‡∏ú‡∏• ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏á‡∏ß‡∏• ‡πÄ‡∏î‡∏µ‡πã‡∏¢‡∏ß‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ó‡∏±‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á

‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ó‡∏µ‡πà hidden states ‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡πÉ‡∏ô‡∏ï‡∏±‡∏ß‡∏°‡∏±‡∏ô‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß ‡∏°‡∏±‡∏ô‡πÄ‡∏•‡∏¢‡∏ñ‡∏π‡∏Å‡∏ô‡∏≥‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏™‡πà‡∏ß‡∏ô‡∏≠‡∏∑‡πà‡∏ô‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢ ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å‡∏Å‡∏±‡∏ô‡πÉ‡∏ô‡∏ô‡∏≤‡∏° *head* ‡πÉ‡∏ô [Chapter 1](/course/chapter1), ‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏°‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡πÑ‡∏î‡πâ ‡πÅ‡∏ï‡πà‡∏á‡∏≤‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏à‡∏∞‡∏°‡∏µ‡∏™‡πà‡∏ß‡∏ô‡∏´‡∏±‡∏ß(head)‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡πÑ‡∏õ

### ‡πÄ‡∏ß‡∏Ñ‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏´‡∏•‡∏≤‡∏¢‡∏°‡∏¥‡∏ï‡∏¥ (A high-dimensional vector) ?

‡πÄ‡∏ß‡∏≠‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡∏î‡∏π‡∏•‡∏Ç‡∏≠‡∏á Transformer ‡∏ô‡∏±‡πâ‡∏ô‡∏õ‡∏Å‡∏ï‡∏¥‡∏à‡∏∞‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà ‡πÇ‡∏î‡∏¢‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡πÅ‡∏•‡πâ‡∏ß‡∏°‡∏±‡∏ô‡∏à‡∏∞‡∏°‡∏µ 3 ‡∏°‡∏¥‡∏ï‡∏¥:

- **‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡∏≠‡∏á‡∏ä‡∏∏‡∏î(‡∏∫Batch size)**: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• (2 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÉ‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤)
- **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏Ç‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ(Sequence length)**: ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏Ç‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÅ‡∏ó‡∏ô‡∏Ç‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ (16 ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÉ‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤)
- **‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡∏≠‡∏á Hidden states (Hidden size)**: ‡∏°‡∏¥‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á‡πÄ‡∏ß‡∏Ñ‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•

‡∏°‡∏±‡∏ô‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡∏°‡∏±‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏Ñ‡πÄ‡∏ï‡∏≠‡∏£‡πå "‡∏´‡∏•‡∏≤‡∏¢‡∏°‡∏¥‡∏ï‡∏¥(high dimensional)" ‡∏Å‡πá‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏Ñ‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ ‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡∏≠‡∏á hidden states ‡∏ô‡∏±‡πâ‡∏ô‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î‡∏ó‡∏µ‡πà‡πÉ‡∏´‡∏ç‡πà‡∏°‡∏≤‡∏Å(786 ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ô‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å, ‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà‡∏ô‡∏±‡πâ‡∏ô‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ç‡∏∂‡πâ‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ‡∏ñ‡∏∂‡∏á 3072 ‡∏´‡∏£‡∏∑‡∏≠‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô)

‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÄ‡∏´‡πá‡∏ô‡πÑ‡∏î‡πâ‡∏ß‡πà‡∏≤‡∏ñ‡πâ‡∏≤‡πÄ‡∏£‡∏≤‡πÉ‡∏™‡πà‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤:

{#if fw === 'pt'}
```python
outputs = model(**inputs)
print(outputs.last_hidden_state.shape)
```

```python out
torch.Size([2, 16, 768])
```
{:else}
```py
outputs = model(inputs)
print(outputs.last_hidden_state.shape)
```

```python out
(2, 16, 768)
```
{/if}

‡∏à‡∏∞‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• ü§ó Transformers ‡∏ô‡∏±‡πâ‡∏ô‡∏à‡∏∞‡∏°‡∏µ‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ö `namedtuple`s ‡∏´‡∏£‡∏∑‡∏≠ dictionaries ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏≠‡∏á‡∏Ñ‡πå‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏ï‡πà‡∏≤‡∏á(elements) ‡πÑ‡∏î‡πâ‡∏î‡πâ‡∏ß‡∏¢ attributes (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏ó‡∏≥) ‡∏´‡∏£‡∏∑‡∏≠‡∏î‡πâ‡∏ß‡∏¢ key (`outputs["last_hidden_state"]`) ‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏°‡πâ‡∏Å‡∏£‡∏∞‡∏ó‡∏±‡πà‡∏á‡∏î‡πâ‡∏ß‡∏¢ index ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏£‡∏π‡πâ‡∏ß‡πà‡∏≤‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏°‡∏≠‡∏á‡∏´‡∏≤‡∏ô‡∏±‡πâ‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏ï‡∏£‡∏á‡πÑ‡∏´‡∏ô (`outputs[0]`)

### Model heads: ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏à‡∏≤‡∏Å‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç

‡πÇ‡∏°‡πÄ‡∏î‡∏• heads ‡∏£‡∏±‡∏ö‡πÄ‡∏ß‡∏Ñ‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏´‡∏•‡∏≤‡∏¢‡∏°‡∏¥‡∏ï‡∏¥(high-dimensional) ‡∏Ç‡∏≠‡∏á hidden states ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÅ‡∏•‡∏∞‡∏à‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡πÄ‡∏ß‡∏Ñ‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏î‡∏±‡∏á‡∏Å‡∏•‡πà‡∏≤‡∏ß‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡∏°‡∏¥‡∏ï‡∏¥‡∏≠‡∏∑‡πà‡∏ô ‡∏ã‡∏∂‡πà‡∏á‡πÇ‡∏î‡∏¢‡∏õ‡∏Å‡∏ï‡∏¥‡πÇ‡∏°‡πÄ‡∏î‡∏• heads ‡∏à‡∏∞‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏•‡πÄ‡∏¢‡∏≠‡∏£‡πå‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏™‡πâ‡∏ô(linear layers) ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢‡∏´‡∏ô‡∏∂‡πà‡∏á‡πÄ‡∏•‡πÄ‡∏¢‡∏≠‡∏£‡πå:

<div class="flex justify-center">
<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/transformer_and_head.svg" alt="A Transformer network alongside its head."/>
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/transformer_and_head-dark.svg" alt="A Transformer network alongside its head."/>
</div>

‡πÄ‡∏≠‡∏≤‡∏ó‡πå‡∏û‡∏∏‡∏ï‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• Transformer ‡∏à‡∏∞‡∏™‡πà‡∏á‡∏ï‡∏£‡∏á‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡∏´‡∏±‡∏ß‡πÇ‡∏°‡πÄ‡∏î‡∏•(model head)‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•

‡πÉ‡∏ô‡πÑ‡∏î‡∏≠‡∏∞‡πÅ‡∏Å‡∏£‡∏°‡∏ô‡∏µ‡πâ ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏•‡πÄ‡∏¢‡∏≠‡∏£‡πå‡∏ù‡∏±‡∏á‡∏ï‡∏±‡∏ß(embeddings layer) ‡πÅ‡∏•‡∏∞‡πÄ‡∏•‡πÄ‡∏¢‡∏≠‡∏£‡πå‡∏¢‡πà‡∏≠‡∏¢(subsequent layers) ‡∏Ç‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡∏°‡∏±‡∏ô‡πÄ‡∏≠‡∏á ‡πÇ‡∏î‡∏¢‡πÄ‡∏•‡πÄ‡∏¢‡∏≠‡∏£‡πå‡∏ù‡∏±‡∏á‡∏ï‡∏±‡∏ß(embeddings layer) ‡∏à‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏ï‡∏±‡∏ß‡∏ö‡πà‡∏á‡∏ä‡∏µ‡πâ‡∏ï‡∏±‡∏ß‡∏ï‡∏ô‡∏Ç‡∏≠‡∏á‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï(Input ID) ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô tokenized ‡πÑ‡∏õ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏Ñ‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÅ‡∏ó‡∏ô‡∏Ç‡∏≠‡∏á token ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á ‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏•‡πÄ‡∏¢‡∏≠‡∏£‡πå‡∏¢‡πà‡∏≠‡∏¢‡∏≠‡∏∑‡πà‡∏ô‡πÜ‡∏à‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏ß‡∏Ñ‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏≠‡∏∑‡πà‡∏ô‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£ attention ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏ã‡∏∂‡πà‡∏á‡∏ï‡∏±‡∏ß‡πÅ‡∏ó‡∏ô(representation) ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ

‡∏°‡∏µ‡∏´‡∏•‡∏≤‡∏¢‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏°‡πÉ‡∏ô ü§ó Transformers ‡πÇ‡∏î‡∏¢‡∏ó‡∏µ‡πà‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏°‡∏ñ‡∏π‡∏Å‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏á‡∏≤‡∏ô ‡∏ô‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏™‡πà‡∏ß‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡πÜ‡πÇ‡∏°‡πÄ‡∏î‡∏• :

- `*Model` (retrieve the hidden states)
- `*ForCausalLM`
- `*ForMaskedLM`
- `*ForMultipleChoice`
- `*ForQuestionAnswering`
- `*ForSequenceClassification`
- `*ForTokenClassification`
- and others ü§ó

{#if fw === 'pt'}
‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ head ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ(sequence classification) (‡πÇ‡∏î‡∏¢‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÄ‡∏ä‡∏¥‡∏á‡∏ö‡∏ß‡∏Å ‡∏´‡∏£‡∏∑‡∏≠ ‡∏•‡∏ö) ‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ‡∏Ñ‡∏•‡∏≤‡∏™ `AutoModel` ‡πÅ‡∏ï‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ  `AutoModelForSequenceClassification`:

```python
from transformers import AutoModelForSequenceClassification

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
model = AutoModelForSequenceClassification.from_pretrained(checkpoint)
outputs = model(**inputs)
```
{:else}
‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ head ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ(sequence classification) (‡πÇ‡∏î‡∏¢‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÄ‡∏ä‡∏¥‡∏á‡∏ö‡∏ß‡∏Å ‡∏´‡∏£‡∏∑‡∏≠ ‡∏•‡∏ö) ‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ‡∏Ñ‡∏•‡∏≤‡∏™ `TFAutoModel` ‡πÅ‡∏ï‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ `TFAutoModelForSequenceClassification`:

```python
from transformers import TFAutoModelForSequenceClassification

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)
outputs = model(inputs)
```
{/if}

‡∏ñ‡πâ‡∏≤‡πÄ‡∏£‡∏≤‡∏î‡∏π‡∏ó‡∏µ‡πà‡∏Ç‡∏ô‡∏≤‡∏î(shape) ‡∏Ç‡∏≠‡∏á‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï ‡∏°‡∏¥‡∏ï‡∏¥(dimensionality)‡∏à‡∏∞‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤‡∏°‡∏≤‡∏Å : model head ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ö‡πÄ‡∏≠‡∏≤‡πÄ‡∏ß‡∏Ñ‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏Ç‡∏ô‡∏≤‡∏î‡∏´‡∏•‡∏≤‡∏¢‡∏°‡∏¥‡∏ï‡∏¥‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÄ‡∏´‡πá‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ ‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡πÄ‡∏≠‡∏≤‡∏ó‡πå‡∏û‡∏∏‡∏ï‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏Ñ‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏™‡∏≠‡∏á‡∏Ñ‡πà‡∏≤ (‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≠‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå(label)) :

```python
print(outputs.logits.shape)
```

{#if fw === 'pt'}
```python out
torch.Size([2, 2])
```
{:else}
```python out
(2, 2)
```
{/if}

‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏£‡∏≤‡∏°‡∏µ‡πÅ‡∏Ñ‡πà‡∏™‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÅ‡∏•‡∏∞‡∏™‡∏≠‡∏á‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå(labels) ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏à‡∏∂‡∏á‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î 2x2

## ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏î‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß (Postprocessing)

‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ô‡∏±‡πâ‡∏ô‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏î‡∏π‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏´‡∏ï‡∏∏‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏•‡πÉ‡∏ô‡∏ï‡∏±‡∏ß‡∏°‡∏±‡∏ô‡πÄ‡∏≠‡∏á ‡πÄ‡∏î‡∏µ‡πã‡∏¢‡∏ß‡πÄ‡∏£‡∏≤‡∏•‡∏≠‡∏á‡∏°‡∏≤‡∏î‡∏π‡∏Å‡∏±‡∏ô:

```python
print(outputs.logits)
```

{#if fw === 'pt'}
```python out
tensor([[-1.5607,  1.6123],
        [ 4.1692, -3.3464]], grad_fn=<AddmmBackward>)
```
{:else}
```python out
<tf.Tensor: shape=(2, 2), dtype=float32, numpy=
    array([[-1.5606991,  1.6122842],
           [ 4.169231 , -3.3464472]], dtype=float32)>
```
{/if}

‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ `[-1.5607, 1.6123]` ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÅ‡∏£‡∏Å ‡πÅ‡∏•‡∏∞ `[ 4.1692, -3.3464]` ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á ‡∏Ñ‡πà‡∏≤‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô(probabilities) ‡πÅ‡∏ï‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤ *logits* ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏î‡∏¥‡∏ö‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£ normalized ‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡πÄ‡∏•‡πÄ‡∏¢‡∏≠‡∏£‡πå‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÑ‡∏õ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô(probabilities) ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏•‡πÄ‡∏¢‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏ä‡∏∑‡πà‡∏≠‡∏ß‡πà‡∏≤ [SoftMax](https://en.wikipedia.org/wiki/Softmax_function) (‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏≠‡∏á ü§ó Transformers ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡∏à‡∏∞‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô logits ‡πÇ‡∏î‡∏¢‡∏ó‡∏µ‡πà loss function ‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏° activation function ‡∏Ç‡∏≠‡∏á‡πÄ‡∏•‡πÄ‡∏¢‡∏≠‡∏£‡πå‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ ‡πÄ‡∏ä‡πà‡∏ô SoftMax ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö loss function ‡∏´‡∏•‡∏±‡∏Å ‡πÄ‡∏ä‡πà‡∏ô cross entropy):

{#if fw === 'pt'}
```py
import torch

predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
print(predictions)
```
{:else}
```py
import tensorflow as tf

predictions = tf.math.softmax(outputs.logits, axis=-1)
print(predictions)
```
{/if}

{#if fw === 'pt'}
```python out
tensor([[4.0195e-02, 9.5980e-01],
        [9.9946e-01, 5.4418e-04]], grad_fn=<SoftmaxBackward>)
```
{:else}
```python out
tf.Tensor(
[[4.01951671e-02 9.59804833e-01]
 [9.9945587e-01 5.4418424e-04]], shape=(2, 2), dtype=float32)
```
{/if}

‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ `[0.0402, 0.9598]` ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÅ‡∏£‡∏Å ‡πÅ‡∏•‡∏∞ `[0.9995,  0.0005]` ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á ‡∏ã‡∏∂‡πà‡∏á‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô(probabilities score) ‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ô‡∏≥‡πÑ‡∏õ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡πÑ‡∏î‡πâ

‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå(label) ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á ‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏π‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥ `id2label` ‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• model config (‡πÄ‡∏î‡∏µ‡πã‡∏¢‡∏ß‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏ô section ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ):

```python
model.config.id2label
```

```python out
{0: 'NEGATIVE', 1: 'POSITIVE'}
```

‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏™‡∏£‡∏∏‡∏õ‡πÑ‡∏î‡πâ‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏î‡∏±‡∏á‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ

- ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÅ‡∏£‡∏Å: NEGATIVE: 0.0402, POSITIVE: 0.9598
- ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á: NEGATIVE: 0.9995, POSITIVE: 0.0005

‡∏ñ‡∏∂‡∏á‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏•‡∏≠‡∏á‡∏ó‡∏≥ ‡∏™‡∏≤‡∏° ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Ç‡∏≠‡∏á pipeline: ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô(preprocessing)‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ tokenizers, ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•,‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•! ‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÑ‡∏õ‡∏•‡∏á‡∏•‡∏∂‡∏Å‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô

<Tip>

‚úèÔ∏è **‡∏•‡∏≠‡∏á‡πÄ‡∏•‡∏¢!** ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡∏≠‡∏á(‡∏´‡∏£‡∏∑‡∏≠‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô) ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏•‡∏≠‡∏á‡πÉ‡∏™‡πà‡∏°‡∏±‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô `sentiment-analysis` pipeline. ‡πÅ‡∏•‡πâ‡∏ß‡∏ó‡∏≥‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ú‡πà‡∏≤‡∏ô‡∏°‡∏≤‡πÉ‡∏ô section ‡∏ô‡∏µ‡πâ‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏î‡∏π‡∏ß‡πà‡∏≤‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏î‡πâ‡∏ú‡∏•‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà!

</Tip>
