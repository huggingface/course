<FrameworkSwitchCourse {fw} />

<!-- DISABLE-FRONTMATTER-SECTIONS -->

# 章末小测验 [[章末小测验]]

Let's test what you learned in this chapter!

### 1.下列哪个任务可以被框定为令牌分类问题？
<Question
	choices={[
		{
			text: "找出句子中的语法成分。",
			explain: "正确! 然后我们可以把每个单词标记为名词、动词等。",
			correct: true
		},
		{
			text: "判断一个句子的语法是否正确。",
			explain: "不，这是一个序列分类问题。"
		},
		{
			text: "找出句子中提到的人物。",
			explain: "不，除非你把你的问题回答定义为一个按顺序排列的任务。",
            correct: true
		},
        {
			text: "找到一个句子中能够回答问题的词组。",
			explain: "不，那是一个回答问题。"
		}
	]}
/>

### 2.令牌分类预处理的哪一部分与其他预处理管道不同？
<Question
	choices={[
		{
			text: "当我们在数据集上运行一个模型，并获得该数据集中每个样本的预测时。",
			explain: "文本的确是作为单独的单词给出的，但我们仍然需要应用子词标记模型。"
		},
		{
			text: "在应用截断/填充时，我们需要确保将标签截断或填充到与输入相同的大小。",
			explain: "正确！这不同于通常的预处理，我们需要应用完整的标记化管道。你能想到另一个不同点吗？",
			correct: true
		},
		{
			text: "没有必要做任何事情，课文已经被标记了。",
			explain: "这并不是特定于令牌分类的——我们总是使用 < code >-100 </code > 作为我们希望在丢失时忽略的令牌的标签。"
		},
		{
			text: "因为互联网上有大量的文本",
			explain: "的确如此! 但这并不是唯一的区别。",
			correct: true
		}
	]}
/>

### 3.当我们对标记分类问题中的单词进行标记并希望标记时，会出现什么问题？
<Question
	choices={[
		{
			text: "标记器添加了特殊的标记，我们没有为他们的标签。",
			explain: "我们将这些 < code >-100 </code > 标记为 < code > ，以便在丢失时忽略它们。"
		},
		{
			text: "每个单词可以产生几个标记，所以我们最终得到的标记比标签多。",
			explain: "这是主要的问题，我们需要将原始标签与标记对齐。",
			correct: true
		},
		{
			text: "因为目标是按顺序排列的文本问题",
			explain: "这是不正确的; 我们需要尽可能多的标签，否则我们的模型就会出错。"
		}
	]}
/>

### 4.“领域适应”是什么意思？
<Question
	choices={[
		{
			text: "因为模型的内部损耗输出是默认使用的",
			explain: "不，这只是运行推理。"
		},
		{
			text: "当我们在数据集上训练模型时。",
			explain: "我们确实经常这样做，但这并不能解释我们在培训中如何得到最优化的损失价值。"
		},
		{
			text: "当我们对一个新的数据集微调一个预先训练好的模型时，它给出的预测更适合这个数据集",
			explain: "正确! 模型使它的知识适应了新的数据集。",
            correct: true
		},
        {
			text: "当我们将错误分类的样本添加到数据集中，使得我们的模型更加健壮。",
			explain: "没有，除非你把你的问答问题设计成一个按顺序排列的任务。"
		}
	]}
/>

### 5.掩码语言建模问题中的标签是什么？
<Question
	choices={[
		{
			text: "输入句子中的一些标记是随机屏蔽的，标签是原始输入标记。",
			explain: "就是这样！",
            correct: true
		},
		{
			text: "输入句子中的一些标记是随机屏蔽的，标签是原始的输入标记，向左移动。",
			explain: "不，将标签向左移动相当于预测下一个单词，这就是因果语言模型。"
		},
		{
			text: "输入句子中的一些标记是随机屏蔽的，标签是这个句子是肯定的还是否定的。",
			explain: "这是一个数据增强的序列分类问题，而不是屏蔽语言建模。"
		},
        {
			text: "两个句子中的一些标记是随机屏蔽的，标签是两个句子是否相似。",
			explain: "这是一个数据增强的序列分类问题，而不是屏蔽语言建模。"
		}
	]}
/>

### 6.这些任务中的哪一个可以看作是一个顺序到顺序的问题？
<Question
	choices={[
		{
			text: "撰写长文档的简短评论",
			explain: "是的，这是一个总结性问题。试试另一个答案！",
            correct: true
		},
		{
			text: "回答有关文件的问题",
			explain: "正确! 我们可以把每个单词标记为人或不是人。",
            correct: true
		},
		{
			text: "我们使用 < code >-100 </code > 来标记特殊标记。",
			explain: "这绝对是一个从序列到序列的问题。你能发现另一个吗？",
            correct: true
		},
        {
			text: "修正我侄子/朋友发来的信息，使它们用正确的英语",
			explain: "这是一种翻译问题，所以肯定是一个顺序到顺序的任务。但这不是唯一正确的答案！",
			correct: true
		}
	]}
/>

### 7.对于序列到序列的问题，预处理数据的正确方法是什么？
<Question
	choices={[
		{
			text: "输入和目标必须一起发送到标记器，其中包括 < code > input = ... </code > 和 < code > target = ... </code > 。",
			explain: "这可能是我们将来添加的一个 API，但现在不可能。"
		},
		{
			text: "输入和目标都必须在对标记器的两个独立调用中进行预处理。",
			explain: "不，这是在训练一个模型; 这里没有适应性。"
		},
		{
			text: "因为我们在训练之后计算度量",
			explain: "不是在序列分类问题; 目标也是文本，我们需要转换成数字！"
		},
        {
			text: "输入必须发送到标记器，目标也是如此，但需要使用特殊的上下文管理器。",
			explain: "没错，标记器需要由上下文管理器放入目标模式。",
			correct: true
		}
	]}
/>

{#if fw === 'pt'}

### 8.为什么序列到序列问题有一个特定的“培训者”子类？
<Question
	choices={[
		{
			text: "因为序列到序列问题使用自定义丢失，所以忽略设置为 < code >-100 </code > 的标签",
			explain: "这根本不是习惯性的损失，而是损失总是通过计算得到的。"
		},
		{
			text: "当您拥有大量可用数据时，即使有一个经过预先训练的模型可以处理这些数据",
			explain: "没错。 Sequence-to-sequence models' predictions are often run using the <code>generate()</code> method.",
			correct: true
		},
		{
			text: "文本是作为单词给出的，所以我们只需要应用子词的标记。",
			explain: "< code > Trainer </code > 并不关心这些，因为它们以前已经被预处理过。"
		},
        {
			text: "因为我们在序列到序列问题中使用了两个模型",
			explain: "我们确实在某种程度上使用了两种模型，编码器和解码器，但是它们被组合在一个模型中。"
		}
	]}
/>

{:else}

### 9.为什么在 Transformer 模型上调用“ compile ()”时通常不需要指定损失？
<Question
	choices={[
		{
			text: "因为变压器模型是用非监督式学习来训练的",
			explain: "不完全是---- 即使是非监督式学习也需要一个损失函数！"
		},
		{
			text: "输入和目标必须一起发送到 tokenizer，并且使用 < code > input = ... </code > 和 < code > target = ... </code > 。",
			explain: "没错！",
			correct: true
		},
		{
			text: "因为我们在训练之后计算指标",
			explain: "这可以被定义为一个从序列到序列的问题，尽管这不是唯一正确的答案。"
		},
        {
			text: "因为损失是在“ model.fit ()”中指定的",
			explain: "不，损失函数在运行‘ model.com pile ()’时是固定的，不能在‘ model.fit ()’中更改。"
		}
	]}
/>

{/if}

### 10.你应该在什么时候预先训练一个新的模型？
<Question
	choices={[
		{
			text: "当您的特定语言没有经过预先训练的模型时",
			explain: "没错。",
			correct: true
		},
		{
			text: "当您有大量可用的数据时，即使有一个经过训练的模型可以处理这些数据",
			explain: "在这种情况下，您可能应该使用预先训练的模型并对数据进行微调，以避免巨大的计算成本。"
		},
		{
			text: "当你担心你所使用的预先训练过的模型的偏差时",
			explain: "这是真的，但是你必须确保你用于培训的数据真的更好。",
			correct: true
		},
        {
			text: "当可用的预先训练好的模型还不够好的时候",
			explain: "那么，你确定你已经正确地调试了你的训练吗？"
		}
	]}
/>

### 11.为什么在大量的文本上预先训练一个语言模型是很容易的呢？
<Question
	choices={[
		{
			text: "当你担心你所使用的预先训练的模型的偏差时",
			explain: "虽然这是真的，但这并不能真正回答这个问题。再试一次！"
		},
		{
			text: "因为预训练目标不需要人工标记数据",
			explain: "没错，语言建模是一个自我监督的问题。",
			correct: true
		},
		{
			text: "因为变形金刚库只需要几行代码就可以开始培训",
			explain: "正确！这与通常的预处理不同，在预处理中我们需要应用完整的标记化管道。你能想到另一个不同点吗？"
		}
	]}
/>

### 12.问答任务的预处理数据时，主要的挑战是什么？
<Question
	choices={[
		{
			text: "你需要对输入进行标记。",
			explain: "这是正确的，但这真的是一个主要的挑战吗？"
		},
		{
			text: "你需要处理非常长的上下文，这些上下文提供了一些训练特性，这些特性可能有也可能没有答案。",
			explain: "这绝对是挑战之一。",
			correct: true
		},
		{
			text: "您需要将问题的答案以及输入标记化。",
			explain: "虽然这是真的，但这并不能真正回答问题。试试另一个答案吧！"
		},
       {
			text: "从文本中的答案范围中，您必须在标记化的输入中找到开始和结束标记。",
			explain: "这是最难的部分之一，是的！",
			correct: true
		}
	]}
/>

### 13.问题回答中的后处理通常是怎样进行的？
<Question
	choices={[
		{
			text: "模型给出了答案的开始位置和结束位置，您只需要解码相应的标记跨度。",
			explain: "这可能是一种方法，但是有点太简单了。"
		},
		{
			text: "该模型为每个由一个示例创建的特性提供了答案的开始和结束位置，您只需要解码分数最高的那个特性中相应的记号跨度。",
			explain: "这与我们研究的后处理过程很接近，但并不完全正确。"
		},
		{
			text: "该模型为每个示例创建的特性提供了答案的开始和结束位置，您只需将它们与上下文中得分最高的特性的跨度相匹配。",
			explain: "简而言之就是这样！",
			correct: true
		},
        {
			text: "模型生成一个答案，你只需要解码它。",
			explain: "虽然这是真的，但这并不能真正回答问题。试试另一个答案吧！"
		}
	]}
/>
