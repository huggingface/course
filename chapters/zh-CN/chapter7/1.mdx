<FrameworkSwitchCourse {fw} />

# 章节简介 [[章节简介]]

在[第三章](/course/chapter3)，您了解了如何微调文本分类的模型。在本章中，我们将处理以下常见NLP任务：

- 标记(token)分类
- 遮罩语言建模（如BERT）
- 提取文本摘要
- 翻译
- 因果语言建模预训练（如GPT-2）
- 问答

{#if fw === 'pt'}

为此，您需要利用[第三章](/course/chapter3)中学到的`Trainer` API 和🤗Accelerate 库、[第五章](/course/chapter5)中的 🤗 Datasets 库以及[第六章](/course/chapter6)中的 🤗 Tokenizers 库的所有知识。我们还会将结果上传到模型中心，就像我们在[第四章](/course/chapter4)中所做的那样，所以这确实是将之前所有内容汇集在一起的章节！

每个部分都可以独立阅读，并将向您展示如何使用API或按照您自己的训练循环训练模型，使用🤗 Accelerate 加速。你可以随意跳过其中一部分，把注意力集中在你最感兴趣的那一部分：API可以优化或训练您的模型而无需担心幕后发生了什么，而训练循环使用可以让您更轻松地自定义所需的任何结构。

{:else}

为此，您需要利用[第三章](/course/chapter3)中学到的有关Keras API、[第五章](/course/chapter5)中的 🤗 Datasets 库以及[第六章](/course/chapter6)中的 🤗 Tokenizers 库的所有知识。我们还会将结果上传到模型中心，就像我们在[第四章](/course/chapter4)中所做的那样，所以这确实是将之前所有内容汇集在一起的章节！

每个部分都可以独立阅读。

{/if}


<Tip>

如果您按顺序阅读这些部分，您会注意到它们有很多共同的代码和陈述。 重复是有意为之的，让您可以深入（或稍后返回）任何您感兴趣的任务并找到一个完整的工作示例。

</Tip>
