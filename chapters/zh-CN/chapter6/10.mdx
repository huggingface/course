<!-- DISABLE-FRONTMATTER-SECTIONS -->

# 章末小测验 [[章末小测验]]

<CourseFloatingBanner
    chapter={6}
    classNames="absolute z-10 right-0 top-0"
/>

让我们测试一下您在本章中学到了什么！

### 1.你应该什么时候训练一个新的标记器？
<Question
	choices={[
		{
			text: "当您的数据集与现有的预训练模型所使用的数据集相似时，并且您希望预训练一个新模型",
			explain: "在这种情况下，为了节省时间和计算资源，一个更好的选择是使用与预训练模型相同的标记器，并对该模型进行微调。"
		},
		{
			text: "当您的数据集与现有的预训练模型所使用的数据集相似时，并且您希望使用此预训练模型对新模型进行微调",
			explain: "要根据预先训练的模型对模型进行微调，您应该始终使用相同的标记器。"
		},
		{
			text: "当您的数据集与现有预训练模型所使用的数据集不同时，您希望预训练一个新模型",
			explain: "正确！ 在这种情况下，使用现有预训练模型标记器将没有任何优势。",
            correct: true
		},
        {
			text: "当您的数据集与现有预训练模型所使用的数据集不同时，但是您希望使用此预训练模型对新模型进行微调",
			explain: "要根据预先训练的模型对模型进行微调，您应该始终使用相同的标记器。"
		}
	]}
/>

### 2.当使用“ train_new_from_iterator()”时，使用文本列表生成器与文本列表相比有什么优点？
<Question
	choices={[
		{
			text: "这是方法 < code > train_new_from_iterator() </code > 接受的唯一类型。",
			explain: "文本列表是一种特殊的文本列表生成器，因此该方法也会接受这种方法。再试一次！"
		},
		{
			text: "您将避免立即将整个数据集载入内存中。",
			explain: "没错！每一批文本都会在你迭代的时候从内存中释放出来，如果你使用数据集存储文本的话，增益将尤其明显。",
			correct: true
		},
		{
			text: "这将允许 Tokenizers 库使用并行处理。",
			explain: "不，无论如何它都将使用并行处理。"
		},
        {
			text: "你训练的标记器将产生更好的文本。",
			explain: "Tokenizer 不生成文本——您是否将其与语言模型混淆了？"
		}
	]}
/>

### 3.使用“快速”标记器的优点是什么？
<Question
	choices={[
		{
			text: "当你批处理大量的输入时，它可以比一个满速的标记器更快地处理输入。",
			explain: "正确！由于在 Rust 中实现了并行性，它将在批量处理输入上更快。你还能想到其他什么好处吗？",
			correct: true
		},
		{
			text: "快速的标记法总是比慢速的标记法快。",
			explain: "一个快速的标记器当你只给它一个或很少的文本实际上可能会更慢，因为它不能使用并行。"
		},
		{
			text: "它可以填充和截断文本。",
			explain: "是的，但是慢速的标记符也会这样做。"
		},
        {
			text: "它有一些额外的功能，允许你将标记映射到创建它们的文本范围。",
			explain: "事实上，这些被称为偏移映射，但这并不是唯一的优点。",
			correct: true
		}
	]}
/>

### 4.“token-classification”管道如何处理跨多个标记的实体？
<Question
	choices={[
		{
			text: "具有相同标签的实体合并为一个实体。",
			explain: "这有点过于简单化了，再试一次！"
		},
		{
			text: "实体的开始有一个标签，实体的持续有一个标签。",
			explain: "正确！",
			correct: true
		},
		{
			text: "在给定的单词中，只要第一个标记具有实体的标签，则认为整个单词都带有该实体的标签。",
			explain: "这是一个处理实体的策略，这里还有什么其他的答案吗？",
			correct: true
		},
        {
			text: "当一个标记具有给定实体的标记时，除非标记为新实体的开始，否则具有相同标记的任何其他后续标记都被视为同一实体的一部分。",
			explain: "这是最常见的将实体组合在一起的方法---- 尽管这不是唯一正确的答案。",
			correct: true
		}
	]}
/>

### 5.“question-answering”流水线如何处理长上下文？
<Question
	choices={[
		{
			text: "实际上并不是这样，因为它在模型接受的最大长度上截断了长上下文。",
			explain: "有一个技巧你可以用来处理很长的上下文，你还记得是什么吗？"
		},
		{
			text: "它将上下文分成若干部分，并对所得结果进行平均。",
			explain: "不，对结果进行平均是没有意义的，因为上下文的某些部分不包括答案。"
		},
		{
			text: "它将上下文拆分为若干部分(有重叠部分) ，并在每个部分中查找一个答案的最大得分。",
			explain: "这就是正确答案！",
			correct: true
		},
        {
			text: "它将上下文分成若干部分(不重叠，以提高效率) ，并在每个部分中找到一个答案的最大得分。",
			explain: "不，它包括部分之间的一些重叠，以避免出现答案将分成两部分的情况。"
		}
	]}
/>

### 6.什么是标准化？
<Question
	choices={[
		{
			text: "这是 tokenizer 在初始阶段对文本执行的任何清理。",
			explain: "这是正确的——例如，它可能涉及删除重音符号或空格，或缩小输入的大小写。",
			correct: true
		},
		{
			text: "这是一种数据增强技术，包括通过删除稀有单词使文本更加标准。",
			explain: "不对! 再试一次。"
		},
		{
			text: "在最后的后处理步骤中，tokenizer 添加特殊标记。",
			explain: "这个阶段简单地称为后期处理。"
		},
        {
			text: "这是当嵌入的平均值为0和标准差为1时，通过减去平均值和除以标准差。",
			explain: "在计算机视觉中，这个过程通常被称为标准化，但在 NLP 中，这并不是标准化的意思。"
		}
	]}
/>

### 7.什么是子词标记化的前标记化？
<Question
	choices={[
		{
			text: "这是标记化之前的步骤，应用数据增强(如随机遮罩)。",
			explain: "不，这一步是预处理的一部分。"
		},
		{
			text: "这是标记化之前的步骤，在这个步骤中，所需的清理操作应用于文本。",
			explain: "不，这是标准化步骤。"
		},
		{
			text: "这是应用 tokenizer 模型之前的步骤，将输入拆分为单词。",
			explain: "这就是正确答案！",
			correct: true
		},
        {
			text: "这是应用 tokenizer 模型之前的步骤，将输入拆分为标记。",
			explain: "不，分解为标记是 tokenizer 模型的工作。"
		}
	]}
/>

### 8.选择描述标记化 BPE 模式最准确的句子。
<Question
	choices={[
		{
			text: "BPE 是一个子词标记算法，从小词汇表开始，学习合并规则。",
			explain: "的确如此！",
			correct: true
		},
		{
			text: "BPE 是一种子词标记算法，从大词汇表开始，逐步从中删除标记。",
			explain: "不，另一种标记算法所采用的方法。"
		},
		{
			text: "BPE 标记器通过合并最常见的一对标记来学习合并规则。",
			explain: "没错！",
			correct: true
		},
		{
			text: "BPE 记号赋予器通过合并一对记号来学习合并规则，该记号最大化了特权频繁对和较少个别部分的分数。",
			explain: "不，这是另一个标记算法应用的策略。"
		},
		{
			text: "BPE 通过将单词分割成字符，然后应用合并规则将单词分解成子单词。",
			explain: "没错！",
			correct: true
		},
		{
			text: "BPE 通过从词汇表的开头找到最长的子词，然后在文本的其余部分重复这个过程，将单词转化为子词。",
			explain: "不，这是另一种标记化算法的做事方式。"
		},
	]}
/>

### 9.选择适用于 WordPiece 标记模型的句子。
<Question
	choices={[
		{
			text: "WordPiece 是一个子词标记算法，它从一个小词汇表开始，学习合并规则。",
			explain: "的确如此！",
			correct: true
		},
		{
			text: "WordPiece 是一种子词标记算法，从大词汇表开始，逐步从中删除标记。",
			explain: "不，这是一种不同的标记算法所采用的方法。"
		},
		{
			text: "WordPiece 标记器通过合并最常见的两个标记来学习合并规则。",
			explain: "不，这是另一个标记算法应用的策略。"
		},
		{
			text: "WordPiece 标记器通过合并两个标记来学习合并规则，这两个标记最大限度地提高了频繁出现的标记的分数，而这两个标记的独立部分出现频率较低。",
			explain: "没错！",
			correct: true
		},
		{
			text: "根据模型，WordPiece 通过找到最有可能的切分符号，将单词标记为子单词。",
			explain: "不，这是另一个标记化算法的工作原理。"
		},
		{
			text: "WordPiece 通过从词汇表的开头找到最长的子词，然后在文本的其余部分重复这个过程，将单词转化为子词。",
			explain: "是的，这就是 WordPiece 进行编码的过程。",
			correct: true
		},
	]}
/>

### 10.选择适用于 Unigram 标记模式的句子。
<Question
	choices={[
		{
			text: "Unigram 是一个子词标记算法，它从一个很小的词汇表开始学习合并规则。",
			explain: "不，这是一种不同的标记算法所采用的方法。"
		},
		{
			text: "Unigram 是一种子词标记算法，它从大词汇表开始，逐步从中删除标记。",
			explain: "没错！",
			correct: true
		},
		{
			text: "Unigram 通过最小化在整个语料库中的损失来调整词汇量。",
			explain: "没错！",
			correct: true
		},
		{
			text: "Unigram 通过保留最频繁的子词来调整它的词汇量。",
			explain: "不，这个不正确。"
		},
		{
			text: "根据模型，Unigram 通过找到最可能的分割符号来将词转化为子词。",
			explain: "没错！",
			correct: true
		},
		{
			text: "Unigram 通过将单词分割成字符，然后应用合并规则将其分解成子单词。",
			explain: "不，这是另一个标记化算法的工作原理。"
		},
	]}
/>
