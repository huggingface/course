<FrameworkSwitchCourse {fw} />

# å…±äº«é¢„è®­ç»ƒæ¨¡å‹ [[å…±äº«é¢„è®­ç»ƒæ¨¡å‹]]

{#if fw === 'pt'}

<CourseFloatingBanner chapter={4}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/zh-CN/chapter4/section3_pt.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/zh-CN/chapter4/section3_pt.ipynb"},
]} />

{:else}

<CourseFloatingBanner chapter={4}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/zh-CN/chapter4/section3_tf.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/zh-CN/chapter4/section3_tf.ipynb"},
]} />

{/if}

åœ¨ä¸‹é¢çš„æ­¥éª¤ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹çœ‹å°†é¢„è®­ç»ƒæ¨¡å‹åˆ†äº«åˆ° ğŸ¤— Hub çš„æœ€ç®€å•æ–¹æ³•ã€‚æœ‰å¯ç”¨çš„å·¥å…·å’Œå®ç”¨ç¨‹åºå¯ä»¥è®©ç›´æ¥åœ¨ Hub ä¸Šå…±äº«å’Œæ›´æ–°æ¨¡å‹å˜å¾—ç®€å•ï¼Œæˆ‘ä»¬å°†åœ¨ä¸‹é¢è¿›è¡Œæ¢è®¨ã€‚

<Youtube id="9yY3RB_GSPM"/>

æˆ‘ä»¬é¼“åŠ±æ‰€æœ‰è®­ç»ƒæ¨¡å‹çš„ç”¨æˆ·é€šè¿‡ä¸ç¤¾åŒºå…±äº«æ¥åšå‡ºè´¡çŒ®â€”â€”å…±äº«æ¨¡å‹ï¼Œå³ä½¿æ˜¯åœ¨éå¸¸ç‰¹å®šçš„æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œä¹Ÿå°†å¸®åŠ©ä»–äººï¼ŒèŠ‚çœä»–ä»¬çš„æ—¶é—´å’Œè®¡ç®—èµ„æºï¼Œå¹¶æä¾›å¯¹æœ‰ç”¨çš„è®­ç»ƒå·¥ä»¶çš„è®¿é—®ã€‚åè¿‡æ¥ï¼Œæ‚¨å¯ä»¥ä»å…¶ä»–äººæ‰€åšçš„å·¥ä½œä¸­å—ç›Šï¼

åˆ›å»ºæ–°æ¨¡å‹å­˜å‚¨åº“çš„æ–¹æ³•æœ‰ä»¥ä¸‹ä¸‰ç§ï¼š

- ä½¿ç”¨ push_to_hub API æ¥å£
- ä½¿ç”¨ huggingface_hub Python åº“
- ä½¿ç”¨ web ç•Œé¢

åˆ›å»ºå­˜å‚¨åº“åï¼Œæ‚¨å¯ä»¥é€šè¿‡ git å’Œ git-lfs å°†æ–‡ä»¶ä¸Šä¼ åˆ°å…¶ä¸­ã€‚æˆ‘ä»¬å°†åœ¨ä»¥ä¸‹éƒ¨åˆ†å¼•å¯¼æ‚¨åˆ›å»ºæ¨¡å‹å­˜å‚¨åº“å¹¶å°†æ–‡ä»¶ä¸Šä¼ åˆ°å®ƒä»¬


## ä½¿ç”¨ push_to_hub API [[ä½¿ç”¨ push_to_hub API]]

{#if fw === 'pt'}

<Youtube id="Zh0FfmVrKX0"/>

{:else}

<Youtube id="pUh5cGmNV8Y"/>

{/if}

å°†æ–‡ä»¶ä¸Šä¼ åˆ°æ¨¡å‹ä¸­å¿ƒçš„æœ€ç®€å•æ–¹æ³•æ˜¯åˆ©ç”¨ **push_to_hub** API æ¥å£ã€‚

åœ¨ç»§ç»­ä¹‹å‰ï¼Œæ‚¨éœ€è¦ç”Ÿæˆä¸€ä¸ªèº«ä»½éªŒè¯ä»¤ç‰Œï¼Œä»¥ä¾¿ **huggingface_hub** API çŸ¥é“æ‚¨æ˜¯è°ä»¥åŠæ‚¨å¯¹å“ªäº›åç§°ç©ºé—´å…·æœ‰å†™å…¥æƒé™ã€‚ç¡®ä¿ä½ åœ¨ä¸€ä¸ªç¯å¢ƒä¸­ **transformers** å·²å®‰è£…ï¼ˆè§[å®‰è£…](/course/chapter0)ï¼‰ã€‚å¦‚æœæ‚¨åœ¨ç¬”è®°æœ¬ä¸­ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹åŠŸèƒ½ç™»å½•ï¼š

```python
from huggingface_hub import notebook_login

notebook_login()
```

åœ¨ç»ˆç«¯ä¸­ï¼Œæ‚¨å¯ä»¥è¿è¡Œï¼š

```bash
huggingface-cli login
```

åœ¨è¿™ä¸¤ç§æƒ…å†µä¸‹ï¼Œç³»ç»Ÿéƒ½ä¼šæç¤ºæ‚¨è¾“å…¥ç”¨æˆ·åå’Œå¯†ç ï¼Œè¿™ä¸æ‚¨ç”¨äºç™»å½• Hub çš„ç”¨æˆ·åå’Œå¯†ç ç›¸åŒã€‚å¦‚æœæ‚¨è¿˜æ²¡æœ‰ Hub é…ç½®æ–‡ä»¶ï¼Œåˆ™åº”è¯¥åˆ›å»ºä¸€ä¸ª[åˆ›å»ºä¸€ä¸ªè´¦æˆ·](https://huggingface.co/join)ã€‚

å¥½çš„ï¼æ‚¨ç°åœ¨å·²å°†èº«ä»½éªŒè¯ä»¤ç‰Œå­˜å‚¨åœ¨ç¼“å­˜æ–‡ä»¶å¤¹ä¸­ã€‚è®©æˆ‘ä»¬åˆ›å»ºä¸€äº›å­˜å‚¨åº“ï¼

{#if fw === 'pt'}

å¦‚æœä½ ç©è¿‡ **Trainer** ç”¨äºè®­ç»ƒæ¨¡å‹çš„ APIï¼Œå°†å…¶ä¸Šä¼ åˆ° Hub çš„æœ€ç®€å•æ–¹æ³•æ˜¯è®¾ç½® **push_to_hub=True** å½“ä½ å®šä¹‰ä½ çš„ **TrainingArguments** ï¼š

```py
from transformers import TrainingArguments

training_args = TrainingArguments(
    "bert-finetuned-mrpc", save_strategy="epoch", push_to_hub=True
)
```

ä½ å£°æ˜ **trainer.train()** çš„æ—¶å€™ï¼Œ è¿™ **Trainer** ç„¶åæ¯æ¬¡å°†æ‚¨çš„æ¨¡å‹ä¿å­˜åˆ°æ‚¨çš„å‘½åç©ºé—´ä¸­çš„å­˜å‚¨åº“ä¸­æ—¶ï¼ˆè¿™é‡Œæ˜¯æ¯ä¸ªæ—¶ä»£ï¼‰ï¼Œå®ƒå°†ä¸Šä¼ åˆ°æ¨¡å‹ä¸­å¿ƒã€‚è¯¥å­˜å‚¨åº“å°†å‘½åä¸ºæ‚¨é€‰æ‹©çš„è¾“å‡ºç›®å½•ï¼ˆæ­¤å¤„ **bert-finetuned-mrpc** ) ä½†æ‚¨å¯ä»¥é€‰æ‹©ä¸åŒçš„åç§° **hub_model_id = a_different_name** ã€‚

è¦å°†æ‚¨çš„æ¨¡å‹ä¸Šä¼ åˆ°æ‚¨æ‰€å±çš„ç»„ç»‡ï¼Œåªéœ€å°†å…¶ä¼ é€’ç»™ **hub_model_id = my_organization/my_repo_name** ã€‚

è®­ç»ƒç»“æŸåï¼Œä½ åº”è¯¥åšæœ€åçš„ **trainer.push_to_hub()** ä¸Šä¼ æ¨¡å‹çš„æœ€æ–°ç‰ˆæœ¬ã€‚å®ƒè¿˜å°†ç”ŸæˆåŒ…å«æ‰€æœ‰ç›¸å…³å…ƒæ•°æ®çš„æ¨¡å‹å¡ï¼ŒæŠ¥å‘Šä½¿ç”¨çš„è¶…å‚æ•°å’Œè¯„ä¼°ç»“æœï¼ä»¥ä¸‹æ˜¯æ‚¨å¯èƒ½ä¼šåœ¨æ­¤ç±»æ¨¡å‹å¡ä¸­æ‰¾åˆ°çš„å†…å®¹ç¤ºä¾‹ï¼š

<div class="flex justify-center">
  <img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/model_card.png" alt="An example of an auto-generated model card." width="100%"/>
</div>


{:else}


å¦‚æœæ‚¨ä½¿ç”¨Kerasæ¥è®­ç»ƒæ‚¨çš„æ¨¡å‹ï¼Œåˆ™å°†å…¶ä¸Šä¼ åˆ°Hubçš„æœ€ç®€å•æ–¹æ³•æ˜¯åœ¨è°ƒç”¨ **model.fit()**  æ—¶ä¼ é€’**PushToHubCallback**ï¼š

```py
from transformers import PushToHubCallback

callback = PushToHubCallback(
    "bert-finetuned-mrpc", save_strategy="epoch", tokenizer=tokenizer
)
```

ç„¶åï¼Œæ‚¨åº”è¯¥åœ¨å¯¹**model.fit()**çš„è°ƒç”¨ä¸­æ·»åŠ **callbacks=[callback]**ã€‚ç„¶åï¼Œæ¯æ¬¡å°†æ¨¡å‹ä¿å­˜åœ¨å‘½åç©ºé—´çš„å­˜å‚¨åº“ä¸­ï¼ˆæ­¤å¤„ä¸ºæ¯ä¸ª epochï¼‰æ—¶ï¼Œå›è°ƒéƒ½ä¼šå°†æ¨¡å‹ä¸Šä¼ åˆ° Hubã€‚è¯¥å­˜å‚¨åº“çš„åç§°å°†ç±»ä¼¼äºæ‚¨é€‰æ‹©çš„è¾“å‡ºç›®å½•ï¼ˆæ­¤å¤„ä¸º**bert-finetuned-mrpc**ï¼‰ï¼Œä½†æ‚¨å¯ä»¥é€‰æ‹©å¦ä¸€ä¸ªåç§°ï¼Œåç§°ä¸º**hub_model_id = a_different_name**ã€‚

è¦å°†æ‚¨çš„æ¨¡å‹ä¸Šä¼ åˆ°æ‚¨æ‰€å±çš„ç»„ç»‡ï¼Œåªéœ€å°†å…¶ä¼ é€’ç»™ **hub_model_id = my_organization/my_repo_name** ã€‚

{/if}

åœ¨è¾ƒä½çº§åˆ«ï¼Œå¯ä»¥é€šè¿‡æ¨¡å‹ã€æ ‡è®°å™¨å’Œé…ç½®å¯¹è±¡ç›´æ¥è®¿é—®æ¨¡å‹ä¸­å¿ƒ **push_to_hub()** æ–¹æ³•ã€‚æ­¤æ–¹æ³•è´Ÿè´£åˆ›å»ºå­˜å‚¨åº“å¹¶å°†æ¨¡å‹å’Œæ ‡è®°å™¨æ–‡ä»¶ç›´æ¥æ¨é€åˆ°å­˜å‚¨åº“ã€‚ä¸æˆ‘ä»¬å°†åœ¨ä¸‹é¢çœ‹åˆ°çš„ API ä¸åŒï¼Œä¸éœ€è¦æ‰‹åŠ¨å¤„ç†ã€‚

ä¸ºäº†äº†è§£å®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œè®©æˆ‘ä»¬é¦–å…ˆåˆå§‹åŒ–ä¸€ä¸ªæ¨¡å‹å’Œä¸€ä¸ªæ ‡è®°å™¨ï¼š

{#if fw === 'pt'}

```py
from transformers import AutoModelForMaskedLM, AutoTokenizer

checkpoint = "camembert-base"

model = AutoModelForMaskedLM.from_pretrained(checkpoint)
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
```

{:else}

```py
from transformers import TFAutoModelForMaskedLM, AutoTokenizer

checkpoint = "camembert-base"

model = TFAutoModelForMaskedLM.from_pretrained(checkpoint)
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
```

{/if}

ä½ å¯ä»¥è‡ªç”±åœ°ç”¨è¿™äº›åšä»»ä½•ä½ æƒ³åšçš„äº‹æƒ…â€”â€”å‘æ ‡è®°å™¨æ·»åŠ æ ‡è®°ï¼Œè®­ç»ƒæ¨¡å‹ï¼Œå¾®è°ƒå®ƒã€‚ä¸€æ—¦æ‚¨å¯¹ç”Ÿæˆçš„æ¨¡å‹ã€æƒé‡å’Œæ ‡è®°å™¨æ„Ÿåˆ°æ»¡æ„ï¼Œæ‚¨å°±å¯ä»¥åˆ©ç”¨ **push_to_hub()** æ–¹æ³•ç›´æ¥åœ¨ **model** ä¸­ï¼š

```py
model.push_to_hub("dummy-model")
```

è¿™å°†åˆ›å»ºæ–°çš„å­˜å‚¨åº“ **dummy-model** åœ¨æ‚¨çš„ä¸ªäººèµ„æ–™ä¸­ï¼Œå¹¶ç”¨æ‚¨çš„æ¨¡å‹æ–‡ä»¶å¡«å……å®ƒã€‚
å¯¹æ ‡è®°å™¨æ‰§è¡Œç›¸åŒçš„æ“ä½œï¼Œä»¥ä¾¿æ‰€æœ‰æ–‡ä»¶ç°åœ¨éƒ½å¯ä»¥åœ¨æ­¤å­˜å‚¨åº“ä¸­ä½¿ç”¨ï¼š

```py
tokenizer.push_to_hub("dummy-model")
```

å¦‚æœæ‚¨å±äºä¸€ä¸ªç»„ç»‡ï¼Œåªéœ€æŒ‡å®š **organization** ä¸Šä¼ åˆ°è¯¥ç»„ç»‡çš„å‘½åç©ºé—´çš„å‚æ•°ï¼š

```py
tokenizer.push_to_hub("dummy-model", organization="huggingface")
```

å¦‚æœæ‚¨å¸Œæœ›ä½¿ç”¨ç‰¹å®šçš„ Hugging Face ä»¤ç‰Œï¼Œæ‚¨å¯ä»¥è‡ªç”±åœ°å°†å…¶æŒ‡å®šç»™ **push_to_hub()** æ–¹æ³•ä¹Ÿæ˜¯ï¼š

```py
tokenizer.push_to_hub("dummy-model", organization="huggingface", use_auth_token="<TOKEN>")
```

ç°åœ¨å‰å¾€æ¨¡å‹ä¸­å¿ƒæ‰¾åˆ°æ‚¨æ–°ä¸Šä¼ çš„æ¨¡å‹ï¼š*https://huggingface.co/user-or-organization/dummy-model*ã€‚

å•å‡»â€œæ–‡ä»¶å’Œç‰ˆæœ¬â€é€‰é¡¹å¡ï¼Œæ‚¨åº”è¯¥ä¼šåœ¨ä»¥ä¸‹å±å¹•æˆªå›¾ä¸­çœ‹åˆ°å¯è§çš„æ–‡ä»¶ï¼š

{#if fw === 'pt'}
<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/push_to_hub_dummy_model.png" alt="Dummy model containing both the tokenizer and model files." width="80%"/>
</div>
{:else}
<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/push_to_hub_dummy_model_tf.png" alt="Dummy model containing both the tokenizer and model files." width="80%"/>
</div>
{/if}

<Tip>

âœï¸ **è¯•è¯•çœ‹**ï¼è·å–ä¸æ£€æŸ¥ç‚¹å…³è”çš„æ¨¡å‹å’Œæ ‡è®°å™¨ï¼Œå¹¶ä½¿ç”¨è¯¥æ–¹æ³•å°†å®ƒä»¬ä¸Šä¼ åˆ°æ‚¨çš„å‘½åç©ºé—´ä¸­çš„å­˜å‚¨åº“ã€‚åœ¨åˆ é™¤ä¹‹å‰ï¼Œè¯·ä»”ç»†æ£€æŸ¥è¯¥å­˜å‚¨åº“æ˜¯å¦æ­£ç¡®æ˜¾ç¤ºåœ¨æ‚¨çš„é¡µé¢ä¸Šã€‚

</Tip>

å¦‚æ‚¨æ‰€è§ï¼Œ **push_to_hub()** æ–¹æ³•æ¥å—å¤šä¸ªå‚æ•°ï¼Œä»è€Œå¯ä»¥ä¸Šä¼ åˆ°ç‰¹å®šçš„å­˜å‚¨åº“æˆ–ç»„ç»‡å‘½åç©ºé—´ï¼Œæˆ–ä½¿ç”¨ä¸åŒçš„ API ä»¤ç‰Œã€‚æˆ‘ä»¬å»ºè®®æ‚¨æŸ¥çœ‹ç›´æ¥åœ¨[ğŸ¤— Transformers documentation](https://huggingface.co/transformers/model_sharing.html)äº†è§£ä»€ä¹ˆæ˜¯å¯èƒ½çš„

è¿™ **push_to_hub()** æ–¹æ³•ç”±[huggingface_hub](https://github.com/huggingface/huggingface_hub)Python åŒ…ï¼Œä¸º Hugging Face Hub æä¾›ç›´æ¥ APIã€‚å®ƒé›†æˆåœ¨ ğŸ¤— Transformers å’Œå…¶ä»–å‡ ä¸ªæœºå™¨å­¦ä¹ åº“ä¸­ï¼Œä¾‹å¦‚[allenlp](https://github.com/allenai/allennlp).è™½ç„¶æˆ‘ä»¬åœ¨æœ¬ç« ä¸­ä¸“æ³¨äº ğŸ¤— Transformers é›†æˆï¼Œä½†å°†å…¶é›†æˆåˆ°æ‚¨è‡ªå·±çš„ä»£ç æˆ–åº“ä¸­å¾ˆç®€å•ã€‚

è·³åˆ°æœ€åä¸€éƒ¨åˆ†ï¼Œäº†è§£å¦‚ä½•å°†æ–‡ä»¶ä¸Šä¼ åˆ°æ–°åˆ›å»ºçš„å­˜å‚¨åº“ï¼

## ä½¿ç”¨ huggingface_hub pythonåº“ [[ä½¿ç”¨ huggingface_hub pythonåº“]]

è¿™ **huggingface_hub** Python åº“æ˜¯ä¸€ä¸ªåŒ…ï¼Œå®ƒä¸ºæ¨¡å‹å’Œæ•°æ®é›†ä¸­å¿ƒæä¾›äº†ä¸€ç»„å·¥å…·ã€‚å®ƒä¸ºå¸¸è§ä»»åŠ¡æä¾›äº†ç®€å•çš„æ–¹æ³•å’Œç±»ï¼Œä¾‹å¦‚
è·å–æœ‰å…³æ¨¡å‹ä¸­å¿ƒä¸Šå­˜å‚¨åº“çš„ä¿¡æ¯å¹¶å¯¹å…¶è¿›è¡Œç®¡ç†ã€‚å®ƒæä¾›äº†åœ¨ git ä¹‹ä¸Šå·¥ä½œçš„ç®€å• API æ¥ç®¡ç†è¿™äº›å­˜å‚¨åº“çš„å†…å®¹å¹¶é›†æˆ Hub
åœ¨æ‚¨çš„é¡¹ç›®å’Œåº“ä¸­ã€‚

ç±»ä¼¼äºä½¿ç”¨ **push_to_hub** APIï¼Œè¿™å°†è¦æ±‚æ‚¨å°† API ä»¤ç‰Œä¿å­˜åœ¨ç¼“å­˜ä¸­ã€‚ä¸ºæ­¤ï¼Œæ‚¨éœ€è¦ä½¿ç”¨ **login** æ¥è‡ª CLI çš„å‘½ä»¤ï¼Œå¦‚ä¸Šä¸€èŠ‚æ‰€è¿°ï¼ˆåŒæ ·ï¼Œç¡®ä¿åœ¨è¿™äº›å‘½ä»¤å‰é¢åŠ ä¸Š **!** å­—ç¬¦ï¼ˆå¦‚æœåœ¨ Google Colab ä¸­è¿è¡Œï¼‰ï¼š

```bash
huggingface-cli login
```

è¿™ **huggingface_hub** åŒ…æä¾›äº†å‡ ç§å¯¹æˆ‘ä»¬æœ‰ç”¨çš„æ–¹æ³•å’Œç±»ã€‚é¦–å…ˆï¼Œæœ‰å‡ ç§æ–¹æ³•å¯ä»¥ç®¡ç†å­˜å‚¨åº“çš„åˆ›å»ºã€åˆ é™¤ç­‰ï¼š

```python no-format
from huggingface_hub import (
    # User management
    login,
    logout,
    whoami,

    # Repository creation and management
    create_repo,
    delete_repo,
    update_repo_visibility,

    # And some methods to retrieve/change information about the content
    list_models,
    list_datasets,
    list_metrics,
    list_repo_files,
    upload_file,
    delete_file,
)
```


æ­¤å¤–ï¼Œå®ƒè¿˜æä¾›äº†éå¸¸å¼ºå¤§çš„ **Repository** ç”¨äºç®¡ç†æœ¬åœ°å­˜å‚¨åº“çš„ç±»ã€‚æˆ‘ä»¬å°†åœ¨æ¥ä¸‹æ¥çš„å‡ èŠ‚ä¸­æ¢è®¨è¿™äº›æ–¹æ³•å’Œè¯¥ç±»ï¼Œä»¥äº†è§£å¦‚ä½•åˆ©ç”¨å®ƒä»¬ã€‚

è¿™ **create_repo** æ–¹æ³•å¯ç”¨äºåœ¨æ¨¡å‹ä¸­å¿ƒä¸Šåˆ›å»ºæ–°å­˜å‚¨åº“ï¼š


```py
from huggingface_hub import create_repo

create_repo("dummy-model")
```

è¿™å°†åˆ›å»ºå­˜å‚¨åº“ **dummy-model** åœ¨æ‚¨çš„å‘½åç©ºé—´ä¸­ã€‚å¦‚æœæ„¿æ„ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ **organization** äº‰è®ºï¼š

```py
from huggingface_hub import create_repo

create_repo("dummy-model", organization="huggingface")
```

è¿™å°†åˆ›å»º **dummy-model** å­˜å‚¨åº“ä¸­çš„ **huggingface** å‘½åç©ºé—´ï¼Œå‡è®¾æ‚¨å±äºè¯¥ç»„ç»‡ã€‚
å…¶ä»–å¯èƒ½æœ‰ç”¨çš„å‚æ•°æ˜¯ï¼š

- private ä»¥æŒ‡å®šå­˜å‚¨åº“æ˜¯å¦åº”å¯¹å…¶ä»–äººå¯è§ã€‚
- token å¦‚æœæ‚¨æƒ³ç”¨ç»™å®šçš„ä»¤ç‰Œè¦†ç›–å­˜å‚¨åœ¨ç¼“å­˜ä¸­çš„ä»¤ç‰Œã€‚
-  repo_type å¦‚æœä½ æƒ³åˆ›å»ºä¸€ä¸ªæˆ–ä¸€ä¸ªæ›¿ä»£ä¸€ä¸ªçš„è€Œä¸æ˜¯æ¨¡å‹ã€‚æ¥å—çš„å€¼å’Œ datasetspace "dataset""space"ã€‚

åˆ›å»ºå­˜å‚¨åº“åï¼Œæˆ‘ä»¬åº”è¯¥å‘å…¶ä¸­æ·»åŠ æ–‡ä»¶ï¼è·³åˆ°ä¸‹ä¸€éƒ¨åˆ†ä»¥æŸ¥çœ‹å¯ä»¥å¤„ç†æ­¤é—®é¢˜çš„ä¸‰ç§æ–¹æ³•ã€‚


## ä½¿ç”¨ç½‘ç»œç•Œé¢ [[ä½¿ç”¨ç½‘ç»œç•Œé¢]]

Web ç•Œé¢æä¾›äº†ç›´æ¥åœ¨ Hub ä¸­ç®¡ç†å­˜å‚¨åº“çš„å·¥å…·ã€‚ä½¿ç”¨è¯¥ç•Œé¢ï¼Œæ‚¨å¯ä»¥è½»æ¾åˆ›å»ºå­˜å‚¨åº“ã€æ·»åŠ æ–‡ä»¶ï¼ˆç”šè‡³æ˜¯å¤§æ–‡ä»¶ï¼ï¼‰ã€æ¢ç´¢æ¨¡å‹ã€å¯è§†åŒ–å·®å¼‚ç­‰ç­‰ã€‚

è¦åˆ›å»ºæ–°çš„å­˜å‚¨åº“ï¼Œè¯·è®¿é—®[huggingface.co/new](https://huggingface.co/new)ï¼š

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/new_model.png" alt="Page showcasing the model used for the creation of a new model repository." width="80%"/>
</div>

é¦–å…ˆï¼ŒæŒ‡å®šå­˜å‚¨åº“çš„æ‰€æœ‰è€…ï¼šè¿™å¯ä»¥æ˜¯æ‚¨æˆ–æ‚¨æ‰€å±çš„ä»»ä½•ç»„ç»‡ã€‚å¦‚æœæ‚¨é€‰æ‹©ä¸€ä¸ªç»„ç»‡ï¼Œè¯¥æ¨¡å‹å°†å‡ºç°åœ¨è¯¥ç»„ç»‡çš„é¡µé¢ä¸Šï¼Œå¹¶ä¸”è¯¥ç»„ç»‡çš„æ¯ä¸ªæˆå‘˜éƒ½å¯ä»¥ä¸ºå­˜å‚¨åº“åšå‡ºè´¡çŒ®ã€‚

æ¥ä¸‹æ¥ï¼Œè¾“å…¥æ‚¨çš„æ¨¡å‹åç§°ã€‚è¿™ä¹Ÿå°†æ˜¯å­˜å‚¨åº“çš„åç§°ã€‚æœ€åï¼Œæ‚¨å¯ä»¥æŒ‡å®šæ‚¨çš„æ¨¡å‹æ˜¯å…¬å¼€çš„è¿˜æ˜¯ç§æœ‰çš„ã€‚ç§äººæ¨¡ç‰¹è¦æ±‚æ‚¨æ‹¥æœ‰ä»˜è´¹ Hugging Face å¸æˆ·ï¼Œå¹¶å…è®¸æ‚¨å°†æ¨¡ç‰¹éšè—åœ¨å…¬ä¼—è§†é‡ä¹‹å¤–ã€‚

åˆ›å»ºæ¨¡å‹å­˜å‚¨åº“åï¼Œæ‚¨åº”è¯¥çœ‹åˆ°å¦‚ä¸‹é¡µé¢ï¼š

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/empty_model.png" alt="An empty model page after creating a new repository." width="80%"/>
</div>

è¿™æ˜¯æ‚¨çš„æ¨¡å‹å°†è¢«æ‰˜ç®¡çš„åœ°æ–¹ã€‚è¦å¼€å§‹å¡«å……å®ƒï¼Œæ‚¨å¯ä»¥ç›´æ¥ä» Web ç•Œé¢æ·»åŠ  README æ–‡ä»¶ã€‚

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/dummy_model.png" alt="The README file showing the Markdown capabilities." width="80%"/>
</div>

README æ–‡ä»¶åœ¨ Markdown ä¸­ - éšæ„ä½¿ç”¨å®ƒï¼æœ¬ç« çš„ç¬¬ä¸‰éƒ¨åˆ†è‡´åŠ›äºæ„å»ºæ¨¡å‹å¡ã€‚è¿™äº›å¯¹äºä¸ºæ‚¨çš„æ¨¡å‹å¸¦æ¥ä»·å€¼è‡³å…³é‡è¦ï¼Œå› ä¸ºå®ƒä»¬æ˜¯æ‚¨å‘Šè¯‰å…¶ä»–äººå®ƒå¯ä»¥åšä»€ä¹ˆçš„åœ°æ–¹ã€‚

å¦‚æœæ‚¨æŸ¥çœ‹â€œæ–‡ä»¶å’Œç‰ˆæœ¬â€é€‰é¡¹å¡ï¼Œæ‚¨ä¼šå‘ç°é‚£é‡Œè¿˜æ²¡æœ‰å¾ˆå¤šæ–‡ä»¶â€”â€”åªæœ‰è‡ªè¿°æ–‡ä»¶ä½ åˆšåˆšåˆ›å»ºå’Œ.git å±æ€§è·Ÿè¸ªå¤§æ–‡ä»¶çš„æ–‡ä»¶ã€‚

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/files.png" alt="The 'Files and versions' tab only shows the .gitattributes and README.md files." width="80%"/>
</div>

æ¥ä¸‹æ¥æˆ‘ä»¬å°†çœ‹çœ‹å¦‚ä½•æ·»åŠ ä¸€äº›æ–°æ–‡ä»¶ã€‚

## ä¸Šä¼ æ¨¡å‹æ–‡ä»¶ [[ä¸Šä¼ æ¨¡å‹æ–‡ä»¶]]

Hugging Face Hub ä¸Šçš„æ–‡ä»¶ç®¡ç†ç³»ç»ŸåŸºäºç”¨äºå¸¸è§„æ–‡ä»¶çš„ git å’Œ git-lfsï¼ˆä»£è¡¨[Git Large File Storage](https://git-lfs.github.com/)) å¯¹äºè¾ƒå¤§çš„æ–‡ä»¶ã€‚

åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»å°†æ–‡ä»¶ä¸Šä¼ åˆ° Hub çš„ä¸‰ç§ä¸åŒæ–¹å¼ï¼šé€šè¿‡ **huggingface_hub** å¹¶é€šè¿‡ git å‘½ä»¤ã€‚

### The `upload_file` approach [[The `upload_file` approach]]

ä½¿ç”¨ **upload_file** ä¸éœ€è¦åœ¨æ‚¨çš„ç³»ç»Ÿä¸Šå®‰è£… git å’Œ git-lfsã€‚å®ƒä½¿ç”¨ HTTP POST è¯·æ±‚å°†æ–‡ä»¶ç›´æ¥æ¨é€åˆ° ğŸ¤— Hubã€‚è¿™ç§æ–¹æ³•çš„ä¸€ä¸ªé™åˆ¶æ˜¯å®ƒä¸èƒ½å¤„ç†å¤§äº 5GB çš„æ–‡ä»¶ã€‚
å¦‚æœæ‚¨çš„æ–‡ä»¶å¤§äº 5GBï¼Œè¯·æŒ‰ç…§ä¸‹é¢è¯¦è¿°çš„å¦å¤–ä¸¤ç§æ–¹æ³•è¿›è¡Œæ“ä½œã€‚API å¯ä»¥æŒ‰å¦‚ä¸‹æ–¹å¼ä½¿ç”¨ï¼š

```py
from huggingface_hub import upload_file

upload_file(
    "<path_to_file>/config.json",
    path_in_repo="config.json",
    repo_id="<namespace>/dummy-model",
)
```

è¿™å°†ä¸Šä¼ æ–‡ä»¶ **config.json** å¯åœ¨ **path_to_file** åˆ°å­˜å‚¨åº“çš„æ ¹ç›®å½• **config.json** , åˆ° **dummy-model** å­˜å‚¨åº“ã€‚
å…¶ä»–å¯èƒ½æœ‰ç”¨çš„å‚æ•°æ˜¯ï¼š

- tokenï¼Œå¦‚æœè¦é€šè¿‡ç»™å®šçš„ä»¤ç‰Œè¦†ç›–ç¼“å­˜ä¸­å­˜å‚¨çš„ä»¤ç‰Œã€‚
- repo_type, å¦‚æœä½ æƒ³è¦ä¸Šä¼ ä¸€ä¸ª `dataset` æˆ–ä¸€ä¸ª `space` è€Œä¸æ˜¯æ¨¡å‹ã€‚ æ¥å—çš„å€¼ä¸º `"dataset"` å’Œ `"space"`.


### The `Repository` class [[The `Repository` class]]

ä»¥ç±»ä¼¼ git çš„æ–¹å¼ç®¡ç†æœ¬åœ°å­˜å‚¨åº“ã€‚å®ƒæŠ½è±¡äº† git å¯èƒ½é‡åˆ°çš„å¤§éƒ¨åˆ†ç—›ç‚¹ï¼Œä»¥æä¾›æˆ‘ä»¬éœ€è¦çš„æ‰€æœ‰åŠŸèƒ½ã€‚

ä½¿ç”¨è¿™ä¸ªç±»éœ€è¦å®‰è£… git å’Œ git-lfsï¼Œæ‰€ä»¥ç¡®ä¿ä½ å·²ç»å®‰è£…äº† git-lfsï¼ˆå‚è§[here](https://git-lfs.github.com/)å®‰è£…è¯´æ˜ï¼‰å¹¶åœ¨å¼€å§‹ä¹‹å‰è¿›è¡Œè®¾ç½®ã€‚

ä¸ºäº†å¼€å§‹ä½¿ç”¨æˆ‘ä»¬åˆšåˆšåˆ›å»ºçš„å­˜å‚¨åº“ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å…‹éš†è¿œç¨‹å­˜å‚¨åº“å°†å…¶åˆå§‹åŒ–åˆ°æœ¬åœ°æ–‡ä»¶å¤¹å¼€å§‹ï¼š

```py
from huggingface_hub import Repository

repo = Repository("<path_to_dummy_folder>", clone_from="<namespace>/dummy-model")
```

è¿™åˆ›å»ºäº†æ–‡ä»¶å¤¹ **path_to_dummy_folder** åœ¨æˆ‘ä»¬çš„å·¥ä½œç›®å½•ä¸­ã€‚è¯¥æ–‡ä»¶å¤¹ä»…åŒ…å« **.gitattributes** æ–‡ä»¶ï¼Œå› ä¸ºè¿™æ˜¯é€šè¿‡å®ä¾‹åŒ–å­˜å‚¨åº“æ—¶åˆ›å»ºçš„å”¯ä¸€æ–‡ä»¶ **create_repo**ã€‚

ä»ç°åœ¨å¼€å§‹ï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨å‡ ç§ä¼ ç»Ÿçš„ git æ–¹æ³•ï¼š

```py
repo.git_pull()
repo.git_add()
repo.git_commit()
repo.git_push()
repo.git_tag()
```

å¦å¤–ï¼æˆ‘ä»¬å»ºè®®æ‚¨æŸ¥çœ‹ **Repository** å¯ç”¨æ–‡ä»¶[here](https://github.com/huggingface/huggingface_hub/tree/main/src/huggingface_hub#advanced-programmatic-repository-management)æœ‰å…³æ‰€æœ‰å¯ç”¨æ–¹æ³•çš„æ¦‚è¿°ã€‚

ç›®å‰ï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªæ¨¡å‹å’Œä¸€ä¸ªæ ‡è®°å™¨ï¼Œæˆ‘ä»¬å¸Œæœ›å°†å…¶æ¨é€åˆ°æ¨¡å‹ä¸­å¿ƒã€‚æˆ‘ä»¬å·²ç»æˆåŠŸå…‹éš†äº†å­˜å‚¨åº“ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥å°†æ–‡ä»¶ä¿å­˜åœ¨è¯¥å­˜å‚¨åº“ä¸­ã€‚

æˆ‘ä»¬é¦–å…ˆé€šè¿‡æ‹‰å–æœ€æ–°æ›´æ”¹æ¥ç¡®ä¿æˆ‘ä»¬çš„æœ¬åœ°å…‹éš†æ˜¯æœ€æ–°çš„ï¼š

```py
repo.git_pull()
```

å®Œæˆåï¼Œæˆ‘ä»¬ä¿å­˜æ¨¡å‹å’Œæ ‡è®°å™¨æ–‡ä»¶ï¼š

```py
model.save_pretrained("<path_to_dummy_folder>")
tokenizer.save_pretrained("<path_to_dummy_folder>")
```

è¿™ **path_to_dummy_folder** ç°åœ¨åŒ…å«æ‰€æœ‰æ¨¡å‹å’Œæ ‡è®°å™¨æ–‡ä»¶ã€‚æˆ‘ä»¬éµå¾ªé€šå¸¸çš„ git å·¥ä½œæµç¨‹ï¼Œå°†æ–‡ä»¶æ·»åŠ åˆ°æš‚å­˜åŒºï¼Œæäº¤å®ƒä»¬å¹¶å°†å®ƒä»¬æ¨é€åˆ°æ¨¡å‹ä¸­å¿ƒï¼š

```py
repo.git_add()
repo.git_commit("Add model and tokenizer files")
repo.git_push()
```

æ­å–œï¼æ‚¨åˆšåˆšå°†ç¬¬ä¸€ä¸ªæ–‡ä»¶æ¨é€åˆ°hubä¸Šã€‚

### The git-based approach [[The git-based approach]]

è¿™æ˜¯ä¸Šä¼ æ–‡ä»¶çš„éå¸¸ç®€å•çš„æ–¹æ³•ï¼šæˆ‘ä»¬å°†ç›´æ¥ä½¿ç”¨ git å’Œ git-lfs æ¥å®Œæˆã€‚å¤§å¤šæ•°å›°éš¾éƒ½è¢«ä»¥å‰çš„æ–¹æ³•æŠ½è±¡æ‰äº†ï¼Œä½†æ˜¯ä¸‹é¢çš„æ–¹æ³•æœ‰ä¸€äº›è­¦å‘Šï¼Œæ‰€ä»¥æˆ‘ä»¬å°†éµå¾ªä¸€ä¸ªæ›´å¤æ‚çš„ç”¨ä¾‹ã€‚

ä½¿ç”¨è¿™ä¸ªç±»éœ€è¦å®‰è£… git å’Œ git-lfsï¼Œæ‰€ä»¥è¯·ç¡®ä¿ä½ æœ‰[git-lfs](https://git-lfs.github.com/)å®‰è£…ï¼ˆè¯·å‚é˜…æ­¤å¤„äº†è§£å®‰è£…è¯´æ˜ï¼‰å¹¶åœ¨å¼€å§‹ä¹‹å‰è¿›è¡Œè®¾ç½®ã€‚

é¦–å…ˆä»åˆå§‹åŒ– git-lfs å¼€å§‹ï¼š

```bash
git lfs install
```

```bash
Updated git hooks.
Git LFS initialized.
```

å®Œæˆåï¼Œç¬¬ä¸€æ­¥æ˜¯å…‹éš†æ‚¨çš„æ¨¡å‹å­˜å‚¨åº“ï¼š

```bash
git clone https://huggingface.co/<namespace>/<your-model-id>
```

æˆ‘çš„ç”¨æˆ·åæ˜¯ **lysandre** æˆ‘ä½¿ç”¨äº†æ¨¡å‹åç§° **dummy** ï¼Œæ‰€ä»¥å¯¹æˆ‘æ¥è¯´ï¼Œå‘½ä»¤æœ€ç»ˆå¦‚ä¸‹æ‰€ç¤ºï¼š

```
git clone https://huggingface.co/lysandre/dummy
```

æˆ‘ç°åœ¨æœ‰ä¸€ä¸ªåä¸ºçš„æ–‡ä»¶å¤¹å‡åœ¨æˆ‘çš„å·¥ä½œç›®å½•ä¸­ã€‚æˆ‘èƒ½ **cd** è¿›å…¥æ–‡ä»¶å¤¹å¹¶æŸ¥çœ‹å†…å®¹ï¼š

```bash
cd dummy && ls
```

```bash
README.md
```

å¦‚æœæ‚¨åˆšåˆšä½¿ç”¨ Hugging Face Hub åˆ›å»ºäº†æ‚¨çš„å­˜å‚¨åº“ **create_repo** æ–¹æ³•ï¼Œè¿™ä¸ªæ–‡ä»¶å¤¹åº”è¯¥åªåŒ…å«ä¸€ä¸ªéšè—çš„ **.gitattributes** æ–‡ä»¶ã€‚å¦‚æœæ‚¨æŒ‰ç…§ä¸Šä¸€èŠ‚ä¸­çš„è¯´æ˜ä½¿ç”¨ Web ç•Œé¢åˆ›å»ºå­˜å‚¨åº“ï¼Œåˆ™è¯¥æ–‡ä»¶å¤¹åº”åŒ…å«ä¸€ä¸ªè‡ªè¿°æ–‡ä»¶æ–‡ä»¶æ—è¾¹çš„éšè— **.gitattributes** æ–‡ä»¶ï¼Œå¦‚å›¾æ‰€ç¤ºã€‚

æ·»åŠ ä¸€ä¸ªå¸¸è§„å¤§å°çš„æ–‡ä»¶ï¼Œä¾‹å¦‚é…ç½®æ–‡ä»¶ã€è¯æ±‡æ–‡ä»¶ï¼Œæˆ–è€…åŸºæœ¬ä¸Šä»»ä½•å‡ å…†å­—èŠ‚ä»¥ä¸‹çš„æ–‡ä»¶ï¼Œå°±åƒåœ¨ä»»ä½•åŸºäº git çš„ç³»ç»Ÿä¸­æ‰€åšçš„ä¸€æ ·ã€‚ä½†æ˜¯ï¼Œæ›´å¤§çš„æ–‡ä»¶å¿…é¡»é€šè¿‡ git-lfs æ³¨å†Œæ‰èƒ½å°†å®ƒä»¬æ¨é€åˆ°Hugging Faceã€‚

è®©æˆ‘ä»¬å›åˆ° Python æ¥ç”Ÿæˆæˆ‘ä»¬æƒ³è¦æäº¤åˆ°æˆ‘ä»¬çš„è™šæ‹Ÿå­˜å‚¨åº“çš„æ¨¡å‹å’Œæ ‡è®°å™¨ï¼š

{#if fw === 'pt'}
```py
from transformers import AutoModelForMaskedLM, AutoTokenizer

checkpoint = "camembert-base"

model = AutoModelForMaskedLM.from_pretrained(checkpoint)
tokenizer = AutoTokenizer.from_pretrained(checkpoint)

# Do whatever with the model, train it, fine-tune it...

model.save_pretrained("<path_to_dummy_folder>")
tokenizer.save_pretrained("<path_to_dummy_folder>")
```
{:else}
```py
from transformers import TFAutoModelForMaskedLM, AutoTokenizer

checkpoint = "camembert-base"

model = TFAutoModelForMaskedLM.from_pretrained(checkpoint)
tokenizer = AutoTokenizer.from_pretrained(checkpoint)

# Do whatever with the model, train it, fine-tune it...

model.save_pretrained("<path_to_dummy_folder>")
tokenizer.save_pretrained("<path_to_dummy_folder>")
```
{/if}

ç°åœ¨æˆ‘ä»¬å·²ç»ä¿å­˜äº†ä¸€äº›æ¨¡å‹å’Œæ ‡è®°å™¨å·¥ä»¶ï¼Œè®©æˆ‘ä»¬å†çœ‹çœ‹å‡æ–‡ä»¶å¤¹ï¼š

```bash
ls
```

{#if fw === 'pt'}
```bash
added_tokens.json config.json model.safetensors sentencepiece.bpe.model special_tokens_map.json tokenizer_config.json tokenizer.json
```

If you look at the file sizes (for example, with `ls -lh`), you should see that the model state dict file (*model.safetensors *) is the only outlier, at more than 400 MB.

{:else}
```bash
config.json  README.md  sentencepiece.bpe.model  special_tokens_map.json  tf_model.h5  tokenizer_config.json  tokenizer.json
```

å¦‚æœæ‚¨æŸ¥çœ‹æ–‡ä»¶å¤§å°ï¼ˆä¾‹å¦‚ï¼Œ **ls -lh** )ï¼Œæ‚¨åº”è¯¥ä¼šçœ‹åˆ°æ¨¡å‹çŠ¶æ€ dict æ–‡ä»¶ (pytorch_model.bin) æ˜¯å”¯ä¸€çš„å¼‚å¸¸å€¼ï¼Œè¶…è¿‡ 400 MBã€‚

{/if}

<Tip>
âœï¸ ä» web ç•Œé¢åˆ›å»ºå­˜å‚¨åº“æ—¶ï¼Œ*.gitattributes* æ–‡ä»¶ä¼šè‡ªåŠ¨è®¾ç½®ä¸ºå°†å…·æœ‰æŸäº›æ‰©å±•åçš„æ–‡ä»¶ï¼Œä¾‹å¦‚ *.safetensors* å’Œ *.h5* è§†ä¸ºå¤§æ–‡ä»¶ï¼Œgit-lfs ä¼šå¯¹å…¶è¿›è¡Œè·Ÿè¸ªæ‚¨æ— éœ€è¿›è¡Œå¿…è¦çš„è®¾ç½®ã€‚
</Tip> 

æˆ‘ä»¬ç°åœ¨å¯ä»¥ç»§ç»­è¿›è¡Œï¼Œå°±åƒæˆ‘ä»¬é€šå¸¸ä½¿ç”¨ä¼ ç»Ÿ Git å­˜å‚¨åº“ä¸€æ ·ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å°†æ‰€æœ‰æ–‡ä»¶æ·»åŠ åˆ° Git çš„æš‚å­˜ç¯å¢ƒä¸­ **git add** å‘½ä»¤ï¼š

```bash
git add .
```

ç„¶åæˆ‘ä»¬å¯ä»¥æŸ¥çœ‹å½“å‰æš‚å­˜çš„æ–‡ä»¶ï¼š

```bash
git status
```

{#if fw === 'pt'}
```bash
On branch main
Your branch is up to date with 'origin/main'.

Changes to be committed:
  (use "git restore --staged <file>..." to unstage)
  modified:   .gitattributes
	new file:   added_tokens.json
	new file:   config.json
	new file:   model.safetensors
	new file:   sentencepiece.bpe.mode
	new file:   special_tokens_map.json
	new file:   tokenizer_config.json
	new file:   tokenizer.json
```
{:else}
```bash
On branch main
Your branch is up to date with 'origin/main'.

Changes to be committed:
  (use "git restore --staged <file>..." to unstage)
  modified:   .gitattributes
  	new file:   config.json
	new file:   sentencepiece.bpe.model
	new file:   special_tokens_map.json
	new file:   tf_model.h5
	new file:   tokenizer.json
	new file:   tokenizer_config.json
```
{/if}

åŒæ ·ï¼Œæˆ‘ä»¬å¯ä»¥ç¡®ä¿ git-lfs ä½¿ç”¨å…¶è·Ÿè¸ªæ­£ç¡®çš„æ–‡ä»¶ **status** å‘½ä»¤ï¼š

```bash
git lfs status
```

{#if fw === 'pt'}
```bash
On branch main
Objects to be pushed to origin/main:


Objects to be committed:

	added_tokens.json (Git: 43734cd)
	config.json (Git: acfd093)
	model.safetensors (LFS: 2785d2e)
	sentencepiece.bpe.model (LFS: 988bc5a)
	special_tokens_map.json (Git: b547935)
	tokenizer.json (Git: 18d0f7a)
	tokenizer_config.json (Git: c49982e)

Objects not staged for commit:


```

æˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ‰€æœ‰æ–‡ä»¶éƒ½æœ‰ **Git** ä½œä¸ºå¤„ç†ç¨‹åºï¼Œé™¤äº†å…¶ä¸­æœ‰ **LFS**çš„*pytorch_model.bin* å’Œ *sentencepiece.bpe.model*ã€‚

{:else}
```bash
On branch main
Objects to be pushed to origin/main:


Objects to be committed:

	config.json (Git: bc20ff2)
	sentencepiece.bpe.model (LFS: 988bc5a)
	special_tokens_map.json (Git: cb23931)
	tf_model.h5 (LFS: 86fce29)
	tokenizer.json (Git: 851ff3e)
	tokenizer_config.json (Git: f0f7783)

Objects not staged for commit:


```

æˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ‰€æœ‰æ–‡ä»¶éƒ½æœ‰ **Git** ä½œä¸ºå¤„ç†ç¨‹åºï¼Œé™¤äº†å…¶ä¸­æœ‰ **LFS**çš„*t5_model.h5*ã€‚

{/if}

è®©æˆ‘ä»¬ç»§ç»­æœ€åçš„æ­¥éª¤ï¼Œæäº¤å¹¶æ¨é€åˆ°Hugging Faceè¿œç¨‹ä»“åº“ï¼š

```bash
git commit -m "First model version"
```

{#if fw === 'pt'}
```bash
[main c2ec5c9] First model version
 7 files changed, 128351 insertions(+)
 create mode 100644 added_tokens.json
 create mode 100644 config.json
 create mode 100644 model.safetensors
 create mode 100644 sentencepiece.bpe.model
 create mode 100644 special_tokens_map.json
 create mode 100644 tokenizer.json
 create mode 100644 tokenizer_config.json
```
{:else}
```bash
[main b08aab1] First model version
 6 files changed, 36 insertions(+)
 create mode 100644 config.json
 create mode 100644 sentencepiece.bpe.model
 create mode 100644 special_tokens_map.json
 create mode 100644 tf_model.h5
 create mode 100644 tokenizer.json
 create mode 100644 tokenizer_config.json
```
{/if}

æ¨é€å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼Œå…·ä½“å–å†³äºæ‚¨çš„äº’è”ç½‘è¿æ¥é€Ÿåº¦å’Œæ–‡ä»¶å¤§å°ï¼š

```bash
git push
```

```bash
Uploading LFS objects: 100% (2/2), 444 MB | 86 MB/s, done.
Enumerating objects: 10, done.
Counting objects: 100% (10/10), done.
Delta compression using up to 2 threads
Compressing objects: 100% (8/8), done.
Writing objects: 100% (9/9), 592.02 KiB | 6.30 MiB/s, done.
Total 9 (delta 0), reused 0 (delta 0), pack-reused 0
To https://huggingface.co/lysandre/dummy
   70fd9db..c2ec5c9  main -> main
```

{#if fw === 'pt'}
If we take a look at the model repository when this is finished, we can see all the recently added files:

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/full_model.png" alt="The 'Files and versions' tab now contains all the recently uploaded files." width="80%"/>
</div>

UI å…è®¸æ‚¨æµè§ˆæ¨¡å‹æ–‡ä»¶å’Œæäº¤ï¼Œå¹¶æŸ¥çœ‹æ¯ä¸ªæäº¤å¼•å…¥çš„å·®å¼‚ï¼š

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/diffs.gif" alt="The diff introduced by the recent commit." width="80%"/>
</div>

{:else}

å¦‚æœæˆ‘ä»¬åœ¨å®ŒæˆåæŸ¥çœ‹æ¨¡å‹å­˜å‚¨åº“ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ‰€æœ‰æœ€è¿‘æ·»åŠ çš„æ–‡ä»¶ï¼š

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/full_model_tf.png" alt="The 'Files and versions' tab now contains all the recently uploaded files." width="80%"/>
</div>

UI å…è®¸æ‚¨æµè§ˆæ¨¡å‹æ–‡ä»¶å’Œæäº¤ï¼Œå¹¶æŸ¥çœ‹æ¯ä¸ªæäº¤å¼•å…¥çš„å·®å¼‚ï¼š

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/diffstf.gif" alt="The diff introduced by the recent commit." width="80%"/>
</div>
{/if}
