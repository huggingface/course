# å¤§æ•°æ®ï¼ŸğŸ¤— Datasets åº”å¯¹æœ‰æ–¹ï¼[[å¤§æ•°æ®ï¼ŸğŸ¤— Datasets åº”å¯¹æœ‰æ–¹ï¼]]

<CourseFloatingBanner chapter={5}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/zh-CN/chapter5/section4.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/zh-CN/chapter5/section4.ipynb"},
]} />


å¦‚ä»Šï¼Œå¤„ç† GB çº§åˆ«çš„æ•°æ®é›†å·²ä¸å†ç½•è§ï¼Œç‰¹åˆ«æ˜¯å¦‚æœä½ æ‰“ç®—ä»å¤´å¼€å§‹é¢„è®­ç»ƒåƒ BERT æˆ–è€… GPT-2 è¿™æ ·çš„ Transormer æ¨¡å‹ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç”šè‡³ `åŠ è½½(load)` æ•°æ®é›†éƒ½å¯èƒ½æˆä¸ºæŒ‘æˆ˜ã€‚ä¾‹å¦‚ï¼Œç”¨äºé¢„è®­ç»ƒ GPT-2 çš„ WebText è¯­æ–™åº“åŒ…å«è¶…è¿‡ 800 ä¸‡ä¸ªæ–‡æ¡£å’Œ 40 GB çš„æ–‡æœ¬ â€”â€” å°†å…¶åŠ è½½åˆ°ç¬”è®°æœ¬ç”µè„‘çš„ RAM ä¸­éƒ½å¯èƒ½ä¼šè®©äººæŠ“ç‹‚ï¼

å¹¸è¿çš„æ˜¯ï¼ŒğŸ¤— Datasets çš„è®¾è®¡æ—¨åœ¨å…‹æœè¿™äº›é™åˆ¶ã€‚å®ƒé€šè¿‡å°†æ•°æ®é›†ä½œä¸º `å†…å­˜æ˜ å°„(memory-mapped)` æ–‡ä»¶æ¥å¤„ç†ï¼Œè§£æ”¾å†…å­˜ç®¡ç†é—®é¢˜ï¼›å¹¶é€šè¿‡ `æµå¼å¤„ç†(streaming)` æ¥æ‘†è„±ç¡¬ç›˜é™åˆ¶ã€‚

<Youtube id="JwISwTCPPWo"/>

åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ªåºå¤§çš„ 825 GB è¯­æ–™åº“â€”â€”è¢«ç§°ä¸º [the Pile](https://pile.eleuther.ai) çš„æ•°æ®é›†ï¼Œæ¥æ¢ç´¢ğŸ¤— Datasets çš„è¿™äº›åŠŸèƒ½ã€‚è®©æˆ‘ä»¬å¼€å§‹å§ï¼

## ä»€ä¹ˆæ˜¯ the Pileï¼Ÿ[[ä»€ä¹ˆæ˜¯ the Pile?]]

The Pile æ˜¯ç”± [EleutherAI](https://www.eleuther.ai) åˆ›å»ºçš„ä¸€ä¸ªç”¨äºè®­ç»ƒå¤§è§„æ¨¡è¯­è¨€æ¨¡å‹çš„è‹±è¯­æ–‡æœ¬è¯­æ–™åº“ã€‚å®ƒåŒ…å«å„ç§å„æ ·çš„æ•°æ®é›†ï¼Œæ¶µç›–ç§‘å­¦æ–‡ç« ï¼ŒGitHub ä»£ç åº“ä»¥åŠè¿‡æ»¤åçš„ Web æ–‡æœ¬ã€‚è®­ç»ƒè¯­æ–™åº“ä»¥ [14 GB çš„æ–‡ä»¶å—](https://the-eye.eu/public/AI/pile/) æä¾›ï¼Œå¹¶ä¸”ä½ ä¹Ÿå¯ä»¥ä¸‹è½½å‡ ä¸ª [å•ç‹¬çš„ç»„ä»¶](https://the-eye.eu/public/AI/pile_preliminary_components/) ã€‚è®©æˆ‘ä»¬å…ˆæ¥çœ‹çœ‹ PubMed Abstracts éƒ¨åˆ†ï¼Œå®ƒæ˜¯ [PubMed](https://pubmed.ncbi.nlm.nih.gov/) ä¸Šçš„ 1500 ä¸‡ç¯‡ç”Ÿç‰©åŒ»å­¦å‡ºç‰ˆç‰©çš„æ‘˜è¦çš„è¯­æ–™åº“ã€‚æ•°æ®é›†é‡‡ç”¨ [JSON Linesæ ¼å¼](https://jsonlines.org) å¹¶ä½¿ç”¨ `zstandard` åº“è¿›è¡Œå‹ç¼©ï¼Œæ‰€ä»¥æˆ‘ä»¬é¦–å…ˆéœ€è¦å…ˆå®‰è£… `zstandard` åº“ï¼š

```py
!pip install zstandard
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ [ç¬¬äºŒèŠ‚](/course/chapter5/2) ä¸­æ‰€å­¦çš„åŠ è½½è¿œç¨‹æ•°æ®é›†çš„æ–¹æ³•åŠ è½½æ•°æ®é›†ï¼š

```py
from datasets import load_dataset

# è¿™éœ€è¦å‡ åˆ†é’Ÿæ‰èƒ½è¿è¡Œ,æ‰€ä»¥åœ¨ä½ ç­‰å¾…çš„æ—¶å€™å»å–æ¯èŒ¶æˆ–å’–å•¡ :)
data_files = "https://the-eye.eu/public/AI/pile_preliminary_components/PUBMED_title_abstracts_2019_baseline.jsonl.zst"
pubmed_dataset = load_dataset("json", data_files=data_files, split="train")
pubmed_dataset
```

```python out
Dataset({
    features: ['meta', 'text'],
    num_rows: 15518009
})
```

æˆ‘ä»¬å¯ä»¥çœ‹åˆ°æˆ‘ä»¬çš„æ•°æ®é›†ä¸­æœ‰ 15,518,009 è¡Œå’Œ 2 åˆ— â€”â€” å¦‚æ­¤åºå¤§ï¼

<Tip>

âœï¸ é»˜è®¤æƒ…å†µä¸‹ï¼ŒğŸ¤— Datasets ä¼šè‡ªåŠ¨è§£å‹åŠ è½½æ•°æ®é›†æ‰€éœ€çš„æ–‡ä»¶ã€‚å¦‚æœä½ æƒ³ä¿ç•™ç¡¬ç›˜ç©ºé—´ï¼Œä½ å¯ä»¥æŠŠ `DownloadConfig(delete_extracted=True)` ä¼ é€’ç»™ `load_dataset()` çš„ `download_config` å‚æ•°ã€‚æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜… [æ–‡æ¡£](https://huggingface.co/docs/datasets/package_reference/builder_classes#datasets.DownloadConfig) ã€‚

</Tip>

è®©æˆ‘ä»¬çœ‹çœ‹æ•°æ®é›†çš„ç¬¬ä¸€ä¸ªå…ƒç´ çš„å†…å®¹ï¼š

```py
pubmed_dataset[0]
```

```python out
{'meta': {'pmid': 11409574, 'language': 'eng'},
 'text': 'Epidemiology of hypoxaemia in children with acute lower respiratory infection.\nTo determine the prevalence of hypoxaemia in children aged under 5 years suffering acute lower respiratory infections (ALRI), the risk factors for hypoxaemia in children under 5 years of age with ALRI, and the association of hypoxaemia with an increased risk of dying in children of the same age ...'}
```

å¯ä»¥çœ‹åˆ°ï¼Œè¿™çœ‹èµ·æ¥åƒæ˜¯åŒ»å­¦æ–‡ç« çš„æ‘˜è¦ã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹åŠ è½½æ•°æ®é›†æ‰€ä½¿ç”¨çš„ RAMï¼

## å†…å­˜æ˜ å°„çš„é­”åŠ› [[å†…å­˜æ˜ å°„çš„é­”åŠ›]]

æµ‹é‡ Python å†…å­˜ä½¿ç”¨çš„ç®€å•æ–¹å¼æ˜¯ä½¿ç”¨ [`psutil`](https://psutil.readthedocs.io/en/latest/) åº“ï¼Œå¯ä»¥é€šè¿‡å¦‚ä¸‹æ–¹å¼å®‰è£…ï¼š

```python
!pip install psutil
```

å®ƒæä¾›äº†ä¸€ä¸ª `Process` ç±»ï¼Œè®©æˆ‘ä»¬å¯ä»¥æ£€æŸ¥å½“å‰è¿›ç¨‹çš„å†…å­˜ä½¿ç”¨æƒ…å†µï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```py
import psutil

# Process.memory_info æ˜¯ä»¥å­—èŠ‚ä¸ºå•ä½çš„,æ‰€ä»¥è½¬æ¢ä¸ºå…†å­—èŠ‚
print(f"ä½¿ç”¨çš„RAM:{psutil.Process().memory_info().rss / (1024 * 1024):.2f} MB")
```

```python out
RAM used: 5678.33 MB
```

è¿™é‡Œçš„ `rss` å±æ€§æ˜¯æŒ‡ `å¸¸é©»é›†ï¼ˆresident set sizeï¼‰` çš„å¤§å°ï¼Œå®ƒæ˜¯è¿›ç¨‹åœ¨ RAM ä¸­å ç”¨çš„å†…å­˜çš„éƒ¨åˆ†ã€‚è¿™ä¸ªæµ‹é‡ç»“æœä¹ŸåŒ…æ‹¬äº† Python è§£é‡Šå™¨å’Œæˆ‘ä»¬åŠ è½½çš„åº“æ‰€ä½¿ç”¨çš„å†…å­˜ï¼Œæ‰€ä»¥å®é™…ä¸Šç”¨äºåŠ è½½æ•°æ®é›†çš„å†…å­˜ä¼šæ›´å°ä¸€äº›ã€‚ä½œä¸ºæ¯”è¾ƒï¼Œè®©æˆ‘ä»¬ä½¿ç”¨ `dataset_size` å±æ€§çœ‹çœ‹æ•°æ®é›†åœ¨ç£ç›˜ä¸Šä¸Šçš„å¤§å°ã€‚ç”±äºç»“æœåƒä¹‹å‰ä¸€æ ·ä»¥å­—èŠ‚ä¸ºå•ä½ï¼Œæˆ‘ä»¬éœ€è¦æ‰‹åŠ¨å°†å…¶è½¬æ¢ä¸º GBï¼š

```py
print(f"æ•°æ®é›†ä¸­æ–‡ä»¶çš„æ•°é‡ : {pubmed_dataset.dataset_size}")
size_gb = pubmed_dataset.dataset_size / (1024**3)
print(f"æ•°æ®é›†å¤§å° (ç¼“å­˜æ–‡ä»¶) : {size_gb:.2f} GB")
```

```python out
æ•°æ®é›†ä¸­æ–‡ä»¶çš„æ•°é‡ : 20979437051
æ•°æ®é›†å¤§å° (ç¼“å­˜æ–‡ä»¶) : 19.54 GB
```

ä»¤äººæ¬£å–œçš„æ˜¯â€”â€”å°½ç®¡å®ƒå°†è¿‘ 20GB ä¹‹å¤§ï¼Œæˆ‘ä»¬å´èƒ½ç”¨è¿œå°äºæ­¤çš„ RAM åŠ è½½å’Œè®¿é—®æ•°æ®é›†ï¼

<Tip>

âœï¸ **è¯•è¯•çœ‹ï¼** ä» Pile é€‰æ‹©ä¸€ä¸ªæ¯”ä½ çš„ç¬”è®°æœ¬ç”µè„‘æˆ–å°å¼æœºçš„ RAM æ›´å¤§çš„ [å­é›†](https://the-eye.eu/public/AI/pile_preliminary_components/) ï¼Œç”¨ ğŸ¤— Datasets åŠ è½½è¿™ä¸ªæ•°æ®é›†ï¼Œå¹¶ä¸”æµ‹é‡ RAM çš„ä½¿ç”¨é‡ã€‚è¯·æ³¨æ„ï¼Œä¸ºäº†è·å¾—å‡†ç¡®çš„æµ‹é‡ç»“æœï¼Œä½ éœ€è¦æ–°å¼€ä¸€ä¸ªè¿›ç¨‹æ‰§è¡Œè¿™ä¸ªæ“ä½œã€‚ä½ å¯ä»¥åœ¨ [the Pile paper](https://arxiv.org/abs/2101.00027) çš„è¡¨ 1 ä¸­æ‰¾åˆ°æ¯ä¸ªå­é›†è§£å‹åçš„å¤§å°ã€‚

</Tip>

å¦‚æœä½ ç†Ÿæ‚‰ Pandasï¼Œè¿™ä¸ªç»“æœå¯èƒ½ä¼šè®©äººæ„Ÿåˆ°å¾ˆæƒŠå¥‡ã€‚å› ä¸ºæ ¹æ® Wes Kinney çš„è‘—åçš„ [ç»éªŒæ³•åˆ™](https://wesmckinney.com/blog/apache-arrow-pandas-internals/) ï¼Œä½ é€šå¸¸éœ€è¦ 5 åˆ° 10 å€äºä½ æ•°æ®é›†å¤§å°çš„ RAMã€‚é‚£ä¹ˆ ğŸ¤— Datasets æ˜¯å¦‚ä½•è§£å†³è¿™ä¸ªå†…å­˜ç®¡ç†é—®é¢˜çš„å‘¢ï¼ŸğŸ¤— Datasets å°†æ¯ä¸€ä¸ªæ•°æ®é›†çœ‹ä½œä¸€ä¸ª [å†…å­˜æ˜ å°„æ–‡ä»¶](https://en.wikipedia.org/wiki/Memory-mapped_file) ï¼Œå®ƒæä¾›äº† RAM å’Œæ–‡ä»¶ç³»ç»Ÿå­˜å‚¨ä¹‹é—´çš„æ˜ å°„ï¼Œè¯¥æ˜ å°„å…è®¸ Datasets åº“æ— éœ€å°†å…¶å®Œå…¨åŠ è½½åˆ°å†…å­˜ä¸­å³å¯è®¿é—®å’Œæ“ä½œæ•°æ®é›†çš„å…ƒç´ ã€‚

å†…å­˜æ˜ å°„æ–‡ä»¶ä¹Ÿä¸€ä¸ªåœ¨å¤šä¸ªè¿›ç¨‹ä¹‹é—´å…±äº«ï¼Œè¿™ä½¿å¾—åƒ `Dataset.map()` ä¹‹ç±»çš„æ–¹æ³•å¯ä»¥åœ¨æ— éœ€ç§»åŠ¨æˆ–è€…å¤åˆ¶æ•°æ®é›†çš„æƒ…å†µä¸‹å®ç°å¹¶è¡ŒåŒ–ã€‚åœ¨åº•å±‚ï¼Œè¿™äº›åŠŸèƒ½éƒ½æ˜¯ç”± [Apache Arrow](https://arrow.apache.org) å†…å­˜æ ¼å¼å’Œ [`pyarrow`](https://arrow.apache.org/docs/python/index.html) åº“å®ç°çš„ï¼Œè¿™ä½¿å¾—æ•°æ®åŠ è½½å’Œå¤„ç†é€Ÿåº¦å¿«å¦‚é—ªç”µã€‚ï¼ˆæ›´å¤šæœ‰å…³ Apache Arrow çš„è¯¦ç»†ä¿¡æ¯ä»¥åŠä¸ Pandas çš„æ¯”è¾ƒï¼Œè¯·æŸ¥çœ‹ [Dejan Simicçš„åšå®¢æ–‡ç« ](https://towardsdatascience.com/apache-arrow-read-dataframe-with-zero-memory-69634092b1a) ã€‚ï¼‰ ä¸ºäº†æ›´æ¸…æ™°åœ°çœ‹åˆ°è¿™ä¸ªè¿‡ç¨‹ï¼Œè®©æˆ‘ä»¬é€šè¿‡éå† PubMed æ‘˜è¦æ•°æ®é›†ä¸­çš„æ‰€æœ‰å…ƒç´ ï¼Œè¿è¡Œä¸€ä¸ªå°é€Ÿåº¦æµ‹è¯•ï¼š

```py
import timeit

code_snippet = """batch_size = 1000

for idx in range(0, len(pubmed_dataset), batch_size):
    _ = pubmed_dataset[idx:idx + batch_size]
"""

time = timeit.timeit(stmt=code_snippet, number=1, globals=globals())
print(
    f"åœ¨ {time:.1f}s å†…éå†äº† {len(pubmed_dataset)}ä¸ªç¤ºä¾‹(çº¦ {size_gb:.1f} GB),å³ {size_gb/time:.3f} GB/s"
)
```

```python out
'åœ¨64.2så†…éå†äº†15518009ä¸ªç¤ºä¾‹(çº¦19.5 GB),å³0.304 GB/s'
```

è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨äº† Python çš„ `timeit` æ¨¡å—æ¥æµ‹é‡æ‰§è¡Œ `code_snippet` æ‰€è€—çš„æ—¶é—´ã€‚ä½ é€šå¸¸èƒ½ä»¥ååˆ†ä¹‹å‡  GB/s åˆ°å‡  GB/s çš„é€Ÿåº¦éå†ä¸€ä¸ªæ•°æ®é›†ã€‚é€šè¿‡ä¸Šè¿°çš„æ–¹æ³•å°±å·²ç»èƒ½å¤Ÿè§£å†³å¤§å¤šæ•°å¤§æ•°æ®é›†åŠ è½½çš„é™åˆ¶ï¼Œä½†æ˜¯æœ‰æ—¶å€™ä½ ä¸å¾—ä¸ä½¿ç”¨ä¸€ä¸ªå¾ˆå¤§çš„æ•°æ®é›†ï¼Œå®ƒç”šè‡³éƒ½ä¸èƒ½å­˜å‚¨åœ¨ç¬”è®°æœ¬ç”µè„‘çš„ç¡¬ç›˜ä¸Šã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬å°è¯•ä¸‹è½½æ•´ä¸ª Pileï¼Œæˆ‘ä»¬éœ€è¦ 825GB çš„å¯ç”¨ç£ç›˜ç©ºé—´ï¼ä¸ºäº†å¤„ç†è¿™ç§æƒ…å†µï¼ŒğŸ¤— Datasets æä¾›äº†ä¸€ä¸ªæµå¼åŠŸèƒ½ï¼Œè¿™ä¸ªåŠŸèƒ½å…è®¸æˆ‘ä»¬åŠ¨æ€ä¸‹è½½å’Œè®¿é—®å…ƒç´ ï¼Œå¹¶ä¸”ä¸éœ€è¦ä¸‹è½½æ•´ä¸ªæ•°æ®é›†ã€‚è®©æˆ‘ä»¬æ¥çœ‹çœ‹è¿™ä¸ªåŠŸèƒ½æ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚

<Tip>

ğŸ’¡åœ¨ Jupyter ç¬”è®°ä¸­ä½ è¿˜å¯ä»¥ä½¿ç”¨ [`%%timeit` é­”æœ¯å‡½æ•°](https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-timeit) ä¸ºæ•´ä¸ªå•å…ƒæ ¼è®¡æ—¶ã€‚

</Tip>

## æµå¼æ•°æ®é›† [[æµå¼æ•°æ®é›†]]

è¦ä½¿ç”¨æ•°æ®é›†æµï¼Œä½ åªéœ€è¦å°† `streaming=True` å‚æ•°ä¼ é€’ç»™ `load_dataset()` å‡½æ•°ã€‚æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬ä»¥æµæ¨¡å¼åŠ è½½ PubMed æ‘˜è¦æ•°æ®é›†ï¼š

```py
pubmed_dataset_streamed = load_dataset(
    "json", data_files=data_files, split="train", streaming=True
)
```

ä¸åŒäºæˆ‘ä»¬åœ¨è¿™ä¸€ç« å…¶å®ƒåœ°æ–¹é‡åˆ°çš„ç†Ÿæ‚‰çš„ `Dataset` ï¼Œ `streaming=True` è¿”å›çš„å¯¹è±¡æ˜¯ä¸€ä¸ª `IterableDataset` ã€‚é¡¾åæ€ä¹‰ï¼Œè¦è®¿é—® `IterableDataset` ï¼Œæˆ‘ä»¬éœ€è¦è¿­ä»£å®ƒã€‚æˆ‘ä»¬å¯ä»¥æŒ‰ç…§å¦‚ä¸‹æ–¹å¼è®¿é—®æµå¼æ•°æ®é›†çš„ç¬¬ä¸€ä¸ªå…ƒç´ ï¼š


```py
next(iter(pubmed_dataset_streamed))
```

```python out
{'meta': {'pmid': 11409574, 'language': 'eng'},
 'text': 'Epidemiology of hypoxaemia in children with acute lower respiratory infection.\nTo determine the prevalence of hypoxaemia in children aged under 5 years suffering acute lower respiratory infections (ALRI), the risk factors for hypoxaemia in children under 5 years of age with ALRI, and the association of hypoxaemia with an increased risk of dying in children of the same age ...'}
```

å¦‚æœä½ éœ€è¦åœ¨è®­ç»ƒæœŸé—´å¯¹æµå¼æ•°æ®é›†ä¸­çš„å…ƒç´  tokenizeï¼Œå¯ä»¥ä½¿ç”¨ `IterableDataset.map()` è¿›è¡Œåœ¨çº¿å¤„ç†ï¼Œè€Œä¸éœ€è¦ç­‰å¾…æ•°æ®é›†å…¨éƒ¨åŠ è½½å®Œæ¯•ã€‚è¯¥è¿‡ç¨‹ä¸æˆ‘ä»¬åœ¨ [ç¬¬ä¸‰ç« ](/course/chapter3) ä¸­å¯¹æ•°æ®é›† tokenize çš„è¿‡ç¨‹å®Œå…¨ç›¸åŒï¼Œå”¯ä¸€çš„åŒºåˆ«æ˜¯è¾“å‡ºæ˜¯é€ä¸ªè¿”å›çš„ï¼š

```py
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased")
tokenized_dataset = pubmed_dataset_streamed.map(lambda x: tokenizer(x["text"]))
next(iter(tokenized_dataset))
```

```python out
{'input_ids': [101, 4958, 5178, 4328, 6779, ...], 'attention_mask': [1, 1, 1, 1, 1, ...]}
```

<Tip>

ğŸ’¡ ä¸ºäº†åŠ é€Ÿæµå¼çš„ tokenizeï¼Œä½ å¯ä»¥ä¼ é€’ `batched=True` ï¼Œå°±åƒæˆ‘ä»¬åœ¨ä¸Šä¸€èŠ‚çœ‹åˆ°çš„é‚£æ ·ã€‚å®ƒä¼šæ‰¹é‡å¤„ç†ç¤ºä¾‹ï¼›é»˜è®¤çš„æ‰¹å¤§å°æ˜¯ 1000ï¼Œå¯ä»¥é€šè¿‡ `batch_size` å‚æ•°æŒ‡å®šæ‰¹é‡å¤§å°ã€‚

</Tip>

ä½ è¿˜å¯ä»¥ä½¿ç”¨ `IterableDataset.shuffle()` æ‰“ä¹±æµå¼æ•°æ®é›†ï¼Œä½†ä¸ `Dataset.shuffle()` ä¸åŒçš„æ˜¯è¿™åªä¼šæ‰“ä¹±é¢„å®šä¹‰ `buffer_size` ä¸­çš„å…ƒç´ ï¼š

```py
shuffled_dataset = pubmed_dataset_streamed.shuffle(buffer_size=10_000, seed=42)
next(iter(shuffled_dataset))
```

```python out
{'meta': {'pmid': 11410799, 'language': 'eng'},
 'text': 'Randomized study of dose or schedule modification of granulocyte colony-stimulating factor in platinum-based chemotherapy for elderly patients with lung cancer ...'}
```

åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬ä»ç¼“å†²åŒºçš„å‰ 10,000 ä¸ªç¤ºä¾‹ä¸­éšæœºé€‰æ‹©äº†ä¸€ä¸ªç¤ºä¾‹ã€‚ä¸€æ—¦è®¿é—®äº†ä¸€ä¸ªç¤ºä¾‹ï¼Œå®ƒåœ¨ç¼“å†²åŒºä¸­çš„ä½ç½®å°±ä¼šè¢«è¯­æ–™åº“ä¸­çš„ä¸‹ä¸€ä¸ªç¤ºä¾‹å¡«å…… ï¼ˆå³ï¼Œä¸Šè¿°æ¡ˆä¾‹ä¸­çš„ç¬¬ 10,001 ä¸ªç¤ºä¾‹ï¼‰ã€‚ä½ è¿˜å¯ä»¥ä½¿ç”¨ `IterableDataset.take()` å’Œ `IterableDataset.skip()` å‡½æ•°ä»æµå¼æ•°æ®é›†ä¸­é€‰æ‹©å…ƒç´ ï¼Œå®ƒçš„ä½œç”¨ç±»ä¼¼äº `Dataset.select()` ã€‚ä¾‹å¦‚ï¼Œè¦é€‰æ‹© PubMed Abstracts æ•°æ®é›†çš„å‰ 5 ä¸ªç¤ºä¾‹ï¼Œæˆ‘ä»¬å¯ä»¥æ‰§è¡Œä»¥ä¸‹ä»£ç ï¼š

```py
dataset_head = pubmed_dataset_streamed.take(5)
list(dataset_head)
```

```python out
[{'meta': {'pmid': 11409574, 'language': 'eng'},
  'text': 'Epidemiology of hypoxaemia in children with acute lower respiratory infection ...'},
 {'meta': {'pmid': 11409575, 'language': 'eng'},
  'text': 'Clinical signs of hypoxaemia in children with acute lower respiratory infection: indicators of oxygen therapy ...'},
 {'meta': {'pmid': 11409576, 'language': 'eng'},
  'text': "Hypoxaemia in children with severe pneumonia in Papua New Guinea ..."},
 {'meta': {'pmid': 11409577, 'language': 'eng'},
  'text': 'Oxygen concentrators and cylinders ...'},
 {'meta': {'pmid': 11409578, 'language': 'eng'},
  'text': 'Oxygen supply in rural africa: a personal experience ...'}]
```

åŒæ ·ï¼Œä½ å¯ä»¥ä½¿ç”¨ `IterableDataset.skip()` å‡½æ•°ä»æ‰“ä¹±çš„æ•°æ®é›†ä¸­åˆ›å»ºè®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```py
# è·³è¿‡å‰ 1,000 ä¸ªç¤ºä¾‹ ,å°†å…¶ä½™éƒ¨åˆ†åˆ›å»ºä¸ºè®­ç»ƒé›†
train_dataset = shuffled_dataset.skip(1000)
# å°†å‰ 1,000 ä¸ªç¤ºä¾‹ç”¨äºéªŒè¯é›†
validation_dataset = shuffled_dataset.take(1000)
```

è®©æˆ‘ä»¬ç”¨ä¸€ä¸ªå¸¸è§çš„ä»»åŠ¡æ¥è¿›è¡Œæˆ‘ä»¬å¯¹æ•°æ®é›†æµçš„æœ€åæ¢ç´¢ï¼šå°†å¤šä¸ªæ•°æ®é›†ç»„åˆåœ¨ä¸€èµ·åˆ›å»ºä¸€ä¸ªæ–°çš„è¯­æ–™åº“ã€‚ğŸ¤— Datasets æä¾›äº†ä¸€ä¸ª `interleave_datasets()` å‡½æ•°ï¼Œå®ƒå°†ä¸€ä¸ª `IterableDataset` å¯¹è±¡åˆ—è¡¨ç»„åˆä¸ºå•ä¸ªçš„ `IterableDataset` ï¼Œå…¶ä¸­æ–°æ•°æ®é›†çš„å…ƒç´ æ˜¯äº¤æ›¿æŠ½å–åˆ—è¡¨ä¸­çš„æ•°æ®é›†è·å¾—çš„ã€‚å½“ä½ è¯•å›¾ç»„åˆå¤§å‹æ•°æ®é›†æ—¶ï¼Œè¿™ä¸ªå‡½æ•°ç‰¹åˆ«æœ‰ç”¨ï¼Œè®©æˆ‘ä»¬é€šè¿‡ä¸‹é¢è¿™ä¸ªä¾‹å­æ¥è¯•ç€ç»„åˆ Pile çš„ FreeLaw æ•°æ®é›†ï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«ç¾å›½æ³•é™¢æ³•å¾‹æ„è§çš„ 51 GB æ•°æ®é›†ï¼š

```py
law_dataset_streamed = load_dataset(
    "json",
    data_files="https://the-eye.eu/public/AI/pile_preliminary_components/FreeLaw_Opinions.jsonl.zst",
    split="train",
    streaming=True,
)
next(iter(law_dataset_streamed))
```

```python out
{'meta': {'case_ID': '110921.json',
  'case_jurisdiction': 'scotus.tar.gz',
  'date_created': '2010-04-28T17:12:49Z'},
 'text': '\n461 U.S. 238 (1983)\nOLIM ET AL.\nv.\nWAKINEKONA\nNo. 81-1581.\nSupreme Court of United States.\nArgued January 19, 1983.\nDecided April 26, 1983.\nCERTIORARI TO THE UNITED STATES COURT OF APPEALS FOR THE NINTH CIRCUIT\n*239 Michael A. Lilly, First Deputy Attorney General of Hawaii, argued the cause for petitioners. With him on the brief was James H. Dannenberg, Deputy Attorney General...'}
```

è¿™ä¸ªæ•°æ®é›†è¶³å¤Ÿå¤§ï¼Œå¯ä»¥å¯¹å¤§å¤šæ•°ç¬”è®°æœ¬ç”µè„‘çš„ RAM æœ‰è¶³å¤Ÿçš„å‹åŠ›ï¼Œä½†æ˜¯æˆ‘ä»¬å·²ç»èƒ½å¤Ÿæ¯«ä¸è´¹åŠ›åœ°åŠ è½½å’Œè®¿é—®å®ƒï¼ç°åœ¨æˆ‘ä»¬ä½¿ç”¨ `interleave_datasets()` å‡½æ•°å°† FreeLaw å’Œ PubMed Abstracts æ•°æ®é›†çš„æ ·æœ¬æ•´åˆåœ¨ä¸€èµ·ï¼š

```py
from itertools import islice
from datasets import interleave_datasets

combined_dataset = interleave_datasets([pubmed_dataset_streamed, law_dataset_streamed])
list(islice(combined_dataset, 2))
```

```python out
[{'meta': {'pmid': 11409574, 'language': 'eng'},
  'text': 'Epidemiology of hypoxaemia in children with acute lower respiratory infection ...'},
 {'meta': {'case_ID': '110921.json',
   'case_jurisdiction': 'scotus.tar.gz',
   'date_created': '2010-04-28T17:12:49Z'},
  'text': '\n461 U.S. 238 (1983)\nOLIM ET AL.\nv.\nWAKINEKONA\nNo. 81-1581.\nSupreme Court of United States.\nArgued January 19, 1983.\nDecided April 26, 1983.\nCERTIORARI TO THE UNITED STATES COURT OF APPEALS FOR THE NINTH CIRCUIT\n*239 Michael A. Lilly, First Deputy Attorney General of Hawaii, argued the cause for petitioners. With him on the brief was James H. Dannenberg, Deputy Attorney General...'}]
```

è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨äº†æ¥è‡ª Python çš„ `itertools` æ¨¡å—çš„ `islice()` å‡½æ•°ä»åˆå¹¶çš„æ•°æ®é›†ä¸­é€‰æ‹©å‰ä¸¤ä¸ªç¤ºä¾‹ï¼Œå¹¶ä¸”æˆ‘ä»¬å¯ä»¥çœ‹åˆ°å®ƒä»¬å®é™…ä¸Šå°±æ˜¯ä¸¤ä¸ªæºæ•°æ®é›†ä¸­çš„å‰ä¸¤ä¸ªç¤ºä¾‹æ‹¼åœ¨ä¸€èµ·å½¢æˆçš„ï¼š

æœ€åï¼Œå¦‚æœä½ æƒ³æµå¼ä¼ è¾“æ•´ä¸ª 825GB çš„ Pileï¼Œä½ å¯ä»¥æŒ‰ç…§å¦‚ä¸‹æ–¹å¼è·å–æ‰€æœ‰çš„é¢„å¤„ç†æ–‡ä»¶ï¼š

```py
base_url = "https://the-eye.eu/public/AI/pile/"
data_files = {
    "train": [base_url + "train/" + f"{idx:02d}.jsonl.zst" for idx in range(30)],
    "validation": base_url + "val.jsonl.zst",
    "test": base_url + "test.jsonl.zst",
}
pile_dataset = load_dataset("json", data_files=data_files, streaming=True)
next(iter(pile_dataset["train"]))
```

```python out
{'meta': {'pile_set_name': 'Pile-CC'},
 'text': 'It is done, and submitted. You can play â€œSurvival of the Tastiestâ€ on Android, and on the web...'}
```

<Tip>

âœï¸ **è¯•è¯•çœ‹ï¼** ä½¿ç”¨åƒ [`mc4`](https://huggingface.co/datasets/mc4) æˆ–è€… [`oscar`](https://huggingface.co/datasets/oscar) è¿™æ ·çš„å¤§å‹ Common Crawl è¯­æ–™åº“æ¥åˆ›å»ºä¸€ä¸ªæµå¼å¤šè¯­è¨€æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†ä»£è¡¨ä½ é€‰æ‹©çš„å›½å®¶/åœ°åŒºè¯­è¨€çš„å£è¯­æ¯”ä¾‹ã€‚ä¾‹å¦‚ï¼Œç‘å£«çš„å››ç§æ°‘æ—è¯­è¨€åˆ†åˆ«æ˜¯å¾·è¯­ã€æ³•è¯­ã€æ„å¤§åˆ©è¯­å’Œç½—æ›¼ä»€è¯­ï¼Œå› æ­¤ä½ å¯ä»¥å°è¯•æ ¹æ®æ ¹æ®å£è¯­æ¯”ä¾‹å¯¹ Oscar å­é›†è¿›è¡ŒæŠ½æ ·æ¥åˆ›å»ºä¸€ä¸ªç‘å£«è¯­æ–™åº“ã€‚

</Tip>

ä½ ç°åœ¨æ‹¥æœ‰åŠ è½½å’Œå¤„ç†å„ç§ç±»å‹å’Œå¤§å°çš„æ•°æ®é›†çš„æ‰€éœ€çš„æ‰€æœ‰å·¥å…· â€”â€” ä½†æ˜¯é™¤éä½ éå¸¸å¹¸è¿ï¼Œå¦åˆ™åœ¨ä½ çš„ NLP ä¹‹æ—…ä¸­ä¼šæœ‰ä¸€ä¸ªéš¾é¢˜ï¼Œä½ å°†ä¸å¾—ä¸äº²è‡ªåˆ›å»ºä¸€ä¸ªæ•°æ®é›†æ¥è§£å†³æ‰‹å¤´çš„é—®é¢˜ã€‚è¿™å°±æ˜¯æˆ‘ä»¬æ¥ä¸‹æ¥è¦è®¨è®ºçš„ä¸»é¢˜ï¼
