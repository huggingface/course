# å¦‚æœæˆ‘çš„æ•°æ®é›†ä¸åœ¨ Hub ä¸Šæ€ä¹ˆåŠï¼Ÿ[[å¦‚æœæˆ‘çš„æ•°æ®é›†ä¸åœ¨ Hub ä¸Šæ€ä¹ˆåŠï¼Ÿ]]

<CourseFloatingBanner chapter={5}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/zh-CN/chapter5/section2.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/zh-CN/chapter5/section2.ipynb"},
]} />

ä½ å·²ç»çŸ¥é“å¦‚ä½•ä½¿ç”¨ [Hugging Face Hub](https://huggingface.co/datasets) ä¸­çš„æ•°æ®é›†ï¼Œä½†ä½ å¾€å¾€ä¼šå‘ç°è‡ªå·±éœ€è¦å¤„ç†åœ¨è‡ªå·±çš„ç¬”è®°æœ¬ç”µè„‘æˆ–è€…ç½‘ç»œä¸Šçš„æ•°æ®é›†ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•ä½¿ç”¨ğŸ¤— Datasets åŠ è½½ä¸åœ¨ Hugging Face Hub ä¸­çš„æ•°æ®é›†ã€‚

<Youtube id="HyQgpJTkRdE"/>

## ä½¿ç”¨æœ¬åœ°å’Œè¿œç¨‹æ•°æ®é›† [[ä½¿ç”¨æœ¬åœ°å’Œè¿œç¨‹æ•°æ®é›†]]

ğŸ¤— Datasets æä¾›äº†åŠ è½½æœ¬åœ°å’Œè¿œç¨‹æ•°æ®é›†çš„æ–¹æ³•ã€‚å®ƒæ”¯æŒå‡ ç§å¸¸è§çš„æ•°æ®æ ¼å¼ï¼Œä¾‹å¦‚ï¼š

|       æ•°æ®æ ¼å¼      |    ç±»å‹å‚æ•°    |                         åŠ è½½çš„æŒ‡ä»¤                            |
| :----------------: | :------------: | :-----------------------------------------------------: |
|     CSV & TSV      | `csv` | `load_dataset("csv", data_files="my_file.csv")` |
|     Text files     | `text` | `load_dataset("text", data_files="my_file.txt")` |
| JSON & JSON Lines  | `json` | `load_dataset("json", data_files="my_file.jsonl")` |
| Pickled DataFrames | `pandas` | `load_dataset("pandas", data_files="my_dataframe.pkl")` |

å¦‚è¡¨æ‰€ç¤ºï¼Œå¯¹äºæ¯ç§æ•°æ®æ ¼å¼ï¼Œæˆ‘ä»¬åªéœ€è¦åœ¨ `load_dataset()` å‡½æ•°ä¸­æŒ‡å®šæ•°æ®çš„ç±»å‹ï¼Œå¹¶ä½¿ç”¨ `data_files` æŒ‡å®šä¸€ä¸ªæˆ–å¤šä¸ªæ–‡ä»¶çš„è·¯å¾„çš„å‚æ•°ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬ä»åŠ è½½æœ¬åœ°æ–‡ä»¶çš„æ•°æ®é›†å¼€å§‹ï¼›ç¨åï¼Œæˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•ä½¿ç”¨è¿œç¨‹æ–‡ä»¶åšåŒæ ·çš„äº‹æƒ…ã€‚

## åŠ è½½æœ¬åœ°æ•°æ®é›† [[åŠ è½½æœ¬åœ°æ•°æ®é›†]]

åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ [SQuAD-it æ•°æ®é›†](https://github.com/crux82/squad-it/) ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºæ„å¤§åˆ©è¯­é—®ç­”çš„å¤§è§„æ¨¡æ•°æ®é›†ã€‚

è®­ç»ƒé›†å’Œæµ‹è¯•é›†éƒ½æ‰˜ç®¡åœ¨ GitHub ä¸Šï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥é€šè¿‡ `wget` å‘½ä»¤éå¸¸è½»æ˜“åœ°ä¸‹è½½å®ƒä»¬ï¼š

```python
!wget https://github.com/crux82/squad-it/raw/master/SQuAD_it-train.json.gz
!wget https://github.com/crux82/squad-it/raw/master/SQuAD_it-test.json.gz
```

è¿™å°†ä¸‹è½½ä¸¤ä¸ªåä¸º `SQuAD_it-train.json.gz` å’Œ `SQuAD_it-test.json.gz` çš„å‹ç¼©æ–‡ä»¶ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ Linux çš„ `gzip` å‘½ä»¤è§£å‹ä»–ä»¬ï¼š

```python
!gzip -dkv SQuAD_it-*.json.gz
```

```bash
SQuAD_it-test.json.gz:	   87.4% -- replaced with SQuAD_it-test.json
SQuAD_it-train.json.gz:	   82.2% -- replaced with SQuAD_it-train.json
```

æˆ‘ä»¬å¯ä»¥çœ‹åˆ°å‹ç¼©æ–‡ä»¶å·²ç»è¢«æ›¿æ¢ä¸º `SQuAD_it-train.json` å’Œ `SQuAD_it-test.json` ï¼Œå¹¶ä¸”æ•°æ®ä»¥ JSON æ ¼å¼å­˜å‚¨ã€‚

<Tip>

âœï¸ å¦‚æœä½ æƒ³çŸ¥é“ä¸ºä»€ä¹ˆä¸Šé¢çš„ shell å‘½ä»¤ä¸­æœ‰ä¸€ä¸ª `!` ï¼Œé‚£æ˜¯å› ä¸ºæˆ‘ä»¬ç°åœ¨æ˜¯åœ¨ Jupyter notebook ä¸­è¿è¡Œå®ƒä»¬ã€‚å¦‚æœä½ æƒ³åœ¨å‘½ä»¤è¡Œä¸­ä¸‹è½½å’Œè§£å‹ç¼©æ•°æ®é›†ï¼Œåªéœ€åˆ é™¤å‰ç¼€ `!` å³å¯ã€‚

</Tip>

å½“æˆ‘ä»¬ä½¿ç”¨ `load_dataset()` å‡½æ•°æ¥åŠ è½½ JSON æ–‡ä»¶æ—¶ï¼Œæˆ‘ä»¬éœ€è¦çŸ¥é“æˆ‘ä»¬æ˜¯åœ¨å¤„ç†æ™®é€šçš„ JSONï¼ˆç±»ä¼¼äºåµŒå¥—å­—å…¸ï¼‰è¿˜æ˜¯ JSON Linesï¼ˆæ¯ä¸€è¡Œéƒ½æ˜¯ä¸€ä¸ª JSONï¼‰ã€‚åƒè®¸å¤šé—®ç­”æ•°æ®é›†ä¸€æ ·ï¼ŒSQuAD-it ä½¿ç”¨çš„æ˜¯åµŒå¥—å­—å…¸ï¼Œæ‰€æœ‰æ–‡æœ¬éƒ½å­˜å‚¨åœ¨ `data` å­—æ®µä¸­ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥é€šè¿‡ä½¿ç”¨å‚æ•° `field` æ¥åŠ è½½æ•°æ®é›†ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```py
from datasets import load_dataset

squad_it_dataset = load_dataset("json", data_files="SQuAD_it-train.json", field="data")
```

é»˜è®¤æƒ…å†µä¸‹ï¼ŒåŠ è½½æœ¬åœ°æ–‡ä»¶ä¼šåˆ›å»ºä¸€ä¸ªå¸¦æœ‰ `train` æ ‡ç­¾çš„ `DatasetDict` å¯¹è±¡ã€‚æˆ‘ä»¬å¯ä»¥åœ¨è¿™é‡ŒæŸ¥çœ‹ä¸€ä¸‹ `squad_it_dataset` å¯¹è±¡ï¼š

```py
squad_it_dataset
```

```python out
DatasetDict({
    train: Dataset({
        features: ['title', 'paragraphs'],
        num_rows: 442
    })
})
```

è¾“å‡ºäº†ä¸è®­ç»ƒé›†çš„è¡Œæ•°å’Œåˆ—åã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `train` æ ‡ç­¾æ¥æŸ¥çœ‹æ•°æ®é›†ä¸­çš„ä¸€ä¸ªç¤ºä¾‹ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```py
squad_it_dataset["train"][0]
```

```python out
{
    "title": "Terremoto del Sichuan del 2008",
    "paragraphs": [
        {
            "context": "Il terremoto del Sichuan del 2008 o il terremoto...",
            "qas": [
                {
                    "answers": [{"answer_start": 29, "text": "2008"}],
                    "id": "56cdca7862d2951400fa6826",
                    "question": "In quale anno si Ã¨ verificato il terremoto nel Sichuan?",
                },
                ...
            ],
        },
        ...
    ],
}
```

å¾ˆå¥½ï¼Œæˆ‘ä»¬å·²ç»åŠ è½½äº†æˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªæœ¬åœ°æ•°æ®é›†ï¼ä½†æ˜¯ï¼Œä¹Ÿä»…ä»…åŠ è½½äº†è®­ç»ƒé›†ï¼Œæˆ‘ä»¬çœŸæ­£æƒ³è¦çš„æ˜¯åŒ…å« `train` å’Œ `test` çš„ `DatasetDict` å¯¹è±¡ã€‚è¿™æ ·çš„è¯å°±å¯ä»¥ä½¿ç”¨ `Dataset.map()` å‡½æ•°åŒæ—¶å¤„ç†è®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å‘ `data_files` å‚æ•°è¾“å…¥ä¸€ä¸ªå­—å…¸ï¼Œå°†æ•°æ®é›†çš„æ ‡ç­¾åæ˜ å°„åˆ°ç›¸å…³è”çš„æ–‡ä»¶ï¼š

```py
data_files = {"train": "SQuAD_it-train.json", "test": "SQuAD_it-test.json"}
squad_it_dataset = load_dataset("json", data_files=data_files, field="data")
squad_it_dataset
```

```python out
DatasetDict({
    train: Dataset({
        features: ['title', 'paragraphs'],
        num_rows: 442
    })
    test: Dataset({
        features: ['title', 'paragraphs'],
        num_rows: 48
    })
})
```

è¿™æ­£æ˜¯æˆ‘ä»¬æƒ³è¦çš„ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å„ç§é¢„å¤„ç†æŠ€æœ¯æ¥æ¸…æ´—æ•°æ®ã€tokenize è¯„è®ºç­‰ç­‰ã€‚

<Tip> 

`load_dataset()` å‡½æ•°çš„ `data_files` å‚æ•°éå¸¸çµæ´»ï¼šå¯ä»¥æ˜¯å•ä¸ªæ–‡ä»¶è·¯å¾„ã€æ–‡ä»¶è·¯å¾„åˆ—è¡¨æˆ–è€…æ˜¯æ ‡ç­¾æ˜ å°„åˆ°æ–‡ä»¶è·¯å¾„çš„å­—å…¸ã€‚ä½ è¿˜å¯ä»¥æ ¹æ® Unix shell çš„è§„åˆ™ï¼Œå¯¹ç¬¦åˆæŒ‡å®šæ¨¡å¼çš„æ–‡ä»¶è¿›è¡Œæ‰¹é‡åŒ¹é…ï¼ˆä¾‹å¦‚ï¼Œä½ å¯ä»¥é€šè¿‡è®¾ç½® `data_files="*.JSON"` åŒ¹é…ç›®å½•ä¸­æ‰€æœ‰çš„ JSON æ–‡ä»¶ï¼‰ã€‚æœ‰å…³`load_dataset()`æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜… [ğŸ¤—Datasets æ–‡æ¡£](https://huggingface.co/docs/datasets/v2.12.0/en/loading#local-and-remote-files) ã€‚

</Tip>

ğŸ¤— Datasets å®é™…ä¸Šæ”¯æŒè‡ªåŠ¨è§£å‹è¾“å…¥æ–‡ä»¶ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥è·³è¿‡ä½¿ç”¨ `gzip` ï¼Œç›´æ¥å°† `data_files` å‚æ•°è®¾ç½®ä¸ºå‹ç¼©æ–‡ä»¶ï¼š

```py
data_files = {"train": "SQuAD_it-train.json.gz", "test": "SQuAD_it-test.json.gz"}
squad_it_dataset = load_dataset("json", data_files=data_files, field="data")
```

å¦‚æœä½ ä¸æƒ³æ‰‹åŠ¨è§£å‹ç¼©è®¸å¤š GZIP æ–‡ä»¶ï¼Œè¿™ä¼šå¾ˆæœ‰ç”¨ã€‚è‡ªåŠ¨è§£å‹ä¹Ÿæ”¯æŒäºå…¶ä»–å¸¸è§æ ¼å¼ï¼Œå¦‚ ZIP å’Œ TARï¼Œå› æ­¤ä½ åªéœ€å°† `data_files` è®¾ç½®ä¸ºå‹ç¼©æ–‡ä»¶æ‰€åœ¨çš„è·¯å¾„ï¼Œæ¥ä¸‹æ¥å°±äº¤ç»™ğŸ¤— Datasets å§ï¼

ç°åœ¨ä½ çŸ¥é“å¦‚ä½•åœ¨ç¬”è®°æœ¬ç”µè„‘æˆ–å°å¼æœºä¸ŠåŠ è½½æœ¬åœ°æ–‡ä»¶ï¼Œè®©æˆ‘ä»¬æ¥çœ‹çœ‹å¦‚ä½•åŠ è½½è¿œç¨‹æ–‡ä»¶ã€‚

## åŠ è½½è¿œç¨‹æ•°æ®é›† [[åŠ è½½è¿œç¨‹æ•°æ®é›†]]

å¦‚æœä½ åœ¨å…¬å¸æ‹…ä»»æ•°æ®ç ”ç©¶å‘˜æˆ–ç¼–ç¨‹å‘˜ï¼Œé‚£ä¹ˆä½ è¦åˆ†æçš„æ•°æ®é›†å¾ˆæœ‰å¯èƒ½å­˜å‚¨åœ¨æŸä¸ªè¿œç¨‹æœåŠ¡å™¨ä¸Šã€‚å¹¸è¿çš„æ˜¯ï¼ŒåŠ è½½è¿œç¨‹æ–‡ä»¶å°±åƒåŠ è½½æœ¬åœ°æ–‡ä»¶ä¸€æ ·ç®€å•ï¼æˆ‘ä»¬åªéœ€è¦å°† `load_dataset()` çš„ `data_files` å‚æ•°æŒ‡å‘å­˜å‚¨è¿œç¨‹æ–‡ä»¶çš„ä¸€ä¸ªæˆ–å¤šä¸ª URLã€‚ä¾‹å¦‚ï¼Œå¯¹äºæ‰˜ç®¡åœ¨ GitHub ä¸Šçš„ SQuAD-it æ•°æ®é›†ï¼Œæˆ‘ä»¬å¯ä»¥å°† `data_files` è®¾ç½®ä¸ºæŒ‡å‘ `SQuAD_it-*.json.gz` çš„ç½‘å€ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```py
url = "https://github.com/crux82/squad-it/raw/master/"
data_files = {
    "train": url + "SQuAD_it-train.json.gz",
    "test": url + "SQuAD_it-test.json.gz",
}
squad_it_dataset = load_dataset("json", data_files=data_files, field="data")
```

è¿™å°†è¿”å›å’Œä¸Šé¢çš„æœ¬åœ°ä¾‹å­ç›¸åŒçš„ `DatasetDict` å¯¹è±¡ï¼Œä½†çœå»äº†æˆ‘ä»¬æ‰‹åŠ¨ä¸‹è½½å’Œè§£å‹ `SQuAD_it-*.json.gz` æ–‡ä»¶çš„æ­¥éª¤ã€‚è¿™æ˜¯æˆ‘ä»¬å¯¹åŠ è½½æœªæ‰˜ç®¡åœ¨ Hugging Face Hub çš„æ•°æ®é›†çš„å„ç§æ–¹æ³•çš„æ€»ç»“ã€‚æ—¢ç„¶æˆ‘ä»¬å·²ç»æœ‰äº†ä¸€ä¸ªå¯ä»¥ä½¿ç”¨çš„æ•°æ®é›†ï¼Œè®©æˆ‘ä»¬å¼€å§‹å¤§å±•èº«æ‰‹å§ï¼

<Tip>

âœï¸ **è¯•è¯•çœ‹ï¼** é€‰æ‹©æ‰˜ç®¡åœ¨ GitHub æˆ– [UCI æœºå™¨å­¦ä¹ ä»“åº“](https://archive.ics.uci.edu/ml/index.php) ä¸Šçš„å¦ä¸€ä¸ªæ•°æ®é›†å¹¶å°è¯•ä½¿ç”¨ä¸Šè¿°æŠ€æœ¯åœ¨æœ¬åœ°å’Œè¿œç¨‹åŠ è½½å®ƒã€‚å¦å¤–ï¼Œå¯ä»¥å°è¯•åŠ è½½ CSV æˆ–è€…æ–‡æœ¬æ ¼å¼å­˜å‚¨çš„æ•°æ®é›†ï¼ˆæœ‰å…³è¿™äº›æ ¼å¼çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜… [æ–‡æ¡£](https://huggingface.co/docs/datasets/loading#local-and-remote-files) ï¼‰ã€‚

</Tip>

