# åˆ†å‰²å’Œæ•´ç†æ•°æ® [[åˆ†å‰²å’Œæ•´ç†æ•°æ®]]

<CourseFloatingBanner chapter={5}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/zh-CN/chapter5/section3.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/zh-CN/chapter5/section3.ipynb"},
]} />

å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œä½ å¤„ç†çš„æ•°æ®å¹¶ä¸èƒ½ç›´æ¥ç”¨äºè®­ç»ƒæ¨¡å‹ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æ¢ç´¢ğŸ¤— Datasets æä¾›çš„å„ç§åŠŸèƒ½ï¼Œç”¨äºæ¸…æ´—ä½ çš„æ•°æ®é›†ã€‚

<Youtube id="tqfSFcPMgOI"/>

## åˆ†å‰²å’Œæ•´ç†æˆ‘ä»¬çš„æ•°æ® [[åˆ†å‰²å’Œæ•´ç†æˆ‘ä»¬çš„æ•°æ®]]

ä¸ Pandas ç±»ä¼¼ï¼ŒğŸ¤— Datasets æä¾›äº†å¤šä¸ªå‡½æ•°æ¥æ“ä½œ `Dataset` å’Œ `DatasetDict` å¯¹è±¡ã€‚æˆ‘ä»¬åœ¨ [ç¬¬ä¸‰ç« ](/course/chapter3) å·²ç»é‡åˆ°äº† `Dataset.map()` æ–¹æ³•ï¼Œåœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æ¢ç´¢ä¸€äº›å…¶ä»–å¯ç”¨çš„å‡½æ•°ã€‚

åœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æ‰˜ç®¡åœ¨ [åŠ å·å¤§å­¦æ¬§æ–‡åˆ†æ ¡æœºå™¨å­¦ä¹ ä»“åº“](https://archive.ics.uci.edu/ml/index.php) çš„ [è¯ç‰©å®¡æŸ¥æ•°æ®é›†](https://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+%28Drugs.com%29) ï¼Œå…¶ä¸­åŒ…å«æ‚£è€…å¯¹å„ç§è¯ç‰©çš„è¯„è®ºï¼Œä»¥åŠæ­£åœ¨æ²»ç–—çš„ç—…æƒ…å’Œæ‚£è€…æ»¡æ„åº¦çš„ 10 æ˜Ÿè¯„ä»·ã€‚

é¦–å…ˆæˆ‘ä»¬éœ€è¦ä¸‹è½½å¹¶è§£å‹æ•°æ®ï¼Œå¯ä»¥é€šè¿‡ `wget` å’Œ `unzip` å‘½ä»¤ï¼š

```py
!wget "https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip"
!unzip drugsCom_raw.zip
```

ç”±äº TSV ä»…ä»…æ˜¯ CSV çš„ä¸€ä¸ªå˜ä½“ï¼Œå®ƒä½¿ç”¨åˆ¶è¡¨ç¬¦è€Œä¸æ˜¯é€—å·ä½œä¸ºåˆ†éš”ç¬¦ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨åŠ è½½ `csv` æ–‡ä»¶çš„ `load_dataset()` å‡½æ•°å¹¶æŒ‡å®šåˆ†éš”ç¬¦ï¼Œæ¥åŠ è½½è¿™äº›æ–‡ä»¶ï¼š

```py
from datasets import load_dataset

data_files = {"train": "drugsComTrain_raw.tsv", "test": "drugsComTest_raw.tsv"}
# \t åœ¨pythonä¸­æ˜¯åˆ¶è¡¨ç¬¦çš„æ„æ€
drug_dataset = load_dataset("csv", data_files=data_files, delimiter="\t")
```

åœ¨è¿›è¡Œæ•°æ®åˆ†ææ—¶ï¼Œè·å–ä¸€ä¸ªå°çš„éšæœºæ ·æœ¬ä»¥å¿«é€Ÿäº†è§£ä½ æ­£åœ¨å¤„ç†æ•°æ®çš„ç‰¹ç‚¹æ˜¯ä¸€ç§å¥½çš„å®è·µã€‚åœ¨ğŸ¤—æ•°æ®é›†ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡é“¾æ¥ `Dataset.shuffle()` å’Œ `Dataset.select()` å‡½æ•°åˆ›å»ºä¸€ä¸ªéšæœºçš„æ ·æœ¬ï¼š

```py
drug_sample = drug_dataset["train"].shuffle(seed=42).select(range(1000))
# ç»†çœ‹å‰å‡ ä¸ªä¾‹å­
drug_sample[:3]
```

```python out
{'Unnamed: 0': [87571, 178045, 80482],
 'drugName': ['Naproxen', 'Duloxetine', 'Mobic'],
 'condition': ['Gout, Acute', 'ibromyalgia', 'Inflammatory Conditions'],
 'review': ['"like the previous person mention, I&#039;m a strong believer of aleve, it works faster for my gout than the prescription meds I take. No more going to the doctor for refills.....Aleve works!"',
  '"I have taken Cymbalta for about a year and a half for fibromyalgia pain. It is great\r\nas a pain reducer and an anti-depressant, however, the side effects outweighed \r\nany benefit I got from it. I had trouble with restlessness, being tired constantly,\r\ndizziness, dry mouth, numbness and tingling in my feet, and horrible sweating. I am\r\nbeing weaned off of it now. Went from 60 mg to 30mg and now to 15 mg. I will be\r\noff completely in about a week. The fibro pain is coming back, but I would rather deal with it than the side effects."',
  '"I have been taking Mobic for over a year with no side effects other than an elevated blood pressure.  I had severe knee and ankle pain which completely went away after taking Mobic.  I attempted to stop the medication however pain returned after a few days."'],
 'rating': [9.0, 3.0, 10.0],
 'date': ['September 2, 2015', 'November 7, 2011', 'June 5, 2013'],
 'usefulCount': [36, 13, 128]}
```

è¯·æ³¨æ„ï¼Œå‡ºäºå¯ä»¥å¤ç°çš„ç›®çš„ï¼Œæˆ‘ä»¬å·²å°†åœ¨ `Dataset.shuffle()` è®¾å®šäº†å›ºå®šçš„éšæœºæ•°ç§å­ã€‚ `Dataset.select()` éœ€è¦ä¸€ä¸ªå¯è¿­ä»£çš„ç´¢å¼•ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¼ é€’äº† `range(1000)` ä»éšæœºæ‰“ä¹±çš„æ•°æ®é›†ä¸­æŠ½å–å‰ 1,000 ä¸ªç¤ºä¾‹ã€‚ä»æŠ½å–çš„æ•°æ®ä¸­ï¼Œæˆ‘ä»¬å·²ç»å¯ä»¥çœ‹åˆ°æˆ‘ä»¬æ•°æ®é›†ä¸­æœ‰ä¸€äº›ç‰¹æ®Šçš„åœ°æ–¹ï¼š

* `Unnamed: 0` è¿™åˆ—çœ‹èµ·æ¥å¾ˆåƒæ¯ä¸ªæ‚£è€…çš„åŒ¿å IDã€‚
* `condition` åˆ—åŒ…å«äº†å¤§å°å†™æ··åˆçš„æ ‡ç­¾ã€‚
* è¯„è®ºé•¿çŸ­ä¸ä¸€ï¼Œæ··åˆæœ‰ Python è¡Œåˆ†éš”ç¬¦ ï¼ˆ `\r\n` ï¼‰ ä»¥åŠ HTML å­—ç¬¦ä»£ç ï¼Œå¦‚ `&\#039;` ã€‚
  

è®©æˆ‘ä»¬çœ‹çœ‹æˆ‘ä»¬å¦‚ä½•ä½¿ç”¨ ğŸ¤— Datasets æ¥å¤„ç†è¿™äº›é—®é¢˜ã€‚ä¸ºäº†éªŒè¯ `Unnamed: 0` åˆ—å­˜å‚¨çš„æ˜¯æ‚£è€… ID çš„çŒœæƒ³ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `Dataset.unique()` å‡½æ•°æ¥éªŒè¯åŒ¿å ID çš„æ•°é‡æ˜¯å¦ä¸åˆ†å‰²åæ¯ä¸ªåˆ†ç»„ä¸­çš„è¡Œæ•°åŒ¹é…ï¼š

```py
for split in drug_dataset.keys():
    assert len(drug_dataset[split]) == len(drug_dataset[split].unique("Unnamed: 0"))
```

è¿™ä¼¼ä¹è¯å®äº†æˆ‘ä»¬çš„å‡è®¾ï¼Œæ‰€ä»¥è®©æˆ‘ä»¬æŠŠ `Unnamed: 0` åˆ—é‡å‘½åä¸ºæ‚£è€…çš„ idã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `DatasetDict.rename_column()` å‡½æ•°æ¥ä¸€æ¬¡æ€§é‡å‘½åä¸¤ä¸ªåˆ†ç»„ï¼š

```py
drug_dataset = drug_dataset.rename_column(
    original_column_name="Unnamed: 0", new_column_name="patient_id"
)
drug_dataset
```

```python out
DatasetDict({
    train: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],
        num_rows: 161297
    })
    test: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],
        num_rows: 53766
    })
})
```

<Tip>

âœï¸  **è¯•è¯•çœ‹ï¼** ä½¿ç”¨ `Dataset.unique()` å‡½æ•°æŸ¥æ‰¾è®­ç»ƒå’Œæµ‹è¯•é›†ä¸­çš„ç‰¹å®šè¯ç‰©å’Œç—…ç—‡çš„æ•°é‡ã€‚

</Tip>

æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬ä½¿ç”¨ `Dataset.map()` æ¥è§„èŒƒæ‰€æœ‰çš„ `condition` æ ‡ç­¾ã€‚æ­£å¦‚æˆ‘ä»¬åœ¨ [ç¬¬ä¸‰ç« ](/course/chapter3) ä¸­å¤„ç† tokenizer ä¸€æ ·ï¼Œæˆ‘ä»¬å¯ä»¥å®šä¹‰ä¸€ä¸ªç®€å•çš„å‡½æ•°ï¼Œå¯ä»¥ä½¿ç”¨è¯¥å‡½æ•° `drug_dataset` å¤„ç†æ¯ä¸ªåˆ†ç»„çš„æ‰€æœ‰è¡Œï¼š

```py
def lowercase_condition(example):
    return {"condition": example["condition"].lower()}


drug_dataset.map(lowercase_condition)
```

```python out
AttributeError: 'NoneType' object has no attribute 'lower'
```

å“¦ä¸ï¼Œæˆ‘ä»¬çš„ map å‡½æ•°é‡åˆ°äº†é—®é¢˜ï¼ä»é”™è¯¯ä¸­æˆ‘ä»¬å¯ä»¥æ¨æ–­å‡º `condition` åˆ—å­˜åœ¨ `None` ï¼Œä¸èƒ½è½¬æ¢ä¸ºå°å†™ï¼Œå› ä¸ºå®ƒä»¬ä¸æ˜¯å­—ç¬¦ä¸²ã€‚è®©æˆ‘ä»¬ä½¿ç”¨ `Dataset.filter()` åˆ é™¤è¿™äº›è¡Œ å…¶å·¥ä½œæ–¹å¼ç±»ä¼¼äº `Dataset.map()` ã€‚ä¾‹å¦‚ï¼š

```py
def filter_nones(x):
    return x["condition"] is not None
```

ç„¶åè¿è¡Œ `drug_dataset.filter(filter_nones)` ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ lambda å‡½æ•°åœ¨ä¸€è¡Œä»£ç å®Œæˆè¿™ä¸ªä»»åŠ¡ã€‚åœ¨ Pyhton ä¸­ï¼Œlambda å‡½æ•°æ˜¯ä½ æ— éœ€æ˜ç¡®å‘½åå³å¯ä½¿ç”¨çš„å¾®å‡½æ•°ï¼ˆåŒ¿åå‡½æ•°ï¼‰ã€‚å®ƒä»¬ä¸€èˆ¬é‡‡ç”¨å¦‚ä¸‹å½¢å¼ï¼š

```
lambda <arguments> : <expression>
```

å…¶ä¸­ `lambda` æ˜¯ Python çš„ç‰¹æ®Š [å…³é”®å­—](https://docs.python.org/3/reference/lexical_analysis.html#keywords) ä¹‹ä¸€ï¼Œ `arguments` æ˜¯ä»¥é€—å·è¿›è¡Œåˆ†éš”çš„å‡½æ•°å‚æ•°çš„åˆ—è¡¨/é›†åˆï¼Œ `expression` ä»£è¡¨ä½ å¸Œæœ›æ‰§è¡Œçš„æ“ä½œã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥å®šä¹‰ä¸€ä¸ªç®€å•çš„ lambda å‡½æ•°æ¥å¯¹ä¸€ä¸ªæ•°å­—è¿›è¡Œå¹³æ–¹ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```
lambda x : x * x
```

æˆ‘ä»¬éœ€è¦å°†è¦è¾“å…¥æ”¾åœ¨æ‹¬å·ä¸­ï¼š

```py
(lambda x: x * x)(3)
```

```python out
9
```

åŒæ ·ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä½¿ç”¨é€—å·åˆ†éš”æ¥å®šä¹‰å¸¦æœ‰å¤šä¸ªå‚æ•°çš„ lambda å‡½æ•°ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥æŒ‰å¦‚ä¸‹æ–¹å¼è®¡ç®—ä¸‰è§’å½¢çš„é¢ç§¯ï¼š

```py
(lambda base, height: 0.5 * base * height)(4, 8)
```

```python out
16.0
```

å½“ä½ æƒ³å®šä¹‰å°å‹ã€ä¸€æ¬¡æ€§ä½¿ç”¨çš„å‡½æ•°æ—¶ï¼Œlambda å‡½æ•°éå¸¸æ–¹ä¾¿ï¼ˆæœ‰å…³å®ƒä»¬çš„æ›´å¤šä¿¡æ¯ï¼Œæˆ‘ä»¬å»ºè®®é˜…è¯» Andre Burgaud å†™çš„ [çœŸæ­£çš„Pythonæ•™ç¨‹](https://realpython.com/python-lambda/) ï¼‰ã€‚åœ¨ğŸ¤— Datasets ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ lambda å‡½æ•°æ¥å®šä¹‰ç®€å•çš„æ˜ å°„å’Œè¿‡æ»¤æ“ä½œï¼Œæ‰€ä»¥è®©æˆ‘ä»¬ä½¿ç”¨è¿™ä¸ªæŠ€å·§æ¥åˆ é™¤æˆ‘ä»¬æ•°æ®é›†ä¸­çš„æ‰€æœ‰`condition` ä¸º `None`çš„è®°å½•ï¼š

```py
drug_dataset = drug_dataset.filter(lambda x: x["condition"] is not None)
``` 

å«æœ‰`None`çš„ç§¯ç´¯åˆ é™¤ä¹‹å,æˆ‘ä»¬å¯ä»¥è§„èŒƒæˆ‘ä»¬çš„ `condition` åˆ—:

```py
drug_dataset = drug_dataset.map(lowercase_condition)
# æ£€æŸ¥ä¸€ä¸‹è½¬æ¢åçš„ç»“æœ
drug_dataset["train"]["condition"][:3]
```

```python out
['left ventricular dysfunction', 'adhd', 'birth control']
```

æœ‰ç”¨ï¼ç°åœ¨æˆ‘ä»¬å·²ç»æ¸…ç†äº†æ ‡ç­¾ï¼Œè®©æˆ‘ä»¬æ¥çœ‹çœ‹æ¸…æ´—åçš„è¯„è®ºæ–‡æœ¬ã€‚

## åˆ›å»ºæ–°çš„åˆ— [[åˆ›å»ºæ–°çš„åˆ—]]

æ¯å½“æˆ‘ä»¬å¤„ç†å®¢æˆ·è¯„è®ºæ—¶ï¼Œä¸€ä¸ªå¥½çš„ä¹ æƒ¯æ˜¯æ£€æŸ¥è¯„è®ºçš„å­—æ•°çš„åˆ†å¸ƒã€‚è¯„è®ºå¯èƒ½åªæ˜¯ä¸€ä¸ªè¯ï¼Œæ¯”å¦‚â€œå¤ªæ£’äº†ï¼â€æˆ–åŒ…å«æ•°åƒå­—çš„å®Œæ•´æ–‡ç« ã€‚åœ¨ä¸åŒçš„ä½¿ç”¨åœºæ™¯ï¼Œä½ éœ€è¦ä»¥ä¸åŒçš„æ–¹å¼å¤„ç†è¿™äº›æç«¯æƒ…å†µã€‚ä¸ºäº†è®¡ç®—æ¯æ¡è¯„è®ºä¸­çš„å•è¯æ•°ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ç©ºæ ¼åˆ†å‰²æ¯ä¸ªæ–‡æœ¬è¿›è¡Œç²—ç•¥ç»Ÿè®¡ã€‚

è®©æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªç®€å•çš„å‡½æ•°ï¼Œè®¡ç®—æ¯æ¡è¯„è®ºçš„å­—æ•°ï¼š

```py
def compute_review_length(example):
    return {"review_length": len(example["review"].split())}
```

ä¸åŒäºæˆ‘ä»¬çš„ `lowercase_condition()` å‡½æ•°ï¼Œ `compute_review_length()` è¿”å›ä¸€ä¸ªå­—å…¸ï¼Œå…¶é”®å¹¶ä¸å¯¹åº”æ•°æ®é›†ä¸­çš„æŸä¸€åˆ—åç§°ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå½“ `compute_review_length()` ä¼ é€’ç»™ `Dataset.map()` æ—¶ï¼Œå®ƒå°†å¤„ç†æ•°æ®é›†ä¸­çš„æ‰€æœ‰è¡Œï¼Œæœ€åè¿”å›å€¼ä¼šåˆ›å»ºä¸€ä¸ªæ–°çš„ `review_length` åˆ—ï¼š

```py
drug_dataset = drug_dataset.map(compute_review_length)
# æ£€æŸ¥ç¬¬ä¸€ä¸ªè®­ç»ƒæ ·ä¾‹
drug_dataset["train"][0]
```

```python out
{'patient_id': 206461,
 'drugName': 'Valsartan',
 'condition': 'left ventricular dysfunction',
 'review': '"It has no side effect, I take it in combination of Bystolic 5 Mg and Fish Oil"',
 'rating': 9.0,
 'date': 'May 20, 2012',
 'usefulCount': 27,
 'review_length': 17}
```

æ­£å¦‚é¢„æœŸçš„é‚£æ ·ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä¸€ä¸ª `review_length` åˆ—å·²æ·»åŠ åˆ°æˆ‘ä»¬çš„è®­ç»ƒé›†ä¸­ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `Dataset.sort()` å¯¹è¿™ä¸ªæ–°åˆ—è¿›è¡Œæ’åºï¼Œç„¶åæŸ¥çœ‹ä¸€ä¸‹æç«¯é•¿åº¦çš„è¯„è®ºæ˜¯ä»€ä¹ˆæ ·çš„ï¼š

```py
drug_dataset["train"].sort("review_length")[:3]
```

```python out
{'patient_id': [103488, 23627, 20558],
 'drugName': ['Loestrin 21 1 / 20', 'Chlorzoxazone', 'Nucynta'],
 'condition': ['birth control', 'muscle spasm', 'pain'],
 'review': ['"Excellent."', '"useless"', '"ok"'],
 'rating': [10.0, 1.0, 6.0],
 'date': ['November 4, 2008', 'March 24, 2017', 'August 20, 2016'],
 'usefulCount': [5, 2, 10],
 'review_length': [1, 1, 1]}
```

æ­£å¦‚æˆ‘ä»¬æ‰€çŒœæƒ³çš„é‚£æ ·ï¼Œæœ‰äº›è¯„è®ºåªåŒ…å«ä¸€ä¸ªè¯ï¼Œè™½ç„¶è¿™å¯¹äºæƒ…æ„Ÿåˆ†æä»»åŠ¡æ¥è¯´è¿˜å¯ä»¥æ¥å—ï¼Œä½†å¦‚æœæˆ‘ä»¬æƒ³è¦é¢„æµ‹ç—…æƒ…ï¼Œé‚£ä¹ˆå®ƒæ‰€æä¾›çš„ä¿¡æ¯å°±ä¸å¤Ÿä¸°å¯Œäº†ã€‚

<Tip>

ğŸ™‹å‘æ•°æ®é›†æ·»åŠ æ–°åˆ—çš„å¦ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨å‡½æ•° `Dataset.add_column()` ï¼Œåœ¨ä½¿ç”¨å®ƒæ—¶ä½ å¯ä»¥é€šè¿‡ Python åˆ—è¡¨æˆ– NumPy æ•°ç»„çš„æ–¹å¼æä¾›æ•°æ®ï¼Œåœ¨ä¸é€‚åˆä½¿ç”¨ `Dataset.map()` æƒ…å†µä¸‹å¯ä»¥å¾ˆæ–¹ä¾¿ã€‚

</Tip>

è®©æˆ‘ä»¬ä½¿ç”¨ `Dataset.filter()` åŠŸèƒ½æ¥åˆ é™¤åŒ…å«å°‘äº 30 ä¸ªå•è¯çš„è¯„è®ºã€‚è¿™ä¸æˆ‘ä»¬è¿‡æ»¤ `condition` åˆ—çš„å¤„ç†æ–¹å¼ç›¸ä¼¼ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡è®¾å®šè¯„è®ºé•¿åº¦çš„æœ€å°é˜ˆå€¼ï¼Œç­›é€‰å‡ºè¿‡çŸ­çš„è¯„è®ºï¼š

```py
drug_dataset = drug_dataset.filter(lambda x: x["review_length"] > 30)
print(drug_dataset.num_rows)
```

```python out
{'train': 138514, 'test': 46108}
```

å¦‚ä½ æ‰€è§ï¼Œè¿™ä¸ªæ“ä½œä»æˆ‘ä»¬çš„åŸå§‹è®­ç»ƒå’Œæµ‹è¯•é›†ä¸­åˆ é™¤äº†å¤§çº¦ 15ï¼… çš„è¯„è®ºã€‚

<Tip>

âœï¸ **è¯•è¯•çœ‹ï¼**ä½¿ç”¨ `Dataset.sort()` å‡½æ•°æŸ¥çœ‹å•è¯æ•°æœ€å¤šçš„è¯„è®ºã€‚ä½ å¯ä»¥å‚é˜… [æ–‡æ¡£](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.sort) äº†è§£å¦‚ä½•æŒ‰ç…§è¯„è®ºçš„é•¿åº¦é™åºæ’åºã€‚

</Tip>

æˆ‘ä»¬éœ€è¦å¤„ç†çš„æœ€åä¸€ä»¶äº‹æ˜¯å¤„ç†è¯„è®ºä¸­çš„ HTML å­—ç¬¦ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ Python çš„ `html` æ¨¡å—æ¥è§£ç è¿™äº›å­—ç¬¦ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```py
import html

text = "I&#039;m a transformer called BERT"
html.unescape(text)
```

```python out
"I'm a transformer called BERT"
```

æˆ‘ä»¬å°†ä½¿ç”¨ `Dataset.map()` å¯¹æˆ‘ä»¬è¯­æ–™åº“ä¸­çš„æ‰€æœ‰ HTML å­—ç¬¦è¿›è¡Œè§£ç ï¼š

```python
drug_dataset = drug_dataset.map(lambda x: {"review": html.unescape(x["review"])})
```

å¦‚ä½ æ‰€è§ï¼Œ `Dataset.map()` æ–¹æ³•å¯¹äºå¤„ç†æ•°æ®éå¸¸æœ‰ç”¨ï¼Œå³ä½¿æˆ‘ä»¬è¿˜æ²¡æœ‰å®Œå…¨äº†è§£å®ƒçš„æ‰€æœ‰åŠŸèƒ½ï¼

## `map()` æ–¹æ³•çš„è¶…çº§åŠ é€Ÿ [[`map()` æ–¹æ³•çš„è¶…çº§åŠ é€Ÿ]]

`Dataset.map()` æ–¹æ³•æœ‰ä¸€ä¸ª `batched` å‚æ•°ï¼Œå¦‚æœè®¾ç½®ä¸º `True` ï¼Œmap å‡½æ•°å°†ä¼šåˆ†æ‰¹æ‰§è¡Œæ‰€éœ€è¦è¿›è¡Œçš„æ“ä½œï¼ˆæ‰¹é‡å¤§å°æ˜¯å¯é…ç½®çš„ï¼Œä½†é»˜è®¤ä¸º 1,000ï¼‰ã€‚ä¾‹å¦‚ï¼Œä¹‹å‰å¯¹æ‰€æœ‰ HTML è¿›è¡Œè§£ç çš„ map å‡½æ•°è¿è¡Œéœ€è¦ä¸€äº›æ—¶é—´ï¼ˆä½ å¯ä»¥ä»è¿›åº¦æ¡ä¸­çœ‹åˆ°æ‰€éœ€çš„æ—¶é—´ï¼‰ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ä½¿ç”¨åˆ—è¡¨æ¨å¯¼åŒæ—¶å¤„ç†å¤šä¸ªå…ƒç´ æ¥åŠ é€Ÿã€‚

å½“ä½ åœ¨ä½¿ç”¨ `Dataset.map()` å‡½æ•°æ—¶è®¾å®š `batched=True` ã€‚è¯¥å‡½æ•°éœ€è¦æ¥æ”¶ä¸€ä¸ªåŒ…å«æ•°æ®é›†å­—æ®µçš„å­—å…¸ï¼Œå­—å…¸çš„å€¼æ˜¯ä¸€ä¸ªåˆ—è¡¨ã€‚ä¾‹å¦‚ï¼Œè¿™æ˜¯ä½¿ç”¨ `batched=True` å¯¹æ‰€æœ‰ HTML å­—ç¬¦è¿›è¡Œè§£ç çš„æ–¹æ³• 

```python
new_drug_dataset = drug_dataset.map(
    lambda x: {"review": [html.unescape(o) for o in x["review"]]}, batched=True
)
```

å¦‚æœä½ åœ¨ç¬”è®°æœ¬ä¸­è¿è¡Œæ­¤ä»£ç ï¼Œä½ ä¼šçœ‹åˆ°æ­¤å‘½ä»¤çš„æ‰§è¡Œé€Ÿåº¦æ¯”å‰ä¸€ä¸ªå‘½ä»¤å¿«å¾—å¤šã€‚è¿™ä¸æ˜¯å› ä¸ºæˆ‘ä»¬çš„è¯„è®ºå·²ç»æ˜¯å¤„ç†è¿‡çš„â€”â€”å¦‚æœä½ é‡æ–°æ‰§è¡Œä¸Šä¸€èŠ‚çš„æŒ‡ä»¤ï¼ˆæ²¡æœ‰ `batched=True` ï¼‰ï¼Œå®ƒå°†èŠ±è´¹ä¸ä¹‹å‰ç›¸åŒçš„æ—¶é—´ã€‚è¿™æ˜¯å› ä¸ºåˆ—è¡¨æ¨å¯¼å¼é€šå¸¸æ¯”åœ¨åŒä¸€ä»£ç ä¸­ç”¨ `for` å¾ªç¯æ‰§è¡Œç›¸åŒçš„ä»£ç æ›´å¿«ï¼Œå¹¶ä¸”æˆ‘ä»¬è¿˜é€šè¿‡åŒæ—¶è®¿é—®å¤šä¸ªå…ƒç´ è€Œä¸æ˜¯ä¸€ä¸ªä¸€ä¸ªæ¥å¤„ç†æ¥æé«˜å¤„ç†çš„é€Ÿåº¦ã€‚

åœ¨ [ç¬¬å…­ç« ](/course/chapter6) æˆ‘ä»¬å°†é‡åˆ°çš„â€œå¿«é€Ÿâ€ tokenizer å®ƒå¯ä»¥å¿«é€Ÿå¯¹é•¿æ–‡æœ¬åˆ—è¡¨è¿›è¡Œ tokenizeã€‚ä½¿ç”¨ `Dataset.map()` æ­é… `batched=True` å‚æ•°æ˜¯åŠ é€Ÿçš„å…³é”®ã€‚ä¾‹å¦‚ï¼Œè¦ä½¿ç”¨å¿«é€Ÿ tokenizer å¯¹æ‰€æœ‰è¯ç‰©è¯„è®º tokenizeï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å¦‚ä¸‹çš„å‡½æ•°ï¼š

```python
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")


def tokenize_function(examples):
    return tokenizer(examples["review"], truncation=True)
```

æ­£å¦‚æˆ‘ä»¬åœ¨ [ç¬¬ä¸‰ç« ](/course/chapter3) æ‰€çœ‹åˆ°çš„ï¼Œæˆ‘ä»¬åŸæœ¬å°±å¯ä»¥å°†ä¸€ä¸ªæˆ–å¤šä¸ªç¤ºä¾‹ä¼ é€’ç»™ tokenizerï¼Œå› æ­¤åœ¨ `batched=True` æ˜¯ä¸€ä¸ªéå¿…é¡»çš„é€‰é¡¹ã€‚è®©æˆ‘ä»¬å€Ÿæ­¤æœºä¼šæ¯”è¾ƒä¸åŒé€‰é¡¹çš„æ€§èƒ½ã€‚åœ¨ notebook ä¸­ï¼Œä½ å¯ä»¥åœ¨ä½ è¦æµ‹é‡çš„ä»£ç è¡Œä¹‹å‰æ·»åŠ  `%time` æ¥è®°å½•è¯¥è¡Œè¿è¡Œæ‰€æ¶ˆè€—çš„æ—¶é—´ï¼š

```python no-format
%time tokenized_dataset = drug_dataset.map(tokenize_function, batched=True)
```

ä½ ä¹Ÿå¯ä»¥å°† `%%time` æ”¾ç½®åœ¨å•å…ƒæ ¼å¼€å¤´æ¥ç»Ÿè®¡æ•´ä¸ªå•å…ƒæ ¼çš„æ‰§è¡Œæ—¶é—´ã€‚åœ¨æˆ‘ä»¬çš„ç¡¬ä»¶ä¸Šï¼Œè¯¥æŒ‡ä»¤æ˜¾ç¤º 10.8 ç§’ï¼ˆè¿™å°±æ˜¯çœŸæ­£ï¼ˆWall timeï¼‰çš„æ‰§è¡Œæ—¶é—´ï¼‰ã€‚

<Tip>

âœï¸ **è¯•è¯•çœ‹ï¼** åœ¨æœ‰å’Œæ—  `batched=True` çš„æƒ…å†µä¸‹æ‰§è¡Œç›¸åŒçš„æŒ‡ä»¤ï¼Œç„¶åè¯•è¯•æ…¢é€Ÿ tokenizer ï¼ˆåœ¨ `AutoTokenizer.from_pretrained()` æ–¹æ³•ä¸­æ·»åŠ  `use_fast=False` ï¼‰ï¼Œè¿™æ ·ä½ å°±å¯ä»¥æµ‹è¯•ä¸€ä¸‹åœ¨ä½ çš„ç”µè„‘ä¸Šå®ƒéœ€è¦å¤šé•¿çš„æ—¶é—´ã€‚

</Tip>

ä»¥ä¸‹æ˜¯æˆ‘ä»¬åœ¨ä½¿ç”¨å’Œä¸ä½¿ç”¨æ‰¹å¤„ç†æ—¶ä½¿ç”¨å¿«é€Ÿå’Œæ…¢é€Ÿ tokenizer è·å¾—çš„ç»“æœï¼š

é€‰é¡¹         | å¿«é€Ÿ tokenizer | æ…¢é€Ÿ tokenizer
:--------------:|:--------------:|:-------------:
`batched=True` | 10.8s          | 4min41s 
`batched=False` | 59.2s          | 5min3s

è¿™æ„å‘³ç€ä½¿ç”¨å¿«é€Ÿ tokenizer é…åˆ `batched=True` é€‰é¡¹æ¯”æ²¡æœ‰æ‰¹å¤„ç†çš„æ…¢é€Ÿç‰ˆæœ¬å¿« 30 å€â€”â€”è¿™çœŸçš„å¤ª Amazing äº†ï¼è¿™å°±æ˜¯ä¸ºä»€ä¹ˆåœ¨ä½¿ç”¨ `AutoTokenizer` æ—¶ï¼Œå°†ä¼šé»˜è®¤ä½¿ç”¨ `use_fast=True` çš„ä¸»è¦åŸå›  ï¼ˆä»¥åŠä¸ºä»€ä¹ˆå®ƒä»¬è¢«ç§°ä¸ºâ€œå¿«é€Ÿâ€çš„åŸå› ï¼‰ã€‚ä»–ä»¬èƒ½å¤Ÿå®ç°è¿™æ ·çš„åŠ é€Ÿï¼Œå› ä¸ºåœ¨åº•å±‚çš„ tokenize ä»£ç æ˜¯åœ¨ Rust ä¸­æ‰§è¡Œçš„ï¼ŒRust æ˜¯ä¸€ç§å¯ä»¥æ˜“äºå¹¶è¡ŒåŒ–æ‰§è¡Œçš„è¯­è¨€ã€‚

å¹¶è¡ŒåŒ–ä¹Ÿæ˜¯å¿«é€Ÿ tokenizer é€šè¿‡æ‰¹å¤„ç†å®ç°è¿‘ 6 å€åŠ é€Ÿçš„åŸå› ï¼šå•ä¸ª tokenize æ“ä½œæ˜¯ä¸èƒ½å¹¶è¡Œçš„ï¼Œä½†æ˜¯å½“ä½ æƒ³åŒæ—¶å¯¹å¤§é‡æ–‡æœ¬è¿›è¡Œ tokenize æ—¶ï¼Œä½ å¯ä»¥å°†æ‰§è¡Œè¿‡ç¨‹æ‹†åˆ†ä¸ºå¤šä¸ªè¿›ç¨‹ï¼Œæ¯ä¸ªè¿›ç¨‹è´Ÿè´£å¤„ç†è‡ªå·±çš„æ–‡æœ¬ã€‚ `Dataset.map()` ä¹Ÿæœ‰ä¸€äº›è‡ªå·±çš„å¹¶è¡ŒåŒ–èƒ½åŠ›ã€‚å°½ç®¡å®ƒä»¬æ²¡æœ‰ Rust æä¾›æ”¯æŒï¼Œä½†å®ƒä»¬ä»ç„¶å¯ä»¥å¸®åŠ©æ…¢é€Ÿ tokenizer åŠ é€Ÿï¼ˆå°¤å…¶æ˜¯å½“ä½ ä½¿ç”¨çš„ tokenizer æ²¡æœ‰å¿«é€Ÿç‰ˆæœ¬æ—¶ï¼‰ã€‚è¦å¯ç”¨å¤šè¿›ç¨‹å¤„ç†ï¼Œè¯·åœ¨è°ƒç”¨ `Dataset.map()` æ—¶ä½¿ç”¨ `num_proc` å‚æ•°å¹¶æŒ‡å®šè¦åœ¨è°ƒç”¨ä¸­ä½¿ç”¨çš„è¿›ç¨‹æ•° 

```py
slow_tokenizer = AutoTokenizer.from_pretrained("bert-base-cased", use_fast=False)


def slow_tokenize_function(examples):
    return slow_tokenizer(examples["review"], truncation=True)


tokenized_dataset = drug_dataset.map(slow_tokenize_function, batched=True, num_proc=8)
```

ä½ å¯ä»¥å¯¹å¤„ç†è¿›è¡Œä¸€äº›è®¡æ—¶çš„è¯•éªŒï¼Œä»¥ç¡®å®šæœ€ä½³è¿›ç¨‹æ•°ï¼›åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œ8 ä¼¼ä¹äº§ç”Ÿäº†æœ€å¥½çš„é€Ÿåº¦å¢ç›Šã€‚ä»¥ä¸‹æ˜¯æˆ‘ä»¬åœ¨æœ‰æ— å¤šè¿›ç¨‹å¤„ç†çš„æƒ…å†µä¸‹ï¼Œå¾—åˆ°çš„ç»“æœï¼š

é€‰é¡¹         | å¿«é€Ÿ tokenizer  | æ…¢é€Ÿ tokenizer 
:--------------:|:--------------:|:-------------: 
`batched=True` | 10.8s          | 4min41s
`batched=False` | 59.2s          | 5min3s 
`batched=True` , `num_proc=8` | 6.52s          | 41.3s
`batched=False` , `num_proc=8` | 9.49s          | 45.2s

è¿™ä¸ªç»“æœå¯¹äºæ…¢é€Ÿåˆ†è¯å™¨æ¥è¯´æ˜¯æ›´åŠ å‹å¥½äº†ï¼Œä½†å¿«é€Ÿåˆ†è¯å™¨çš„æ€§èƒ½ä¹Ÿå¾—åˆ°äº†æ˜¾è‘—æå‡ã€‚ä½†æ˜¯è¯·æ³¨æ„ï¼Œæƒ…å†µå¹¶éæ€»æ˜¯å¦‚æ­¤â€”å¯¹äº `num_proc` çš„å…¶ä»–å€¼ï¼Œåœ¨æˆ‘ä»¬çš„æµ‹è¯•ä¸­ï¼Œä½¿ç”¨ `batched=True` è€Œä¸å¸¦æœ‰ `num_proc` å‚æ•°çš„é€‰é¡¹å¤„ç†èµ·æ¥æ›´å¿«ã€‚æ€»çš„æ¥è¯´ï¼Œæˆ‘ä»¬å¹¶ä¸æ¨èåœ¨å¿«é€Ÿ tokenizer å’Œ `batched=True` çš„æƒ…å†µä¸‹ä½¿ç”¨ Python çš„å¤šè¿›ç¨‹å¤„ç†ã€‚

<Tip>

é€šå¸¸æ¥è¯´ï¼Œä½¿ç”¨ `num_proc` ä»¥åŠ å¿«å¤„ç†é€Ÿåº¦é€šå¸¸æ˜¯ä¸€ä¸ªå¥½ä¸»æ„ï¼Œåªè¦ä½ ä½¿ç”¨çš„å‡½æ•°æœ¬èº«æ²¡æœ‰è¿›è¡ŒæŸç§ç±»å‹çš„å¤šè¿›ç¨‹å¤„ç†ã€‚

</Tip>

å°†æ‰€æœ‰è¿™äº›åŠŸèƒ½æµ“ç¼©åˆ°ä¸€ä¸ªæ–¹æ³•ä¸­å·²ç»éå¸¸äº†ä¸èµ·ï¼Œä½†æ˜¯è¿˜æœ‰æ›´å¤šï¼ä½¿ç”¨ `Dataset.map()` å’Œ `batched=True` ä½ å¯ä»¥æ›´æ”¹æ•°æ®é›†ä¸­çš„å…ƒç´ æ•°é‡ã€‚å½“ä½ æƒ³ä»ä¸€ä¸ªæ ·æœ¬ä¸­åˆ›å»ºå‡ ä¸ªè®­ç»ƒç‰¹å¾æ—¶ï¼Œè¿™æ˜¯éå¸¸æœ‰ç”¨çš„ã€‚æˆ‘ä»¬å°†åœ¨ [ç¬¬ä¸ƒç« ](/course/chapter7) ä¸­å‡ ä¸ª NLP ä»»åŠ¡çš„é¢„å¤„ç†ä¸­ä½¿ç”¨åˆ°è¿™ä¸ªåŠŸèƒ½ï¼Œå®ƒéå¸¸ä¾¿æ·ã€‚

<Tip>

ğŸ’¡åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œä¸€ä¸ªæ ·æœ¬é€šå¸¸å¯ä»¥ä¸ºæˆ‘ä»¬çš„æ¨¡å‹æä¾›ä¸€ç»„ç‰¹å¾ã€‚åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œè¿™ç»„ç‰¹å¾ä¼šå‚¨å­˜åœ¨æ•°æ®é›†çš„å‡ ä¸ªåˆ—ï¼Œä½†åœ¨æŸäº›æƒ…å†µä¸‹ï¼ˆä¾‹å¦‚æ­¤å¤„çš„ä¾‹å­å’Œç”¨äºé—®ç­”çš„æ•°æ®ï¼‰ï¼Œå¯ä»¥ä»å•ä¸ªæ ·æœ¬çš„é‚£ä¸€åˆ—ä¸­æå–å¤šä¸ªç‰¹å¾ã€‚

</Tip>

è®©æˆ‘ä»¬æ¥çœ‹çœ‹ä»ä¸€åˆ—ä¸­æå–å¤šä¸ªç‰¹å¾æ˜¯å¦‚ä½•å®ç°çš„ï¼åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†å¯¹æˆ‘ä»¬çš„æ ·æœ¬è¿›è¡Œ tokenize å¹¶å°†æœ€å¤§æˆªæ–­é•¿åº¦è®¾ç½®ä¸º 128ï¼Œå¹¶ä¸”æˆ‘ä»¬å°†è¦æ±‚ tokenizer è¿”å›å…¨éƒ¨æ–‡æœ¬å—ï¼Œè€Œä¸ä»…ä»…æ˜¯ç¬¬ä¸€ä¸ªã€‚è¿™å¯ä»¥é€šè¿‡è®¾ç½® `return_overflowing_tokens=True` æ¥å®ç°ï¼š

```py
def tokenize_and_split(examples):
    return tokenizer(
        examples["review"],
        truncation=True,
        max_length=128,
        return_overflowing_tokens=True,
    )
```

åœ¨ä½¿ç”¨ `Dataset.map()` æ­£å¼å¼€å§‹å¤„ç†æ•´ä¸ªæ•°æ®é›†ä¹‹å‰ï¼Œè®©æˆ‘ä»¬å…ˆåœ¨ä¸€ä¸ªæ ·æœ¬ä¸Šæµ‹è¯•ä¸€ä¸‹ï¼š

```py
result = tokenize_and_split(drug_dataset["train"][0])
[len(inp) for inp in result["input_ids"]]
```

```python out
[128, 49]
```

ç§ï¼æˆ‘ä»¬åœ¨è®­ç»ƒé›†ä¸­çš„ç¬¬ä¸€ä¸ªæ ·æœ¬å˜æˆäº†ä¸¤ä¸ªç‰¹å¾ï¼Œå› ä¸ºå®ƒè¶…è¿‡äº†æˆ‘ä»¬æŒ‡å®šçš„æœ€å¤§æˆªæ–­é•¿åº¦ï¼Œå› æ­¤è¢«æˆªæˆäº†ä¸¤æ®µï¼šç¬¬ä¸€æ®µé•¿åº¦ä¸º 128 ç¬¬äºŒæ®µé•¿åº¦ä¸º 49 ç°åœ¨è®©æˆ‘ä»¬å¯¹æ•°æ®é›†çš„æ‰€æœ‰æ ·æœ¬æ‰§è¡Œæ­¤æ“ä½œï¼

```py
tokenized_dataset = drug_dataset.map(tokenize_and_split, batched=True)
```

```python out
ArrowInvalid: Column 1 named condition expected length 1463 but got length 1000
```

ä¸å¥½äº†ï¼è¿™å¹¶æ²¡æœ‰æˆåŠŸï¼ä¸ºä»€ä¹ˆå‘¢ï¼ŸæŸ¥çœ‹é”™è¯¯æ¶ˆæ¯ä¼šç»™æˆ‘ä»¬ä¸€ä¸ªçº¿ç´¢ï¼šåˆ—çš„é•¿åº¦ä¸åŒ¹é…ï¼Œä¸€åˆ—é•¿åº¦ä¸º 1,463ï¼Œå¦ä¸€åˆ—é•¿åº¦ä¸º 1,000ã€‚1,000 è¡Œçš„â€œé‡æ–°â€ç”Ÿæˆäº† 1,463 è¡Œçš„æ–°ç‰¹å¾ï¼Œå¯¼è‡´å’ŒåŸæœ¬çš„ 1000 è¡Œçš„é•¿åº¦ä¸åŒ¹é…ã€‚

é—®é¢˜å‡ºåœ¨æˆ‘ä»¬è¯•å›¾æ··åˆä¸¤ä¸ªé•¿åº¦ä¸åŒçš„æ•°æ®é›†ï¼š `drug_dataset` åˆ—å°†æœ‰ 1000 ä¸ªæ ·æœ¬ï¼Œä½†æ˜¯æˆ‘ä»¬æ­£åœ¨æ„å»º `tokenized_dataset` åˆ—å°†æœ‰ 1,463 ä¸ªæ ·æœ¬ï¼ˆå› ä¸ºæˆ‘ä»¬ä½¿ç”¨ `return_overflowing_tokens=True` å°†é•¿è¯„è®ºåˆ†è¯æˆäº†å¤šä¸ªæ ·æœ¬ï¼‰ã€‚è¿™å¯¹ `Dataset` æ¥è¯´ä¸å¯è¡Œï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦è¦ä¹ˆåˆ é™¤æ—§æ•°æ®é›†çš„åˆ—ï¼Œè¦ä¹ˆä½¿å®ƒä»¬ä¸æ–°æ•°æ®é›†ä¸­çš„å°ºå¯¸ç›¸åŒã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `remove_columns` å‚æ•°æ¥å®ç°å‰è€…ï¼š

```py
tokenized_dataset = drug_dataset.map(
    tokenize_and_split, batched=True, remove_columns=drug_dataset["train"].column_names
)
```

ç°åœ¨è¿™ä¸ªè¿‡ç¨‹æ²¡æœ‰é”™è¯¯ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡æ¯”è¾ƒé•¿åº¦æ¥æ£€æŸ¥æˆ‘ä»¬çš„æ–°æ•°æ®é›†æ˜¯å¦æ¯”åŸå§‹æ•°æ®é›†æœ‰æ›´å¤šçš„å…ƒç´ ï¼š

```py
len(tokenized_dataset["train"]), len(drug_dataset["train"])
```

```python out
(206772, 138514)
```

æˆ‘ä»¬ä¹Ÿå¯ä»¥é€šè¿‡ä½¿æ—§åˆ—ä¸æ–°åˆ—ä¿æŒç›¸åŒå¤§å°æ¥å¤„ç†ä¸åŒ¹é…é•¿åº¦çš„é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œå½“æˆ‘ä»¬è®¾ç½® `return_overflowing_tokens=True` æ—¶ï¼Œå¯ä»¥ä½¿ç”¨ `overflow_to_sample_mapping` å­—æ®µã€‚å®ƒç»™å‡ºäº†æ–°ç‰¹å¾ç´¢å¼•åˆ°å®ƒæºè‡ªçš„æ ·æœ¬ç´¢å¼•çš„æ˜ å°„ã€‚ä½¿ç”¨è¿™ä¸ªï¼Œæˆ‘ä»¬å¯ä»¥å°†åŸå§‹æ•°æ®é›†ä¸­çš„æ¯ä¸ªé”®å…³è”åˆ°ä¸€ä¸ªåˆé€‚å¤§å°çš„å€¼åˆ—è¡¨ä¸­ï¼Œé€šè¿‡éå†æ‰€æœ‰çš„æ•°æ®æ¥ç”Ÿæˆæ–°ç‰¹æ€§ï¼š

```py
def tokenize_and_split(examples):
    result = tokenizer(
        examples["review"],
        truncation=True,
        max_length=128,
        return_overflowing_tokens=True,
    )
    # æå–æ–°æ—§ç´¢å¼•ä¹‹é—´çš„æ˜ å°„
    sample_map = result.pop("overflow_to_sample_mapping")
    for key, values in examples.items():
        result[key] = [values[i] for i in sample_map]
    return result
```

å¯ä»¥çœ‹åˆ°å®ƒå¯ä»¥ä¸ `Dataset.map()` ä¸€èµ·åä½œï¼Œæ— éœ€æˆ‘ä»¬åˆ é™¤æ—§åˆ—ï¼š

```py
tokenized_dataset = drug_dataset.map(tokenize_and_split, batched=True)
tokenized_dataset
```

```python out
DatasetDict({
    train: Dataset({
        features: ['attention_mask', 'condition', 'date', 'drugName', 'input_ids', 'patient_id', 'rating', 'review', 'review_length', 'token_type_ids', 'usefulCount'],
        num_rows: 206772
    })
    test: Dataset({
        features: ['attention_mask', 'condition', 'date', 'drugName', 'input_ids', 'patient_id', 'rating', 'review', 'review_length', 'token_type_ids', 'usefulCount'],
        num_rows: 68876
    })
})
```

æˆ‘ä»¬è·å¾—äº†ä¸ä¹‹å‰æ•°é‡ç›¸åŒçš„è®­ç»ƒç‰¹å¾ï¼Œå¹¶ä¸”åœ¨è¿™é‡Œæˆ‘ä»¬ä¿ç•™äº†æ‰€æœ‰æ—§å­—æ®µã€‚å¦‚æœä½ åœ¨ä½¿ç”¨æ¨¡å‹è®¡ç®—ä¹‹åéœ€è¦å®ƒä»¬è¿›è¡Œä¸€äº›åç»­å¤„ç†ï¼Œä½ å¯èƒ½éœ€è¦ä½¿ç”¨è¿™ç§æ–¹æ³•ã€‚

ä½ ç°åœ¨å·²ç»äº†è§£äº†å¦‚ä½•ä½¿ç”¨ ğŸ¤— Datasets ä»¥å„ç§æ–¹å¼ç”¨äºé¢„å¤„ç†æ•°æ®é›†ã€‚è™½ç„¶ğŸ¤— Datasets çš„å¤„ç†åŠŸèƒ½ä¼šè¦†ç›–ä½ å¤§éƒ¨åˆ†çš„æ¨¡å‹è®­ç»ƒéœ€æ±‚ï¼Œæœ‰æ—¶ä½ å¯èƒ½éœ€è¦åˆ‡æ¢åˆ° Pandas ä»¥ä½¿ç”¨æ›´å¼ºå¤§çš„åŠŸèƒ½ï¼Œä¾‹å¦‚ `DataFrame.groupby()` æˆ–ç”¨äºå¯è§†åŒ–çš„é«˜çº§ APIã€‚å¹¸è¿çš„æ˜¯ï¼ŒğŸ¤— Datasets è®¾è®¡å®—æ—¨å°±æ˜¯ä¸ Pandasã€NumPyã€PyTorchã€TensorFlow å’Œ JAX ç­‰åº“å¯ä»¥ç›¸äº’è½¬æ¢ã€‚è®©æˆ‘ä»¬æ¥çœ‹çœ‹è¿™æ˜¯å¦‚ä½•å®ç°çš„ã€‚

## ğŸ¤— Datasets å’Œ DataFrames çš„ç›¸äº’è½¬æ¢ [[ ğŸ¤— Datasets å’Œ DataFrames çš„ç›¸äº’è½¬æ¢]]

<Youtube id="tfcY1067A5Q"/>

ä¸ºäº†å®ç°å„ç§ç¬¬ä¸‰æ–¹åº“ä¹‹é—´çš„è½¬æ¢ï¼ŒğŸ¤— Datasets æä¾›äº†ä¸€ä¸ª `Dataset.set_format()` å‡½æ•°ã€‚æ­¤å‡½æ•°å¯ä»¥é€šè¿‡ä»…æ›´æ”¹è¾“å‡ºæ ¼å¼çš„ï¼Œè½»æ¾åˆ‡æ¢åˆ°å¦ä¸€ç§æ ¼å¼ï¼Œè€Œä¸ä¼šå½±å“åº•å±‚æ•°æ®æ ¼å¼ï¼ˆä»¥ Apache Arrow æ–¹å¼è¿›è¡Œå­˜å‚¨ï¼‰ã€‚ä¸ºäº†æ¼”ç¤ºï¼Œè®©æˆ‘ä»¬æŠŠæ•°æ®é›†è½¬æ¢ä¸º Pandasï¼š

```py
drug_dataset.set_format("pandas")
```

ç°åœ¨ï¼Œå½“æˆ‘ä»¬è®¿é—®æ•°æ®é›†çš„å…ƒç´ æ—¶ï¼Œæˆ‘ä»¬ä¼šå¾—åˆ°ä¸€ä¸ª `pandas.DataFrame` è€Œä¸æ˜¯å­—å…¸ï¼š

```py
drug_dataset["train"][:3]
```

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>patient_id</th>
      <th>drugName</th>
      <th>condition</th>
      <th>review</th>
      <th>rating</th>
      <th>date</th>
      <th>usefulCount</th>
      <th>review_length</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>95260</td>
      <td>Guanfacine</td>
      <td>adhd</td>
      <td>"My son is halfway through his fourth week of Intuniv."</td>
      <td>8.0</td>
      <td>April 27, 2010</td>
      <td>192</td>
      <td>141</td>
    </tr>
    <tr>
      <th>1</th>
      <td>92703</td>
      <td>Lybrel</td>
      <td>birth control</td>
      <td>"I used to take another oral contraceptive, which had 21 pill cycle, and was very happy- very light periods, max 5 days, no other side effects."</td>
      <td>5.0</td>
      <td>December 14, 2009</td>
      <td>17</td>
      <td>134</td>
    </tr>
    <tr>
      <th>2</th>
      <td>138000</td>
      <td>Ortho Evra</td>
      <td>birth control</td>
      <td>"This is my first time using any form of birth control."</td>
      <td>8.0</td>
      <td>November 3, 2015</td>
      <td>10</td>
      <td>89</td>
    </tr>
  </tbody>
</table>

æ¥ä¸‹æ¥æˆ‘ä»¬ä»æ•°æ®é›†ä¸­é€‰æ‹© `drug_dataset[train]` çš„æ‰€æœ‰æ•°æ®æ¥å¾—åˆ°è®­ç»ƒé›†æ•°æ®ï¼š

```py
train_df = drug_dataset["train"][:]
```

<Tip>

ğŸš¨ å®é™…ä¸Šï¼Œ `Dataset.set_format()` ä»…ä»…æ”¹å˜äº†æ•°æ®é›†çš„ `__getitem__()` æ–¹æ³•çš„è¿”å›æ ¼å¼ã€‚è¿™æ„å‘³ç€å½“æˆ‘ä»¬æƒ³ä» `"pandas"` æ ¼å¼çš„ `Dataset` ä¸­åˆ›å»ºåƒ `train_df` è¿™æ ·çš„æ–°å¯¹è±¡æ—¶ï¼Œæˆ‘ä»¬éœ€è¦å¯¹æ•´ä¸ªæ•°æ®é›†è¿›è¡Œåˆ‡ç‰‡ï¼ˆ[:]ï¼‰æ‰å¯ä»¥è·å¾— `pandas.DataFrame` å¯¹è±¡ã€‚æ— è®ºè¾“å‡ºæ ¼å¼å¦‚ä½•ï¼Œä½ éƒ½å¯ä»¥è‡ªå·±éªŒè¯ `drug_dataset["train"]` çš„ç±»å‹ä¾ç„¶è¿˜æ˜¯ `Dataset` ã€‚

</Tip>


æœ‰äº†è¿™ä¸ªåŸºç¡€ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æˆ‘ä»¬æƒ³è¦çš„æ‰€æœ‰ Pandas åŠŸèƒ½ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥å·§å¦™åœ°é“¾å¼æ“ä½œï¼Œæ¥è®¡ç®— `condition` åˆ—ä¸­ä¸åŒç±»åˆ«çš„åˆ†å¸ƒ 

```py
frequencies = (
    train_df["condition"]
    .value_counts()
    .to_frame()
    .reset_index()
    .rename(columns={"index": "condition", "count": "frequency"})
)
frequencies.head()
```

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>condition</th>
      <th>frequency</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>birth control</td>
      <td>27655</td>
    </tr>
    <tr>
      <th>1</th>
      <td>depression</td>
      <td>8023</td>
    </tr>
    <tr>
      <th>2</th>
      <td>acne</td>
      <td>5209</td>
    </tr>
    <tr>
      <th>3</th>
      <td>anxiety</td>
      <td>4991</td>
    </tr>
    <tr>
      <th>4</th>
      <td>pain</td>
      <td>4744</td>
    </tr>
  </tbody>
</table>


å½“æˆ‘ä»¬å®Œæˆäº† Pandas åˆ†æä¹‹åï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å¯¹è±¡ `Dataset.from_pandas()` æ–¹æ³•å¯ä»¥åˆ›å»ºä¸€ä¸ªæ–°çš„ `Dataset` å¯¹è±¡ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š


```py
from datasets import Dataset

freq_dataset = Dataset.from_pandas(frequencies)
freq_dataset
```

```python out
Dataset({
    features: ['condition', 'frequency'],
    num_rows: 819
})
```

<Tip>

âœï¸**è¯•è¯•çœ‹ï¼**è®¡ç®—æ¯ç§è¯ç‰©çš„å¹³å‡è¯„åˆ†å¹¶å°†ç»“æœå­˜å‚¨åœ¨ä¸€ä¸ªæ–°çš„ Dataset ä¸­ã€‚

</Tip>

åˆ°æ­¤ä¸ºæ­¢ï¼Œæˆ‘ä»¬å¯¹ğŸ¤— Datasets ä¸­å¯ç”¨çš„å„ç§é¢„å¤„ç†æŠ€æœ¯çš„ä»‹ç»å°±ç»“æŸäº†ã€‚åœ¨æœ¬èŠ‚çš„æœ€åä¸€éƒ¨åˆ†ï¼Œè®©æˆ‘ä»¬ä¸ºè®­ç»ƒåˆ†ç±»å™¨åˆ›å»ºä¸€ä¸ªéªŒè¯é›†ã€‚åœ¨æ­¤ä¹‹å‰ï¼Œè®©æˆ‘ä»¬å°†è¾“å‡ºæ ¼å¼ `drug_dataset` ä» `pandas` é‡ç½®åˆ° `arrow` ï¼š

```python
drug_dataset.reset_format()
```

## åˆ›å»ºéªŒè¯é›† [[åˆ›å»ºéªŒè¯é›†]]

å°½ç®¡æˆ‘ä»¬æœ‰ä¸€ä¸ªå¯ä»¥ç”¨äºè¯„ä¼°çš„æµ‹è¯•é›†ï¼Œä½†åœ¨å¼€å‘è¿‡ç¨‹ä¸­ä¿æŒæµ‹è¯•é›†ä¸å˜å¹¶åˆ›å»ºä¸€ä¸ªå•ç‹¬çš„éªŒè¯é›†æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„åšæ³•ã€‚ä¸€æ—¦ä½ å¯¹æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„è¡¨ç°æ„Ÿåˆ°æ»¡æ„ï¼Œä½ å°±å¯ä»¥ä½¿ç”¨éªŒè¯é›†è¿›è¡Œæœ€ç»ˆçš„æ£€æŸ¥ã€‚æ­¤è¿‡ç¨‹æœ‰åŠ©äºé™ä½ä½ è¿‡æ‹Ÿåˆæµ‹è¯•é›†å’Œéƒ¨ç½²åœ¨ç°å®ä¸–ç•Œæ•°æ®ä¸Šå¤±è´¥çš„æ¨¡å‹çš„é£é™©ã€‚

ğŸ¤— Datasets æä¾›äº†ä¸€ä¸ªåŸºäº `scikit-learn` çš„ç»å…¸æ–¹æ³•ï¼š `Dataset.train_test_split()` ã€‚è®©æˆ‘ä»¬ç”¨å®ƒæŠŠæˆ‘ä»¬çš„è®­ç»ƒé›†åˆ†æˆ `train` å’Œ `validation` ï¼ˆä¸ºäº†å¯ä»¥å¤ç°ï¼Œæˆ‘ä»¬å°†è®¾ç½® `seed` çš„å€¼ä¸ºä¸€ä¸ªå¸¸é‡ï¼‰ï¼š

```py
drug_dataset_clean = drug_dataset["train"].train_test_split(train_size=0.8, seed=42)
# å°†é»˜è®¤çš„ "test" éƒ¨åˆ†é‡å‘½åä¸º "validation"
drug_dataset_clean["validation"] = drug_dataset_clean.pop("test")
# å°† "test" éƒ¨åˆ†æ·»åŠ åˆ°æˆ‘ä»¬çš„ `DatasetDict` ä¸­
drug_dataset_clean["test"] = drug_dataset["test"]
drug_dataset_clean
```

```python out
DatasetDict({
    train: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'review_clean'],
        num_rows: 110811
    })
    validation: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'review_clean'],
        num_rows: 27703
    })
    test: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'review_clean'],
        num_rows: 46108
    })
})
```

å¤ªå¥½äº†ï¼Œæˆ‘ä»¬ç°åœ¨å·²ç»å‡†å¤‡å¥½äº†ä¸€ä¸ªé€‚åˆè®­ç»ƒæ¨¡å‹çš„æ•°æ®é›†äº†ï¼åœ¨ [ç¬¬äº”èŠ‚](/course/chapter5/5) æˆ‘ä»¬å°†å‘ä½ å±•ç¤ºå¦‚ä½•å°†æ•°æ®é›†ä¸Šä¼ åˆ° Hugging Face Hubï¼Œç°åœ¨è®©æˆ‘ä»¬å…ˆç»“æŸæˆ‘ä»¬çš„åˆ†æï¼Œçœ‹ä¸€çœ‹åœ¨æœ¬åœ°è®¡ç®—æœºä¸Šä¿å­˜æ•°æ®é›†çš„å‡ ç§æ–¹æ³•ã€‚

## ä¿å­˜æ•°æ®é›† [[ä¿å­˜æ•°æ®é›†]]

<Youtube id="blF9uxYcKHo"/>

è™½ç„¶ ğŸ¤— Datasets ä¼šç¼“å­˜æ¯ä¸ªä¸‹è½½çš„æ•°æ®é›†å’Œå¯¹å®ƒæ‰§è¡Œçš„æ“ä½œï¼Œä½†æœ‰æ—¶ä½ ä¼šæƒ³è¦å°†æ•°æ®é›†ä¿å­˜åˆ°ç£ç›˜ï¼ˆæ¯”å¦‚ï¼Œä»¥é˜²ç¼“å­˜è¢«åˆ é™¤ï¼‰ã€‚å¦‚ä¸‹è¡¨æ‰€ç¤ºï¼ŒğŸ¤— Datasets æä¾›äº†ä¸‰ä¸ªä¸»è¦å‡½æ•°æ¥ä»¥ä¸åŒçš„æ ¼å¼ä¿å­˜ä½ çš„æ•°æ®é›†ï¼š

| æ•°æ®æ ¼å¼    |        å¯¹åº”çš„æ–¹æ³•        |
| :---------: | :--------------------: |
|    Arrow    | `Dataset.save_to_disk()` |
|     CSV     | `Dataset.to_csv()` |
|    JSON     | `Dataset.to_json()` |

ä¾‹å¦‚ï¼Œè®©æˆ‘ä»¬ä»¥ Arrow æ ¼å¼ä¿å­˜æˆ‘ä»¬æ¸…æ´—è¿‡çš„æ•°æ®é›†ï¼š

```py
drug_dataset_clean.save_to_disk("drug-reviews")
```

è¿™å°†åˆ›å»ºä¸€ä¸ªå…·æœ‰ä»¥ä¸‹ç»“æ„çš„ç›®å½•ï¼š

```
drug-reviews/
â”œâ”€â”€ dataset_dict.json
â”œâ”€â”€ test
â”‚   â”œâ”€â”€ dataset.arrow
â”‚   â”œâ”€â”€ dataset_info.json
â”‚   â””â”€â”€ state.json
â”œâ”€â”€ train
â”‚   â”œâ”€â”€ dataset.arrow
â”‚   â”œâ”€â”€ dataset_info.json
â”‚   â”œâ”€â”€ indices.arrow
â”‚   â””â”€â”€ state.json
â””â”€â”€ validation
    â”œâ”€â”€ dataset.arrow
    â”œâ”€â”€ dataset_info.json
    â”œâ”€â”€ indices.arrow
    â””â”€â”€ state.json
```

å…¶ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œæ¯ä¸ªéƒ¨åˆ†éƒ½æœ‰ `dataset.arrow` è¡¨ï¼Œä»¥åŠä¿å­˜å…ƒæ•°æ®çš„ `dataset_info.json` å’Œ `state.json` ã€‚ä½ å¯ä»¥å°† Arrow æ ¼å¼è§†ä¸ºä¸€ä¸ªä¼˜åŒ–è¿‡çš„åˆ—å’Œè¡Œçš„ç²¾ç¾è¡¨æ ¼ï¼Œå®ƒé’ˆå¯¹æ„å»ºå¤„ç†å’Œä¼ è¾“å¤§å‹æ•°æ®é›†çš„é«˜æ€§èƒ½åº”ç”¨ç¨‹åºè¿›è¡Œäº†ä¼˜åŒ–ã€‚

ä¿å­˜æ•°æ®é›†åï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `load_from_disk()` åŠŸèƒ½ä»ç£ç›˜è¯»å–æ•°æ®ï¼š

```py
from datasets import load_from_disk

drug_dataset_reloaded = load_from_disk("drug-reviews")
drug_dataset_reloaded
```

```python out
DatasetDict({
    train: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],
        num_rows: 110811
    })
    validation: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],
        num_rows: 27703
    })
    test: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],
        num_rows: 46108
    })
})
```

å¯¹äº CSV å’Œ JSON æ ¼å¼ï¼Œæˆ‘ä»¬å¿…é¡»å°†æ¯ä¸ªéƒ¨åˆ†å­˜å‚¨ä¸ºå•ç‹¬çš„æ–‡ä»¶ã€‚ä¸€ç§æ–¹æ³•æ˜¯éå† `DatasetDict` ä¸­çš„é”®å’Œå€¼ 

```py
for split, dataset in drug_dataset_clean.items():
    dataset.to_json(f"drug-reviews-{split}.jsonl")
```

è¿™å°†æŠŠæ¯ä¸ªéƒ¨åˆ†ä¿å­˜ä¸º [JSON Linesæ ¼å¼](https://jsonlines.org) ï¼Œå…¶ä¸­æ•°æ®é›†ä¸­çš„æ¯ä¸€è¡Œéƒ½å­˜å‚¨ä¸ºä¸€è¡Œ JSONã€‚ä¸‹é¢æ˜¯ç¬¬ä¸€ä¸ªä¾‹å­çš„æ ·å­ï¼š

```py
!head -n 1 drug-reviews-train.jsonl
```

```python out
{"patient_id":141780,"drugName":"Escitalopram","condition":"depression","review":"\"I seemed to experience the regular side effects of LEXAPRO, insomnia, low sex drive, sleepiness during the day. I am taking it at night because my doctor said if it made me tired to take it at night. I assumed it would and started out taking it at night. Strange dreams, some pleasant. I was diagnosed with fibromyalgia. Seems to be helping with the pain. Have had anxiety and depression in my family, and have tried quite a few other medications that haven't worked. Only have been on it for two weeks but feel more positive in my mind, want to accomplish more in my life. Hopefully the side effects will dwindle away, worth it to stick with it from hearing others responses. Great medication.\"","rating":9.0,"date":"May 29, 2011","usefulCount":10,"review_length":125}
```

ç„¶åæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ [ç¬¬äºŒèŠ‚](/course/chapter5/2) ä¸­çš„æŠ€å·§ï¼ŒæŒ‰å¦‚ä¸‹æ‰€ç¤ºåŠ è½½ JSON æ–‡ä»¶

```py
data_files = {
    "train": "drug-reviews-train.jsonl",
    "validation": "drug-reviews-validation.jsonl",
    "test": "drug-reviews-test.jsonl",
}
drug_dataset_reloaded = load_dataset("json", data_files=data_files)
```

è‡³æ­¤ï¼Œæˆ‘ä»¬å¯¹ä½¿ç”¨ğŸ¤— Datasets è¿›è¡Œæ•°æ®æ•´ç†çš„æ¢ç´¢å°±æ­¤ç»“æŸï¼ç°åœ¨æˆ‘ä»¬æœ‰äº†ä¸€ä¸ªæ¸…æ´—è¿‡çš„æ•°æ®é›†ï¼Œä»¥ä¸‹æ˜¯ä½ å¯ä»¥å°è¯•çš„ä¸€äº›æƒ³æ³•ï¼š

1. ä½¿ç”¨ [ç¬¬ä¸‰ç« ](/course/chapter3) çš„æŠ€æœ¯æ¥è®­ç»ƒä¸€ä¸ªåˆ†ç±»å™¨ï¼Œå®ƒèƒ½å¤ŸåŸºäºè¯å“è¯„ä»·é¢„æµ‹æ‚£è€…çš„ç—…æƒ…ã€‚
2. ä½¿ç”¨ [ç¬¬ä¸€ç« ](/course/chapter1) ä¸­çš„ `summarization` ç®¡é“ç”Ÿæˆè¯„è®ºçš„æ‘˜è¦ã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†çœ‹çœ‹ ğŸ¤— Datasets å¦‚ä½•ä½¿ä½ èƒ½å¤Ÿåœ¨ä¸æ’‘çˆ†ç¬”è®°æœ¬ç”µè„‘å†…å­˜çš„æƒ…å†µä¸‹å¤„ç†åºå¤§çš„æ•°æ®é›†ï¼