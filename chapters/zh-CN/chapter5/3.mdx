# æ˜¯æ—¶å€™æ¥å­¦ä¸€ä¸‹åˆ‡ç‰‡äº†

<DocNotebookDropdown
  classNames="absolute z-10 right-0 top-0"
  options={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter5/section3.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter5/section3.ipynb"},
]} />

å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œæ‚¨ä½¿ç”¨çš„æ•°æ®éƒ½éœ€æ ¹æ®æ¨¡å‹æ‰€è¦æ±‚çš„è¾“å…¥è¿›è¡Œæ¸…æ´—ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æ¢ç´¢ ğŸ¤— Datasets æä¾›çš„ç”¨äºæ•°æ®é›†æ¸…æ´—çš„å„ç§åŠŸèƒ½ã€‚

<Youtube id="tqfSFcPMgOI"/>

## åˆ‡ç‰‡ä¸åˆ‡åˆ†æˆ‘ä»¬çš„æ•°æ®

ä¸ Pandas ç±»ä¼¼ï¼ŒğŸ¤— Datasets æä¾›äº†å‡ ä¸ªå‡½æ•°æ¥æ“ä½œ **Dataset** å’Œ **DatasetDict** å¯¹è±¡ã€‚æˆ‘ä»¬åœ¨[ç¬¬ä¸‰ç« ](/course/chapter3)å·²ç»é‡åˆ°äº† **Dataset.map()** æ–¹æ³•ï¼Œåœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æ¢ç´¢æˆ‘ä»¬å¯ä»¥ä½¿ç”¨çš„å…¶ä»–åŠŸèƒ½ã€‚

å¯¹äºè¿™ä¸ªä¾‹å­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æ‰˜ç®¡åœ¨[åŠ å·å¤§å­¦æ¬§æ–‡åˆ†æ ¡æœºå™¨å­¦ä¹ å­˜å‚¨åº“](https://archive.ics.uci.edu/ml/index.php)çš„[è¯ç‰©å®¡æŸ¥æ•°æ®é›†](https://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+%28Drugs.com%29)ï¼Œå…¶ä¸­åŒ…å«æ‚£è€…å¯¹å„ç§è¯ç‰©çš„è¯„è®ºï¼Œä»¥åŠæ­£åœ¨æ²»ç–—çš„ç—…æƒ…å’Œæ‚£è€…æ»¡æ„åº¦çš„ 10 æ˜Ÿè¯„çº§ã€‚

é¦–å…ˆæˆ‘ä»¬éœ€è¦ä¸‹è½½å¹¶æå–æ•°æ®ï¼Œè¿™å¯ä»¥é€šè¿‡ **wget** å’Œ **unzip** å‘½ä»¤ï¼š

```py
!wget "https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip"
!unzip drugsCom_raw.zip
```

ç”±äº TSV åªæ˜¯ä½¿ç”¨åˆ¶è¡¨ç¬¦è€Œä¸æ˜¯é€—å·ä½œä¸ºåˆ†éš”ç¬¦çš„ CSV å˜ä½“ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨åŠ è½½**csv**æ–‡ä»¶çš„**load_dataset()**å‡½æ•°å¹¶æŒ‡å®šåˆ†éš”ç¬¦ ç¤ºä¾‹å¦‚ä¸‹ï¼š

```py
from datasets import load_dataset

data_files = {"train": "drugsComTrain_raw.tsv", "test": "drugsComTest_raw.tsv"}
# \t is the tab character in Python
drug_dataset = load_dataset("csv", data_files=data_files, delimiter="\t")
```

åœ¨è¿›è¡Œä»»ä½•ç±»å‹çš„æ•°æ®åˆ†ææ—¶ï¼Œä¸€ä¸ªå¥½çš„åšæ³•æ˜¯æŠ½å–ä¸€ä¸ªå°çš„éšæœºæ ·æœ¬ï¼Œä»¥å¿«é€Ÿäº†è§£æ‚¨æ­£åœ¨å¤„ç†çš„æ•°æ®ç±»å‹ã€‚åœ¨ğŸ¤—æ•°æ®é›†ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡é“¾æ¥ **Dataset.shuffle()** å’Œ **Dataset.select()** å…±åŒæ¥å®ŒæˆæŠ½å–ï¼š

```py
drug_sample = drug_dataset["train"].shuffle(seed=42).select(range(1000))
# Peek at the first few examples
drug_sample[:3]
```

```python out
{'Unnamed: 0': [87571, 178045, 80482],
 'drugName': ['Naproxen', 'Duloxetine', 'Mobic'],
 'condition': ['Gout, Acute', 'ibromyalgia', 'Inflammatory Conditions'],
 'review': ['"like the previous person mention, I&#039;m a strong believer of aleve, it works faster for my gout than the prescription meds I take. No more going to the doctor for refills.....Aleve works!"',
  '"I have taken Cymbalta for about a year and a half for fibromyalgia pain. It is great\r\nas a pain reducer and an anti-depressant, however, the side effects outweighed \r\nany benefit I got from it. I had trouble with restlessness, being tired constantly,\r\ndizziness, dry mouth, numbness and tingling in my feet, and horrible sweating. I am\r\nbeing weaned off of it now. Went from 60 mg to 30mg and now to 15 mg. I will be\r\noff completely in about a week. The fibro pain is coming back, but I would rather deal with it than the side effects."',
  '"I have been taking Mobic for over a year with no side effects other than an elevated blood pressure.  I had severe knee and ankle pain which completely went away after taking Mobic.  I attempted to stop the medication however pain returned after a few days."'],
 'rating': [9.0, 3.0, 10.0],
 'date': ['September 2, 2015', 'November 7, 2011', 'June 5, 2013'],
 'usefulCount': [36, 13, 128]}
```

è¯·æ³¨æ„ï¼Œå‡ºäºå¯ä»¥å¤ç°çš„ç›®çš„ï¼Œæˆ‘ä»¬å·²å°†åœ¨**Dataset.shuffle()**é€‰å–äº†å›ºå®šçš„éšæœºæ•°ç§å­ã€‚ **Dataset.select()** éœ€è¦ä¸€ä¸ªå¯è¿­ä»£çš„ç´¢å¼•ï¼Œæ‰€ä»¥æˆ‘ä»¬å·²ç»é€šè¿‡äº† **range(1000)** ä»éšæœºæ‰“ä¹±çš„æ•°æ®é›†ä¸­é€‰å–å‰ 1,000 ä¸ªç¤ºä¾‹ã€‚ä»æŠ½å–çš„æ•°æ®ä¸­ï¼Œæˆ‘ä»¬å·²ç»å¯ä»¥çœ‹åˆ°æˆ‘ä»¬æ•°æ®é›†çš„ä¸€äº›ç‰¹ç‚¹ï¼š

* **Unnamed: 0**è¿™åˆ—çœ‹èµ·æ¥å¾ˆåƒæ¯ä¸ªæ‚£è€…çš„åŒ¿å IDã€‚
* **condition** è¿™åˆ—åŒ…å«æœ‰æè¿°å¥åº·çŠ¶å†µçš„æ ‡ç­¾ã€‚
* è¯„è®ºé•¿çŸ­ä¸ä¸€ï¼Œæ··åˆæœ‰ Python è¡Œåˆ†éš”ç¬¦ (**\r\n**) ä»¥åŠ HTML å­—ç¬¦ä»£ç ï¼Œå¦‚** &\#039;**ã€‚
  
è®©æˆ‘ä»¬çœ‹çœ‹æˆ‘ä»¬å¦‚ä½•ä½¿ç”¨ ğŸ¤— Datasets æ¥å¤„ç†è¿™äº›é—®é¢˜ã€‚ä¸ºäº†éªŒè¯**Unnamed: 0** åˆ—å­˜å‚¨çš„æ˜¯æ‚£è€… IDçš„çŒœæƒ³ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ **Dataset.unique()** å‡½æ•°æ¥éªŒè¯åŒ¿åID çš„æ•°é‡æ˜¯å¦ä¸æ‹†åˆ†åæ¯éƒ¨åˆ†ä¸­çš„è¡Œæ•°åŒ¹é…ï¼š

```py
for split in drug_dataset.keys():
    assert len(drug_dataset[split]) == len(drug_dataset[split].unique("Unnamed: 0"))
```

è¿™ä¼¼ä¹è¯å®äº†æˆ‘ä»¬çš„å‡è®¾ï¼Œæ‰€ä»¥è®©æˆ‘ä»¬æŠŠ **Unnamed: 0** åˆ—é‡å‘½åä¸ºæ‚£è€…çš„idã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ **DatasetDict.rename_column()**å‡½æ•°ä¸€æ¬¡æ€§é‡å‘½åDatasetDictä¸­å…±æœ‰çš„åˆ—ï¼š

```py
drug_dataset = drug_dataset.rename_column(
    original_column_name="Unnamed: 0", new_column_name="patient_id"
)
drug_dataset
```

```python out
DatasetDict({
    train: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],
        num_rows: 161297
    })
    test: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],
        num_rows: 53766
    })
})
```

<Tip>

âœï¸ **è¯•è¯•çœ‹ï¼** ä½¿ç”¨ `Dataset.unique()` å‡½æ•°æŸ¥æ‰¾è®­ç»ƒå’Œæµ‹è¯•é›†ä¸­æ»¡è¶³æŸä¸ªæ¡ä»¶çš„è¯ç‰©ç»è¿‡å»é‡ä¹‹åçš„æ•°é‡ã€‚

</Tip>

æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬ä½¿ç”¨ **Dataset.map()**æ ‡å‡†åŒ–æ‰€æœ‰ **condition** æ ‡ç­¾ .æ­£å¦‚æˆ‘ä»¬åœ¨[ç¬¬ä¸‰ç« ](/course/chapter3)ä¸­æ‰€åšçš„é‚£æ ·ï¼Œæˆ‘ä»¬å¯ä»¥å®šä¹‰ä¸€ä¸ªç®€å•çš„å‡½æ•°ï¼Œå¯ä»¥å°†è¯¥å‡½æ•°åº”ç”¨äº**drug_dataset** æ‹†åˆ†åæ¯éƒ¨åˆ†çš„æ‰€æœ‰è¡Œï¼š

```py
def lowercase_condition(example):
    return {"condition": example["condition"].lower()}


drug_dataset.map(lowercase_condition)
```

```python out
AttributeError: 'NoneType' object has no attribute 'lower'
```

å“¦ä¸ï¼Œæˆ‘ä»¬çš„mapåŠŸèƒ½é‡åˆ°äº†é—®é¢˜ï¼ä»é”™è¯¯ä¸­æˆ‘ä»¬å¯ä»¥æ¨æ–­å‡º **condition** åˆ—å­˜åœ¨ **None** , ä¸èƒ½è½¬æ¢ä¸ºå°å†™ï¼Œå› ä¸ºå®ƒä»¬ä¸æ˜¯å­—ç¬¦ä¸²ã€‚è®©æˆ‘ä»¬ä½¿ç”¨ **Dataset.filter()** åˆ é™¤è¿™äº›è¡Œ ï¼Œå…¶å·¥ä½œæ–¹å¼ç±»ä¼¼äº **Dataset.map()** ã€‚ä¾‹å¦‚ï¼š

```py
def filter_nones(x):
    return x["condition"] is not None
```

ç„¶åè¿è¡Œ **drug_dataset.filter(filter_nones)** ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ä¸€è¡Œä¸­ä½¿ç”¨lambda å‡½æ•°.åœ¨ Python ä¸­ï¼Œlambda å‡½æ•°æ˜¯æ‚¨æ— éœ€æ˜ç¡®å‘½åå³å¯ä½¿ç”¨çš„å¾®å‡½æ•°ï¼ˆåŒ¿åå‡½æ•°ï¼‰ã€‚å®ƒä»¬ä¸€èˆ¬é‡‡ç”¨å¦‚ä¸‹å½¢å¼ï¼š

```
lambda <arguments> : <expression>
```

å…¶ä¸­**lambda** æ˜¯ Python çš„ç‰¹æ®Š[å…³é”®å­—](https://docs.python.org/3/reference/lexical_analysis.html#keywords), **arguments** æ˜¯ä»¥é€—å·è¿›è¡Œåˆ†éš”çš„å‡½æ•°è¾“å…¥çš„åˆ—è¡¨/é›†åˆï¼Œ **expression** ä»£è¡¨æ‚¨å¸Œæœ›æ‰§è¡Œçš„æ“ä½œã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥å®šä¹‰ä¸€ä¸ªç®€å•çš„ lambda å‡½æ•°æ¥å¯¹ä¸€ä¸ªæ•°å­—è¿›è¡Œå¹³æ–¹ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```
lambda x : x * x
```

æˆ‘ä»¬éœ€è¦å°†è¦è¾“å…¥ç»™è¿™ä¸ªå‡½æ•°å€¼æ‹¬åœ¨æ‹¬å·ä¸­ï¼š

```py
(lambda x: x * x)(3)
```

```python out
9
```

ç±»ä¼¼åœ°ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ç”¨é€—å·åˆ†éš”å¤šä¸ªå‚æ•°æ¥å®šä¹‰ lambda å‡½æ•°ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥æŒ‰å¦‚ä¸‹æ–¹å¼è®¡ç®—ä¸‰è§’å½¢çš„é¢ç§¯ï¼š

```py
(lambda base, height: 0.5 * base * height)(4, 8)
```

```python out
16.0
```

å½“æ‚¨æƒ³å®šä¹‰å°å‹ã€ä¸€æ¬¡æ€§ä½¿ç”¨çš„å‡½æ•°æ—¶ï¼ŒLambda å‡½æ•°éå¸¸æ–¹ä¾¿ï¼ˆæœ‰å…³å®ƒä»¬çš„æ›´å¤šä¿¡æ¯ï¼Œæˆ‘ä»¬å»ºè®®é˜…è¯»å®‰å¾·çƒˆÂ·å¸ƒå°”é«˜å†™çš„[çœŸæ­£çš„Pythonæ•™ç¨‹](https://realpython.com/python-lambda/)ï¼‰ã€‚åœ¨ğŸ¤— Datasets ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ lambda å‡½æ•°æ¥å®šä¹‰ç®€å•çš„æ˜ å°„å’Œè¿‡æ»¤æ“ä½œï¼Œæ‰€ä»¥è®©æˆ‘ä»¬ä½¿ç”¨è¿™ä¸ªæŠ€å·§æ¥æ¶ˆé™¤æˆ‘ä»¬æ•°æ®é›†ä¸­çš„ **None** æ¡ç›®ï¼š

```py
drug_dataset = drug_dataset.filter(lambda x: x["condition"] is not None)
```

å½“ **None** æ¡ç›®å·²åˆ é™¤ï¼Œæˆ‘ä»¬å¯ä»¥æ ‡å‡†åŒ–æˆ‘ä»¬çš„ **condition** åˆ—ï¼š

```py
drug_dataset = drug_dataset.map(lowercase_condition)
# Check that lowercasing worked
drug_dataset["train"]["condition"][:3]
```

```python out
['left ventricular dysfunction', 'adhd', 'birth control']
```

æœ‰ç”¨ï¼ç°åœ¨æˆ‘ä»¬å·²ç»æ¸…ç†äº†æ ‡ç­¾ï¼Œè®©æˆ‘ä»¬æ¥çœ‹çœ‹æ¸…æ´—åçš„è¯„è®ºæ–‡æœ¬ã€‚

## Creating new columns

æ¯å½“æ‚¨å¤„ç†å®¢æˆ·è¯„è®ºæ—¶ï¼Œä¸€ä¸ªå¥½çš„åšæ³•æ˜¯æ£€æŸ¥æ¯ä¸ªè¯„è®ºä¸­çš„å­—æ•°ã€‚è¯„è®ºå¯èƒ½åªæ˜¯ä¸€ä¸ªè¯ï¼Œæ¯”å¦‚â€œå¤ªæ£’äº†ï¼â€æˆ–åŒ…å«æ•°åƒå­—çš„å®Œæ•´æ–‡ç« ï¼Œæ ¹æ®å®é™…çš„æƒ…å†µï¼Œæ‚¨éœ€è¦ä»¥ä¸åŒçš„æ–¹å¼å¤„ç†è¿™äº›æç«¯æƒ…å†µã€‚ä¸ºäº†è®¡ç®—æ¯æ¡è¯„è®ºä¸­çš„å•è¯æ•°ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨åŸºäºç©ºæ ¼åˆ†å‰²æ¯ä¸ªæ–‡æœ¬çš„ç²—ç•¥æ–¹æ³•ã€‚

è®©æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªç®€å•çš„å‡½æ•°æ¥è®¡ç®—æ¯æ¡è¯„è®ºä¸­çš„å•è¯æ•°ï¼š

```py
def compute_review_length(example):
    return {"review_length": len(example["review"].split())}
```

ä¸æˆ‘ä»¬çš„ `lowercase_condition()` å‡½æ•°ä¸åŒï¼Œ`compute_review_length()` è¿”å›ä¸€ä¸ªå­—å…¸ï¼Œå…¶é”®ä¸æ•°æ®é›†ä¸­çš„åˆ—åä¹‹ä¸€ä¸å¯¹åº”ã€‚ åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå½“ `compute_review_length()` ä¼ é€’ç»™ `Dataset.map()` æ—¶ï¼Œå®ƒå°†åº”ç”¨äºæ•°æ®é›†ä¸­çš„æ‰€æœ‰è¡Œä»¥åˆ›å»ºæ–°çš„ `review_length` åˆ—ï¼š

```py
drug_dataset = drug_dataset.map(compute_review_length)
# Inspect the first training example
drug_dataset["train"][0]
```

```python out
{'patient_id': 206461,
 'drugName': 'Valsartan',
 'condition': 'left ventricular dysfunction',
 'review': '"It has no side effect, I take it in combination of Bystolic 5 Mg and Fish Oil"',
 'rating': 9.0,
 'date': 'May 20, 2012',
 'usefulCount': 27,
 'review_length': 17}
```

æ­£å¦‚é¢„æœŸçš„é‚£æ ·ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä¸€ä¸ª **review_length** åˆ—å·²æ·»åŠ åˆ°æˆ‘ä»¬çš„è®­ç»ƒé›†ä¸­ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ **Dataset.sort()**å¯¹è¿™ä¸ªæ–°åˆ—è¿›è¡Œæ’åºï¼Œç„¶åæŸ¥çœ‹æç«¯é•¿åº¦çš„è¯„è®ºçš„æ ·å­ï¼š

```py
drug_dataset["train"].sort("review_length")[:3]
```

```python out
{'patient_id': [103488, 23627, 20558],
 'drugName': ['Loestrin 21 1 / 20', 'Chlorzoxazone', 'Nucynta'],
 'condition': ['birth control', 'muscle spasm', 'pain'],
 'review': ['"Excellent."', '"useless"', '"ok"'],
 'rating': [10.0, 1.0, 6.0],
 'date': ['November 4, 2008', 'March 24, 2017', 'August 20, 2016'],
 'usefulCount': [5, 2, 10],
 'review_length': [1, 1, 1]}
```

æ­£å¦‚æˆ‘ä»¬æ‰€çŒœæƒ³çš„é‚£æ ·ï¼Œä¸€äº›è¯„è®ºåªåŒ…å«ä¸€ä¸ªè¯ï¼Œè™½ç„¶è¿™å¯¹äºæƒ…æ„Ÿåˆ†ææ¥è¯´å¯èƒ½æ²¡é—®é¢˜ï¼Œä½†å¦‚æœæˆ‘ä»¬æƒ³è¦é¢„æµ‹ç—…æƒ…ï¼Œè¿™äº›è¯„è®ºå¯èƒ½å¹¶ä¸é€‚åˆã€‚

<Tip>

ğŸ™‹å‘æ•°æ®é›†æ·»åŠ æ–°åˆ—çš„å¦ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨å‡½æ•°Dataset.add_column() ã€‚è¿™å…è®¸æ‚¨è¾“å…¥Python åˆ—è¡¨æˆ– NumPyï¼Œåœ¨ä¸é€‚åˆä½¿ç”¨Dataset.map()æƒ…å†µä¸‹å¯ä»¥å¾ˆæ–¹ä¾¿ã€‚

</Tip>

è®©æˆ‘ä»¬ä½¿ç”¨ **Dataset.filter()** åŠŸèƒ½æ¥åˆ é™¤åŒ…å«å°‘äº 30 ä¸ªå•è¯çš„è¯„è®ºã€‚ä¸æˆ‘ä»¬å¯¹ **condition** åˆ—çš„å¤„ç†ç›¸ä¼¼ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡é€‰å–è¯„è®ºçš„é•¿åº¦é«˜äºæ­¤é˜ˆå€¼æ¥è¿‡æ»¤æ‰éå¸¸çŸ­çš„è¯„è®ºï¼š

```py
drug_dataset = drug_dataset.filter(lambda x: x["review_length"] > 30)
print(drug_dataset.num_rows)
```

```python out
{'train': 138514, 'test': 46108}
```

å¦‚æ‚¨æ‰€è§ï¼Œè¿™å·²ç»ä»æˆ‘ä»¬çš„åŸå§‹è®­ç»ƒå’Œæµ‹è¯•é›†ä¸­åˆ é™¤äº†å¤§çº¦ 15% çš„è¯„è®ºã€‚

<Tip>

âœï¸ è¯•è¯•çœ‹ï¼ä½¿ç”¨ Dataset.sort() å‡½æ•°æŸ¥çœ‹å•è¯æ•°æœ€å¤šçš„è¯„è®ºã€‚è¯·å‚é˜…æ–‡æ¡£ä»¥äº†è§£æ‚¨éœ€è¦ä½¿ç”¨å“ªä¸ªå‚æ•°æŒ‰é•¿åº¦é™åºå¯¹è¯„è®ºè¿›è¡Œæ’åºã€‚

</Tip>

æˆ‘ä»¬éœ€è¦å¤„ç†çš„æœ€åä¸€ä»¶äº‹æ˜¯è¯„è®ºä¸­æ˜¯å¦å­˜åœ¨ HTML å­—ç¬¦ä»£ç ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ Python çš„**html**æ¨¡å—å–æ¶ˆè¿™äº›å­—ç¬¦çš„è½¬ä¹‰ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```py
import html

text = "I&#039;m a transformer called BERT"
html.unescape(text)
```

```python out
"I'm a transformer called BERT"
```

æˆ‘ä»¬å°†ä½¿ç”¨ **Dataset.map()** å¯¹æˆ‘ä»¬è¯­æ–™åº“ä¸­çš„æ‰€æœ‰ HTML å­—ç¬¦è¿›è¡Œè½¬ä¹‰ï¼š

```python
drug_dataset = drug_dataset.map(lambda x: {"review": html.unescape(x["review"])})
```

å¦‚æ‚¨æ‰€è§ï¼Œ **Dataset.map()** æ–¹æ³•å¯¹äºå¤„ç†æ•°æ®éå¸¸æœ‰ç”¨â€”â€”åœ¨ç¤ºä¾‹ä¸­ä»…ä»…æ˜¯æµ…å°è¾„æ­¢å°±æœ‰å¾ˆå¤§çš„æ”¶è·ï¼

## map() æ–¹æ³•çš„è¶…çº§åŠ é€Ÿ

**Dataset.map()** æ–¹æ³•æœ‰ä¸€ä¸ª **batched** å‚æ•°ï¼Œå¦‚æœè®¾ç½®ä¸º **True** , map å‡½æ•°å°†ä¼šåˆ†æ‰¹æ‰§è¡Œæ‰€éœ€è¦è¿›è¡Œçš„æ“ä½œï¼ˆæ‰¹é‡å¤§å°æ˜¯å¯é…ç½®çš„ï¼Œä½†é»˜è®¤ä¸º 1,000ï¼‰ã€‚ä¾‹å¦‚ï¼Œä¹‹å‰å¯¹æ‰€æœ‰ HTML è¿›è¡Œè½¬ä¹‰çš„ map å‡½æ•°è¿è¡Œéœ€è¦ä¸€äº›æ—¶é—´ï¼ˆæ‚¨å¯ä»¥ä»è¿›åº¦æ¡ä¸­è¯»å–æ‰€ç”¨æ—¶é—´ï¼‰ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ä½¿ç”¨åˆ—è¡¨æ¨å¯¼åŒæ—¶å¤„ç†å¤šä¸ªå…ƒç´ æ¥åŠ å¿«é€Ÿåº¦ã€‚

å½“æ‚¨åœ¨ä½¿ç”¨ **Dataset.map()**å‡½æ•°æ—¶æŒ‡å®š **batched=True**ã€‚è¯¥å‡½æ•°ä¼šæ¥æ”¶ä¸€ä¸ªåŒ…å«æ•°æ®é›†å­—æ®µçš„å­—å…¸ï¼Œæ¯ä¸ªå€¼éƒ½æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œè€Œä¸ä»…ä»…æ˜¯å•ä¸ªå€¼ã€‚**Dataset.map()** çš„è¿”å›å€¼åº”è¯¥æ˜¯ç›¸åŒçš„ï¼šä¸€ä¸ªåŒ…å«æˆ‘ä»¬æƒ³è¦æ›´æ–°æˆ–æ·»åŠ åˆ°æ•°æ®é›†ä¸­çš„å­—æ®µçš„å­—å…¸ï¼Œå­—å…¸çš„é”®æ˜¯è¦æ·»åŠ çš„å­—æ®µï¼Œå­—å…¸çš„å€¼æ˜¯ç»“æœçš„åˆ—è¡¨ã€‚ä¾‹å¦‚ï¼Œè¿™æ˜¯ä½¿ç”¨ **batched=True**å¯¹æ‰€æœ‰ HTML å­—ç¬¦è¿›è¡Œè½¬ä¹‰çš„æ–¹æ³• ï¼š

```python
new_drug_dataset = drug_dataset.map(
    lambda x: {"review": [html.unescape(o) for o in x["review"]]}, batched=True
)
```

å¦‚æœæ‚¨åœ¨ç¬”è®°æœ¬ä¸­è¿è¡Œæ­¤ä»£ç ï¼Œæ‚¨ä¼šçœ‹åˆ°æ­¤å‘½ä»¤çš„æ‰§è¡Œé€Ÿåº¦æ¯”å‰ä¸€ä¸ªå‘½ä»¤å¿«å¾—å¤šã€‚è¿™ä¸æ˜¯å› ä¸ºæˆ‘ä»¬çš„è¯„è®ºå·²ç»æ˜¯å¤„ç†è¿‡çš„â€”â€”å¦‚æœä½ é‡æ–°æ‰§è¡Œä¸Šä¸€èŠ‚çš„æŒ‡ä»¤ï¼ˆæ²¡æœ‰ **batched=True** )ï¼Œå®ƒå°†èŠ±è´¹ä¸ä»¥å‰ç›¸åŒçš„æ—¶é—´ã€‚è¿™æ˜¯å› ä¸ºåˆ—è¡¨æ¨å¯¼å¼é€šå¸¸æ¯”åœ¨åŒä¸€ä»£ç ä¸­ç”¨ **for** å¾ªç¯æ‰§è¡Œç›¸åŒçš„ä»£ç æ›´å¿«ï¼Œå¹¶ä¸”æˆ‘ä»¬è¿˜é€šè¿‡åŒæ—¶è®¿é—®å¤šä¸ªå…ƒç´ è€Œä¸æ˜¯ä¸€ä¸ªä¸€ä¸ªæ¥å¤„ç†æ¥æé«˜å¤„ç†çš„é€Ÿåº¦ã€‚

åœ¨[ç¬¬å…­ç« ](/course/chapter6)æˆ‘ä»¬å°†é‡åˆ°çš„â€œå¿«é€Ÿâ€æ ‡è®°å™¨ï¼Œå®ƒå¯ä»¥å¿«é€Ÿæ ‡è®°å¤§æ–‡æœ¬åˆ—è¡¨ã€‚ä½¿ç”¨ **Dataset.map()** å’Œ **batched=True** æ˜¯åŠ é€Ÿçš„å…³é”®ã€‚ä¾‹å¦‚ï¼Œè¦ä½¿ç”¨å¿«é€Ÿæ ‡è®°å™¨æ ‡è®°æ‰€æœ‰è¯ç‰©è¯„è®ºï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¿™æ ·çš„å‡½æ•°ï¼š

```python
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")


def tokenize_function(examples):
    return tokenizer(examples["review"], truncation=True)
```

æ­£å¦‚ä½ åœ¨[ç¬¬ä¸‰ç« ](/course/chapter3)æ‰€çœ‹åˆ°çš„ï¼Œæˆ‘ä»¬åŸæœ¬å°±å¯ä»¥å°†ä¸€ä¸ªæˆ–å¤šä¸ªç¤ºä¾‹ä¼ é€’ç»™åˆ†è¯å™¨ï¼Œå› æ­¤åœ¨**batched=True**æ˜¯ä¸€ä¸ªéå¿…é¡»çš„é€‰é¡¹.è®©æˆ‘ä»¬å€Ÿæ­¤æœºä¼šæ¯”è¾ƒä¸åŒé€‰é¡¹çš„æ€§èƒ½ã€‚åœ¨ç¬”è®°æœ¬ä¸­ï¼Œæ‚¨å¯ä»¥åœ¨æ‚¨è¦æµ‹é‡çš„ä»£ç è¡Œä¹‹å‰æ·»åŠ  **%time**æ¥æµ‹è¯•æ”¹è¡Œè¿è¡Œæ‰€æ¶ˆè€—çš„æ—¶é—´ï¼š

```python no-format
%time tokenized_dataset = drug_dataset.map(tokenize_function, batched=True)
```

æ‚¨è¿˜å¯ä»¥é€šè¿‡å°†æ•´ä¸ªå•å…ƒæ ¼è®¡æ—¶ **%%time** åœ¨å•å…ƒæ ¼çš„å¼€å¤´ã€‚åœ¨æˆ‘ä»¬æ‰§è¡Œæ­¤æ“ä½œçš„ç¡¬ä»¶ä¸Šï¼Œè¯¥æŒ‡ä»¤æ˜¾ç¤º 10.8 ç§’ï¼ˆè¿™æ˜¯å†™åœ¨â€œWall timeâ€ä¹‹åçš„æ•°å­—ï¼‰ã€‚

<Tip>

âœï¸ **è¯•è¯•çœ‹ï¼** ä½¿ç”¨å’Œä¸ä½¿ç”¨ `batched=True` æ‰§è¡Œç›¸åŒçš„æŒ‡ä»¤ï¼Œç„¶åä½¿ç”¨æ…¢é€Ÿæ ‡è®°å™¨å°è¯•ï¼ˆåœ¨ `AutoTokenizer.from_pretrained()` æ–¹æ³•ä¸­æ·»åŠ  `use_fast=False`ï¼‰ï¼Œè¿™æ ·ä½ å°±å¯ä»¥çœ‹çœ‹åœ¨ä½ çš„ç”µè„‘ä¸Šå®ƒéœ€è¦å¤šé•¿çš„æ—¶é—´ã€‚

</Tip>

ä»¥ä¸‹æ˜¯æˆ‘ä»¬åœ¨ä½¿ç”¨å’Œä¸ä½¿ç”¨æ‰¹å¤„ç†æ—¶ä½¿ç”¨å¿«é€Ÿå’Œæ…¢é€Ÿåˆ†è¯å™¨è·å¾—çš„ç»“æœï¼š

Options         | Fast tokenizer | Slow tokenizer
:--------------:|:--------------:|:-------------:
`batched=True`  | 10.8s          | 4min41s
`batched=False` | 59.2s          | 5min3s

è¿™æ„å‘³ç€ä½¿ç”¨å¸¦æœ‰ **batched=True** é€‰é¡¹æ¯”æ²¡æœ‰æ‰¹å¤„ç†çš„æ…¢é€‰é¡¹å¿« 30 å€â€”â€”è¿™çœŸæ˜¯å¤ªæ£’äº†ï¼è¿™å°±æ˜¯ä¸ºä»€ä¹ˆ**AutoTokenizer** çš„é»˜è®¤è®¾ç½®æ˜¯**use_fast=True**çš„ä¸»è¦åŸå›  ï¼ˆä»¥åŠä¸ºä»€ä¹ˆå®ƒä»¬è¢«ç§°ä¸ºâ€œå¿«é€Ÿâ€ï¼‰ã€‚ä»–ä»¬èƒ½å¤Ÿå®ç°è¿™æ ·çš„åŠ é€Ÿï¼Œå› ä¸ºåœ¨åº•å±‚çš„æ ‡è®°åŒ–ä»£ç æ˜¯åœ¨ Rust ä¸­æ‰§è¡Œçš„ï¼ŒRust æ˜¯ä¸€ç§å¯ä»¥è½»æ¾å¹¶è¡ŒåŒ–æ‰§è¡Œçš„è¯­è¨€ã€‚

å¹¶è¡ŒåŒ–ä¹Ÿæ˜¯å¿«é€Ÿæ ‡è®°å™¨é€šè¿‡æ‰¹å¤„ç†å®ç°è¿‘ 6 å€åŠ é€Ÿçš„åŸå› ï¼šå•ä¸ªæ ‡è®°åŒ–æ“ä½œæ˜¯ä¸èƒ½å¹¶è¡Œçš„ï¼Œä½†æ˜¯å½“æ‚¨æƒ³åŒæ—¶æ ‡è®°å¤§é‡æ–‡æœ¬æ—¶ï¼Œæ‚¨å¯ä»¥å°†æ‰§è¡Œæ‹†åˆ†ä¸ºå¤šä¸ªè¿›ç¨‹ï¼Œæ¯ä¸ªè¿›ç¨‹éƒ½å¯¹è‡ªå·±çš„æ–‡æœ¬è´Ÿè´£ã€‚

**Dataset.map()** ä¹Ÿæœ‰ä¸€äº›è‡ªå·±çš„å¹¶è¡ŒåŒ–èƒ½åŠ›ã€‚ç”±äºå®ƒä»¬ä¸å— Rust çš„æ”¯æŒï¼Œå› æ­¤æ…¢é€Ÿåˆ†è¯å™¨çš„é€Ÿåº¦èµ¶ä¸ä¸Šå¿«é€Ÿåˆ†è¯å™¨ï¼Œä½†å®ƒä»¬ä»ç„¶ä¼šæ›´å¿«ä¸€äº›ï¼ˆå°¤å…¶æ˜¯å½“æ‚¨ä½¿ç”¨æ²¡æœ‰å¿«é€Ÿç‰ˆæœ¬çš„åˆ†è¯å™¨æ—¶ï¼‰ã€‚è¦å¯ç”¨å¤šå¤„ç†ï¼Œè¯·åœ¨**Dataset.map()**æ—¶ä½¿ç”¨ **num_proc** å‚æ•°å¹¶æŒ‡å®šè¦åœ¨è°ƒç”¨ä¸­ä½¿ç”¨çš„è¿›ç¨‹æ•° ï¼š

```py
slow_tokenizer = AutoTokenizer.from_pretrained("bert-base-cased", use_fast=False)


def slow_tokenize_function(examples):
    return slow_tokenizer(examples["review"], truncation=True)


tokenized_dataset = drug_dataset.map(slow_tokenize_function, batched=True, num_proc=8)
```

æ‚¨å¯ä»¥å¯¹å¤„ç†çš„æ—¶é—´è¿›è¡Œä¸€äº›è¯•éªŒï¼Œä»¥ç¡®å®šè¦ä½¿ç”¨çš„æœ€ä½³è¿›ç¨‹æ•°ï¼›åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œ8 ä¼¼ä¹äº§ç”Ÿäº†æœ€å¥½çš„é€Ÿåº¦å¢ç›Šã€‚ä»¥ä¸‹æ˜¯æˆ‘ä»¬åœ¨ä½¿ç”¨å’Œä¸ä½¿ç”¨å¤šå¤„ç†æ—¶æ‰€éœ€è¦çš„æ—¶é—´ï¼š

Options         | Fast tokenizer | Slow tokenizer
:--------------:|:--------------:|:-------------:
`batched=True`  | 10.8s          | 4min41s
`batched=False` | 59.2s          | 5min3s
`batched=True`, `num_proc=8`  | 6.52s          | 41.3s
`batched=False`, `num_proc=8` | 9.49s          | 45.2s

å¯¹äºæ…¢é€Ÿåˆ†è¯å™¨æ¥è¯´ï¼Œè¿™äº›ç»“æœè¦åˆç†å¾—å¤šï¼Œä½†å¿«é€Ÿåˆ†è¯å™¨çš„æ€§èƒ½ä¹Ÿå¾—åˆ°äº†æ˜¾ç€æé«˜ã€‚ä½†æ˜¯è¯·æ³¨æ„ï¼Œæƒ…å†µå¹¶éæ€»æ˜¯å¦‚æ­¤â€”â€”é™¤äº† **num_proc=8**ï¼Œæˆ‘ä»¬çš„æµ‹è¯•è¡¨æ˜ï¼Œä½¿ç”¨**batched=True**è€Œä¸å¸¦æœ‰**num_proc**å‚æ•°çš„é€‰é¡¹å¤„ç†èµ·æ¥æ›´å¿«ã€‚é€šå¸¸ï¼Œæˆ‘ä»¬ä¸å»ºè®®å°† Python å¤šçº¿ç¨‹å¤„ç†ç”¨äºå…·æœ‰**batched=True**åŠŸèƒ½çš„å¿«é€Ÿæ ‡è®°å™¨  .

<Tip>

ä½¿ç”¨num_procä»¥åŠ å¿«å¤„ç†é€Ÿåº¦é€šå¸¸æ˜¯ä¸€ä¸ªå¥½ä¸»æ„ï¼Œåªè¦æ‚¨ä½¿ç”¨çš„å‡½æ•°è¿˜æ²¡æœ‰è‡ªå·±å¸¦æœ‰çš„è¿›è¡ŒæŸç§å¤šè¿›ç¨‹å¤„ç†çš„æ–¹æ³•ã€‚

</Tip>

å°†æ‰€æœ‰è¿™äº›åŠŸèƒ½æµ“ç¼©åˆ°ä¸€ä¸ªæ–¹æ³•ä¸­å·²ç»éå¸¸äº†ä¸èµ·ï¼Œä½†è¿˜æœ‰æ›´å¤šï¼ä½¿ç”¨ **Dataset.map()** å’Œ **batched=True** æ‚¨å¯ä»¥æ›´æ”¹æ•°æ®é›†ä¸­çš„å…ƒç´ æ•°é‡ã€‚å½“ä½ æƒ³ä»ä¸€ä¸ªä¾‹å­ä¸­åˆ›å»ºå‡ ä¸ªè®­ç»ƒç‰¹å¾æ—¶ï¼Œè¿™æ˜¯éå¸¸æœ‰ç”¨çš„ã€‚æˆ‘ä»¬å°†åœ¨[ç¬¬ä¸ƒç« ](/course/chapter7).ä¸­è¿›è¡Œçš„å‡ ä¸ªNLPä»»åŠ¡çš„é¢„å¤„ç†ä¸­ä½¿ç”¨åˆ°è¿™ä¸ªåŠŸèƒ½ï¼Œå®ƒéå¸¸ä¾¿åˆ©ã€‚

<Tip>

ğŸ’¡åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œä¸€ä¸ªä¾‹å­é€šå¸¸å¯ä»¥ä¸ºæˆ‘ä»¬çš„æ¨¡å‹æä¾›ä¸€ç»„ç‰¹å¾ã€‚åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œè¿™äº›ç‰¹å¾ä¼šå‚¨å­˜åœ¨æ•°æ®é›†çš„å‡ ä¸ªåˆ—ï¼Œä½†åœ¨å…¶ä»–æƒ…å†µä¸‹ï¼ˆä¾‹å¦‚æ­¤å¤„çš„ä¾‹å­å’Œç”¨äºé—®ç­”çš„æ•°æ®ï¼‰ï¼Œå¯ä»¥ä»å•ä¸ªç¤ºä¾‹çš„ä¸€åˆ—ä¸­æå–å¤šä¸ªç‰¹å¾

</Tip>

è®©æˆ‘ä»¬æ¥çœ‹çœ‹å®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†æ ‡è®°åŒ–æˆ‘ä»¬çš„ç¤ºä¾‹å¹¶å°†æœ€å¤§æˆªæ–­é•¿åº¦è®¾ç½®128ï¼Œä½†æˆ‘ä»¬å°†è¦æ±‚æ ‡è®°å™¨è¿”å›å…¨éƒ¨æ–‡æœ¬å—ï¼Œè€Œä¸ä»…ä»…æ˜¯ç¬¬ä¸€ä¸ªã€‚è¿™å¯ä»¥ç”¨ **return_overflowing_tokens=True** ï¼š

```py
def tokenize_and_split(examples):
    return tokenizer(
        examples["review"],
        truncation=True,
        max_length=128,
        return_overflowing_tokens=True,
    )
```

åœ¨ä½¿ç”¨**Dataset.map()** æ­£å¼åœ¨æ•´ä¸ªæ•°æ®é›†ä¸Šå¼€å§‹å¤„ç†ä¹‹å‰è®©æˆ‘ä»¬å…ˆåœ¨ä¸€ä¸ªä¾‹å­ä¸Šæµ‹è¯•ä¸€ä¸‹ï¼š

```py
result = tokenize_and_split(drug_dataset["train"][0])
[len(inp) for inp in result["input_ids"]]
```

```python out
[128, 49]
```

ç§ï¼æˆ‘ä»¬åœ¨è®­ç»ƒé›†ä¸­çš„ç¬¬ä¸€ä¸ªç¤ºä¾‹å˜æˆäº†ä¸¤ä¸ªç‰¹å¾ï¼Œå› ä¸ºå®ƒè¢«æ ‡è®°ä¸ºè¶…è¿‡æˆ‘ä»¬æŒ‡å®šçš„æœ€å¤§æˆªæ–­é•¿åº¦ï¼Œå› æ­¤ç»“æœè¢«æˆªæˆäº†ä¸¤æ®µï¼šç¬¬ä¸€æ®µé•¿åº¦ä¸º 128 ï¼Œç¬¬äºŒæ®µé•¿åº¦ä¸º 49 ã€‚ç°åœ¨è®©æˆ‘ä»¬å¯¹æ‰€æœ‰å…ƒç´ æ‰§è¡Œæ­¤æ“ä½œæ•°æ®é›†ï¼

```py
tokenized_dataset = drug_dataset.map(tokenize_and_split, batched=True)
```

```python out
ArrowInvalid: Column 1 named condition expected length 1463 but got length 1000
```

ä¸å¥½äº†ï¼å®ƒæ²¡æœ‰èµ·ä½œç”¨ï¼ä¸ºä»€ä¹ˆå‘¢ï¼ŸæŸ¥çœ‹é”™è¯¯æ¶ˆæ¯ä¼šç»™æˆ‘ä»¬ä¸€ä¸ªçº¿ç´¢ï¼šåˆ—çš„é•¿åº¦ä¸åŒ¹é…ï¼Œä¸€åˆ—é•¿åº¦ä¸º 1,463ï¼Œå¦ä¸€åˆ—é•¿åº¦ä¸º 1,000ã€‚1,000è¡Œçš„"review"ç»™å‡ºäº† 1,463 è¡Œçš„æ–°ç‰¹å¾ï¼Œå¯¼è‡´å’ŒåŸæœ¬çš„1000è¡Œæ•°æ®ä¸åŒ¹é…ã€‚

é—®é¢˜å‡ºåœ¨æˆ‘ä»¬è¯•å›¾æ··åˆä¸¤ä¸ªä¸åŒå¤§å°çš„ä¸åŒæ•°æ®é›†ï¼š **drug_dataset** åˆ—å°†æœ‰ä¸€å®šæ•°é‡çš„å…ƒç´ ï¼ˆæˆ‘ä»¬é”™è¯¯ä¸­çš„ 1,000ï¼‰ï¼Œä½†æ˜¯æˆ‘ä»¬æ­£åœ¨æ„å»º**tokenized_dataset** å°†æœ‰æ›´å¤šçš„å…ƒç´ ï¼ˆé”™è¯¯æ¶ˆæ¯ä¸­çš„ 1,463ï¼‰ã€‚è¿™ä¸é€‚ç”¨äº **Dataset** ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦ä»æ—§æ•°æ®é›†ä¸­åˆ é™¤åˆ—æˆ–ä½¿å®ƒä»¬çš„å¤§å°ä¸æ–°æ•°æ®é›†ä¸­çš„å¤§å°ç›¸åŒã€‚æˆ‘ä»¬å¯ä»¥ç”¨ **remove_columns** å‚æ•°ï¼š

```py
tokenized_dataset = drug_dataset.map(
    tokenize_and_split, batched=True, remove_columns=drug_dataset["train"].column_names
)
```

ç°åœ¨è¿™ä¸ªè¿‡ç¨‹æ²¡æœ‰é”™è¯¯ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡æ¯”è¾ƒé•¿åº¦æ¥æ£€æŸ¥æ–°æ•°æ®é›†çš„å…ƒç´ æ˜¯å¦æ¯”åŸå§‹æ•°æ®é›†å¤šå¾—å¤šï¼š

```py
len(tokenized_dataset["train"]), len(drug_dataset["train"])
```

```python out
(206772, 138514)
```

æˆ‘ä»¬æåˆ°æˆ‘ä»¬è¿˜å¯ä»¥é€šè¿‡ä½¿æ—§åˆ—ä¸æ–°åˆ—çš„å¤§å°ç›¸åŒæ¥å¤„ç†é•¿åº¦ä¸åŒ¹é…çš„é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ **overflow_to_sample_mapping** å­—æ®µï¼Œå½“æˆ‘ä»¬è®¾ç½®**return_overflowing_tokens=True** .å®ƒä¸ºæˆ‘ä»¬æä¾›äº†ç‰¹å¾åˆ°å®ƒæ‰€äº§ç”Ÿçš„æ ·æœ¬çš„æ˜ å°„ã€‚ä½¿ç”¨è¿™ä¸ªï¼Œæˆ‘ä»¬å¯ä»¥å°†åŸå§‹æ•°æ®é›†ä¸­çš„æ¯ä¸ªé”®å…³è”åˆ°ä¸€ä¸ªåˆé€‚å¤§å°çš„å€¼åˆ—è¡¨ä¸­ï¼Œé€šè¿‡éå†æ‰€æœ‰çš„æ•°æ®æ¥ç”Ÿæˆæ–°ç‰¹æ€§:

```py
def tokenize_and_split(examples):
    result = tokenizer(
        examples["review"],
        truncation=True,
        max_length=128,
        return_overflowing_tokens=True,
    )
    # Extract mapping between new and old indices
    sample_map = result.pop("overflow_to_sample_mapping")
    for key, values in examples.items():
        result[key] = [values[i] for i in sample_map]
    return result
```

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨**Dataset.map()**æ¥è¿›è¡Œæ‰¹å¤„ç†ï¼Œè¿™æ ·æ— éœ€æˆ‘ä»¬åˆ é™¤æ—§åˆ—ï¼š

```py
tokenized_dataset = drug_dataset.map(tokenize_and_split, batched=True)
tokenized_dataset
```

```python out
DatasetDict({
    train: Dataset({
        features: ['attention_mask', 'condition', 'date', 'drugName', 'input_ids', 'patient_id', 'rating', 'review', 'review_length', 'token_type_ids', 'usefulCount'],
        num_rows: 206772
    })
    test: Dataset({
        features: ['attention_mask', 'condition', 'date', 'drugName', 'input_ids', 'patient_id', 'rating', 'review', 'review_length', 'token_type_ids', 'usefulCount'],
        num_rows: 68876
    })
})
```

æˆ‘ä»¬è·å¾—äº†ä¸ä»¥å‰ç›¸åŒæ•°é‡çš„è®­ç»ƒç‰¹å¾ï¼Œä½†åœ¨è¿™é‡Œæˆ‘ä»¬ä¿ç•™äº†æ‰€æœ‰æ—§å­—æ®µã€‚å¦‚æœæ‚¨åœ¨ä½¿ç”¨æ¨¡å‹è®¡ç®—ä¹‹åéœ€è¦å®ƒä»¬è¿›è¡Œä¸€äº›åå¤„ç†ï¼Œæ‚¨å¯èƒ½éœ€è¦ä½¿ç”¨è¿™ç§æ–¹æ³•ã€‚

æ‚¨ç°åœ¨å·²ç»äº†è§£äº† ğŸ¤— Datasetså¦‚ä½•ä»¥å„ç§æ–¹å¼ç”¨äºé¢„å¤„ç†æ•°æ®é›†ã€‚è™½ç„¶ğŸ¤— Datasets çš„å¤„ç†åŠŸèƒ½ä¼šè¦†ç›–ä½ å¤§éƒ¨åˆ†çš„æ¨¡å‹è®­ç»ƒéœ€æ±‚ï¼Œæœ‰æ—¶æ‚¨å¯èƒ½éœ€è¦åˆ‡æ¢åˆ° Pandas ä»¥ä½¿ç”¨æ›´å¼ºå¤§çš„åŠŸèƒ½ï¼Œä¾‹å¦‚ **DataFrame.groupby()** æˆ–ç”¨äºå¯è§†åŒ–çš„é«˜çº§ APIã€‚å¹¸è¿çš„æ˜¯ï¼ŒğŸ¤— Datasetsæ—¨åœ¨ä¸ Pandasã€NumPyã€PyTorchã€TensorFlow å’Œ JAX ç­‰åº“å¯ä»¥ç›¸äº’è½¬æ¢ã€‚è®©æˆ‘ä»¬æ¥çœ‹çœ‹è¿™æ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚

## `ğŸ¤— Datasets å’Œ DataFrames çš„ç›¸äº’è½¬æ¢

<Youtube id="tfcY1067A5Q"/>

ä¸ºäº†å®ç°å„ç§ç¬¬ä¸‰æ–¹åº“ä¹‹é—´çš„è½¬æ¢ï¼ŒğŸ¤— Datasets æä¾›äº†ä¸€ä¸ª **Dataset.set_format()** åŠŸèƒ½ã€‚æ­¤åŠŸèƒ½å¯ä»¥é€šè¿‡ä»…æ›´æ”¹è¾“å‡ºæ ¼å¼çš„ï¼Œè½»æ¾åˆ‡æ¢åˆ°å¦ä¸€ç§æ ¼å¼ï¼Œè€Œä¸ä¼šå½±å“åº•å±‚æ•°æ®æ ¼å¼ï¼Œå³ Apache Arrowã€‚æ ¼å¼åŒ–ä¼šåœ¨æ•°æ®æœ¬èº«ä¸Šè¿›è¡Œã€‚ä¸ºäº†æ¼”ç¤ºï¼Œè®©æˆ‘ä»¬å°†æ•°æ®é›†è½¬æ¢ä¸º Pandasï¼š

```py
drug_dataset.set_format("pandas")
```

ç°åœ¨ï¼Œå½“æˆ‘ä»¬è®¿é—®æ•°æ®é›†çš„å…ƒç´ æ—¶ï¼Œæˆ‘ä»¬ä¼šå¾—åˆ°ä¸€ä¸ª **pandas.DataFrame** è€Œä¸æ˜¯å­—å…¸ï¼š

```py
drug_dataset["train"][:3]
```

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>patient_id</th>
      <th>drugName</th>
      <th>condition</th>
      <th>review</th>
      <th>rating</th>
      <th>date</th>
      <th>usefulCount</th>
      <th>review_length</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>95260</td>
      <td>Guanfacine</td>
      <td>adhd</td>
      <td>"My son is halfway through his fourth week of Intuniv..."</td>
      <td>8.0</td>
      <td>April 27, 2010</td>
      <td>192</td>
      <td>141</td>
    </tr>
    <tr>
      <th>1</th>
      <td>92703</td>
      <td>Lybrel</td>
      <td>birth control</td>
      <td>"I used to take another oral contraceptive, which had 21 pill cycle, and was very happy- very light periods, max 5 days, no other side effects..."</td>
      <td>5.0</td>
      <td>December 14, 2009</td>
      <td>17</td>
      <td>134</td>
    </tr>
    <tr>
      <th>2</th>
      <td>138000</td>
      <td>Ortho Evra</td>
      <td>birth control</td>
      <td>"This is my first time using any form of birth control..."</td>
      <td>8.0</td>
      <td>November 3, 2015</td>
      <td>10</td>
      <td>89</td>
    </tr>
  </tbody>
</table>

è®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ª **pandas.DataFrame** æ¥é€‰æ‹© **drug_dataset[train]** çš„æ‰€æœ‰å…ƒç´ ï¼š

```py
train_df = drug_dataset["train"][:]
```

<Tip>

ğŸš¨ åœ¨åº•å±‚ï¼Œ`Dataset.set_format()` æ”¹å˜äº†æ•°æ®é›†çš„ `__getitem__()` dunder æ–¹æ³•çš„è¿”å›æ ¼å¼ã€‚ è¿™æ„å‘³ç€å½“æˆ‘ä»¬æƒ³ä» `"pandas"` æ ¼å¼çš„ `Dataset` ä¸­åˆ›å»ºåƒ `train_df` è¿™æ ·çš„æ–°å¯¹è±¡æ—¶ï¼Œæˆ‘ä»¬éœ€è¦å¯¹æ•´ä¸ªæ•°æ®é›†è¿›è¡Œåˆ‡ç‰‡ä»¥è·å¾— `pandas.DataFrame`ã€‚ æ— è®ºè¾“å‡ºæ ¼å¼å¦‚ä½•ï¼Œæ‚¨éƒ½å¯ä»¥è‡ªå·±éªŒè¯ `drug_dataset["train"]` çš„ç±»å‹ä¾ç„¶è¿˜æ˜¯ `Dataset`ã€‚

</Tip>


ä»è¿™é‡Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æˆ‘ä»¬æƒ³è¦çš„æ‰€æœ‰ Pandas åŠŸèƒ½ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡èŠ±å¼é“¾æ¥æ¥è®¡ç®— **condition**ç±»ä¹‹é—´çš„åˆ†å¸ƒ ï¼š

```py
frequencies = (
    train_df["condition"]
    .value_counts()
    .to_frame()
    .reset_index()
    .rename(columns={"index": "condition", "condition": "frequency"})
)
frequencies.head()
```

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>condition</th>
      <th>frequency</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>birth control</td>
      <td>27655</td>
    </tr>
    <tr>
      <th>1</th>
      <td>depression</td>
      <td>8023</td>
    </tr>
    <tr>
      <th>2</th>
      <td>acne</td>
      <td>5209</td>
    </tr>
    <tr>
      <th>3</th>
      <td>anxiety</td>
      <td>4991</td>
    </tr>
    <tr>
      <th>4</th>
      <td>pain</td>
      <td>4744</td>
    </tr>
  </tbody>
</table>


ä¸€æ—¦æˆ‘ä»¬å®Œæˆäº† Pandas åˆ†æï¼Œæˆ‘ä»¬æ€»æ˜¯é€šè¿‡ä½¿ç”¨å¯¹è±¡ **Dataset.from_pandas()**æ–¹æ³•å¯ä»¥åˆ›å»ºä¸€ä¸ªæ–°çš„ **Dataset** å¦‚ä¸‹ï¼š


```py
from datasets import Dataset

freq_dataset = Dataset.from_pandas(frequencies)
freq_dataset
```

```python out
Dataset({
    features: ['condition', 'frequency'],
    num_rows: 819
})
```

<Tip>

âœï¸ **è¯•è¯•çœ‹ï¼** è®¡ç®—æ¯ç§è¯ç‰©çš„å¹³å‡è¯„çº§å¹¶å°†ç»“æœå­˜å‚¨åœ¨ä¸€ä¸ªæ–°çš„Dataset.

</Tip>

æˆ‘ä»¬å¯¹ ğŸ¤— Datasetsä¸­å¯ç”¨çš„å„ç§é¢„å¤„ç†æŠ€æœ¯çš„ä»‹ç»åˆ°æ­¤ç»“æŸã€‚åœ¨æœ€åä¸€éƒ¨åˆ†ï¼Œè®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªéªŒè¯é›†æ¥å‡†å¤‡ç”¨äºè®­ç»ƒåˆ†ç±»å™¨çš„æ•°æ®é›†ã€‚åœ¨æ­¤ä¹‹å‰ï¼Œæˆ‘ä»¬å°†è¾“å‡ºæ ¼å¼ **drug_dataset** ä» **pandas**é‡ç½®åˆ° **arrow** ï¼š

```python
drug_dataset.reset_format()
```

## åˆ›å»ºéªŒè¯é›†

å°½ç®¡æˆ‘ä»¬æœ‰ä¸€ä¸ªå¯ä»¥ç”¨äºè¯„ä¼°çš„æµ‹è¯•é›†ï¼Œä½†åœ¨å¼€å‘è¿‡ç¨‹ä¸­ä¿æŒæµ‹è¯•é›†ä¸å˜å¹¶åˆ›å»ºä¸€ä¸ªå•ç‹¬çš„éªŒè¯é›†æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„åšæ³•ã€‚ä¸€æ—¦æ‚¨å¯¹æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„è¡¨ç°æ„Ÿåˆ°æ»¡æ„ï¼Œæ‚¨å°±å¯ä»¥å¯¹éªŒè¯é›†è¿›è¡Œæœ€ç»ˆçš„æ£€æŸ¥ã€‚æ­¤è¿‡ç¨‹æœ‰åŠ©äºé™ä½æ‚¨è¿‡æ‹Ÿåˆæµ‹è¯•é›†å¹¶éƒ¨ç½²åœ¨ç°å®ä¸–ç•Œæ•°æ®ä¸Šå¤±è´¥çš„æ¨¡å‹çš„é£é™©ã€‚

ğŸ¤— Datasetsæä¾›äº†ä¸€ä¸ªåŸºäº**scikit-learn**çš„ç»å…¸æ–¹æ³•**Dataset.train_test_split()** .è®©æˆ‘ä»¬ç”¨å®ƒæŠŠæˆ‘ä»¬çš„è®­ç»ƒé›†åˆ†æˆ **train** å’Œ **validation** ï¼ˆä¸ºäº†å¯ä»¥å¤ç°ï¼Œæˆ‘ä»¬å°†è®¾ç½®**seed**çš„å€¼ä¸ºä¸€ä¸ªå¸¸é‡ï¼‰ï¼š

```py
drug_dataset_clean = drug_dataset["train"].train_test_split(train_size=0.8, seed=42)
# Rename the default "test" split to "validation"
drug_dataset_clean["validation"] = drug_dataset_clean.pop("test")
# Add the "test" set to our `DatasetDict`
drug_dataset_clean["test"] = drug_dataset["test"]
drug_dataset_clean
```

```python out
DatasetDict({
    train: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'review_clean'],
        num_rows: 110811
    })
    validation: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'review_clean'],
        num_rows: 27703
    })
    test: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'review_clean'],
        num_rows: 46108
    })
})
```

å¤ªå¥½äº†ï¼Œæˆ‘ä»¬ç°åœ¨å·²ç»å‡†å¤‡å¥½äº†ä¸€ä¸ªæ•°æ®é›†ï¼Œå¯ä»¥ç”¨æ¥è®­ç»ƒä¸€äº›æ¨¡å‹äº†ï¼åœ¨[ç¬¬äº”èŠ‚]](/course/chapter5/5)æˆ‘ä»¬å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•å°†æ•°æ®é›†ä¸Šä¼ åˆ° Hugging Face Hubï¼Œä½†ç°åœ¨è®©æˆ‘ä»¬æŸ¥çœ‹åœ¨æœ¬åœ°è®¡ç®—æœºä¸Šä¿å­˜æ•°æ®é›†çš„å‡ ç§æ–¹æ³•ã€‚

## ä¿å­˜æ•°æ®é›†

<Youtube id="blF9uxYcKHo"/>

è™½ç„¶ ğŸ¤— Datasets ä¼šç¼“å­˜æ¯ä¸ªä¸‹è½½çš„æ•°æ®é›†å’Œå¯¹å®ƒæ‰§è¡Œçš„æ“ä½œï¼Œä½†æœ‰æ—¶ä½ ä¼šæƒ³è¦å°†æ•°æ®é›†ä¿å­˜åˆ°ç£ç›˜ï¼ˆä¾‹å¦‚ï¼Œä»¥é˜²ç¼“å­˜è¢«åˆ é™¤ï¼‰ã€‚å¦‚ä¸‹è¡¨æ‰€ç¤ºï¼ŒğŸ¤— Datasets æä¾›äº†ä¸‰ä¸ªä¸»è¦åŠŸèƒ½æ¥ä»¥ä¸åŒçš„æ ¼å¼ä¿å­˜æ‚¨çš„æ•°æ®é›†ï¼š

| æ•°æ®æ ¼å¼    |        å¯¹åº”çš„æ–¹æ³•        |
| :---------: | :--------------------: |
|    Arrow    | `Dataset.save_to_disk()` |
|     CSV     |    `Dataset.to_csv()`    |
|    JSON     |   `Dataset.to_json()`    |

ä¾‹å¦‚ï¼Œè®©æˆ‘ä»¬ä»¥ Arrow æ ¼å¼ä¿å­˜æˆ‘ä»¬æ¸…æ´—è¿‡çš„æ•°æ®é›†ï¼š

```py
drug_dataset_clean.save_to_disk("drug-reviews")
```

è¿™å°†åˆ›å»ºä¸€ä¸ªå…·æœ‰ä»¥ä¸‹ç»“æ„çš„ç›®å½•ï¼š

```
drug-reviews/
â”œâ”€â”€ dataset_dict.json
â”œâ”€â”€ test
â”‚   â”œâ”€â”€ dataset.arrow
â”‚   â”œâ”€â”€ dataset_info.json
â”‚   â””â”€â”€ state.json
â”œâ”€â”€ train
â”‚   â”œâ”€â”€ dataset.arrow
â”‚   â”œâ”€â”€ dataset_info.json
â”‚   â”œâ”€â”€ indices.arrow
â”‚   â””â”€â”€ state.json
â””â”€â”€ validation
    â”œâ”€â”€ dataset.arrow
    â”œâ”€â”€ dataset_info.json
    â”œâ”€â”€ indices.arrow
    â””â”€â”€ state.json
```

åœ¨é‚£é‡Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ¯ä¸ªéƒ¨åˆ†.arrowè¡¨ï¼Œä»¥åŠä¸€äº›å…ƒæ•°æ®æ•°æ®é›†ä¿¡æ¯.jsonå’ŒçŠ¶æ€æ–‡ä»¶ä¿å­˜åœ¨ä¸€èµ·.æ‚¨å¯ä»¥å°† Arrow æ ¼å¼è§†ä¸ºä¸€ä¸ªç²¾ç¾çš„åˆ—å’Œè¡Œçš„è¡¨æ ¼ï¼Œå®ƒé’ˆå¯¹æ„å»ºå¤„ç†å’Œä¼ è¾“å¤§å‹æ•°æ®é›†çš„é«˜æ€§èƒ½åº”ç”¨ç¨‹åºè¿›è¡Œäº†ä¼˜åŒ–ã€‚

ä¿å­˜æ•°æ®é›†åï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ **load_from_disk()** åŠŸèƒ½ä»ç£ç›˜è¯»å–æ•°æ®å¦‚ä¸‹ï¼š

```py
from datasets import load_from_disk

drug_dataset_reloaded = load_from_disk("drug-reviews")
drug_dataset_reloaded
```

```python out
DatasetDict({
    train: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],
        num_rows: 110811
    })
    validation: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],
        num_rows: 27703
    })
    test: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],
        num_rows: 46108
    })
})
```

å¯¹äº CSV å’Œ JSON æ ¼å¼ï¼Œæˆ‘ä»¬å¿…é¡»å°†æ¯ä¸ªéƒ¨åˆ†å­˜å‚¨ä¸ºå•ç‹¬çš„æ–‡ä»¶ã€‚ä¸€ç§æ–¹æ³•æ˜¯è¿­ä»£**DatasetDict**ä¸­çš„é”®å’Œå€¼ ï¼š

```py
for split, dataset in drug_dataset_clean.items():
    dataset.to_json(f"drug-reviews-{split}.jsonl")
```

è¿™å°†ä¿å­˜æ¯ä¸ªæ‹†åˆ†éƒ½æ˜¯[JSONçš„æ ‡å‡†æ ¼å¼](https://jsonlines.org)ï¼Œå…¶ä¸­æ•°æ®é›†ä¸­çš„æ¯ä¸€è¡Œéƒ½å­˜å‚¨ä¸ºä¸€è¡Œ JSONã€‚è¿™æ˜¯ç¬¬ä¸€ä¸ªç¤ºä¾‹ï¼š

```py
!head -n 1 drug-reviews-train.jsonl
```

```python out
{"patient_id":141780,"drugName":"Escitalopram","condition":"depression","review":"\"I seemed to experience the regular side effects of LEXAPRO, insomnia, low sex drive, sleepiness during the day. I am taking it at night because my doctor said if it made me tired to take it at night. I assumed it would and started out taking it at night. Strange dreams, some pleasant. I was diagnosed with fibromyalgia. Seems to be helping with the pain. Have had anxiety and depression in my family, and have tried quite a few other medications that haven't worked. Only have been on it for two weeks but feel more positive in my mind, want to accomplish more in my life. Hopefully the side effects will dwindle away, worth it to stick with it from hearing others responses. Great medication.\"","rating":9.0,"date":"May 29, 2011","usefulCount":10,"review_length":125}
```

ç„¶åæˆ‘ä»¬å¯ä»¥ä½¿ç”¨[ç¬¬äºŒèŠ‚](/course/chapter5/2)å­¦è¿‡çš„æŠ€æœ¯åŠ è½½ JSON æ–‡ä»¶å¦‚ä¸‹ï¼š

```py
data_files = {
    "train": "drug-reviews-train.jsonl",
    "validation": "drug-reviews-validation.jsonl",
    "test": "drug-reviews-test.jsonl",
}
drug_dataset_reloaded = load_dataset("json", data_files=data_files)
```

è¿™å°±æ˜¯æˆ‘ä»¬æ¢ç´¢ ğŸ¤— Datasets çš„æ—…ç¨‹ï¼ç°åœ¨æˆ‘ä»¬æœ‰äº†ä¸€ä¸ªæ¸…æ´—è¿‡çš„æ•°æ®é›†ï¼Œä»¥ä¸‹æ˜¯æ‚¨å¯ä»¥å°è¯•çš„ä¸€äº›æƒ³æ³•ï¼š

1. ä½¿ç”¨[ç¬¬3ç« ](/course/chapter3)çš„æŠ€æœ¯æ¥è®­ç»ƒä¸€ä¸ªåˆ†ç±»å™¨ï¼Œå®ƒå¯ä»¥æ ¹æ®è¯ç‰©è¯„è®ºé¢„æµ‹ç—…äººçš„æƒ…å†µã€‚
2. ä½¿ç”¨ [Chapter 1](/course/chapter1) ä¸­çš„â€œsummarizationâ€ç®¡é“ç”Ÿæˆè¯„è®ºæ‘˜è¦ã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†çœ‹çœ‹ ğŸ¤— Datasetså¦‚ä½•ä½¿æ‚¨èƒ½å¤Ÿåœ¨ä¸æ’‘çˆ†ç¬”è®°æœ¬ç”µè„‘å†…å­˜çš„æƒ…å†µä¸‹å¤„ç†åºå¤§çš„æ•°æ®é›†ï¼