<FrameworkSwitchCourse {fw} />

<!-- DISABLE-FRONTMATTER-SECTIONS -->

# 章末小测验 [[章末小测验]]

<CourseFloatingBanner
    chapter={3}
    classNames="absolute z-10 right-0 top-0"
/>

Test what you learned in this chapter!


### 1.`emotion`数据集包含标记有情绪的 Twitter 消息。在[Hub](https://huggingface.co/datasets)中搜索它，然后读取数据集卡。哪一个不是它的基本情感？
<Question
	choices={[
		{
			text: "欢乐",
			explain: "再试一次ーー这种情绪出现在那个数据集中！"
		},
		{
			text: "爱",
			explain: "再试一次ーー这种情绪出现在那个数据集中！"
		},
		{
			text: "困惑",
			explain: "正确! 困惑不是六种基本情绪之一。",
            correct: true
		},
        {
			text: "惊喜",
			explain: "惊喜! 再试一个！"
		}
	]}
/>

### 2.在[Hub](https://huggingface.co/datasets)中搜索`ar_sarcasm`数据集，它支持哪个任务？
<Question
	choices={[
		{
			text: "情绪分类",
			explain: "没错! 你可以感谢这些标签。",
            correct: true
		},
		{
			text: "机器翻译",
			explain: "不是这样的ーー再看看 <a href='https://huggingface.co/datasets/ar_sarcasm'>数据集卡</a> ！"
		},
		{
			text: "命名实体识别",
			explain: "不是这样的ーー再看看 <a href ='https://huggingface.co/datasets/ar_sarcasm'>数据集卡</a> ！"
		},
        {
			text: "回答问题",
			explain: "哎呀, 问题回答不正确. 再试一次！"
		}
	]}
/>

### 3.BERT模型期望如何处理一对句子？
<Question
	choices={[
		{
			text: "句子1 [SEP] 句子2",
			explain: "确实需要一个<code>[SEP]</code>标记来分割两个句子，但这并不是唯一的需求！"
		},
		{
			text: "[CLS]句子1 句子2",
			explain: "确实在最开始需要一个<code>[CLS]</code>标记的，但是这不是唯一的事情！"
		},
		{
			text: "[CLS]句子1 [SEP] 句子2 [SEP]",
			explain: "没错！",
            correct: true
		},
        {
			text: "[CLS]句子1 [SEP] 句子2",
			explain: "开头需要一个<code>[CLS]</code>特殊标记，还需要一个<code>[SEP]</code>特殊标记来分隔两个句子，但这还不是全部！"
		}
	]}
/>

{#if fw === 'pt'}
### 4.`Dataset.map()`方法的好处是什么？
<Question
	choices={[
		{
			text: "函数的结果会被缓存，因此如果我们重新执行代码，不会花费任何时间。",
			explain: "这确实是这种方法的优点之一! 但是它不是唯一的一个..。",
            correct: true
		},
		{
			text: "它可以应用多重处理，比在数据集的每个元素上逐个应用函数更快。",
			explain: "这是这个方法的一个优雅的特性，但它不是唯一的一个！",
            correct: true
		},
		{
			text: "它不会将整个数据集加载到内存中，而是在处理一个元素后立即保存结果。",
			explain: "这是这种方法的一个优点，尽管还有其他的优点！",
            correct: true
		},
	]}
/>

### 5.什么是动态填充？
<Question
	choices={[
		{
			text: "它指的是将每批数据的输入填充到整个数据集中的最大长度。",
			explain: "它确实意味着在创建批处理时填充，但不是整个数据集中的最大长度。"
		},
		{
			text: "当创建批处理时，将输入填充到该批处理中句子的最大长度。",
			explain: "这是正确的!\“动态\”部分来自这样一个事实，即每个批的大小是在创建时确定的，因此所有批可能具有不同的形状。",
            correct: true
		},
		{
			text: "当您填充输入时，每个句子与数据集中的前一个句子具有相同数量的标记。",
			explain: "这是不正确的，而且由于我们在训练过程中对数据集进行了洗牌，所以查看数据集中的顺序是没有意义的。"
		},
	]}
/>

### 6.校对函数的用途是什么？
<Question
	choices={[
		{
			text: "它确保数据集中的所有序列具有相同的长度。",
			explain: "校对函数用于处理单个批次，而不是整个数据集。此外，我们讨论的是通用的排序函数，而不是专门讨论<code>DataCollatorWithPadding</code>。"
		},
		{
			text: "它把所有的样品放在一起成一批",
			explain: "正确的!可以将校对函数作为<code>DataLoader</code>的参数传递。我们使用了<code>DataCollatorWithPadding</code>函数，该函数填充批处理中的所有项，使它们具有相同的长度。",
            correct: true
		},
		{
			text: "它对整个数据集进行预处理。",
			explain: "这将是一个预处理函数，而不是校对函数。"
		},
        {
			text: "它截断数据集中的序列。",
			explain: "校对函数用于处理单个批次，而不是整个数据集。如果您对截断感兴趣，可以使用<code>标记器</code>的<code>truncate</code>参数。"
		}
	]}
/>

### 7.当你用一个预先训练过的语言模型(例如`bert-base-uncased`)实例化一个`AutoModelForXxx`类，这个类对应于一个不同于它所被训练的任务时会发生什么？
<Question
	choices={[
		{
			text: "什么都没有，但是你得到了一个警告。",
			explain: "你确实得到了警告，但这还不是全部！"
		},
		{
			text: "丢弃预训练模型的头部，并插入一个新的头部适合的任务。",
			explain: "正确的。例如，当我们使用<code>AutoModelForSequenceClassification</code>配合<code>bert-base-uncase </code>时，我们在实例化模型时会得到警告。预训练的头部不用于序列分类任务，因此它被丢弃，并用随机权重实例化一个新的头部。",
            correct: true
		},
		{
			text: "丢弃预先训练好的模型头部。",
			explain: "还有其他事情需要发生。 再试一次！"
		},
        {
			text: "无事发生，因为模型仍然可以针对不同的任务进行微调。",
			explain: "预训练模型的头部没有被训练来解决这个任务，所以我们应该丢弃头部!！"
		}
	]}
/>

### 8.`TrainingArguments`的目的是什么？
<Question
	choices={[
		{
			text: "它包含使用<code>训练器</code>进行训练和评估的所有超参数。",
			explain: "正确！",
            correct: true
		},
		{
			text: "它指定模型的大小。",
			explain: "模型大小是由模型配置定义的，而不是类<code>TrainingArguments</code>。"
		},
		{
			text: "它只包含用于评估的超参数。",
			explain: "在举例中，我们指定了模型及其检查点的保存位置。再试一次!"
		},
        {
			text: "它只包含用于训练的超参数。",
			explain: "在举例中，我们还使用了<code>求值策略</code>，因此这会影响求值。再试一次!"
		}
	]}
/>

### 9.为什么要使用 🤗Accelerate 库？
<Question
	choices={[
		{
			text: "它提供了对更快的模型的访问。",
			explain: "不，🤗Accelerate 库不提供任何模型。"
		},
		{
			text: "它提供了一个高级 API，因此我不必实现自己的培训循环。",
			explain: "这是我们在<code>Trainer</code>所做的，而不是🤗Accelerate库。再试一次!”"
		},
		{
			text: "它使我们的训练循环工作在分布式策略上",
			explain: "正确! 随着🤗Accelerate库，你的训练循环将为多个GPU和TPU工作。",
            correct: true
		},
        {
			text: "它提供了更多的优化功能。",
			explain: "不，🤗Accelerate 库不提供任何优化功能。"
		}
	]}
/>

{:else}
### 4.当你用一个预先训练过的语言模型(例如`bert-base-uncased`)实例化一个`TFAutoModelForXxx`类时，会发生什么？
<Question
	choices={[
		{
			text: "什么都没有，但是你得到了一个警告。",
			explain: "你确实得到了警告，但这还不是全部！"
		},
		{
			text: "丢弃预训练模型的头部，并插入一个新的头部适合的任务。",
			explain: "正确的。例如，当我们使用<code>TFAutoModelForSequenceClassification</code>配合<code>bert-base-uncase</code>时，我们在实例化模型时会得到警告。预训练的头部不用于序列分类任务，因此它被丢弃，并用随机权重实例化一个新的头部。",
            correct: true
		},
		{
			text: "丢弃预先训练好的模型头部。",
			explain: "还有其他事情需要发生。 再试一次！"
		},
        {
			text: "无事发生，因为模型仍然可以针对不同的任务进行微调。",
			explain: "预训练模型的头部没有被训练来解决这个任务，所以我们应该丢弃头部!！"
		}
	]}
/>

### 5.来自`transfomers`的 TensorFlow 模型已经是 Keras 模型，这有什么好处？
<Question
	choices={[
		{
			text: "这些模型在一个开箱即用的TPU上工作。",
			explain: "差不多了!还需要进行一些小的额外更改。例如，您需要在<code>TPUStrategy</code>范围内运行所有内容，包括模型的初始化。"
		},
		{
			text: "您可以利用现有的方法，如<code>compile()</code > 、<code>fit()</code>和<code>predict()</code> 。",
			explain: "正确! 一旦你有了这些数据，在这些数据上进行培训只需要很少的工作。",
            correct: true
		},
		{
			text: "你可以学习 Keras 和 transformers库。",
			explain: "没错，但我们要找的是别的东西:)",
			correct: true
		},
        {
			text: "您可以轻松地计算与数据集相关的指标。",
			explain: "Keras 帮助我们训练和评估模型，而不是计算与数据集相关的指标。"
		}
	]}
/>

### 6.如何定义自己的定制指标？
<Question
	choices={[
		{
			text: "通过子类化<code>tf.keras.metrics.Metric</code>。",
			explain: "太好了！",
			correct: true
		},
		{
			text: "使用 Keras 函数 API。",
			explain: "再试一次！"
		},
		{
			text: "通过使用带签名的可调用<code>metric_fn(y_true, y_pred)</code> 。",
			explain: "正确！",
			correct: true
		},
        {
			text: "通过谷歌搜索。",
			explain: "这不是我们要找的答案，但它应该能帮助你找到答案。",
			correct: true
		}
	]}
/>

{/if}