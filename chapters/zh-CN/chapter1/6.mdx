# “解码器”模型 [[“解码器”模型]]

<CourseFloatingBanner
    chapter={1}
    classNames="absolute z-10 right-0 top-0"
/>

<Youtube id="d_ixlCubqQw" />

“解码器”模型仅使用 Transformer 模型的解码器部分。在每个阶段，对于给定的单词，注意力层只能获取到句子中位于将要预测单词前面的单词。这些模型通常被称为自回归模型。

“解码器”模型的预训练通常围绕预测句子中的下一个单词进行。

这些模型最适合处理文本生成的任务。

该系列模型的典型代表有：

- [CTRL](https://huggingface.co/transformers/model_doc/ctrl) 
- [GPT](https://huggingface.co/docs/transformers/model_doc/openai-gpt) 
- [GPT-2](https://huggingface.co/transformers/model_doc/gpt2) 
- [Transformer XL](https://huggingface.co/transformers/model_doc/transfor-xl) 
