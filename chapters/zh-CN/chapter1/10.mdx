<!-- DISABLE-FRONTMATTER-SECTIONS -->

# 章末小测试 [[章末小测试]]

<CourseFloatingBanner
    chapter={1}
    classNames="absolute z-10 right-0 top-0"
/>

这一章涵盖了很多内容！ 如果有一些不太明白的地方，请不要担心； 下一章将帮助你了解这些模块在底层是如何工作的。

让我们来测试一下你在这一章学到了什么！

### 1. 探索 Hub 并寻找 `roberta-large-mnli` checkpoint。 它可以完成什么类型的任务？


<Question
	choices={[
		{
			text: "文本摘要提取",
			explain: "点击前往<a href=\"https://huggingface.co/roberta-large-mnli\">roberta-large-mnli 页面</a>回顾一下."
		},
		{
			text: "文本分类",
			explain: "更准确地说，它对两个句子在三个标签（矛盾、无关、相近）之间的逻辑链接进行分类——这项任务也称为<em>自然语言推理</em>.",
			correct: true
		},
		{
			text: "文本生成",
			explain: "点击前往<a href=\"https://huggingface.co/roberta-large-mnli\">roberta-large-mnli 页面</a>回顾一下."
		}
	]}
/>

### 2. 下面的代码将会返回什么结果？

```py
from transformers import pipeline

ner = pipeline("ner", grouped_entities=True)
ner("My name is Sylvain and I work at Hugging Face in Brooklyn.")
```

<Question
	choices={[
		{
			text: "它将返回这个句子的分类的分数, 带有 \"positive\" 或者 \"negative\"的标签.",
			explain: "这个选项是不对的 — <code>sentiment-analysis</code> pipeline将会返回这些."
		},
		{
			text: "它将返回一个生成的文本来完成这句话。",
			explain: "这个选项是不对的 — <code>text-generation</code> pipeline将会返回这些.",
		},
		{
			text: "它将返回代表人员、组织或位置的单词。",
			explain: "此外，使用 <code>grouped_entities=True</code>，它会将属于同一实体的单词组合在一起，例如“Hugging Face”。",
			correct: true
		}
	]}
/>

### 3. 在此代码示例中...的地方应该填写什么？

```py
from transformers import pipeline

filler = pipeline("fill-mask", model="bert-base-cased")
result = filler("...")
```

<Question
	choices={[
		{
			text: "This <mask> has been waiting for you.",
			explain: "这个选项是不对的。 请查看 <code>bert-base-cased</code> 模型卡片,然后再尝试找找错在哪里。"
		},
		{
			text: "This [MASK] has been waiting for you.",
			explain: "正解! 这个模型的mask的掩码是[MASK].",
			correct: true
		},
		{
			text: "This man has been waiting for you.",
			explain: "这个选项是不对的。 这个pipeline的作用是填充经过mask的文字，因此它需要在输入的文本中存在mask的token。"
		}
	]}
/>

### 4. 为什么这段代码会无法运行？

```py
from transformers import pipeline

classifier = pipeline("zero-shot-classification")
result = classifier("This is a course about the Transformers library")
```

<Question
	choices={[
		{
			text: "这个pipeline要求提供用来分类此文本的标签。",
			explain: "正解 — 正确的代码需要包括：<code>candidate_labels=[...]</code>.",
			correct: true
		},
		{
			text: "这个pipeline需要多个句子，而不仅仅是一个。",
			explain: "这个选项是不对的。尽管正确使用时，此pipeline可以同时处理多个句子（与所有其他pipeline一样）。"
		},
		{
			text: "像往常一样，🤗 Transformers库出故障了。",
			explain: "对此，我们不予置评！"
		},
		{
			text: "该pipeline需要更长的输入； 这个句子太短了。",
			explain: "这个选项是不对的。 不过请注意，在这个pipeline处理时，太长的文本将被截断。"
		}
	]}
/>

### 5. “迁移学习”是什么意思？

<Question
	choices={[
		{
			text: "通过在同一数据集上训练模型，将预训练模型的知识迁移到新模型。",
			explain: "不，那将是同一模型的两个版本。"
		},
		{
			text: "通过使用第一个模型的权重初始化第二个模型，将预训练模型的知识迁移到新模型。",
			explain: "正确：当第二个模型接受新任务训练时，它*迁移*第一个模型的知识。",
			correct: true
		},
		{
			text: "构建与第一个模型具有相同架构的第二个模型，将预训练模型的知识迁移到新模型。",
			explain: "架构只是模型的构建方式； 在这种情况下，没有知识共享或迁移。"
		}
	]}
/>

### 6. 语言模型在预训练时通常不需要标签，这样的说法是否正确。


<Question
	choices={[
		{
			text: "正确",
			explain: "预训练通常是<em>自监督</em>，这意味着标签是根据输入自动创建的（例如：预测下一个单词或填充一些[MARSK]单词）。",
			correct: true
		},
		{
			text: "错误",
			explain: "这不是一个正确的答案。"
		}
	]}
/>


### 7. 选择最能描述“模型(model)”、“架构(architecture)”和“权重(weights)”的句子。
<Question
	choices={[
		{
			text: "如果模型是一座建筑物，那么它的架构就是蓝图，而权重就是住在里面的人。",
			explain: "按照这个比喻，权重将是用于建造建筑物的砖块和其他材料。"
		},
		{
			text: "架构是构建模型的地图，其权重是地图上表示的城市。",
			explain: "这个比喻的问题在于，一张地图通常代表只有一个确定的事实（法国只有一个城市叫巴黎）。 对于给定的体系结构，多个权重是可能的。"
		},
		{
			text: "架构是用于构建模型的一系列数学函数，其权重是这些函数参数。",
			explain: "同一组数学函数（架构）可以通过使用不同的参数（权重）来构建不同的模型。",
			correct: true
		}
	]}
/>


### 8. 你将使用以下哪种类型的模型来根据输入的提示生成文本？
<Question
	choices={[
		{
			text: "一个“编码器”模型",
			explain: "“编码器”模型生成整个句子的表示，这种表示更适合于分类之类的任务。"
		},
		{
			text: "一个“解码器”模型",
			explain: "“解码器”模型非常适合根据提示生成文本。",
			correct: true
		},
		{
			text: "一个“序列到序列”模型",
			explain: "“序列到序列”模型更适合于你想要根据输入的句子而不是给定的提示生成句子的任务。"
		}
	]}
/>

### 9. 你会使用哪些类型的模型来生成文本的摘要？

<Question
	choices={[
		{
			text: "一个“编码器”模型",
			explain: "“编码器”模型生成整个句子的表示，这种表示更适合于分类之类的任务。"
		},
		{
			text: "一个“解码器”模型",
			explain: "“解码器”模型对于生成输出文本(如摘要)很好，但它们不具备利用上下文(如整个文本)进行总结的能力。"
		},
		{
			text: "一个“序列到序列”模型",
			explain: "“序列到序列”模型非常适合摘要任务。",
			correct: true
		}
	]}
/>

### 10. 你会使用哪一种类型的模型来根据特定的标签对文本输入进行分类？

<Question
	choices={[
		{
			text: "一个“编码器”模型",
			explain: "“编码器”模型可以生成整个句子的表示，非常适合分类这样的任务。",
			correct: true
		},
		{
			text: "一个“解码器”模型",
			explain: "“解码器”模型适合于生成输出文本，而不是从句子中提取标签。"
		},
		{
			text: "一个“序列到序列”模型",
			explain: "“序列到序列”模型更适合于输入句子而不是标签生成文本的任务。",
		}
	]}
/>

### 11. 模型中观察到的偏见有哪些可能的来源？

<Question
	choices={[
		{
			text: "这个模型是一个预训练模型的微调版本，它从中继承了预训练模型的偏见。",
			explain: "当应用迁移学习时，在预训练模型中产生的偏见在微调模型中不能完全去除。",
			correct: true
		},
		{
			text: "用于训练模型的数据是有偏见的。",
			explain: "这是最明显的偏见来源，但不是唯一的来源。",
			correct: true
		},
		{
			text: "模型优化的指标是有偏见的。",
			explain: "一个不太明显的偏见来源是模型的训练方式。 你的模型将盲目地只针对你选择的指标进行优化，而不会思考是否会带有偏见。",
			correct: true
		}
	]}
/>
