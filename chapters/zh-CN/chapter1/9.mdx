# 总结 [[总结]]

<CourseFloatingBanner
    chapter={1}
    classNames="absolute z-10 right-0 top-0"
/>

在本章中，你了解了如何使用来自🤗Transformers 的高级函数 `pipeline()` 处理不同的 NLP 任务。你还了解了如何在模型中心（hub）中搜索和使用模型，以及如何使用推理 API 直接在浏览器中测试模型。

我们从最终的效果的角度讨论了 Transformer 模型的工作方式，并讨论了迁移学习和微调的重要性。一个关键的收获是：你可以使用完整的体系结构，也可以仅使用编码器或解码器，具体取决于你要解决的任务类型。下表总结了这一点：

|  模型   | 示例  | 任务|
|  ----  | ----  |----|
| 编码器  | ALBERT，BERT，DistilBERT，ELECTRA，RoBERTa	|句子分类、命名实体识别、抽取式问答（从文本中提取答案）|
| 解码器  | CTRL，GPT，GPT－2，Transformer XL	 |文本生成|
| 编码器-解码器  | BART，T5，Marian，mBART	 |文本摘要、翻译、生成式问答（生成问题的回答类似 chatgpt）|