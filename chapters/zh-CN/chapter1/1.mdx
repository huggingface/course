# 简介

## 欢迎来到🤗课程

<Youtube id="00GKzGyWFEs" />

本课程将使用 Hugging Face 生态系统中的库——🤗 Transformers、🤗 Datasets、🤗 Tokenizers 和 🤗 Accelerate——以及 Hugging Face Hub 教你自然语言处理 (NLP)。它是完全免费的，并且没有广告。


## 有什么是值得期待的？

以下是课程的简要概述：

<div class="flex justify-center">
<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary.svg" alt="Brief overview of the chapters of the course."/>
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary-dark.svg" alt="Brief overview of the chapters of the course."/>
</div>

- 第 1 章到第 4 章介绍了 🤗 Transformers 库的主要概念。在本课程的这一部分结束时，您将熟悉 Transformer 模型的工作原理，并将了解如何使用 [Hugging Face Hub](https://huggingface.co/models) 中的模型，在数据集上对其进行微调，并在 Hub 上分享您的结果。
- 第 5 章到第 8 章在深入研究经典 NLP 任务之前，教授 🤗 Datasets和 🤗 Tokenizers的基础知识。在本部分结束时，您将能够自己解决最常见的 NLP 问题。
- 第 9 章到第 12 章更加深入，探讨了如何使用 Transformer 模型处理语音处理和计算机视觉中的任务。在此过程中，您将学习如何构建和分享模型，并针对生产环境对其进行优化。在这部分结束时，您将准备好将🤗 Transformers 应用于（几乎）任何机器学习问题！

这个课程：

* 需要良好的 Python 知识 
* 最好先学习深度学习入门课程，例如[DeepLearning.AI](https://www.deeplearning.ai/) 提供的 [fast.ai实用深度学习教程](https://course.fast.ai/) 
* 不需要事先具备 [PyTorch](https://pytorch.org/) 或 [TensorFlow](https://www.tensorflow.org/) 知识，虽然熟悉其中任何一个都会对huggingface的学习有所帮助

完成本课程后，我们建议您查看 [DeepLearning.AI的自然语言处理系列课程](https://www.coursera.org/specializations/natural-language-processing?utm_source=deeplearning-ai&utm_medium=institutions&utm_campaign=20211011-nlp-2-hugging_face-page-nlp-refresh)，其中涵盖了广泛的传统 NLP 模型，如朴素贝叶斯和 LSTM，这些模型非常值得了解！

## 我们是谁？

关于作者：

**Matthew Carrigan** 是 Hugging Face 的机器学习工程师。他住在爱尔兰都柏林，之前在 Parse.ly 担任机器学习工程师，在此之前，他在Trinity College Dublin担任博士后研究员。他不相信我们会通过扩展现有架构来实现 AGI，但无论如何都对机器人充满希望。

**Lysandre Debut** 是 Hugging Face 的机器学习工程师，从早期的开发阶段就一直致力于 🤗 Transformers 库。他的目标是通过使用非常简单的 API 开发工具，让每个人都可以使用 NLP。

**Sylvain Gugger** 是 Hugging Face 的一名研究工程师，也是 🤗Transformers库的核心维护者之一。此前，他是 fast.ai 的一名研究科学家，他与Jeremy Howard 共同编写了[Deep Learning for Coders with fastai and Py Torch](https://learning.oreilly.com/library/view/deep-learning-for/9781492045519/)。他的主要研究重点是通过设计和改进允许模型在有限资源上快速训练的技术，使深度学习更容易普及。

**Merve Noyan** 是 Hugging Face 的开发者倡导者，致力于开发工具并围绕它们构建内容，以使每个人的机器学习平民化。

**Lucile Saulnier** 是 Hugging Face 的机器学习工程师，负责开发和支持开源工具的使用。她还积极参与了自然语言处理领域的许多研究项目，例如协作训练和 BigScience。

**Lewis Tunstall**  是 Hugging Face 的机器学习工程师，专注于开发开源工具并使更广泛的社区可以使用它们。他也是即将出版的一本书[O’Reilly book on Transformers](https://www.oreilly.com/library/view/natural-language-processing/9781098103231/)的作者之一。

**Leandro von Werra**  是 Hugging Face 开源团队的机器学习工程师，也是即将出版的一本书[O’Reilly book on Transformers](https://www.oreilly.com/library/view/natural-language-processing/9781098103231/)的作者之一。他拥有多年的行业经验，通过在整个机器学习堆栈中工作，将 NLP 项目投入生产。

你准备好了吗？在本章中，您将学习：
* 如何使用 `pipeline()` 函数解决文本生成、分类等NLP任务
* 关于 Transformer 架构
* 如何区分编码器、解码器和编码器-解码器架构和用例 
