# å‡ºç°é”™è¯¯æ—¶è¯¥æ€ä¹ˆåŠ [[å‡ºç°é”™è¯¯æ—¶è¯¥æ€ä¹ˆåŠ]]

<DocNotebookDropdown
  classNames="absolute z-10 right-0 top-0"
  options={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter8/section2.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter8/section2.ipynb"},
]} />

åœ¨æœ¬èŠ‚ä¸­, æˆ‘ä»¬å°†ç ”ç©¶å½“ä½ å°è¯•ä»æ–°è°ƒæ•´çš„ Transformer æ¨¡å‹ç”Ÿæˆé¢„æµ‹æ—¶å¯èƒ½å‘ç”Ÿçš„ä¸€äº›å¸¸è§é”™è¯¯ã€‚è¿™å°†ä¸º [ç¬¬å››èŠ‚](/course/chapter8/section4) åšå‡†å¤‡, æˆ‘ä»¬å°†æ¢ç´¢å¦‚ä½•è°ƒè¯•è®­ç»ƒé˜¶æ®µæœ¬èº«ã€‚

<Youtube id="DQ-CpJn6Rc4"/>

æˆ‘ä»¬ä¸ºè¿™ä¸€èŠ‚å‡†å¤‡äº†ä¸€ä¸ª [æ¨¡æ¿æ¨¡å‹åº“](https://huggingface.co/lewtun/distilbert-base-uncased-finetuned-squad-d5716d28), å¦‚æœä½ æƒ³è¿è¡Œæœ¬ç« ä¸­çš„ä»£ç , ä½ é¦–å…ˆéœ€è¦å°†æ¨¡å‹å¤åˆ¶åˆ°ä½ çš„ [Hugging Face Hub](https://huggingface.co) è´¦å·ã€‚ä¸ºæ­¤, é¦–å…ˆé€šè¿‡åœ¨ Jupyter ç¬”è®°æœ¬ä¸­è¿è¡Œä»¥ä¸‹ä»»ä¸€å‘½ä»¤æ¥ç™»å½•:

```python
from huggingface_hub import notebook_login

notebook_login()
```

æˆ–åœ¨ä½ æœ€å–œæ¬¢çš„ç»ˆç«¯ä¸­æ‰§è¡Œä»¥ä¸‹æ“ä½œ:

```bash
huggingface-cli login
```

è¿™å°†æç¤ºä½ è¾“å…¥ç”¨æˆ·åå’Œå¯†ç , å¹¶å°†åœ¨ä¸‹é¢ä¿å­˜ä¸€ä¸ªä»¤ç‰Œ *~/.cache/huggingface/*ã€‚ç™»å½•å, ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹åŠŸèƒ½å¤åˆ¶æ¨¡æ¿å­˜å‚¨åº“:

```python
from distutils.dir_util import copy_tree
from huggingface_hub import Repository, snapshot_download, create_repo, get_full_repo_name


def copy_repository_template():
    # Clone the repo and extract the local path
    template_repo_id = "lewtun/distilbert-base-uncased-finetuned-squad-d5716d28"
    commit_hash = "be3eaffc28669d7932492681cd5f3e8905e358b4"
    template_repo_dir = snapshot_download(template_repo_id, revision=commit_hash)
    # Create an empty repo on the Hub
    model_name = template_repo_id.split("/")[1]
    create_repo(model_name, exist_ok=True)
    # Clone the empty repo
    new_repo_id = get_full_repo_name(model_name)
    new_repo_dir = model_name
    repo = Repository(local_dir=new_repo_dir, clone_from=new_repo_id)
    # Copy files
    copy_tree(template_repo_dir, new_repo_dir)
    # Push to Hub
    repo.push_to_hub()
```

ç°åœ¨, å½“ä½ è°ƒç”¨ `copy_repository_template()` æ—¶, å®ƒå°†åœ¨ä½ çš„å¸æˆ·ä¸‹åˆ›å»ºæ¨¡æ¿å­˜å‚¨åº“çš„å‰¯æœ¬ã€‚

## ä» ğŸ¤— Transformers è°ƒè¯•ç®¡é“ [[ä» ğŸ¤— Transformers è°ƒè¯•ç®¡é“]]

è¦å¼€å§‹æˆ‘ä»¬è°ƒè¯• Transformer æ¨¡å‹çš„å¥‡å¦™ä¸–ç•Œä¹‹æ—…, è¯·è€ƒè™‘ä»¥ä¸‹åœºæ™¯: ä½ æ­£åœ¨ä¸ä¸€ä½åŒäº‹åˆä½œè¿›è¡Œé—®ç­”é¡¹ç›®, ä»¥å¸®åŠ©ç”µå­å•†åŠ¡ç½‘ç«™çš„å®¢æˆ·æ‰¾åˆ°æœ‰å…³æ¶ˆè´¹å“çš„ç­”æ¡ˆã€‚ä½ çš„åŒäº‹ç»™ä½ å‘äº†ä¸€æ¡æ¶ˆæ¯, æ¯”å¦‚:

> å—¨! æˆ‘åˆšåˆšä½¿ç”¨äº†æŠ±æŠ±è„¸è¯¾ç¨‹çš„ [ç¬¬ä¸ƒç« ](/course/chapter7/7) ä¸­çš„æŠ€æœ¯è¿›è¡Œäº†ä¸€ä¸ªå®éªŒ, å¹¶åœ¨ SQuAD ä¸Šè·å¾—äº†ä¸€äº›å¾ˆæ£’çš„ç»“æœ! æˆ‘è®¤ä¸ºæˆ‘ä»¬å¯ä»¥ç”¨è¿™ä¸ªæ¨¡å‹ä½œä¸ºæˆ‘ä»¬é¡¹ç›®çš„èµ·ç‚¹ã€‚Hubä¸Šçš„æ¨¡å‹IDæ˜¯ "lewtun/distillbert-base-uncased-finetuned-squad-d5716d28"ã€‚è¯·éšæ„æµ‹è¯•ä¸€ä¸‹ :)

ä½ é¦–å…ˆæƒ³åˆ°çš„æ˜¯ä½¿ç”¨ ğŸ¤— Transformers ä¸­çš„ `ç®¡é“`:

```python
from transformers import pipeline

model_checkpoint = get_full_repo_name("distillbert-base-uncased-finetuned-squad-d5716d28")
reader = pipeline("question-answering", model=model_checkpoint)
```

```python out
"""
OSError: Can't load config for 'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28'. Make sure that:

- 'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28' is a correct model identifier listed on 'https://huggingface.co/models'

- or 'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28' is the correct path to a directory containing a config.json file
"""
```

å“¦ä¸å¯¹, å¥½åƒå‡ºäº†ä»€ä¹ˆé—®é¢˜! å¦‚æœä½ æ˜¯ç¼–ç¨‹æ–°æ‰‹, è¿™äº›ç±»å‹çš„é”™è¯¯ä¸€å¼€å§‹çœ‹èµ·æ¥æœ‰ç‚¹ç¥ç§˜ (ç”šè‡³æ˜¯ä¸€ä¸ª `OSError`?!)ã€‚è¿™é‡Œæ˜¾ç¤ºçš„é”™è¯¯åªæ˜¯ä¸€ä¸ªæ›´å¤§çš„é”™è¯¯æŠ¥å‘Šçš„æœ€åä¸€éƒ¨åˆ†, ç§°ä¸º _Python traceback_ (åˆåå †æ ˆè·Ÿè¸ª)ã€‚ä¾‹å¦‚, å¦‚æœä½ åœ¨ Google Colab ä¸Šè¿è¡Œæ­¤ä»£ç , ä½ åº”è¯¥ä¼šçœ‹åˆ°ç±»ä¼¼äºä»¥ä¸‹å±å¹•æˆªå›¾çš„å†…å®¹:

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter8/traceback.png" alt="A Python traceback." width="100%"/>
</div>

è¿™äº›æŠ¥å‘Šä¸­åŒ…å«å¾ˆå¤šä¿¡æ¯, æ‰€ä»¥è®©æˆ‘ä»¬ä¸€èµ·æ¥çœ‹çœ‹å…³é”®éƒ¨åˆ†ã€‚é¦–å…ˆè¦æ³¨æ„çš„æ˜¯, åº”è¯¥ä» _ä»åº•éƒ¨åˆ°é¡¶éƒ¨_ è¯»å–å›æº¯ã€‚å¦‚æœä½ ä¹ æƒ¯äºä»ä¸Šåˆ°ä¸‹é˜…è¯»è‹±æ–‡æ–‡æœ¬, è¿™å¯èƒ½å¬èµ·æ¥å¾ˆå¥‡æ€ª,ä½†å®ƒåæ˜ äº†è¿™æ ·ä¸€ä¸ªäº‹å®,å³å›æº¯æ˜¾ç¤ºäº†åœ¨ä¸‹è½½æ¨¡å‹å’Œæ ‡è®°å™¨æ—¶ `ç®¡é“` è¿›è¡Œçš„å‡½æ•°è°ƒç”¨åºåˆ—ã€‚(æŸ¥çœ‹ [ç¬¬äºŒç« ](/course/chapter2) äº†è§£æœ‰å…³ `pipeline` å¦‚ä½•åœ¨åå°å·¥ä½œçš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚)

<Tip>

ğŸš¨ çœ‹åˆ°Google Colab å›æº¯ä¸­ "6 å¸§" å‘¨å›´çš„è“è‰²æ¡†äº†å—? è¿™æ˜¯ Colab çš„ä¸€ä¸ªç‰¹æ®ŠåŠŸèƒ½, å®ƒå°†å›æº¯å‹ç¼©ä¸º"å¸§"ã€‚å¦‚æœä½ ä¼¼ä¹æ— æ³•æ‰¾åˆ°é”™è¯¯çš„æ¥æº, è¯·ç¡®ä¿é€šè¿‡å•å‡»è¿™ä¸¤ä¸ªå°ç®­å¤´æ¥å±•å¼€å®Œæ•´çš„å›æº¯ã€‚

</Tip>

è¿™æ„å‘³ç€å›æº¯çš„æœ€åä¸€è¡ŒæŒ‡ç¤ºæœ€åä¸€æ¡é”™è¯¯æ¶ˆæ¯å¹¶ç»™å‡ºå¼•å‘çš„å¼‚å¸¸çš„åç§°ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹, å¼‚å¸¸ç±»å‹æ˜¯`OSError`, è¡¨ç¤ºä¸ç³»ç»Ÿç›¸å…³çš„é”™è¯¯ã€‚å¦‚æœæˆ‘ä»¬é˜…è¯»éšé™„çš„é”™è¯¯æ¶ˆæ¯, æˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ¨¡å‹çš„ *config.json* æ–‡ä»¶ä¼¼ä¹æœ‰é—®é¢˜, æˆ‘ä»¬ç»™å‡ºäº†ä¸¤ä¸ªä¿®å¤å®ƒçš„å»ºè®®:

```python out
"""
Make sure that:

- 'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28' is a correct model identifier listed on 'https://huggingface.co/models'

- or 'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28' is the correct path to a directory containing a config.json file
"""
```

<Tip>

ğŸ’¡ å¦‚æœä½ é‡åˆ°éš¾ä»¥ç†è§£çš„é”™è¯¯æ¶ˆæ¯, åªéœ€å°†è¯¥æ¶ˆæ¯å¤åˆ¶å¹¶ç²˜è´´åˆ° Google æˆ– [Stack Overflow](https://stackoverflow.com/) æœç´¢æ ä¸­ (æ˜¯çš„, çœŸçš„!)ã€‚ä½ å¾ˆå¯èƒ½ä¸æ˜¯ç¬¬ä¸€ä¸ªé‡åˆ°é”™è¯¯çš„äºº, è¿™æ˜¯æ‰¾åˆ°ç¤¾åŒºä¸­å…¶ä»–äººå‘å¸ƒçš„è§£å†³æ–¹æ¡ˆçš„å¥½æ–¹æ³•ã€‚ä¾‹å¦‚, åœ¨ Stack Overflow ä¸Šæœç´¢ `OSError: Can't load config for` ç»™å‡ºäº†å‡ ä¸ª[hits](https://stackoverflow.com/search?q=OSError%3A+Can%27t+load+config+for+), å¯èƒ½æ˜¯ç”¨ä½œè§£å†³é—®é¢˜çš„èµ·ç‚¹ã€‚

</Tip>

ç¬¬ä¸€ä¸ªå»ºè®®æ˜¯è¦æ±‚æˆ‘ä»¬æ£€æŸ¥æ¨¡å‹IDæ˜¯å¦çœŸçš„æ­£ç¡®, æ‰€ä»¥é¦–å…ˆè¦åšçš„å°±æ˜¯å¤åˆ¶æ ‡è¯†ç¬¦å¹¶å°†å…¶ç²˜è´´åˆ°Hubçš„æœç´¢æ ä¸­:

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter8/wrong-model-id.png" alt="The wrong model name." width="100%"/>
</div>

å—¯, çœ‹èµ·æ¥æˆ‘ä»¬åŒäº‹çš„æ¨¡å‹ç¡®å®ä¸åœ¨ Hub ä¸Š... å•Šå“ˆ, ä½†æ˜¯æ¨¡å‹åç§°ä¸­æœ‰ä¸€ä¸ªé”™å­—! DistilBERT çš„åç§°ä¸­åªæœ‰ä¸€ä¸ª "l", æ‰€ä»¥è®©æˆ‘ä»¬è§£å†³è¿™ä¸ªé—®é¢˜å¹¶å¯»æ‰¾ "lewtun/distilbert-base-uncased-finetuned-squad-d5716d28":

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter8/true-model-id.png" alt="The right model name." width="100%"/>
</div>

å¥½çš„, è¿™å¾ˆå—æ¬¢è¿ã€‚ç°åœ¨è®©æˆ‘ä»¬å°è¯•ä½¿ç”¨æ­£ç¡®çš„æ¨¡å‹ ID å†æ¬¡ä¸‹è½½æ¨¡å‹:

```python
model_checkpoint = get_full_repo_name("distilbert-base-uncased-finetuned-squad-d5716d28")
reader = pipeline("question-answering", model=model_checkpoint)
```

```python out
"""
OSError: Can't load config for 'lewtun/distilbert-base-uncased-finetuned-squad-d5716d28'. Make sure that:

- 'lewtun/distilbert-base-uncased-finetuned-squad-d5716d28' is a correct model identifier listed on 'https://huggingface.co/models'

- or 'lewtun/distilbert-base-uncased-finetuned-squad-d5716d28' is the correct path to a directory containing a config.json file
"""
```

å•Š, å†æ¬¡æŒ«è´¥ -- æ¬¢è¿æ¥åˆ°æœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆçš„æ—¥å¸¸ç”Ÿæ´»! å› ä¸ºæˆ‘ä»¬å·²ç»ä¿®å¤äº†æ¨¡å‹ ID, æ‰€ä»¥é—®é¢˜ä¸€å®šå‡ºåœ¨å­˜å‚¨åº“æœ¬èº«ã€‚è®¿é—® ğŸ¤— Hub ä¸Šå­˜å‚¨åº“å†…å®¹çš„ä¸€ç§å¿«é€Ÿæ–¹æ³•æ˜¯é€šè¿‡ `huggingface_hub` åº“çš„ `list_repo_files()` æ–¹æ³•:

```python
from huggingface_hub import list_repo_files

list_repo_files(repo_id=model_checkpoint)
```

```python out
['.gitattributes', 'README.md', 'pytorch_model.bin', 'special_tokens_map.json', 'tokenizer_config.json', 'training_args.bin', 'vocab.txt']
```

æœ‰è¶£ -- ä¼¼ä¹æ²¡æœ‰é…ç½®æ–‡ä»¶å­˜å‚¨åº“ä¸­çš„ *config.json* æ–‡ä»¶! éš¾æ€ªæˆ‘ä»¬çš„ `pipeline` æ— æ³•åŠ è½½æ¨¡å‹; æˆ‘ä»¬çš„åŒäº‹ä¸€å®šæ˜¯åœ¨å¾®è°ƒåå¿˜è®°å°†è¿™ä¸ªæ–‡ä»¶æ¨é€åˆ° Hubã€‚åœ¨è¿™ç§æƒ…å†µä¸‹, é—®é¢˜ä¼¼ä¹å¾ˆå®¹æ˜“è§£å†³: æˆ‘ä»¬å¯ä»¥è¦æ±‚ä»–ä»¬æ·»åŠ æ–‡ä»¶, æˆ–è€…, å› ä¸ºæˆ‘ä»¬å¯ä»¥ä»æ¨¡å‹ ID ä¸­çœ‹åˆ°ä½¿ç”¨çš„é¢„è®­ç»ƒæ¨¡å‹æ˜¯ [`distilbert-base-uncased`](https://huggingface.co/distilbert-base-uncased), æˆ‘ä»¬å¯ä»¥ä¸‹è½½æ­¤æ¨¡å‹çš„é…ç½®å¹¶å°†å…¶æ¨é€åˆ°æˆ‘ä»¬çš„å­˜å‚¨åº“ä»¥æŸ¥çœ‹æ˜¯å¦å¯ä»¥è§£å†³é—®é¢˜ã€‚è®©æˆ‘ä»¬è¯•è¯•çœ‹ã€‚ä½¿ç”¨æˆ‘ä»¬åœ¨ [ç¬¬äºŒç« ](/course/chapter2) ä¸­å­¦ä¹ çš„æŠ€æœ¯, æˆ‘ä»¬ä½¿ç”¨ `AutoConfig` ç±»ä¸‹è½½æ¨¡å‹çš„é…ç½®:

```python
from transformers import AutoConfig

pretrained_checkpoint = "distilbert-base-uncased"
config = AutoConfig.from_pretrained(pretrained_checkpoint)
```

<Tip warning={true}>

ğŸš¨ æˆ‘ä»¬åœ¨è¿™é‡Œé‡‡ç”¨çš„æ–¹æ³•å¹¶ä¸æ˜¯ä¸‡æ— ä¸€å¤±çš„, å› ä¸ºæˆ‘ä»¬çš„åŒäº‹å¯èƒ½åœ¨å¾®è°ƒæ¨¡å‹ä¹‹å‰å·²ç»è°ƒæ•´äº† `distilbert-base-uncased` é…ç½®ã€‚åœ¨ç°å®ç”Ÿæ´»ä¸­, æˆ‘ä»¬æƒ³é¦–å…ˆæ£€æŸ¥å®ƒä»¬, ä½†å‡ºäºæœ¬èŠ‚çš„ç›®çš„, æˆ‘ä»¬å‡è®¾å®ƒä»¬ä½¿ç”¨é»˜è®¤é…ç½®ã€‚

</Tip>

ç„¶åæˆ‘ä»¬å¯ä»¥ä½¿ç”¨é…ç½®çš„ `push_to_hub()` æ–¹æ³•å°†å…¶æ¨é€åˆ°æˆ‘ä»¬çš„æ¨¡å‹å­˜å‚¨åº“:

```python
config.push_to_hub(model_checkpoint, commit_message="Add config.json")
```

ç°åœ¨æˆ‘ä»¬å¯ä»¥é€šè¿‡ä»æœ€æ–°æäº¤çš„ `main` åˆ†æ”¯ä¸­åŠ è½½æ¨¡å‹æ¥æµ‹è¯•è¿™æ˜¯å¦æœ‰æ•ˆ:

```python
reader = pipeline("question-answering", model=model_checkpoint, revision="main")

context = r"""
Extractive Question Answering is the task of extracting an answer from a text
given a question. An example of a question answering dataset is the SQuAD
dataset, which is entirely based on that task. If you would like to fine-tune a
model on a SQuAD task, you may leverage the
examples/pytorch/question-answering/run_squad.py script.

ğŸ¤— Transformers is interoperable with the PyTorch, TensorFlow, and JAX
frameworks, so you can use your favourite tools for a wide variety of tasks!
"""

question = "What is extractive question answering?"
reader(question=question, context=context)
```

```python out
{'score': 0.38669535517692566,
 'start': 34,
 'end': 95,
 'answer': 'the task of extracting an answer from a text given a question'}
```

å“‡å“¦, æˆåŠŸäº†!è®©æˆ‘ä»¬å›é¡¾ä¸€ä¸‹ä½ åˆšåˆšå­¦åˆ°çš„ä¸œè¥¿:

- Python ä¸­çš„é”™è¯¯æ¶ˆæ¯ç§°ä¸º _tracebacks_ , å¹¶ä»ä¸‹åˆ°ä¸Šé˜…è¯»ã€‚é”™è¯¯æ¶ˆæ¯çš„æœ€åä¸€è¡Œé€šå¸¸åŒ…å«å®šä½é—®é¢˜æ ¹æºæ‰€éœ€çš„ä¿¡æ¯ã€‚
- å¦‚æœæœ€åä¸€è¡Œæ²¡æœ‰åŒ…å«è¶³å¤Ÿçš„ä¿¡æ¯, è¯·æŒ‰ç…§æ‚¨çš„æ–¹å¼è¿›è¡Œå›æº¯, çœ‹çœ‹æ‚¨æ˜¯å¦å¯ä»¥ç¡®å®šæºä»£ç ä¸­å‘ç”Ÿé”™è¯¯çš„ä½ç½®ã€‚
- å¦‚æœæ²¡æœ‰ä»»ä½•é”™è¯¯æ¶ˆæ¯å¯ä»¥å¸®åŠ©æ‚¨è°ƒè¯•é—®é¢˜, è¯·å°è¯•åœ¨çº¿æœç´¢ç±»ä¼¼é—®é¢˜çš„è§£å†³æ–¹æ¡ˆã€‚
- `huggingface_hub` 
// ğŸ¤— Hub?
åº“æä¾›äº†ä¸€å¥—å·¥å…·, ä½ å¯ä»¥ä½¿ç”¨è¿™äº›å·¥å…·ä¸ Hub ä¸Šçš„å­˜å‚¨åº“è¿›è¡Œäº¤äº’å’Œè°ƒè¯•ã€‚

ç°åœ¨ä½ çŸ¥é“å¦‚ä½•è°ƒè¯•ç®¡é“, è®©æˆ‘ä»¬çœ‹ä¸€ä¸‹æ¨¡å‹æœ¬èº«å‰å‘ä¼ é€’ä¸­çš„ä¸€ä¸ªæ›´æ£˜æ‰‹çš„ç¤ºä¾‹ã€‚

## è°ƒè¯•æ¨¡å‹çš„å‰å‘ä¼ é€’ [[è°ƒè¯•æ¨¡å‹çš„å‰å‘ä¼ é€’]]

å°½ç®¡ `pipeline` å¯¹äºå¤§å¤šæ•°éœ€è¦å¿«é€Ÿç”Ÿæˆé¢„æµ‹çš„åº”ç”¨ç¨‹åºæ¥è¯´éå¸¸æœ‰ç”¨, æœ‰æ—¶æ‚¨éœ€è¦è®¿é—®æ¨¡å‹çš„ logits (ä¾‹å¦‚, å¦‚æœæ‚¨æœ‰ä¸€äº›æƒ³è¦åº”ç”¨çš„è‡ªå®šä¹‰åå¤„ç†)ã€‚ä¸ºäº†çœ‹çœ‹åœ¨è¿™ç§æƒ…å†µä¸‹ä¼šå‡ºç°ä»€ä¹ˆé—®é¢˜, è®©æˆ‘ä»¬é¦–å…ˆä» `pipeline` ä¸­è·å–æ¨¡å‹å’Œæ ‡è®°å™¨:

```python
tokenizer = reader.tokenizer
model = reader.model
```

æ¥ä¸‹æ¥æˆ‘ä»¬éœ€è¦ä¸€ä¸ªé—®é¢˜, é‚£ä¹ˆè®©æˆ‘ä»¬çœ‹çœ‹æ˜¯å¦æ”¯æŒæˆ‘ä»¬æœ€å–œæ¬¢çš„æ¡†æ¶:

```python
question = "Which frameworks can I use?"
```

æ­£å¦‚æˆ‘ä»¬åœ¨ [ç¬¬ä¸ƒç« ](/course/chapter7) ä¸­å­¦ä¹ çš„, æˆ‘ä»¬éœ€è¦é‡‡å–çš„é€šå¸¸æ­¥éª¤æ˜¯å¯¹è¾“å…¥è¿›è¡Œæ ‡è®°åŒ–, æå–å¼€å§‹å’Œç»“æŸæ ‡è®°çš„å¯¹æ•°, ç„¶åè§£ç ç­”æ¡ˆèŒƒå›´:

```python
import torch

inputs = tokenizer(question, context, add_special_tokens=True)
input_ids = inputs["input_ids"][0]
outputs = model(**inputs)
answer_start_scores = outputs.start_logits
answer_end_scores = outputs.end_logits
# Get the most likely beginning of answer with the argmax of the score
answer_start = torch.argmax(answer_start_scores)
# Get the most likely end of answer with the argmax of the score
answer_end = torch.argmax(answer_end_scores) + 1
answer = tokenizer.convert_tokens_to_string(
    tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end])
)
print(f"Question: {question}")
print(f"Answer: {answer}")
```

```python out
"""
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
/var/folders/28/k4cy5q7s2hs92xq7_h89_vgm0000gn/T/ipykernel_75743/2725838073.py in <module>
      1 inputs = tokenizer(question, text, add_special_tokens=True)
      2 input_ids = inputs["input_ids"]
----> 3 outputs = model(**inputs)
      4 answer_start_scores = outputs.start_logits
      5 answer_end_scores = outputs.end_logits

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)
   1049         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
   1050                 or _global_forward_hooks or _global_forward_pre_hooks):
-> 1051             return forward_call(*input, **kwargs)
   1052         # Do not call functions when jit is used
   1053         full_backward_hooks, non_full_backward_hooks = [], []

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py in forward(self, input_ids, attention_mask, head_mask, inputs_embeds, start_positions, end_positions, output_attentions, output_hidden_states, return_dict)
    723         return_dict = return_dict if return_dict is not None else self.config.use_return_dict
    724
--> 725         distilbert_output = self.distilbert(
    726             input_ids=input_ids,
    727             attention_mask=attention_mask,

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)
   1049         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
   1050                 or _global_forward_hooks or _global_forward_pre_hooks):
-> 1051             return forward_call(*input, **kwargs)
   1052         # Do not call functions when jit is used
   1053         full_backward_hooks, non_full_backward_hooks = [], []

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py in forward(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)
    471             raise ValueError("You cannot specify both input_ids and inputs_embeds at the same time")
    472         elif input_ids is not None:
--> 473             input_shape = input_ids.size()
    474         elif inputs_embeds is not None:
    475             input_shape = inputs_embeds.size()[:-1]

AttributeError: 'list' object has no attribute 'size'
"""
```

å™¢, çœ‹èµ·æ¥æˆ‘ä»¬çš„ä»£ç ä¸­æœ‰ä¸€ä¸ªé”™è¯¯!ä½†æˆ‘ä»¬ä¸æ€•ä¸€ç‚¹è°ƒè¯•ã€‚æ‚¨å¯ä»¥åœ¨ç¬”è®°æœ¬ä¸­ä½¿ç”¨ Python è°ƒè¯•å™¨:

<Youtube id="rSPyvPw0p9k"/>

æˆ–åœ¨ç»ˆç«¯ä¸­:

<Youtube id="5PkZ4rbHL6c"/>

åœ¨è¿™é‡Œ, é˜…è¯»é”™è¯¯æ¶ˆæ¯å‘Šè¯‰æˆ‘ä»¬ `'list' object has no attribute 'size'`, æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä¸€ä¸ª `-->` ç®­å¤´æŒ‡å‘ `model(**inputs)` ä¸­å‡ºç°é—®é¢˜çš„è¡Œã€‚ä½ å¯ä»¥ä½¿ç”¨ Python è°ƒè¯•å™¨ä»¥äº¤äº’æ–¹å¼è°ƒè¯•å®ƒ, ä½†ç°åœ¨æˆ‘ä»¬åªéœ€æ‰“å°å‡ºä¸€éƒ¨åˆ† `inputs`, çœ‹çœ‹æˆ‘ä»¬æœ‰ä»€ä¹ˆ:

```python
inputs["input_ids"][:5]
```

```python out
[101, 2029, 7705, 2015, 2064]
```

è¿™å½“ç„¶çœ‹èµ·æ¥åƒä¸€ä¸ªæ™®é€šçš„ Python `list`, ä½†è®©æˆ‘ä»¬ä»”ç»†æ£€æŸ¥ä¸€ä¸‹ç±»å‹:

```python
type(inputs["input_ids"])
```

```python out
list
```

æ˜¯çš„, è¿™è‚¯å®šæ˜¯ä¸€ä¸ª Python `list`ã€‚é‚£ä¹ˆå‡ºäº†ä»€ä¹ˆé—®é¢˜å‘¢? å›å¿† [ç¬¬äºŒç« ](/course/chapter2) ğŸ¤— Transformers ä¸­çš„ `AutoModelForXxx` ç±»åœ¨ _tensors_ ä¸Šè¿è¡Œ(PyTorchæˆ–è€…or TensorFlow), ä¸€ä¸ªå¸¸è§çš„æ“ä½œæ˜¯ä½¿ç”¨ `Tensor.size()` æ–¹æ³•æå–å¼ é‡çš„ç»´åº¦, ä¾‹å¦‚, åœ¨ PyTorch ä¸­ã€‚è®©æˆ‘ä»¬å†çœ‹çœ‹å›æº¯, çœ‹çœ‹å“ªä¸€è¡Œè§¦å‘äº†å¼‚å¸¸:

```
~/miniconda3/envs/huggingface/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py in forward(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)
    471             raise ValueError("You cannot specify both input_ids and inputs_embeds at the same time")
    472         elif input_ids is not None:
--> 473             input_shape = input_ids.size()
    474         elif inputs_embeds is not None:
    475             input_shape = inputs_embeds.size()[:-1]

AttributeError: 'list' object has no attribute 'size'
```

çœ‹èµ·æ¥æˆ‘ä»¬çš„ä»£ç è¯•å›¾è°ƒç”¨ `input_ids.size()`, ä½†è¿™æ˜¾ç„¶ä¸é€‚ç”¨äº Python `list`, è¿™åªæ˜¯ä¸€ä¸ªå®¹å™¨ã€‚æˆ‘ä»¬å¦‚ä½•è§£å†³è¿™ä¸ªé—®é¢˜? åœ¨ Stack Overflow ä¸Šæœç´¢é”™è¯¯æ¶ˆæ¯ç»™å‡ºäº†å¾ˆå¤šç›¸å…³çš„ [hits](https://stackoverflow.com/search?q=AttributeError%3A+%27list%27+object+has+no+attribute+%27size%27&s=c15ec54c-63cb-481d-a749-408920073e8f)ã€‚å•å‡»ç¬¬ä¸€ä¸ªä¼šæ˜¾ç¤ºä¸æˆ‘ä»¬ç±»ä¼¼çš„é—®é¢˜, ç­”æ¡ˆå¦‚ä¸‹é¢çš„å±å¹•æˆªå›¾æ‰€ç¤º:

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter8/stack-overflow.png" alt="An answer from Stack Overflow." width="100%"/>
</div>

ç­”æ¡ˆå»ºè®®æˆ‘ä»¬æ·»åŠ  `return_tensors='pt'` åˆ°æ ‡è®°å™¨, æ‰€ä»¥è®©æˆ‘ä»¬çœ‹çœ‹è¿™æ˜¯å¦é€‚åˆæˆ‘ä»¬:

```python out
inputs = tokenizer(question, context, add_special_tokens=True, return_tensors="pt")
input_ids = inputs["input_ids"][0]
outputs = model(**inputs)
answer_start_scores = outputs.start_logits
answer_end_scores = outputs.end_logits
# Get the most likely beginning of answer with the argmax of the score
answer_start = torch.argmax(answer_start_scores)
# Get the most likely end of answer with the argmax of the score
answer_end = torch.argmax(answer_end_scores) + 1
answer = tokenizer.convert_tokens_to_string(
    tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end])
)
print(f"Question: {question}")
print(f"Answer: {answer}")
```

```python out
"""
Question: Which frameworks can I use?
Answer: pytorch, tensorflow, and jax
"""
```

ä¸é”™, æˆåŠŸäº†! è¿™æ˜¯ Stack Overflow éå¸¸æœ‰ç”¨çš„ä¸€ä¸ªå¾ˆå¥½çš„ä¾‹å­: é€šè¿‡è¯†åˆ«ç±»ä¼¼çš„é—®é¢˜, æˆ‘ä»¬èƒ½å¤Ÿä»ç¤¾åŒºä¸­å…¶ä»–äººçš„ç»éªŒä¸­å—ç›Šã€‚ç„¶è€Œ, åƒè¿™æ ·çš„æœç´¢å¹¶ä¸æ€»æ˜¯ä¼šäº§ç”Ÿç›¸å…³çš„ç­”æ¡ˆ, é‚£ä¹ˆåœ¨è¿™ç§æƒ…å†µä¸‹ä½ èƒ½åšä»€ä¹ˆå‘¢? å¹¸è¿çš„æ˜¯, æœ‰ä¸€ä¸ªå—æ¬¢è¿çš„å¼€å‘è€…ç¤¾åŒº [Hugging Face forums](https://discuss.huggingface.co/) å¯ä»¥å¸®åŠ©ä½ ! åœ¨ä¸‹ä¸€èŠ‚ä¸­, æˆ‘ä»¬å°†çœ‹çœ‹å¦‚ä½•è®¾è®¡å¯èƒ½å¾—åˆ°å›ç­”çš„ä¼˜ç§€è®ºå›é—®é¢˜ã€‚