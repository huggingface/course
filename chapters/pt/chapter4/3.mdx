<FrameworkSwitchCourse {fw} />

# Compartilhando modelos pr√©-treinados

{#if fw === 'pt'}

<CourseFloatingBanner chapter={4}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/pt/chapter4/section3_pt.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/pt/chapter4/section3_pt.ipynb"},
]} />

{:else}

<CourseFloatingBanner chapter={4}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/pt/chapter4/section3_tf.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/pt/chapter4/section3_tf.ipynb"},
]} />

{/if}

Nas etapas abaixo, veremos as maneiras mais f√°ceis de compartilhar modelos pr√©-treinados para o Hub ü§ó. H√° ferramentas e utilit√°rios dispon√≠veis que facilitam o compartilhamento e atualiza√ß√£o de modelos diretamente no Hub, que exploraremos a seguir.

<Youtube id="9yY3RB_GSPM"/>

Encorajamos todos os usu√°rios que treinam modelos a contribuir compartilhando-os com a comunidade - compartilhar modelos, mesmo quando treinados em conjuntos de dados muito espec√≠ficos, ajudar√° outros, economizando tempo e recursos e fornecendo acesso a artefatos √∫teis treinados. Por sua vez, voc√™ pode se beneficiar do trabalho que outros realizaram!

H√° tr√™s maneiras de se criar novos reposit√≥rios modelo:

- Usando a API`push_to_hub`
- Usando a biblioteca Python `huggingface_hub`
- Usando a interface web 

Uma vez criado um reposit√≥rio, voc√™ pode fazer o upload de arquivos para ele via git e git-lfs. N√≥s o acompanharemos na cria√ß√£o de reposit√≥rios modelo e no upload de arquivos para eles nas se√ß√µes seguintes.


## Usando a API`push_to_hub`

{#if fw === 'pt'}

<Youtube id="Zh0FfmVrKX0"/>

{:else}

<Youtube id="pUh5cGmNV8Y"/>

{/if}

A maneira mais simples de carregar arquivos no Hub √© usando a API `push_to_hub`.

Antes de ir adiante, voc√™ precisar√° gerar um token de autentica√ß√£o para que a API `huggingface_hub` saiba quem voc√™ √© e a que namespaces voc√™ tem acesso de escrita. Certifique-se de estar em um ambiente onde voc√™ tenha `transformers` instalado (ver [Setup](/course/chapter0)). Se voc√™ estiver em um notebook, voc√™ pode utilizar a seguinte fun√ß√£o para fazer o login:


```python
from huggingface_hub import notebook_login

notebook_login()
```

Em um terminal, voc√™ pode rodar:

```bash
huggingface-cli login
```

Em ambos os casos, voc√™ ser√° solicitado seu nome de usu√°rio e senha, que s√£o os mesmos que voc√™ usa para fazer o login no Hub. Se voc√™ ainda n√£o tem um perfil do Hub, voc√™ deve criar um [aqui](https://huggingface.co/join).

√ìtimo! Agora voc√™ tem seu token de autentica√ß√£o armazenado em sua pasta de cache. Vamos criar alguns reposit√≥rios!

{#if fw === 'pt'}

Se voc√™ usou a API do `Trainer` para treinar um modelo, a maneira mais f√°cil de carreg√°-lo no Hub √© definir `push_to_hub=True` quando voc√™ definir seus `TrainingArguments`:

```py
from transformers import TrainingArguments

training_args = TrainingArguments(
    "bert-finetuned-mrpc", save_strategy="epoch", push_to_hub=True
)
```

Quando voc√™ chama `trainer.train()`, o `Trainer` ent√£o carregar√° seu modelo no Hub cada vez que ele for salvo (aqui a cada √©poca) em um reposit√≥rio em seu namespace. Esse reposit√≥rio ser√° nomeado como o diret√≥rio de sa√≠da que voc√™ escolheu (aqui `bert-finetuned-mrpc`), mas voc√™ pode escolher um nome diferente com `hub_model_id = "a_diferent_name"`.

Para enviar seu modelo para uma organiza√ß√£o da qual voc√™ √© membro, basta pass√°-lo com `hub_model_id = "my_organization/my_repo_name"`.

Uma vez terminado seu treinamento, voc√™ deve fazer um √∫ltimo `trainer.push_to_hub()` para carregar a √∫ltima vers√£o de seu modelo. Ele tamb√©m gerar√° um cart√£o modelo com todos os metadados relevantes, relatando os hiperpar√¢metros utilizados e os resultados da avalia√ß√£o! Aqui est√° um exemplo do conte√∫do que voc√™ pode encontrar em um cart√£o modelo deste tipo:

<div class="flex justify-center">
  <img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/model_card.png" alt="An example of an auto-generated model card." width="100%"/>
</div>

{:else}


Se voc√™ estiver utilizando Keras para treinar seu modelo, a maneira mais f√°cil de carreg√°-lo no Hub √© passar um `PushToHubCallback` quando voc√™ chama de `model.fit()`:

```py
from transformers import PushToHubCallback

callback = PushToHubCallback(
    "bert-finetuned-mrpc", save_strategy="epoch", tokenizer=tokenizer
)
```

Ent√£o voc√™ deve adicionar `callbacks=[callback]` em sua chamada de `model.fit()`. A chamada de retorno ser√° ent√£o enviada ao Hub cada vez que o modelo for salvo (aqui a cada √©poca) em um reposit√≥rio em seu namespace. Esse reposit√≥rio ser√° nomeado como o diret√≥rio de sa√≠da que voc√™ escolheu (aqui `bert-finetuned-mrpc`), mas voc√™ pode escolher um nome diferente com `hub_model_id = "a_diferent_name"`.

Para enviar seu modelo para uma organiza√ß√£o da qual voc√™ √© membro, basta pass√°-lo com `hub_model_id = "my_organization/my_repo_name"`.

{/if}

Em um n√≠vel inferior, o acesso ao Model Hub pode ser feito diretamente nos modelos, tokenizers e objetos de configura√ß√£o atrav√©s de seu m√©todo `push_to_hub()`. Este m√©todo cuida da cria√ß√£o do reposit√≥rio e empurra os arquivos modelo e tokenizer diretamente para o reposit√≥rio. N√£o √© necess√°rio nenhum tratamento manual, ao contr√°rio do que acontece com a API, veremos abaixo.

Para se ter uma id√©ia de como funciona, vamos primeiro inicializar um modelo e um tokenizer:

{#if fw === 'pt'}
```py
from transformers import AutoModelForMaskedLM, AutoTokenizer

checkpoint = "camembert-base"

model = AutoModelForMaskedLM.from_pretrained(checkpoint)
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
```
{:else}
```py
from transformers import TFAutoModelForMaskedLM, AutoTokenizer

checkpoint = "camembert-base"

model = TFAutoModelForMaskedLM.from_pretrained(checkpoint)
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
```
{/if}

Voc√™ √© livre para fazer o que quiser com elas - adicionar fichas ao tokenizer, treinar o modelo, afinar o modelo. Quando voc√™ estiver satisfeito com o modelo, pesos e tokenizer resultantes, voc√™ pode aproveitar o m√©todo `push_to_hub()` diretamente dispon√≠vel no objeto `model`:

```py
model.push_to_hub("dummy-model")
```

Isto criar√° o novo reposit√≥rio `dummy-model`  em seu perfil, e o preencher√° com seus arquivos de modelos.
Fa√ßa o mesmo com o tokenizer, para que todos os arquivos estejam agora dispon√≠veis neste reposit√≥rio:

```py
tokenizer.push_to_hub("dummy-model")
```

Se voc√™ pertence a uma organiza√ß√£o, basta especificar o argumento `organization` a ser carregado no namespace dessa organiza√ß√£o:

```py
tokenizer.push_to_hub("dummy-model", organization="huggingface")
```

Se voc√™ desejar utilizar um toke espec√≠fica do Hugging Face, voc√™ √© livre para especific√°-la tamb√©m para o m√©todo `push_to_hub()`:

```py
tokenizer.push_to_hub("dummy-model", organization="huggingface", use_auth_token="<TOKEN>")
```

Agora v√° at√© o Model Hub para encontrar seu modelo rec√©m-carregado: *https://huggingface.co/user-or-organization/dummy-model*.

Clique na aba "Files and versions", e voc√™ deve ver os arquivos vis√≠veis na seguinte captura de tela:

{#if fw === 'pt'}
<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/push_to_hub_dummy_model.png" alt="Dummy model containing both the tokenizer and model files." width="80%"/>
</div>
{:else}
<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/push_to_hub_dummy_model_tf.png" alt="Dummy model containing both the tokenizer and model files." width="80%"/>
</div>
{/if}

<Tip>

‚úèÔ∏è **Teste-o!** Pegue o modelo e o tokenizer associados ao checkpoint `bert-base-cased` e carregue-os para um repo em seu namespace utilizando o m√©todo `push_to_hub()`. Verifique novamente se o repo aparece corretamente em sua p√°gina antes de exclu√≠-lo.

</Tip>

Como voc√™ j√° viu, o m√©todo `push_to_hub()` aceita v√°rios argumentos, tornando poss√≠vel carregar para um reposit√≥rio espec√≠fico ou espa√ßo de nomes de organiza√ß√µes, ou utilizar um token API diferente. Recomendamos que voc√™ d√™ uma olhada na especifica√ß√£o do m√©todo dispon√≠vel diretamente na documenta√ß√£o [ü§ó Transformers documentation](https://huggingface.co/transformers/model_sharing.html) para ter uma id√©ia do que √© poss√≠vel.

O m√©todo `push_to_hub()` √© apoiado pelo pacote [`huggingface_hub`](https://github.com/huggingface/huggingface_hub) Python, que oferece uma API direta para o Hub Hugging Face. Est√° integrado ao ü§ó Transformers e v√°rias outras bibliotecas de aprendizagem de m√°quinas, como [`allenlp`](https://github.com/allenai/allennlp). Embora nos concentremos na integra√ß√£o do ü§ó Transformers neste cap√≠tulo, integr√°-lo em seu pr√≥prio c√≥digo ou biblioteca √© simples.

Salte para a √∫ltima se√ß√£o para ver como carregar arquivos em seu reposit√≥rio rec√©m-criado!

## Usando a biblioteca Python `huggingface_hub`

A biblioteca Python`huggingface_hub` √© um pacote que oferece um conjunto de ferramentas para os hubs do modelo e dos conjuntos de dados. Ela fornece m√©todos e classes simples para tarefas comuns como obter informa√ß√µes sobre os reposit√≥rios no centro e gerenci√°-los. Ele fornece APIs simples que funcionam em cima do git para gerenciar o conte√∫do desses reposit√≥rios e para integrar o Hub em seus projetos e bibliotecas.

Da mesma forma que a utiliza√ß√£o da API `push_to_hub`, isto exigir√° que voc√™ tenha seu token API salvo em seu cache. Para fazer isso, voc√™ precisar√° utilizar o comando `login` do CLI, como mencionado na se√ß√£o anterior (mais uma vez, certifique-se de utilizar antes desses comandos o caracter `!` se estiver rodando no Google Colab):

```bash
huggingface-cli login
```

O pacote `huggingface_hub` oferece v√°rios m√©todos e classes que s√£o √∫teis para nosso prop√≥sito. Em primeiro lugar, existem alguns m√©todos para gerenciar a cria√ß√£o de reposit√≥rios, exclus√£o, e outros:

```python no-format
from huggingface_hub import (
    # Gest√£o de usu√°rios
    login,
    logout,
    whoami,

    # Cria√ß√£o e gest√£o de reposit√≥rio
    create_repo,
    delete_repo,
    update_repo_visibility,

    #E alguns m√©todos para recuperar/trocar informa√ß√µes sobre o conte√∫do
    list_models,
    list_datasets,
    list_metrics,
    list_repo_files,
    upload_file,
    delete_file,
)
```


Al√©m disso, oferece uma poderosa classe `Repository` para gerenciar um reposit√≥rio local. Vamos explorar esses m√©todos e essa classe na pr√≥xima se√ß√£o para entender como aproveit√°-los.

O m√©todo `create_repo` pode ser utilizado para criar um novo reposit√≥rio no centro:

```py
from huggingface_hub import create_repo

create_repo("dummy-model")
```

Isto criar√° o reposit√≥rio `dummy-model` em seu namespace. Se desejar, voc√™ pode especificar a que organiza√ß√£o o reposit√≥rio deve pertencer utilizando o argumento `organization`:

```py
from huggingface_hub import create_repo

create_repo("dummy-model", organization="huggingface")
```


Isto criar√° o reposit√≥rio `dummy-model` no espa√ßo de nomes `huggingface`, assumindo que voc√™ perten√ßa a essa organiza√ß√£o.
Outros argumentos que podem ser √∫teis s√£o:

- `private`, a fim de especificar se o reposit√≥rio deve ser vis√≠vel de outros ou n√£o.
- `token`,se voc√™ gostaria de substituir o token armazenada em seu cache por uma determinada token.
- `repo_type`, se voc√™ gostaria de criar um "`dataset` ou um "espa√ßo" em vez de um modelo. Os valores aceitos s√£o `"dataset"`  e `"space"`.

Uma vez criado o reposit√≥rio, devemos adicionar arquivos a ele! Salte para a pr√≥xima se√ß√£o para ver as tr√™s maneiras como isto pode ser tratado.


## Usando a interface web 

A interface web oferece ferramentas para gerenciar os reposit√≥rios diretamente no Hub. Usando a interface, voc√™ pode facilmente criar reposit√≥rios, adicionar arquivos (mesmo grandes!), explorar modelos, visualizar diffs, e muito mais.

Para criar um novo reposit√≥rio, visite [huggingface.co/novo](https://huggingface.co/new):

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/new_model.png" alt="Page showcasing the model used for the creation of a new model repository." width="80%"/>
</div>

Primeiro, especifique o propriet√°rio do reposit√≥rio: este pode ser voc√™ ou qualquer uma das organiza√ß√µes √†s quais voc√™ est√° afiliado. Se voc√™ escolher uma organiza√ß√£o, o modelo ser√° apresentado na p√°gina da organiza√ß√£o e cada membro da organiza√ß√£o ter√° a capacidade de contribuir com o reposit√≥rio.

A seguir, digite o nome do seu modelo. Este tamb√©m ser√° o nome do reposit√≥rio. Finalmente, voc√™ pode especificar se deseja que seu modelo seja p√∫blico ou privado. Os modelos privados n√£o podem ser encontrados publicamente.

Depois de criar seu reposit√≥rio de modelos, voc√™ deve ver uma p√°gina como esta:

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/empty_model.png" alt="An empty model page after creating a new repository." width="80%"/>
</div>

Aqui √© onde seu modelo ser√° hospedado. Para come√ßar a preench√™-lo, voc√™ pode adicionar um arquivo README diretamente da interface web.

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/dummy_model.png" alt="The README file showing the Markdown capabilities." width="80%"/>
</div>

O arquivo README est√° em Markdown - sinta-se √† vontade para ficar louco com ele! A terceira parte deste cap√≠tulo √© dedicada √† constru√ß√£o de um modelo de cart√£o. Estes s√£o de extrema import√¢ncia para trazer valor ao seu modelo, pois est√£o onde voc√™ diz aos outros o que ele pode fazer.

Se voc√™ olhar a aba "Files and versions", voc√™ ver√° que ainda n√£o h√° muitos arquivos - apenas o *README.md* que voc√™ acabou de criar e o arquivo *.gitattributes* que mant√©m o controle de arquivos grandes.

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/files.png" alt="The 'Files and versions' tab only shows the .gitattributes and README.md files." width="80%"/>
</div>

A seguir, veremos como adicionar alguns novos arquivos.

## Fazendo upload dos arquivos de modelos

O sistema para gerenciar arquivos no Hub Hugging Face Hub √© baseado no git para arquivos regulares, e git-lfs (que significa [Git Large File Storage](https://git-lfs.github.com/)) para arquivos maiores. 

Na se√ß√£o seguinte, passamos por tr√™s maneiras diferentes de carregar arquivos no Hub: atrav√©s de `huggingface_hub` e atrav√©s de comandos de git.

### A abordagem: `upload_file`

A utiliza√ß√£o do `upload_file` n√£o requer que git e git-lfs sejam instalados em seu sistema. Ele empurra os arquivos diretamente para o Hub ü§ó utilizando solicita√ß√µes HTTP POST. Uma limita√ß√£o desta abordagem √© que ele n√£o lida com arquivos maiores que 5GB de tamanho.
Se seus arquivos forem maiores que 5GB, por favor, siga os dois outros m√©todos detalhados abaixo.

A API pode ser usada da seguinte forma:

```py
from huggingface_hub import upload_file

upload_file(
    "<path_to_file>/config.json",
    path_in_repo="config.json",
    repo_id="<namespace>/dummy-model",
)
```

Isto far√° o upload do arquivo `config.json` dispon√≠vel em `<path_to_file>` para a raiz do reposit√≥rio como `config.json`, para o reposit√≥rio `dummy-model`.
Outros argumentos que podem ser √∫teis s√£o:

- `token`, se voc√™ gostaria de substituir o token armazenado em seu cache por um determinado token.
- `repo_type`, se voc√™ gostaria de carregar em um `dataset` ou em um `espa√ßo` em vez de um modelo. Os valores aceitos s√£o `"dataset"` e `"space"`.

### A classe: `Repository`

A classe `Repository` gerencia um reposit√≥rio local de forma idiota. Ele resume a maioria dos pontos de dor que se pode ter com o git para fornecer todas as caracter√≠sticas que necessitamos. 

A utiliza√ß√£o desta classe requer ter git e git-lfs instalados, portanto certifique-se de ter o git-lfs instalado (veja [aqui](https://git-lfs.github.com/) para instru√ß√µes de instala√ß√£o) e configure-o antes de come√ßar. 

Para come√ßar a brincar com o reposit√≥rio que acabamos de criar, podemos come√ßar inicializando-o em uma pasta local atrav√©s da clonagem do reposit√≥rio remoto:

```py
from huggingface_hub import Repository

repo = Repository("<path_to_dummy_folder>", clone_from="<namespace>/dummy-model")
```

Isto criou a pasta `<path_to_dummy_folder>` em nosso diret√≥rio de trabalho. Esta pasta cont√©m apenas o arquivo `.gitattributes`, pois este √© o √∫nico arquivo criado ao instanciar o reposit√≥rio atrav√©s do `create_repo`.

A partir deste ponto, podemos aproveitar v√°rios dos m√©todos tradicionais do gitattributes:

```py
repo.git_pull()
repo.git_add()
repo.git_commit()
repo.git_push()
repo.git_tag()
```

E outros! Recomendamos dar uma olhada na documenta√ß√£o `Repository` dispon√≠vel [aqui](https://github.com/huggingface/huggingface_hub/tree/main/src/huggingface_hub#advanced-programmatic-repository-management) para uma vis√£o geral de todos os m√©todos dispon√≠veis.

No momento, temos um modelo e um tokenizer que gostar√≠amos de empurrar para o centro. Clonamos com sucesso o reposit√≥rio, portanto, podemos salvar os arquivos dentro desse reposit√≥rio.

Primeiro nos certificamos de que nosso clone local esteja atualizado, puxando as √∫ltimas mudan√ßas:

```py
repo.git_pull()
```

Uma vez feito isso, salvamos os arquivos do modelo e do tokenizer:

```py
model.save_pretrained("<path_to_dummy_folder>")
tokenizer.save_pretrained("<path_to_dummy_folder>")
```

O `<path_to_dummy_folder>` agora cont√©m todos os modelos e arquivos de fichas. Seguimos o fluxo de trabalho habitual do git, adicionando arquivos √† √°rea de encena√ß√£o, comprometendo-os e empurrando-os para o centro:

```py
repo.git_add()
repo.git_commit("Add model and tokenizer files")
repo.git_push()
```

Parab√©ns! Voc√™ acabou de empurrar seus primeiros arquivos para o centro.

### A abordagem: `baseada em git`

Esta √© a pr√≥pria abordagem do barebone para carregar arquivos: faremos isso com git e git-lfs diretamente. A maior parte da dificuldade √© abstra√≠da por abordagens anteriores, mas h√° algumas advert√™ncias com o seguinte m√©todo, ent√£o seguiremos um caso de uso mais complexo.

O uso desta classe requer ter git e git-lfs instalados, portanto, certifique-se de ter [git-lfs](https://git-lfs.github.com/) instalado (veja aqui as instru√ß√µes de instala√ß√£o) e configurado antes de come√ßar. 

Primeiro comece inicializando o git-lfs:

```bash
git lfs install
```

```bash
Updated git hooks.
Git LFS initialized.
```

Uma vez feito isso, o primeiro passo √© clonar seu reposit√≥rio modelo:

```bash
git clone https://huggingface.co/<namespace>/<your-model-id>
```

Meu nome de usu√°rio √© `lysandre` e j√° utilizei o nome modelo `dummy`, ent√£o para mim o comando acaba parecendo o seguinte:

```
git clone https://huggingface.co/lysandre/dummy
```

Agora tenho uma pasta com o nome *dummy* em meu diret√≥rio de trabalho. Eu posso `cd` dentro da pasta e dar uma olhada no conte√∫do:

```bash
cd dummy && ls
```

```bash
README.md
```

Se voc√™ acabou de criar seu reposit√≥rio utilizando o m√©todo `create_repo` do Hugging Face Hub, esta pasta deve conter apenas um arquivo oculto `.gitattributes`. Se voc√™ seguiu as instru√ß√µes da se√ß√£o anterior para criar um reposit√≥rio utilizando a interface web, a pasta deve conter um √∫nico arquivo *README.md* ao lado do arquivo oculto `.gitattributes`, como mostrado aqui.

Adicionar um arquivo de tamanho normal, como um arquivo de configura√ß√£o, um arquivo de vocabul√°rio, ou basicamente qualquer arquivo sob alguns megabytes, √© feito exatamente como se faria em qualquer sistema baseado no gitattributes. Entretanto, arquivos maiores devem ser registrados atrav√©s do git-lfs a fim de empurr√°-los para *huggingface.co*. 

Vamos voltar a Python para gerar um modelo e tokenizer que gostar√≠amos de comprometer com nosso reposit√≥rio dummy:

{#if fw === 'pt'}
```py
from transformers import AutoModelForMaskedLM, AutoTokenizer

checkpoint = "camembert-base"

model = AutoModelForMaskedLM.from_pretrained(checkpoint)
tokenizer = AutoTokenizer.from_pretrained(checkpoint)

# Do whatever with the model, train it, fine-tune it...

model.save_pretrained("<path_to_dummy_folder>")
tokenizer.save_pretrained("<path_to_dummy_folder>")
```
{:else}
```py
from transformers import TFAutoModelForMaskedLM, AutoTokenizer

checkpoint = "camembert-base"

model = TFAutoModelForMaskedLM.from_pretrained(checkpoint)
tokenizer = AutoTokenizer.from_pretrained(checkpoint)

# Do whatever with the model, train it, fine-tune it...

model.save_pretrained("<path_to_dummy_folder>")
tokenizer.save_pretrained("<path_to_dummy_folder>")
```
{/if}

Agora que salvamos alguns artefatos de modelo e tokenizer, vamos dar outra olhada na pasta *dummy*:

```bash
ls
```

{#if fw === 'pt'}
```bash
config.json  pytorch_model.bin  README.md  sentencepiece.bpe.model  special_tokens_map.json tokenizer_config.json  tokenizer.json
```

Se voc√™ olhar para os tamanhos de arquivo (por exemplo, com `ls -lh`), voc√™ deve ver que o arquivo de estado do modelo (*pytorch_model.bin*) √© o √∫nico outlier, com mais de 400 MB.

{:else}
```bash
config.json  README.md  sentencepiece.bpe.model  special_tokens_map.json  tf_model.h5  tokenizer_config.json  tokenizer.json
```

Se voc√™ olhar para os tamanhos de arquivo (por exemplo, com `ls -lh`), voc√™ deve ver que o arquivo de estado do modelo (*t5_model.h5*) √© o √∫nico outlier, com mais de 400 MB.

{/if}

<Tip>
‚úèÔ∏è Ao criar o reposit√≥rio a partir da interface web, o arquivo *.gitattributes* √© automaticamente configurado para considerar arquivos com certas extens√µes, como *.bin* e *.h5*, como arquivos grandes, e o git-lfs os rastrear√° sem nenhuma configura√ß√£o necess√°ria em seu lado.
</Tip> 

Agora podemos ir em frente e proceder como normalmente far√≠amos com os reposit√≥rios tradicionais da Git. Podemos adicionar todos os arquivos ao ambiente de encena√ß√£o do Git utilizando o comando `git add`:

```bash
git add .
```

Podemos, ent√£o, dar uma olhada nos arquivos que est√£o atualmente em fase de montagem:

```bash
git status
```

{#if fw === 'pt'}
```bash
On branch main
Your branch is up to date with 'origin/main'.

Changes to be committed:
  (use "git restore --staged <file>..." to unstage)
  modified:   .gitattributes
	new file:   config.json
	new file:   pytorch_model.bin
	new file:   sentencepiece.bpe.model
	new file:   special_tokens_map.json
	new file:   tokenizer.json
	new file:   tokenizer_config.json
```
{:else}
```bash
On branch main
Your branch is up to date with 'origin/main'.

Changes to be committed:
  (use "git restore --staged <file>..." to unstage)
  modified:   .gitattributes
  	new file:   config.json
	new file:   sentencepiece.bpe.model
	new file:   special_tokens_map.json
	new file:   tf_model.h5
	new file:   tokenizer.json
	new file:   tokenizer_config.json
```
{/if}

Da mesma forma, podemos ter certeza de que o git-lfs est√° rastreando os arquivos corretos, utilizando seu comando `status`:

```bash
git lfs status
```

{#if fw === 'pt'}
```bash
On branch main
Objects to be pushed to origin/main:


Objects to be committed:

	config.json (Git: bc20ff2)
	pytorch_model.bin (LFS: 35686c2)
	sentencepiece.bpe.model (LFS: 988bc5a)
	special_tokens_map.json (Git: cb23931)
	tokenizer.json (Git: 851ff3e)
	tokenizer_config.json (Git: f0f7783)

Objects not staged for commit:


```

Podemos ver que todos os arquivos t√™m `Git` como manipulador, exceto *pytorch_model.bin* e *sentencepiece.bpe.model*, que t√™m `LFS`. √ìtimo!

{:else}
```bash
On branch main
Objects to be pushed to origin/main:


Objects to be committed:

	config.json (Git: bc20ff2)
	sentencepiece.bpe.model (LFS: 988bc5a)
	special_tokens_map.json (Git: cb23931)
	tf_model.h5 (LFS: 86fce29)
	tokenizer.json (Git: 851ff3e)
	tokenizer_config.json (Git: f0f7783)

Objects not staged for commit:


```

Podemos ver que todos os arquivos t√™m `Git` como manipulador, exceto *t5_model.h5*, que tem `LFS`. Excelente!

{/if}

Vamos prosseguir para as etapas finais, comprometendo-nos e empurrando para o reposit√≥rio remoto *huggingface.co*:

```bash
git commit -m "First model version"
```

{#if fw === 'pt'}
```bash
[main b08aab1] First model version
 7 files changed, 29027 insertions(+)
  6 files changed, 36 insertions(+)
 create mode 100644 config.json
 create mode 100644 pytorch_model.bin
 create mode 100644 sentencepiece.bpe.model
 create mode 100644 special_tokens_map.json
 create mode 100644 tokenizer.json
 create mode 100644 tokenizer_config.json
```
{:else}
```bash
[main b08aab1] First model version
 6 files changed, 36 insertions(+)
 create mode 100644 config.json
 create mode 100644 sentencepiece.bpe.model
 create mode 100644 special_tokens_map.json
 create mode 100644 tf_model.h5
 create mode 100644 tokenizer.json
 create mode 100644 tokenizer_config.json
```
{/if}

O push pode levar um pouco de tempo, dependendo da velocidade de sua conex√£o √† Internet e do tamanho de seus arquivos:

```bash
git push
```

```bash
Uploading LFS objects: 100% (1/1), 433 MB | 1.3 MB/s, done.
Enumerating objects: 11, done.
Counting objects: 100% (11/11), done.
Delta compression using up to 12 threads
Compressing objects: 100% (9/9), done.
Writing objects: 100% (9/9), 288.27 KiB | 6.27 MiB/s, done.
Total 9 (delta 1), reused 0 (delta 0), pack-reused 0
To https://huggingface.co/lysandre/dummy
   891b41d..b08aab1  main -> main
```

{#if fw === 'pt'}
Se dermos uma olhada no reposit√≥rio modelo quando este estiver terminado, podemos ver todos os arquivos recentemente adicionados:

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/full_model.png" alt="The 'Files and versions' tab now contains all the recently uploaded files." width="80%"/>
</div>

A IU permite que voc√™ explore os arquivos modelo e os commits e veja as diferen√ßas introduzidas por cada commit:

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/diffs.gif" alt="The diff introduced by the recent commit." width="80%"/>
</div>
{:else}
Se dermos uma olhada no reposit√≥rio modelo quando este estiver terminado, podemos ver todos os arquivos recentemente adicionados:

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/full_model_tf.png" alt="The 'Files and versions' tab now contains all the recently uploaded files." width="80%"/>
</div>

A IU permite que voc√™ explore os arquivos modelo e os commits e veja as diferen√ßas introduzidas por cada commit:

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/diffstf.gif" alt="The diff introduced by the recent commit." width="80%"/>
</div>
{/if}
