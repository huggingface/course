# Criando seu pr√≥prio dataset

<DocNotebookDropdown
  classNames="absolute z-10 right-0 top-0"
  options={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter5/section5.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter5/section5.ipynb"},
]} />

√Äs vezes, o conjunto de dados de que voc√™ precisa para criar um aplicativo de PLN n√£o existe, portanto, voc√™ mesmo precisar√° cri√°-lo. Nesta se√ß√£o, mostraremos como criar um corpus de [issues do GitHub](https://github.com/features/issues/), que s√£o comumente usados ‚Äã‚Äãpara rastrear bugs ou recursos nos reposit√≥rios do GitHub. Este corpus pode ser usado para v√°rios fins, incluindo:

* Explorar quanto tempo leva para fechar as issues abertos ou pull requests
* Treinar um _classificador multilabel_ que pode marcar issues com metadados com base na descri√ß√£o da issue (por exemplo, "bug", "melhoria" ou "pergunta")
* Criando um mecanismo de pesquisa sem√¢ntica para descobrir quais issues correspondem √† consulta de um usu√°rio

Aqui nos concentraremos na cria√ß√£o do corpus e, na pr√≥xima se√ß√£o, abordaremos o aplicativo de pesquisa sem√¢ntica. Para manter a meta, usaremos as issues do GitHub associados a um projeto de c√≥digo aberto popular: ü§ó Datasets! Vamos dar uma olhada em como obter os dados e explorar as informa√ß√µes contidas nessas edi√ß√µes.

## Obtendo os dados

Voc√™ pode encontrar todos as issues em ü§ó Datasets navegando at√© a [guia de issues](https://github.com/huggingface/datasets/issues) do reposit√≥rio. Conforme mostrado na captura de tela a seguir, no momento da reda√ß√£o, havia 331 issues abertos e 668 fechados.

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter5/datasets-issues.png" alt="The GitHub issues associated with ü§ó Datasets." width="80%"/>
</div>

Se voc√™ clicar em uma dessas issues, ver√° que ele cont√©m um t√≠tulo, uma descri√ß√£o e um conjunto de r√≥tulos que caracterizam a issue. Um exemplo √© mostrado na captura de tela abaixo.

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter5/datasets-issues-single.png" alt="A typical GitHub issue in the ü§ó Datasets repository." width="80%"/>
</div>

Para baixar todos as issues do reposit√≥rio, usaremos a [GitHub REST API](https://docs.github.com/en/rest) para pesquisar o [`Issues` endpoint](https://docs.github. com/en/rest/reference/issues#list-repository-issues). Esse endpoint retorna uma lista de objetos JSON, com cada objeto contendo um grande n√∫mero de campos que incluem o t√≠tulo e a descri√ß√£o, bem como metadados sobre o status da issue e assim por diante.

Uma maneira conveniente de baixar as issues √© por meio da biblioteca `requests`, que √© a maneira padr√£o de fazer solicita√ß√µes HTTP em Python. Voc√™ pode instalar a biblioteca executando:

```python
!pip install requests
```

Uma vez que a biblioteca esteja instalada, voc√™ pode fazer solicita√ß√µes GET para o endpoint `Issues` invocando a fun√ß√£o `requests.get()`. Por exemplo, voc√™ pode executar o seguinte comando para recuperar a primeira issue na primeira p√°gina:

```py
import requests

url = "https://api.github.com/repos/huggingface/datasets/issues?page=1&per_page=1"
response = requests.get(url)
```

O objeto `response` cont√©m muitas informa√ß√µes √∫teis sobre a solicita√ß√£o, incluindo o c√≥digo de status HTTP:

```py
response.status_code
```

```python out
200
```

onde um status `200` significa que a solicita√ß√£o foi bem-sucedida (voc√™ pode encontrar uma lista de poss√≠veis c√≥digos de status HTTP [aqui](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)). O que realmente nos interessa, por√©m, √© o _payload_, que pode ser acessado em v√°rios formatos como bytes, strings ou JSON. Como sabemos que nossas issues est√£o no formato JSON, vamos inspecionar o payload da seguinte forma:

```py
response.json()
```

```python out
[{'url': 'https://api.github.com/repos/huggingface/datasets/issues/2792',
  'repository_url': 'https://api.github.com/repos/huggingface/datasets',
  'labels_url': 'https://api.github.com/repos/huggingface/datasets/issues/2792/labels{/name}',
  'comments_url': 'https://api.github.com/repos/huggingface/datasets/issues/2792/comments',
  'events_url': 'https://api.github.com/repos/huggingface/datasets/issues/2792/events',
  'html_url': 'https://github.com/huggingface/datasets/pull/2792',
  'id': 968650274,
  'node_id': 'MDExOlB1bGxSZXF1ZXN0NzEwNzUyMjc0',
  'number': 2792,
  'title': 'Update GooAQ',
  'user': {'login': 'bhavitvyamalik',
   'id': 19718818,
   'node_id': 'MDQ6VXNlcjE5NzE4ODE4',
   'avatar_url': 'https://avatars.githubusercontent.com/u/19718818?v=4',
   'gravatar_id': '',
   'url': 'https://api.github.com/users/bhavitvyamalik',
   'html_url': 'https://github.com/bhavitvyamalik',
   'followers_url': 'https://api.github.com/users/bhavitvyamalik/followers',
   'following_url': 'https://api.github.com/users/bhavitvyamalik/following{/other_user}',
   'gists_url': 'https://api.github.com/users/bhavitvyamalik/gists{/gist_id}',
   'starred_url': 'https://api.github.com/users/bhavitvyamalik/starred{/owner}{/repo}',
   'subscriptions_url': 'https://api.github.com/users/bhavitvyamalik/subscriptions',
   'organizations_url': 'https://api.github.com/users/bhavitvyamalik/orgs',
   'repos_url': 'https://api.github.com/users/bhavitvyamalik/repos',
   'events_url': 'https://api.github.com/users/bhavitvyamalik/events{/privacy}',
   'received_events_url': 'https://api.github.com/users/bhavitvyamalik/received_events',
   'type': 'User',
   'site_admin': False},
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2021-08-12T11:40:18Z',
  'updated_at': '2021-08-12T12:31:17Z',
  'closed_at': None,
  'author_association': 'CONTRIBUTOR',
  'active_lock_reason': None,
  'pull_request': {'url': 'https://api.github.com/repos/huggingface/datasets/pulls/2792',
   'html_url': 'https://github.com/huggingface/datasets/pull/2792',
   'diff_url': 'https://github.com/huggingface/datasets/pull/2792.diff',
   'patch_url': 'https://github.com/huggingface/datasets/pull/2792.patch'},
  'body': '[GooAQ](https://github.com/allenai/gooaq) dataset was recently updated after splits were added for the same. This PR contains new updated GooAQ with train/val/test splits and updated README as well.',
  'performed_via_github_app': None}]
```

Uau, √© muita informa√ß√£o! Podemos ver campos √∫teis como `title`, `body` e `number` que descrevem a issue, bem como informa√ß√µes sobre o usu√°rio do GitHub que abriu a issue.

<Tip>

‚úèÔ∏è **Experimente!** Clique em alguns dos URLs na carga JSON acima para ter uma ideia de que tipo de informa√ß√£o cada issue do GitHub est√° vinculado.

</Tip>

Conforme descrito na [documenta√ß√£o] do GitHub (https://docs.github.com/en/rest/overview/resources-in-the-rest-api#rate-limiting), as solicita√ß√µes n√£o autenticadas s√£o limitadas a 60 solicita√ß√µes por hora. Embora voc√™ possa aumentar o par√¢metro de consulta `per_page` para reduzir o n√∫mero de solicita√ß√µes feitas, voc√™ ainda atingir√° o limite de taxa em qualquer reposit√≥rio que tenha mais do que alguns milhares de issues. Ent√£o, em vez disso, voc√™ deve seguir as [instru√ß√µes] do GitHub (https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token) sobre como criar um _token de acesso pessoal_ para que voc√™ pode aumentar o limite de taxa para 5.000 solicita√ß√µes por hora. Depois de ter seu token, voc√™ pode inclu√≠-lo como parte do cabe√ßalho da solicita√ß√£o:

```py
GITHUB_TOKEN = xxx  # Copy your GitHub token here
headers = {"Authorization": f"token {GITHUB_TOKEN}"}
```

<Tip warning={true}>

‚ö†Ô∏è N√£o compartilhe um notebook com seu `GITHUB_TOKEN` colado nele. Recomendamos que voc√™ exclua a √∫ltima c√©lula depois de execut√°-la para evitar o vazamento dessas informa√ß√µes acidentalmente. Melhor ainda, armazene o token em um arquivo *.env* e use a [`python-dotenv` library](https://github.com/theskumar/python-dotenv) para carreg√°-lo automaticamente para voc√™ como uma vari√°vel de ambiente.

</Tip>

Agora que temos nosso token de acesso, vamos criar uma fun√ß√£o que possa baixar todas as issues de um reposit√≥rio do GitHub:

```py
import time
import math
from pathlib import Path
import pandas as pd
from tqdm.notebook import tqdm


def fetch_issues(
    owner="huggingface",
    repo="datasets",
    num_issues=10_000,
    rate_limit=5_000,
    issues_path=Path("."),
):
    if not issues_path.is_dir():
        issues_path.mkdir(exist_ok=True)

    batch = []
    all_issues = []
    per_page = 100  # Number of issues to return per page
    num_pages = math.ceil(num_issues / per_page)
    base_url = "https://api.github.com/repos"

    for page in tqdm(range(num_pages)):
        # Query with state=all to get both open and closed issues
        query = f"issues?page={page}&per_page={per_page}&state=all"
        issues = requests.get(f"{base_url}/{owner}/{repo}/{query}", headers=headers)
        batch.extend(issues.json())

        if len(batch) > rate_limit and len(all_issues) < num_issues:
            all_issues.extend(batch)
            batch = []  # Flush batch for next time period
            print(f"Reached GitHub rate limit. Sleeping for one hour ...")
            time.sleep(60 * 60 + 1)

    all_issues.extend(batch)
    df = pd.DataFrame.from_records(all_issues)
    df.to_json(f"{issues_path}/{repo}-issues.jsonl", orient="records", lines=True)
    print(
        f"Downloaded all the issues for {repo}! Dataset stored at {issues_path}/{repo}-issues.jsonl"
    )
```

Agora, quando chamamos `fetch_issues()`, ele far√° o download de todas as issues em lotes para evitar exceder o limite do GitHub no n√∫mero de solicita√ß√µes por hora; o resultado ser√° armazenado em um arquivo _repository_name-issues.jsonl_, onde cada linha √© um objeto JSON que representa uma issue. Vamos usar esta fun√ß√£o para pegar todas as issues de ü§ó Datasets:

```py
# Depending on your internet connection, this can take several minutes to run...
fetch_issues()
```

Depois que as issues forem baixadas, podemos carreg√°-las localmente usando nossas novas habilidades da [se√ß√£o 2](/course/chaper5/2):

```py
issues_dataset = load_dataset("json", data_files="datasets-issues.jsonl", split="train")
issues_dataset
```

```python out
Dataset({
    features: ['url', 'repository_url', 'labels_url', 'comments_url', 'events_url', 'html_url', 'id', 'node_id', 'number', 'title', 'user', 'labels', 'state', 'locked', 'assignee', 'assignees', 'milestone', 'comments', 'created_at', 'updated_at', 'closed_at', 'author_association', 'active_lock_reason', 'pull_request', 'body', 'timeline_url', 'performed_via_github_app'],
    num_rows: 3019
})
```

√ìtimo, criamos nosso primeiro conjunto de dados do zero! Mas por que existem v√°rios milhares de issues quando a [guia Issue](https://github.com/huggingface/datasets/issues) do reposit√≥rio ü§ó Datasets mostra apenas cerca de 1.000 issues no total ü§î? Conforme descrito na [documenta√ß√£o] do GitHub (https://docs.github.com/en/rest/reference/issues#list-issues-assigned-to-the-authenticated-user), isso ocorre porque baixamos todos os pull request tamb√©m:

> A API REST v3 do GitHub considera cada pull request como uma issue, mas nem toda issue √© um pull request. Por esse motivo, os endpoints de "issues" podem retornar issues e solicita√ß√µes de pull na resposta. Voc√™ pode identificar solicita√ß√µes de pull pela chave `pull_request`. Esteja ciente de que o `id` de uma solicita√ß√£o pull retornada de endpoints "issues" ser√° um ID de issue.

Como o conte√∫do das issues e dos pull request s√£o bem diferentes, vamos fazer um pequeno pr√©-processamento para nos permitir distinguir entre eles.

## Limpando os dados

O trecho acima da documenta√ß√£o do GitHub nos diz que a coluna `pull_request` pode ser usada para diferenciar entre issues e solicita√ß√µes de pull request. Vamos olhar para uma amostra aleat√≥ria para ver qual √© a diferen√ßa. Como fizemos na [se√ß√£o 3](/course/chapter5/3), vamos encadear `Dataset.shuffle()` e `Dataset.select()` para criar uma amostra aleat√≥ria e ent√£o compactar o `html_url` e ` pull_request` para que possamos comparar os v√°rios URLs:


```py
sample = issues_dataset.shuffle(seed=666).select(range(3))

# Print out the URL and pull request entries
for url, pr in zip(sample["html_url"], sample["pull_request"]):
    print(f">> URL: {url}")
    print(f">> Pull request: {pr}\n")
```

```python out
>> URL: https://github.com/huggingface/datasets/pull/850
>> Pull request: {'url': 'https://api.github.com/repos/huggingface/datasets/pulls/850', 'html_url': 'https://github.com/huggingface/datasets/pull/850', 'diff_url': 'https://github.com/huggingface/datasets/pull/850.diff', 'patch_url': 'https://github.com/huggingface/datasets/pull/850.patch'}

>> URL: https://github.com/huggingface/datasets/issues/2773
>> Pull request: None

>> URL: https://github.com/huggingface/datasets/pull/783
>> Pull request: {'url': 'https://api.github.com/repos/huggingface/datasets/pulls/783', 'html_url': 'https://github.com/huggingface/datasets/pull/783', 'diff_url': 'https://github.com/huggingface/datasets/pull/783.diff', 'patch_url': 'https://github.com/huggingface/datasets/pull/783.patch'}
```

Aqui podemos ver que cada pull request est√° associado a v√°rios URLs, enquanto as issues comuns t√™m uma entrada `None`. Podemos usar essa distin√ß√£o para criar uma nova coluna `is_pull_request` que verifica se o campo `pull_request` √© `None` ou n√£o:

```py
issues_dataset = issues_dataset.map(
    lambda x: {"is_pull_request": False if x["pull_request"] is None else True}
)
```

<Tip>

‚úèÔ∏è **Experimente!** Calcule o tempo m√©dio que leva para fechar as issues em ü§ó Datasets. Voc√™ pode achar a fun√ß√£o `Dataset.filter()` √∫til para filtrar os pull requests e as issues abertas, e voc√™ pode usar a fun√ß√£o `Dataset.set_format()` para converter o conjunto de dados em um `DataFrame` para que voc√™ possa manipular facilmente os timestamps `created_at` e `closed_at`. Para pontos de b√¥nus, calcule o tempo m√©dio que leva para fechar os pull requests.

</Tip>

Embora possamos continuar a limpar o conjunto de dados descartando ou renomeando algumas colunas, geralmente √© uma boa pr√°tica manter o conjunto de dados o mais "bruto" poss√≠vel neste est√°gio para que possa ser facilmente usado em v√°rios aplicativos.

Antes de enviarmos nosso conjunto de dados para o Hugging Face Hub, vamos lidar com uma coisa que est√° faltando: os coment√°rios associados a cada issue e pull request. Vamos adicion√°-los a seguir - voc√™ adivinhou - a API REST do GitHub!

## Aumentando o conjunto de dados

Conforme mostrado na captura de tela a seguir, os coment√°rios associados a uma issue ou a pull request fornecem uma rica fonte de informa√ß√µes, especialmente se estivermos interessados ‚Äã‚Äãem criar um mecanismo de pesquisa para responder √†s consultas dos usu√°rios sobre a biblioteca.

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter5/datasets-issues-comment.png" alt="Comments associated with an issue about ü§ó Datasets." width="80%"/>
</div>

A API REST do GitHub fornece um [endpoint `Comments`](https://docs.github.com/en/rest/reference/issues#list-issue-comments) que retorna todos os coment√°rios associados a uma issue. Vamos testar o endpoint para ver o que ele retorna:

```py
issue_number = 2792
url = f"https://api.github.com/repos/huggingface/datasets/issues/{issue_number}/comments"
response = requests.get(url, headers=headers)
response.json()
```

```python out
[{'url': 'https://api.github.com/repos/huggingface/datasets/issues/comments/897594128',
  'html_url': 'https://github.com/huggingface/datasets/pull/2792#issuecomment-897594128',
  'issue_url': 'https://api.github.com/repos/huggingface/datasets/issues/2792',
  'id': 897594128,
  'node_id': 'IC_kwDODunzps41gDMQ',
  'user': {'login': 'bhavitvyamalik',
   'id': 19718818,
   'node_id': 'MDQ6VXNlcjE5NzE4ODE4',
   'avatar_url': 'https://avatars.githubusercontent.com/u/19718818?v=4',
   'gravatar_id': '',
   'url': 'https://api.github.com/users/bhavitvyamalik',
   'html_url': 'https://github.com/bhavitvyamalik',
   'followers_url': 'https://api.github.com/users/bhavitvyamalik/followers',
   'following_url': 'https://api.github.com/users/bhavitvyamalik/following{/other_user}',
   'gists_url': 'https://api.github.com/users/bhavitvyamalik/gists{/gist_id}',
   'starred_url': 'https://api.github.com/users/bhavitvyamalik/starred{/owner}{/repo}',
   'subscriptions_url': 'https://api.github.com/users/bhavitvyamalik/subscriptions',
   'organizations_url': 'https://api.github.com/users/bhavitvyamalik/orgs',
   'repos_url': 'https://api.github.com/users/bhavitvyamalik/repos',
   'events_url': 'https://api.github.com/users/bhavitvyamalik/events{/privacy}',
   'received_events_url': 'https://api.github.com/users/bhavitvyamalik/received_events',
   'type': 'User',
   'site_admin': False},
  'created_at': '2021-08-12T12:21:52Z',
  'updated_at': '2021-08-12T12:31:17Z',
  'author_association': 'CONTRIBUTOR',
  'body': "@albertvillanova my tests are failing here:\r\n```\r\ndataset_name = 'gooaq'\r\n\r\n    def test_load_dataset(self, dataset_name):\r\n        configs = self.dataset_tester.load_all_configs(dataset_name, is_local=True)[:1]\r\n>       self.dataset_tester.check_load_dataset(dataset_name, configs, is_local=True, use_local_dummy_data=True)\r\n\r\ntests/test_dataset_common.py:234: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\ntests/test_dataset_common.py:187: in check_load_dataset\r\n    self.parent.assertTrue(len(dataset[split]) > 0)\r\nE   AssertionError: False is not true\r\n```\r\nWhen I try loading dataset on local machine it works fine. Any suggestions on how can I avoid this error?",
  'performed_via_github_app': None}]
```

Podemos ver que o coment√°rio est√° armazenado no campo `body`, ent√£o vamos escrever uma fun√ß√£o simples que retorna todos os coment√°rios associados a uma issue selecionando o conte√∫do do `body` para cada elemento em `response.json()`:

```py
def get_comments(issue_number):
    url = f"https://api.github.com/repos/huggingface/datasets/issues/{issue_number}/comments"
    response = requests.get(url, headers=headers)
    return [r["body"] for r in response.json()]


# Test our function works as expected
get_comments(2792)
```

```python out
["@albertvillanova my tests are failing here:\r\n```\r\ndataset_name = 'gooaq'\r\n\r\n    def test_load_dataset(self, dataset_name):\r\n        configs = self.dataset_tester.load_all_configs(dataset_name, is_local=True)[:1]\r\n>       self.dataset_tester.check_load_dataset(dataset_name, configs, is_local=True, use_local_dummy_data=True)\r\n\r\ntests/test_dataset_common.py:234: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\ntests/test_dataset_common.py:187: in check_load_dataset\r\n    self.parent.assertTrue(len(dataset[split]) > 0)\r\nE   AssertionError: False is not true\r\n```\r\nWhen I try loading dataset on local machine it works fine. Any suggestions on how can I avoid this error?"]
```

Isso parece certo, ent√£o vamos usar `Dataset.map()` para adicionar uma nova coluna `comments` para cada issue em nosso conjunto de dados:

```py
# Depending on your internet connection, this can take a few minutes...
issues_with_comments_dataset = issues_dataset.map(
    lambda x: {"comments": get_comments(x["number"])}
)
```

A etapa final √© salvar o conjunto de dados aumentado junto com nossos dados brutos para que possamos envi√°-los para o Hub:

```py
issues_with_comments_dataset.to_json("issues-datasets-with-comments.jsonl")
```

## Carregando o conjunto de dados para o Hugging Face Hub

<Youtube id="HaN6qCr_Afc"/>

Agora que temos nosso conjunto de dados aumentado, √© hora de envi√°-lo para o Hub para que possamos compartilh√°-lo com a comunidade! Para fazer o upload do conjunto de dados, usaremos a [ü§ó Hub library](https://github.com/huggingface/huggingface_hub), que nos permite interagir com o Hugging Face Hub por meio de uma API Python. ü§ó Hub vem pr√©-instalado com ü§ó Transformers, para que possamos us√°-lo diretamente. Por exemplo, podemos usar a fun√ß√£o `list_datasets()` para obter informa√ß√µes sobre todos os conjuntos de dados p√∫blicos atualmente hospedados no Hub:

```py
from huggingface_hub import list_datasets

all_datasets = list_datasets()
print(f"Number of datasets on Hub: {len(all_datasets)}")
print(all_datasets[0])
```

```python out
Number of datasets on Hub: 1487
Dataset Name: acronym_identification, Tags: ['annotations_creators:expert-generated', 'language_creators:found', 'languages:en', 'licenses:mit', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:structure-prediction', 'task_ids:structure-prediction-other-acronym-identification']
```

Podemos ver que atualmente existem cerca de 1.500 conjuntos de dados no Hub, e a fun√ß√£o `list_datasets()` tamb√©m fornece alguns metadados b√°sicos sobre cada reposit√≥rio de conjuntos de dados.

Para nossos prop√≥sitos, a primeira coisa que precisamos fazer √© criar um novo reposit√≥rio de conjunto de dados no Hub. Para fazer isso, precisamos de um token de autentica√ß√£o, que pode ser obtido primeiro entrando no Hugging Face Hub com a fun√ß√£o `notebook_login()`:

```py
from huggingface_hub import notebook_login

notebook_login()
```

Isso criar√° um widget onde voc√™ poder√° inserir seu nome de usu√°rio e senha, e um token de API ser√° salvo em *~/.huggingface/token*. Se voc√™ estiver executando o c√≥digo em um terminal, poder√° fazer login via CLI:

```bash
huggingface-cli login
```

Feito isso, podemos criar um novo reposit√≥rio de conjunto de dados com a fun√ß√£o `create_repo()`:

```py
from huggingface_hub import create_repo

repo_url = create_repo(name="github-issues", repo_type="dataset")
repo_url
```

```python out
'https://huggingface.co/datasets/lewtun/github-issues'
```

Neste exemplo, criamos um reposit√≥rio de conjunto de dados vazio chamado `github-issues` sob o nome de usu√°rio `lewtun` (o nome de usu√°rio deve ser seu nome de usu√°rio do Hub quando voc√™ estiver executando este c√≥digo!).

<Tip>

‚úèÔ∏è **Experimente!** Use seu nome de usu√°rio e senha do Hugging Face Hub para obter um token e criar um reposit√≥rio vazio chamado `github-issues`. Lembre-se de **nunca salvar suas credenciais** no Colab ou em qualquer outro reposit√≥rio, pois essas informa√ß√µes podem ser exploradas por agentes mal-intencionados.

</Tip>

Em seguida, vamos clonar o reposit√≥rio do Hub para nossa m√°quina local e copiar nosso arquivo de conjunto de dados para ele. O ü§ó Hub fornece uma classe `Repository` √∫til que envolve muitos dos comandos comuns do Git, portanto, para clonar o reposit√≥rio remoto, basta fornecer o URL e o caminho local para o qual desejamos clonar:


```py
from huggingface_hub import Repository

repo = Repository(local_dir="github-issues", clone_from=repo_url)
!cp datasets-issues-with-comments.jsonl github-issues/
```

Por padr√£o, v√°rias extens√µes de arquivo (como *.bin*, *.gz* e *.zip*) s√£o rastreadas com o Git LFS para que arquivos grandes possam ser versionados no mesmo fluxo de trabalho do Git. Voc√™ pode encontrar uma lista de extens√µes de arquivos rastreados dentro do arquivo *.gitattributes* do reposit√≥rio. Para incluir o formato JSON Lines na lista, podemos executar o seguinte comando:

```py
repo.lfs_track("*.jsonl")
```

Ent√£o podemos usar `Repository.push_to_hub()` para enviar o conjunto de dados para o Hub:

```py
repo.push_to_hub()
```

Se navegarmos para a URL contida em `repo_url`, veremos agora que nosso arquivo de conjunto de dados foi carregado.

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter5/hub-repo.png" alt="Our dataset repository on the Hugging Face Hub." width="80%"/>
</div>

A partir daqui, qualquer um pode baixar o conjunto de dados simplesmente fornecendo `load_dataset()` com o ID do reposit√≥rio como o argumento `path`:

```py
remote_dataset = load_dataset("lewtun/github-issues", split="train")
remote_dataset
```

```python out
Dataset({
    features: ['url', 'repository_url', 'labels_url', 'comments_url', 'events_url', 'html_url', 'id', 'node_id', 'number', 'title', 'user', 'labels', 'state', 'locked', 'assignee', 'assignees', 'milestone', 'comments', 'created_at', 'updated_at', 'closed_at', 'author_association', 'active_lock_reason', 'pull_request', 'body', 'performed_via_github_app', 'is_pull_request'],
    num_rows: 2855
})
```

Legal, n√≥s enviamos nosso conjunto de dados para o Hub e est√° dispon√≠vel para outros usarem! H√° apenas uma coisa importante a fazer: adicionar um _cart√£o de conjunto de dados_ que explica como o corpus foi criado e fornece outras informa√ß√µes √∫teis para a comunidade.

<Tip>

üí° Voc√™ tamb√©m pode enviar um conjunto de dados para o Hugging Face Hub diretamente do terminal usando `huggingface-cli` e um pouco de magia Git. Consulte o [guia do ü§ó Datasets](https://huggingface.co/docs/datasets/share.html#add-a-community-dataset) para obter detalhes sobre como fazer isso.

</Tip>

## Criando um cart√£o do datasets

Conjuntos de dados bem documentados s√£o mais propensos a serem √∫teis para outras pessoas (incluindo voc√™ mesmo no futuro!), pois fornecem o contexto para permitir que os usu√°rios decidam se o conjunto de dados √© relevante para sua tarefa e avaliem poss√≠veis vieses ou riscos associados ao uso o conjunto de dados.

No Hugging Face Hub, essas informa√ß√µes s√£o armazenadas no arquivo *README.md* de cada reposit√≥rio de conjunto de dados. H√° duas etapas principais que voc√™ deve seguir antes de criar este arquivo:

1. Use a aplica√ß√£o [`datasets-tagging`](https://huggingface.co/datasets/tagging/) para criar tags de metadados no formato YAML. Essas tags s√£o usadas para uma variedade de recursos de pesquisa no Hugging Face Hub e garantem que seu conjunto de dados possa ser facilmente encontrado pelos membros da comunidade. Como criamos um conjunto de dados personalizado aqui, voc√™ precisar√° clonar o reposit√≥rio `datasets-tagging` e executar o aplicativo localmente. Veja como √© a interface:

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter5/datasets-tagger.png" alt="The `datasets-tagging` interface." width="80%"/>
</div>

2. Leia o [guia do ü§ó datasets](https://github.com/huggingface/datasets/blob/master/templates/README_guide.md) sobre como criar cart√µes informativos de conjuntos de dados e use-os como modelo.

Voc√™ pode criar o arquivo *README.md* diretamente no Hub e encontrar um cart√£o de conjunto de dados de modelo no reposit√≥rio de conjunto de dados `lewtun/github-issues`. Uma captura de tela do cart√£o de conjunto de dados preenchido √© mostrada abaixo.

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter5/dataset-card.png" alt="A dataset card." width="80%"/>
</div>

<Tip>

‚úèÔ∏è **Experimente!** Use o aplicativo `dataset-tagging` e [guia do ü§ó datasets](https://github.com/huggingface/datasets/blob/master/templates/README_guide.md) para concluir o *Arquivo README.md* para o conjunto de dados de issues do GitHub.

</Tip>

√â isso! Vimos nesta se√ß√£o que criar um bom conjunto de dados pode ser bastante complicado, mas felizmente carreg√°-lo e compartilh√°-lo com a comunidade n√£o √©. Na pr√≥xima se√ß√£o, usaremos nosso novo conjunto de dados para criar um mecanismo de pesquisa sem√¢ntica com o ü§ó datasets que podem corresponder perguntas as issues e coment√°rios mais relevantes.

<Tip>

‚úèÔ∏è **Experimente!** Siga as etapas que seguimos nesta se√ß√£o para criar um conjunto de dados de issues do GitHub para sua biblioteca de c√≥digo aberto favorita (escolha algo diferente do ü§ó datasets, √© claro!). Para pontos de b√¥nus, ajuste um classificador multilabel para prever as tags presentes no campo `labels`.

</Tip>


