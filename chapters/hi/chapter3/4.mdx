# рдПрдХ рдкреВрд░реНрдг рдкреНрд░рд╢рд┐рдХреНрд╖рдг

<DocNotebookDropdown
  classNames="absolute z-10 right-0 top-0"
  options={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter3/section4.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter3/section4.ipynb"},
]} />

<Youtube id="Dh9CL8fyG80"/>

рдЕрдм рд╣рдо рджреЗрдЦреЗрдВрдЧреЗ рдХрд┐ `Trainer` рдХреНрд▓рд╛рд╕ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд┐рдП рдмрд┐рдирд╛ рдХреИрд╕реЗ рд╣рдо рд╕рдорд╛рди  рдкрд░рд┐рдгрд╛рдо рдкреНрд░рд╛рдкреНрдд рдХрд░реЗ рдЬреИрд╕рд╛ рдХреА рд╣рдордиреЗ рдкрд┐рдЫрд▓реЗ рдЦрдВрдб рдкреНрд░рд╛рдкреНрдд рдХрд┐рдпрд╛ рдерд╛ред рдлрд┐рд░ рд╕реЗ, рд╣рдо рдорд╛рдирддреЗ рд╣реИрдВ рдХрд┐ рдЖрдкрдиреЗ рдЕрдиреБрднрд╛рдЧ 2 рдореЗрдВ рдбреЗрдЯрд╛ рдкреНрд░рд╕рдВрд╕реНрдХрд░рдг рдпрд╛рдирд┐ рдбреЗрдЯрд╛ рдкреНрд░реЛрд╕реЗрд╕рд┐рдВрдЧ рдХрд░ рд▓реА рд╣реИред рдпрд╣рд╛рдВ рдПрдХ рд╕рдВрдХреНрд╖рд┐рдкреНрдд рд╕рд╛рд░рд╛рдВрд╢ рджрд┐рдпрд╛ рдЧрдпрд╛ рд╣реИ рдЬреЛ рд╡рд╣ рд╕рдм рдХреБрдЫ рд╢рд╛рдорд┐рд▓ рдХрд░ рд░рд╣рд╛ рд╣реИ рдЬрд┐рд╕рдХреА рдЖрдкрдХреЛ рдЖрд╡рд╢реНрдпрдХрддрд╛ рд╣реЛрдЧреА:

```py
from datasets import load_dataset
from transformers import AutoTokenizer, DataCollatorWithPadding

raw_datasets = load_dataset("glue", "mrpc")
checkpoint = "bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)


def tokenize_function(example):
    return tokenizer(example["sentence1"], example["sentence2"], truncation=True)


tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)
data_collator = DataCollatorWithPadding(tokenizer=tokenizer)
```

### рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдХреЗ рд▓рд┐рдП рддреИрдпрд╛рд░ рдХрд░реЗрдВ

рд╣рдорд╛рд░реЗ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рд▓реВрдк рд╡рд╛рд╕реНрддрд╡ рдореЗрдВ рд▓рд┐рдЦрдиреЗ рд╕реЗ рдкрд╣рд▓реЗ, рд╣рдореЗрдВ рдХреБрдЫ рд╡рд╕реНрддреБрдУрдВ рдХреЛ рдкрд░рд┐рднрд╛рд╖рд┐рдд рдХрд░рдиреЗ рдХреА рдЖрд╡рд╢реНрдпрдХрддрд╛ рд╣реЛрдЧреАред рдкрд╣рд▓реЗ рд╣реИ рдбреЗрдЯрд╛рд▓реЛрдбрд░реНрд╕  рдЬрд┐рдирдХрд╛ рдЙрдкрдпреЛрдЧ рд╣рдо рдмреИрдЪреЛрдВ рдкрд░ рдкреБрдирд░рд╛рд╡реГрддрд┐ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдХрд░реЗрдВрдЧреЗред рд▓реЗрдХрд┐рди рдЗрд╕рд╕реЗ рдкрд╣рд▓реЗ рдХрд┐ рд╣рдо рдЙрди рдбреЗрдЯрд╛рд▓реЛрдбрд░реНрд╕ рдХреЛ рдкрд░рд┐рднрд╛рд╖рд┐рдд рдХрд░ рд╕рдХреЗ, рд╣рдореЗрдВ рдЕрдкрдиреЗ `tokenized_datasets` рдореЗрдВ рдХреБрдЫ рдкреЛрд╕реНрдЯрдкреНрд░реЛрд╕реЗрд╕рд┐рдВрдЧ рд▓рд╛рдЧреВ рдХрд░рдиреЗ рдХреА рдЬрд░реВрд░рдд рд╣реИ, рддрд╛рдХрд┐ рдХреБрдЫ рдЪреАрдЬреЛрдВ рдХрд╛ рдЦреНрдпрд╛рд▓ рд░рдЦрд╛ рдЬрд╛ рд╕рдХреЗ рдЬреЛ `Trainer` рдиреЗ рд╣рдорд╛рд░реЗ рд▓рд┐рдП рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рд░реВрдк рд╕реЗ рдХрд┐рдпрд╛ рдерд╛ред рд╡рд┐рд╢реЗрд╖ рд░реВрдк рд╕реЗ, рд╣рдореЗрдВ рдЬрд░реВрд░рдд рд╣реИ рдХреА:

- рдЙрди рд╡реИрд▓реНрдпреВрдЬ рдХреЗ рдЕрдиреБрд░реВрдк рдХреЙрд▓рдо рдирд┐рдХрд╛рд▓реЗрдВ рдЬрд┐рдирдХреА рдореЙрдбрд▓ рдЕрдкреЗрдХреНрд╖рд╛ рдирд╣реАрдВ рдХрд░рддрд╛ (рдЬреИрд╕реЗ `sentence1` рдФрд░ `sentence2` рдХреЙрд▓рдо)ред
- рдХреЙрд▓рдо `label` рдХрд╛ рдирд╛рдо рдмрджрд▓рдХрд░ `labels` рдХрд░ рджреЗрдВ (рдХреНрдпреЛрдВрдХрд┐ рдореЙрдбрд▓ рдЙрдореНрдореАрдж рдХрд░рддрд╛ рд╣реИ рдХреА рд╡рд┐рддрд░реНрдХ рдХрд╛ рдирд╛рдо `labels` рд╣реЛ)ред
- рдбреЗрдЯрд╛рд╕реЗрдЯ рдХрд╛ рдкреНрд░рд╛рд░реВрдк рд╕реЗрдЯ рдХрд░реЗрдВ рддрд╛рдХрд┐ рд╡реЗ рд╕реВрдЪрд┐рдпреЛрдВ рдХреЗ рдмрдЬрд╛рдп PyTorch рдЯреЗрдВрд╕рд░ рд▓реМрдЯрд╛рдПрдВред

рд╣рдорд╛рд░реЗ `tokenized_datasets` рдореЗрдВ рдЙрдирдореЗ рд╕реЗ рдкреНрд░рддреНрдпреЗрдХ рдЪрд░рдг рдХреЗ рд▓рд┐рдП рдПрдХ рд╡рд┐рдзрд┐ рд╣реИ:

```py
tokenized_datasets = tokenized_datasets.remove_columns(["sentence1", "sentence2", "idx"])
tokenized_datasets = tokenized_datasets.rename_column("label", "labels")
tokenized_datasets.set_format("torch")
tokenized_datasets["train"].column_names
```

рд╣рдо рдлрд┐рд░ рдЬрд╛рдВрдЪ рд╕рдХрддреЗ рд╣реИрдВ рдХрд┐ рдкрд░рд┐рдгрд╛рдо рдореЗрдВ рдХреЗрд╡рд▓ рдХреЙрд▓рдо рд╣реИ рдЬрд┐рдиреНрд╣реЗрдВ рд╣рдорд╛рд░рд╛ рдореЙрдбрд▓ рд╕реНрд╡реАрдХрд╛рд░ рдХрд░реЗрдЧрд╛:

```python
["attention_mask", "input_ids", "labels", "token_type_ids"]
```

рдЕрдм рдЬрдм рдпрд╣ рд╣реЛ рдЧрдпрд╛ рд╣реИ, рддреЛ рд╣рдо рдЖрд╕рд╛рдиреА рд╕реЗ рдЕрдкрдиреЗ рдбреЗрдЯрд╛рд▓реЛрдбрд░реНрд╕ рдХреЛ рдкрд░рд┐рднрд╛рд╖рд┐рдд рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ:

```py
from torch.utils.data import DataLoader

train_dataloader = DataLoader(
    tokenized_datasets["train"], shuffle=True, batch_size=8, collate_fn=data_collator
)
eval_dataloader = DataLoader(
    tokenized_datasets["validation"], batch_size=8, collate_fn=data_collator
)
```

рдпрд╣ рдЬрд╛рдВрдЪрдиреЗ рдХреЗ рд▓рд┐рдП рдХрд┐ рдбреЗрдЯрд╛ рдкреНрд░реЛрд╕реЗрд╕рд┐рдВрдЧ рдореЗрдВ рдХреЛрдИ рдЧрд▓рддреА рддреЛ рдирд╣реАрдВ рд╣реИ, рд╣рдо рдЗрд╕ рддрд░рд╣ рдПрдХ рдмреИрдЪ рдХрд╛ рдирд┐рд░реАрдХреНрд╖рдг рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ:

```py
for batch in train_dataloader:
    break
{k: v.shape for k, v in batch.items()}
```

```python out
{'attention_mask': torch.Size([8, 65]),
 'input_ids': torch.Size([8, 65]),
 'labels': torch.Size([8]),
 'token_type_ids': torch.Size([8, 65])}
```

рдзреНрдпрд╛рди рджреЗрдВ рдХрд┐ рд╡рд╛рд╕реНрддрд╡рд┐рдХ рдЖрдХрд╛рд░ рдЖрдкрдХреЗ рд▓рд┐рдП рд╢рд╛рдпрдж рдереЛрдбрд╝рд╛ рдЕрд▓рдЧ рд╣реЛрдЧрд╛ рдХреНрдпреЛрдВрдХрд┐ рд╣рдордиреЗ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдбреЗрдЯрд╛рд▓реЛрдбрд░ рдХреЗ рд▓рд┐рдП `shuffle=True` рд╕реЗрдЯ рдХрд┐рдпрд╛ рд╣реИ рдФрд░ рд╣рдо рдмреИрдЪ рдХреЗ рдЕрдВрджрд░ рдЕрдзрд┐рдХрддрдо рд▓рдВрдмрд╛рдИ рддрдХ рдкреИрдбрд┐рдВрдЧ рдХрд░ рд░рд╣реЗ рд╣реИрдВред

рдЕрдм рдЬрдмрдХрд┐ рд╣рдо рдбреЗрдЯрд╛ рдкреНрд░реАрдкреНрд░реЛрд╕реЗрд╕рд┐рдВрдЧ (рдПрдХ рд╕рдВрддреЛрд╖рдЬрдирдХ рд▓реЗрдХрд┐рди рдорд╛рдпрд╛рд╡реА рд▓рдХреНрд╖реНрдп рдХрд┐рд╕реА рднреА ML рдкреНрд░реИрдХреНрдЯрд┐рд╢рдирд░ рдХреЗ рд▓рд┐рдП) рдХреЗ рд╕рд╛рде рдкреВрд░реА рддрд░рд╣ рд╕реЗ рд╕рдорд╛рдкреНрдд рдХрд░ рдЪреБрдХреЗ рд╣реИрдВ, рдЖрдЗрдП рдореЙрдбрд▓ рдХреА рдУрд░ рдореБрдбрд╝реЗрдВред рд╣рдо рдЗрд╕реЗ рдареАрдХ рд╡реИрд╕реЗ рд╣реА рдЗрдиреНрд╕реНрдЯреИрдиреНрд╢реАрдРрдЯ рдХрд░рддреЗ рд╣реИрдВ рдЬреИрд╕реЗ рд╣рдордиреЗ рдкрд┐рдЫрд▓реЗ рд╕реЗрдХреНрд╢рди рдореЗрдВ рдХрд┐рдпрд╛ рдерд╛:

```py
from transformers import AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)
```

рдпрд╣ рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдХрд┐ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдХреЗ рджреМрд░рд╛рди рд╕рдм рдХреБрдЫ рд╕реБрдЪрд╛рд░реВ рд░реВрдк рд╕реЗ рдЪрд▓реЗ, рд╣рдо рдЕрдкрдиреЗ рдмреИрдЪ рдХреЛ рдЗрд╕ рдореЙрдбрд▓ рдореЗрдВ рдкрд╛рд╕ рдХрд░рддреЗ рд╣реИрдВ:

```py
outputs = model(**batch)
print(outputs.loss, outputs.logits.shape)
```

```python out
tensor(0.5441, grad_fn=<NllLossBackward>) torch.Size([8, 2])
```

рд╕рднреА ЁЯдЧ рдЯреНрд░рд╛рдВрд╕рдлреЙрд░реНрдорд░ рдореЙрдбрд▓ рд▓реЙрд╕ рд▓реМрдЯрд╛рдПрдВрдЧреЗ рдЬрдм `labels` рдкреНрд░рджрд╛рди рдХрд┐рдпрд╛ рдЬрд╛рддреЗ рд╣реИ, рдФрд░ рд╣рдореЗрдВ logits рднреА рдорд┐рд▓рддреЗ рд╣реИрдВ (рд╣рдорд╛рд░реЗ рдмреИрдЪ рдореЗрдВ рдкреНрд░рддреНрдпреЗрдХ рдЗрдирдкреБрдЯ рдХреЗ рд▓рд┐рдП рджреЛ, рдЗрд╕рд▓рд┐рдП рдЯреЗрдВрд╕рд░ рдЖрдХрд╛рд░ рдХрд╛ 8 x 2)ред

рд╣рдо рдЕрдкрдирд╛ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рд▓реВрдк рд▓рд┐рдЦрдиреЗ рдХреЗ рд▓рд┐рдП рд▓рдЧрднрдЧ рддреИрдпрд╛рд░ рд╣реИрдВ! рд╣рдо рдХреЗрд╡рд▓ рджреЛ рдЪреАрдЬреЗрдВ рдЦреЛ рд░рд╣реЗ рд╣реИрдВ: рдПрдХ рдСрдкреНрдЯрд┐рдорд╛рдЗрдЬрд╝рд░ рдФрд░ рдПрдХ рд▓рд░реНрдирд┐рдВрдЧ рд░реЗрдЯ рдЕрдиреБрд╕реВрдЪрдХред рдЪреВрдВрдХрд┐ `Trainer` рдЬреЛ рдХрд░ рд░рд╣рд╛ рдерд╛ рдЙрд╕реЗ рд╣рдо рдЦреБрдж рд╕реЗ рджреЛрд╣рд░рд╛рдиреЗ рдХреА рдХреЛрд╢рд┐рд╢ рдХрд░ рд░рд╣реЗ рд╣реИрдВ, рддреЛ рд╣рдо рдЙрдиреНрд╣реА рдбрд┐рдлрд╝реЙрд▓реНрдЯ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВрдЧреЗред `Trainer` рджреНрд╡рд╛рд░рд╛ рдЙрдкрдпреЛрдЧ рдХрд┐рдпрд╛ рдЬрд╛рдиреЗ рд╡рд╛рд▓рд╛ рдСрдкреНрдЯрд┐рдорд╛рдЗрдЬрд╝рд░ `AdamW` рд╣реИ, рдЬреЛ Adam рдХреЗ рд╕рдорд╛рди рд╣реИ, рд▓реЗрдХрд┐рди рдПрдХ рдореЛрдбрд╝ рдХреЗ рд╕рд╛рде рд╡рдЬрди рдХреНрд╖рдп рдирд┐рдпрдорд┐рддреАрдХрд░рдг рдХреЗ рд▓рд┐рдП (рдЗрд▓реНрдпрд╛ рд▓реЛрд╢рд┐рд▓реЛрд╡ рдФрд░ рдлреНрд░реИрдВрдХ рд╣рдЯрд░ рджреНрд╡рд╛рд░рд╛ ["рдбреАрдХрдкрд▓рдб рд╡реЗрдЯ рдбреЗрдХреЗ рд░реЗрдЧреБрд▓рд░рд╛рдЗрдЬреЗрд╢рди"](https://arxiv.org/abs/1711.05101) рджреЗрдЦреЗрдВ):

```py
from transformers import AdamW

optimizer = AdamW(model.parameters(), lr=5e-5)
```

рдЕрдВрдд рдореЗрдВ, рд▓рд░реНрдирд┐рдВрдЧ рд░реЗрдЯ рдЕрдиреБрд╕реВрдЪрдХ рдЬрд┐рд╕реЗ рдбрд┐рдлрд╝реЙрд▓реНрдЯ рд░реВрдк рд╕реЗ рдЙрдкрдпреЛрдЧ рдХрд┐рдпрд╛ рдЬрд╛рддрд╛ рд╣реИ рдХреЗрд╡рд▓ рдПрдХ рд░реИрдЦрд┐рдХ рдХреНрд╖рдп рд╣реИ рдЬреЛ рдЕрдзрд┐рдХрддрдо рдореВрд▓реНрдп (5e-5) рд╕реЗ 0 рддрдХ рд╣реИред рдЗрд╕реЗ рдареАрдХ рд╕реЗ рдкрд░рд┐рднрд╛рд╖рд┐рдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП, рд╣рдореЗрдВ рдпрд╣ рдЬрд╛рдирдирд╛ рд╣реЛрдЧрд╛ рдХрд┐ рд╣рдо рдХрд┐рддрдиреЗ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдХрджрдо рдЙрдард╛рдПрдВрдЧреЗ, рдЬреЛ рдХрд┐ рд╣реИ рдпреБрдЧреЛрдВ рдпрд╛рдирд┐ рдПрдкреЛрдХ рдХреА рд╕рдВрдЦреНрдпрд╛ рдЬрд┐рдиреНрд╣реЗ рд╣рдореЗ рд░рди рдХрд░рдирд╛ рд╣реИ рдЙрд╕рдХрд╛ рдЧреБрдгрд╛ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдмреИрдЪреЛрдВ рдХреА рд╕рдВрдЦреНрдпрд╛ рд╕реЗ рдХрд░рдирд╛ (рдЬреЛ рдХрд┐ рд╣рдорд╛рд░реЗ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдбреЗрдЯрд╛рд▓реЛрдбрд░ рдХреА рд▓рдВрдмрд╛рдИ рд╣реИ)ред `Trainer` рдбрд┐рдлрд╝реЙрд▓реНрдЯ рд░реВрдк рд╕реЗ рддреАрди рдпреБрдЧреЛрдВ рдпрд╛рдирд┐ рдПрдкреЛрдХ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рддрд╛ рд╣реИ, рдЗрд╕рд▓рд┐рдП рд╣рдо рдЙрд╕рдХрд╛ рдЕрдиреБрд╕рд░рдг рдХрд░реЗрдВрдЧреЗ:

```py
from transformers import get_scheduler

num_epochs = 3
num_training_steps = num_epochs * len(train_dataloader)
lr_scheduler = get_scheduler(
    "linear",
    optimizer=optimizer,
    num_warmup_steps=0,
    num_training_steps=num_training_steps,
)
print(num_training_steps)
```

```python out
1377
```

### рдЯреНрд░реЗрдирд┐рдВрдЧ рд▓реВрдк

рдПрдХ рдЖрдЦрд┐рд░реА рдмрд╛рдд: рд╣рдо GPU рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдирд╛ рдЪрд╛рд╣реЗрдВрдЧреЗ рдЕрдЧрд░ рд╣рдорд╛рд░реЗ рдкрд╛рд╕ рдПрдХ рдХрд╛ рдПрдХреНрд╕реЗрд╕ рд╣реИ рддреЛ (CPU рдкрд░, рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдореЗрдВ рдХреБрдЫ рдорд┐рдирдЯреЛрдВ рдХреЗ рдмрдЬрд╛рдп рдХрдИ рдШрдВрдЯреЗ рд▓рдЧ рд╕рдХрддреЗ рд╣реИрдВ)ред рдРрд╕рд╛ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП, рд╣рдо рдПрдХ `device` рдХреЛ рдкрд░рд┐рднрд╛рд╖рд┐рдд рдХрд░реЗрдВрдЧреЗ, рдЬрд┐рд╕ рдкрд░ рд╣рдо рдЕрдкрдиреЗ рдореЙрдбрд▓ рдХреЛ рдФрд░ рдЕрдкрдиреЗ рдмреИрдЪреЛрдВ рдХреЛ рд░рдЦреЗрдВрдЧреЗ:

```py
import torch

device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
model.to(device)
device
```

```python out
device(type='cuda')
```

рдЕрдм рд╣рдо рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдХреЗ рд▓рд┐рдП рддреИрдпрд╛рд░ рд╣реИрдВ! рдпрд╣ рдЬрд╛рдирдиреЗ рдХреЗ рд▓рд┐рдП рдХрд┐ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдХрдм рд╕рдорд╛рдкреНрдд рд╣реЛрдЧрд╛, рд╣рдо `tqdm` рд▓рд╛рдЗрдмреНрд░реЗрд░реА рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рдЕрдкрдиреЗ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдЪрд░рдгреЛрдВ рдХреА рд╕рдВрдЦреНрдпрд╛ рдкрд░ рдПрдХ рдкреНрд░рдЧрддрд┐ рдкрдЯреНрдЯреА рдЬреЛреЬреЗрдЧреЗ:

```py
from tqdm.auto import tqdm

progress_bar = tqdm(range(num_training_steps))

model.train()
for epoch in range(num_epochs):
    for batch in train_dataloader:
        batch = {k: v.to(device) for k, v in batch.items()}
        outputs = model(**batch)
        loss = outputs.loss
        loss.backward()

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(1)
```

рдЖрдк рджреЗрдЦ рд╕рдХрддреЗ рд╣реИрдВ рдХрд┐ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рд▓реВрдк рдХрд╛ рдореВрд▓ рдЬреЛ рдкрд░рд┐рдЪрдп рдореЗрдВ рд╣реИ рдЙрд╕рдХреЗ рд╕рдорд╛рди рджрд┐рдЦрддрд╛ рд╣реИред рд╣рдордиреЗ рдХреЛрдИ рд░рд┐рдкреЛрд░реНрдЯрд┐рдВрдЧ рдирд╣реАрдВ рдорд╛рдВрдЧреА, рдЗрд╕рд▓рд┐рдП рдпрд╣ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рд▓реВрдк рд╣рдореЗрдВ рдЗрд╕ рдмрд╛рд░реЗ рдореЗрдВ рдХреБрдЫ рдирд╣реАрдВ рдмрддрд╛рдПрдЧрд╛ рдХрд┐ рдореЙрдбрд▓ рдХрд╛ рдХрд┐рд░рд╛рдпрд╛ рдХреИрд╕рд╛ рд╣реИред рд╣рдореЗрдВ рдЙрд╕рдХреЗ рд▓рд┐рдП рдПрдХ рдореВрд▓реНрдпрд╛рдВрдХрди рд▓реВрдк рдЬреЛрдбрд╝рдиреЗ рдХреА рдЬрд░реВрд░рдд рд╣реИред


### рдореВрд▓реНрдпрд╛рдВрдХрди рд▓реВрдк

рдЬреИрд╕рд╛ рдХрд┐ рд╣рдордиреЗ рдкрд╣рд▓реЗ рдХрд┐рдпрд╛ рдерд╛, рд╣рдо ЁЯдЧ рдореВрд▓реНрдпрд╛рдВрдХрди рдХрд░рдирд╛ рд▓рд╛рдЗрдмреНрд░реЗрд░реА рджреНрд╡рд╛рд░рд╛ рдкреНрд░рджрд╛рди рдХрд┐рдП рдЧрдП рдореАрдЯреНрд░рд┐рдХ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВрдЧреЗред рд╣рдо рдкрд╣рд▓реЗ рд╣реА `metric.compute()` рд╡рд┐рдзрд┐ рджреЗрдЦ рдЪреБрдХреЗ рд╣реИрдВ, рд▓реЗрдХрд┐рди рдореЗрдЯреНрд░рд┐рдХреНрд╕ рд╡рд╛рд╕реНрддрд╡ рдореЗрдВ рд╣рдорд╛рд░реЗ рд▓рд┐рдП рдмреИрдЪ рдЬрдорд╛ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ рдЬрдм рд╣рдо рднрд╡рд┐рд╖реНрдпрд╡рд╛рдгреА рд▓реВрдк рдкрд░ рдЬрд╛рддреЗ рд╣реИрдВ `add_batch()` рд╡рд┐рдзрд┐ рдХреЗ рд╕рд╛рде ред рдПрдХ рдмрд╛рд░ рдЬрдм рд╣рдо рд╕рднреА рдмреИрдЪреЛрдВ рдХреЛ рдЬрдорд╛ рдХрд░ рд▓реЗрддреЗ рд╣реИрдВ, рддреЛ рд╣рдо `metric.compute()` рдХреЗ рд╕рд╛рде рдЕрдВрддрд┐рдо рдкрд░рд┐рдгрд╛рдо рдкреНрд░рд╛рдкреНрдд рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред рдореВрд▓реНрдпрд╛рдВрдХрди рд▓реВрдк рдореЗрдВ рдЗрди рд╕рднреА рдХреЛ рдХрд╛рд░реНрдпрд╛рдиреНрд╡рд┐рдд рдХрд░рдиреЗ рдХрд╛ рддрд░реАрдХрд╛ рдпрд╣рд╛рдВ рджрд┐рдпрд╛ рдЧрдпрд╛ рд╣реИ:

```py
import evaluate

metric = evaluate.load("glue", "mrpc")
model.eval()
for batch in eval_dataloader:
    batch = {k: v.to(device) for k, v in batch.items()}
    with torch.no_grad():
        outputs = model(**batch)

    logits = outputs.logits
    predictions = torch.argmax(logits, dim=-1)
    metric.add_batch(predictions=predictions, references=batch["labels"])

metric.compute()
```

```python out
{'accuracy': 0.8431372549019608, 'f1': 0.8907849829351535}
```

рдлрд┐рд░ рд╕реЗ, рдореЙрдбрд▓ рд╣реЗрдб рдЗрдирд┐рд╢рд┐рдпрд▓рд╛рдЗрдЬрд╝реЗрд╢рди рдФрд░ рдбреЗрдЯрд╛ рдлреЗрд░рдмрджрд▓ рдореЗрдВ рдХреНрд░рдорд░рд╣рд┐рдд рд╣реЛрдиреЗ рдХреЗ рдХрд╛рд░рдг рдЖрдкрдХреЗ рдкрд░рд┐рдгрд╛рдо рдереЛрдбрд╝реЗ рднрд┐рдиреНрди рд╣реЛрдВрдЧреЗ, рд▓реЗрдХрд┐рди рд╡реЗ рдПрдХ рд╣реА рдмреЙрд▓рдкрд╛рд░реНрдХ рдореЗрдВ рд╣реЛрдиреЗ рдЪрд╛рд╣рд┐рдПред

<Tip>

тЬПя╕П **рдХреЛрд╢рд┐рд╢ рдХрд░рдХреЗ рджреЗрдЦреЗ!** рдкрд┐рдЫрд▓реЗ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рд▓реВрдк рдХреЛ рд╕рдВрд╢реЛрдзрд┐рдд рдХрд░реЗрдВ рддрд╛рдХрд┐ рдЕрдкрдиреЗ рдореЙрдбрд▓ рдХреЛ SST-2 рдбреЗрдЯрд╛рд╕реЗрдЯ рдкрд░ рдлрд╛рдЗрди-рдЯреНрдпреВрди рдХрд░ рд╕рдХреЗред 

</Tip>

### рдЕрдкрдиреЗ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рд▓реВрдк рдХреЛ рд╕реБрдкрд░рдЪрд╛рд░реНрдЬ рдХрд░реЗрдВ ЁЯдЧ Accelerate рдХреЗ рд╕рд╛рдеред

<Youtube id="s7dy8QRgjJ0" />

рд╣рдордиреЗ рдкрд╣рд▓реЗ рдЬреЛ рдЯреНрд░реЗрдирд┐рдВрдЧ рд▓реВрдк рдкрд░рд┐рднрд╛рд╖рд┐рдд рдХрд┐рдпрд╛ рдерд╛, рд╡рд╣ рд╕рд┐рдВрдЧрд▓ CPU рдпрд╛ GPU рдкрд░ рдареАрдХ рдХрд╛рдо рдХрд░рддрд╛ рд╣реИред рд▓реЗрдХрд┐рди  [ЁЯдЧ Accelerate](https://github.com/huggingface/accelerate) рд▓рд╛рдЗрдмреНрд░реЗрд░реА рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ, рдмрд╕ рдХреБрдЫ рд╕рдорд╛рдпреЛрдЬрди рдХреЗ рд╕рд╛рде рд╣рдо рдХрдИ GPUs рдпрд╛ TPUs рдкрд░ рд╡рд┐рддрд░рд┐рдд рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдХреЛ рд╕рдХреНрд╖рдо рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред рд╢реБрд░реБрдЖрдд рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдФрд░ рд╕рддреНрдпрд╛рдкрди рдбреЗрдЯрд╛ рд▓реЛрдбрд░ рдХреЗ рдирд┐рд░реНрдорд╛рдг рд╕реЗ рд╣реБрдИ, рдпрд╣рд╛рдБ рд╣рдорд╛рд░рд╛ рдореИрдиреБрдЕрд▓ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рд▓реВрдк рдХреИрд╕рд╛ рджрд┐рдЦрддрд╛ рд╣реИ:

```py
from transformers import AdamW, AutoModelForSequenceClassification, get_scheduler

model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)
optimizer = AdamW(model.parameters(), lr=3e-5)

device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
model.to(device)

num_epochs = 3
num_training_steps = num_epochs * len(train_dataloader)
lr_scheduler = get_scheduler(
    "linear",
    optimizer=optimizer,
    num_warmup_steps=0,
    num_training_steps=num_training_steps,
)

progress_bar = tqdm(range(num_training_steps))

model.train()
for epoch in range(num_epochs):
    for batch in train_dataloader:
        batch = {k: v.to(device) for k, v in batch.items()}
        outputs = model(**batch)
        loss = outputs.loss
        loss.backward()

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(1)
```

рдФрд░ рдкрд░рд┐рд╡рд░реНрддрди рдпрд╣рд╛рдБ рд╣реИрдВ:

```diff
+ from accelerate import Accelerator
  from transformers import AdamW, AutoModelForSequenceClassification, get_scheduler

+ accelerator = Accelerator()

  model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)
  optimizer = AdamW(model.parameters(), lr=3e-5)

- device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
- model.to(device)

+ train_dataloader, eval_dataloader, model, optimizer = accelerator.prepare(
+     train_dataloader, eval_dataloader, model, optimizer
+ )

  num_epochs = 3
  num_training_steps = num_epochs * len(train_dataloader)
  lr_scheduler = get_scheduler(
      "linear",
      optimizer=optimizer,
      num_warmup_steps=0,
      num_training_steps=num_training_steps
  )

  progress_bar = tqdm(range(num_training_steps))

  model.train()
  for epoch in range(num_epochs):
      for batch in train_dataloader:
-         batch = {k: v.to(device) for k, v in batch.items()}
          outputs = model(**batch)
          loss = outputs.loss
-         loss.backward()
+         accelerator.backward(loss)

          optimizer.step()
          lr_scheduler.step()
          optimizer.zero_grad()
          progress_bar.update(1)
```

рд╕рдмрд╕реЗ рдкрд╣рд▓реА рд▓рд╛рдЗрди рдЬреЛ рдЬреЛрдбрд╝рдиреА рд╣реИ рд╡реЛ рд╣реИ рдЗрдореНрдкреЛрд░реНрдЯ рд▓рд╛рдЗрдиред рджреВрд╕рд░реА рд▓рд╛рдЗрди рдПрдХ `Accelerator` рд╡рд╕реНрддреБ рдХреЛ рдЗрдиреНрд╕реНрдЯреИрдиреНрд╢реАрдРрдЯ рдХрд░рддреА рд╣реИ рдЬреЛ рд╡рд╛рддрд╛рд╡рд░рдг рдХреЛ рджреЗрдЦреЗрдЧреА рдФрд░ рдЙрдЪрд┐рдд рд╡рд┐рддрд░рд┐рдд рд╕реЗрдЯрдЕрдк рдХреЛ рдЗрдирд┐рд╢рд┐рдпрд▓рд╛рдЗрдЬрд╝ рдХрд░реЗрдЧреАред ЁЯдЧ Accelerate рдЖрдкрдХреЗ рд▓рд┐рдП рдбрд┐рд╡рд╛рдЗрд╕ рдкреНрд▓реЗрд╕рдореЗрдВрдЯ рдХреЛ рд╣реИрдВрдбрд▓ рдХрд░рддрд╛ рд╣реИ, рддрд╛рдХрд┐ рдЖрдк рдЙрди рд▓рд╛рдЗрдиреЛрдВ рдХреЛ рд╣рдЯрд╛ рд╕рдХреЗрдВ рдЬреЛ рдореЙрдбрд▓ рдХреЛ рдбрд┐рд╡рд╛рдЗрд╕ рдкрд░ рд░рдЦрддреА рд╣реИрдВ (рдпрд╛, рдпрджрд┐ рдЖрдк рдЪрд╛рд╣реЗрдВ, рддреЛ рдЙрдиреНрд╣реЗрдВ `device` рдХреЗ рдмрдЬрд╛рдп `accelerator.device` рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдмрджрд▓реЗрдВ)ред

рдлрд┐рд░ рдХрд╛рдо рдХрд╛ рдореБрдЦреНрдп рд╣рд┐рд╕реНрд╕рд╛ рдЙрд╕ рд▓рд╛рдЗрди рдореЗрдВ рдХрд┐рдпрд╛ рдЬрд╛рддрд╛ рд╣реИ рдЬреЛ рдбреЗрдЯрд╛рд▓реЛрдбрд░реНрд╕, рдореЙрдбрд▓ рдФрд░ рдСрдкреНрдЯрд┐рдорд╛рдЗрдЬрд╝рд░ рдХреЛ `accelerator.prepare()` рдкрд░ рднреЗрдЬрддрд╛ рд╣реИред рдпрд╣ рдЙрди рд╡рд╕реНрддреБрдУрдВ рдХреЛ рдЙрдЪрд┐рдд рдХрдВрдЯреЗрдирд░ рдореЗрдВ рд▓рдкреЗрдЯ рджреЗрдЧрд╛ рддрд╛рдХрд┐ рдпрд╣ рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рд╣реЛ рд╕рдХреЗ рдХрд┐ рдЖрдкрдХрд╛ рд╡рд┐рддрд░рд┐рдд рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдЙрджреНрджреЗрд╢реНрдп рдХреЗ рдЕрдиреБрд╕рд╛рд░ рдХрд╛рдо рдХрд░рддрд╛ рд╣реИред рд╢реЗрд╖ рдкрд░рд┐рд╡рд░реНрддрди рд╣реИ рдЙрд╕ рд▓рд╛рдЗрди рдХреЛ рд╣рдЯрд╛рдирд╛ рдЬреЛ рдмреИрдЪ рдХреЛ `device` рдкрд░ рд░рдЦрддрд╛ рд╣реИ (рдлрд┐рд░ рд╕реЗ, рдпрджрд┐ рдЖрдк рдЗрд╕реЗ рд░рдЦрдирд╛ рдЪрд╛рд╣рддреЗ рд╣реИрдВ рддреЛ рдЖрдк рдЗрд╕реЗ рдХреЗрд╡рд▓ `accelerator.device` рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдмрджрд▓ рд╕рдХрддреЗ рд╣реИрдВ) рдФрд░ `loss.backward()` рдХреЛ `accelerator.backward(loss)` рдХреЗ рд╕рд╛рде рдмрджрд▓рдирд╛ред

<Tip>
тЪая╕П Cloud TPUs рджреНрд╡рд╛рд░рд╛ рдкреЗрд╢ рдХрд┐рдП рдЧрдП рд╕реНрдкреАрдб-рдЕрдк рд╕реЗ рд▓рд╛рдн рдЙрдард╛рдиреЗ рдХреЗ рд▓рд┐рдП, рд╣рдо рдЕрдиреБрд╢рдВрд╕рд╛ рдХрд░рддреЗ рд╣реИрдВ рдХрд┐ рдЖрдк рдЕрдкрдиреЗ рд╕реИрдореНрдкрд▓реНрд╕ рдХреЛ рдЯреЛрдХрдирдирд╛рдЗрдЬрд╝рд░ рдХреЗ `padding="max_length"` рдФрд░ `max_length` рдкреНрд░рд╛рдЪрд▓ рдпрд╛рдирд┐ рдЖрд░реНрдЧреБрдореЗрдВрдЯ рдХреЗ рд╕рд╛рде рдПрдХ рдирд┐рд╢реНрдЪрд┐рдд рд▓рдВрдмрд╛рдИ рддрдХ рдкреИрдбрд┐рдВрдЧ рдХрд░реЗрдВред
</Tip>

рдпрджрд┐ рдЖрдк рдЗрд╕реЗ рдЦреЗрд▓рдиреЗ рдХреЗ рд▓рд┐рдП рдХреЙрдкреА рдФрд░ рдкреЗрд╕реНрдЯ рдХрд░рдирд╛ рдЪрд╛рд╣рддреЗ рд╣реИрдВ, рддреЛ рдпрд╣рд╛рдВ рдмрддрд╛рдпрд╛ рдЧрдпрд╛ рд╣реИ рдХрд┐ ЁЯдЧ Accelerate рдХреЗ рд╕рд╛рде рдкреВрд░рд╛ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рд▓реВрдк рдХреИрд╕рд╛ рджрд┐рдЦрддрд╛ рд╣реИ:

```py
from accelerate import Accelerator
from transformers import AdamW, AutoModelForSequenceClassification, get_scheduler

accelerator = Accelerator()

model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)
optimizer = AdamW(model.parameters(), lr=3e-5)

train_dl, eval_dl, model, optimizer = accelerator.prepare(
    train_dataloader, eval_dataloader, model, optimizer
)

num_epochs = 3
num_training_steps = num_epochs * len(train_dl)
lr_scheduler = get_scheduler(
    "linear",
    optimizer=optimizer,
    num_warmup_steps=0,
    num_training_steps=num_training_steps,
)

progress_bar = tqdm(range(num_training_steps))

model.train()
for epoch in range(num_epochs):
    for batch in train_dl:
        outputs = model(**batch)
        loss = outputs.loss
        accelerator.backward(loss)

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(1)
```

рдЗрд╕реЗ рдПрдХ `train.py` рд╕реНрдХреНрд░рд┐рдкреНрдЯ рдореЗрдВ рд░рдЦрдиреЗ рд╕реЗ рд╡рд╣ рд╕реНрдХреНрд░рд┐рдкреНрдЯ рдХрд┐рд╕реА рднреА рдкреНрд░рдХрд╛рд░ рдХреЗ рд╡рд┐рддрд░рд┐рдд рд╕реЗрдЯрдЕрдк рдкрд░ рдЪрд▓рдиреЗ рдпреЛрдЧреНрдп рд╣реЛ рдЬрд╛рдПрдЧреАред рдЗрд╕реЗ рдЕрдкрдиреЗ рд╡рд┐рддрд░рд┐рдд рд╕реЗрдЯрдЕрдк рдореЗрдВ рдЖрдЬрд╝рдорд╛рдиреЗ рдХреЗ рд▓рд┐рдП, рдХрдорд╛рдВрдб рдЪрд▓рд╛рдПрдБ:

```bash
accelerate config
```

рдЬреЛ рдЖрдкрдХреЛ рдХреБрдЫ рд╕рд╡рд╛рд▓реЛрдВ рдХреЗ рдЬрд╡рд╛рдм рджреЗрдиреЗ рдХреЗ рд▓рд┐рдП рдкреНрд░реЗрд░рд┐рдд рдХрд░реЗрдЧрд╛ рдФрд░ рдЗрд╕ рдХрдорд╛рдВрдб рджреНрд╡рд╛рд░рд╛ рдЙрдкрдпреЛрдЧ рдХреА рдЬрд╛рдиреЗ рд╡рд╛рд▓реА рдХреЙрдиреНрдлрд╝рд┐рдЧрд░реЗрд╢рди рдлрд╝рд╛рдЗрд▓ рдореЗрдВ рдЖрдкрдХреЗ рдЙрддреНрддрд░реЛрдВ рдХреЛ рдбрдВрдк рдХрд░ рджреЗрдЧрд╛:

```
accelerate launch train.py
```

рдЬреЛ рд╡рд┐рддрд░рд┐рдд рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдХреЛ рд╢реБрд░реВ рдХрд░реЗрдЧрд╛ред

рдпрджрд┐ рдЖрдк рдЗрд╕реЗ рдиреЛрдЯрдмреБрдХ рдореЗрдВ рдЖрдЬрд╝рдорд╛рдирд╛ рдЪрд╛рд╣рддреЗ рд╣реИрдВ (рдЙрджрд╛рд╣рд░рдг рдХреЗ рд▓рд┐рдП, Colab рдкрд░ TPUs рдХреЗ рд╕рд╛рде рдЗрд╕рдХрд╛ рдкрд░реАрдХреНрд╖рдг рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП), рддреЛ рдмрд╕ рдХреЛрдб рдХреЛ `training_function()` рдореЗрдВ рдкреЗрд╕реНрдЯ рдХрд░реЗрдВ рдФрд░ рдПрдХ рдЕрдВрддрд┐рдо рд╕реЗрд▓ рдЪрд▓рд╛рдПрдБ рд╕рд╛рде рдореЗрдВ:

```python
from accelerate import notebook_launcher

notebook_launcher(training_function)
```

рдЖрдк рдХрдИ рдЕрдзрд┐рдХ рдЙрджрд╛рд╣рд░рдг [ЁЯдЧ Accelerate repo](https://github.com/huggingface/accelerate/tree/main/examples) рдореЗрдВ рдкрд╛ рд╕рдХрддреЗ рд╣реИред
