# डिकोडर मॉडल

<Youtube id="d_ixlCubqQw" />

डिकोडर मॉडल केवल ट्रांसफॉर्मर मॉडल के डिकोडर का उपयोग करते हैं। प्रत्येक चरण में, किसी दिए गए शब्द के लिए ध्यान की परतें केवल वाक्य में उसके सामने स्थित शब्दों तक पहुंच सकती हैं। इन मॉडलों को अक्सर *स्वतः प्रतिगामी मॉडल* कहा जाता है।

डिकोडर मॉडल का पूर्व-प्रशिक्षण आमतौर पर वाक्य में अगले शब्द की भविष्यवाणी करने के इर्द-गिर्द घूमता है।

ये मॉडल टेक्स्ट जनरेशन से जुड़े कार्यों के लिए सबसे उपयुक्त हैं।

मॉडल के इस परिवार के प्रतिनिधियों में शामिल हैं:

- [CTRL](https://huggingface.co/transformers/model_doc/ctrl.html)
- [GPT](https://huggingface.co/transformers/model_doc/gpt.html)
- [GPT-2](https://huggingface.co/transformers/model_doc/gpt2.html)
- [Transformer XL](https://huggingface.co/transformers/model_doc/transfo-xl.html)
