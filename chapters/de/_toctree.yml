- title: 0. Einrichtung
  sections:
  - local: chapter0/1
    title: Einführung

- title: 1. Transformer-Modelle
  sections:
  - local: chapter1/1
    title: Einführung
  - local: chapter1/2
    title: Natural Language Processing
  - local: chapter1/3
    title: Transformer-Modelle - wozu sind sie imstande?
  - local: chapter1/4
    title: Wie funktionieren Transformer-Modelle?
  - local: chapter1/5
    title: Encoder-Modelle
  - local: chapter1/6
    title: Decoder-Modelle
  - local: chapter1/7
    title: Sequence-to-Sequence-Modelle
  - local: chapter1/8
    title: Bias und Einschränkungen
  - local: chapter1/9
    title: Zusammenfassung
  - local: chapter1/10
    title: Quiz am Ende des Kapitels
    quiz: 1

- title: 3. Fine-tuning von vortrainierten Modellen
  sections:
  - local: chapter3/1
    title: Einführung
  - local: chapter3/2
    title: Datenbearbeitung
  - local: chapter3/3
    title: Fine-tuning von Modellen mit der Trainer API oder Keras
    local_fw: { pt: chapter3/3, tf: chapter3/3_tf }
  - local: chapter3/4
    title: Komplettes Training
  - local: chapter3/5
    title: Fine-tuning, Check!
  - local: chapter3/6
    title: Quiz am Ende des Kapitels
    quiz: 3

- title: 4. Teilen von Modellen und Tokenizers
  sections:
  - local: chapter4/1
    title: Der Hugging Face Hub
  - local: chapter4/2
    title: Verwendung vortrainierter Modelle
  - local: chapter4/3
    title: Vortrainierte Modelle teilen

- title: Wörterverzeichnis
  sections:
  - local: glossary/1
    title: Wörterverzeichnis
