<!-- DISABLE-FRONTMATTER-SECTIONS -->

<CourseFloatingBanner
    chapter={1}
    classNames="absolute z-10 right-0 top-0"
/>


# Quiz am Ende des Kapitels

In diesem Kapitel hast du viel gelernt! Mach dir keine Sorgen, wenn du noch nicht alle Einzelheiten verstanden hast. In den n√§chsten Kapiteln wirst du mehr dar√ºber erfahren, wie die Dinge im Einzelnen funktionieren.

Doch zuerst wollen wir noch testen, was du in diesem Kapitel gelernt hast!


### 1. Erkunde den Hub und suche nach dem Checkpoint `roberta-large-mnli`. Welche Aufgabe unterst√ºtzt er?


<Question
	choices={[
		{
			text: "Summarization (Textzusammenfassung)",
			explain: "Sieh nochmal auf der Seite des Modells<a href=\"https://huggingface.co/roberta-large-mnli\">roberta-large-mnli</a> nach."
		},
		{
			text: "Text Classification (Textklassifizierung)",
			explain: "Genauer gesagt, wird klassifiziert, ob zwei S√§tze hinsichtlich dreier Labels (Widerspruch (engl. Contradiction), Neutral, Konsequenz (engl. Entailment)) logisch miteinander verbunden sind - eine Aufgabe, die auch als <em>Natural Language Inference</em> bezeichnet wird.",
			correct: true
		},
		{
			text: "Text Generation (Textgenerierung)",
			explain: "Sieh nochmal auf der Seite des Modells <a href=\"https://huggingface.co/roberta-large-mnli\">roberta-large-mnli</a> nach."
		}
	]}
/>

### 2. Was gibt der folgende Code zur√ºck?

```py
from transformers import pipeline

ner = pipeline("ner", grouped_entities=True)
ner("My name is Sylvain and I work at Hugging Face in Brooklyn.")
```

<Question
	choices={[
		{
			text: "Er gibt die Ergebnisse der Klassifizierung f√ºr diesen Satz f√ºr die Labels \"positive\" oder \"negative\" zur√ºck.",
			explain: "Das ist nicht richtig - daf√ºr m√ºsstest du eine <code>sentiment-analysis</code>-Pipeline verwenden."
		},
		{
			text: "Er wird einen generierten Text zur√ºckgeben, der diesen Satz vervollst√§ndigt.",
			explain: "Das ist nicht richtig - daf√ºr m√ºsstest du eine <code>text-generation</code>-Pipeline verwenden.",
		},
		{
			text: "Er gibt Begriffe zur√ºck, die f√ºr Personen, Organisationen oder Orte stehen.",
			explain: "Au√üerdem werden mit <code>grouped_entities=True</code> die W√∂rter, die zur selben Entit√§t geh√∂ren, gruppiert, wie z. B. \"Hugging Face\".",
			correct: true
		}
	]}
/>

### 3. Wodurch m√ºsste ... in diesem Codebeispiel ersetzt werden?

```py
from transformers import pipeline

filler = pipeline("fill-mask", model="bert-base-cased")
result = filler("...")
```

<Question
	choices={[
		{
			text: "This &#60;mask> has been waiting for you.",
			explain: "Das stimmt nicht. Schau dir die <code>bert-base-cased</code>-√úbersichtsseite des Modells an und versuche, deinen Fehler zu entdecken."
		},
		{
			text: "This [MASK] has been waiting for you.",
			explain: "Richtig! Der Mask Token dieses Modells ist [MASK].",
			correct: true
		},
		{
			text: "This man has been waiting for you.",
			explain: "Leider falsch. Diese Pipeline f√ºllt maskierte W√∂rter auf, also braucht sie irgendwo einen Mask Token."
		}
	]}
/>

### 4. Warum wird dieser Code nicht funktionieren?

```py
from transformers import pipeline

classifier = pipeline("zero-shot-classification")
result = classifier("This is a course about the Transformers library")
```

<Question
	choices={[
		{
			text: "Diese Pipeline erfordert, dass Labels angegeben werden, damit der Text klassifiziert werden kann.",
			explain: "Richtig ‚Äî der korrekte Code muss <code>candidate_labels=[...]</code> enthalten.",
			correct: true
		},
		{
			text: "Diese Pipeline erfordert mehrere S√§tze, nicht nur einen.",
			explain: "Das ist falsch - obwohl diese Pipeline, wenn sie korrekt verwendet wird, eine Liste von S√§tzen verarbeiten kann (wie alle anderen Pipelines)."
		},
		{
			text: "Die ü§ó Transformers-Bibliothek funktioniert wie immer nicht.",
			explain: "Zu dieser Antwort er√ºbrigt sich jeder Kommentar!"
		},
		{
			text: "Diese Pipeline erfordert l√§ngere Inputs; diese hier sind zu kurz.",
			explain: "Das ist falsch. √úbrigens wird ein sehr langer Text bei der Verarbeitung durch diese Pipeline gestutzt (engl. truncated) bzw. gek√ºrzt."
		}
	]}
/>

### 5. Was bedeutet der Begriff "Transfer Learning"?

<Question
	choices={[
		{
			text: "√úbertragen des im Pretraining erlangten Wissens auf ein neues Modell, indem es auf demselben Datensatz trainiert wird.",
			explain: "Nein, das w√§ren dann zwei Versionen desselben Modells."
		},
		{
			text: "√úbertragen des im Pretraining erlangten Wissens auf ein neues Modell durch Initialisierung des zweiten Modells mit der Gewichtung des ersten Modells.",
			explain: "Richtig: Wenn das zweite Modell f√ºr eine neue Aufgabe trainiert wird, *√ºbertr√§gt* (engl. transfer) es das Wissen des ersten Modells.",
			correct: true
		},
		{
			text: "√úbertragen des im Pretraining erlangten Wissens auf ein neues Modell, indem das zweite Modell mit der gleichen Architektur wie das erste Modell aufgebaut wird.",
			explain: "Die Architektur ist nur die Art und Weise, wie das Modell aufgebaut ist. Es wird in diesem Fall kein Wissen geteilt oder √ºbertragen."
		}
	]}
/>

### 6. Richtig oder falsch? Ein Sprachmodell ben√∂tigt im Rahmen des Pretraining in der Regel keine Labels.


<Question
	choices={[
		{
			text: "Richtig",
			explain: "Das Pretraining ist in der Regel <em>selbst√ºberwacht</em> (engl. self-supervised), d. h. die Labels werden automatisch aus den Inputs erstellt (wie z. B. die Vorhersage des n√§chsten Wortes oder das Auff√ºllen einiger maskierter W√∂rter).",
			correct: true
		},
		{
			text: "Falsch",
			explain: "Das ist nicht die richtige Antwort."
		}
	]}
/>

### 7. W√§hle den Satz aus, der die Begriffe "Modell", "Architektur" und "Gewichte" bzw. "Gewichtung" am besten beschreibt.

<Question
	choices={[
		{
			text: "Wenn ein Modell ein Geb√§ude ist, ist seine Architektur der Bauplan und die Gewichte sind die Menschen, die darin leben.",
			explain: "In Anlehnung an diese Metapher w√§ren die Gewichte die Ziegel (und weitere Materialien), die zum Bau des Geb√§udes verwendet werden."
		},
		{
			text: "Eine Architektur ist eine Karte zum Aufbau eines Modells und ihre Gewichte sind die St√§dte, die auf der Karte dargestellt sind.",
			explain: "Das Problem bei dieser Metapher ist, dass eine Karte in der Regel nur eine Realit√§t abbildet (es gibt nur eine Stadt in Frankreich namens Paris). F√ºr eine bestimmte Architektur sind jedoch verschiedene Gewichtungen m√∂glich."
		},
		{
			text: "Eine Architektur ist eine Abfolge von mathematischen Funktionen zum Aufbau eines Modells und ihre Gewichte sind die Parameter dieser Funktionen.",
			explain: "Dieselben mathematischen Funktionen (Architektur) k√∂nnen verwendet werden, um verschiedene Modelle zu erstellen, indem unterschiedliche Parameter (Gewichte) verwendet werden.",
			correct: true
		}
	]}
/>


### 8. Welche dieser Modelle w√ºrdest du nutzen, um einen Prompt bzw. Text-Input durch einen generierten Text vervollst√§ndigen zu lassen?

<Question
	choices={[
		{
			text: "Ein Encoder-Modell",
			explain: "Ein Encoder-Modell erzeugt eine Repr√§sentation f√ºr den gesamten Satz. Diese ist f√ºr Aufgaben wie die Klassifizierung besser geeignet."
		},
		{
			text: "Ein Decoder-Modell",
			explain: "Decoder-Modelle eignen sich perfekt f√ºr die Generierung von Text auf Basis eines Prompts bzw. Input-Textes.",
			correct: true
		},
		{
			text: "Ein Sequence-to-Sequence-Modell",
			explain: "Sequence-to-Sequence-Modelle eignen sich besser f√ºr Aufgaben, bei denen du S√§tze generieren m√∂chtest, die jeweils einen Bezug zu den Input-S√§tzen haben, und nicht auf einen bestimmten Prompt zur√ºckzuf√ºhren sind."
		}
	]}
/>

### 9. Welche dieser Modelle w√ºrdest du f√ºr die Zusammenfassung von Texten verwenden?

<Question
	choices={[
		{
			text: "Ein Encoder-Modell",
			explain: "Ein Encoder-Modell erzeugt eine Repr√§sentation f√ºr den gesamten Satz. Diese ist f√ºr Aufgaben wie die Klassifizierung besser geeignet."
		},
		{
			text: "Ein Decoder-Modell",
			explain: "Decoder-Modelle sind gut f√ºr die Erstellung von Text-Outputs (wie Zusammenfassungen), aber sie haben nicht die F√§higkeit, einen Gesamtkontext wie den kompletten Text f√ºr die Zusammenfassung zu nutzen."
		},
		{
			text: "Ein Sequence-to-Sequence-Modell",
			explain: "Sequence-to-Sequence-Modelle eignen sich perfekt f√ºr eine Textzusammenfassungsaufgabe.",
			correct: true
		}
	]}
/>

### 10. Welche Art von Modellen w√ºrdest du verwenden, um Text-Inputs entsprechend bestimmter Labels zu klassifizieren?

<Question
	choices={[
		{
			text: "Ein Encoder-Modell",
			explain: "Ein Encoder-Modell erzeugt eine Repr√§sentation f√ºr den gesamten Satz. Diese eignet sich perfekt f√ºr eine Aufgabe wie die Klassifizierung.",
			correct: true
		},
		{
			text: "Ein Decoder-Modell",
			explain: "Decoder-Modelle eignen sich f√ºr die Generierung von Output-Texten, aber nicht daf√ºr, ein Label f√ºr einen bestimmten Satz zu ermitteln."
		},
		{
			text: "Ein Sequence-to-Sequence-Modell",
			explain: "Sequence-to-Sequence-Modelle eignen sich besser f√ºr Aufgaben, bei denen du Text auf der Grundlage eines vorgegebenen Satzes und nicht eines Labels generieren m√∂chtest.",
		}
	]}
/>

### 11. Welche m√∂gliche Ursache kann eine vom Modell zu beobachtende Voreingenommenheit (Bias) haben?

<Question
	choices={[
		{
			text: "Das Modell ist eine feingetunte Version eines vortrainierten Modells, das den Bias aus dem Pretraining √ºbernommen hat.",
			explain: "Bei der Anwendung von Transfer Learning wird ein Bias, der dem vortrainierten Modell zugrunde lag, auch beim feingetunten Modell durchsickern.",
			correct: true
		},
		{
			text: "Die Daten, mit denen das Modell trainiert wurde, spiegeln Voreingenommenheiten wider bzw. sind mit einem Bias versehen.",
			explain: "Dies ist die offensichtlichste Ursache f√ºr eine Voreingenommenheit (Bias), aber nicht die einzige.",
			correct: true
		},
		{
			text: "Das Ma√ü, auf dessen Grundlage das Modell optimiert wurde, f√ºhrt zu einem Bias.",
			explain: "Eine weniger offensichtliche Ursache f√ºr Voreingenommenheiten (Bias) ist die Art und Weise, wie das Modell trainiert wird. Bspw. wenn du dein Modell einfach blindlings in Bezug auf das von dir gew√§hlte Ma√ü optimierst.",
			correct: true
		}
	]}
/>
