<FrameworkSwitchCourse {fw} />

<!-- DISABLE-FRONTMATTER-SECTIONS -->

# End-of-chapter quiz[[end-of-chapter-quiz]]

<CourseFloatingBanner
    chapter={3}
    classNames="absolute z-10 right-0 top-0"
/>

TestaÈ›i-vÄƒ cunoÈ™tinÈ›ele din acest capitol!

### 1. Dataset-ul `emotion` conÈ›ine mesaje de pe Twitter etichetate cu emoÈ›ii. CÄƒutaÈ›i-l Ã®n [Hub](https://huggingface.co/datasets) È™i citiÈ›i descrierea dataset-ului. Care dintre acestea nu este una dintre emoÈ›iile sale de bazÄƒ?

<Question
	choices={[
		{
			text: "Bucurie",
			explain: "ÃncercaÈ›i din nou - aceastÄƒ emoÈ›ie este prezentÄƒ Ã®n acel set de date!"
		},
		{
			text: "Iubire",
			explain: "ÃncercaÈ›i din nou - aceastÄƒ emoÈ›ie este prezentÄƒ Ã®n acel set de date!"
		},
		{
			text: "Confuzie",
			explain: "Corect! Confuzia nu este una dintre cele È™ase emoÈ›ii de bazÄƒ.",
            correct: true
		},
        {
			text: "SurprizÄƒ",
			explain: "SurprizÄƒ! ÃncercaÈ›i din nou!"
		}
	]}
/>

### 2. CÄƒutaÈ›i dataset-ul `ar_sarcasm` Ã®n [Hub](https://huggingface.co/datasets). Ce tip de sarcinÄƒ suportÄƒ?

<Question
	choices={[
		{
			text: "Clasificarea sentimentelor",
			explain: "Corect! PuteÈ›i verifica etichetele (tags) din descrierea dataset-ului.",
            correct: true
		},
		{
			text: "Traducere automatÄƒ (Machine translation)",
			explain: "Nu este corect â€” aruncaÈ›i din nou o privire la <a href='https://huggingface.co/datasets/ar_sarcasm'>descrierea dataset-ului</a>!"
		},
		{
			text: "Named entity recognition",
			explain: "Nu este corect â€” aruncaÈ›i din nou o privire la <a href='https://huggingface.co/datasets/ar_sarcasm'>descrierea dataset-ului</a>!"
		},
        {
			text: "RÄƒspuns la Ã®ntrebÄƒri (Question answering)",
			explain: "Din pÄƒcate, nu aÈ›i rÄƒspuns corect. ÃncercaÈ›i din nou!"
		}
	]}
/>

### 3. Cum se aÈ™teaptÄƒ modelul BERT ca o pereche de propoziÈ›ii sÄƒ fie procesatÄƒ?

<Question
	choices={[
		{
			text: "Tokens_of_sentence_1 [SEP] Tokens_of_sentence_2",
			explain: "Este nevoie de un token special <code>[SEP]</code> pentru a separa cele douÄƒ propoziÈ›ii, dar nu este singurul lucru necesar!"
		},
		{
			text: "[CLS] Tokens_of_sentence_1 Tokens_of_sentence_2",
			explain: "Este nevoie de un token special <code>[CLS]</code> la Ã®nceput, dar nu este singurul lucru necesar!"
		},
		{
			text: "[CLS] Tokens_of_sentence_1 [SEP] Tokens_of_sentence_2 [SEP]",
			explain: "Corect!",
            correct: true
		},
        {
			text: "[CLS] Tokens_of_sentence_1 [SEP] Tokens_of_sentence_2",
			explain: "Este nevoie atÃ¢t de un token special <code>[CLS]</code> la Ã®nceput, cÃ¢t È™i de un token special <code>[SEP]</code> pentru a separa cele douÄƒ propoziÈ›ii, dar mai lipseÈ™te ceva!"
		}
	]}
/>

{#if fw === 'pt'}
### 4. Care sunt avantajele metodei `Dataset.map()`?

<Question
	choices={[
		{
			text: "Rezultatele funcÈ›iei sunt memorate Ã®n cache, astfel Ã®ncÃ¢t nu va dura nimic dacÄƒ reexecutÄƒm codul.",
			explain: "Acesta este Ã®ntr-adevÄƒr unul dintre avantajele acestei metode! TotuÈ™i, nu este singurul...",
            correct: true
		},
		{
			text: "Poate aplica multiprocessing pentru a rula mai rapid decÃ¢t aplicÃ¢nd funcÈ›ia pe fiecare element din dataset.",
			explain: "Aceasta este o caracteristicÄƒ interesantÄƒ, dar nu este unica!",
            correct: true
		},
		{
			text: "Nu Ã®ncarcÄƒ Ã®ntregul set de date Ã®n memorie, salvÃ¢nd rezultatele de Ã®ndatÄƒ ce este procesat un element.",
			explain: "Acesta este un avantaj al acestei metode. ExistÄƒ Ã®nsÄƒ È™i altele!",
            correct: true
		},
	]}
/>

### 5. Ce Ã®nseamnÄƒ umplerea dinamicÄƒ (dynamic padding)?

<Question
	choices={[
		{
			text: "E atunci cÃ¢nd Ã®mpachetezi intrÄƒrile pentru fiecare batch la lungimea maximÄƒ din Ã®ntregul dataset.",
			explain: "Este adevÄƒrat cÄƒ Ã®mpachetÄƒm cÃ¢nd creÄƒm batch-ul, dar nu pÃ¢nÄƒ la lungimea maximÄƒ din Ã®ntregul set de date."
		},
		{
			text: "E atunci cÃ¢nd Ã®mpachetezi intrÄƒrile Ã®n momentul creÄƒrii batch-ului, la lungimea maximÄƒ a propoziÈ›iilor din acel batch.",
			explain: "Corect! Partea \"dinamicÄƒ\" vine din faptul cÄƒ mÄƒrimea fiecÄƒrui batch este stabilitÄƒ Ã®n momentul creÄƒrii, iar ca urmare, toate batch-urile ar putea avea forme diferite.",
            correct: true
		},
		{
			text: "E atunci cÃ¢nd Ã®mpachetezi intrÄƒrile astfel Ã®ncÃ¢t fiecare propoziÈ›ie sÄƒ aibÄƒ acelaÈ™i numÄƒr de tokeni ca precedenta Ã®n dataset.",
			explain: "Nu este corect, È™i nici nu are sens sÄƒ ne uitÄƒm la ordinea din dataset, din moment ce Ã®l amestecÄƒm Ã®n timpul antrenamentului."
		},
	]}
/>

### 6. Care este scopul unei funcÈ›ii de â€collate"?

<Question
	choices={[
		{
			text: "AsigurÄƒ cÄƒ toate secvenÈ›ele din setul de date au aceeaÈ™i lungime.",
			explain: "O funcÈ›ie de collate se ocupÄƒ de manipularea batch-urilor individuale, nu a Ã®ntregului set de date. Ãn plus, vorbim despre funcÈ›iile de collate Ã®n general, nu despre <code>DataCollatorWithPadding</code> Ã®n mod specific."
		},
		{
			text: "ReuneÈ™te toate eÈ™antioanele Ã®ntr-un batch.",
			explain: "Corect! PoÈ›i transmite funcÈ›ia de collate ca argument al unui <code>DataLoader</code>. Am folosit funcÈ›ia <code>DataCollatorWithPadding</code>, care Ã®mpacheteazÄƒ toate elementele dintr-un batch astfel Ã®ncÃ¢t sÄƒ aibÄƒ aceeaÈ™i lungime.",
            correct: true
		},
		{
			text: "PreproceseazÄƒ Ã®ntregul set de date.",
			explain: "Aceasta ar fi o funcÈ›ie de preprocessing, nu o funcÈ›ie de collate."
		},
        {
			text: "TrunchiazÄƒ secvenÈ›ele din setul de date.",
			explain: "O funcÈ›ie de collate se ocupÄƒ de manipularea batch-urilor individuale, nu a Ã®ntregului set de date. DacÄƒ sunteÈ›i interesaÈ›i de trunchiere, puteÈ›i folosi argumentul <code>truncate</code> al <code>tokenizer</code>."
		}
	]}
/>

### 7. Ce se Ã®ntÃ¢mplÄƒ cÃ¢nd instanÈ›iaÈ›i una dintre clasele `AutoModelForXxx` cu un model de limbaj preantrenat (cum ar fi `bert-base-uncased`), care corespunde unei alte sarcini decÃ¢t cea pentru care a fost antrenat?

<Question
	choices={[
		{
			text: "Nimic, dar primeÈ™ti un avertisment.",
			explain: "PrimiÈ›i un avertisment, dar asta nu e tot!"
		},
		{
			text: "Head-ul modelului preantrenat este eliminat, iar Ã®n locul lui este inserat un head nou, potrivit pentru sarcinÄƒ.",
			explain: "Corect. De exemplu, cÃ¢nd am folosit <code>AutoModelForSequenceClassification</code> cu <code>bert-base-uncased</code>, am primit avertismente la instanÈ›ierea modelului. Head-ul preantrenat nu este folosit pentru sarcina de clasificare secvenÈ›ialÄƒ, aÈ™a cÄƒ este eliminat È™i un nou head este instanÈ›iat cu greutÄƒÈ›i iniÈ›ializate aleator.",
            correct: true
		},
		{
			text: "Head-ul modelului preantrenat este eliminat.",
			explain: "Mai trebuie sÄƒ se Ã®ntÃ¢mple È™i altceva. ÃncercaÈ›i din nou!"
		},
        {
			text: "Nimic, pentru cÄƒ modelul poate fi ajustat fin (fine-tuned) chiar È™i pentru o altÄƒ sarcinÄƒ.",
			explain: "Head-ul preantrenat al modelului nu a fost antrenat pentru aceastÄƒ sarcinÄƒ, deci trebuie eliminat!"
		}
	]}
/>

### 8. Care este scopul folosirii `TrainingArguments`?

<Question
	choices={[
		{
			text: "ConÈ›ine toÈ›i hiperparametrii folosiÈ›i pentru antrenare È™i evaluare cu <code>Trainer</code>.",
			explain: "Corect!",
            correct: true
		},
		{
			text: "SpecificÄƒ dimensiunea modelului.",
			explain: "Dimensiunea modelului este definitÄƒ de configuraÈ›ia modelului, nu de clasa <code>TrainingArguments</code>."
		},
		{
			text: "ConÈ›ine doar hiperparametrii folosiÈ›i pentru evaluare.",
			explain: "Ãn exemplu, am specificat È™i unde va fi salvat modelul È™i checkpoint-urile. ÃncercaÈ›i din nou!"
		},
        {
			text: "ConÈ›ine doar hiperparametrii folosiÈ›i pentru antrenare.",
			explain: "Ãn exemplu, am folosit È™i un <code>evaluation_strategy</code>, aÈ™adar acest lucru afecteazÄƒ evaluarea. ÃncercaÈ›i din nou!"
		}
	]}
/>

### 9. De ce ar trebui sÄƒ folosiÈ›i biblioteca ğŸ¤— Accelerate?

<Question
	choices={[
		{
			text: "OferÄƒ acces la modele mai rapide.",
			explain: "Nu, biblioteca ğŸ¤— Accelerate nu oferÄƒ niciun model."
		},
		{
			text: "OferÄƒ o API la nivel Ã®nalt, astfel Ã®ncÃ¢t sÄƒ nu fie nevoie sÄƒ implementaÈ›i propria buclÄƒ de antrenament.",
			explain: "Asta am fÄƒcut cu <code>Trainer</code>, nu cu biblioteca ğŸ¤— Accelerate. ÃncercaÈ›i din nou!"
		},
		{
			text: "Face ca buclele noastre de antrenament sÄƒ funcÈ›ioneze pe strategii distribuite.",
			explain: "Corect! Cu ğŸ¤— Accelerate, buclele voastre de antrenament vor funcÈ›iona pentru mai multe GPU-uri È™i TPU-uri.",
            correct: true
		},
        {
			text: "OferÄƒ mai multe funcÈ›ii de optimizare.",
			explain: "Nu, biblioteca ğŸ¤— Accelerate nu oferÄƒ nicio funcÈ›ie de optimizare."
		}
	]}
/>

{:else}
### 4. Ce se Ã®ntÃ¢mplÄƒ cÃ¢nd instanÈ›iaÈ›i una dintre clasele `TFAutoModelForXxx` cu un model de limbaj preantrenat (cum ar fi `bert-base-uncased`), care corespunde unei alte sarcini decÃ¢t cea pentru care a fost antrenat?

<Question
	choices={[
		{
			text: "Nimic, dar primeÈ™ti un avertisment.",
			explain: "PrimiÈ›i un avertisment, dar asta nu e tot!"
		},
		{
			text: "Head-ul modelului preantrenat este eliminat, iar Ã®n locul lui este inserat un head nou, potrivit pentru sarcinÄƒ.",
			explain: "Corect. De exemplu, cÃ¢nd am folosit <code>TFAutoModelForSequenceClassification</code> cu <code>bert-base-uncased</code>, am primit avertismente la instanÈ›ierea modelului. Head-ul preantrenat nu este folosit pentru sarcina de clasificare secvenÈ›ialÄƒ, aÈ™a cÄƒ este eliminat È™i un nou head este instanÈ›iat cu greutÄƒÈ›i iniÈ›ializate aleator.",
            correct: true
		},
		{
			text: "Head-ul modelului preantrenat este eliminat.",
			explain: "Mai trebuie sÄƒ se Ã®ntÃ¢mple È™i altceva. ÃncercaÈ›i din nou!"
		},
        {
			text: "Nimic, pentru cÄƒ modelul poate fi ajustat fin (fine-tuned) chiar È™i pentru o altÄƒ sarcinÄƒ.",
			explain: "Head-ul preantrenat al modelului nu a fost antrenat pentru aceastÄƒ sarcinÄƒ, deci trebuie eliminat!"
		}
	]}
/>

### 5. Modelele TensorFlow din `transformers` sunt deja modele Keras. Ce avantaj oferÄƒ acest lucru?

<Question
	choices={[
		{
			text: "Modelele funcÈ›ioneazÄƒ pe un TPU din start.",
			explain: "EÈ™ti pe aproape! TotuÈ™i, sunt necesare cÃ¢teva modificÄƒri suplimentare. De exemplu, trebuie sÄƒ rulaÈ›i totul Ã®ntr-un context <code>TPUStrategy</code>, inclusiv iniÈ›ializarea modelului."
		},
		{
			text: "PuteÈ›i valorifica metodele existente precum <code>compile()</code>, <code>fit()</code> È™i <code>predict()</code>.",
			explain: "Corect! OdatÄƒ ce aveÈ›i datele, antrenarea necesitÄƒ foarte puÈ›in efort.",
            correct: true
		},
		{
			text: "ÃnvÄƒÈ›aÈ›i atÃ¢t Keras, cÃ¢t È™i transformers.",
			explain: "Corect, dar cÄƒutÄƒm altceva :)",
			correct: true
		},
        {
			text: "PuteÈ›i calcula cu uÈ™urinÈ›Äƒ metrici legate de dataset.",
			explain: "Keras ne ajutÄƒ la antrenarea È™i evaluarea modelului, nu la calcularea metricilor legate de dataset."
		}
	]}
/>

### 6. Cum vÄƒ puteÈ›i defini propria metricÄƒ personalizatÄƒ?

<Question
	choices={[
		{
			text: "Prin moÈ™tenirea <code>tf.keras.metrics.Metric</code>.",
			explain: "Perfect!",
			correct: true
		},
		{
			text: "Folosind API-ul funcÈ›ional Keras.",
			explain: "Mai Ã®ncearcÄƒ!"
		},
		{
			text: "Folosind o funcÈ›ie apelabilÄƒ cu semnÄƒtura <code>metric_fn(y_true, y_pred)</code>.",
			explain: "Corect!",
			correct: true
		},
        {
			text: "CÄƒutÃ¢nd pe Google.",
			explain: "Nu este rÄƒspunsul pe care Ã®l cÄƒutÄƒm, dar probabil v-ar putea ajuta sÄƒ-l gÄƒsiÈ›i.",
			correct: true
		}
	]}
/>

{/if}