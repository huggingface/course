<CourseFloatingBanner chapter={2}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/main/course/en/chapter11/section3.ipynb"},
]} />

# Fine-tuning supervizat

Fine-tuningul supervizat (SFT) este un proces folosit 칥n principal pentru a adapta modelele de limbaj pre-antrenate s캒 urmeze instruc탵iuni, s캒 se angajeze 칥n dialog 탳i s캒 foloseasc캒 formate specifice de ie탳ire. 칉n timp ce modelele pre-antrenate au capacit캒탵i generale impresionante, SFT ajut캒 la transformarea lor 칥n modele asem캒n캒toare asistentului care pot 칥n탵elege 탳i r캒spunde mai bine la prompturile utilizatorilor. Acest lucru se realizeaz캒 de obicei prin antrenare pe seturi de date cu conversa탵ii 탳i instruc탵iuni scrise de oameni.

Aceast캒 pagin캒 ofer캒 un ghid pas cu pas pentru fine-tuningul modelului [`deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B`](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B) folosind [`SFTTrainer`](https://huggingface.co/docs/trl/en/sft_trainer). Urm칙nd ace탳ti pa탳i, pute탵i adapta modelul s캒 칥ndeplineasc캒 anumite sarcini mai eficient.

## C칙nd s캒 utiliza탵i SFT

칉nainte de a se ad칙nci 칥n implementare, este important s캒 칥n탵elegem c칙nd SFT este alegerea potrivit캒 pentru proiectul dumneavoastr캒. Ca primul pas, ar trebui s캒 considera탵i dac캒 folosirea unui model existent ajustat pentru instruc탵iuni cu prompturi bine elaborate ar fi suficient캒 pentru cazul dumneavoastr캒 de utilizare. SFT implic캒 resurse computa탵ionale semnificative 탳i efort de inginerie, a탳a c캒 ar trebui urm캒rit doar c칙nd promptarea modelelor existente se dovede탳te insuficient캒.

<Tip>
Considera탵i SFT doar dac캒:
- Ave탵i nevoie de performan탵e suplimentare dincolo de ceea ce poate realiza promptarea
- Ave탵i un caz de utilizare specific 칥n care costul folosirii unui model mare de uz general dep캒탳e탳te costul fine-tuningului unui model mai mic
- Ave탵i nevoie de formate de ie탳ire specializate sau cuno탳tin탵e specifice domeniului cu care modelele existente se confrunt캒
</Tip>

Dac캒 determina탵i c캒 SFT este necesar, decizia de a continua depinde de doi factori principali:

### Controlul template-ului
SFT permite control precis asupra structurii de ie탳ire a modelului. Acest lucru este deosebit de valoros c칙nd ave탵i nevoie ca modelul s캒:
1. Genereze r캒spunsuri 칥ntr-un format specific de template de chat
2. Urmeze scheme stricte de ie탳ire
3. Men탵in캒 stiluri consecvente 칥n toate r캒spunsurile

### Adaptarea la domeniu
C칙nd lucra탵i 칥n domenii specializate, SFT ajut캒 la alinierea modelului cu cerin탵ele specifice domeniului prin:
1. Predarea terminologiei 탳i conceptelor domeniului
2. Impunerea standardelor profesionale
3. Gestionarea adecvat캒 a 칥ntreb캒rilor tehnice
4. Urmarea ghidurilor specifice industriei

<Tip>
칉nainte de a 칥ncepe SFT, evalua탵i dac캒 cazul dumneavoastr캒 de utilizare necesit캒:
- Formatare precis캒 de ie탳ire
- Cuno탳tin탵e specifice domeniului
- Modele consecvente de r캒spuns
- Aderarea la ghiduri specifice

Aceast캒 evaluare va ajuta s캒 determina탵i dac캒 SFT este abordarea potrivit캒 pentru nevoile dumneavoastr캒.
</Tip>

## Preg캒tirea setului de date

Procesul de fine-tuning supervizat necesit캒 un set de date specific sarcinii structurat cu perechi intrare-ie탳ire. Fiecare pereche ar trebui s캒 con탵in캒:
1. Un prompt de intrare
2. R캒spunsul a탳teptat al modelului
3. Orice context sau metadate suplimentare

Calitatea datelor de antrenare este crucial캒 pentru succesul fine-tuningului. S캒 vedem cum s캒 preg캒tim 탳i s캒 valid캒m setul de date:

<iframe
  src="https://huggingface.co/datasets/HuggingFaceTB/smoltalk/embed/viewer/all/train?row=0"
  frameborder="0"
  width="100%"
  height="360px"
></iframe>

## Configura탵ia antrenamentului

Succesul fine-tuningului depinde 칥n mare m캒sur캒 de alegerea parametrilor de antrenare corec탵i. S캒 explor캒m fiecare parametru important 탳i cum s캒 칥i configura탵i eficient:

Configura탵ia SFTTrainer necesit캒 considerarea mai multor parametri care controleaz캒 procesul de antrenare. S캒 explor캒m fiecare parametru 탳i scopul lor:

1. **Parametrii duratei antrenamentului**:
   - `num_train_epochs`: Controleaz캒 durata total캒 a antrenamentului
   - `max_steps`: Alternativ캒 la epoci, stabile탳te num캒rul maxim de pa탳i de antrenare
   - Mai multe epoci permit 칥nv캒탵are mai bun캒 dar risc캒 supraadaptarea

2. **Parametrii dimensiunii batch-ului**:
   - `per_device_train_batch_size`: Determin캒 utilizarea memoriei 탳i stabilitatea antrenamentului
   - `gradient_accumulation_steps`: Permite dimensiuni efective mai mari ale batch-ului
   - Batch-uri mai mari ofer캒 gradien탵i mai stabili dar necesit캒 mai mult캒 memorie

3. **Parametrii ratei de 칥nv캒탵are**:
   - `learning_rate`: Controleaz캒 dimensiunea actualiz캒rilor greut캒탵ilor
   - `warmup_ratio`: Por탵iunea de antrenament folosit캒 pentru 칥nc캒lzirea ratei de 칥nv캒탵are
   - Prea mare poate cauza instabilitate, prea mic캒 rezult캒 칥n 칥nv캒탵are lent캒

4. **Parametrii de monitorizare**:
   - `logging_steps`: Frecven탵a 칥nregistr캒rii metricilor
   - `eval_steps`: C칙t de des s캒 evalueze pe datele de validare
   - `save_steps`: Frecven탵a salv캒rii punctelor de verificare ale modelului

<Tip>
칉ncepe탵i cu valori conservatoare 탳i ajusta탵i bazat pe monitorizare:
- 칉ncepe탵i cu 1-3 epoci
- Folosi탵i dimensiuni mai mici ale batch-ului ini탵ial
- Monitoriza탵i metricile de validare atent
- Ajusta탵i rata de 칥nv캒탵are dac캒 antrenamentul este instabil
</Tip>

## Implementare cu TRL

Acum c캒 칥n탵elegem componentele cheie, s캒 implement캒m antrenamentul cu validare 탳i monitorizare adecvate. Vom folosi clasa `SFTTrainer` din biblioteca Transformers Reinforcement Learning (TRL), care este construit캒 pe biblioteca `transformers`. Iat캒 un exemplu complet folosind biblioteca TRL:

```python
from datasets import load_dataset
from trl import SFTConfig, SFTTrainer
import torch

# Seta탵i dispozitivul
device = "cuda" if torch.cuda.is_available() else "cpu"

# 칉nc캒rca탵i setul de date
dataset = load_dataset("HuggingFaceTB/smoltalk", "all")

# Configura탵i modelul 탳i tokenizer-ul
model_name = "HuggingFaceTB/SmolLM2-135M"
model = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=model_name).to(
    device
)
tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_name)
# Configura탵i template-ul de chat
model, tokenizer = setup_chat_format(model=model, tokenizer=tokenizer)

# Configura탵i trainer-ul
training_args = SFTConfig(
    output_dir="./sft_output",
    max_steps=1000,
    per_device_train_batch_size=4,
    learning_rate=5e-5,
    logging_steps=10,
    save_steps=100,
    eval_strategy="steps",
    eval_steps=50,
)

# Ini탵ializa탵i trainer-ul
trainer = SFTTrainer(
    model=model,
    args=training_args,
    train_dataset=dataset["train"],
    eval_dataset=dataset["test"],
    processing_class=tokenizer,
)

# 칉ncepe탵i antrenamentul
trainer.train()
```

<Tip>
C칙nd folosi탵i un set de date cu un c칙mp "messages" (ca exemplul de mai sus), SFTTrainer aplic캒 automat template-ul de chat al modelului, pe care 칥l recupereaz캒 de pe hub. Aceasta 칥nseamn캒 c캒 nu ave탵i nevoie de nicio configura탵ie suplimentar캒 pentru a gestiona conversa탵iile 칥n stil chat - trainer-ul va formata mesajele conform formatului de template a탳teptat al modelului.
</Tip>

## 칉mpachetarea setului de date

SFTTrainer suport캒 칥mpachetarea exemplelor pentru a optimiza eficien탵a antrenamentului. Aceast캒 func탵ionalitate permite ca mai multe exemple scurte s캒 fie 칥mpachetate 칥n aceea탳i secven탵캒 de intrare, maximiz칙nd utilizarea GPU 칥n timpul antrenamentului. Pentru a activa 칥mpachetarea, pur 탳i simplu seta탵i `packing=True` 칥n constructorul SFTConfig. C칙nd folosi탵i seturi de date 칥mpachetate cu `max_steps`, fi탵i con탳tien탵i c캒 s-ar putea s캒 antrena탵i pentru mai multe epoci dec칙t a탵i a탳teptat, 칥n func탵ie de configura탵ia de 칥mpachetare. Pute탵i personaliza modul 칥n care exemplele sunt combinate folosind o func탵ie de formatare - deosebit de util캒 c칙nd lucra탵i cu seturi de date care au mai multe c칙mpuri precum perechi 칥ntrebare-r캒spuns. Pentru seturile de date de evaluare, pute탵i dezactiva 칥mpachetarea set칙nd `eval_packing=False` 칥n SFTConfig. Iat캒 un exemplu de baz캒 de personalizare a configura탵iei de 칥mpachetare:

```python
# Configura탵i 칥mpachetarea
training_args = SFTConfig(packing=True)

trainer = SFTTrainer(model=model, train_dataset=dataset, args=training_args)

trainer.train()
```

C칙nd 칥mpacheta탵i setul de date cu mai multe c칙mpuri, pute탵i defini o func탵ie de formatare personalizat캒 pentru a combina c칙mpurile 칥ntr-o singur캒 secven탵캒 de intrare. Aceast캒 func탵ie ar trebui s캒 ia o list캒 de exemple 탳i s캒 returneze un dic탵ionar cu secven탵a de intrare 칥mpachetat캒. Iat캒 un exemplu de func탵ie de formatare personalizat캒:

```python
def formatting_func(example):
    text = f"### Question: {example['question']}\n ### Answer: {example['answer']}"
    return text


training_args = SFTConfig(packing=True)
trainer = SFTTrainer(
    "facebook/opt-350m",
    train_dataset=dataset,
    args=training_args,
    formatting_func=formatting_func,
)
```

## Monitorizarea progresului antrenamentului

Monitorizarea eficient캒 este crucial캒 pentru succesul fine-tuningului. S캒 explor캒m ce s캒 urm캒rim 칥n timpul antrenamentului:

### 칉n탵elegerea modelelor de pierdere

Pierderea antrenamentului urmeaz캒 de obicei trei faze distincte:
1. Sc캒dere abrupt캒 ini탵ial캒: Adaptare rapid캒 la noua distribu탵ie de date
2. Stabilizare gradual캒: Rata de 칥nv캒탵are 칥ncetine탳te pe m캒sur캒 ce modelul se ajusteaz캒 fin
3. Convergen탵a: Valorile pierderilor se stabilizeaz캒, indic칙nd finalizarea antrenamentului

<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/nlp_course_sft_loss_graphic.png" alt="Antrenamentul SFTTrainer" />

### Metrici de monitorizat

Monitorizarea eficient캒 implic캒 urm캒rirea metricilor cantitative 탳i evaluarea metricilor calitative. Metricile disponibile sunt:

- Pierderea antrenamentului
- Pierderea valid캒rii
- Progresia ratei de 칥nv캒탵are
- Normele gradientului

<Tip warning={true}>
Urm캒ri탵i aceste semne de avertizare 칥n timpul antrenamentului:
1. Pierderea valid캒rii cre탳te 칥n timp ce pierderea antrenamentului scade (supraadaptare)
2. Nicio 칥mbun캒t캒탵ire semnificativ캒 칥n valorile pierderilor (subadaptare)
3. Valori extrem de mici ale pierderilor (posibil캒 memorizare)
4. Formatare inconsistent캒 a ie탳irii (probleme de 칥nv캒탵are a template-ului)
</Tip>

### Calea c캒tre convergen탵캒

Pe m캒sur캒 ce antrenamentul progreseaz캒, curba pierderii ar trebui s캒 se stabilizeze treptat. Indicatorul cheie al antrenamentului s캒n캒tos este un decalaj mic 칥ntre pierderea antrenamentului 탳i cea de validare, suger칙nd c캒 modelul 칥nva탵캒 modele generalizabile mai degrab캒 dec칙t s캒 memoreze exemple specifice. Valorile absolute ale pierderilor vor varia 칥n func탵ie de sarcina 탳i setul de date.

### Monitorizarea progresului antrenamentului

Graficul de mai sus arat캒 o progresie tipic캒 a antrenamentului. Observa탵i cum at칙t pierderea antrenamentului, c칙t 탳i cea de validare scad brusc la 칥nceput, apoi se niveleaz캒 treptat. Acest model indic캒 faptul c캒 modelul 칥nva탵캒 eficient men탵in칙nd 칥n acela탳i timp capacitatea de generalizare.

### Semne de avertizare de urm캒rit

Mai multe modele 칥n curbele pierderilor pot indica probleme poten탵iale. Mai jos ilustr캒m semne comune de avertizare 탳i solu탵ii pe care le putem considera.

<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/sft_loss_1.png" alt="Antrenamentul SFTTrainer" />

Dac캒 pierderea valid캒rii scade cu o rat캒 semnificativ mai lent캒 dec칙t pierderea antrenamentului, modelul probabil se supraadapteaz캒 la datele de antrenare. Considera탵i:
- Reducerea pa탳ilor de antrenare
- Cre탳terea dimensiunii setului de date
- Validarea calit캒탵ii 탳i diversit캒탵ii setului de date

<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/sft_loss_2.png" alt="Antrenamentul SFTTrainer" />

Dac캒 pierderea nu arat캒 칥mbun캒t캒탵iri semnificative, modelul ar putea s캒:
- 칉nve탵e prea 칥ncet (칥ncerca탵i s캒 cre탳te탵i rata de 칥nv캒탵are)
- Se confrunte cu sarcina (verifica탵i calitatea datelor 탳i complexitatea sarcinii)
- Ating캒 limit캒rile arhitecturii (considera탵i un model diferit)

<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/sft_loss_3.png" alt="Antrenamentul SFTTrainer" />

Valori extrem de mici ale pierderilor ar putea sugera memorizare mai degrab캒 dec칙t 칥nv캒탵are. Acest lucru este deosebit de 칥ngrijor캒tor dac캒:
- Modelul performeaz캒 slab pe exemple noi, similare
- Ie탳irile lipsesc de diversitate
- R캒spunsurile sunt prea similare cu exemplele de antrenare

<Tip warning={true}>
Monitoriza탵i at칙t valorile pierderilor, c칙t 탳i ie탳irile efective ale modelului 칥n timpul antrenamentului. Uneori pierderea poate ar캒ta bine 칥n timp ce modelul dezvolt캒 comportamente nedorite. Evaluarea calitativ캒 regulat캒 a r캒spunsurilor modelului ajut캒 la detectarea problemelor pe care metricile singure le-ar putea rata.
</Tip>

Ar trebui s캒 observ캒m c캒 interpretarea valorilor pierderilor pe care o descriem aici este destinat캒 cazului cel mai comun, 탳i de fapt, valorile pierderilor se pot comporta 칥n moduri diferite 칥n func탵ie de model, setul de date, parametrii de antrenare, etc. Dac캒 sunte탵i interesa탵i s캒 explora탵i mai multe despre modelele descrise, ar trebui s캒 consulta탵i acest articol de blog de la oamenii de la [Fast AI](https://www.fast.ai/posts/2023-09-04-learning-jumps/).

## Evaluarea dup캒 SFT

칉n sec탵iunea [11.4](/en/chapter11/4) vom 칥nv캒탵a cum s캒 evalu캒m modelul folosind seturi de date de referin탵캒. Pentru moment, ne vom concentra pe evaluarea calitativ캒 a modelului.

Dup캒 finalizarea SFT, considera탵i aceste ac탵iuni de urm캒rire:

1. Evalua탵i modelul temeinic pe datele de test p캒strate deoparte
2. Valida탵i aderarea la template pe diverse intr캒ri
3. Testa탵i re탵inerea cuno탳tin탵elor specifice domeniului
4. Monitoriza탵i metricile de performan탵캒 din lumea real캒

<Tip>
Documenta탵i procesul de antrenare, inclusiv:
- Caracteristicile setului de date
- Parametrii antrenamentului
- Metricile de performan탵캒
- Limit캒rile cunoscute
Aceast캒 documenta탵ie va fi valoroas캒 pentru itera탵iile viitoare ale modelului.
</Tip>

## Chestionar

### 1. Ce parametri controleaz캒 durata antrenamentului 칥n SFT?

<Question
	choices={[
		{
			text: "num_train_epochs 탳i max_steps",
			explain: "Corect! Ace탳ti parametri determin캒 c칙t timp va antrena modelul, fie prin num캒rul de epoci, fie prin pa탳ii totali.",
			correct: true
		},
		{
			text: "batch_size 탳i learning_rate",
			explain: "De탳i ace탳tia afecteaz캒 antrenamentul, nu controleaz캒 direct durata."
		},
		{
			text: "gradient_checkpointing 탳i warmup_ratio",
			explain: "Ace탳ti parametri afecteaz캒 eficien탵a 탳i stabilitatea antrenamentului, nu durata."
		}
	]}
/>

### 2. Ce model 칥n curbele pierderilor indic캒 supraadaptarea poten탵ial캒?

<Question
    choices={[
        {
            text: "Pierderea valid캒rii cre탳te 칥n timp ce pierderea antrenamentului continu캒 s캒 scad캒",
            explain: "Corect! Aceast캒 divergen탵캒 칥ntre pierderea antrenamentului 탳i cea de validare este un semn clasic al supraadapt캒rii.",
            correct: true
        },
        {
            text: "At칙t pierderea antrenamentului, c칙t 탳i cea de validare scad constant",
            explain: "Acest model indic캒 de fapt un antrenament s캒n캒tos."
        },
        {
            text: "Pierderea antrenamentului r캒m칙ne constant캒 칥n timp ce pierderea valid캒rii scade",
            explain: "Acesta ar fi un model neobi탳nuit 탳i nu indic캒 supraadaptarea."
        }
    ]}
/>

### 3. Pentru ce este folosit gradient_accumulation_steps?

<Question
    choices={[
        {
            text: "Pentru a cre탳te dimensiunea efectiv캒 a batch-ului f캒r캒 a folosi mai mult캒 memorie",
            explain: "Corect! Acumuleaz캒 gradien탵ii pe mai multe treceri 칥nainte 칥nainte de a actualiza greut캒탵ile.",
            correct: true
        },
        {
            text: "Pentru a salva puncte de verificare 칥n timpul antrenamentului",
            explain: "Aceasta este gestionat캒 de parametrii save_steps 탳i save_strategy."
        },
        {
            text: "Pentru a controla programul ratei de 칥nv캒탵are",
            explain: "Programarea ratei de 칥nv캒탵are este controlat캒 de learning_rate 탳i warmup_ratio."
        }
    ]}
/>

### 4. Ce ar trebui s캒 monitoriza탵i 칥n timpul antrenamentului SFT?

<Question
    choices={[
        {
            text: "At칙t metricile cantitative, c칙t 탳i ie탳irile calitative",
            explain: "Corect! Monitorizarea ambelor tipuri de metrici ajut캒 la detectarea tuturor problemelor poten탵iale.",
            correct: true
        },
        {
            text: "Doar pierderea antrenamentului",
            explain: "Pierderea antrenamentului singur캒 nu este suficient캒 pentru a asigura un comportament bun al modelului."
        },
        {
            text: "Doar calitatea ie탳irii modelului",
            explain: "De탳i important캒, evaluarea calitativ캒 singur캒 rateaz캒 dinamici importante ale antrenamentului."
        }
    ]}
/>

### 5. Ce indic캒 convergen탵a s캒n캒toas캒 칥n timpul antrenamentului?

<Question
    choices={[
        {
            text: "Un decalaj mic 칥ntre pierderea antrenamentului 탳i cea de validare",
            explain: "Corect! Aceasta indic캒 faptul c캒 modelul 칥nva탵캒 modele generalizabile.",
            correct: true
        },
        {
            text: "Pierderea antrenamentului ajung칙nd la zero",
            explain: "Valori extrem de mici ale pierderilor ar putea indica memorizare mai degrab캒 dec칙t 칥nv캒탵are."
        },
        {
            text: "Pierderea valid캒rii fiind mai mic캒 dec칙t pierderea antrenamentului",
            explain: "Aceasta ar fi neobi탳nuit캒 탳i ar putea indica probleme cu setul de validare."
        }
    ]}
/>

## 游눓 Bun캒 treab캒!

A탵i 칥nv캒탵at cum s캒 face탵i fine-tuning la modele folosind SFT! Pentru a continua 칥nv캒탵area:
1. 칉ncerca탵i notebook-ul cu parametri diferi탵i
2. Experimenta탵i cu alte seturi de date
3. Contribui탵i cu 칥mbun캒t캒탵iri la materialul cursului

## Resurse adi탵ionale

- [Documenta탵ia TRL](https://huggingface.co/docs/trl)
- [Depozitul de exemple SFT](https://github.com/huggingface/trl/blob/main/trl/scripts/sft.py)
- [Cele mai bune practici pentru fine-tuning](https://huggingface.co/docs/transformers/training) 