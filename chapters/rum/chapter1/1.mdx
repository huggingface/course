# Introducere[[introducere]]

<CourseFloatingBanner
    chapter={1}
    classNames="absolute z-10 right-0 top-0"
/>

## Bun venit la ğŸ¤— curs![[bun-venit-la-curs]]

<Youtube id="00GKzGyWFEs" />
Acest curs vÄƒ va Ã®nvÄƒÈ›a despre procesarea limbajelor naturale (NLP) folosind biblioteci din [Hugging Face](https://huggingface.co/) ecosystem â€” [ğŸ¤— Transformers](https://github.com/huggingface/transformers), [ğŸ¤— Datasets](https://github.com/huggingface/datasets), [ğŸ¤— Tokenizers](https://github.com/huggingface/tokenizers), and [ğŸ¤— Accelerate](https://github.com/huggingface/accelerate) â€” precum È™i [Hugging Face Hub](https://huggingface.co/models).Este complet gratuit È™i nu conÈ›ine reclame.

## La ce sÄƒ te aÈ™tepÈ›i?[[la-ce-sa-te-aÈ™tepÈ›i]]

Aceasta este o scurtÄƒ prezentare a cursului:

<div class="flex justify-center">
<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary.svg" alt="Brief overview of the chapters of the course.">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary-dark.svg" alt="Brief overview of the chapters of the course.">
</div>

- Capitolele 1-4 oferÄƒ o introducere Ã®n conceptele fundamentale ale bibliotecii ğŸ¤— Transformers. PÃ¢nÄƒ la sfÃ¢rÈ™itul acestei pÄƒrÈ›i a cursului, veÈ›i fi familiarizaÈ›i cu modul Ã®n care funcÈ›ioneazÄƒ modelele Transformer È™i veÈ›i È™ti cum sÄƒ utilizaÈ›i un model din [Hugging Face Hub](https://huggingface.co/models), sÄƒ Ã®l ajustaÈ›i pe un set de date È™i sÄƒ vÄƒ partajaÈ›i rezultatele pe Hub!
- # Introducere[[introduction]]

<CourseFloatingBanner
    chapter={1}
    classNames="absolute z-10 right-0 top-0"
/>

## Bun venit la ğŸ¤— curs![[bun-venit-la-curs]]

<Youtube id="00GKzGyWFEs" />
Acest curs vÄƒ va Ã®nvÄƒÈ›a despre procesarea limbajelor naturale (NLP) folosind biblioteci din [Hugging Face](https://huggingface.co/) ecosystem â€” [ğŸ¤— Transformers](https://github.com/huggingface/transformers), [ğŸ¤— Datasets](https://github.com/huggingface/datasets), [ğŸ¤— Tokenizers](https://github.com/huggingface/tokenizers), and [ğŸ¤— Accelerate](https://github.com/huggingface/accelerate) â€” precum È™i [Hugging Face Hub](https://huggingface.co/models).Este complet gratuit È™i nu conÈ›ine reclame.

## La ce sÄƒ te aÈ™tepÈ›i?[[la-ce-sa-te-aÈ™tepÈ›i]]

Aceasta este o scurtÄƒ prezentare a cursului:

<div class="flex justify-center">
<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary.svg" alt="Brief overview of the chapters of the course.">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary-dark.svg" alt="Brief overview of the chapters of the course.">
</div>

- Capitolele 1-4 oferÄƒ o introducere Ã®n conceptele fundamentale ale bibliotecii ğŸ¤— Transformers. PÃ¢nÄƒ la sfÃ¢rÈ™itul acestei pÄƒrÈ›i a cursului, veÈ›i fi familiarizaÈ›i cu modul Ã®n care funcÈ›ioneazÄƒ modelele Transformer È™i veÈ›i È™ti cum sÄƒ utilizaÈ›i un model din [Hugging Face Hub](https://huggingface.co/models), sÄƒ Ã®l ajustaÈ›i pe un set de date È™i sÄƒ vÄƒ partajaÈ›i rezultatele pe Hub!
- Capitolele 5-8 predau elementele de bazÄƒ ale Datasets ğŸ¤— È™i ale Tokenizerelor ğŸ¤— Ã®nainte de a vÄƒ scufunda Ã®n sarcinile NLP. PÃ¢nÄƒ la sfÃ¢rÈ™itul acestei pÄƒrÈ›i, veÈ›i fi capabil sÄƒ abordaÈ›i singur cele mai frecvente probleme NLP.
- Capitolele 9-12 trec dincolo de NLP È™i exploreazÄƒ modul Ã®n care modelele Transformer pot fi utilizate pentru a aborda sarcini din domeniul procesÄƒrii semnalelor vorbirii È™i al viziunii computerizate. Pe parcurs, veÈ›i Ã®nvÄƒÈ›a cum sÄƒ construiÈ›i È™i sÄƒ partajaÈ›i demo-uri ale modelelor dumneavoastrÄƒ È™i cum sÄƒ le optimizaÈ›i pentru mediul de producÈ›ie. PÃ¢nÄƒ la sfÃ¢rÈ™itul acestei pÄƒrÈ›i, veÈ›i fi gata sÄƒ aplicaÈ›i ğŸ¤— Transformers la (aproape) orice problemÄƒ de machine learning!

Acest curs:

* NecesitÄƒ o bunÄƒ cunoaÈ™tere a limbajului Python.
* Este mai bine sÄƒ fie urmat dupÄƒ un curs introductiv de deep learning, cum ar fi [fast.ai's](https://www.fast.ai/) [Practical Deep Learning for Coders](https://course.fast.ai/) sau unul dintre programele dezvoltate de [DeepLearning.AI](https://www.deeplearning.ai/).
* Nu se aÈ™teaptÄƒ la cunoÈ™tinÈ›e anterioare despre [PyTorch](https://pytorch.org/) sau [TensorFlow](https://www.tensorflow.org/), deÈ™i o familiaritate cu oricare dintre acestea va fi de ajutor.

DupÄƒ ce aÈ›i completat acest curs, vÄƒ recomandÄƒm sÄƒ accesaÈ›i [Natural Language Processing Specialization] (https://www.coursera.org/specializations/natural-language-processing?utm_source=deeplearning-ai&utm_medium=institutions&utm_campaign=20211011-nlp-2-hugging_face-page-nlp-refresh) de la DeepLearning.AI, care acoperÄƒ o gamÄƒ largÄƒ de modele NLP clasice, cum ar fi naive Bayes È™i LSTMs, despre care este bine sÄƒ È™tiÈ›i!

## Cine suntem noi?[[cine-suntem-noi]]

Despre autori:

[**Abubakar Abid**](https://huggingface.co/abidlabs) È™i-a susÈ›inut doctoratul la Stanford Ã®n domeniul Ã®nvÄƒÈ›Äƒrii automate (Machine Learning) aplicate. Ãn timpul doctoratului sÄƒu, a fondat [Gradio](https://github.com/gradio-app/gradio), o bibliotecÄƒ Python open-source care a fost utilizatÄƒ pentru a construi peste 600.000 de demo-uri de Machine Learning. Gradio a fost achiziÈ›ionatÄƒ de Hugging Face, unde Abubakar activeazÄƒ acum ca lider al echipei de Machine Learning.

[**Matthew Carrigan**](https://huggingface.co/Rocketknight1) este inginer de Machine Learning la Hugging Face. LocuieÈ™te Ã®n Dublin, Irlanda È™i a lucrat anterior ca inginer ML la Parse.ly È™i Ã®nainte de asta ca cercetÄƒtor postdoctoral la Trinity College Dublin. El nu crede cÄƒ vom ajunge la AGI prin scalarea arhitecturilor existente, dar are mari speranÈ›e Ã®n ceea ce priveÈ™te nemurirea roboÈ›ilor.

[**Lysandre Debut**](https://huggingface.co/lysandre) este inginer de Machine Learning la Hugging Face È™i a lucrat la biblioteca ğŸ¤— Transformers Ã®ncÄƒ din primele etape de dezvoltare. Scopul sÄƒu este de a face NLP accesibil pentru toatÄƒ lumea prin dezvoltarea de instrumente cu un API foarte simplu.

[**Sylvain Gugger**](https://huggingface.co/sgugger) este inginer de cercetare Ã®n Machine Learning la Hugging Face È™i unul dintre principalii Ã®ntreÈ›inÄƒtori ai bibliotecii ğŸ¤— Transformers. Anterior a fost cercetÄƒtor È™tiinÈ›ific la fast.ai È™i a fost coautor la _[Deep Learning for Coders with fastai and PyTorch](https://learning.oreilly.com/library/view/deep-learning-for/9781492045519/)_ cu Jeremy Howard. Obiectivul principal al cercetÄƒrii sale este de a face Ã®nvÄƒÈ›area profundÄƒ mai accesibilÄƒ, prin proiectarea È™i Ã®mbunÄƒtÄƒÈ›irea tehnicilor care permit modelelor sÄƒ se antreneze rapid pe resurse limitate.

[**Dawood Khan**](https://huggingface.co/dawoodkhan82) este inginer de Machine Learning la Hugging Face. Este originar din New York È™i a absolvit Universitatea din New York, unde a studiat Informatica. DupÄƒ ce a lucrat ca inginer iOS timp de cÃ¢È›iva ani, Dawood a demisionat pentru a Ã®nfiinÈ›a Gradio Ã®mpreunÄƒ cu colegii sÄƒi co-fondatori. Gradio a fost Ã®n cele din urmÄƒ achiziÈ›ionat de Hugging Face.

[**Merve Noyan**](https://huggingface.co/merve) este un susÈ›inÄƒtor al dezvoltatorilor la Hugging Face, lucrÃ¢nd la dezvoltarea de instrumente È™i la crearea de conÈ›inut Ã®n jurul acestora pentru a facilita Ã®nvÄƒÈ›area automatÄƒ pentru toatÄƒ lumea. 

[**Lucile Saulnier**](https://huggingface.co/SaulLu) este inginer de Machine Learning la Hugging Face, dezvoltÃ¢nd È™i susÈ›inÃ¢nd utilizarea de instrumente open source. De asemenea, este implicatÄƒ activ Ã®n multe proiecte de cercetare Ã®n domeniul procesÄƒrii limbajului natural, cum ar fi formarea colaborativÄƒ È™i BigScience.

[**Lewis Tunstall**](https://huggingface.co/lewtun) este inginer de Machine Learning la Hugging Face, concentrÃ¢ndu-se pe dezvoltarea de instrumente open-source È™i pe asigurarea accesibilitÄƒÈ›ii acestora pentru Ã®ntreaga comunitate. De asemenea, este coautor al cÄƒrÈ›ii O'Reilly [Natural Language Processing with Transformers] (https://www.oreilly.com/library/view/natural-language-processing/9781098136789/).

[**Leandro von Werra**](https://huggingface.co/lvwerra) este inginer de Machine Learning Ã®n cadrul echipei open-source de la Hugging Face È™i, de asemenea, coautor al cÄƒrÈ›ii O'Reilly [Natural Language Processing with Transformers] (https://www.oreilly.com/library/view/natural-language-processing/9781098136789/). El are mai mulÈ›i ani de experienÈ›Äƒ Ã®n industrie, aducÃ¢nd proiecte NLP Ã®n stadiul de producÈ›ie, lucrÃ¢nd pe Ã®ntreaga stivÄƒ de Ã®nvÄƒÈ›are automatÄƒ.

## FAQ[[faq]]

IatÄƒ cÃ¢teva rÄƒspunsuri la Ã®ntrebÄƒri frecvente:

- **Acest curs permite obÈ›inerea unei certificÄƒri?**
DeocamdatÄƒ nu avem nicio certificare pentru acest curs. Cu toate acestea, lucrÄƒm la un program de certificare pentru ecosistemul Hugging Face - rÄƒmÃ¢neÈ›i pe fazÄƒ!

- **CÃ¢t timp ar trebui sÄƒ dedic acestui curs?**
Fiecare capitol din acest curs este conceput pentru a fi parcurs Ã®ntr-o sÄƒptÄƒmÃ¢nÄƒ, cu aproximativ 6-8 ore de lucru pe sÄƒptÄƒmÃ¢nÄƒ. Cu toate acestea, vÄƒ puteÈ›i lua cÃ¢t timp aveÈ›i nevoie pentru a finaliza cursul.

- **Unde pot sÄƒ pun o Ã®ntrebare dacÄƒ am una?**
DacÄƒ aveÈ›i o Ã®ntrebare despre orice secÈ›iune a cursului, faceÈ›i clic pe bannerul â€*Pune o Ã®ntrebare*â€ din partea de sus a paginii pentru a fi redirecÈ›ionat automat cÄƒtre secÈ›iunea corectÄƒ a [[Hugging Face forums](https://discuss.huggingface.co/):

<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/forum-button.png" alt="Link to the Hugging Face forums" width="75%">

ReÈ›ineÈ›i cÄƒ o listÄƒ de [idei de proiecte](https://discuss.huggingface.co/c/course/course-event/25) este de asemenea disponibilÄƒ pe forumuri dacÄƒ doriÈ›i sÄƒ practicaÈ›i mai mult dupÄƒ ce aÈ›i terminat cursul.

- **De unde pot obÈ›ine codul pentru curs?**
Pentru fiecare secÈ›iune, faceÈ›i clic pe bannerul din partea de sus a paginii pentru a rula codul Ã®n Google Colab sau Amazon SageMaker Studio Lab:

<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/notebook-buttons.png" alt="Link to the Hugging Face course notebooks" width="75%">

Caietele Jupyter care conÈ›in tot codul din curs sunt gÄƒzduite Ã®n repo-ul [`huggingface/notebooks`](https://github.com/huggingface/notebooks). DacÄƒ doriÈ›i sÄƒ le generaÈ›i local, consultaÈ›i instrucÈ›iunile din repo-ul [`course`](https://github.com/huggingface/course#-jupyter-notebooks) de pe GitHub.


- **Cum pot contribui la curs?**
ExistÄƒ multe modalitÄƒÈ›i de a contribui la curs! DacÄƒ gÄƒsiÈ›i o greÈ™ealÄƒ de tipar sau o eroare, vÄƒ rugÄƒm sÄƒ creaÈ›i o cerere Ã®n repo-ul [`course`](https://github.com/huggingface/course). DacÄƒ doriÈ›i sÄƒ ajutaÈ›i la traducerea cursului Ã®n limba dumneavoastrÄƒ maternÄƒ, consultaÈ›i instrucÈ›iunile [aici](https://github.com/huggingface/course#translating-the-course-into-your-language).

- **Care au fost alegerile fÄƒcute pentru fiecare traducere?**
Fiecare traducere are un glosar È™i un fiÈ™ier `TRANSLATING.txt` care detaliazÄƒ alegerile care au fost fÄƒcute pentru jargonul de Machine Learning etc. PuteÈ›i gÄƒsi un exemplu Ã®n limba germanÄƒ [aici](https://github.com/huggingface/course/blob/main/chapters/de/TRANSLATING.txt).


- **Pot reutiliza acest curs?**
Desigur! Cursul este distribuit sub licenÈ›a [Apache 2 license](https://www.apache.org/licenses/LICENSE-2.0.html) cu caracter permisiv. Aceasta Ã®nseamnÄƒ cÄƒ trebuie sÄƒ acordaÈ›i creditul corespunzÄƒtor, sÄƒ furnizaÈ›i un link cÄƒtre licenÈ›Äƒ È™i sÄƒ indicaÈ›i dacÄƒ au fost fÄƒcute modificÄƒri. PuteÈ›i face acest lucru Ã®n orice mod rezonabil, dar nu Ã®n niciun fel care sÄƒ sugereze cÄƒ licenÈ›iatorul vÄƒ aprobÄƒ pe dumneavoastrÄƒ sau utilizarea dumneavoastrÄƒ. DacÄƒ doriÈ›i sÄƒ citaÈ›i cursul, vÄƒ rugÄƒm sÄƒ utilizaÈ›i urmÄƒtorul BibTeX:

```
@misc{huggingfacecourse,
  author = {Hugging Face},
  title = {The Hugging Face Course, 2022},
  howpublished = "\url{https://huggingface.co/course}",
  year = {2022},
  note = "[Online; accessed <today>]"
}
```

## Let's Go
SunteÈ›i gata sÄƒ Ã®ncepeÈ›i? Ãn acest capitol, veÈ›i Ã®nvÄƒÈ›a:

* Cum sÄƒ utilizaÈ›i funcÈ›ia `pipeline()` pentru a rezolva sarcini NLP precum generarea È™i clasificarea textului
* Despre arhitectura Transformer
* Cum sÄƒ faceÈ›i distincÈ›ia Ã®ntre arhitecturile È™i cazurile de utilizare ale codificatorului, decodificatorului È™i codificatorului-decodificator.
- Capitolele 9-12 trec dincolo de NLP È™i exploreazÄƒ modul Ã®n care modelele Transformer pot fi utilizate pentru a aborda sarcini din domeniul procesÄƒrii semnalelor vorbirii È™i al viziunii computerizate. Pe parcurs, veÈ›i Ã®nvÄƒÈ›a cum sÄƒ construiÈ›i È™i sÄƒ partajaÈ›i demo-uri ale modelelor dumneavoastrÄƒ È™i cum sÄƒ le optimizaÈ›i pentru mediul de producÈ›ie. PÃ¢nÄƒ la sfÃ¢rÈ™itul acestei pÄƒrÈ›i, veÈ›i fi gata sÄƒ aplicaÈ›i ğŸ¤— Transformers la (aproape) orice problemÄƒ de machine learning!

Acest curs:

* NecesitÄƒ o bunÄƒ cunoaÈ™tere a limbajului Python.
* Este mai bine sÄƒ fie urmat dupÄƒ un curs introductiv de deep learning, cum ar fi [fast.ai's](https://www.fast.ai/) [Practical Deep Learning for Coders](https://course.fast.ai/) sau unul dintre programele dezvoltate de [DeepLearning.AI](https://www.deeplearning.ai/).
* Nu se aÈ™teaptÄƒ la cunoÈ™tinÈ›e anterioare despre [PyTorch](https://pytorch.org/) sau [TensorFlow](https://www.tensorflow.org/), deÈ™i o familiaritate cu oricare dintre acestea va fi de ajutor.

DupÄƒ ce aÈ›i completat acest curs, vÄƒ recomandÄƒm sÄƒ accesaÈ›i [Natural Language Processing Specialization] (https://www.coursera.org/specializations/natural-language-processing?utm_source=deeplearning-ai&utm_medium=institutions&utm_campaign=20211011-nlp-2-hugging_face-page-nlp-refresh) de la DeepLearning.AI, care acoperÄƒ o gamÄƒ largÄƒ de modele NLP clasice, cum ar fi naive Bayes È™i LSTMs, despre care este bine sÄƒ È™tiÈ›i!

## Cine suntem noi?[[cine-suntem-noi]]

Despre autori:

[**Abubakar Abid**](https://huggingface.co/abidlabs) È™i-a susÈ›inut doctoratul la Stanford Ã®n domeniul Ã®nvÄƒÈ›Äƒrii automate (Machine Learning) aplicate. Ãn timpul doctoratului sÄƒu, a fondat [Gradio](https://github.com/gradio-app/gradio), o bibliotecÄƒ Python open-source care a fost utilizatÄƒ pentru a construi peste 600.000 de demo-uri de Machine Learning. Gradio a fost achiziÈ›ionatÄƒ de Hugging Face, unde Abubakar activeazÄƒ acum ca lider al echipei de Machine Learning.

[**Matthew Carrigan**](https://huggingface.co/Rocketknight1) este inginer de Machine Learning la Hugging Face. LocuieÈ™te Ã®n Dublin, Irlanda È™i a lucrat anterior ca inginer ML la Parse.ly È™i Ã®nainte de asta ca cercetÄƒtor postdoctoral la Trinity College Dublin. El nu crede cÄƒ vom ajunge la AGI prin scalarea arhitecturilor existente, dar are mari speranÈ›e Ã®n ceea ce priveÈ™te nemurirea roboÈ›ilor.

[**Lysandre Debut**](https://huggingface.co/lysandre) este inginer de Machine Learning la Hugging Face È™i a lucrat la biblioteca ğŸ¤— Transformers Ã®ncÄƒ din primele etape de dezvoltare. Scopul sÄƒu este de a face NLP accesibil pentru toatÄƒ lumea prin dezvoltarea de instrumente cu un API foarte simplu.

[**Sylvain Gugger**](https://huggingface.co/sgugger) este inginer de cercetare Ã®n Machine Learning la Hugging Face È™i unul dintre principalii Ã®ntreÈ›inÄƒtori ai bibliotecii ğŸ¤— Transformers. Anterior a fost cercetÄƒtor È™tiinÈ›ific la fast.ai È™i a fost coautor la _[Deep Learning for Coders with fastai and PyTorch](https://learning.oreilly.com/library/view/deep-learning-for/9781492045519/)_ cu Jeremy Howard. Obiectivul principal al cercetÄƒrii sale este de a face Ã®nvÄƒÈ›area profundÄƒ mai accesibilÄƒ, prin proiectarea È™i Ã®mbunÄƒtÄƒÈ›irea tehnicilor care permit modelelor sÄƒ se antreneze rapid pe resurse limitate.

[**Dawood Khan**](https://huggingface.co/dawoodkhan82) este inginer de Machine Learning la Hugging Face. Este originar din New York È™i a absolvit Universitatea din New York, unde a studiat Informatica. DupÄƒ ce a lucrat ca inginer iOS timp de cÃ¢È›iva ani, Dawood a demisionat pentru a Ã®nfiinÈ›a Gradio Ã®mpreunÄƒ cu colegii sÄƒi co-fondatori. Gradio a fost Ã®n cele din urmÄƒ achiziÈ›ionat de Hugging Face.

[**Merve Noyan**](https://huggingface.co/merve) este un susÈ›inÄƒtor al dezvoltatorilor la Hugging Face, lucrÃ¢nd la dezvoltarea de instrumente È™i la crearea de conÈ›inut Ã®n jurul acestora pentru a facilita Ã®nvÄƒÈ›area automatÄƒ pentru toatÄƒ lumea. 

[**Lucile Saulnier**](https://huggingface.co/SaulLu) este inginer de Machine Learning la Hugging Face, dezvoltÃ¢nd È™i susÈ›inÃ¢nd utilizarea de instrumente open source. De asemenea, este implicatÄƒ activ Ã®n multe proiecte de cercetare Ã®n domeniul procesÄƒrii limbajului natural, cum ar fi formarea colaborativÄƒ È™i BigScience.

[**Lewis Tunstall**](https://huggingface.co/lewtun) este inginer de Machine Learning la Hugging Face, concentrÃ¢ndu-se pe dezvoltarea de instrumente open-source È™i pe asigurarea accesibilitÄƒÈ›ii acestora pentru Ã®ntreaga comunitate. De asemenea, este coautor al cÄƒrÈ›ii O'Reilly [Natural Language Processing with Transformers] (https://www.oreilly.com/library/view/natural-language-processing/9781098136789/).

[**Leandro von Werra**](https://huggingface.co/lvwerra) este inginer de Machine Learning Ã®n cadrul echipei open-source de la Hugging Face È™i, de asemenea, coautor al cÄƒrÈ›ii O'Reilly [Natural Language Processing with Transformers] (https://www.oreilly.com/library/view/natural-language-processing/9781098136789/). El are mai mulÈ›i ani de experienÈ›Äƒ Ã®n industrie, aducÃ¢nd proiecte NLP Ã®n stadiul de producÈ›ie, lucrÃ¢nd pe Ã®ntreaga stivÄƒ de Ã®nvÄƒÈ›are automatÄƒ.

## FAQ[[faq]]

IatÄƒ cÃ¢teva rÄƒspunsuri la Ã®ntrebÄƒri frecvente:

- **Acest curs permite obÈ›inerea unei certificÄƒri?**
DeocamdatÄƒ nu avem nicio certificare pentru acest curs. Cu toate acestea, lucrÄƒm la un program de certificare pentru ecosistemul Hugging Face - rÄƒmÃ¢neÈ›i pe fazÄƒ!

- **CÃ¢t timp ar trebui sÄƒ dedic acestui curs?**
Fiecare capitol din acest curs este conceput pentru a fi parcurs Ã®ntr-o sÄƒptÄƒmÃ¢nÄƒ, cu aproximativ 6-8 ore de lucru pe sÄƒptÄƒmÃ¢nÄƒ. Cu toate acestea, vÄƒ puteÈ›i lua cÃ¢t timp aveÈ›i nevoie pentru a finaliza cursul.

- **Unde pot sÄƒ pun o Ã®ntrebare dacÄƒ am una?**
DacÄƒ aveÈ›i o Ã®ntrebare despre orice secÈ›iune a cursului, faceÈ›i clic pe bannerul â€*Pune o Ã®ntrebare*â€ din partea de sus a paginii pentru a fi redirecÈ›ionat automat cÄƒtre secÈ›iunea corectÄƒ a [[Hugging Face forums](https://discuss.huggingface.co/):

<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/forum-button.png" alt="Link to the Hugging Face forums" width="75%">

ReÈ›ineÈ›i cÄƒ o listÄƒ de [idei de proiecte](https://discuss.huggingface.co/c/course/course-event/25) este de asemenea disponibilÄƒ pe forumuri dacÄƒ doriÈ›i sÄƒ practicaÈ›i mai mult dupÄƒ ce aÈ›i terminat cursul.

- **De unde pot obÈ›ine codul pentru curs?**
Pentru fiecare secÈ›iune, faceÈ›i clic pe bannerul din partea de sus a paginii pentru a rula codul Ã®n Google Colab sau Amazon SageMaker Studio Lab:

<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/notebook-buttons.png" alt="Link to the Hugging Face course notebooks" width="75%">

Caietele Jupyter care conÈ›in tot codul din curs sunt gÄƒzduite Ã®n repo-ul [`huggingface/notebooks`](https://github.com/huggingface/notebooks). DacÄƒ doriÈ›i sÄƒ le generaÈ›i local, consultaÈ›i instrucÈ›iunile din repo-ul [`course`](https://github.com/huggingface/course#-jupyter-notebooks) de pe GitHub.


- **Cum pot contribui la curs?**
ExistÄƒ multe modalitÄƒÈ›i de a contribui la curs! DacÄƒ gÄƒsiÈ›i o greÈ™ealÄƒ de tipar sau o eroare, vÄƒ rugÄƒm sÄƒ creaÈ›i o cerere Ã®n repo-ul [`course`](https://github.com/huggingface/course). DacÄƒ doriÈ›i sÄƒ ajutaÈ›i la traducerea cursului Ã®n limba dumneavoastrÄƒ maternÄƒ, consultaÈ›i instrucÈ›iunile [aici](https://github.com/huggingface/course#translating-the-course-into-your-language).

- **Care au fost alegerile fÄƒcute pentru fiecare traducere?**
Fiecare traducere are un glosar È™i un fiÈ™ier `TRANSLATING.txt` care detaliazÄƒ alegerile care au fost fÄƒcute pentru jargonul de Machine Learning etc. PuteÈ›i gÄƒsi un exemplu Ã®n limba germanÄƒ [aici](https://github.com/huggingface/course/blob/main/chapters/de/TRANSLATING.txt).


- **Pot reutiliza acest curs?**
Desigur! Cursul este distribuit sub licenÈ›a [Apache 2 license](https://www.apache.org/licenses/LICENSE-2.0.html) cu caracter permisiv. Aceasta Ã®nseamnÄƒ cÄƒ trebuie sÄƒ acordaÈ›i creditul corespunzÄƒtor, sÄƒ furnizaÈ›i un link cÄƒtre licenÈ›Äƒ È™i sÄƒ indicaÈ›i dacÄƒ au fost fÄƒcute modificÄƒri. PuteÈ›i face acest lucru Ã®n orice mod rezonabil, dar nu Ã®n niciun fel care sÄƒ sugereze cÄƒ licenÈ›iatorul vÄƒ aprobÄƒ pe dumneavoastrÄƒ sau utilizarea dumneavoastrÄƒ. DacÄƒ doriÈ›i sÄƒ citaÈ›i cursul, vÄƒ rugÄƒm sÄƒ utilizaÈ›i urmÄƒtorul BibTeX:

```
@misc{huggingfacecourse,
  author = {Hugging Face},
  title = {The Hugging Face Course, 2022},
  howpublished = "\url{https://huggingface.co/course}",
  year = {2022},
  note = "[Online; accessed <today>]"
}
```

## Let's Go
SunteÈ›i gata sÄƒ Ã®ncepeÈ›i? Ãn acest capitol, veÈ›i Ã®nvÄƒÈ›a:

* Cum sÄƒ utilizaÈ›i funcÈ›ia `pipeline()` pentru a rezolva sarcini NLP precum generarea È™i clasificarea textului
* Despre arhitectura Transformer
* Cum sÄƒ faceÈ›i distincÈ›ia Ã®ntre arhitecturile È™i cazurile de utilizare ale codificatorului, decodificatorului È™i codificatorului-decodificatort
