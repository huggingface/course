# Ce pot face modelele Transformer[[ce-pot-face-modelele-transformer]]

<CourseFloatingBanner chapter={1}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter1/section3.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter1/section3.ipynb"},
]} />

Ãn aceastÄƒ parte, vom vedea ce pot face modelele Transformer È™i vom folosi primul nostru instrument din biblioteca ğŸ¤— Transformers: funcÈ›ia `pipeline()`.

<Tip>
ğŸ‘€ VedeÈ›i butonul <em>Open in Colab</em> din dreapta sus? FaceÈ›i clic pe el pentru a deschide un notebook Google Colab cu toate exemplele de cod din aceastÄƒ secÈ›iune. Acest buton va fi prezent Ã®n orice secÈ›iune care conÈ›ine exemple de cod. 
DacÄƒ doriÈ›i sÄƒ executaÈ›i exemplele local, vÄƒ recomandÄƒm sÄƒ aruncaÈ›i o privire la <a href="/course/chapter0">setup</a>.
</Tip>

## Modelele Transformer sunt peste tot![[modelele-transformer-sunt-peste-tot]]

Modelele Transformer sunt utilizate pentru a rezolva toate tipurile de sarcini NLP, precum cele menÈ›ionate Ã®n secÈ›iunea anterioarÄƒ. IatÄƒ cÃ¢teva dintre companiile È™i organizaÈ›iile care utilizeazÄƒ modelele Hugging Face È™i Transformer, care de asemenea contribuie la dezvoltarea comunitÄƒÈ›ii prin partajarea modelelor lor:

<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/companies.PNG" alt="Companies using Hugging Face" width="100%">

Biblioteca [ğŸ¤— Transformers](https://github.com/huggingface/transformers) oferÄƒ funcÈ›ionalitatea de a crea È™i utiliza aceste modele partajate. [Model Hub](https://huggingface.co/models) conÈ›ine mii de modele preinstruite pe care oricine le poate descÄƒrca È™i utiliza. De asemenea, vÄƒ puteÈ›i Ã®ncÄƒrca propriile modele pe Hub!

<Tip>
âš ï¸ Hub-ul Hugging Face nu este limitat la modelele Transformer. Oricine poate partaja orice fel de modele sau seturi de date pe care le doreÈ™te! <a href="https://huggingface.co/join">CreaÈ›i un cont huggingface.co</a> pentru a beneficia de toate funcÈ›iile disponibile!
</Tip>

Ãnainte de a analiza funcÈ›ionarea internÄƒ a modelelor Transformer , sÄƒ ne oprim asupra unor exemple privind modul Ã®n care acestea pot fi utilizate pentru a rezolva unele probleme interesante de NLP.

## Lucrul cu pipelines[[lucrul-cu-pipelines]]

<Youtube id="tiZFewofSLM" />

Obiectul cel mai elementar din biblioteca ğŸ¤— Transformers este funcÈ›ia `pipeline()`. Aceasta conecteazÄƒ un model cu etapele sale necesare de preprocesare È™i postprocesare, permiÈ›Ã¢ndu-ne sÄƒ introducem direct orice text È™i sÄƒ obÈ›inem un rÄƒspuns inteligibil:

```python
from transformers import pipeline

classifier = pipeline("sentiment-analysis")
classifier("I've been waiting for a HuggingFace course my whole life.")
```

```python out
[{'label': 'POSITIVE', 'score': 0.9598047137260437}]
```

Putem adÄƒuga chiar È™i  mai multe propoziÈ›ii!

```python
classifier(
    ["I've been waiting for a HuggingFace course my whole life.", "I hate this so much!"]
)
```

```python out
[{'label': 'POSITIVE', 'score': 0.9598047137260437},
 {'label': 'NEGATIVE', 'score': 0.9994558095932007}]
```

Ãn mod implicit, aceast pipeline selecteazÄƒ un anumit model preinstruit care a fost ajustat pentru a analiza emoÈ›iile dintr-un text Ã®n limba englezÄƒ. Modelul este descÄƒrcat È™i pus Ã®n cache atunci cÃ¢nd creaÈ›i obiectul `classifier`. DacÄƒ rulaÈ›i din nou comanda, modelul din memoria cache va fi utilizat Ã®n locul acestuia È™i nu este nevoie sÄƒ descÄƒrcaÈ›i din nou modelul.

Atunci cÃ¢nd transmiteÈ›i un text cÄƒtre un pipeline, sunt necesari trei paÈ™i:

1. Textul este preprocesat Ã®ntr-un format pe care modelul Ã®l poate Ã®nÈ›elege.
2. Datele de intrare preprocesate sunt transmise modelului.
3. PredicÈ›iile modelului sunt postprocesate, astfel Ã®ncÃ¢t sÄƒ le puteÈ›i Ã®nÈ›elege.


Unele dintre [pipeline-urile disponibile] Ã®n prezent (https://huggingface.co/transformers/main_classes/pipelines) sunt:

- `feature-extraction` (obÈ›ine reprezentarea vectorialÄƒ a unui text)
- `fill-mask`
- `ner` (recunoaÈ™terea NE (named entity))
- `question-answering`
- `sentiment-analysis`
- `summarization`
- `text-generation`
- `translation`
- `zero-shot-classification`

SÄƒ aruncÄƒm o privire la cÃ¢teva dintre ele!

## Zero-shot classification[zero-shot-classification]]

Vom Ã®ncepe prin a aborda o sarcinÄƒ mai dificilÄƒ Ã®n care trebuie sÄƒ clasificÄƒm texte care nu au fost etichetate. Acesta este un scenariu comun Ã®n proiectele din lumea realÄƒ, deoarece adnotarea textului este de obicei costisitoare Ã®n timp È™i necesitÄƒ expertizÄƒ Ã®n domeniu. Pentru acest caz de utilizare, pipeline-ul `zero-shot-classification` este foarte puternicÄƒ: vÄƒ permite sÄƒ specificaÈ›i ce etichete sÄƒ utilizaÈ›i pentru clasificare, astfel Ã®ncÃ¢t sÄƒ nu trebuie sÄƒ vÄƒ bazaÈ›i pe etichetele modelului preinstruit. AÈ›i vÄƒzut deja cum modelul poate clasifica o propoziÈ›ie ca fiind pozitivÄƒ sau negativÄƒ folosind aceste douÄƒ etichete - dar poate, de asemenea, clasifica textul folosind orice alt set de etichete doriÈ›i.

```python
from transformers import pipeline

classifier = pipeline("zero-shot-classification")
classifier(
    "This is a course about the Transformers library",
    candidate_labels=["education", "politics", "business"],
)
```

```python out
{'sequence': 'This is a course about the Transformers library',
 'labels': ['education', 'business', 'politics'],
 'scores': [0.8445963859558105, 0.111976258456707, 0.043427448719739914]}
```

Aceast pipeline se numeÈ™te _zero-shot_ deoarece nu trebuie sÄƒ reglaÈ›i modelul pe datele dvs. pentru a o utiliza. Aceasta poate returna direct scoruri de probabilitate pentru orice listÄƒ de etichete doriÈ›i!

<Tip>

âœï¸ **ÃncercaÈ›i** JucaÈ›i-vÄƒ cu propriile secvenÈ›e È™i etichete È™i vedeÈ›i cum se comportÄƒ modelul.

</Tip>


## Text generation[[text-generation]]

SÄƒ vedem acum cum se utilizeazÄƒ un pipeline pentru a genera un text. Ideea principalÄƒ aici este cÄƒ furnizaÈ›i o solicitare, iar modelul o va completa automat prin generarea textului rÄƒmas. Acest lucru este similar cu funcÈ›ia de text previzibil care se gÄƒseÈ™te pe multe telefoane. Generarea textului implicÄƒ caracter aleatoriu, deci este normal sÄƒ nu obÈ›ineÈ›i aceleaÈ™i rezultate ca cele prezentate mai jos.

```python
from transformers import pipeline

generator = pipeline("text-generation")
generator("In this course, we will teach you how to")
```

```python out
[{'generated_text': 'In this course, we will teach you how to understand and use '
                    'data flow and data interchange when handling user data. We '
                    'will be working with one or more of the most commonly used '
                    'data flows â€” data flows of various types, as seen by the '
                    'HTTP'}]
```

PuteÈ›i controla cÃ¢te secvenÈ›e diferite sunt generate cu argumentul `num_return_sequences` È™i lungimea totalÄƒ a textului de ieÈ™ire cu argumentul `max_length`.

<Tip>

âœï¸ **ÃncercaÈ›i!** UtilizaÈ›i argumentele `num_return_sequences` È™i `max_length` pentru a genera douÄƒ propoziÈ›ii a cÃ¢te 15 cuvinte fiecare.

</Tip>


## Utilizarea oricÄƒrui model de pe Hub Ã®ntr-un pipeline[[utilizarea-oricÄƒrui-model-de-pe-hub-Ã®ntr-un-pipeline]]

Exemplele anterioare au utilizat modelul implicit pentru sarcina Ã®n cauzÄƒ, dar puteÈ›i alege, de asemenea, un anumit model din Hub pentru a-l utiliza Ã®ntr-un pipeline pentru o sarcinÄƒ specificÄƒ - de exemplu, generarea de text. AccesaÈ›i [Model Hub](https://huggingface.co/models) È™i faceÈ›i clic pe eticheta corespunzÄƒtoare din stÃ¢nga pentru a afiÈ™a numai modelele acceptate pentru sarcina respectivÄƒ. Ar trebui sÄƒ ajungeÈ›i la o paginÄƒ precum [aceasta](https://huggingface.co/models?pipeline_tag=text-generation).

SÄƒ Ã®ncercÄƒm modelul [`distilgpt2`](https://huggingface.co/distilgpt2)! IatÄƒ cum sÄƒ Ã®l Ã®ncÄƒrcaÈ›i Ã®n acelaÈ™i pipeline ca Ã®nainte:

```python
from transformers import pipeline

generator = pipeline("text-generation", model="distilgpt2")
generator(
    "In this course, we will teach you how to",
    max_length=30,
    num_return_sequences=2,
)
```

```python out
[{'generated_text': 'In this course, we will teach you how to manipulate the world and '
                    'move your mental and physical capabilities to your advantage.'},
 {'generated_text': 'In this course, we will teach you how to become an expert and '
                    'practice realtime, and with a hands on experience on both real '
                    'time and real'}]
```

PuteÈ›i sÄƒ vÄƒ Ã®mbunÄƒtÄƒÈ›iÈ›i cÄƒutarea unui model fÄƒcÃ¢nd clic pe tag-urile de limbaj È™i sÄƒ alegeÈ›i un model care va genera text Ã®n altÄƒ limbÄƒ. Model Hub conÈ›ine chiar È™i puncte de control pentru modele multilingve care acceptÄƒ mai multe limbi.

DupÄƒ ce selectaÈ›i un model fÄƒcÃ¢nd clic pe el, veÈ›i vedea cÄƒ existÄƒ un widget care vÄƒ permite sÄƒ Ã®l Ã®ncercaÈ›i direct online. Ãn acest fel, puteÈ›i testa rapid capacitÄƒÈ›ile modelului Ã®nainte de a-l descÄƒrca.

<Tip>

âœï¸ ** ÃncercaÈ›i!** UtilizaÈ›i filtrele pentru a gÄƒsi un model de generare a textului pentru o altÄƒ limbÄƒ. Nu ezitaÈ›i sÄƒ vÄƒ jucaÈ›i cu widget-ul È™i sÄƒ Ã®l utilizaÈ›i Ã®ntr-un pipeline!

</Tip>

### API-ul de inferenÈ›Äƒ[[api-ul-de-inferenÈ›Äƒ]]

Toate modelele pot fi testate direct prin browser utilizÃ¢nd API-ul de inferenÈ›Äƒ, care este disponibil pe site-ul Hugging Face [website] (https://huggingface.co/). VÄƒ puteÈ›i juca cu modelul direct pe aceastÄƒ paginÄƒ introducÃ¢nd text personalizat È™i urmÄƒrind cum modelul proceseazÄƒ datele de intrare.

API-ul de inferenÈ›Äƒ care alimenteazÄƒ widget-ul este, de asemenea, disponibil ca produs plÄƒtit, ceea ce este util dacÄƒ aveÈ›i nevoie de el pentru fluxurile dvs. de lucru. ConsultaÈ›i [pagina de preÈ›uri](https://huggingface.co/pricing) pentru mai multe detalii.

## Mask filling[[mask-filling]]

UrmÄƒtorul pipeline pe care il veÈ›i Ã®ncerca este `fill-mask`. Ideea acestei sarcini este de a completa golurile dintr-un text dat:

```python
from transformers import pipeline

unmasker = pipeline("fill-mask")
unmasker("This course will teach you all about <mask> models.", top_k=2)
```

```python out
[{'sequence': 'This course will teach you all about mathematical models.',
  'score': 0.19619831442832947,
  'token': 30412,
  'token_str': ' mathematical'},
 {'sequence': 'This course will teach you all about computational models.',
  'score': 0.04052725434303284,
  'token': 38163,
  'token_str': ' computational'}]
```

Argumentul `top_k` controleazÄƒ cÃ¢te posibilitÄƒÈ›i doriÈ›i sÄƒ fie afiÈ™ate. ReÈ›ineÈ›i cÄƒ aici modelul completeazÄƒ cuvÃ¢ntul special `<mask>`, care este adesea denumit *mask token*. Alte modele de umplere a mÄƒÈ™tii ar putea avea token-uri de mascÄƒ diferite, astfel Ã®ncÃ¢t este Ã®ntotdeauna bine sÄƒ verificaÈ›i cuvÃ¢ntul de mascÄƒ adecvat atunci cÃ¢nd exploraÈ›i alte modele. O modalitate de verificare este sÄƒ vÄƒ uitaÈ›i la cuvÃ¢ntul mascÄƒ utilizat Ã®n widget.

<Tip>

âœï¸ **ÃncercaÈ›i!** CÄƒutaÈ›i modelul `bert-base-cased` pe Hub È™i identificaÈ›i-i cuvÃ¢ntul mascÄƒ Ã®n widget-ul Inference API. Ce prezice acest model pentru propoziÈ›ia din exemplul nostru `pipeline` de mai sus?

</Tip>

## RecunoaÈ™terea NE (named entity)[[recunoaÈ™terea-NE]]

RecunoaÈ™terea (NE) este o sarcinÄƒ Ã®n care modelul trebuie sÄƒ gÄƒseascÄƒ care pÄƒrÈ›i din textul de intrare corespund unor entitÄƒÈ›i precum persoane, locaÈ›ii sau organizaÈ›ii. SÄƒ ne uitÄƒm la un exemplu:

```python
from transformers import pipeline

ner = pipeline("ner", grouped_entities=True)
ner("My name is Sylvain and I work at Hugging Face in Brooklyn.")
```

```python out
[{'entity_group': 'PER', 'score': 0.99816, 'word': 'Sylvain', 'start': 11, 'end': 18}, 
 {'entity_group': 'ORG', 'score': 0.97960, 'word': 'Hugging Face', 'start': 33, 'end': 45}, 
 {'entity_group': 'LOC', 'score': 0.99321, 'word': 'Brooklyn', 'start': 49, 'end': 57}
]
```

Aici, modelul a identificat corect cÄƒ Sylvain este o persoanÄƒ (PER), Hugging Face o organizaÈ›ie (ORG), iar Brooklyn o locaÈ›ie (LOC).

Trecem opÈ›iunea `grouped_entities=True` Ã®n funcÈ›ia de creare a pipeline-ului pentru a-i spune pipeline-ului sÄƒ regrupeze pÄƒrÈ›ile propoziÈ›iei care corespund aceleiaÈ™i entitÄƒÈ›i: aici, modelul a grupat corect â€Huggingâ€ È™i â€Faceâ€ ca o singurÄƒ organizaÈ›ie, chiar dacÄƒ numele este format din mai multe cuvinte. De fapt, dupÄƒ cum vom vedea Ã®n capitolul urmÄƒtor, preprocesarea chiar Ã®mparte unele cuvinte Ã®n pÄƒrÈ›i mai mici. De exemplu, `Sylvain` este Ã®mpÄƒrÈ›it Ã®n patru pÄƒrÈ›i: `S`, `##yl`, `##va`, È™i `##in`. Ãn etapa de postprocesare, pipeline-ul a reuÈ™it sÄƒ regrupeze aceste pÄƒrÈ›i.

<Tip>

âœï¸ **ÃncercaÈ›i!** CÄƒutaÈ›i Ã®n Hub-ul de modele un model capabil sÄƒ facÄƒ etichetarea pÄƒrÈ›ii de vorbire (de obicei abreviatÄƒ ca POS) Ã®n limba englezÄƒ. Ce prezice acest model pentru propoziÈ›ia din exemplul de mai sus?

</Tip>

## Question answering[[question-answering]]

Pipeline-ul "question-answering" rÄƒspunde la Ã®ntrebÄƒri folosind informaÈ›ii dintr-un context dat:

```python
from transformers import pipeline

question_answerer = pipeline("question-answering")
question_answerer(
    question="Where do I work?",
    context="My name is Sylvain and I work at Hugging Face in Brooklyn",
)
```

```python out
{'score': 0.6385916471481323, 'start': 33, 'end': 45, 'answer': 'Hugging Face'}
```

ReÈ›ineÈ›i cÄƒ acest pipeline funcÈ›ioneazÄƒ prin extragerea informaÈ›iilor din contextul furnizat; el nu genereazÄƒ rÄƒspunsul.

## Summarization[[summarization]]

Rezumarea este sarcina de a reduce un text Ã®ntr-un altul mai scurt, pÄƒstrÃ¢nd toate (sau majoritatea) aspectelor importante menÈ›ionate Ã®n el. IatÄƒ un exemplu:

```python
from transformers import pipeline

summarizer = pipeline("summarization")
summarizer(
      """
    America has changed dramatically during recent years. Not only has the number of 
    graduates in traditional engineering disciplines such as mechanical, civil, 
    electrical, chemical, and aeronautical engineering declined, but in most of 
    the premier American universities engineering curricula now concentrate on 
    and encourage largely the study of engineering science. As a result, there 
    are declining offerings in engineering subjects dealing with infrastructure, 
    the environment, and related issues, and greater concentration on high 
    technology subjects, largely supporting increasingly complex scientific 
    developments. While the latter is important, it should not be at the expense 
    of more traditional engineering.

    Rapidly developing economies such as China and India, as well as other 
    industrial countries in Europe and Asia, continue to encourage and advance 
    the teaching of engineering. Both China and India, respectively, graduate 
    six and eight times as many traditional engineers as does the United States. 
    Other industrial countries at minimum maintain their output, while America 
    suffers an increasingly serious decline in the number of engineering graduates 
    and a lack of well-educated engineers.
"""
)
```

```python out
[{'summary_text': ' America has changed dramatically during recent years . The '
                  'number of engineering graduates in the U.S. has declined in '
                  'traditional engineering disciplines such as mechanical, civil '
                  ', electrical, chemical, and aeronautical engineering . Rapidly '
                  'developing economies such as China and India, as well as other '
                  'industrial countries in Europe and Asia, continue to encourage '
                  'and advance engineering .'}]
```

La fel ca Ã®n cazul generÄƒrii de text, puteÈ›i specifica o lungime `max_length` sau `min_length` pentru rezultat.

## Translation[[translation]]

Pentru traducere, puteÈ›i utiliza un model predefinit dacÄƒ introduceÈ›i o combinaÈ›ie de limbi Ã®n numele sarcinii (cum ar fi `â€translation_en_to_frâ€`), dar cel mai simplu este sÄƒ alegeÈ›i modelul pe care doriÈ›i sÄƒ Ã®l utilizaÈ›i Ã®n [Model Hub](https://huggingface.co/models). Aici vom Ã®ncerca sÄƒ traducem din francezÄƒ Ã®n englezÄƒ:

```python
from transformers import pipeline

translator = pipeline("translation", model="Helsinki-NLP/opus-mt-fr-en")
translator("Ce cours est produit par Hugging Face.")
```

```python out
[{'translation_text': 'This course is produced by Hugging Face.'}]
```

Ca È™i Ã®n cazul generÄƒrii È™i rezumÄƒrii textului, puteÈ›i specifica `max_length` sau `min_length` pentru rezultat.
<Tip>

âœï¸ **IncercaÈ›i!** CÄƒutaÈ›i modele de traducere Ã®n alte limbi È™i Ã®ncercaÈ›i sÄƒ traduceÈ›i propoziÈ›ia anterioarÄƒ Ã®n cÃ¢teva limbi diferite.

</Tip>

Pipeline-urile prezentate pÃ¢nÄƒ Ã®n acest moment au Ã®n principal scop demonstrativ. Ele au fost programate pentru sarcini specifice È™i nu pot efectua variaÈ›ii ale acestora. Ãn capitolul urmÄƒtor, veÈ›i afla ce se aflÄƒ Ã®n interiorul unei funcÈ›ii `pipeline()` È™i cum sÄƒ Ã®i personalizaÈ›i comportamentul.