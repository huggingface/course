# Modele Decoder[[modele-decoder]]

<CourseFloatingBanner
    chapter={1}
    classNames="absolute z-10 right-0 top-0"
/>

<Youtube id="d_ixlCubqQw" />

Modelele Decoder utilizează doar decoder-ul unui model Transformer. În fiecare etapă, pentru un cuvânt dat, layerele de atenție pot accesa doar cuvintele poziționate înaintea acestuia în propoziție. Aceste modele sunt adesea numite *modele autoregresive*.

Preantrenarea modelelor de decodare se axează de obicei pe prezicerea următorului cuvânt din propoziție.

Aceste modele sunt cele mai potrivite pentru sarcinile care implică generarea de text.

Printre reprezentanții acestei familii de modele se numără:

- [CTRL](https://huggingface.co/transformers/model_doc/ctrl)
- [GPT](https://huggingface.co/docs/transformers/model_doc/openai-gpt)
- [GPT-2](https://huggingface.co/transformers/model_doc/gpt2)
- [Transformer XL](https://huggingface.co/transformers/model_doc/transfo-xl)