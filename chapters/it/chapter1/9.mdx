# Riassunto

In questo capitolo, hai scoperto come approcciare diversi compiti di NLP utilizzando la funzione di alto livello `pipeline()` degli ü§ó Transformer. Abbiamo anche visto come cercare e utilizzare i modelli dell'Hub, nonch√© come usare l'Inference API per testare i modelli direttamente nel tuo browser.

Abbiamo discusso di come i modelli Transformer lavorino a livello alto, e parlato dell'importanza del transfer learning e dell'affinamento. Un aspetto chiave √® che √® possibile utilizzare l'architettuta completa oppure solo l'encoder o il decoder, dipendentemente dal compito a cui desideri lavorare. La tabella seguente riordina questi concetti:

| Modello         | Esempi                                     | Compiti                                                                          |
|-----------------|--------------------------------------------|----------------------------------------------------------------------------------|
| Encoder         | ALBERT, BERT, DistilBERT, ELECTRA, RoBERTa | Classificazione frasale, riconoscimento delle entit√† nominate, estrazione di risposte a domande |
| Decoder         | CTRL, GPT, GPT-2, Transformer XL           | Generazione di testi                                                             |
| Encoder-decoder | BART, T5, Marian, mBART                    | Riassunti, traduzione, generazione di risposte a domande                         |
