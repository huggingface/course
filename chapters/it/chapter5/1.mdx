# Introduzione

<CourseFloatingBanner
    chapter={5}
    classNames="absolute z-10 right-0 top-0"
/>

Nel [Capitolo 3](/course/chapter3) hai mosso i primi passi nella libreria ü§ó Datasets, e hai scoperto i tre passaggi fondamentali nell'ottimizzazione dei modelli:

1. Si carica un dataset dell'Hub Hugging Face.
2. Si processano i dati con `Dataset.map()`.
3. Si caricano e si elaborano le metriche.

Ma questo non √® che un assaggio di ci√≤ che ü§ó Datasets √® in grado di fare! In questo capitolo approfondiremo le potenzialit√† della libreria. Durante questo percorso, troverai risposta alle seguenti domande:

* Cosa fare quando un dataset non √® presente nell'Hub?
* Come fare a tagliuzzare il dataset? (E cosa succede se devi _proprio_ usare Pandas?)
* Cosa fare quando un dataset √® tanto grande da sciogliere la RAM del tuo portatile?
* Cosa cavolo sono il "mappamento di memoria" e Apache Arrow?
* Come fare per creare il proprio dataset e pubblicarlo sull'Hub?

Le tecniche che imparerai ti prepareranno a compiti pi√π avanzati di tokenizzazione e fine-tuning che troverai nei capitoli [Chapter 6](/course/chapter6) e [Chapter 7](/course/chapter7) -- quindi preparati una tazza di caff√® e iniziamo!
