# Integrazione con l'Hugging Face Hub[[integrations-with-the-hugging-face-hub]]

<CourseFloatingBanner chapter={9}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter9/section5.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter9/section5.ipynb"},
]} />

Per semplificare ulteriormente la vita, Gradio si integra direttamente con Hugging Face Hub e Hugging Face Spaces.
È possibile caricare demo da Hub e Spaces con una *sola linea di codice*.

### Caricare i modelli dall'Hugging Face Hub[[loading-models-from-the-hugging-face-hub]]
Per iniziare, scegli uno delle migliaia di modelli che Hugging Face offre attraverso l'Hub, come descritto nel [Capitolo 4](/course/chapter4/2).

Utilizzando il metodo apposito `Interface.load()`, passa `"model/"` (o, analogamente, `"huggingface/"`) 
seguito dal nome del modello.
Ad esempio, ecco il codice per costruire una demo per [GPT-J](https://huggingface.co/EleutherAI/gpt-j-6B), un _large language model_(modell linguistico di grandi dimensioni),  aggiungendo un paio di esempi di input:

```py
import gradio as gr

title = "GPT-J-6B"
description = "Gradio Demo for GPT-J 6B, a transformer model trained using Ben Wang's Mesh Transformer JAX. 'GPT-J' refers to the class of model, while '6B' represents the number of trainable parameters. To use it, simply add your text, or click one of the examples to load them. Read more at the links below."
article = "<p style='text-align: center'><a href='https://github.com/kingoflolz/mesh-transformer-jax' target='_blank'>GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model</a></p>"
examples = [
    ["The tower is 324 metres (1,063 ft) tall,"],
    ["The Moon's orbit around Earth has"],
    ["The smooth Borealis basin in the Northern Hemisphere covers 40%"],
]
gr.Interface.load(
    "huggingface/EleutherAI/gpt-j-6B",
    inputs=gr.Textbox(lines=5, label="Input Text"),
    title=title,
    description=description,
    article=article,
    examples=examples,
    enable_queue=True,
).launch()
```
    
Il codice sopra riportato produrrà l'interfaccia qui sotto

<iframe src="https://course-demos-gpt-j-6B.hf.space" frameBorder="0" height="750" title="Gradio app" class="container p-0 flex-grow space-iframe" allow="accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking" sandbox="allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"></iframe>

Caricando un modello in questo modo si utilizza l'[Inference API](https://huggingface.co/inference-api) di Hugging Face,
invece di caricare il modello in memoria. Questo è un metodo ideale per modelli enormi come GPT-J o T0pp, che 
richiedono molta RAM.

### Caricare da Hugging Face Spaces[[loading-from-hugging-face-spaces]]
Per caricare qualsiasi Space dall'Hub di Hugging Face e ricrearlo localmente, si può passare `spaces/` all'`Interface`, seguito dal nome dello Space.

Ricordate la demo della sezione 1 che rimuove lo sfondo di un'immagine? Carichiamola da Hugging Face Spaces:

```py
gr.Interface.load("spaces/abidlabs/remove-bg").launch()
```

<iframe src="https://course-demos-remove-bg-original.hf.space" frameBorder="0" height="650" title="Gradio app" class="container p-0 flex-grow space-iframe" allow="accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking" sandbox="allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"></iframe>

Uno degli aspetti interessanti del caricare le demo dall'Hub o da Spaces è che si possono personalizzare 
modificando uno qualsiasi dei 
parametri. Qui aggiungiamo un titolo e facciamo in modo che funzioni con una webcam:

```py
gr.Interface.load(
    "spaces/abidlabs/remove-bg", inputs="webcam", title="Remove your webcam background!"
).launch()
```

<iframe src="https://course-demos-Remove-bg.hf.space" frameBorder="0" height="550" title="Gradio app" class="container p-0 flex-grow space-iframe" allow="accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking" sandbox="allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"></iframe>

Ora che abbiamo esplorato alcuni modi per integrare Gradio con l'Hugging Face Hub, diamo un'occhiata ad alcune funzionalità avanzate della classe `Interface`. Questo è l'argomento della prossima sezione!