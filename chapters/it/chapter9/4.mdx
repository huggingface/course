# Condividere le demo con altri[[sharing-demos-with-others]]

<CourseFloatingBanner chapter={9}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter9/section4.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter9/section4.ipynb"},
]} />

Ora che hai fatto una demo, probabilmente vorrai condividerla con altre persone. Le demo di Gradio
possono essere condivise in 2 modi: usando un ***link temporaneo*** o ***un hosting permanente su Spaces***.

Tratteremo entrambi gli approcci a breve. Ma prima di condividere la tua demo, potresti volerla perfezionare üíÖ.

### Perfezionare la tua demo di Gradio:[[polishing-your-gradio-demo]]

<div class="flex justify-center">
<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter9/gradio-demo-overview.png" alt="Overview of a gradio interface">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter9/gradio-demo-overview-dark.png" alt="Overview of a gradio interface">
</div>

Per aggiungere ulteriori contenuti alla demo, la classe `Interface` supporta alcuni parametri facoltativi:
    - `title`: si pu√≤ dare un titolo alla demo, che appare _sopra_ i componenti di input e output.
    - `description`: si pu√≤ aggiungere una descrizione (come testo, Markdown o HTML) per l'interfaccia, che appare sopra i componenti di input e output e sotto il titolo.
    - `article`: si pu√≤ anche scrivere un articolo pi√π esteso (in testo, Markdown o HTML) che spieghi l'interfaccia. Se inserito, appare _sotto_ i componenti di input e output.
    - `theme`: non ti piacciono i colori predefiniti? Imposta il tema in modo che utilizzi uno tra `default`, `huggingface`, `grass`, `peach`. Si pu√≤ anche aggiungere il prefisso `dark-`, per esempio `dark-peach` per la Dark Mode (o semplicemente `dark` per la modalit√† scura predefinita).
    - `examples`: per rendere la demo *molto pi√π facile da usare*, √® possibile fornire alcuni input di esempio per la funzione. Questi appaiono sotto i componenti dell'interfaccia utente e possono essere usati per popolare l'interfaccia. Questi dovrebbero essere forniti come una nested list (_lista nidificata_), in cui ogni elemento della lista esterna √® un esempio e ogni lista interna consiste di un input per ogni componente di input.
    - `live`: se si vuole rendere la demo "live", cio√® che il modello venga rieseguito ogni volta che l'input cambia, si pu√≤ impostare `live=True`. Questo ha senso per modelli veloci (ne vedremo un esempio alla fine di questa sezione).
Utilizzando le opzioni precedenti, si ottiene un'interfaccia pi√π completa. Esegui il codice sottostante per poter chattare con Rick e Morty:

```py
title = "Ask Rick a Question"
description = """
The bot was trained to answer questions based on Rick and Morty dialogues. Ask Rick anything!
<img src="https://huggingface.co/spaces/course-demos/Rick_and_Morty_QA/resolve/main/rick.png" width=200px>
"""

article = "Check out [the original Rick and Morty Bot](https://huggingface.co/spaces/kingabzpro/Rick_and_Morty_Bot) that this demo is based off of."

gr.Interface(
    fn=predict,
    inputs="textbox",
    outputs="text",
    title=title,
    description=description,
    article=article,
    examples=[["What are you doing?"], ["Where should we time travel to?"]],
).launch()
```

Using the options above, we end up with a more complete interface. Try the interface below:

<iframe src="https://course-demos-Rick-and-Morty-QA.hf.space" frameBorder="0" height="800" title="Gradio app" class="container p-0 flex-grow space-iframe" allow="accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking" sandbox="allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"></iframe>

### Condividere la tua demo con un link temporaneo[[sharing-your-demo-with-temporary-links]]
Ora che abbiamo una demo funzionante del nostro modello di machine learning, vediamo come condividere facilmente un link alla nostra interfaccia.
Le interfacce possono essere facilmente condivise pubblicamente impostando `share=True` nel metodo `launch()`:

```python
gr.Interface(classify_image, "image", "label").launch(share=True)
```

Questo genera un link pubblico e condivisibile che puoi inviare a chiunque! Quando si invia questo link, l'utente dall'altra parte pu√≤ provare il modello nel suo browser per un massimo di 72 ore. Poich√© l'elaborazione avviene sul tuo dispositivo (a patto che il dispositivo rimanga acceso!), non √® necessario preoccuparsi di impacchettare le varie dipendenze. Se si lavora da un notebook di Google Colab, il link di condivisione viene sempre creato automaticamente. Solitamente ha un formato simile a questo: **XXXXX.gradio.app**. Sebbene il link sia servito attraverso un link Gradio, noi siamo solo un proxy per il tuo server locale e non memorizziamo alcun dato inviato attraverso le interfacce.

Si tenga presente, tuttavia, che questi link sono accessibili pubblicamente, il che significa che chiunque pu√≤ utilizzare il tuo modello per fare previsioni! Perci√≤, bisogna assicurarsi di non esporre informazioni sensibili attraverso le funzioni scritte e di non permettere che il tuo dispositivo possa venire criticamente modificato. Se si imposta `share=False` (l'impostazione predefinita), viene creato solo un collegamento locale.

### Hosting della tua demo su Hugging Face Spaces[[hosting-your-demo-on-hugging-face-spaces]]

Un link da condividere con i colleghi e le colleghe √® una buona idea, ma come si pu√≤ hostare in modo permanente la demo e farla esistere in un proprio "spazio" su Internet?

Hugging Face Spaces  fornisce l'infrastruttura per ospitare permanentemente il tuo modello su Gradio su Internet, **gratuitamente**! Spaces ti permette di creare e fare push a un repo (pubblico o privato),
dove il codice della tua interfaccia di Gradio
esister√† in un `app.py` file. [Leggi il tutorial passo dopo passo](https://huggingface.co/blog/gradio-spaces) per cominiciare, oppure guarda il video d'esempio qui sotto.

<Youtube id="LS9Y2wDVI0k" />

## ‚úèÔ∏è Mettiamolo in pratica![[lets-apply-it]]

Utilizzando quanto appreso nelle sezioni precedenti, creiamo la demo di riconoscimento di disegni che abbiamo visto nella [sezione uno di questo capitolo](/course/chapter9/1). Personalizziamo un po' la nostra interfaccia e impostiamo `share=True` per creare un link pubblico che possiamo far circolare.

Possiamo aggiungere le classi da [class_names.txt](https://huggingface.co/spaces/dawood/Sketch-Recognition/blob/main/class_names.txt) e caricare dal file [pytorch_model.bin](https://huggingface.co/spaces/dawood/Sketch-Recognition/blob/main/pytorch_model.bin) il modello di pytorch affinato. Scarica questi file seguendo il link e facendo clic su download nell'angolo in alto a sinistra dell'anteprima del file. Diamo un'occhiata al codice qui sotto per vedere come usare questi file per caricare il nostro modello e creare una funzione `predict()`:
```py
from pathlib import Path
import torch
import gradio as gr
from torch import nn

LABELS = Path("class_names.txt").read_text().splitlines()

model = nn.Sequential(
    nn.Conv2d(1, 32, 3, padding="same"),
    nn.ReLU(),
    nn.MaxPool2d(2),
    nn.Conv2d(32, 64, 3, padding="same"),
    nn.ReLU(),
    nn.MaxPool2d(2),
    nn.Conv2d(64, 128, 3, padding="same"),
    nn.ReLU(),
    nn.MaxPool2d(2),
    nn.Flatten(),
    nn.Linear(1152, 256),
    nn.ReLU(),
    nn.Linear(256, len(LABELS)),
)
state_dict = torch.load("pytorch_model.bin", map_location="cpu")
model.load_state_dict(state_dict, strict=False)
model.eval()


def predict(im):
    x = torch.tensor(im, dtype=torch.float32).unsqueeze(0).unsqueeze(0) / 255.0
    with torch.no_grad():
        out = model(x)
    probabilities = torch.nn.functional.softmax(out[0], dim=0)
    values, indices = torch.topk(probabilities, 5)
    return {LABELS[i]: v.item() for i, v in zip(indices, values)}
```

Now that we have a `predict()` function. The next step is to define and launch our gradio interface:

```py
interface = gr.Interface(
    predict,
    inputs="sketchpad",
    outputs="label",
    theme="huggingface",
    title="Sketch Recognition",
    description="Who wants to play Pictionary? Draw a common object like a shovel or a laptop, and the algorithm will guess in real time!",
    article="<p style='text-align: center'>Sketch Recognition | Demo Model</p>",
    live=True,
)
interface.launch(share=True)
```

<iframe src="https://course-demos-Sketch-Recognition.hf.space" frameBorder="0" height="650" title="Gradio app" class="container p-0 flex-grow space-iframe" allow="accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking" sandbox="allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"></iframe>


Notare il parametro `live=True` in `Interface`, che significa che la demo fa
una previsione ogni volta che qualcuno disegna sullo sketchpad (senza premere il pulsante di invio!).

Inoltre, abbiamo anche impostato l'argomento `share=True` nel metodo `launch()`.
Questo creer√† un link pubblico che si pu√≤
inviare a chiunque! Quando si invia questo link, l'utente dall'altra parte pu√≤ provare il
modello di riconoscimento di disegni. Per ribadire, si pu√≤ anche esporre il modello su Hugging Face Spaces,
che √® il modo in cui siamo riusciti a incorporare la demo qui sopra.

Nella prossima sezione parleremo di altri modi in cui Gradio pu√≤ essere utilizzato con l'ecosistema di Hugging Face!