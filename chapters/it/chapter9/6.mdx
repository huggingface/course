# Funzionalità avanzate dell'Interface[[advanced-interface-features]]

<CourseFloatingBanner chapter={9}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter9/section6.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter9/section6.ipynb"},
]} />

Ora che siamo in grado di costruire e condividere una interfaccia basilare, esploriamo alcune caratteristiche più avanzate, come _state_(stato) e _interpretation_(interpretazione).

### Usare state per persistere i dati[[using-state-to-persist-data]]

Gradio supporta lo *stato di sessione*, in cui i dati persistono tra diversi submit all'interno della 
stessa pagina. Questo è utile per creare demo di, ad esempio, chatbot in cui si desidera 
persistere i dati mentre l'utente interagisce con il modello. Nota che lo stato di sessione non condivide i dati tra  utenti diversi del tuo modello. 

Per memorizzare i dati nello stato di sessione, è necessario fare tre cose:

1. Passare un *parametro in più* alla funzione, che rappresenta lo stato dell'interfaccia.
1. Alla fine della funzione, restituire anche il valore aggiornato dello stato come *valore di ritorno*.
1. Aggiungere lo 'stato' di input e lo 'stato' di output quando si crea la `Interface`.

Vediamo l'esempio di un chatbot qui sotto:

```py
import random

import gradio as gr


def chat(message, history):
    history = history or []
    if message.startswith("How many"):
        response = random.randint(1, 10)
    elif message.startswith("How"):
        response = random.choice(["Great", "Good", "Okay", "Bad"])
    elif message.startswith("Where"):
        response = random.choice(["Here", "There", "Somewhere"])
    else:
        response = "I don't know"
    history.append((message, response))
    return history, history


iface = gr.Interface(
    chat,
    ["text", "state"],
    ["chatbot", "state"],
    allow_screenshot=False,
    allow_flagging="never",
)
iface.launch()
```

<iframe src="https://course-demos-Chatbot-Demo.hf.space" frameBorder="0" height="350" title="Gradio app" class="container p-0 flex-grow space-iframe" allow="accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking" sandbox="allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"></iframe>

Si osservi come lo stato del componente di output persista tra i submit.
Nota: si può passare un valore di default al parametro di stato,
che viene utilizzato come valore iniziale dello stato.

### Usare interpretation per comprendere le previsioni[[using-interpretation-to-understand-predictions]]

La maggior parte dei modelli di machine learning sono _black boxes_(scatole nere) e la logica interna della funzione è nascosta all'utente finale. Per incoraggiare la trasparenza, abbiamo reso molto facile aggiungere l'interpretazione al tuo modello semplicemente impostando la parola chiave `interpretation` nella classe `Interface` su `default`. Questo consente ai tuoi utenti di capire quali parti dell'input sono responsabili dell'output. Dai un'occhiata alla semplice interfaccia qui sotto che mostra un classificatore di immagini che include anche l'interpretazione:

```py
import requests
import tensorflow as tf

import gradio as gr

inception_net = tf.keras.applications.MobileNetV2()  # load the model

# Download human-readable labels for ImageNet.
response = requests.get("https://git.io/JJkYN")
labels = response.text.split("\n")


def classify_image(inp):
    inp = inp.reshape((-1, 224, 224, 3))
    inp = tf.keras.applications.mobilenet_v2.preprocess_input(inp)
    prediction = inception_net.predict(inp).flatten()
    return {labels[i]: float(prediction[i]) for i in range(1000)}


image = gr.Image(shape=(224, 224))
label = gr.Label(num_top_classes=3)

title = "Gradio Image Classifiction + Interpretation Example"
gr.Interface(
    fn=classify_image, inputs=image, outputs=label, interpretation="default", title=title
).launch()
```

Fai un test della funzione di interpretazione fornendo un input e facendo clic su _Interpret_ sotto il componente di output.

<iframe src="https://course-demos-gradio-image-interpretation.hf.space" frameBorder="0" height="570" title="Gradio app" class="container p-0 flex-grow space-iframe" allow="accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking" sandbox="allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"></iframe>

Oltre al metodo di interpretazione predefinito fornito da Gradio, è anche possibile specificare `shap` per il parametro `interpretation` e impostare il parametro `num_shap`. In questo modo viene utilizzata l'interpretazione basata su Shapley, di cui puoi leggere di più [qui](https://christophm.github.io/interpretable-ml-book/shap.html).
Infine, è anche possibile passare una funzione di interpretazione personalizzata nel parametro `interpretation`. Si può vedere un esempio nella pagina introduttiva di Gradio [qui](https://gradio.app/getting_started/).

Questo conclude l'approfondimento sulla classe `Interface` di Gradio. Come abbiamo visto, questa classe semplifica la creazione di demo di machine learning in poche righe di codice Python. Tuttavia, a volte si vuole personalizzare la demo modificando il layout o concatenando più funzioni di predizione. Non sarebbe bello se potessimo dividere la `Interface` in "blocchi" customizzabili? Fortunatamente, c'è un modo! Questo è l'argomento della sezione finale.