# Les modèles basés sur le décodeur

<Youtube id="d_ixlCubqQw" />

Les modèles basés sur le décodeur utilisent seulement le décodeur d'un *transformer*. À chaque étape, pour un mot donné, les couches d'attention ne peuvent strictement accéder qu'aux mots situés avant dans la phrase. Ces modèles sont souvent appelés *modèles autorégressifs*.

Le pré-entraînement des modèles basés sur le décodeur se concentre généralement sur la prédiction du prochain mot dans la phrase.

Ces modèles sont vraiment adaptés aux tâches qui impliquent la génération de texte.

Les modèles qui représentent le mieux la famille des modèles décodeurs sont :

- [CTRL](https://huggingface.co/transformers/model_doc/ctrl.html)
- [GPT](https://huggingface.co/transformers/model_doc/gpt.html)
- [GPT-2](https://huggingface.co/transformers/model_doc/gpt2.html)
- [Transformer XL](https://huggingface.co/transformers/model_doc/transformerxl.html)
