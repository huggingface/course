<!-- DISABLE-FRONTMATTER-SECTIONS -->

# Quiz de fin de chapitre

Ce chapitre a couvert un grand nombre de notions ! Ne vous inquiÃ©tez pas si vous n'avez pas compris tous les dÃ©tails, les chapitres suivants vous aideront Ã  comprendre comment les choses fonctionnent concrÃ¨tement.

Mais avant d'aller plus loin, prenons un instant pour voir ce que vous avez appris dans ce chapitre !


### 1. Explorez le *Hub* et cherchez le modÃ¨le `roberta-large-mnli`. Quelle tÃ¢che accomplit-il ?


<Question
	choices={[
		{
			text: "RÃ©sumÃ© de texte",
			explain: "Regardez Ã  nouveau sur la <a href=\"https://huggingface.co/roberta-large-mnli\">page roberta-large-mnli</a>."
		},
		{
			text: "Classification de texte",
			explain: "Pour Ãªtre plus prÃ©cis, il classifie si deux phrases sont logiquement liÃ©es entre elles parmis trois possibilitÃ©s (contradiction, neutre, lien). Il s'agit d'une tÃ¢che aussi appelÃ©e <em>inference de langage naturel</em>.",
			correct: true
		},
		{
			text: "GÃ©nÃ©ration de texte",
			explain: "Regardez Ã  nouveau sur la <a href=\"https://huggingface.co/roberta-large-mnli\">page roberta-large-mnli</a>."
		}
	]}
/>

### 2. Que renvoie le code suivant ?

```py
from transformers import pipeline

ner = pipeline("ner", grouped_entities=True)
ner(
    "My name is Sylvain and I work at Hugging Face in Brooklyn."
)  # Je m'appelle Sylvain et je travaille Ã  Hugging Face Ã  Brooklyn.
```

<Question
	choices={[
		{
			text: "Il renvoie les scores de classification pour cette phrase, avec les labels \"positive\" ou \"negative\".",
			explain: "Cela correspondrait au pipeline <code>d'analyse de sentiment</code> (<i>sentiment-analysis</i> dans la documentation d'Hugging-Face)."
		},
		{
			text: "Il renvoie un texte gÃ©nÃ©rÃ© qui complÃ¨te cette phrase.",
			explain: "Cela correspondrait au pipeline de <code>gÃ©nÃ©ration de texte</code> (<i>text-generation</i> dans la documentation d'Hugging-Face)."
		},
		{
			text: "Il renvoie les entitÃ©s nommÃ©es dans cette phrase, telles que les personnes, les organisations ou lieux.",
			explain: "De plus, avec <code>grouped_entities=True</code>, cela regroupe les mots appartenant Ã  la mÃªme entitÃ©, comme par exemple \"Hugging Face\".",
			correct: true
		}
	]}
/>

### 3. Que remplace Â« ... Â» dans ce code ?

```py
from transformers import pipeline

filler = pipeline("fill-mask", model="bert-base-cased")
result = filler("...")
```

<Question
	choices={[
		{
			text: "This &#60;mask> has been waiting for you. # Ce &#60;mask> vous attend.",
			explain: "Regardez la description du modÃ¨le <code>bert-base-cased</code> et essayez de trouver votre erreur."
		},
		{
			text: "This [MASK] has been waiting for you. # Ce [MASK] vous attend.",
			explain: "Le modÃ¨le utilise [MASK] comme mot-masque.",
			correct: true
		},
		{
			text: "This man has been waiting for you. # Cet homme vous attend.",
			explain: "Ce pipeline permet de remplacer les mot manquants donc il a besoin d'un mot-masque."
		}
	]}
/>

### 4. Pourquoi ce code ne fonctionne-t-il pas ?

```py
from transformers import pipeline

classifier = pipeline("zero-shot-classification")
result = classifier(
    "This is a course about the Transformers library"
)  # C'est un cours sur la bibliothÃ¨que Transformers
```

<Question
	choices={[
		{
			text: "Ce pipeline nÃ©cessite que des Ã©tiquettes soient donnÃ©es pour classifier ce texte.",
			explain: "Le code doit inclure <code>candidate_labels=[...]</code>.",
			correct: true
		},
		{
			text: "Ce pipeline nÃ©cessite que des phrases soient donnÃ©es, pas juste une phrase.",
			explain: "Bien que ce pipeline puisse prendre une liste de phrases Ã  traiter (comme tous les autres pipelines)."
		},
		{
			text: "La bibliothÃ¨que ğŸ¤— <i>Transformers</i> est cassÃ©e, comme d'habitude.",
			explain: "Nous n'avons aucun commentaire pour cette rÃ©ponse !",
		},
		{
			text: "Ce pipeline nÃ©cessite des phrases plus longues, celle-ci est trop courte.",
			explain: "Notez que si un texte est trÃ¨s long, il est tronquÃ© par le pipeline."
		}
	]}
/>

### 5. Que signifie Â« apprentissage par transfert Â» ?

<Question
	choices={[
		{
			text: "TransfÃ©rer les connaissances d'un modÃ¨le prÃ©-entraÃ®nÃ© vers un nouveau modÃ¨le en entraÃ®nant ce second modÃ¨le sur le mÃªme jeu de donnÃ©es.",
			explain: "Non, cela donnerait deux versions du mÃªme modÃ¨le."
		},
		{
			text: "TransfÃ©rer les connaissances d'un modÃ¨le prÃ©-entraÃ®nÃ© vers un nouveau modÃ¨le en initialisant ce second modÃ¨le avec les poids du premier.",
			explain: "Quand le second modÃ¨le est entraÃ®nÃ© sur une nouvelle tÃ¢che, il transfÃ¨re les connaissances du premier modÃ¨le.",
			correct: true
		},
		{
			text: "TransfÃ©rer les connaissances d'un modÃ¨le prÃ©-entraÃ®nÃ© vers un nouveau modÃ¨le en construisant le second modÃ¨le avec la mÃªme architecture que le premier.",
			explain: "L'architecture correspond uniquement Ã  la structure du modÃ¨le, pas Ã  ses connaissances. Il n'y a donc pas de connaissances Ã  transfÃ©rer dans ce cas.",
		}
	]}
/>

### 6. Vrai ou faux ? Un modÃ¨le de langage n'a gÃ©nÃ©ralement pas besoin d'Ã©tiquettes pour son prÃ©-entraÃ®nement.


<Question
	choices={[
		{
			text: "Vrai",
			explain: "Le prÃ©-entraÃ®nement est <em>autosupervisÃ©</em>, ce qui signifie que les Ã©tiquettes sont crÃ©Ã©es automatiquement Ã  partir des donnÃ©es d'entrÃ©e (comme prÃ©dire le mot suivant ou remplacer des mots masquÃ©s).",
			correct: true
		},
		{
			text: "Faux",
			explain: "Ce n'est pas la bonne rÃ©ponse."
		}
	]}
/>

### 7. SÃ©lectionnez la phrase qui dÃ©crit le mieux les termes Â« modÃ¨le Â», Â« architecture Â» et Â« poids Â».

<Question
	choices={[
		{
			text: "Si un modÃ¨le est un bÃ¢timent, son architecture est le plan de construction et les poids reprÃ©sentent les personnes qui vivent dedans.",
			explain: "Si on suit cette mÃ©taphore, les poids seraient plutÃ´t les briques et les matÃ©riaux utilisÃ©s pour construire le bÃ¢timent."
		},
		{
			text: "Une architecture est une carte pour construire un modÃ¨le et les poids sont les villes reprÃ©sentÃ©es sur la carte.",
			explain: "Le problÃ¨me avec cette mÃ©taphore est que la carte reprÃ©sente une rÃ©alitÃ© existante (il n'y a qu'une seule ville nommÃ©e Paris en France). Pour une architecture donnÃ©e, plusieurs poids sont possibles."
		},
		{
			text: "Une architecture est une succession de fonctions mathÃ©matiques permettant de construire un modÃ¨le et les poids sont les paramÃ¨tres de ces fonctions.",
			explain: "Le mÃªme ensemble de fonctions mathÃ©matiques peut Ãªtre utilisÃ© pour construire plusieurs modÃ¨les avec diffÃ©rents paramÃ¨tres (poids).",
			correct: true
		}
	]}
/>


### 8. Parmi ces types de modÃ¨les, quel est le plus appropriÃ© pour gÃ©nÃ©rer du texte Ã  partir d'une instruction (*prompt*) ?

<Question
	choices={[
		{
			text: "Un modÃ¨le basÃ© sur l'encodeur",
			explain: "Un modÃ¨le basÃ© sur l'encodeur gÃ©nÃ¨re une reprÃ©sentation de la phrase entiÃ¨re qui est plus adaptÃ©e Ã  des tÃ¢ches de classification."
		},
		{
			text: "Un modÃ¨le basÃ© sur le dÃ©codeur",
			explain: "Les modÃ¨les basÃ©s sur le dÃ©codeur sont bien pour gÃ©nÃ©rer du texte Ã  partir d'une instruction.",
			correct: true
		},
		{
			text: "Un modÃ¨le de sÃ©quence-Ã -sÃ©quence",
			explain: "Les modÃ¨les de sÃ©quence-Ã -sÃ©quence sont davantage adaptÃ©s aux tÃ¢ches qui nÃ©cessitent de gÃ©nÃ©rer des phrases Ã  partir d'un texte donnÃ© en entrÃ©e, pas un texte gÃ©nÃ©rÃ© Ã  partir d'une instruction."
		}
	]}
/>

### 9. Parmi ces types de modÃ¨les, quel est le plus appropriÃ© pour le rÃ©sumÃ© de texte ?

<Question
	choices={[
		{
			text: "Un modÃ¨le basÃ© sur l'encodeur",
			explain: "Un modÃ¨le basÃ© sur l'encodeur gÃ©nÃ¨re une reprÃ©sentation de la phrase entiÃ¨re qui est plus adaptÃ©e Ã  des tÃ¢ches de classification.",
		},
		{
			text: "Un modÃ¨le basÃ© sur le dÃ©codeur",
			explain: "Les modÃ¨les basÃ©s sur le dÃ©codeur sont bien pour gÃ©nÃ©rer du texte (comme les rÃ©sumÃ©s) mais ils n'ont pas la capacitÃ© d'exploiter un contexte comme un texte entier pour en faire un rÃ©sumÃ©.",
		},
		{
			text: "Un modÃ¨le de sÃ©quence-Ã -sÃ©quence",
			explain: "Les modÃ¨les de sÃ©quence-Ã -sÃ©quence sont parfaitement adaptÃ©s Ã  une tÃ¢che de rÃ©sumÃ©.",
			correct: true
		}
	]}
/>

### 10. Quel type de modÃ¨le utiliseriez-vous pour classifier des entrÃ©es de texte en fonction de certains labels ?

<Question
	choices={[
		{
			text: "Un modÃ¨le basÃ© sur l'encodeur",
			explain: "Un modÃ¨le basÃ© sur un encodeur gÃ©nÃ¨re une reprÃ©sentation de la phrase entiÃ¨re et est donc parfaitement adaptÃ© Ã  des tÃ¢ches de classification.",
			correct: true
		},
		{
			text: "Un modÃ¨le basÃ© sur le dÃ©codeur",
			explain: "Les modÃ¨les basÃ©s sur le dÃ©codeur sont bons pour gÃ©nÃ©rer des textes et non pour extraire une Ã©tiquette d'une phrase.",
		},
		{
			text: "Un modÃ¨le de sÃ©quence-Ã -sÃ©quence",
			explain: "Les modÃ¨les de sÃ©quence-Ã -sÃ©quence sont davantage adaptÃ©s pour des tÃ¢ches qui nÃ©cessitent de gÃ©nÃ©rer des phrases Ã  partir d'un texte donnÃ© en entrÃ©e, non pour extraire une Ã©tiquette Ã  partir d'une phrase.",
		}
	]}
/>

### 11. De quelle source possible peut Ãªtre le biais observÃ© dans un modÃ¨le ?

<Question
	choices={[
		{
			text: "Le modÃ¨le est une version <i>finetunÃ©e</i> d'un modÃ¨le prÃ©-entraÃ®nÃ© et il a conservÃ© ses biais.",
			explain: "Avec l'apprentissage par transfert, les biais du modÃ¨le prÃ©-entraÃ®nÃ© perdurent dans le modÃ¨le <i>finetunÃ©</i>.",
			correct: true
		},
		{
			text: "Le modÃ¨le a Ã©tÃ© entraÃ®nÃ© sur des donnÃ©es qui sont biaisÃ©es.",
			explain: "Ceci reprÃ©sente la source de biais la plus Ã©vidente mais n'est pas la seule possible.",
			correct: true
		},
		{
			text: "La mÃ©trique optimisÃ©e lors de l'entraÃ®nement du modÃ¨le est biaisÃ©e.",
			explain: "Une source moins Ã©vidente est la faÃ§on dont le modÃ¨le est entraÃ®nÃ©. Votre modÃ¨le va de faÃ§on aveugle optimiser la mÃ©trique que vous avez sÃ©lectionnÃ©e, sans prendre aucun recul.",
			correct: true
		}
	]}
/>
