# Introduction

## Bienvenue sur le cours ü§ó !

<Youtube id="00GKzGyWFEs" />

Ce cours vous apprendra √† utiliser les librairies de NLP de l'√©cosyst√®me [Hugging Face](https://huggingface.co/) ‚Äî [ü§ó Transformers](https://github.com/huggingface/transformers), [ü§ó Datasets](https://github.com/huggingface/datasets), [ü§ó Tokenizers](https://github.com/huggingface/tokenizers), et [ü§ó Accelerate](https://github.com/huggingface/accelerate) ‚Äî ainsi que le [Hub de Hugging Face](https://huggingface.co/models). C'est totalement gratuit et sans publicit√©.

## √Ä quoi s'attendre ?

Voici un bref aper√ßu du cours:

<div class="flex justify-center">
<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary.svg" alt="Bref aper√ßu du contenu du cours.">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary-dark.svg" alt="Bref aper√ßu des diff√©rents chapitres du cours.">
</div>

- Les chapitres 1 √† 4 pr√©sentent les principaux concepts de la librairie ü§ó Transformers. √Ä la fin de ce chapitre, vous serez familier du fonctionnement des mod√®les Transformers et vous saurez comment utiliser un mod√®le du [Hub de Hugging Face](https://huggingface.co/models), le finetuner sur un jeu de donn√©es, et partager vos r√©sultats sur le Hub!
- Les chapitres 5 √† 8 pr√©sentent les bases de ü§ó Datasets et ü§ó Tokenizers ainsi qu'une d√©couverte des probl√®mes classiques de NLP. √Ä la fin de ce chapitre, vous serez capable de r√©soudre les probl√®mes de NLP les plus communs par vous-m√™me.
- Les chapitres 9 √† 12 proposent d'aller plus loin et d'explorer comment les mod√®les Transformers peuvent √™tre utilis√©s pour r√©soudre des probl√®mes de traitement de la parole et de la vision par ordinateur. En suivant ces chapitres, vous apprendrez √† construire et √† partager vos mod√®les via des d√©monstrateurs, et vous serez capable d'optimiser ces mod√®les pour les environnements de production. Enfin, vous serez pr√™t √† appliquer ü§ó Transformers √† (presque) n'importe quel probl√®me de machine learning!

Ce cours:

* Requiert un bon niveau en Python
* Se comprend mieux si vous avez d√©j√† suivi un cours d'introduction au deep learning, comme [fast.ai's](https://www.fast.ai/) [Practical Deep Learning for Coders](https://course.fast.ai/) ou un des cours d√©velopp√©s par [DeepLearning.AI](https://www.deeplearning.ai/)
* N'attend pas une connaissance appronfondie de [PyTorch](https://pytorch.org/) ou de [TensorFlow](https://www.tensorflow.org/), bien qu'√™tre familiaris√© avec l'un d'entre eux peut aider

Apr√®s avoir termin√© ce cours, nous vous recommandons de suivre la [Sp√©cialisation en NLP](https://www.coursera.org/specializations/natural-language-processing?utm_source=deeplearning-ai&utm_medium=institutions&utm_campaign=20211011-nlp-2-hugging_face-page-nlp-refresh) dispens√©e par DeepLearning.AI, qui couvre une grande gamme de mod√®les traditionnels de NLP comme les Na√Øves Bayes et les LSTMs qui sont importants √† conna√Ætre!

## Qui sommes-nous ?

√Ä propos des auteurs de ce cours:

**Matthew Carrigan** est Machine Learning Engineer chez Hugging Face. Il vit √† Dublin, en Irlande et √† travaill√© auparavant comme ing√©nieur en ML chez Parse.ly et avant cela comme chercheur postdoctoral √† Trinity College Dublin. Il ne croit pas que nous arrivions √† AGI en mettant √† l'√©chelle les architectures existantes, mais il a tout de m√™me beaucoup d'espoir dans l'immortalit√© des robots.

**Lysandre Debut** est Machine Learning Engineer chez Hugging Face et a travaill√© sur la librairie ü§ó Transformers depuis les premi√®res phases de d√©veloppement. Son but est de rendre NLP accessible pour tout le monde en d√©veloppant des outils disposant d'une API tr√®s simple.

**Sylvain Gugger** est Research Engineer chez Hugging Face et un des principaux responsable de la librairie ü§ó Transformers. Pr√©c√©demment, Il a √©t√© chercheur en ML chez fast.ai et a √©crit _[Deep Learning for Coders with fastai and PyTorch](https://learning.oreilly.com/library/view/deep-learning-for/9781492045519/)_ avec Jeremy Howard. Son but ultime est de rendre le deep learning plus accessible, en d√©veloppant et en am√©liorant des techniques permettant aux mod√®les d'apprendre rapidement sur des ressources limit√©es.

**Merve Noyan** est Developer Advocate chez Hugging Face et travaille √† la cr√©ation d'outils et de contenu visant √† d√©mocratiser le machine learning pour tous.

**Lucile Saulnier** est Machine Learning Engineer chez Hugging Face qui travaille au d√©veloppement et √† l'impl√©mentation de nombreux outils open source. Elle est √©galement activement impliqu√©e dans de nombreux projets de recherche dans le domaine de NLP comme l'entra√Ænement collaboratif de mod√®les et le projet BigScience.

**Lewis Tunstall** est Machine Learning Engineer chez Hugging Face d√©vou√© au d√©veloppement d'outils open source avec la volont√© de les rendre accessibles √† une communaut√© plus large. Il est √©galement co-auteur d'un livre qui va bient√¥t para√Ætre, [Natural Language Processing with Transformers](https://www.oreilly.com/library/view/natural-language-processing/9781098103231/).

**Leandro von Werra** est Machine Learning Engineer dans l'√©quipe open-source chez Hugging Face et √©galement co-auteur du livre qui va bient√¥t para√Ætre, [Natural Language Processing with Transformers](https://www.oreilly.com/library/view/natural-language-processing/9781098103231/). Il a plusieurs ann√©es d'exp√©rience dans l'industrie du machine learning, o√π il a pu d√©ployer des projets de NLP en production en travaillant sur toutes les √©tapes clefs du d√©ploiement.

√ätes-vous pr√™t √† commencer ? Dans ce chapitre, vous apprendrez:
* √Ä utiliser la fonction `pipeline()` pour r√©soudre des probl√®mes de NLP comme la g√©n√©ration de texte et la classification
* Quelle est l'architecture d'un mod√®le Transformer
* Comment faire la distinction entre les diff√©rentes architectures d'encodeur, de d√©codeur et d'encodeur-d√©codeur et leurs condition d'utilisation
