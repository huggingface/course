# Il est temps de trancher et de d√©couper

<DocNotebookDropdown
  classNames="absolute z-10 right-0 top-0"
  options={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter5/section3.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter5/section3.ipynb"},
]} />

La plupart du temps, les donn√©es avec lesquelles vous travaillez ne sont pas parfaitement pr√©par√©es pour l‚Äôentra√Ænements de mod√®les. Dans cette section, nous allons explorer les diff√©rentes fonctionnalit√©s fournies par ü§ó *Datasets* pour nettoyer vos jeux de donn√©es.

<Youtube id="tqfSFcPMgOI"/>

## Trancher et d√©couper nos donn√©es

Semblable √† Pandas, ü§ó *Datasets* fournit plusieurs fonctions pour manipuler le contenu des objets `Dataset` et `DatasetDict`. Nous avons d√©j√† rencontr√© la m√©thode `Dataset.map()` dans le [chapitre 3](/course/fr/chapter3) et dans cette section nous allons explorer certaines des autres fonctions √† notre disposition.

Pour cet exemple, nous utiliserons le [*Drug Review Dataset*](https://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+%28Drugs.com%29) qui est h√©berg√© sur [*UC Irvine Machine Learning Repository*](https://archive.ics.uci.edu/ml/index.php) et contenant des avis de patients sur divers m√©dicaments ainsi que la condition trait√©e et une note de 10 √©toiles sur la satisfaction du patient.

Nous devons d'abord t√©l√©charger et extraire les donn√©es, ce qui peut √™tre fait avec les commandes `wget` et `unzip` :

```py
!wget "https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip"
!unzip drugsCom_raw.zip
```

√âtant donn√© que TSV n'est qu'une variante de CSV qui utilise des tabulations au lieu de virgules comme s√©parateurs, nous pouvons charger ces fichiers en utilisant le script de chargement `csv` et en sp√©cifiant l'argument `delimiter` dans la fonction `load_dataset()` comme suit :

```py
from datasets import load_dataset

data_files = {"train": "drugsComTrain_raw.tsv", "test": "drugsComTest_raw.tsv"}
# \t is the tab character in Python
drug_dataset = load_dataset("csv", data_files=data_files, delimiter="\t")
```

Une bonne pratique lors de toute sorte d'analyse de donn√©es consiste √† pr√©lever un petit √©chantillon al√©atoire pour avoir une id√©e rapide du type de donn√©es avec lesquelles vous travaillez. Dans ü§ó *Datasets*, nous pouvons cr√©er un √©chantillon al√©atoire en encha√Ænant les fonctions `Dataset.shuffle()` et `Dataset.select()` :

```py
drug_sample = drug_dataset["train"].shuffle(seed=42).select(range(1000))
# Un coup d'≈ìil sur les premiers exemples
drug_sample[:3]
```

```python out
{'Unnamed: 0': [87571, 178045, 80482],
 'drugName': ['Naproxen', 'Duloxetine', 'Mobic'],
 'condition': ['Gout, Acute', 'ibromyalgia', 'Inflammatory Conditions'], 
 #['Goutte aigu√´', 'ibromyalgie', 'Affections inflammatoires']
 'review': ['"like the previous person mention, I&#039;m a strong believer of aleve, it works faster for my gout than the prescription meds I take. No more going to the doctor for refills.....Aleve works!"', 
 # comme la personne pr√©c√©dente l'a mentionn√©, je suis un fervent partisan de l'aleve, il fonctionne plus rapidement pour ma goutte que les m√©dicaments sur ordonnance que je prends. Je n'ai plus besoin d'aller chez le m√©decin pour des renouvellements.....Aleve fonctionne !"
  '"I have taken Cymbalta for about a year and a half for fibromyalgia pain. It is great\r\nas a pain reducer and an anti-depressant, however, the side effects outweighed \r\nany benefit I got from it. I had trouble with restlessness, being tired constantly,\r\ndizziness, dry mouth, numbness and tingling in my feet, and horrible sweating. I am\r\nbeing weaned off of it now. Went from 60 mg to 30mg and now to 15 mg. I will be\r\noff completely in about a week. The fibro pain is coming back, but I would rather deal with it than the side effects."', 
  # J'ai pris du Cymbalta pendant environ un an et demi pour des douleurs de la fibromyalgie. C'est un excellent analg√©sique et un antid√©presseur, mais les effets secondaires l'ont emport√© sur tous les avantages que j'en ai tir√©s. J'ai eu des probl√®mes d'agitation, de fatigue constante, de vertiges, de bouche s√®che, d'engourdissement, de picotements dans les pieds, et de transpiration horrible. Je suis en train de m'en sevrer maintenant. Je suis pass√©e de 60 mg √† 30 mg et maintenant √† 15 mg. Je l'arr√™terai compl√®tement dans environ une semaine. La douleur de la fibrose revient, mais je pr√©f√®re la supporter plut√¥t que les effets secondaires.
  '"I have been taking Mobic for over a year with no side effects other than an elevated blood pressure.  I had severe knee and ankle pain which completely went away after taking Mobic.  I attempted to stop the medication however pain returned after a few days."'], 
  # J'ai pris Mobic pendant plus d'un an sans effets secondaires autres qu'une pression sanguine √©lev√©e.  J'avais de fortes douleurs au genou et √† la cheville qui ont compl√®tement disparu apr√®s avoir pris Mobic. J'ai essay√© d'arr√™ter le m√©dicament mais la douleur est revenue apr√®s quelques jours."
 'rating': [9.0, 3.0, 10.0],
 'date': ['September 2, 2015', 'November 7, 2011', 'June 5, 2013'], 
        #['2 septembre 2015', '7 novembre 2011', '5 juin 2013']
 'usefulCount': [36, 13, 128]}
```

Notez que nous avons corrig√© la graine dans `Dataset.shuffle()` √† des fins de reproductibilit√©. `Dataset.select()` attend un it√©rable d'indices, nous avons donc pass√© `range(1000)` pour r√©cup√©rer les 1 000 premiers exemples du jeu de donn√©es m√©lang√©. √Ä partir de cet √©chantillon, nous pouvons d√©j√† voir quelques bizarreries dans notre jeu de donn√©es :

* la colonne `Unnamed: 0` ressemble √©trangement √† un identifiant anonyme pour chaque patient,
* la colonne `condition` comprend un m√©lange d'√©tiquettes en majuscules et en minuscules,
* les avis sont de longueur variable et contiennent un m√©lange de s√©parateurs de lignes Python (`\r\n`) ainsi que des codes de caract√®res HTML comme `&\#039;`.

Voyons comment nous pouvons utiliser ü§ó *Datasets* pour traiter chacun de ces probl√®mes. Pour tester l'hypoth√®se de l'ID patient pour la colonne `Unnamed : 0`, nous pouvons utiliser la fonction `Dataset.unique()` pour v√©rifier que le nombre d'ID correspond au nombre de lignes dans chaque division :

```py
for split in drug_dataset.keys():
    assert len(drug_dataset[split]) == len(drug_dataset[split].unique("Unnamed: 0"))
```

Cela semble confirmer notre hypoth√®se, alors nettoyons un peu en renommant la colonne `Unnamed: 0` en quelque chose d'un peu plus interpr√©table. Nous pouvons utiliser la fonction `DatasetDict.rename_column()` pour renommer la colonne sur les deux divisions en une seule fois :

```py
drug_dataset = drug_dataset.rename_column(
    original_column_name="Unnamed: 0", new_column_name="patient_id"
)
drug_dataset
```

```python out
DatasetDict({
    train: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],
        num_rows: 161297
    })
    test: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],
        num_rows: 53766
    })
})
```

<Tip>

‚úèÔ∏è **Essayez !** Utilisez la fonction ` Dataset.unique()` pour trouver le nombre de m√©dicaments et de conditions uniques dans les √©chantillons d'entra√Ænement et de test.

</Tip>

Ensuite, normalisons toutes les √©tiquettes `condition` en utilisant `Dataset.map()`. Comme nous l'avons fait avec la tokenisation dans le [chapitre 3](/course/fr/chapter3), nous pouvons d√©finir une fonction simple qui peut √™tre appliqu√©e sur toutes les lignes de chaque division dans `drug_dataset` :

```py
def lowercase_condition(example):
    return {"condition": example["condition"].lower()}


drug_dataset.map(lowercase_condition)
```

```python out
AttributeError: 'NoneType' object has no attribute 'lower'
```

Oh non, nous rencontrons un probl√®me avec notre fonction ! √Ä partir de l'erreur, nous pouvons d√©duire que certaines des entr√©es de la colonne `condition` sont `None` ne pouvant donc pas √™tre mises en minuscules car ce ne sont pas des cha√Ænes. Supprimons ces lignes en utilisant `Dataset.filter()`, qui fonctionne de mani√®re similaire √† `Dataset.map()` et attend une fonction qui re√ßoit un seul exemple issu du jeu de donn√©es. Au lieu d'√©crire une fonction explicite comme :

```py
def filter_nones(x):
    return x["condition"] is not None
```

puis ex√©cuter `drug_dataset.filter(filter_nones)`, nous pouvons le faire en une seule ligne en utilisant une _fonction lambda_. En Python, les fonctions lambda sont de petites fonctions que vous pouvez d√©finir sans les nommer explicitement. Ils prennent la forme g√©n√©rale :

```
lambda <arguments> : <expression>
```

o√π `lambda` est l'un des [mots cl√©s](https://docs.python.org/3/reference/lexical_analysis.html#keywords) sp√©ciaux de Python, `<arguments>` est une liste/ensemble de valeurs s√©par√©es par des virgules qui d√©finissent les entr√©es de la fonction et `<expression>` repr√©sente les op√©rations que vous souhaitez ex√©cuter. Par exemple, nous pouvons d√©finir une simple fonction lambda qui met au carr√© un nombre comme suit :

```
lambda x : x * x
```

Pour appliquer cette fonction √† une entr√©e, nous devons l'envelopper ainsi que l'entr√©e entre parenth√®ses :

```py
(lambda x: x * x)(3)
```

```python out
9
```

De m√™me, nous pouvons d√©finir des fonctions lambda avec plusieurs arguments en les s√©parant par des virgules. Par exemple, nous pouvons calculer l'aire d'un triangle comme suit :

```py
(lambda base, height: 0.5 * base * height)(4, 8)
```

```python out
16.0
```

Les fonctions lambda sont pratiques lorsque vous souhaitez d√©finir de petites fonctions √† usage unique (pour plus d'informations √† leur sujet, nous vous recommandons de lire l'excellent [tutoriel Real Python](https://realpython.com/python-lambda/) d'Andr√© Burgaud) . Dans le contexte de la biblioth√®que ü§ó *Datasets*, nous pouvons utiliser des fonctions lambda pour d√©finir des op√©rations simples de ¬´ mappage ¬ª et de filtrage. Utilisons cette astuce pour √©liminer les entr√©es `None` dans notre jeu de donn√©es :

```py
drug_dataset = drug_dataset.filter(lambda x: x["condition"] is not None)
```

Avec les entr√©es `None` supprim√©es, nous pouvons normaliser notre colonne `condition` :

```py
drug_dataset = drug_dataset.map(lowercase_condition)
# V√©rification que la mise en minuscule a fonctionn√©
drug_dataset["train"]["condition"][:3]
```

```python out
['left ventricular dysfunction', 'adhd', 'birth control']
```

√áa marche ! Maintenant que nous avons nettoy√© les √©tiquettes, examinons le nettoyage des avis eux-m√™mes.

## Cr√©ation de nouvelles colonnes

Chaque fois que vous avez affaire √† des avis de clients, une bonne pratique consiste √† v√©rifier le nombre de mots dans chaque avis. Une critique peut √™tre un simple mot comme ¬´ G√©nial ! ¬ª ou un essai complet avec des milliers de mots. Selon le cas d'usage, vous devrez g√©rer ces extr√™mes diff√©remment. Pour calculer le nombre de mots dans chaque r√©vision, nous utiliserons une heuristique approximative bas√©e sur la division de chaque texte par des espaces.

D√©finissons une fonction simple qui compte le nombre de mots dans chaque avis :

```py
def compute_review_length(example):
    return {"review_length": len(example["review"].split())}
```

Contrairement √† notre fonction `lowercase_condition()`, `compute_review_length()` renvoie un dictionnaire dont la cl√© ne correspond pas √† l'un des noms de colonne du jeu de donn√©es. Dans ce cas, lorsque `compute_review_length()` est pass√© √† `Dataset.map()`, il est appliqu√© √† toutes les lignes du jeu de donn√©es pour cr√©er une nouvelle colonne `review_length` :

```py
drug_dataset = drug_dataset.map(compute_review_length)
# Inspecter le premier exemple d'entra√Ænement
drug_dataset["train"][0]
```

```python out
{'patient_id': 206461,
 'drugName': 'Valsartan',
 'condition': 'left ventricular dysfunction', # dysfonctionnement du ventricule gauche
 'review': '"It has no side effect, I take it in combination of Bystolic 5 Mg and Fish Oil"', 
           # Il n'a aucun effet secondaire, je le prends en combinaison avec Bystolic 5 mg et de l'huile de poisson.
 'rating': 9.0,
 'date': 'May 20, 2012', # 20 mai 2012
 'usefulCount': 27,
 'review_length': 17}
```

Comme pr√©vu, nous pouvons voir qu'une colonne `review_length` a √©t√© ajout√©e √† notre jeu d'entra√Ænement. Nous pouvons trier cette nouvelle colonne avec `Dataset.sort()` pour voir √† quoi ressemblent les valeurs extr√™mes :

```py
drug_dataset["train"].sort("review_length")[:3]
```

```python out
{'patient_id': [103488, 23627, 20558],
 'drugName': ['Loestrin 21 1 / 20', 'Chlorzoxazone', 'Nucynta'],
 'condition': ['birth control', 'muscle spasm', 'pain'], 
              # contraception, spasme musculaire, douleur.
 'review': ['"Excellent."', '"useless"', '"ok"'], # Excellent, inutile, ok 
 'rating': [10.0, 1.0, 6.0],
 'date': ['November 4, 2008', 'March 24, 2017', 'August 20, 2016'], 
         # 4 novembre 2008, 24 mars 2017, 20 ao√ªt 2016
 'usefulCount': [5, 2, 10],
 'review_length': [1, 1, 1]}
```

Comme nous le soup√ßonnions, certaines critiques ne contiennent qu'un seul mot, ce qui, bien que cela puisse convenir √† l'analyse des sentiments, n‚Äôest pas informatif si nous voulons pr√©dire la condition.

<Tip>

üôã Une autre fa√ßon d'ajouter de nouvelles colonnes √† un jeu de donn√©es consiste √† utiliser la fonction `Dataset.add_column()`. Cela vous permet de donner la colonne sous forme de liste Python ou de tableau NumPy et peut √™tre utile dans les situations o√π `Dataset.map()` n'est pas bien adapt√© √† votre analyse.

</Tip>

Utilisons la fonction `Dataset.filter()` pour supprimer les avis contenant moins de 30 mots. De la m√™me mani√®re que nous l'avons fait avec la colonne `condition`, nous pouvons filtrer les avis tr√®s courts en exigeant que les avis aient une longueur sup√©rieure √† ce seuil :

```py
drug_dataset = drug_dataset.filter(lambda x: x["review_length"] > 30)
print(drug_dataset.num_rows)
```

```python out
{'train': 138514, 'test': 46108}
```

Comme vous pouvez le constater, cela a supprim√© environ 15 % des avis de nos jeux d'entra√Ænement et de test d'origine.

<Tip>

‚úèÔ∏è **Essayez !** Utilisez la fonction `Dataset.sort()` pour inspecter les avis avec le plus grand nombre de mots. Consultez la [documentation](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.sort) pour voir quel argument vous devez utiliser pour trier les avis par longueur dans l'ordre d√©croissant.

</Tip>

La derni√®re chose √† laquelle nous devons faire face est la pr√©sence de caract√®res HTML dans nos avis. Nous pouvons utiliser le module `html` de Python pour supprimer ces caract√®res, comme ceci :

```py
import html

text = "I&#039;m a transformer called BERT"
html.unescape(text)
```

```python out
"I'm a transformer called BERT"
```

Nous utilisons `Dataset.map()` pour d√©masquer tous les caract√®res HTML de notre corpus :

```python
drug_dataset = drug_dataset.map(lambda x: {"review": html.unescape(x["review"])})
```

Comme vous pouvez le voir, la m√©thode `Dataset.map()` est tr√®s utile pour le traitement des donn√©es. Et nous n'avons m√™me pas effleur√© la surface de tout ce qu'elle peut faire !

## Les superpouvoirs de la m√©thode `map()`

La m√©thode `Dataset.map()` prend un argument `batched` qui, s'il est d√©fini sur `True`, l'am√®ne √† envoyer un batch d'exemples √† la fonction *map* en une seule fois (la taille du batch est configurable mais est fix√© par d√©faut √† 1 000). Par exemple, la fonction `map()` pr√©c√©dente qui supprime tout le code HTML prend un peu de temps √† s'ex√©cuter (vous pouvez lire le temps pris dans les barres de progression). On peut acc√©l√©rer cela en traitant plusieurs √©l√©ments en m√™me temps √† l'aide d'une compr√©hension de liste.

Lorsque vous sp√©cifiez `batched=True`, la fonction re√ßoit un dictionnaire avec les champs du jeu de donn√©es mais chaque valeur est maintenant une _liste de valeurs_ et non plus une seule valeur. La valeur retourn√©e par `Dataset.map()` devrait √™tre la m√™me : un dictionnaire avec les champs que nous voulons mettre √† jour ou ajouter √† notre jeu de donn√©es, et une liste de valeurs. Par exemple, voici une autre fa√ßon de supprimer tous les caract√®res HTML, mais en utilisant `batched=True` :

```python
new_drug_dataset = drug_dataset.map(
    lambda x: {"review": [html.unescape(o) for o in x["review"]]}, batched=True
)
```

Si vous ex√©cutez ce code dans un *notebook*, vous verrez que cette commande s'ex√©cute beaucoup plus rapidement que la pr√©c√©dente. Et ce n'est pas parce que nos critiques ont d√©j√† √©t√© scann√©es au format HTML. Si vous r√©-ex√©cutez l'instruction de la section pr√©c√©dente (sans `batched=True`), cela prendra le m√™me temps qu'avant. En effet, les compr√©hensions de liste sont g√©n√©ralement plus rapides que l'ex√©cution du m√™me code dans une boucle `for` et nous gagnons √©galement en performances en acc√©dant √† de nombreux √©l√©ments en m√™me temps au lieu d'un par un.

L'utilisation de `Dataset.map()` avec `batched=True` est essentielle pour les *tokenizers rapides* que nous rencontrerons dans le [chapitre 6](/course/fr/chapter6) et qui peuvent rapidement tokeniser de grandes listes de textes. Par exemple, pour tokeniser toutes les critiques de m√©dicaments avec un *tokenizer* rapide nous pouvons utiliser une fonction comme celle-ci :

```python
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")


def tokenize_function(examples):
    return tokenizer(examples["review"], truncation=True)
```

Comme vous l'avez vu dans le [chapitre 3](/course/fr/chapter3), nous pouvons passer un ou plusieurs exemples au *tokenizer*. Nous pouvons donc utiliser cette fonction avec ou sans `batched=True`. Profitons-en pour comparer les performances des diff√©rentes options. Dans un *notebook*, vous pouvez chronom√©trer une instruction d'une ligne en ajoutant `%time` avant la ligne de code que vous souhaitez mesurer :

```python no-format
%time tokenized_dataset = drug_dataset.map(tokenize_function, batched=True)
```

Vous pouvez √©galement chronom√©trer une cellule enti√®re en mettant `%%time` au d√©but de la cellule. Sur le mat√©riel sur lequel nous avons ex√©cut√© cela, cela affichait 10,8 s pour cette instruction (c'est le nombre √©crit apr√®s "Wall time").

<Tip>

‚úèÔ∏è **Essayez !** Ex√©cutez la m√™me instruction avec et sans `batched=True`, puis essayez-le avec un *tokenizer* lent (ajoutez `use_fast=False` dans la m√©thode `AutoTokenizer.from_pretrained()`) afin que vous puissiez voir quels temps vous obtenez sur votre mat√©riel.

</Tip>

Voici les r√©sultats que nous avons obtenus avec et sans *batching*, avec un *tokenizer* rapide et un lent :

Options         | *Tokenizer* rapide | *Tokenizer* lent
:--------------:|:----------------:|:-----------------:
`batched=True`  | 10.8s            | 4min41s
`batched=False` | 59.2s            | 5min3s

Cela signifie que l'utilisation d'un *tokenizer* rapide avec l'option `batched=True` est 30 fois plus rapide que son homologue lent sans batch. C'est vraiment incroyable ! C'est la raison principale pour laquelle les *tokenizers* rapides sont la valeur par d√©faut lors de l'utilisation de `AutoTokenizer` (et pourquoi ils sont appel√©s ¬´ rapides ¬ª). Ils sont capables d'atteindre une telle vitesse car en coulisses le code de tokenisation est ex√©cut√© en Rust qui est un langage facilitant la parall√©lisation de l'ex√©cution du code.

La parall√©lisation est √©galement la raison du gain de vitesse de pr√®s de 6 fois obtenue par le *tokenizer* rapide avec batch. Vous ne pouvez pas parall√©liser une seule op√©ration de tokenisation, mais lorsque vous souhaitez tokeniser de nombreux textes en m√™me temps, vous pouvez simplement r√©partir l'ex√©cution sur plusieurs processus. Chacun responsable de ses propres textes.

`Dataset.map()` poss√®de aussi ses propres capacit√©s de parall√©lisation. Comme elles ne sont pas soutenus par Rust, un *tokenizer* lent ne peut pas rattraper un rapide mais cela peut toujours √™tre utile (surtout si vous utilisez un *tokenizer* qui n'a pas de version rapide). Pour activer le multitraitement, utilisez l'argument `num_proc` et sp√©cifiez le nombre de processus √† utiliser dans votre appel √† `Dataset.map()` :

```py
slow_tokenizer = AutoTokenizer.from_pretrained("bert-base-cased", use_fast=False)


def slow_tokenize_function(examples):
    return slow_tokenizer(examples["review"], truncation=True)


tokenized_dataset = drug_dataset.map(slow_tokenize_function, batched=True, num_proc=8)
```

Vous pouvez faire des tests pour d√©terminer le nombre optimal de processus √† utiliser. Dans notre cas 8 semble produire le meilleur gain de vitesse. Voici les chiffres que nous avons obtenus avec et sans multitraitement :

Options                       | *Tokenizer* rapide | *Tokenizer* lent
:----------------------------:|:----------------:|:---------------:
`batched=True`                | 10.8s            | 4min41s
`batched=False`               | 59.2s            | 5min3s
`batched=True`, `num_proc=8`  | 6.52s            | 41.3s
`batched=False`, `num_proc=8` | 9.49s            | 45.2s

Ce sont des r√©sultats beaucoup plus raisonnables pour le *tokenizer* lent mais les performances du *tokenizer* rapide ont √©galement √©t√© consid√©rablement am√©lior√©es. Notez, cependant, que ce ne sera pas toujours le cas : pour des valeurs de `num_proc` autres que 8, nos tests ont montr√© qu'il √©tait plus rapide d'utiliser `batched=True` sans cette option. En g√©n√©ral, nous ne recommandons pas d'utiliser le multitraitement pour les *tokenizers* rapides avec `batched=True`.

<Tip>

Utiliser `num_proc` pour acc√©l√©rer votre traitement est g√©n√©ralement une bonne id√©e tant que la fonction que vous utilisez n'effectue pas d√©j√† une sorte de multitraitement.

</Tip>

Toutes ces fonctionnalit√©s condens√©es en une seule m√©thode sont d√©j√† assez √©tonnantes, mais il y a plus ! Avec `Dataset.map()` et `batched=True` vous pouvez modifier le nombre d'√©l√©ments dans votre jeu de donn√©es. Ceci est tr√®s utile dans de nombreuses situations o√π vous souhaitez cr√©er plusieurs fonctionnalit√©s d'entra√Ænement √† partir d'un exemple. Nous devrons le faire dans le cadre du pr√©traitement de plusieurs des t√¢ches de traitement du langage naturel que nous entreprendrons dans le [chapitre 7](/course/fr/chapter7).

<Tip>

üí° En apprentissage automatique, un _exemple_ est g√©n√©ralement d√©fini comme l'ensemble de _features_ que nous donnons au mod√®le. Dans certains contextes, ces caract√©ristiques seront l'ensemble des colonnes d'un `Dataset`, mais dans d'autres (comme ici et pour la r√©ponse aux questions), plusieurs caract√©ristiques peuvent √™tre extraites d'un seul exemple et appartenir √† une seule colonne.

</Tip>

Voyons comment cela fonctionne ! Ici, nous allons tokeniser nos exemples et les tronquer √† une longueur maximale de 128 mais nous demanderons au *tokenizer* de renvoyer *tous* les morceaux des textes au lieu du premier. Cela peut √™tre fait avec `return_overflowing_tokens=True` :

```py
def tokenize_and_split(examples):
    return tokenizer(
        examples["review"],
        truncation=True,
        max_length=128,
        return_overflowing_tokens=True,
    )
```

Testons cela sur un exemple avant d'utiliser `Dataset.map()` sur le jeu de donn√©es :

```py
result = tokenize_and_split(drug_dataset["train"][0])
[len(inp) for inp in result["input_ids"]]
```

```python out
[128, 49]
```

Notre premier exemple du jeu d‚Äôentra√Ænement est devenu deux caract√©ristiques car il a √©t√© segment√© √† plus que le nombre maximum de *tokens* que nous avons sp√©cifi√© : le premier de longueur 128 et le second de longueur 49. Faisons maintenant cela pour tous les √©l√©ments du jeu de donn√©es !

```py
tokenized_dataset = drug_dataset.map(tokenize_and_split, batched=True)
```

```python out
ArrowInvalid: Column 1 named condition expected length 1463 but got length 1000
```

Oh non ! Cela n'a pas fonctionn√© ! Pourquoi ? L'examen du message d'erreur nous donne un indice : il y a une incompatibilit√© dans les longueurs de l'une des colonnes. L'une √©tant de longueur 1 463 et l'autre de longueur 1 000. Si vous avez consult√© la [documentation](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.map) de `Dataset.map()`, vous vous souvenez peut-√™tre qu'il s'agit du nombre d'√©chantillons pass√©s √† la fonction que nous mappons. Ici, ces 1 000 exemples ont donn√© 1 463 nouvelles caract√©ristiques, entra√Ænant une erreur de forme.

Le probl√®me est que nous essayons de m√©langer deux jeux de donn√©es diff√©rents de tailles diff√©rentes : les colonnes `drug_dataset` auront un certain nombre d'exemples (les 1 000 dans notre erreur), mais le `tokenized_dataset` que nous construisons en aura plus (le 1 463 dans le message d'erreur). Cela ne fonctionne pas pour un `Dataset`, nous devons donc soit supprimer les colonnes de l'ancien jeu de donn√©es, soit leur donner la m√™me taille que dans le nouveau jeu de donn√©es. Nous pouvons faire la premi√®re option avec l'argument `remove_columns` :

```py
tokenized_dataset = drug_dataset.map(
    tokenize_and_split, batched=True, remove_columns=drug_dataset["train"].column_names
)
```

Maintenant, cela fonctionne sans erreur. Nous pouvons v√©rifier que notre nouveau jeu de donn√©es contient beaucoup plus d'√©l√©ments que le jeu de donn√©es d'origine en comparant les longueurs :

```py
len(tokenized_dataset["train"]), len(drug_dataset["train"])
```

```python out
(206772, 138514)
```

Nous avons mentionn√© que nous pouvions √©galement r√©soudre le probl√®me de longueur non concordante en donnant aux anciennes colonnes la m√™me taille que les nouvelles. Pour ce faire, nous avons besoin du champ `overflow_to_sample_mapping` que le *tokenizer* renvoie lorsque nous d√©finissons `return_overflowing_tokens=True`. Il nous donne une correspondance entre un nouvel index de caract√©ristique et l'index de l'√©chantillon dont il est issu. Gr√¢ce √† cela, nous pouvons associer chaque cl√© pr√©sente dans notre jeu de donn√©es d'origine √† une liste de valeurs de la bonne taille en r√©p√©tant les valeurs de chaque exemple autant de fois qu'il g√©n√®re de nouvelles caract√©ristiques :

```py
def tokenize_and_split(examples):
    result = tokenizer(
        examples["review"],
        truncation=True,
        max_length=128,
        return_overflowing_tokens=True,
    )
    # Extract mapping between new and old indices
    sample_map = result.pop("overflow_to_sample_mapping")
    for key, values in examples.items():
        result[key] = [values[i] for i in sample_map]
    return result
```

Nous pouvons voir que cela fonctionne avec `Dataset.map()` sans que nous ayons besoin de supprimer les anciennes colonnes :

```py
tokenized_dataset = drug_dataset.map(tokenize_and_split, batched=True)
tokenized_dataset
```

```python out
DatasetDict({
    train: Dataset({
        features: ['attention_mask', 'condition', 'date', 'drugName', 'input_ids', 'patient_id', 'rating', 'review', 'review_length', 'token_type_ids', 'usefulCount'],
        num_rows: 206772
    })
    test: Dataset({
        features: ['attention_mask', 'condition', 'date', 'drugName', 'input_ids', 'patient_id', 'rating', 'review', 'review_length', 'token_type_ids', 'usefulCount'],
        num_rows: 68876
    })
})
```

Nous obtenons le m√™me nombre de caract√©ristiques d'entra√Ænement qu'auparavant, mais ici nous avons conserv√© tous les anciens champs. Si vous en avez besoin pour un post-traitement apr√®s l'application de votre mod√®le, vous pouvez utiliser cette approche.

Vous avez maintenant vu comment ü§ó *Datasets* peut √™tre utilis√© pour pr√©traiter un jeu de donn√©es de diff√©rentes mani√®res. Bien que les fonctions de traitement de ü§ó *Datasets* couvrent la plupart de vos besoins, il peut arriver que vous deviez passer √† Pandas pour acc√©der √† des fonctionnalit√©s plus puissantes, telles que `DataFrame.groupby()` ou des API de haut niveau pour la visualisation. Heureusement, ü§ó *Datasets* est con√ßu pour √™tre interop√©rable avec des biblioth√®ques telles que Pandas, NumPy, PyTorch, TensorFlow et JAX. Voyons comment cela fonctionne.

## De `Dataset` √† `DataFrame` et vice versa

<Youtube id="tfcY1067A5Q"/>

Pour permettre la conversion entre diverses biblioth√®ques tierces, ü§ó *Datasets* fournit une fonction `Dataset.set_format()`. Cette fonction ne modifie que le _format de sortie_ du jeu de donn√©es. Vous pouvez donc facilement passer √† un autre format sans affecter le _format de donn√©es_ sous-jacent, qui est Apache Arrow. Le formatage se fait sur place. Pour d√©montrer, convertissons notre jeu de donn√©es vers Pandas :

```py
drug_dataset.set_format("pandas")
```

Maintenant, lorsque nous acc√©dons aux √©l√©ments du jeu de donn√©es, nous obtenons un `pandas.DataFrame` au lieu d'un dictionnaire :

```py
drug_dataset["train"][:3]
```

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>patient_id</th>
      <th>drugName</th>
      <th>condition</th>
      <th>review</th>
      <th>rating</th>
      <th>date</th>
      <th>usefulCount</th>
      <th>review_length</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>95260</td>
      <td>Guanfacine</td>
      <td>adhd</td>
      <td>"My son is halfway through his fourth week of Intuniv..."</td>
      <td>8.0</td>
      <td>April 27, 2010</td>
      <td>192</td>
      <td>141</td>
    </tr>
    <tr>
      <th>1</th>
      <td>92703</td>
      <td>Lybrel</td>
      <td>birth control</td>
      <td>"I used to take another oral contraceptive, which had 21 pill cycle, and was very happy- very light periods, max 5 days, no other side effects..."</td>
      <td>5.0</td>
      <td>December 14, 2009</td>
      <td>17</td>
      <td>134</td>
    </tr>
    <tr>
      <th>2</th>
      <td>138000</td>
      <td>Ortho Evra</td>
      <td>birth control</td>
      <td>"This is my first time using any form of birth control..."</td>
      <td>8.0</td>
      <td>November 3, 2015</td>
      <td>10</td>
      <td>89</td>
    </tr>
  </tbody>
</table>

Cr√©ons un `pandas.DataFrame` pour l'ensemble d'entra√Ænement en s√©lectionnant tous les √©l√©ments de `drug_dataset["train"]` :

```py
train_df = drug_dataset["train"][:]
```

<Tip>

üö® Sous le capot, `Dataset.set_format()` change le format de retour pour la m√©thode `__getitem__()`. Cela signifie que lorsque nous voulons cr√©er un nouvel objet comme `train_df` √† partir d'un `Dataset` au format `"pandas"`, nous devons d√©couper tout le jeu de donn√©es pour obtenir un `pandas.DataFrame`. Vous pouvez v√©rifier par vous-m√™me que le type de `drug_dataset["train"]` est `Dataset`, quel que soit le format de sortie.

</Tip>


De l√†, nous pouvons utiliser toutes les fonctionnalit√©s Pandas que nous voulons. Par exemple, nous pouvons faire un cha√Ænage sophistiqu√© pour calculer la distribution de classe parmi les entr√©es `condition` :

```py
frequencies = (
    train_df["condition"]
    .value_counts()
    .to_frame()
    .reset_index()
    .rename(columns={"index": "condition", "condition": "frequency"})
)
frequencies.head()
```

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>condition</th>
      <th>frequency</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>birth control</td>
      <td>27655</td>
    </tr>
    <tr>
      <th>1</th>
      <td>depression</td>
      <td>8023</td>
    </tr>
    <tr>
      <th>2</th>
      <td>acne</td>
      <td>5209</td>
    </tr>
    <tr>
      <th>3</th>
      <td>anxiety</td>
      <td>4991</td>
    </tr>
    <tr>
      <th>4</th>
      <td>pain</td>
      <td>4744</td>
    </tr>
  </tbody>
</table>


Et une fois que nous avons termin√© notre analyse Pandas, nous pouvons toujours cr√©er un nouvel objet `Dataset` en utilisant la fonction `Dataset.from_pandas()` comme suit :


```py
from datasets import Dataset

freq_dataset = Dataset.from_pandas(frequencies)
freq_dataset
```

```python out
Dataset({
    features: ['condition', 'frequency'],
    num_rows: 819
})
```

<Tip>

‚úèÔ∏è **Essayez !** Calculez la note moyenne par m√©dicament et stockez le r√©sultat dans un nouveau jeu de donn√©es.

</Tip>

Ceci conclut notre visite des diff√©rentes techniques de pr√©traitement disponibles dans ü§ó *Datasets*. Pour compl√©ter la section, cr√©ons un ensemble de validation pour pr√©parer le jeu de donn√©es √† l‚Äôentra√Ænement d'un classifieur. Avant cela, nous allons r√©initialiser le format de sortie de `drug_dataset` de `"pandas"` √† `"arrow"` :

```python
drug_dataset.reset_format()
```

## Cr√©ation d'un ensemble de validation

Bien que nous ayons un jeu de test que nous pourrions utiliser pour l'√©valuation, il est recommand√© de ne pas toucher au jeu de test et de cr√©er un jeu de validation s√©par√© pendant le d√©veloppement. Une fois que vous √™tes satisfait des performances de vos mod√®les sur l'ensemble de validation, vous pouvez effectuer une derni√®re v√©rification d'int√©grit√© sur l'ensemble test. Ce processus permet d'att√©nuer le risque de surentra√Ænement sur le jeu de test et de d√©ployer un mod√®le qui √©choue sur des donn√©es du monde r√©el.

ü§ó *Datasets* fournit une fonction `Dataset.train_test_split()` bas√©e sur la c√©l√®bre fonctionnalit√© de `scikit-learn`. Utilisons-la pour diviser notre ensemble d'entra√Ænement `train` et `validation` (nous d√©finissons l'argument `seed` pour la reproductibilit√©) :

```py
drug_dataset_clean = drug_dataset["train"].train_test_split(train_size=0.8, seed=42)
# Rename the default "test" split to "validation"
drug_dataset_clean["validation"] = drug_dataset_clean.pop("test")
# Add the "test" set to our `DatasetDict`
drug_dataset_clean["test"] = drug_dataset["test"]
drug_dataset_clean
```

```python out
DatasetDict({
    train: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'review_clean'],
        num_rows: 110811
    })
    validation: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'review_clean'],
        num_rows: 27703
    })
    test: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'review_clean'],
        num_rows: 46108
    })
})
```

G√©nial, nous avons maintenant pr√©par√© un jeu de donn√©es pr√™t pour l'entra√Ænement de certains mod√®les ! Dans la [section 5](/course/fr/chapter5/5), nous vous montrerons comment t√©l√©charger des jeux de donn√©es sur le *Hub*. Mais pour l'instant, terminons notre analyse en examinant quelques fa√ßons d'enregistrer des jeux de donn√©es sur votre ordinateur local. 

## Enregistrer un jeu de donn√©es

<Youtube id="blF9uxYcKHo"/>

Bien que ü§ó *Datasets* mette en cache chaque jeu de donn√©es t√©l√©charg√© et les op√©rations qui y sont effectu√©es, il y a des moments o√π vous voudrez enregistrer un jeu de donn√©es sur le disque (par exemple, au cas o√π le cache serait supprim√©). Comme indiqu√© dans le tableau ci-dessous, ü§ó *Datasets* fournit trois fonctions principales pour enregistrer votre jeu de donn√©es dans diff√©rents formats :

| Format de donn√©es |         Fonction         |
| :---------------: | :----------------------: |
|      Arrow        | `Dataset.save_to_disk()` |
|       CSV         |    `Dataset.to_csv()`    |
|      JSON         |   `Dataset.to_json()`    |

Par exemple, enregistrons notre jeu de donn√©es nettoy√© au format Arrow :

```py
drug_dataset_clean.save_to_disk("drug-reviews")
```

Cela cr√©era un r√©pertoire avec la structure suivante :

```
drug-reviews/
‚îú‚îÄ‚îÄ dataset_dict.json
‚îú‚îÄ‚îÄ test
‚îÇ   ‚îú‚îÄ‚îÄ dataset.arrow
‚îÇ   ‚îú‚îÄ‚îÄ dataset_info.json
‚îÇ   ‚îî‚îÄ‚îÄ state.json
‚îú‚îÄ‚îÄ train
‚îÇ   ‚îú‚îÄ‚îÄ dataset.arrow
‚îÇ   ‚îú‚îÄ‚îÄ dataset_info.json
‚îÇ   ‚îú‚îÄ‚îÄ indices.arrow
‚îÇ   ‚îî‚îÄ‚îÄ state.json
‚îî‚îÄ‚îÄ validation
    ‚îú‚îÄ‚îÄ dataset.arrow
    ‚îú‚îÄ‚îÄ dataset_info.json
    ‚îú‚îÄ‚îÄ indices.arrow
    ‚îî‚îÄ‚îÄ state.json
```

o√π nous pouvons voir que chaque division est associ√©e √† sa propre table *dataset.arrow* et √† certaines m√©tadonn√©es dans *dataset_info.json* et *state.json*. Vous pouvez consid√©rer le format Arrow comme un tableau sophistiqu√© de colonnes et de lignes optimis√© pour la cr√©ation d'applications hautes performances qui traitent et transportent de grands ensembles de donn√©es.

Une fois le jeu de donn√©es enregistr√©, nous pouvons le charger en utilisant la fonction `load_from_disk()` comme suit :

```py
from datasets import load_from_disk

drug_dataset_reloaded = load_from_disk("drug-reviews")
drug_dataset_reloaded
```

```python out
DatasetDict({
    train: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],
        num_rows: 110811
    })
    validation: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],
        num_rows: 27703
    })
    test: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],
        num_rows: 46108
    })
})
```

Pour les formats CSV et JSON, nous devons stocker chaque fractionnement dans un fichier s√©par√©. Pour ce faire, vous pouvez parcourir les cl√©s et les valeurs de l'objet `DatasetDict` :

```py
for split, dataset in drug_dataset_clean.items():
    dataset.to_json(f"drug-reviews-{split}.jsonl")
```

Cela enregistre chaque fractionnement au [format JSON Lines](https://jsonlines.org), o√π chaque ligne du jeu de donn√©es est stock√©e sous la forme d'une seule ligne de JSON. Voici √† quoi ressemble le premier exemple :

```py
!head -n 1 drug-reviews-train.jsonl
```

```python out
{"patient_id":141780,"drugName":"Escitalopram","condition":"depression","review":"\"I seemed to experience the regular side effects of LEXAPRO, insomnia, low sex drive, sleepiness during the day. I am taking it at night because my doctor said if it made me tired to take it at night. I assumed it would and started out taking it at night. Strange dreams, some pleasant. I was diagnosed with fibromyalgia. Seems to be helping with the pain. Have had anxiety and depression in my family, and have tried quite a few other medications that haven't worked. Only have been on it for two weeks but feel more positive in my mind, want to accomplish more in my life. Hopefully the side effects will dwindle away, worth it to stick with it from hearing others responses. Great medication.\"","rating":9.0,"date":"May 29, 2011","usefulCount":10,"review_length":125}
                                                                                  # Il semble que je ressente les effets secondaires habituels de LEXAPRO : insomnie, baisse de la libido, somnolence pendant la journ√©e. Je le prends le soir parce que mon m√©decin m'a dit de le prendre le soir s'il me fatiguait. J'ai suppos√© que ce serait le cas et j'ai commenc√© √† le prendre la nuit. R√™ves √©tranges, certains agr√©ables. On m'a diagnostiqu√© une fibromyalgie. Il semble que ce m√©dicament aide √† soulager la douleur. J'ai eu de l'anxi√©t√© et de la d√©pression dans ma famille, et j'ai essay√© plusieurs autres m√©dicaments qui n'ont pas fonctionn√©. Cela ne fait que deux semaines que je prends ce m√©dicament, mais je me sens plus positif dans mon esprit et je veux accomplir davantage dans ma vie. J'esp√®re que les effets secondaires vont s'estomper, cela vaut la peine de s'y tenir d'apr√®s les r√©ponses des autres. C'est un excellent m√©dicament.
```

Nous pouvons ensuite utiliser les techniques de [section 2](/course/fr/chapter5/2) pour charger les fichiers JSON comme suit :

```py
data_files = {
    "train": "drug-reviews-train.jsonl",
    "validation": "drug-reviews-validation.jsonl",
    "test": "drug-reviews-test.jsonl",
}
drug_dataset_reloaded = load_dataset("json", data_files=data_files)
```

Et c'est tout pour notre excursion dans la manipulation des donn√©es avec ü§ó *Datasets* ! Maintenant que nous disposons d'un ensemble de donn√©es nettoy√© pour entra√Æner un mod√®le, voici quelques id√©es que vous pouvez essayer :

1. Utilisez les techniques du [chapitre 3](/course/fr/chapter3) pour entra√Æner un classifieur capable de pr√©dire l'√©tat du patient en fonction de l'examen du m√©dicament.
2. Utilisez le pipeline `summarization` du [chapitre 1](/course/fr/chapter1) pour g√©n√©rer des r√©sum√©s des r√©visions.

Ensuite, nous verrons comment ü§ó *Datasets* peut vous permettre de travailler avec d'√©normes jeux de donn√©es sans faire exploser votre ordinateur portable !
