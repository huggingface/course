# Que faire si mon jeu de donnÃ©es n'est pas sur le <i>Hub</i> ?

<CourseFloatingBanner chapter={5}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "English", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter5/section2.ipynb"},
    {label: "FranÃ§ais", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/fr/chapter5/section2.ipynb"},
    {label: "English", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter5/section2.ipynb"},
    {label: "FranÃ§ais", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/fr/chapter5/section2.ipynb"},
]} />

Vous savez comment utiliser le [*Hub*](https://huggingface.co/datasets) pour tÃ©lÃ©charger des jeux de donnÃ©es mais en pratique vous vous retrouverez souvent Ã  travailler avec des donnÃ©es stockÃ©es sur votre ordinateur portable ou sur un serveur distant. Dans cette section, nous allons vous montrer comment ğŸ¤— *Datasets* peut Ãªtre utilisÃ© pour charger des jeux de donnÃ©es qui ne sont pas disponibles sur le *Hub* dâ€™Hugging Face.

<Youtube id="HyQgpJTkRdE"/>

## Travailler avec des jeux de donnÃ©es locaux et distants

ğŸ¤— *Datasets* fournit des scripts de chargement de jeux de donnÃ©es locaux et distants. La bibliothÃ¨que prend en charge plusieurs formats de donnÃ©es courants, tels que :

| Format des donnÃ©es  | Script de chargement |                         Exemple                         |
| :----------------: | :------------------: | :-----------------------------------------------------: |
|     CSV & TSV      |        `csv`         |     `load_dataset("csv", data_files="my_file.csv")`     |
|   Fichiers texte   |        `text`        |    `load_dataset("text", data_files="my_file.txt")`     |
| JSON & JSON Lines |        `json`        |   `load_dataset("json", data_files="my_file.jsonl")`    |
| DataFrames en Pickle |       `pandas`       | `load_dataset("pandas", data_files="my_dataframe.pkl")` |

Comme indiquÃ© dans le tableau, pour chaque format de donnÃ©es, nous avons juste besoin de spÃ©cifier le type de script de chargement dans la fonction `load_dataset()`, ainsi qu'un argument `data_files` qui spÃ©cifie le chemin vers un ou plusieurs fichiers. CommenÃ§ons par charger un jeu de donnÃ©es Ã  partir de fichiers locaux puis plus tard comment faire la mÃªme chose avec des fichiers distants.

## Charger un jeu de donnÃ©es local

Pour cet exemple, nous utilisons le jeu de donnÃ©es [SQuAD-it](https://github.com/crux82/squad-it/) qui est un grand jeu de donnÃ©es pour la tÃ¢che de *Question Awnswering* en italien.

Les Ã©chantillons dâ€™entraÃ®nement et de test sont hÃ©bergÃ©s sur GitHub, nous pouvons donc les tÃ©lÃ©charger avec une simple commande `wget` :

```python
!wget https://github.com/crux82/squad-it/raw/master/SQuAD_it-train.json.gz
!wget https://github.com/crux82/squad-it/raw/master/SQuAD_it-test.json.gz
```

Cela tÃ©lÃ©charge deux fichiers compressÃ©s appelÃ©s *SQuAD_it-train.json.gz* et *SQuAD_it-test.json.gz* que nous pouvons dÃ©compresser avec la commande Linux `gzip` :

```python
!gzip -dkv SQuAD_it-*.json.gz
```

```bash
SQuAD_it-test.json.gz:	   87.4% -- replaced with SQuAD_it-test.json
SQuAD_it-train.json.gz:	   82.2% -- replaced with SQuAD_it-train.json
```

Nous pouvons voir que les fichiers compressÃ©s ont Ã©tÃ© remplacÃ©s par _SQuAD_it-train.json_ et _SQuAD_it-text.json_, et que les donnÃ©es sont stockÃ©es au format JSON.

> [!TIP]
> âœ Si vous vous demandez pourquoi il y a un caractÃ¨re `!` dans les commandes *shell* ci-dessus, c'est parce que nous les exÃ©cutons dans un *notebook* Jupyter. Supprimez simplement le prÃ©fixe si vous souhaitez tÃ©lÃ©charger et dÃ©compresser le jeu de donnÃ©es dans un terminal.

Pour charger un fichier JSON avec la fonction `load_dataset()`, nous avons juste besoin de savoir si nous avons affaire Ã  du JSON ordinaire (similaire Ã  un dictionnaire imbriquÃ©) ou Ã  des lignes JSON (JSON sÃ©parÃ© par des lignes). Comme de nombreux jeux de donnÃ©es de questions-rÃ©ponses, SQuAD-it utilise le format imbriquÃ© oÃ¹ tout le texte est stockÃ© dans un champ `data`. Cela signifie que nous pouvons charger le jeu de donnÃ©es en spÃ©cifiant l'argument `field` comme suit :

```py
from datasets import load_dataset

squad_it_dataset = load_dataset("json", data_files="SQuAD_it-train.json", field="data")
```

Par dÃ©faut, le chargement de fichiers locaux crÃ©e un objet `DatasetDict` avec un Ã©chantillon `train`. Nous pouvons le voir en inspectant l'objet `squad_it_dataset` :

```py
squad_it_dataset
```

```python out
DatasetDict({
    train: Dataset({
        features: ['title', 'paragraphs'],
        num_rows: 442
    })
})
```

Cela nous montre le nombre de lignes et les noms de colonnes associÃ©s Ã  lâ€™Ã©chantillon dâ€™entraÃ®nement. Nous pouvons afficher l'un des exemples en indexant lâ€™Ã©chantillon `train` comme suit :

```py
squad_it_dataset["train"][0]
```

```python out
{
    "title": "Terremoto del Sichuan del 2008", # SÃ©isme du Sichuan 2008
    "paragraphs": [
        {
            "context": "Il terremoto del Sichuan del 2008 o il terremoto...",
			# Le tremblement de terre du Sichuan de 2008 ou le...
            "qas": [
                {
                    "answers": [{"answer_start": 29, "text": "2008"}],
                    "id": "56cdca7862d2951400fa6826",
                    "question": "In quale anno si Ã¨ verificato il terremoto nel Sichuan?", 
					# En quelle annÃ©e le tremblement de terre du Sichuan a-t-il eu lieu ?
                },
                ...
            ],
        },
        ...
    ],
}
```

Super, nous avons chargÃ© notre premier jeu de donnÃ©es local ! Mais ce que nous voulons vraiment, c'est inclure Ã  la fois les Ã©chantillons `train` et `test` dans un seul objet `DatasetDict` afin que nous puissions appliquer les fonctions `Dataset.map()` sur les deux Ã  la fois . Pour ce faire, nous pouvons fournir un dictionnaire Ã  l'argument `data_files` qui associe chaque nom des Ã©chantillons Ã  un fichier associÃ© Ã  cet Ã©chantillon :

```py
data_files = {"train": "SQuAD_it-train.json", "test": "SQuAD_it-test.json"}
squad_it_dataset = load_dataset("json", data_files=data_files, field="data")
squad_it_dataset
```

```python out
DatasetDict({
    train: Dataset({
        features: ['title', 'paragraphs'],
        num_rows: 442
    })
    test: Dataset({
        features: ['title', 'paragraphs'],
        num_rows: 48
    })
})
```

C'est exactement ce que nous voulions. DÃ©sormais, nous pouvons appliquer diverses techniques de prÃ©traitement pour nettoyer les donnÃ©es, tokeniser les avis, etc.

> [!TIP]
> L'argument `data_files` de la fonction `load_dataset()` est assez flexible et peut Ãªtre soit un chemin de fichier unique, une liste de chemins de fichiers, ou un dictionnaire qui fait correspondre les noms des Ã©chantillons aux chemins de fichiers. Vous pouvez Ã©galement regrouper les fichiers correspondant Ã  un motif spÃ©cifiÃ© selon les rÃ¨gles utilisÃ©es par le shell Unix. Par exemple, vous pouvez regrouper tous les fichiers JSON d'un rÃ©pertoire en une seule division en dÃ©finissant `data_files="*.json"`. Voir la [documentation](https://huggingface.co/docs/datasets/loading#local-and-remote-files) de ğŸ¤— *Datasets* pour plus de dÃ©tails.

Les scripts de chargement de ğŸ¤— *Datasets* prennent en charge la dÃ©compression automatique des fichiers d'entrÃ©e. Nous aurions donc pu ignorer l'utilisation de `gzip` en pointant l'argument `data_files` directement sur les fichiers compressÃ©s :

```py
data_files = {"train": "SQuAD_it-train.json.gz", "test": "SQuAD_it-test.json.gz"}
squad_it_dataset = load_dataset("json", data_files=data_files, field="data")
```

Cela peut Ãªtre utile si vous ne souhaitez pas dÃ©compresser manuellement de nombreux fichiers GZIP. La dÃ©compression automatique s'applique Ã©galement Ã  d'autres formats courants tels que ZIP et TAR. Il vous suffit donc de pointer `data_files` vers les fichiers compressÃ©s et vous Ãªtes prÃªt Ã  partir !

Maintenant que vous savez comment charger des fichiers locaux sur votre ordinateur portable ou de bureau, examinons le chargement de fichiers distants.

## Charger un jeu de donnÃ©es distant

Si vous travaillez en tant que *data scientist* ou codeur dans une entreprise, il y a de fortes chances que les jeux de donnÃ©es que vous souhaitez analyser soient stockÃ©s sur un serveur distant. Heureusement, charger des fichiers distants est aussi simple que de charger des fichiers locaux ! Au lieu de fournir un chemin vers les fichiers locaux, nous pointons l'argument `data_files` de `load_dataset()` vers une ou plusieurs URL oÃ¹ les fichiers distants sont stockÃ©s. Par exemple, pour le jeu de donnÃ©es SQuAD-it hÃ©bergÃ© sur GitHub, nous pouvons simplement faire pointer `data_files` vers les URL _SQuAD_it-*.json.gz_ comme suit :

```py
url = "https://github.com/crux82/squad-it/raw/master/"
data_files = {
    "train": url + "SQuAD_it-train.json.gz",
    "test": url + "SQuAD_it-test.json.gz",
}
squad_it_dataset = load_dataset("json", data_files=data_files, field="data")
```

Cela renvoie le mÃªme objet `DatasetDict` obtenu ci-dessus mais nous Ã©vite de tÃ©lÃ©charger et de dÃ©compresser manuellement les fichiers _SQuAD_it-*.json.gz_. Ceci conclut notre incursion dans les diffÃ©rentes faÃ§ons de charger des jeux de donnÃ©es qui ne sont pas hÃ©bergÃ©s sur le *Hub*. Maintenant que nous avons un jeu de donnÃ©es avec lequel jouer, mettons la main Ã  la pÃ¢te avec diverses techniques de gestion des donnÃ©es !

> [!TIP]
> âœï¸ **Essayez !** Choisissez un autre jeu de donnÃ©es hÃ©bergÃ© sur GitHub ou dans le [*UCI Machine Learning Repository*](https://archive.ics.uci.edu/ml/index.php) et essayez de le charger localement et Ã  distance en utilisant les techniques prÃ©sentÃ©es ci-dessus. Pour obtenir des points bonus, essayez de charger un jeu de donnÃ©es stockÃ© au format CSV ou texte (voir la [documentation](https://huggingface.co/docs/datasets/loading#local-and-remote-files) pour plus d'informations sur ces formats).
