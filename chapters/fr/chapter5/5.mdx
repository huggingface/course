# Cr√©ation de votre propre jeu de donn√©es

<CourseFloatingBanner chapter={5}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "English", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter5/section5.ipynb"},
    {label: "Fran√ßais", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/fr/chapter5/section5.ipynb"},
    {label: "English", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter5/section5.ipynb"},
    {label: "Fran√ßais", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/fr/chapter5/section5.ipynb"},
]} />


Parfois, le jeu de donn√©es dont vous avez besoin pour cr√©er une application de NLP n'existe pas. Vous devrez donc le cr√©er vous-m√™me. Dans cette section, nous allons vous montrer comment cr√©er un corpus de [probl√®mes GitHub](https://github.com/features/issues/), qui sont couramment utilis√©s pour suivre les bogues ou les fonctionnalit√©s dans les d√©p√¥ts GitHub. Ce corpus pourrait √™tre utilis√© √† diverses fins, notamment :

* explorer combien de temps il faut pour fermer les probl√®mes ouverts ou les *pull requests*
* entra√Æner d'un _classifieur multilabel_ capable d'√©tiqueter les probl√®mes avec des m√©tadonn√©es bas√©es sur la description du probl√®me (par exemple : ¬´ bug ¬ª, ¬´ am√©lioration ¬ª ou  ¬´ question ¬ª)
* cr√©er un moteur de recherche s√©mantique pour trouver les probl√®mes correspondant √† la requ√™te d'un utilisateur

Ici, nous nous concentrerons sur la cr√©ation du corpus, et dans la section suivante, nous aborderons l'application de recherche s√©mantique. Pour garder les choses m√©ta, nous utiliserons les probl√®mes GitHub associ√©s √† un projet open source populaire : ü§ó *Datasets* ! Voyons comment obtenir les donn√©es et explorons les informations contenues dans ces probl√®mes.

## Obtenir les donn√©es

Vous pouvez trouver tous les probl√®mes dans ü§ó *Datasets* en acc√©dant √† l'[onglet ¬´ Issues ¬ª](https://github.com/huggingface/datasets/issues) du d√©p√¥t. Comme le montre la capture d'√©cran suivante, au moment de la r√©daction, il y avait 331 probl√®mes ouverts et 668 probl√®mes ferm√©s.

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter5/datasets-issues.png" alt="The GitHub issues associated with ü§ó Datasets." width="80%"/>
</div>

Si vous cliquez sur l'un de ces probl√®mes, vous constaterez qu'il contient un titre, une description et un ensemble d'√©tiquettes qui caract√©risent le probl√®me. Un exemple est montr√© dans la capture d'√©cran ci-dessous.

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter5/datasets-issues-single.png" alt="A typical GitHub issue in the ü§ó Datasets repository." width="80%"/>
</div>

Pour t√©l√©charger tous les probl√®mes du d√©p√¥t, nous utilisons l'[API REST GitHub](https://docs.github.com/en/rest) pour interroger le point de terminaison [`Issues`](https://docs.github.com/en/rest/reference/issues#list-repository-issues). Ce point de terminaison renvoie une liste d'objets JSON. Chaque objet contenant un grand nombre de champs qui incluent le titre et la description ainsi que des m√©tadonn√©es sur l'√©tat du probl√®me, etc.

Un moyen pratique de t√©l√©charger les probl√®mes consiste √† utiliser la biblioth√®que `requests`, qui est la m√©thode standard pour effectuer des requ√™tes HTTP en Python. Vous pouvez installer la biblioth√®que en ex√©cutant :

```python
!pip install requests
```

Une fois la biblioth√®que install√©e, vous pouvez envoyer des requ√™tes GET au point de terminaison `Issues` en appelant la fonction `requests.get()`. Par exemple, vous pouvez ex√©cuter la commande suivante pour r√©cup√©rer le premier num√©ro sur la premi√®re page :

```py
import requests

url = "https://api.github.com/repos/huggingface/datasets/issues?page=1&per_page=1"
response = requests.get(url)
```

L'objet `response` contient de nombreuses informations utiles sur la requ√™te, y compris le code d'√©tat HTTP :

```py
response.status_code
```

```python out
200
```

o√π un statut `200` signifie que la requ√™te a r√©ussi (vous pouvez trouver une liste des codes de statut HTTP possibles [ici](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)). Ce qui nous int√©resse vraiment, cependant, c'est le _payload_, qui peut √™tre consult√© dans diff√©rents formats comme les octets, les cha√Ænes ou JSON. Comme nous savons que nos probl√®mes sont au format JSON, examinons la charge utile comme suit :

```py
response.json()
```

```python out
[{'url': 'https://api.github.com/repos/huggingface/datasets/issues/2792',
  'repository_url': 'https://api.github.com/repos/huggingface/datasets',
  'labels_url': 'https://api.github.com/repos/huggingface/datasets/issues/2792/labels{/name}',
  'comments_url': 'https://api.github.com/repos/huggingface/datasets/issues/2792/comments',
  'events_url': 'https://api.github.com/repos/huggingface/datasets/issues/2792/events',
  'html_url': 'https://github.com/huggingface/datasets/pull/2792',
  'id': 968650274,
  'node_id': 'MDExOlB1bGxSZXF1ZXN0NzEwNzUyMjc0',
  'number': 2792,
  'title': 'Update GooAQ',
  'user': {'login': 'bhavitvyamalik',
   'id': 19718818,
   'node_id': 'MDQ6VXNlcjE5NzE4ODE4',
   'avatar_url': 'https://avatars.githubusercontent.com/u/19718818?v=4',
   'gravatar_id': '',
   'url': 'https://api.github.com/users/bhavitvyamalik',
   'html_url': 'https://github.com/bhavitvyamalik',
   'followers_url': 'https://api.github.com/users/bhavitvyamalik/followers',
   'following_url': 'https://api.github.com/users/bhavitvyamalik/following{/other_user}',
   'gists_url': 'https://api.github.com/users/bhavitvyamalik/gists{/gist_id}',
   'starred_url': 'https://api.github.com/users/bhavitvyamalik/starred{/owner}{/repo}',
   'subscriptions_url': 'https://api.github.com/users/bhavitvyamalik/subscriptions',
   'organizations_url': 'https://api.github.com/users/bhavitvyamalik/orgs',
   'repos_url': 'https://api.github.com/users/bhavitvyamalik/repos',
   'events_url': 'https://api.github.com/users/bhavitvyamalik/events{/privacy}',
   'received_events_url': 'https://api.github.com/users/bhavitvyamalik/received_events',
   'type': 'User',
   'site_admin': False},
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2021-08-12T11:40:18Z',
  'updated_at': '2021-08-12T12:31:17Z',
  'closed_at': None,
  'author_association': 'CONTRIBUTOR',
  'active_lock_reason': None,
  'pull_request': {'url': 'https://api.github.com/repos/huggingface/datasets/pulls/2792',
   'html_url': 'https://github.com/huggingface/datasets/pull/2792',
   'diff_url': 'https://github.com/huggingface/datasets/pull/2792.diff',
   'patch_url': 'https://github.com/huggingface/datasets/pull/2792.patch'},
  'body': '[GooAQ](https://github.com/allenai/gooaq) dataset was recently updated after splits were added for the same. This PR contains new updated GooAQ with train/val/test splits and updated README as well.',
  'performed_via_github_app': None}]
```

Waouh, √ßa fait beaucoup d'informations ! Nous pouvons voir des champs utiles comme `title`, `body` et `number` qui d√©crivent le probl√®me, ainsi que des informations sur l'utilisateur GitHub qui a ouvert le probl√®me.

<Tip>

‚úèÔ∏è **Essayez !** Cliquez sur quelques-unes des URL pour avoir une id√©e du type d'informations auxquelles chaque probl√®me GitHub est li√©.

</Tip>

Comme d√©crit dans la [documentation GitHub](https://docs.github.com/en/rest/overview/resources-in-the-rest-api#rate-limiting), les requ√™tes non authentifi√©es sont limit√©es √† 60 requ√™tes par heure. Bien que vous puissiez augmenter le param√®tre de requ√™te `per_page` pour r√©duire le nombre de requ√™tes que vous effectuez, vous atteindrez toujours la limite de d√©bit sur tout d√©p√¥t contenant des milliers de probl√®mes. Donc, √† la place, vous devez suivre les [instructions de GitHub](https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token) sur la cr√©ation d'un _jeton d'acc√®s personnel_ afin que vous peut augmenter la limite de d√©bit √† 5 000 requ√™tes par heure. Une fois que vous avez votre *token*, vous pouvez l'inclure dans l'en-t√™te de la requ√™te :

```py
GITHUB_TOKEN = xxx  # Copiez votre jeton GitHub ici
headers = {"Authorization": f"token {GITHUB_TOKEN}"}
```

<Tip warning={true}>

‚ö†Ô∏è Ne partagez pas un *notebook* avec votre `GITHUB_TOKEN` coll√© dedans. Nous vous recommandons de supprimer la derni√®re cellule une fois que vous l'avez ex√©cut√©e pour √©viter de divulguer accidentellement ces informations. Mieux encore, stockez le jeton dans un fichier *.env* et utilisez la [biblioth√®que `python-dotenv`](https://github.com/theskumar/python-dotenv) pour le charger automatiquement pour vous en tant que variable d'environnement.

</Tip>

Maintenant que nous avons notre jeton d'acc√®s, cr√©ons une fonction qui peut t√©l√©charger tous les probl√®mes depuis un r√©f√©rentiel GitHub :

```py
import time
import math
from pathlib import Path
import pandas as pd
from tqdm.notebook import tqdm


def fetch_issues(
    owner="huggingface",
    repo="datasets",
    num_issues=10_000,
    rate_limit=5_000,
    issues_path=Path("."),
):
    if not issues_path.is_dir():
        issues_path.mkdir(exist_ok=True)

    batch = []
    all_issues = []
    per_page = 100  # Nombre d'issues √† retourner par page
    num_pages = math.ceil(num_issues / per_page)
    base_url = "https://api.github.com/repos"

    for page in tqdm(range(num_pages)):
        # Requ√™te avec state=all pour obtenir les issues ouvertes et ferm√©es
        query = f"issues?page={page}&per_page={per_page}&state=all"
        issues = requests.get(f"{base_url}/{owner}/{repo}/{query}", headers=headers)
        batch.extend(issues.json())

        if len(batch) > rate_limit and len(all_issues) < num_issues:
            all_issues.extend(batch)
            batch = []  # Vider le batch pour la p√©riode de temps suivante
            print(f"Reached GitHub rate limit. Sleeping for one hour ...")
            time.sleep(60 * 60 + 1)

    all_issues.extend(batch)
    df = pd.DataFrame.from_records(all_issues)
    df.to_json(f"{issues_path}/{repo}-issues.jsonl", orient="records", lines=True)
    print(
        f"Downloaded all the issues for {repo}! Dataset stored at {issues_path}/{repo}-issues.jsonl"
    )
```

D√©sormais, lorsque nous appellerons `fetch_issues()`, tous les probl√®mes seront t√©l√©charg√©s par batchs pour √©viter de d√©passer la limite de GitHub sur le nombre de requ√™tes par heure. Le r√©sultat sera stock√© dans un fichier _repository_name-issues.jsonl_, o√π chaque ligne est un objet JSON qui repr√©sente un probl√®me. Utilisons cette fonction pour saisir tous les probl√®mes de ü§ó *Datasets* :

```py
# En fonction de votre connexion Internet, l'ex√©cution peut prendre plusieurs minutes...
fetch_issues()
```

Une fois les probl√®mes t√©l√©charg√©s, nous pouvons les charger localement en utilisant nos nouvelles comp√©tences de [section 2](/course/fr/chapter5/2) :

```py
issues_dataset = load_dataset("json", data_files="datasets-issues.jsonl", split="train")
issues_dataset
```

```python out
Dataset({
    features: ['url', 'repository_url', 'labels_url', 'comments_url', 'events_url', 'html_url', 'id', 'node_id', 'number', 'title', 'user', 'labels', 'state', 'locked', 'assignee', 'assignees', 'milestone', 'comments', 'created_at', 'updated_at', 'closed_at', 'author_association', 'active_lock_reason', 'pull_request', 'body', 'timeline_url', 'performed_via_github_app'],
    num_rows: 3019
})
```

G√©nial, nous avons cr√©√© notre premier jeu de donn√©es √† partir de rien ! Mais pourquoi y a-t-il plusieurs milliers de probl√®mes alors que l'[onglet ¬´ Issues ¬ª](https://github.com/huggingface/datasets/issues) de la librairie ü§ó *Datasets* n'affiche qu'environ 1 000 probl√®mes au total ü§î ? Comme d√©crit dans la [documentation GitHub](https://docs.github.com/en/rest/reference/issues#list-issues-assigned-to-the-authenticated-user), c'est parce que nous avons t√©l√©charg√© toutes les *pull requests* √©galement :

> L'API REST v3 de GitHub consid√®re chaque *pull request* comme un probl√®me, mais chaque probl√®me n'est pas une *pull request*. Pour cette raison, les points de terminaison ¬´ Issues ¬ª peuvent renvoyer √† la fois des probl√®mes et des *pull requests* dans la r√©ponse. Vous pouvez identifier les *pull requests* par la cl√© `pull_request`. Sachez que l'identifiant d'une *pull request* renvoy√©e par les points de terminaison ¬´ Issues ¬ª sera un identifiant de probl√®me.

√âtant donn√© que le contenu des ¬´ Issues ¬ª et des *pull request* est assez diff√©rent, proc√©dons √† un pr√©traitement mineur pour nous permettre de les distinguer.

## Nettoyer les donn√©es

L'extrait ci-dessus de la documentation de GitHub nous indique que la colonne `pull_request` peut √™tre utilis√©e pour diff√©rencier les *issues* et les *pull requests*. Regardons un √©chantillon al√©atoire pour voir quelle est la diff√©rence. Comme nous l'avons fait dans [section 3](/course/fr/chapter5/3), nous allons encha√Æner `Dataset.shuffle()` et `Dataset.select()` pour cr√©er un √©chantillon al√©atoire, puis compresser `html_url` et ` pull_request` afin que nous puissions comparer les diff√©rentes URL :

```py
sample = issues_dataset.shuffle(seed=666).select(range(3))

# Afficher l'URL et les entr√©es de la PR
for url, pr in zip(sample["html_url"], sample["pull_request"]):
    print(f">> URL: {url}")
    print(f">> Pull request: {pr}\n")
```

```python out
>> URL: https://github.com/huggingface/datasets/pull/850
>> Pull request: {'url': 'https://api.github.com/repos/huggingface/datasets/pulls/850', 'html_url': 'https://github.com/huggingface/datasets/pull/850', 'diff_url': 'https://github.com/huggingface/datasets/pull/850.diff', 'patch_url': 'https://github.com/huggingface/datasets/pull/850.patch'}

>> URL: https://github.com/huggingface/datasets/issues/2773
>> Pull request: None

>> URL: https://github.com/huggingface/datasets/pull/783
>> Pull request: {'url': 'https://api.github.com/repos/huggingface/datasets/pulls/783', 'html_url': 'https://github.com/huggingface/datasets/pull/783', 'diff_url': 'https://github.com/huggingface/datasets/pull/783.diff', 'patch_url': 'https://github.com/huggingface/datasets/pull/783.patch'}
```

Ici, nous pouvons voir que chaque *pull request* est associ√©e √† diverses URL, tandis que les probl√®mes ordinaires ont une entr√©e `None`. Nous pouvons utiliser cette distinction pour cr√©er une nouvelle colonne `is_pull_request` qui v√©rifie si le champ `pull_request` est `None` ou non :

```py
issues_dataset = issues_dataset.map(
    lambda x: {"is_pull_request": False if x["pull_request"] is None else True}
)
```

<Tip>

‚úèÔ∏è **Essayez !** Calculez le temps moyen n√©cessaire pour r√©soudre les probl√®mes dans ü§ó *Datasets*. Vous pouvez trouver la fonction `Dataset.filter()` utile pour filtrer les demandes d'extraction et les probl√®mes ouverts. Vous pouvez utiliser la fonction `Dataset.set_format()` pour convertir le jeu de donn√©es en un `DataFrame` afin que vous puissiez facilement manipuler les horodatages `created_at` et `closed_at`. Pour les points bonus, calculez le temps moyen n√©cessaire pour fermer les *pull_requests*.

</Tip>

Bien que nous puissions continuer √† nettoyer davantage le jeu de donn√©es en supprimant ou en renommant certaines colonnes, il est g√©n√©ralement recommand√© de le conserver aussi brut que possible √† ce stade afin qu'il puisse √™tre facilement utilis√© dans plusieurs applications.

Avant de pousser notre jeu de donn√©es vers le *Hub* d‚ÄôHugging Face, traitons une chose manquante : les commentaires associ√©s √† chaque probl√®me et *pull requests*. Nous les ajouterons ensuite avec l'API GitHub REST !

## Enrichir le jeu de donn√©es

Comme le montre la capture d'√©cran suivante, les commentaires associ√©s √† un probl√®me ou √† une *pull request* fournissent une riche source d'informations, en particulier si nous souhaitons cr√©er un moteur de recherche pour r√©pondre aux requ√™tes des utilisateurs sur la biblioth√®que.

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter5/datasets-issues-comment.png" alt="Comments associated with an issue about ü§ó Datasets." width="80%"/>
</div>

L'API REST GitHub fournit un point de terminaison [`Comments`](https://docs.github.com/en/rest/reference/issues#list-issue-comments) qui renvoie tous les commentaires associ√©s √† un num√©ro de probl√®me. Testons le point de terminaison pour voir ce qu'il renvoie :

```py
issue_number = 2792
url = f"https://api.github.com/repos/huggingface/datasets/issues/{issue_number}/comments"
response = requests.get(url, headers=headers)
response.json()
```

```python out
[{'url': 'https://api.github.com/repos/huggingface/datasets/issues/comments/897594128',
  'html_url': 'https://github.com/huggingface/datasets/pull/2792#issuecomment-897594128',
  'issue_url': 'https://api.github.com/repos/huggingface/datasets/issues/2792',
  'id': 897594128,
  'node_id': 'IC_kwDODunzps41gDMQ',
  'user': {'login': 'bhavitvyamalik',
   'id': 19718818,
   'node_id': 'MDQ6VXNlcjE5NzE4ODE4',
   'avatar_url': 'https://avatars.githubusercontent.com/u/19718818?v=4',
   'gravatar_id': '',
   'url': 'https://api.github.com/users/bhavitvyamalik',
   'html_url': 'https://github.com/bhavitvyamalik',
   'followers_url': 'https://api.github.com/users/bhavitvyamalik/followers',
   'following_url': 'https://api.github.com/users/bhavitvyamalik/following{/other_user}',
   'gists_url': 'https://api.github.com/users/bhavitvyamalik/gists{/gist_id}',
   'starred_url': 'https://api.github.com/users/bhavitvyamalik/starred{/owner}{/repo}',
   'subscriptions_url': 'https://api.github.com/users/bhavitvyamalik/subscriptions',
   'organizations_url': 'https://api.github.com/users/bhavitvyamalik/orgs',
   'repos_url': 'https://api.github.com/users/bhavitvyamalik/repos',
   'events_url': 'https://api.github.com/users/bhavitvyamalik/events{/privacy}',
   'received_events_url': 'https://api.github.com/users/bhavitvyamalik/received_events',
   'type': 'User',
   'site_admin': False},
  'created_at': '2021-08-12T12:21:52Z',
  'updated_at': '2021-08-12T12:31:17Z',
  'author_association': 'CONTRIBUTOR',
  'body': "@albertvillanova my tests are failing here:\r\n```\r\ndataset_name = 'gooaq'\r\n\r\n    def test_load_dataset(self, dataset_name):\r\n        configs = self.dataset_tester.load_all_configs(dataset_name, is_local=True)[:1]\r\n>       self.dataset_tester.check_load_dataset(dataset_name, configs, is_local=True, use_local_dummy_data=True)\r\n\r\ntests/test_dataset_common.py:234: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\ntests/test_dataset_common.py:187: in check_load_dataset\r\n    self.parent.assertTrue(len(dataset[split]) > 0)\r\nE   AssertionError: False is not true\r\n```\r\nWhen I try loading dataset on local machine it works fine. Any suggestions on how can I avoid this error?",
  'performed_via_github_app': None}]
```

Nous pouvons voir que le commentaire est stock√© dans le champ `body`. Ecrivons donc une fonction simple qui renvoie tous les commentaires associ√©s √† un probl√®me en s√©lectionnant le contenu `body` pour chaque √©l√©ment dans `response.json()` :

```py
def get_comments(issue_number):
    url = f"https://api.github.com/repos/huggingface/datasets/issues/{issue_number}/comments"
    response = requests.get(url, headers=headers)
    return [r["body"] for r in response.json()]


# Tester notre fonction fonctionne comme pr√©vu
get_comments(2792)
```

```python out
["@albertvillanova my tests are failing here:\r\n```\r\ndataset_name = 'gooaq'\r\n\r\n    def test_load_dataset(self, dataset_name):\r\n        configs = self.dataset_tester.load_all_configs(dataset_name, is_local=True)[:1]\r\n>       self.dataset_tester.check_load_dataset(dataset_name, configs, is_local=True, use_local_dummy_data=True)\r\n\r\ntests/test_dataset_common.py:234: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\ntests/test_dataset_common.py:187: in check_load_dataset\r\n    self.parent.assertTrue(len(dataset[split]) > 0)\r\nE   AssertionError: False is not true\r\n```\r\nWhen I try loading dataset on local machine it works fine. Any suggestions on how can I avoid this error?"]
```

Cela a l'air bien. Utilisons `Dataset.map()` pour ajouter une nouvelle colonne `comments` √† chaque probl√®me de notre jeu de donn√©es :

```py
# Selon votre connexion internet, cela peut prendre quelques minutes...
issues_with_comments_dataset = issues_dataset.map(
    lambda x: {"comments": get_comments(x["number"])}
)
```

La derni√®re √©tape consiste √† enregistrer le jeu de donn√©es augment√©es avec nos donn√©es brutes afin que nous puissions les pousser tous les deux vers le *Hub* :

```py
issues_with_comments_dataset.to_json("issues-datasets-with-comments.jsonl")
```

## T√©l√©chargement du jeu de donn√©es sur le <i>Hub</i>

<Youtube id="HaN6qCr_Afc"/>

Maintenant que nous avons notre jeu de donn√©es augment√©, il est temps de le pousser vers le *Hub* afin que nous puissions le partager avec la communaut√© ! Pour t√©l√©charger le jeu de donn√©es, nous utilisons la [biblioth√®que ü§ó *Hub*](https://github.com/huggingface/huggingface_hub), qui nous permet d'interagir avec le *Hub* d‚ÄôHugging Face via une API Python. ü§ó *Hub* est pr√©install√© avec ü§ó *Transformers*, nous pouvons donc l'utiliser directement. Par exemple, nous pouvons utiliser la fonction `list_datasets()` pour obtenir des informations sur tous les ensembles de donn√©es publics actuellement h√©berg√©s sur le *Hub*:

```py
from huggingface_hub import list_datasets

all_datasets = list_datasets()
print(f"Number of datasets on Hub: {len(all_datasets)}")
print(all_datasets[0])
```

```python out
Number of datasets on Hub: 1487
Dataset Name: acronym_identification, Tags: ['annotations_creators:expert-generated', 'language_creators:found', 'languages:en', 'licenses:mit', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:structure-prediction', 'task_ids:structure-prediction-other-acronym-identification']
```

Nous pouvons voir qu'il y a actuellement pr√®s de 1 500 jeux de donn√©es sur le *Hub* et la fonction `list_datasets()` fournit √©galement des m√©tadonn√©es de base sur chaque d√©p√¥ts de jeux de donn√©es.

Pour nos besoins, la premi√®re chose que nous devons faire est de cr√©er un nouveau d√©p√¥t de jeux de donn√©es sur le *Hub*. Pour ce faire, nous avons besoin d'un jeton d'authentification, qui peut √™tre obtenu en se connectant d'abord au *Hub* d‚ÄôHugging Face avec la fonction `notebook_login()` :

```py
from huggingface_hub import notebook_login

notebook_login()
```

Cela cr√©√© un *widget* dans lequel vous pouvez entrer votre nom d'utilisateur et votre mot de passe. Un jeton API sera enregistr√© dans *~/.huggingface/token*. Si vous ex√©cutez le code dans un terminal, vous pouvez vous connecter via la CLI √† la place :

```bash
huggingface-cli login
```

Une fois que nous avons fait cela, nous pouvons cr√©er un nouveau d√©p√¥t de jeux de donn√©es avec la fonction `create_repo()` :

```py
from huggingface_hub import create_repo

repo_url = create_repo(name="github-issues", repo_type="dataset")
repo_url
```

```python out
'https://huggingface.co/datasets/lewtun/github-issues'
```

Dans cet exemple, nous avons cr√©√© un d√©p√¥t vide appel√© `github-issues` sous le nom d'utilisateur `lewtun` (le nom d'utilisateur doit √™tre votre nom d'utilisateur Hub lorsque vous ex√©cutez ce code !).

<Tip>

‚úèÔ∏è **Essayez !** Utilisez votre nom d'utilisateur et votre mot de passe Hugging Face pour obtenir un jeton et cr√©er un d√©p√¥t vide appel√© `github-issues`. N'oubliez pas de **n'enregistrez jamais vos informations d'identification** dans Colab ou tout autre r√©f√©rentiel car ces informations peuvent √™tre exploit√©es par de mauvais individus.

</Tip>

Ensuite, clonons le d√©p√¥t du Hub sur notre machine locale et copions-y notre fichier jeu de donn√©es. ü§ó *Hub* fournit une classe `Repository` pratique qui encapsule de nombreuses commandes Git courantes. Donc pour cloner le d√©p√¥t distant, nous devons simplement fournir l'URL et le chemin local vers lesquels nous souhaitons cloner :

```py
from huggingface_hub import Repository

repo = Repository(local_dir="github-issues", clone_from=repo_url)
!cp datasets-issues-with-comments.jsonl github-issues/
```

Par d√©faut, diverses extensions de fichiers (telles que *.bin*, *.gz* et *.zip*) sont suivies avec Git LFS afin que les fichiers volumineux puissent √™tre versionn√©s dans le m√™me workflow Git. Vous pouvez trouver une liste des extensions de fichiers suivis dans le fichier *.gitattributes* du r√©f√©rentiel. Pour inclure le format JSON Lines dans la liste, nous pouvons ex√©cuter la commande suivante :

```py
repo.lfs_track("*.jsonl")
```

Ensuite, nous pouvons utiliser `Repository.push_to_hub()` pour pousser le jeu de donn√©es vers le *Hub* :

```py
repo.push_to_hub()
```

Si nous naviguons vers l'URL contenue dans `repo_url`, nous devrions maintenant voir que notre fichier de jeu de donn√©es a √©t√© t√©l√©charg√©.

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter5/hub-repo.png" alt="Our dataset repository on the Hugging Face Hub." width="80%"/>
</div>

√Ä partir de l√†, n'importe qui peut t√©l√©charger le jeu de donn√©es en fournissant simplement `load_dataset()` avec l'ID du r√©f√©rentiel comme argument `path` :

```py
remote_dataset = load_dataset("lewtun/github-issues", split="train")
remote_dataset
```

```python out
Dataset({
    features: ['url', 'repository_url', 'labels_url', 'comments_url', 'events_url', 'html_url', 'id', 'node_id', 'number', 'title', 'user', 'labels', 'state', 'locked', 'assignee', 'assignees', 'milestone', 'comments', 'created_at', 'updated_at', 'closed_at', 'author_association', 'active_lock_reason', 'pull_request', 'body', 'performed_via_github_app', 'is_pull_request'],
    num_rows: 2855
})
```

Cool, nous avons pouss√© notre jeu de donn√©es vers le *Hub* et il est disponible pour que d'autres puissent l'utiliser ! Il ne reste plus qu'une chose importante √† faire : ajouter une _carte de jeu de donn√©es_ qui explique comment le corpus a √©t√© cr√©√© et fournit d'autres informations utiles √† la communaut√©.

<Tip>

üí° Vous pouvez √©galement t√©l√©charger un jeu de donn√©es sur le *Hub* directement depuis le terminal en utilisant `huggingface-cli` et un peu de magie Git. Consultez le [guide de ü§ó *Datasets*](https://huggingface.co/docs/datasets/share.html#add-a-community-dataset) pour savoir comment proc√©der.

</Tip>

## Cr√©ation d'une carte pour un jeu de donn√©es

Des jeux de donn√©es bien document√©s sont plus susceptibles d'√™tre utiles aux autres (y compris √† vous-m√™me) car ils fournissent le contexte permettant aux utilisateurs de d√©cider si le jeu de donn√©es est pertinent pour leur t√¢che et d'√©valuer les biais potentiels ou les risques associ√©s √† l'utilisation du jeu de donn√©es.

Sur le *Hub*, ces informations sont stock√©es dans le fichier *README.md* de chaque d√©p√¥t de jeux de donn√©es. Il y a deux √©tapes principales que vous devez suivre avant de cr√©er ce fichier :

1. Utilisez l'[application `datasets-tagging`](https://huggingface.co/datasets/tagging/) pour cr√©er des balises de m√©tadonn√©es au format YAML. Ces balises sont utilis√©es pour une vari√©t√© de fonctionnalit√©s de recherche sur le *Hub* d‚ÄôHugging Face et garantissent que votre jeu de donn√©es peut √™tre facilement trouv√© par les membres de la communaut√©. Puisque nous avons cr√©√© un jeu de donn√©es personnalis√© ici, vous devrez cloner le r√©f√©rentiel `datasets-tagging` et ex√©cuter l'application localement. Voici √† quoi ressemble l'interface :

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter5/datasets-tagger.png" alt="The `datasets-tagging` interface." width="80%"/>
</div>

2. Lisez le [guide de ü§ó *Datasets*](https://github.com/huggingface/datasets/blob/master/templates/README_guide.md) sur la cr√©ation des cartes informatives des jeux de donn√©es et utilisez-le comme mod√®le.

Vous pouvez cr√©er le fichier *README.md* directement sur le *Hub* et vous pouvez trouver un mod√®le de carte dans le d√©pot `lewtun/github-issues`. Une capture d'√©cran de la carte remplie est illustr√©e ci-dessous.


<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter5/dataset-card.png" alt="A dataset card." width="80%"/>
</div>

<Tip>

‚úèÔ∏è **Essayez !** Utilisez l'application `dataset-tagging` et [le guide de ü§ó *Datasets*](https://github.com/huggingface/datasets/blob/master/templates/README_guide.md) pour compl√©ter le fichier *README.md* de votre jeu de donn√©es de probl√®mes GitHub.
</Tip>

C‚Äôest tout ! Nous avons vu dans cette section que la cr√©ation d'un bon jeu de donn√©es peut √™tre assez complexe, mais heureusement, le t√©l√©charger et le partager avec la communaut√© ne l'est pas. Dans la section suivante, nous utiliserons notre nouveau jeu de donn√©es pour cr√©er un moteur de recherche s√©mantique avec ü§ó *Datasets* qui peut faire correspondre les questions aux probl√®mes et commentaires les plus pertinents.

<Tip>

‚úèÔ∏è **Essayez !** Suivez les √©tapes que nous avons suivies dans cette section pour cr√©er un jeu de donn√©es de probl√®mes GitHub pour votre biblioth√®que open source pr√©f√©r√©e (choisissez autre chose que ü§ó *Datasets*, bien s√ªr !). Pour obtenir des points bonus, *finetunez* un classifieur multilabel pour pr√©dire les balises pr√©sentes dans le champ `labels`.

</Tip>
