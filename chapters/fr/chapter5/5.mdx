# CrÃ©ation de votre propre jeu de donnÃ©es

<CourseFloatingBanner chapter={5}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "English", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter5/section5.ipynb"},
    {label: "FranÃ§ais", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/fr/chapter5/section5.ipynb"},
    {label: "English", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter5/section5.ipynb"},
    {label: "FranÃ§ais", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/fr/chapter5/section5.ipynb"},
]} />


Parfois, le jeu de donnÃ©es dont vous avez besoin pour crÃ©er une application de NLP n'existe pas. Vous devrez donc le crÃ©er vous-mÃªme. Dans cette section, nous allons vous montrer comment crÃ©er un corpus de [problÃ¨mes GitHub](https://github.com/features/issues/), qui sont couramment utilisÃ©s pour suivre les bogues ou les fonctionnalitÃ©s dans les dÃ©pÃ´ts GitHub. Ce corpus pourrait Ãªtre utilisÃ© Ã  diverses fins, notamment :

* explorer combien de temps il faut pour fermer les problÃ¨mes ouverts ou les *pull requests*
* entraÃ®ner d'un _classifieur multilabel_ capable d'Ã©tiqueter les problÃ¨mes avec des mÃ©tadonnÃ©es basÃ©es sur la description du problÃ¨me (par exemple : Â« bug Â», Â« amÃ©lioration Â» ou  Â« question Â»)
* crÃ©er un moteur de recherche sÃ©mantique pour trouver les problÃ¨mes correspondant Ã  la requÃªte d'un utilisateur

Ici, nous nous concentrerons sur la crÃ©ation du corpus, et dans la section suivante, nous aborderons l'application de recherche sÃ©mantique. Pour garder les choses mÃ©ta, nous utiliserons les problÃ¨mes GitHub associÃ©s Ã  un projet open source populaire : ğŸ¤— *Datasets* ! Voyons comment obtenir les donnÃ©es et explorons les informations contenues dans ces problÃ¨mes.

## Obtenir les donnÃ©es

Vous pouvez trouver tous les problÃ¨mes dans ğŸ¤— *Datasets* en accÃ©dant Ã  l'[onglet Â« Issues Â»](https://github.com/huggingface/datasets/issues) du dÃ©pÃ´t. Comme le montre la capture d'Ã©cran suivante, au moment de la rÃ©daction, il y avait 331 problÃ¨mes ouverts et 668 problÃ¨mes fermÃ©s.

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter5/datasets-issues.png" alt="The GitHub issues associated with ğŸ¤— Datasets." width="80%"/>
</div>

Si vous cliquez sur l'un de ces problÃ¨mes, vous constaterez qu'il contient un titre, une description et un ensemble d'Ã©tiquettes qui caractÃ©risent le problÃ¨me. Un exemple est montrÃ© dans la capture d'Ã©cran ci-dessous.

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter5/datasets-issues-single.png" alt="A typical GitHub issue in the ğŸ¤— Datasets repository." width="80%"/>
</div>

Pour tÃ©lÃ©charger tous les problÃ¨mes du dÃ©pÃ´t, nous utilisons l'[API REST GitHub](https://docs.github.com/en/rest) pour interroger le point de terminaison [`Issues`](https://docs.github.com/en/rest/reference/issues#list-repository-issues). Ce point de terminaison renvoie une liste d'objets JSON. Chaque objet contenant un grand nombre de champs qui incluent le titre et la description ainsi que des mÃ©tadonnÃ©es sur l'Ã©tat du problÃ¨me, etc.

Un moyen pratique de tÃ©lÃ©charger les problÃ¨mes consiste Ã  utiliser la bibliothÃ¨que `requests`, qui est la mÃ©thode standard pour effectuer des requÃªtes HTTP en Python. Vous pouvez installer la bibliothÃ¨que en exÃ©cutant :

```python
!pip install requests
```

Une fois la bibliothÃ¨que installÃ©e, vous pouvez envoyer des requÃªtes GET au point de terminaison `Issues` en appelant la fonction `requests.get()`. Par exemple, vous pouvez exÃ©cuter la commande suivante pour rÃ©cupÃ©rer le premier numÃ©ro sur la premiÃ¨re page :

```py
import requests

url = "https://api.github.com/repos/huggingface/datasets/issues?page=1&per_page=1"
response = requests.get(url)
```

L'objet `response` contient de nombreuses informations utiles sur la requÃªte, y compris le code d'Ã©tat HTTP :

```py
response.status_code
```

```python out
200
```

oÃ¹ un statut `200` signifie que la requÃªte a rÃ©ussi (vous pouvez trouver une liste des codes de statut HTTP possibles [ici](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)). Ce qui nous intÃ©resse vraiment, cependant, c'est le _payload_, qui peut Ãªtre consultÃ© dans diffÃ©rents formats comme les octets, les chaÃ®nes ou JSON. Comme nous savons que nos problÃ¨mes sont au format JSON, examinons la charge utile comme suit :

```py
response.json()
```

```python out
[{'url': 'https://api.github.com/repos/huggingface/datasets/issues/2792',
  'repository_url': 'https://api.github.com/repos/huggingface/datasets',
  'labels_url': 'https://api.github.com/repos/huggingface/datasets/issues/2792/labels{/name}',
  'comments_url': 'https://api.github.com/repos/huggingface/datasets/issues/2792/comments',
  'events_url': 'https://api.github.com/repos/huggingface/datasets/issues/2792/events',
  'html_url': 'https://github.com/huggingface/datasets/pull/2792',
  'id': 968650274,
  'node_id': 'MDExOlB1bGxSZXF1ZXN0NzEwNzUyMjc0',
  'number': 2792,
  'title': 'Update GooAQ',
  'user': {'login': 'bhavitvyamalik',
   'id': 19718818,
   'node_id': 'MDQ6VXNlcjE5NzE4ODE4',
   'avatar_url': 'https://avatars.githubusercontent.com/u/19718818?v=4',
   'gravatar_id': '',
   'url': 'https://api.github.com/users/bhavitvyamalik',
   'html_url': 'https://github.com/bhavitvyamalik',
   'followers_url': 'https://api.github.com/users/bhavitvyamalik/followers',
   'following_url': 'https://api.github.com/users/bhavitvyamalik/following{/other_user}',
   'gists_url': 'https://api.github.com/users/bhavitvyamalik/gists{/gist_id}',
   'starred_url': 'https://api.github.com/users/bhavitvyamalik/starred{/owner}{/repo}',
   'subscriptions_url': 'https://api.github.com/users/bhavitvyamalik/subscriptions',
   'organizations_url': 'https://api.github.com/users/bhavitvyamalik/orgs',
   'repos_url': 'https://api.github.com/users/bhavitvyamalik/repos',
   'events_url': 'https://api.github.com/users/bhavitvyamalik/events{/privacy}',
   'received_events_url': 'https://api.github.com/users/bhavitvyamalik/received_events',
   'type': 'User',
   'site_admin': False},
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2021-08-12T11:40:18Z',
  'updated_at': '2021-08-12T12:31:17Z',
  'closed_at': None,
  'author_association': 'CONTRIBUTOR',
  'active_lock_reason': None,
  'pull_request': {'url': 'https://api.github.com/repos/huggingface/datasets/pulls/2792',
   'html_url': 'https://github.com/huggingface/datasets/pull/2792',
   'diff_url': 'https://github.com/huggingface/datasets/pull/2792.diff',
   'patch_url': 'https://github.com/huggingface/datasets/pull/2792.patch'},
  'body': '[GooAQ](https://github.com/allenai/gooaq) dataset was recently updated after splits were added for the same. This PR contains new updated GooAQ with train/val/test splits and updated README as well.',
  'performed_via_github_app': None}]
```

Waouh, Ã§a fait beaucoup d'informations ! Nous pouvons voir des champs utiles comme `title`, `body` et `number` qui dÃ©crivent le problÃ¨me, ainsi que des informations sur l'utilisateur GitHub qui a ouvert le problÃ¨me.

> [!TIP]
> âœï¸ **Essayez !** Cliquez sur quelques-unes des URL pour avoir une idÃ©e du type d'informations auxquelles chaque problÃ¨me GitHub est liÃ©.

Comme dÃ©crit dans la [documentation GitHub](https://docs.github.com/en/rest/overview/resources-in-the-rest-api#rate-limiting), les requÃªtes non authentifiÃ©es sont limitÃ©es Ã  60 requÃªtes par heure. Bien que vous puissiez augmenter le paramÃ¨tre de requÃªte `per_page` pour rÃ©duire le nombre de requÃªtes que vous effectuez, vous atteindrez toujours la limite de dÃ©bit sur tout dÃ©pÃ´t contenant des milliers de problÃ¨mes. Donc, Ã  la place, vous devez suivre les [instructions de GitHub](https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token) sur la crÃ©ation d'un _jeton d'accÃ¨s personnel_ afin que vous peut augmenter la limite de dÃ©bit Ã  5 000 requÃªtes par heure. Une fois que vous avez votre *token*, vous pouvez l'inclure dans l'en-tÃªte de la requÃªte :

```py
GITHUB_TOKEN = xxx  # Copiez votre jeton GitHub ici
headers = {"Authorization": f"token {GITHUB_TOKEN}"}
```

> [!WARNING]
> âš ï¸ Ne partagez pas un *notebook* avec votre `GITHUB_TOKEN` collÃ© dedans. Nous vous recommandons de supprimer la derniÃ¨re cellule une fois que vous l'avez exÃ©cutÃ©e pour Ã©viter de divulguer accidentellement ces informations. Mieux encore, stockez le jeton dans un fichier *.env* et utilisez la [bibliothÃ¨que `python-dotenv`](https://github.com/theskumar/python-dotenv) pour le charger automatiquement pour vous en tant que variable d'environnement.

Maintenant que nous avons notre jeton d'accÃ¨s, crÃ©ons une fonction qui peut tÃ©lÃ©charger tous les problÃ¨mes depuis un rÃ©fÃ©rentiel GitHub :

```py
import time
import math
from pathlib import Path
import pandas as pd
from tqdm.notebook import tqdm


def fetch_issues(
    owner="huggingface",
    repo="datasets",
    num_issues=10_000,
    rate_limit=5_000,
    issues_path=Path("."),
):
    if not issues_path.is_dir():
        issues_path.mkdir(exist_ok=True)

    batch = []
    all_issues = []
    per_page = 100  # Nombre d'issues Ã  retourner par page
    num_pages = math.ceil(num_issues / per_page)
    base_url = "https://api.github.com/repos"

    for page in tqdm(range(num_pages)):
        # RequÃªte avec state=all pour obtenir les issues ouvertes et fermÃ©es
        query = f"issues?page={page}&per_page={per_page}&state=all"
        issues = requests.get(f"{base_url}/{owner}/{repo}/{query}", headers=headers)
        batch.extend(issues.json())

        if len(batch) > rate_limit and len(all_issues) < num_issues:
            all_issues.extend(batch)
            batch = []  # Vider le batch pour la pÃ©riode de temps suivante
            print(f"Reached GitHub rate limit. Sleeping for one hour ...")
            time.sleep(60 * 60 + 1)

    all_issues.extend(batch)
    df = pd.DataFrame.from_records(all_issues)
    df.to_json(f"{issues_path}/{repo}-issues.jsonl", orient="records", lines=True)
    print(
        f"Downloaded all the issues for {repo}! Dataset stored at {issues_path}/{repo}-issues.jsonl"
    )
```

DÃ©sormais, lorsque nous appellerons `fetch_issues()`, tous les problÃ¨mes seront tÃ©lÃ©chargÃ©s par batchs pour Ã©viter de dÃ©passer la limite de GitHub sur le nombre de requÃªtes par heure. Le rÃ©sultat sera stockÃ© dans un fichier _repository_name-issues.jsonl_, oÃ¹ chaque ligne est un objet JSON qui reprÃ©sente un problÃ¨me. Utilisons cette fonction pour saisir tous les problÃ¨mes de ğŸ¤— *Datasets* :

```py
# En fonction de votre connexion Internet, l'exÃ©cution peut prendre plusieurs minutes...
fetch_issues()
```

Une fois les problÃ¨mes tÃ©lÃ©chargÃ©s, nous pouvons les charger localement en utilisant nos nouvelles compÃ©tences de [section 2](/course/fr/chapter5/2) :

```py
issues_dataset = load_dataset("json", data_files="datasets-issues.jsonl", split="train")
issues_dataset
```

```python out
Dataset({
    features: ['url', 'repository_url', 'labels_url', 'comments_url', 'events_url', 'html_url', 'id', 'node_id', 'number', 'title', 'user', 'labels', 'state', 'locked', 'assignee', 'assignees', 'milestone', 'comments', 'created_at', 'updated_at', 'closed_at', 'author_association', 'active_lock_reason', 'pull_request', 'body', 'timeline_url', 'performed_via_github_app'],
    num_rows: 3019
})
```

GÃ©nial, nous avons crÃ©Ã© notre premier jeu de donnÃ©es Ã  partir de rien ! Mais pourquoi y a-t-il plusieurs milliers de problÃ¨mes alors que l'[onglet Â« Issues Â»](https://github.com/huggingface/datasets/issues) de la librairie ğŸ¤— *Datasets* n'affiche qu'environ 1 000 problÃ¨mes au total ğŸ¤” ? Comme dÃ©crit dans la [documentation GitHub](https://docs.github.com/en/rest/reference/issues#list-issues-assigned-to-the-authenticated-user), c'est parce que nous avons tÃ©lÃ©chargÃ© toutes les *pull requests* Ã©galement :

> L'API REST v3 de GitHub considÃ¨re chaque *pull request* comme un problÃ¨me, mais chaque problÃ¨me n'est pas une *pull request*. Pour cette raison, les points de terminaison Â« Issues Â» peuvent renvoyer Ã  la fois des problÃ¨mes et des *pull requests* dans la rÃ©ponse. Vous pouvez identifier les *pull requests* par la clÃ© `pull_request`. Sachez que l'identifiant d'une *pull request* renvoyÃ©e par les points de terminaison Â« Issues Â» sera un identifiant de problÃ¨me.

Ã‰tant donnÃ© que le contenu des Â« Issues Â» et des *pull request* est assez diffÃ©rent, procÃ©dons Ã  un prÃ©traitement mineur pour nous permettre de les distinguer.

## Nettoyer les donnÃ©es

L'extrait ci-dessus de la documentation de GitHub nous indique que la colonne `pull_request` peut Ãªtre utilisÃ©e pour diffÃ©rencier les *issues* et les *pull requests*. Regardons un Ã©chantillon alÃ©atoire pour voir quelle est la diffÃ©rence. Comme nous l'avons fait dans [section 3](/course/fr/chapter5/3), nous allons enchaÃ®ner `Dataset.shuffle()` et `Dataset.select()` pour crÃ©er un Ã©chantillon alÃ©atoire, puis compresser `html_url` et ` pull_request` afin que nous puissions comparer les diffÃ©rentes URL :

```py
sample = issues_dataset.shuffle(seed=666).select(range(3))

# Afficher l'URL et les entrÃ©es de la PR
for url, pr in zip(sample["html_url"], sample["pull_request"]):
    print(f">> URL: {url}")
    print(f">> Pull request: {pr}\n")
```

```python out
>> URL: https://github.com/huggingface/datasets/pull/850
>> Pull request: {'url': 'https://api.github.com/repos/huggingface/datasets/pulls/850', 'html_url': 'https://github.com/huggingface/datasets/pull/850', 'diff_url': 'https://github.com/huggingface/datasets/pull/850.diff', 'patch_url': 'https://github.com/huggingface/datasets/pull/850.patch'}

>> URL: https://github.com/huggingface/datasets/issues/2773
>> Pull request: None

>> URL: https://github.com/huggingface/datasets/pull/783
>> Pull request: {'url': 'https://api.github.com/repos/huggingface/datasets/pulls/783', 'html_url': 'https://github.com/huggingface/datasets/pull/783', 'diff_url': 'https://github.com/huggingface/datasets/pull/783.diff', 'patch_url': 'https://github.com/huggingface/datasets/pull/783.patch'}
```

Ici, nous pouvons voir que chaque *pull request* est associÃ©e Ã  diverses URL, tandis que les problÃ¨mes ordinaires ont une entrÃ©e `None`. Nous pouvons utiliser cette distinction pour crÃ©er une nouvelle colonne `is_pull_request` qui vÃ©rifie si le champ `pull_request` est `None` ou non :

```py
issues_dataset = issues_dataset.map(
    lambda x: {"is_pull_request": False if x["pull_request"] is None else True}
)
```

> [!TIP]
> âœï¸ **Essayez !** Calculez le temps moyen nÃ©cessaire pour rÃ©soudre les problÃ¨mes dans ğŸ¤— *Datasets*. Vous pouvez trouver la fonction `Dataset.filter()` utile pour filtrer les demandes d'extraction et les problÃ¨mes ouverts. Vous pouvez utiliser la fonction `Dataset.set_format()` pour convertir le jeu de donnÃ©es en un `DataFrame` afin que vous puissiez facilement manipuler les horodatages `created_at` et `closed_at`. Pour les points bonus, calculez le temps moyen nÃ©cessaire pour fermer les *pull_requests*.

Bien que nous puissions continuer Ã  nettoyer davantage le jeu de donnÃ©es en supprimant ou en renommant certaines colonnes, il est gÃ©nÃ©ralement recommandÃ© de le conserver aussi brut que possible Ã  ce stade afin qu'il puisse Ãªtre facilement utilisÃ© dans plusieurs applications.

Avant de pousser notre jeu de donnÃ©es vers le *Hub* dâ€™Hugging Face, traitons une chose manquante : les commentaires associÃ©s Ã  chaque problÃ¨me et *pull requests*. Nous les ajouterons ensuite avec l'API GitHub REST !

## Enrichir le jeu de donnÃ©es

Comme le montre la capture d'Ã©cran suivante, les commentaires associÃ©s Ã  un problÃ¨me ou Ã  une *pull request* fournissent une riche source d'informations, en particulier si nous souhaitons crÃ©er un moteur de recherche pour rÃ©pondre aux requÃªtes des utilisateurs sur la bibliothÃ¨que.

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter5/datasets-issues-comment.png" alt="Comments associated with an issue about ğŸ¤— Datasets." width="80%"/>
</div>

L'API REST GitHub fournit un point de terminaison [`Comments`](https://docs.github.com/en/rest/reference/issues#list-issue-comments) qui renvoie tous les commentaires associÃ©s Ã  un numÃ©ro de problÃ¨me. Testons le point de terminaison pour voir ce qu'il renvoie :

```py
issue_number = 2792
url = f"https://api.github.com/repos/huggingface/datasets/issues/{issue_number}/comments"
response = requests.get(url, headers=headers)
response.json()
```

```python out
[{'url': 'https://api.github.com/repos/huggingface/datasets/issues/comments/897594128',
  'html_url': 'https://github.com/huggingface/datasets/pull/2792#issuecomment-897594128',
  'issue_url': 'https://api.github.com/repos/huggingface/datasets/issues/2792',
  'id': 897594128,
  'node_id': 'IC_kwDODunzps41gDMQ',
  'user': {'login': 'bhavitvyamalik',
   'id': 19718818,
   'node_id': 'MDQ6VXNlcjE5NzE4ODE4',
   'avatar_url': 'https://avatars.githubusercontent.com/u/19718818?v=4',
   'gravatar_id': '',
   'url': 'https://api.github.com/users/bhavitvyamalik',
   'html_url': 'https://github.com/bhavitvyamalik',
   'followers_url': 'https://api.github.com/users/bhavitvyamalik/followers',
   'following_url': 'https://api.github.com/users/bhavitvyamalik/following{/other_user}',
   'gists_url': 'https://api.github.com/users/bhavitvyamalik/gists{/gist_id}',
   'starred_url': 'https://api.github.com/users/bhavitvyamalik/starred{/owner}{/repo}',
   'subscriptions_url': 'https://api.github.com/users/bhavitvyamalik/subscriptions',
   'organizations_url': 'https://api.github.com/users/bhavitvyamalik/orgs',
   'repos_url': 'https://api.github.com/users/bhavitvyamalik/repos',
   'events_url': 'https://api.github.com/users/bhavitvyamalik/events{/privacy}',
   'received_events_url': 'https://api.github.com/users/bhavitvyamalik/received_events',
   'type': 'User',
   'site_admin': False},
  'created_at': '2021-08-12T12:21:52Z',
  'updated_at': '2021-08-12T12:31:17Z',
  'author_association': 'CONTRIBUTOR',
  'body': "@albertvillanova my tests are failing here:\r\n```\r\ndataset_name = 'gooaq'\r\n\r\n    def test_load_dataset(self, dataset_name):\r\n        configs = self.dataset_tester.load_all_configs(dataset_name, is_local=True)[:1]\r\n>       self.dataset_tester.check_load_dataset(dataset_name, configs, is_local=True, use_local_dummy_data=True)\r\n\r\ntests/test_dataset_common.py:234: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\ntests/test_dataset_common.py:187: in check_load_dataset\r\n    self.parent.assertTrue(len(dataset[split]) > 0)\r\nE   AssertionError: False is not true\r\n```\r\nWhen I try loading dataset on local machine it works fine. Any suggestions on how can I avoid this error?",
  'performed_via_github_app': None}]
```

Nous pouvons voir que le commentaire est stockÃ© dans le champ `body`. Ecrivons donc une fonction simple qui renvoie tous les commentaires associÃ©s Ã  un problÃ¨me en sÃ©lectionnant le contenu `body` pour chaque Ã©lÃ©ment dans `response.json()` :

```py
def get_comments(issue_number):
    url = f"https://api.github.com/repos/huggingface/datasets/issues/{issue_number}/comments"
    response = requests.get(url, headers=headers)
    return [r["body"] for r in response.json()]


# Tester notre fonction fonctionne comme prÃ©vu
get_comments(2792)
```

```python out
["@albertvillanova my tests are failing here:\r\n```\r\ndataset_name = 'gooaq'\r\n\r\n    def test_load_dataset(self, dataset_name):\r\n        configs = self.dataset_tester.load_all_configs(dataset_name, is_local=True)[:1]\r\n>       self.dataset_tester.check_load_dataset(dataset_name, configs, is_local=True, use_local_dummy_data=True)\r\n\r\ntests/test_dataset_common.py:234: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\ntests/test_dataset_common.py:187: in check_load_dataset\r\n    self.parent.assertTrue(len(dataset[split]) > 0)\r\nE   AssertionError: False is not true\r\n```\r\nWhen I try loading dataset on local machine it works fine. Any suggestions on how can I avoid this error?"]
```

Cela a l'air bien. Utilisons `Dataset.map()` pour ajouter une nouvelle colonne `comments` Ã  chaque problÃ¨me de notre jeu de donnÃ©es :

```py
# Selon votre connexion internet, cela peut prendre quelques minutes...
issues_with_comments_dataset = issues_dataset.map(
    lambda x: {"comments": get_comments(x["number"])}
)
```

La derniÃ¨re Ã©tape consiste Ã  enregistrer le jeu de donnÃ©es augmentÃ©es avec nos donnÃ©es brutes afin que nous puissions les pousser tous les deux vers le *Hub* :

```py
issues_with_comments_dataset.to_json("issues-datasets-with-comments.jsonl")
```

## TÃ©lÃ©chargement du jeu de donnÃ©es sur le <i>Hub</i>

<Youtube id="HaN6qCr_Afc"/>

Maintenant que nous avons notre jeu de donnÃ©es augmentÃ©, il est temps de le pousser vers le *Hub* afin que nous puissions le partager avec la communautÃ© ! Pour tÃ©lÃ©charger le jeu de donnÃ©es, nous utilisons la [bibliothÃ¨que ğŸ¤— *Hub*](https://github.com/huggingface/huggingface_hub), qui nous permet d'interagir avec le *Hub* dâ€™Hugging Face via une API Python. ğŸ¤— *Hub* est prÃ©installÃ© avec ğŸ¤— *Transformers*, nous pouvons donc l'utiliser directement. Par exemple, nous pouvons utiliser la fonction `list_datasets()` pour obtenir des informations sur tous les ensembles de donnÃ©es publics actuellement hÃ©bergÃ©s sur le *Hub*:

```py
from huggingface_hub import list_datasets

all_datasets = list_datasets()
print(f"Number of datasets on Hub: {len(all_datasets)}")
print(all_datasets[0])
```

```python out
Number of datasets on Hub: 1487
Dataset Name: acronym_identification, Tags: ['annotations_creators:expert-generated', 'language_creators:found', 'languages:en', 'licenses:mit', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:structure-prediction', 'task_ids:structure-prediction-other-acronym-identification']
```

Nous pouvons voir qu'il y a actuellement prÃ¨s de 1 500 jeux de donnÃ©es sur le *Hub* et la fonction `list_datasets()` fournit Ã©galement des mÃ©tadonnÃ©es de base sur chaque dÃ©pÃ´ts de jeux de donnÃ©es.

Pour nos besoins, la premiÃ¨re chose que nous devons faire est de crÃ©er un nouveau dÃ©pÃ´t de jeux de donnÃ©es sur le *Hub*. Pour ce faire, nous avons besoin d'un jeton d'authentification, qui peut Ãªtre obtenu en se connectant d'abord au *Hub* dâ€™Hugging Face avec la fonction `notebook_login()` :

```py
from huggingface_hub import notebook_login

notebook_login()
```

Cela crÃ©Ã© un *widget* dans lequel vous pouvez entrer votre nom d'utilisateur et votre mot de passe. Un jeton API sera enregistrÃ© dans *~/.huggingface/token*. Si vous exÃ©cutez le code dans un terminal, vous pouvez vous connecter via la CLI Ã  la place :

```bash
huggingface-cli login
```

Une fois que nous avons fait cela, nous pouvons crÃ©er un nouveau dÃ©pÃ´t de jeux de donnÃ©es avec la fonction `create_repo()` :

```py
from huggingface_hub import create_repo

repo_url = create_repo(name="github-issues", repo_type="dataset")
repo_url
```

```python out
'https://huggingface.co/datasets/lewtun/github-issues'
```

Dans cet exemple, nous avons crÃ©Ã© un dÃ©pÃ´t vide appelÃ© `github-issues` sous le nom d'utilisateur `lewtun` (le nom d'utilisateur doit Ãªtre votre nom d'utilisateur Hub lorsque vous exÃ©cutez ce code !).

> [!TIP]
> âœï¸ **Essayez !** Utilisez votre nom d'utilisateur et votre mot de passe Hugging Face pour obtenir un jeton et crÃ©er un dÃ©pÃ´t vide appelÃ© `github-issues`. N'oubliez pas de **n'enregistrez jamais vos informations d'identification** dans Colab ou tout autre rÃ©fÃ©rentiel car ces informations peuvent Ãªtre exploitÃ©es par de mauvais individus.

Ensuite, clonons le dÃ©pÃ´t du Hub sur notre machine locale et copions-y notre fichier jeu de donnÃ©es. ğŸ¤— *Hub* fournit une classe `Repository` pratique qui encapsule de nombreuses commandes Git courantes. Donc pour cloner le dÃ©pÃ´t distant, nous devons simplement fournir l'URL et le chemin local vers lesquels nous souhaitons cloner :

```py
from huggingface_hub import Repository

repo = Repository(local_dir="github-issues", clone_from=repo_url)
!cp datasets-issues-with-comments.jsonl github-issues/
```

Par dÃ©faut, diverses extensions de fichiers (telles que *.bin*, *.gz* et *.zip*) sont suivies avec Git LFS afin que les fichiers volumineux puissent Ãªtre versionnÃ©s dans le mÃªme workflow Git. Vous pouvez trouver une liste des extensions de fichiers suivis dans le fichier *.gitattributes* du rÃ©fÃ©rentiel. Pour inclure le format JSON Lines dans la liste, nous pouvons exÃ©cuter la commande suivante :

```py
repo.lfs_track("*.jsonl")
```

Ensuite, nous pouvons utiliser `Repository.push_to_hub()` pour pousser le jeu de donnÃ©es vers le *Hub* :

```py
repo.push_to_hub()
```

Si nous naviguons vers l'URL contenue dans `repo_url`, nous devrions maintenant voir que notre fichier de jeu de donnÃ©es a Ã©tÃ© tÃ©lÃ©chargÃ©.

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter5/hub-repo.png" alt="Our dataset repository on the Hugging Face Hub." width="80%"/>
</div>

Ã€ partir de lÃ , n'importe qui peut tÃ©lÃ©charger le jeu de donnÃ©es en fournissant simplement `load_dataset()` avec l'ID du rÃ©fÃ©rentiel comme argument `path` :

```py
remote_dataset = load_dataset("lewtun/github-issues", split="train")
remote_dataset
```

```python out
Dataset({
    features: ['url', 'repository_url', 'labels_url', 'comments_url', 'events_url', 'html_url', 'id', 'node_id', 'number', 'title', 'user', 'labels', 'state', 'locked', 'assignee', 'assignees', 'milestone', 'comments', 'created_at', 'updated_at', 'closed_at', 'author_association', 'active_lock_reason', 'pull_request', 'body', 'performed_via_github_app', 'is_pull_request'],
    num_rows: 2855
})
```

Cool, nous avons poussÃ© notre jeu de donnÃ©es vers le *Hub* et il est disponible pour que d'autres puissent l'utiliser ! Il ne reste plus qu'une chose importante Ã  faire : ajouter une _carte de jeu de donnÃ©es_ qui explique comment le corpus a Ã©tÃ© crÃ©Ã© et fournit d'autres informations utiles Ã  la communautÃ©.

> [!TIP]
> ğŸ’¡ Vous pouvez Ã©galement tÃ©lÃ©charger un jeu de donnÃ©es sur le *Hub* directement depuis le terminal en utilisant `huggingface-cli` et un peu de magie Git. Consultez le [guide de ğŸ¤— *Datasets*](https://huggingface.co/docs/datasets/share#share-a-dataset-using-the-cli) pour savoir comment procÃ©der.

## CrÃ©ation d'une carte pour un jeu de donnÃ©es

Des jeux de donnÃ©es bien documentÃ©s sont plus susceptibles d'Ãªtre utiles aux autres (y compris Ã  vous-mÃªme) car ils fournissent le contexte permettant aux utilisateurs de dÃ©cider si le jeu de donnÃ©es est pertinent pour leur tÃ¢che et d'Ã©valuer les biais potentiels ou les risques associÃ©s Ã  l'utilisation du jeu de donnÃ©es.

Sur le *Hub*, ces informations sont stockÃ©es dans le fichier *README.md* de chaque dÃ©pÃ´t de jeux de donnÃ©es. Il y a deux Ã©tapes principales que vous devez suivre avant de crÃ©er ce fichier :

1. Utilisez l'[application `datasets-tagging`](https://huggingface.co/datasets/tagging/) pour crÃ©er des balises de mÃ©tadonnÃ©es au format YAML. Ces balises sont utilisÃ©es pour une variÃ©tÃ© de fonctionnalitÃ©s de recherche sur le *Hub* dâ€™Hugging Face et garantissent que votre jeu de donnÃ©es peut Ãªtre facilement trouvÃ© par les membres de la communautÃ©. Puisque nous avons crÃ©Ã© un jeu de donnÃ©es personnalisÃ© ici, vous devrez cloner le rÃ©fÃ©rentiel `datasets-tagging` et exÃ©cuter l'application localement. Voici Ã  quoi ressemble l'interface :

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter5/datasets-tagger.png" alt="The `datasets-tagging` interface." width="80%"/>
</div>

2. Lisez le [guide de ğŸ¤— *Datasets*](https://github.com/huggingface/datasets/blob/master/templates/README_guide.md) sur la crÃ©ation des cartes informatives des jeux de donnÃ©es et utilisez-le comme modÃ¨le.

Vous pouvez crÃ©er le fichier *README.md* directement sur le *Hub* et vous pouvez trouver un modÃ¨le de carte dans le dÃ©pot `lewtun/github-issues`. Une capture d'Ã©cran de la carte remplie est illustrÃ©e ci-dessous.


<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter5/dataset-card.png" alt="A dataset card." width="80%"/>
</div>

> [!TIP]
> âœï¸ **Essayez !** Utilisez l'application `dataset-tagging` et [le guide de ğŸ¤— *Datasets*](https://github.com/huggingface/datasets/blob/master/templates/README_guide.md) pour complÃ©ter le fichier *README.md* de votre jeu de donnÃ©es de problÃ¨mes GitHub.

Câ€™est tout ! Nous avons vu dans cette section que la crÃ©ation d'un bon jeu de donnÃ©es peut Ãªtre assez complexe, mais heureusement, le tÃ©lÃ©charger et le partager avec la communautÃ© ne l'est pas. Dans la section suivante, nous utiliserons notre nouveau jeu de donnÃ©es pour crÃ©er un moteur de recherche sÃ©mantique avec ğŸ¤— *Datasets* qui peut faire correspondre les questions aux problÃ¨mes et commentaires les plus pertinents.

> [!TIP]
> âœï¸ **Essayez !** Suivez les Ã©tapes que nous avons suivies dans cette section pour crÃ©er un jeu de donnÃ©es de problÃ¨mes GitHub pour votre bibliothÃ¨que open source prÃ©fÃ©rÃ©e (choisissez autre chose que ğŸ¤— *Datasets*, bien sÃ»r !). Pour obtenir des points bonus, *finetunez* un classifieur multilabel pour prÃ©dire les balises prÃ©sentes dans le champ `labels`.
