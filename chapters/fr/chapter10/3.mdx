# Chargez votre jeu de données dans Argilla[[load-your-dataset-to-argilla]]

<CourseFloatingBanner chapter={10}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "English", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter10/section3.ipynb"},
	{label: "Français", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter10/section3.ipynb"},
    {label: "English", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/fr/chapter10/section3.ipynb"},
    {label: "Français", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/fr/chapter10/section3.ipynb"},
]} />

En fonction de la tâche NLP sur laquelle vous travaillez et du cas d'utilisation/votre application spécifique, vos données et la tâche d'annotation se présenteront différemment. Pour cette partie du cours, nous utiliserons [un jeu de données collectant des actualités](https://huggingface.co/datasets/SetFit/ag_news) pour réaliser deux tâches : de la classification indiquant le thème de chaque texte et de la reconnaissannce d'entités nommées pour identifier les entités mentionnées.

<iframe
  src="https://huggingface.co/datasets/SetFit/ag_news/embed/viewer/default/train"
  frameborder="0"
  width="100%"
  height="560px"
></iframe>

Il est possible d'importer des jeux de données depuis le Hub en utilisant directement l'interface utilisateur Argilla, mais nous utiliserons le SDK pour apprendre à modifier les données si nécessaire.

## Configurez votre jeu de données

La première étape consiste à se connecter à notre instance Argilla comme nous l'avons fait dans la section précédente :

```python
import argilla as rg

HF_TOKEN = "..."  # uniquement pour les spaces privés

client = rg.Argilla(
    api_url="...",
    api_key="...",
    headers={"Authorization": f"Bearer {HF_TOKEN}"},  # uniquement pour les spaces privés
)
```

Nous pouvons maintenant réfléchir aux paramètres de notre jeu de données dans Argilla. Ceux-ci représentent la tâche d'annotation que nous allons effectuer sur nos données. Tout d'abord, nous pouvons charger le jeu de données depuis le Hub et inspecter ses caractéristiques, afin de nous assurer que nous le configurons correctement.

```python
from datasets import load_dataset

data = load_dataset("SetFit/ag_news", split="train")
data.features
```

Voici les caractéristiques de notre jeu de données :

```python out
{'text': Value(dtype='string', id=None),
 'label': Value(dtype='int64', id=None),
 'label_text': Value(dtype='string', id=None)}
```

Il contient un `text` ainsi que des labels pour la tâche de classification. Nous les ajouterons à nos paramètres de jeu de données avec une question `spans` pour les entités nommées :

```python
settings = rg.Settings(
    fields=[rg.TextField(name="text")],
    questions=[
        rg.LabelQuestion(
            name="label", title="Classifier le texte :", labels=data.unique("label_text")
        ),
        rg.SpanQuestion(
            name="entities",
            title="Surligner toutes les entités présentes dans le texte :",
            labels=["PERSON", "ORG", "LOC", "EVENT"],
            field="text",
        ),
    ],
)
```

Voyons un peu plus en détail ce que signifient ces paramètres. Tout d'abord, nous avons défini les **champs**, qui contiennent les informations que nous allons annoter. Dans ce cas, nous n'avons qu'un seul champ et il se présente sous la forme d'un texte, nous avons donc choisi un `TextField`.

Ensuite, nous définissons des **questions** qui représentent les tâches que nous voulons effectuer sur nos données :

- Pour la tâche de classification de texte, nous avons choisi une `LabelQuestion` et nous avons utilisé les valeurs uniques de la colonne `label_text` comme nos labels, pour s'assurer que la question est compatible avec ceux qui existent déjà dans le jeu de données.
- Pour la tâche de classification de *tokens*, nous aurons besoin d'une `SpanQuestion`. Nous avons défini un ensemble de labels que nous utiliserons pour cette tâche, ainsi que le champ sur lequel nous surlignerons les entités.

Pour en savoir plus sur tous les types de champs et de questions disponibles et sur d'autres paramètres avancés, tels que les métadonnées et les vecteurs, consultez la [documentation](https://docs.argilla.io/latest/how_to_guides/dataset/#define-dataset-settings).

## Charger le jeu de données

Maintenant que nous avons défini quelques paramètres, nous pouvons créer le jeu de données :

```python
dataset = rg.Dataset(name="ag_news", settings=settings)

dataset.create()
```

Le jeu de données apparaît maintenant dans notre instance Argilla, mais vous verrez qu'il est vide :

<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter10/empty_dataset.png" alt="Screenshot of the empty dataset."/>

Nous devons maintenant ajouter les enregistrements que nous allons annoter, c'est-à-dire les lignes de notre jeu de données. Pour ce faire, nous devons simplement saisir les données en tant qu'enregistrements et fournir une correspondance pour les éléments qui n'ont pas le même nom dans les jeux de données du Hub et d'Argilla :

```python
dataset.records.log(data, mapping={"label_text": "label"})
```

Dans notre correspondance, nous avons spécifié que la colonne `label_text` dans le jeu de données devrait être associée à la question avec le nom `label`. De cette façon, nous utiliserons les étiquettes existantes dans le jeu de données comme pré-annotations afin de pouvoir annoter plus rapidement.

Pendant que les enregistrements continuent à être consignés, vous pouvez déjà commencer à travailler avec votre jeu de données dans l'interface utilisateur d'Argilla. A ce stade, cela devrait ressembler à ceci :

<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter10/argilla_initial_dataset.png" alt="Screenshot of the dataset in Argilla."/>

Notre jeu de données est maintenant prêt à être annoté !