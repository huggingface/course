<FrameworkSwitchCourse {fw} />

# D√©bogage du pipeline d'entra√Ænement

<DocNotebookDropdown
  classNames="absolute z-10 right-0 top-0"
  options={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter8/section4_pt.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter8/section4_pt.ipynb"},
]} />

Vous avez √©crit un magnifique script pour entra√Æner ou *finetuner* un mod√®le sur une t√¢che donn√©e en suivant consciencieusement les conseils du [chapitre 7](/course/fr/chapter7). Mais lorsque vous lancez la commande `model.fit()`, quelque chose d'horrible se produit : vous obtenez une erreur üò± ! Ou pire, tout semble aller bien et l'entra√Ænement se d√©roule sans erreur mais le mod√®le r√©sultant est mauvais. Dans cette section, nous allons vous montrer ce que vous pouvez faire pour d√©boguer ce genre de probl√®mes.

## D√©boguer le pipeline d'entra√Ænement

<Youtube id="L-WSwUWde1U"/>

Le probl√®me lorsque vous rencontrez une erreur dans `trainer.train()` est qu'elle peut provenir de plusieurs sources, car la fonction `Trainer` assemble g√©n√©ralement des batchs de choses. Elle convertit les jeux de donn√©es en chargeurs de donn√©es donc le probl√®me pourrait √™tre quelque chose d'erron√© dans votre jeu de donn√©es, ou un probl√®me en essayant de regrouper les √©l√©ments des jeux de donn√©es ensemble. Ensuite, elle prend un batch de donn√©es et le transmet au mod√®le, le probl√®me peut donc se situer dans le code du mod√®le. Apr√®s cela, elle calcule les gradients et effectue l'√©tape d'optimisation, le probl√®me peut donc √©galement se situer dans votre optimiseur. Et m√™me si tout se passe bien pendant l'entra√Ænement, quelque chose peut encore mal tourner pendant l'√©valuation si votre m√©trique pose probl√®me.

La meilleure fa√ßon de d√©boguer une erreur qui survient dans `trainer.train()` est de passer manuellement en revue tout le pipeline pour voir o√π les choses se sont mal pass√©es. L'erreur est alors souvent tr√®s facile √† r√©soudre.

Pour le d√©montrer, nous utiliserons le script suivant qui tente de *finetuner* un mod√®le DistilBERT sur le [jeu de donn√©es MNLI](https://huggingface.co/datasets/glue) :

```py
from datasets import load_dataset
import evaluate
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
    return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)

args = TrainingArguments(
    f"distilbert-finetuned-mnli",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
)

metric = evaluate.load("glue", "mnli")


def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    return metric.compute(predictions=predictions, references=labels)


trainer = Trainer(
    model,
    args,
    train_dataset=raw_datasets["train"],
    eval_dataset=raw_datasets["validation_matched"],
    compute_metrics=compute_metrics,
)
trainer.train()
```

Si vous essayez de l'ex√©cuter, vous serez confront√© √† une erreur plut√¥t cryptique :

```python out
'ValueError: You have to specify either input_ids or inputs_embeds'
```

### V√©rifiez vos donn√©es

Cela va sans dire, mais si vos donn√©es sont corrompues, le `Trainer` ne sera pas capable de former des batchs et encore moins d'entra√Æner votre mod√®le. Donc, tout d'abord, vous devez jeter un coup d'oeil √† ce qui se trouve dans votre jeu d'entra√Ænement.

Pour √©viter d'innombrables heures pass√©es √† essayer de corriger quelque chose qui n'est pas la source du bug, nous vous recommandons d'utiliser `trainer.train_dataset` pour vos v√©rifications et rien d'autre. Faisons donc cela ici :

```py
trainer.train_dataset[0]
```

```python out
{'hypothesis': 'Product and geography are what make cream skimming work. ',
 'idx': 0,
 'label': 1,
 'premise': 'Conceptually cream skimming has two basic dimensions - product and geography.'}
```

Vous remarquez quelque chose d'anormal ? Ceci, en conjonction avec le message d'erreur sur les `input_ids` manquants, devrait vous faire r√©aliser que ce sont des textes et non des nombres que le mod√®le peut comprendre. Ici, l'erreur originale est tr√®s trompeuse parce que le `Trainer` enl√®ve automatiquement les colonnes qui ne correspondent pas √† la signature du mod√®le (c'est-√†-dire, les arguments attendus par le mod√®le). Cela signifie qu'ici, tout, sauf les √©tiquettes, a √©t√© √©limin√©. Il n'y avait donc aucun probl√®me √† cr√©er des batchs et √† les envoyer ensuite au mod√®le, qui s'est plaint √† son tour de ne pas avoir re√ßu les bons arguments.

Pourquoi les donn√©es n'ont-elles pas √©t√© trait√©es ? Nous avons utilis√© la m√©thode `Dataset.map()` sur les jeux de donn√©es pour appliquer le *tokenizer* sur chaque √©chantillon. Mais si vous regardez attentivement le code, vous verrez que nous avons fait une erreur en passant les ensembles d'entra√Ænement et d'√©valuation au `Trainer`. Au lieu d'utiliser `tokenized_datasets` ici, nous avons utilis√© `raw_datasets` ü§¶. Alors corrigeons √ßa !

```py
from datasets import load_dataset
import evaluate
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
    return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)

args = TrainingArguments(
    f"distilbert-finetuned-mnli",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
)

metric = evaluate.load("glue", "mnli")


def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    return metric.compute(predictions=predictions, references=labels)


trainer = Trainer(
    model,
    args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation_matched"],
    compute_metrics=compute_metrics,
)
trainer.train()
```

Ce nouveau code donnera maintenant une erreur diff√©rente (c'est un progr√®s !) :

```python out
'ValueError: expected sequence of length 43 at dim 1 (got 37)'
```

En regardant le *traceback*, nous pouvons voir que l'erreur se produit dans l'√©tape de collationnement des donn√©es :

```python out
~/git/transformers/src/transformers/data/data_collator.py in torch_default_data_collator(features)
    105                 batch[k] = torch.stack([f[k] for f in features])
    106             else:
--> 107                 batch[k] = torch.tensor([f[k] for f in features])
    108 
    109     return batch
```

Donc, nous devrions passer √† cela. Mais avant finissons d'inspecter nos donn√©es, pour √™tre s√ªrs √† 100% qu'elles sont correctes.

Une chose que vous devriez toujours faire lorsque vous d√©boguez une session d'entra√Ænement est de jeter un coup d'oeil aux entr√©es d√©cod√©es de votre mod√®le. Nous ne pouvons pas donner un sens aux chiffres que nous lui fournissons directement, nous devons donc examiner ce que ces chiffres repr√©sentent. Dans le domaine de la vision par ordinateur cela signifie regarder les images d√©cod√©es des pixels que vous passez, dans le domaine de la parole cela signifie √©couter les √©chantillons audio d√©cod√©s, et pour notre exemple de NLP cela signifie utiliser notre *tokenizer* pour d√©coder les entr√©es :

```py
tokenizer.decode(trainer.train_dataset[0]["input_ids"])
```

```python out
'[CLS] conceptually cream skimming has two basic dimensions - product and geography. [SEP] product and geography are what make cream skimming work. [SEP]'
```

Cela semble correct. Vous devriez faire cela pour toutes les cl√©s dans les entr√©es : 

```py
trainer.train_dataset[0].keys()
```

```python out
dict_keys(['attention_mask', 'hypothesis', 'idx', 'input_ids', 'label', 'premise'])
```

Notez que les cl√©s qui ne correspondent pas √† des entr√©es accept√©es par le mod√®le seront automatiquement √©cart√©es, donc ici nous ne garderons que `input_ids`, `attention_mask`, et `label` (qui sera renomm√© `labels`). Pour rev√©rifier la signature du mod√®le, vous pouvez imprimer la classe de votre mod√®le, puis aller consulter sa documentation :

```py
type(trainer.model)
```

```python out
transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification
```

Donc dans notre cas, nous pouvons v√©rifier les param√®tres accept√©s sur [cette page](https://huggingface.co/transformers/model_doc/distilbert.html#distilbertforsequenceclassification). Le `Trainer` va √©galement enregistrer les colonnes qu'il rejette.

Nous avons v√©rifi√© que les identifiants d'entr√©e sont corrects en les d√©codant. Ensuite, il y a le `attention_mask` :

```py
tokenizer.decode(trainer.train_dataset[0]["attention_mask"])
```

```python out
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
```

Comme nous n'avons pas appliqu√© de *padding* dans notre pr√©traitement, cela semble parfaitement naturel. Pour √™tre s√ªr qu'il n'y a pas de probl√®me avec ce masque d'attention, v√©rifions qu'il est de la m√™me longueur que nos identifiants d'entr√©e :

```py
len(trainer.train_dataset[0]["attention_mask"]) == len(
    trainer.train_dataset[0]["input_ids"]
)
```

```python out
True
```

C'est bien ! Enfin, v√©rifions notre √©tiquette :

```py
trainer.train_dataset[0]["label"]
```

```python out
1
```

Comme les identifiants d'entr√©e, c'est un nombre qui n'a pas vraiment de sens en soi. Comme nous l'avons vu pr√©c√©demment, la correspondance entre les entiers et les noms d'√©tiquettes est stock√©e dans l'attribut `names` de la *caract√©ristique* correspondante du jeu de donn√©es :

```py
trainer.train_dataset.features["label"].names
```

```python out
['entailment', 'neutral', 'contradiction']
```

Donc `1` signifie `neutral`, ce qui signifie que les deux phrases que nous avons vues ci-dessus ne sont pas en contradiction : la premi√®re n'implique pas la seconde. Cela semble correct !

Nous n'avons pas de *token* de type identifiant ici puisque DistilBERT ne les attend pas. Si vous en avez dans votre mod√®le, vous devriez √©galement vous assurer qu'ils correspondent correctement √† l'endroit o√π se trouvent la premi√®re et la deuxi√®me phrase dans l'entr√©e.

<Tip>

‚úèÔ∏è *A votre tour !* V√©rifiez que tout semble correct avec le deuxi√®me √©l√©ment du jeu de donn√©es d'entra√Ænement.

</Tip>

Ici nous ne v√©rifions que le jeu d'entra√Ænement. Vous devez bien s√ªr v√©rifier de la m√™me fa√ßon les jeux de validation et de test.

Maintenant que nous savons que nos jeux de donn√©es sont bons, il est temps de v√©rifier l'√©tape suivante du pipeline d'entra√Ænement.

### Des jeux de donn√©es aux chargeurs de donn√©es

La prochaine chose qui peut mal tourner dans le pipeline d'entra√Ænement est lorsque le `Trainer` essaie de former des batchs √† partir du jeu d'entra√Ænement ou de validation. Une fois que vous √™tes s√ªr que les jeux de donn√©es du `Trainer` sont corrects, vous pouvez essayer de former manuellement un batch en ex√©cutant ce qui suit (remplacez `train` par `eval` pour le *dataloader* de validation) :

```py
for batch in trainer.get_train_dataloader():
    break
```

Ce code cr√©e le *dataloader* d'entra√Ænement puis le parcourt en s'arr√™tant √† la premi√®re it√©ration. Si le code s'ex√©cute sans erreur, vous avez le premier batch d'entra√Ænement que vous pouvez inspecter, et si le code se trompe, vous √™tes s√ªr que le probl√®me se situe dans le *dataloader*, comme c'est le cas ici :

```python out
~/git/transformers/src/transformers/data/data_collator.py in torch_default_data_collator(features)
    105                 batch[k] = torch.stack([f[k] for f in features])
    106             else:
--> 107                 batch[k] = torch.tensor([f[k] for f in features])
    108 
    109     return batch

ValueError: expected sequence of length 45 at dim 1 (got 76)
```

L'inspection de la derni√®re image du *traceback* devrait suffire √† vous donner un indice mais creusons un peu plus. La plupart des probl√®mes lors de la cr√©ation d'un batch sont dus √† l'assemblage des exemples en un seul batch. La premi√®re chose √† v√©rifier en cas de doute est le `collate_fn` utilis√© par votre `DataLoader` :

```py
data_collator = trainer.get_train_dataloader().collate_fn
data_collator
```

```python out
<function transformers.data.data_collator.default_data_collator(features: List[InputDataClass], return_tensors='pt') -> Dict[str, Any]>
```

C'est donc `default_data_collator`, mais ce n'est pas ce que nous voulons dans ce cas. Nous voulons rembourrer nos exemples √† la phrase la plus longue du batch, ce qui est fait par `DataCollatorWithPadding`. Et cette assembleur de donn√©es est cens√© √™tre utilis√© par d√©faut par le `Trainer`, alors pourquoi n'est-il pas utilis√© ici ?

La r√©ponse est que nous n'avons pas pass√© le `tokenizer` au `Trainer`, donc il ne pouvait pas cr√©er le `DataCollatorWithPadding` que nous voulons. En pratique, il ne faut jamais h√©siter √† transmettre explicitement l'assembleur de donn√©es que l'on veut utiliser pour √™tre s√ªr d'√©viter ce genre d'erreurs. Adaptons notre code pour faire exactement cela :

```py
from datasets import load_dataset
import evaluate
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    DataCollatorWithPadding,
    TrainingArguments,
    Trainer,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
    return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)

args = TrainingArguments(
    f"distilbert-finetuned-mnli",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
)

metric = evaluate.load("glue", "mnli")


def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    return metric.compute(predictions=predictions, references=labels)


data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

trainer = Trainer(
    model,
    args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation_matched"],
    compute_metrics=compute_metrics,
    data_collator=data_collator,
    tokenizer=tokenizer,
)
trainer.train()
```

La bonne nouvelle ? Nous n'avons plus la m√™me erreur qu'avant, ce qui est un progr√®s certain. La mauvaise nouvelle ? Nous obtenons une erreur CUDA inf√¢me √† la place :

```python out
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
```

C'est une mauvaise chose car les erreurs CUDA sont extr√™mement difficiles √† d√©boguer en g√©n√©ral. Nous verrons dans une minute comment r√©soudre ce probl√®me mais terminons d'abord notre analyse de la cr√©ation de batchs.

Si vous √™tes s√ªr que votre collecteur de donn√©es est le bon, vous devriez essayer de l'appliquer sur quelques √©chantillons de votre jeu de donn√©es :

```py
data_collator = trainer.get_train_dataloader().collate_fn
batch = data_collator([trainer.train_dataset[i] for i in range(4)])
```

Ce code √©chouera parce que le `train_dataset` contient des colonnes de type *string* que le `Trainer` supprime habituellement. Vous pouvez les supprimer manuellement ou si vous voulez reproduire exactement ce que le `Trainer` fait en coulisse, vous pouvez appeler la m√©thode `Trainer._remove_unused_columns()` qui fait cela :

```py
data_collator = trainer.get_train_dataloader().collate_fn
actual_train_set = trainer._remove_unused_columns(trainer.train_dataset)
batch = data_collator([actual_train_set[i] for i in range(4)])
```

Vous devriez alors √™tre en mesure de d√©boguer manuellement ce qui se passe dans le collecteur de donn√©es si l'erreur persiste.

Maintenant que nous avons d√©bogu√© le processus de cr√©ation de batch, il est temps d'en passer un dans le mod√®le !


### Passage par le mod√®le

Vous devriez √™tre en mesure d'obtenir un batch en ex√©cutant la commande suivante :

```py
for batch in trainer.get_train_dataloader():
    break
```

Si vous ex√©cutez ce code dans un *notebook*, vous risquez d'obtenir une erreur CUDA similaire √† celle que nous avons vue pr√©c√©demment, auquel cas vous devrez red√©marrer votre *notebook* et r√©ex√©cuter le dernier extrait sans la ligne `trainer.train()`. C'est la deuxi√®me chose la plus ennuyeuse √† propos des erreurs CUDA : elles cassent irr√©m√©diablement votre noyau. La premi√®re plus ennuyeuse est le fait qu'elles sont difficiles √† d√©boguer.

Comment cela se fait-il ? Cela tient √† la fa√ßon dont les GPUs fonctionnent. Ils sont extr√™mement efficaces pour ex√©cuter un batch d'op√©rations en parall√®le, mais l'inconv√©nient est que lorsque l'une de ces instructions entra√Æne une erreur, vous ne le savez pas imm√©diatement. Ce n'est que lorsque le programme appelle une synchronisation des multiples processus sur le GPU qu'il r√©alise que quelque chose s'est mal pass√©, de sorte que l'erreur est en fait mentionn√©e √† un endroit qui n'a rien √† voir avec ce qui l'a cr√©√©e. Par exemple, si nous regardons notre *traceback* pr√©c√©dent, l'erreur a √©t√© soulev√©e pendant la passe arri√®re, mais nous verrons dans une minute qu'elle provient en fait de quelque chose dans la passe avant.

Alors comment d√©boguer ces erreurs ? La r√©ponse est simple : nous ne le faisons pas. √Ä moins que votre erreur CUDA ne soit une erreur *out-of-memory* (ce qui signifie qu'il n'y a pas assez de m√©moire dans votre GPU), vous devez toujours revenir au CPU pour la d√©boguer.

Pour faire cela dans notre cas, nous devons juste remettre le mod√®le sur le CPU et l'appeler sur notre batch. Le batch retourn√© par le `DataLoader` n'a pas encore √©t√© d√©plac√© sur le GPU :

```python
outputs = trainer.model.cpu()(**batch)
```

```python out
~/.pyenv/versions/3.7.9/envs/base/lib/python3.7/site-packages/torch/nn/functional.py in nll_loss(input, target, weight, size_average, ignore_index, reduce, reduction)
   2386         )
   2387     if dim == 2:
-> 2388         ret = torch._C._nn.nll_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index)
   2389     elif dim == 4:
   2390         ret = torch._C._nn.nll_loss2d(input, target, weight, _Reduction.get_enum(reduction), ignore_index)

IndexError: Target 2 is out of bounds.
```

L'image devient plus claire. Au lieu d'avoir une erreur CUDA, nous avons maintenant une `IndexError` dans le calcul de la perte (donc rien √† voir avec la passe arri√®re comme nous l'avons dit plus t√¥t). Plus pr√©cis√©ment, nous pouvons voir que c'est la cible 2 qui cr√©e l'erreur, donc c'est un bon moment pour v√©rifier le nombre de labels de notre mod√®le :

```python
trainer.model.config.num_labels
```

```python out
2
```

Avec deux √©tiquettes, seuls les 0 et les 1 sont autoris√©s comme cibles, mais d'apr√®s le message d'erreur, nous avons obtenu un 2. Obtenir un 2 est en fait normal : si nous nous souvenons des noms des √©tiquettes que nous avons extraits plus t√¥t, il y en avait trois, donc nous avons les indices 0, 1 et 2 dans notre jeu de donn√©es. Le probl√®me est que nous n'avons pas indiqu√© cela √† notre mod√®le, qui aurait d√ª √™tre cr√©√© avec trois √©tiquettes. Alors, corrigeons cela !

```py
from datasets import load_dataset
import evaluate
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    DataCollatorWithPadding,
    TrainingArguments,
    Trainer,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
    return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=3)

args = TrainingArguments(
    f"distilbert-finetuned-mnli",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
)

metric = evaluate.load("glue", "mnli")


def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    return metric.compute(predictions=predictions, references=labels)


data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

trainer = Trainer(
    model,
    args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation_matched"],
    compute_metrics=compute_metrics,
    data_collator=data_collator,
    tokenizer=tokenizer,
)
```

Nous n'incluons pas encore la ligne `trainer.train()` pour prendre le temps de v√©rifier que tout se passe bien. Si nous passons un batch √† notre mod√®le, il fonctionne maintenant sans erreur !

```py
for batch in trainer.get_train_dataloader():
    break

outputs = trainer.model.cpu()(**batch)
```

L'√©tape suivante consiste alors √† revenir au GPU et √† v√©rifier que tout fonctionne encore :

```py
import torch

device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
batch = {k: v.to(device) for k, v in batch.items()}

outputs = trainer.model.to(device)(**batch)
```

Si vous obtenez toujours une erreur, assurez-vous de red√©marrer votre *notebook* et d'ex√©cuter uniquement la derni√®re version du script.

### Ex√©cution d'une √©tape d'optimisation

Maintenant que nous savons que nous pouvons construire des batchs qui passent r√©ellement par le mod√®le, nous sommes pr√™ts pour l'√©tape suivante du pipeline d'entra√Ænement : calculer les gradients et effectuer une √©tape d'optimisation.

La premi√®re partie est juste une question d'appel de la m√©thode `backward()` sur la perte :

```py
loss = outputs.loss
loss.backward()
```

Il est plut√¥t rare d'obtenir une erreur √† ce stade, mais si vous en obtenez une, assurez-vous de retourner au CPU pour obtenir un message d'erreur utile.

Pour effectuer l'√©tape d'optimisation, il suffit de cr√©er le `optimizer` et d'appeler sa m√©thode `step()` :

```py
trainer.create_optimizer()
trainer.optimizer.step()
```

Encore une fois, si vous utilisez l'optimiseur par d√©faut dans le `Trainer`, vous ne devriez pas avoir d'erreur √† ce stade, mais si vous avez un optimiseur personnalis√©, il pourrait y avoir quelques probl√®mes √† d√©boguer ici. N'oubliez pas de revenir au CPU si vous obtenez une erreur CUDA bizarre √† ce stade. En parlant d'erreurs CUDA, nous avons mentionn√© pr√©c√©demment un cas particulier. Voyons cela maintenant.

### G√©rer les erreurs <i>CUDA out of memory</i>

Chaque fois que vous obtenez un message d'erreur qui commence par `RuntimeError : CUDA out of memory`, cela indique que vous √™tes √† court de m√©moire GPU. Cela n'est pas directement li√© √† votre code et peut arriver avec un script qui fonctionne parfaitement bien. Cette erreur signifie que vous avez essay√© de mettre trop de choses dans la m√©moire interne de votre GPU et que cela a entra√Æn√© une erreur. Comme pour d'autres erreurs CUDA, vous devrez red√©marrer votre noyau pour √™tre en mesure d'ex√©cuter √† nouveau votre entra√Ænement.

Pour r√©soudre ce probl√®me, il suffit d'utiliser moins d'espace GPU, ce qui est souvent plus facile √† dire qu'√† faire. Tout d'abord, assurez-vous que vous n'avez pas deux mod√®les sur le GPU en m√™me temps (sauf si cela est n√©cessaire pour votre probl√®me, bien s√ªr). Ensuite, vous devriez probablement r√©duire la taille de votre batch car elle affecte directement les tailles de toutes les sorties interm√©diaires du mod√®le et leurs gradients. Si le probl√®me persiste, envisagez d'utiliser une version plus petite de votre mod√®le.

<Tip>

Dans la prochaine partie du cours, nous examinerons des techniques plus avanc√©es qui peuvent vous aider √† r√©duire votre empreinte m√©moire et vous permettre de <i>finetuner</i> les plus grands mod√®les.

</Tip>

### √âvaluation du mod√®le

Maintenant que nous avons r√©solu tous les probl√®mes li√©s √† notre code, tout est parfait et l'entra√Ænement devrait se d√©rouler sans probl√®me, n'est-ce pas ? Pas si vite ! Si vous ex√©cutez la commande `trainer.train()`, tout aura l'air bien au d√©but, mais apr√®s un moment vous obtiendrez ce qui suit :

```py
# Cela prendra beaucoup de temps et se soldera par une erreur, vous ne devriez donc pas utiliser cette cellule.
trainer.train()
```

```python out
TypeError: only size-1 arrays can be converted to Python scalars
```

Vous r√©aliserez que cette erreur appara√Æt pendant la phase d'√©valuation, donc c'est la derni√®re chose que nous aurons besoin de d√©boguer.

Vous pouvez ex√©cuter la boucle d'√©valuation du `Trainer` ind√©pendamment de l'entra√Ænement comme ceci :

```py
trainer.evaluate()
```

```python out
TypeError: only size-1 arrays can be converted to Python scalars
```

<Tip>

üí° Vous devriez toujours vous assurer que vous pouvez ex√©cuter `trainer.evaluate()` avant de lancer `trainer.train()`, pour √©viter de gaspiller beaucoup de ressources de calcul avant de tomber sur une erreur.

</Tip>

Avant de tenter de d√©boguer un probl√®me dans la boucle d'√©valuation, vous devez d'abord vous assurer que vous avez examin√© les donn√©es, que vous √™tes en mesure de former un batch correctement et que vous pouvez ex√©cuter votre mod√®le sur ces donn√©es. Nous avons effectu√© toutes ces √©tapes, et le code suivant peut donc √™tre ex√©cut√© sans erreur :

```py
for batch in trainer.get_eval_dataloader():
    break

batch = {k: v.to(device) for k, v in batch.items()}

with torch.no_grad():
    outputs = trainer.model(**batch)
```

L'erreur survient plus tard, √† la fin de la phase d'√©valuation, et si nous regardons le *traceback*, nous voyons ceci :

```python trace
~/git/datasets/src/datasets/metric.py in add_batch(self, predictions, references)
    431         """
    432         batch = {"predictions": predictions, "references": references}
--> 433         batch = self.info.features.encode_batch(batch)
    434         if self.writer is None:
    435             self._init_writer()
```

Cela nous indique que l'erreur provient du module `datasets/metric.py` donc c'est un probl√®me avec notre fonction `compute_metrics()`. Elle prend un *tuple* avec les logits et les labels sous forme de tableaux NumPy, alors essayons de lui fournir cela :

```py
predictions = outputs.logits.cpu().numpy()
labels = batch["labels"].cpu().numpy()

compute_metrics((predictions, labels))
```

```python out
TypeError: only size-1 arrays can be converted to Python scalars
```

Nous obtenons la m√™me erreur, donc le probl√®me vient bien de cette fonction. Si on regarde son code, on voit qu'elle transmet simplement les `predictions` et les `labels` √† `metric.compute()`. Y a-t-il donc un probl√®me avec cette m√©thode ? Pas vraiment. Jetons un coup d'oeil rapide aux formes :

```py
predictions.shape, labels.shape
```

```python out
((8, 3), (8,))
```

Nos pr√©dictions sont toujours des logits et non les pr√©dictions r√©elles, c'est pourquoi la m√©trique retourne cette erreur (quelque peu obscure). La correction est assez simple, il suffit d'ajouter un argmax dans la fonction `compute_metrics()` :

```py
import numpy as np


def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    predictions = np.argmax(predictions, axis=1)
    return metric.compute(predictions=predictions, references=labels)


compute_metrics((predictions, labels))
```

```python out
{'accuracy': 0.625}
```

Maintenant notre erreur est corrig√©e ! C'√©tait la derni√®re, donc notre script va maintenant entra√Æner un mod√®le correctement.

Pour r√©f√©rence, voici le script compl√®tement corrig√© :

```py
import numpy as np
from datasets import load_dataset
import evaluate
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    DataCollatorWithPadding,
    TrainingArguments,
    Trainer,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
    return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=3)

args = TrainingArguments(
    f"distilbert-finetuned-mnli",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
)

metric = evaluate.load("glue", "mnli")


def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    predictions = np.argmax(predictions, axis=1)
    return metric.compute(predictions=predictions, references=labels)


data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

trainer = Trainer(
    model,
    args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation_matched"],
    compute_metrics=compute_metrics,
    data_collator=data_collator,
    tokenizer=tokenizer,
)
trainer.train()
```

Dans ce cas, il n'y a plus de probl√®me, et notre script va *finetuner* un mod√®le qui devrait donner des r√©sultats raisonnables. Mais que faire lorsque l'entra√Ænement se d√©roule sans erreur et que le mod√®le entra√Æn√© n'est pas du tout performant ? C'est la partie la plus difficile de l'apprentissage automatique et nous allons vous montrer quelques techniques qui peuvent vous aider.

<Tip>

üí° Si vous utilisez une boucle d'entra√Ænement manuelle, les m√™mes √©tapes s'appliquent pour d√©boguer votre pipeline d'entra√Ænement, mais il est plus facile de les s√©parer. Assurez-vous cependant de ne pas avoir oubli√© le `model.eval()` ou le `model.train()` aux bons endroits, ou le `zero_grad()` √† chaque √©tape !

</Tip>

## D√©boguer les erreurs silencieuses pendant l'entra√Ænement

Que peut-on faire pour d√©boguer un entra√Ænement qui se termine sans erreur mais qui ne donne pas de bons r√©sultats ? Nous allons vous donner quelques pistes ici, mais sachez que ce type de d√©bogage est la partie la plus difficile de l'apprentissage automatique et qu'il n'y a pas de r√©ponse magique.

### V√©rifiez vos donn√©es (encore !)

Votre mod√®le n'apprendra quelque chose que s'il est r√©ellement possible d'apprendre quelque chose de vos donn√©es. Si un *bug* corrompt les donn√©es ou si les √©tiquettes sont attribu√©es de mani√®re al√©atoire, il est tr√®s probable que vous n'obtiendrez aucun entra√Ænement de mod√®le sur votre jeu de donn√©es. Commencez donc toujours par rev√©rifier vos entr√©es et √©tiquettes d√©cod√©es, et posez-vous les questions suivantes :

- les donn√©es d√©cod√©es sont-elles compr√©hensibles ?
- √™tes-vous d'accord avec les √©tiquettes ?
- y a-t-il une √©tiquette qui est plus courante que les autres ?
- quelle devrait √™tre la perte/m√©trique si le mod√®le pr√©disait une r√©ponse al√©atoire/toujours la m√™me r√©ponse ?

<Tip warning={true}>

‚ö†Ô∏è Si vous effectuez un entra√Ænement distribu√©, imprimez des √©chantillons de votre ensemble de donn√©es dans chaque processus et v√©rifiez par trois fois que vous obtenez la m√™me chose. Un bug courant consiste √† avoir une source d'al√©a dans la cr√©ation des donn√©es qui fait que chaque processus a une version diff√©rente du jeu de donn√©es.

</Tip>

Apr√®s avoir examin√© vos donn√©es, examinez quelques-unes des pr√©dictions du mod√®le. Si votre mod√®le produit des *tokens*, essayez aussi de les d√©coder ! Si le mod√®le pr√©dit toujours la m√™me chose, cela peut √™tre d√ª au fait que votre jeu de donn√©es est biais√© en faveur d'une cat√©gorie (pour les probl√®mes de classification). Des techniques telles que le sur√©chantillonnage des classes rares peuvent aider. D'autre part, cela peut √©galement √™tre d√ª √† des probl√®mes d'entra√Ænement tels que de mauvais r√©glages des hyperparam√®tres.

Si la perte/la m√©trique que vous obtenez sur votre mod√®le initial avant entra√Ænement est tr√®s diff√©rente de la perte/la m√©trique √† laquelle vous vous attendez pour des pr√©dictions al√©atoires, v√©rifiez la fa√ßon dont votre perte ou votre m√©trique est calcul√©e. Il y a probablement un bug. Si vous utilisez plusieurs pertes que vous ajoutez √† la fin, assurez-vous qu'elles sont de la m√™me √©chelle.

Lorsque vous √™tes s√ªr que vos donn√©es sont parfaites, vous pouvez voir si le mod√®le est capable de s'entra√Æner sur elles gr√¢ce √† un test simple.

### Surentra√Ænement du mod√®le sur un seul batch

Le surentra√Ænement est g√©n√©ralement une chose que nous essayons d'√©viter lors de l'entra√Ænement car cela signifie que le mod√®le n'apprend pas √† reconna√Ætre les caract√©ristiques g√©n√©rales que nous voulons qu'il reconnaisse et se contente de m√©moriser les √©chantillons d'entra√Ænement. Cependant, essayer d'entra√Æner votre mod√®le sur un batch encore et encore est un bon test pour v√©rifier si le probl√®me tel que vous l'avez formul√© peut √™tre r√©solu par le mod√®le que vous essayez d'entra√Æner. Cela vous aidera √©galement √† voir si votre taux d'apprentissage initial est trop √©lev√©.

Une fois que vous avez d√©fini votre `mod√®le`, c'est tr√®s facile. Il suffit de prendre un batch de donn√©es d'entra√Ænement, puis de le traiter comme votre jeu de donn√©es entier que vous *finetunez* sur un grand nombre d'√©poques :

```py
for batch in trainer.get_train_dataloader():
    break

batch = {k: v.to(device) for k, v in batch.items()}
trainer.create_optimizer()

for _ in range(20):
    outputs = trainer.model(**batch)
    loss = outputs.loss
    loss.backward()
    trainer.optimizer.step()
    trainer.optimizer.zero_grad()
```

<Tip>

üí° Si vos donn√©es d'entra√Ænement ne sont pas √©quilibr√©es, veillez √† cr√©er un batch de donn√©es d'entra√Ænement contenant toutes les √©tiquettes.

</Tip>

Le mod√®le r√©sultant devrait avoir des r√©sultats proches de la perfection sur le m√™me `batch`. Calculons la m√©trique sur les pr√©dictions r√©sultantes :

```py
with torch.no_grad():
    outputs = trainer.model(**batch)
preds = outputs.logits
labels = batch["labels"]

compute_metrics((preds.cpu().numpy(), labels.cpu().numpy()))
```

```python out
{'accuracy': 1.0}
```

100% de pr√©cision, voil√† un bel exemple de surentra√Ænement (ce qui signifie que si vous essayez votre mod√®le sur n'importe quelle autre phrase, il vous donnera tr√®s probablement une mauvaise r√©ponse) !

Si vous ne parvenez pas √† ce que votre mod√®le obtienne des r√©sultats parfaits comme celui-ci, cela signifie qu'il y a quelque chose qui ne va pas dans la fa√ßon dont vous avez formul√© le probl√®me ou dans vos donn√©es. Vous devez donc y rem√©dier. Ce n'est que lorsque vous parviendrez √† passer le test de surentra√Ænement que vous pourrez √™tre s√ªr que votre mod√®le peut r√©ellement apprendre quelque chose.

<Tip warning={true}>

‚ö†Ô∏è Vous devrez recr√©er votre mod√®le et votre `Trainer` apr√®s ce test, car le mod√®le obtenu ne sera probablement pas capable de r√©cup√©rer et d'apprendre quelque chose d'utile sur votre jeu de donn√©es complet.

</Tip>

### Ne r√©glez rien tant que vous n'avez pas une premi√®re ligne de base

Le r√©glage des hyperparam√®tres est toujours consid√©r√© comme la partie la plus difficile de l'apprentissage automatique mais c'est juste la derni√®re √©tape pour vous aider √† gagner un peu sur la m√©trique. La plupart du temps, les hyperparam√®tres par d√©faut du `Trainer` fonctionneront tr√®s bien pour vous donner de bons r√©sultats. Donc ne vous lancez pas dans une recherche d'hyperparam√®tres longue et co√ªteuse jusqu'√† ce que vous ayez quelque chose qui batte la ligne de base que vous avez sur votre jeu de donn√©es.

Une fois que vous avez un mod√®le suffisamment bon, vous pouvez commencer √† le *finetuner* un peu. N'essayez pas de lancer un millier d'ex√©cutions avec diff√©rents hyperparam√®tres mais comparez quelques ex√©cutions avec diff√©rentes valeurs pour un hyperparam√®tre afin de vous faire une id√©e de celui qui a le plus d'impact.

Si vous modifiez le mod√®le lui-m√™me, restez simple et n'essayez rien que vous ne puissiez raisonnablement justifier. Veillez toujours √† revenir au test de surentra√Ænement pour v√©rifier que votre modification n'a pas eu de cons√©quences inattendues.

### Demander de l'aide

Nous esp√©rons que vous avez trouv√© dans cette section des conseils qui vous ont aid√© √† r√©soudre votre probl√®me. Si ce n'est pas le cas, n'oubliez pas que vous pouvez toujours demander de l'aide √† la communaut√© sur le [forum](https://discuss.huggingface.co/). 

Voici quelques ressources (en anglais) suppl√©mentaires qui peuvent s'av√©rer utiles :

- [La reproductibilit√© comme vecteur des meilleures pratiques d'ing√©nierie](https://docs.google.com/presentation/d/1yHLPvPhUs2KGI5ZWo0sU-PKU3GimAk3iTsI38Z-B5Gw/edit#slide=id.p) par Joel Grus
- [Liste de contr√¥le pour le d√©bogage des r√©seaux de neurones](https://towardsdatascience.com/checklist-for-debugging-neural-networks-d8b2a9434f21) par Cecelia Shao
- [Comment tester unitairement le code d'apprentissage automatique](https://medium.com/@keeper6928/how-to-unit-test-machine-learning-code-57cf6fd81765) par Chase Roberts
- [Une recette pour entra√Æner les r√©seaux de neurones](http://karpathy.github.io/2019/04/25/recipe/) par Andrej Karpathy

Bien s√ªr, tous les probl√®mes rencontr√©s lors de l'entra√Ænement ne sont pas forc√©ment de votre faute ! Si vous rencontrez quelque chose dans la biblioth√®que ü§ó *Transformers* ou ü§ó *Datasets* qui ne semble pas correct, vous avez peut-√™tre trouver un *bug*. Vous devez absolument nous en parler pour qu'on puisse le corriger. Dans la section suivante, nous allons vous expliquer exactement comment faire.
