<FrameworkSwitchCourse {fw} />

# D√©bogage du pipeline d'entra√Ænement


<CourseFloatingBanner chapter={8}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "English", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter8/section4_tf.ipynb"},
    {label: "Fran√ßais", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/fr/chapter8/section4_tf.ipynb"},
    {label: "English", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter8/section4_tf.ipynb"},
    {label: "Fran√ßais", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/fr/chapter8/section4_tf.ipynb"},
]} />


Vous avez √©crit un magnifique script pour entra√Æner ou *finetuner* un mod√®le sur une t√¢che donn√©e en suivant consciencieusement les conseils du [chapitre 7](/course/fr/chapter7). Mais lorsque vous lancez la commande `model.fit()`, quelque chose d'horrible se produit : vous obtenez une erreur üò± ! Ou pire, tout semble aller bien et l'entra√Ænement se d√©roule sans erreur mais le mod√®le r√©sultant est mauvais. Dans cette section, nous allons vous montrer ce que vous pouvez faire pour d√©boguer ce genre de probl√®mes.

## D√©boguer le pipeline d'entra√Ænement

<Youtube id="N9kO52itd0Q"/>

Le probl√®me lorsque vous rencontrez une erreur dans `trainer.train()` est qu'elle peut provenir de plusieurs sources, car la fonction `Trainer` assemble g√©n√©ralement des batchs de choses. Elle convertit les jeux de donn√©es en chargeurs de donn√©es donc le probl√®me pourrait √™tre quelque chose d'erron√© dans votre jeu de donn√©es, ou un probl√®me en essayant de regrouper les √©l√©ments des jeux de donn√©es ensemble. Ensuite, elle prend un batch de donn√©es et le transmet au mod√®le, le probl√®me peut donc se situer dans le code du mod√®le. Apr√®s cela, elle calcule les gradients et effectue l'√©tape d'optimisation, le probl√®me peut donc √©galement se situer dans votre optimiseur. Et m√™me si tout se passe bien pendant l'entra√Ænement, quelque chose peut encore mal tourner pendant l'√©valuation si votre m√©trique pose probl√®me.

La meilleure fa√ßon de d√©boguer une erreur qui survient dans `trainer.train()` est de passer manuellement en revue tout le pipeline pour voir o√π les choses se sont mal pass√©es. L'erreur est alors souvent tr√®s facile √† r√©soudre.

Pour le d√©montrer, nous utiliserons le script suivant qui tente de *finetuner* un mod√®le DistilBERT sur le [jeu de donn√©es MNLI](https://huggingface.co/datasets/glue) :

```py
from datasets import load_dataset
import evaluate
from transformers import (
    AutoTokenizer,
    TFAutoModelForSequenceClassification,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
    return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)

train_dataset = tokenized_datasets["train"].to_tf_dataset(
    columns=["input_ids", "labels"], batch_size=16, shuffle=True
)

validation_dataset = tokenized_datasets["validation_matched"].to_tf_dataset(
    columns=["input_ids", "labels"], batch_size=16, shuffle=True
)

model = TFAutoModelForSequenceClassification.from_pretrained(model_checkpoint)

model.compile(loss="sparse_categorical_crossentropy", optimizer="adam")

model.fit(train_dataset)
```

Si vous essayez de l'ex√©cuter, il se peut que vous obteniez des `VisibleDeprecationWarning`s lors de la conversion du jeu de donn√©es. Il s'agit d'un probl√®me UX connu par l'√©quipe d'Hugging Face, donc veuillez l'ignorer. Si vous lisez le cours apr√®s novembre 2021 et que cela se produit encore, envoyez des tweets de rage √† @carrigmat jusqu'√† ce qu'il le corrige.

Le probl√®me cependant est que nous avons une erreur flagrante. Et c'est vraiment, terriblement long :

```python out
ValueError: No gradients provided for any variable: ['tf_distil_bert_for_sequence_classification/distilbert/embeddings/word_embeddings/weight:0', '...']
```

Qu'est-ce que cela signifie ? Nous avons essay√© d'entra√Æner sur nos donn√©es mais nous n'avons pas obtenu de gradient. C'est assez d√©concertant. Comment commencer √† d√©boguer quelque chose comme √ßa ? Lorsque l'erreur que vous obtenez ne sugg√®re pas imm√©diatement l'origine du probl√®me, la meilleure solution consiste souvent √† proc√©der par √©tapes, en s'assurant √† chaque fois que tout semble correct. Et bien s√ªr, il faut toujours commencer par...

### V√©rifier vos donn√©es

Cela va sans dire, mais si vos donn√©es sont corrompues, Keras ne sera pas en mesure de les r√©parer pour vous. Avant toute chose, vous devez donc jeter un coup d'≈ìil √† ce que contient votre ensemble d'entra√Ænement.

Bien qu'il soit tentant de regarder dans `raw_datasets` et `tokenized_datasets`, nous vous recommandons fortement d'aller voir les donn√©es au moment o√π elles vont entrer dans le mod√®le. Cela signifie lire une sortie du `tf.data.Dataset` que vous avez cr√©√© avec la fonction `to_tf_dataset()` ! Alors comment faire ? Les objets `tf.data.Dataset` nous donnent des batchs entiers √† la fois et ne supportent pas l'indexation, donc nous ne pouvons pas simplement demander `train_dataset[0]`. Nous pouvons, cependant, lui demander poliment un batch :

```py
for batch in train_dataset:
    break
```

`break` termine la boucle apr√®s une it√©ration, donc cela prend le premier batch qui sort de `train_dataset` et l'enregistre comme `batch`. Maintenant, jetons un coup d'oeil √† ce qu'il y a √† l'int√©rieur :

```python out
{'attention_mask': <tf.Tensor: shape=(16, 76), dtype=int64, numpy=
 array([[1, 1, 1, ..., 0, 0, 0],
        [1, 1, 1, ..., 0, 0, 0],
        [1, 1, 1, ..., 0, 0, 0],
        ...,
        [1, 1, 1, ..., 1, 1, 1],
        [1, 1, 1, ..., 0, 0, 0],
        [1, 1, 1, ..., 0, 0, 0]])>,
 'label': <tf.Tensor: shape=(16,), dtype=int64, numpy=array([0, 2, 1, 2, 1, 1, 2, 0, 0, 0, 1, 0, 1, 2, 2, 1])>,
 'input_ids': <tf.Tensor: shape=(16, 76), dtype=int64, numpy=
 array([[ 101, 2174, 1010, ...,    0,    0,    0],
        [ 101, 3174, 2420, ...,    0,    0,    0],
        [ 101, 2044, 2048, ...,    0,    0,    0],
        ...,
        [ 101, 3398, 3398, ..., 2051, 2894,  102],
        [ 101, 1996, 4124, ...,    0,    0,    0],
        [ 101, 1999, 2070, ...,    0,    0,    0]])>}
```

Cela semble correct. Nous passons les `labels`, `attention_mask`, et `input_ids` au mod√®le, ce qui devrait √™tre tout ce dont il a besoin pour calculer les sorties et la perte. Alors pourquoi n'avons-nous pas de gradient ? Regardez de plus pr√®s : nous passons un seul dictionnaire en entr√©e mais un batch d'entra√Ænement est g√©n√©ralement un tenseur ou un dictionnaire d'entr√©e, plus un tenseur d'√©tiquettes. Nos √©tiquettes sont juste une cl√© dans notre dictionnaire d'entr√©e.

Est-ce un probl√®me ? Pas toujours, en fait ! Mais c'est l'un des probl√®mes les plus courants que vous rencontrerez lorsque vous entra√Ænerez des *transformers* avec TensorFlow. Nos mod√®les peuvent tous calculer la perte en interne, mais pour ce faire, les √©tiquettes doivent √™tre transmises dans le dictionnaire d'entr√©e. C'est la perte qui est utilis√©e lorsque nous ne sp√©cifions pas de valeur de perte √† `compile()`. Keras, d'autre part, s'attend g√©n√©ralement √† ce que les √©tiquettes soient pass√©es s√©par√©ment du dictionnaire d'entr√©e, et les calculs de perte √©choueront g√©n√©ralement si vous ne le faites pas.

Le probl√®me est maintenant devenu plus clair : nous avons pass√© un argument `loss`, ce qui signifie que nous demandons √† Keras de calculer les pertes pour nous, mais nous avons pass√© nos √©tiquettes comme entr√©es au mod√®le, et non comme √©tiquettes √† l'endroit o√π Keras les attend ! Nous devons choisir l'un ou l'autre : soit nous utilisons la perte interne du mod√®le et gardons les √©tiquettes o√π elles sont, soit nous continuons √† utiliser les pertes de Keras, mais nous d√©pla√ßons les √©tiquettes √† l'endroit o√π Keras les attend. Pour simplifier, prenons la premi√®re approche. Changez l'appel √† `compile()` pour lire :

```py
model.compile(optimizer="adam")
```

Maintenant, nous allons utiliser la perte interne du mod√®le et ce probl√®me devrait √™tre r√©solu !

<Tip>

‚úèÔ∏è *A votre tour !* Comme d√©fi optionnel apr√®s avoir r√©solu les autres probl√®mes, vous pouvez essayer de revenir √† cette √©tape et faire fonctionner le mod√®le avec la perte originale calcul√©e par Keras au lieu de la perte interne. Vous devrez ajouter `"labels"` √† l'argument `label_cols` de `to_tf_dataset()` pour vous assurer que les labels sont correctement sortis, ce qui vous donnera des gradients. Mais il y a un autre probl√®me avec la perte que nous avons sp√©cifi√©e. L'entra√Ænement fonctionnera toujours avec ce probl√®me mais l'apprentissage sera tr√®s lent et se stabilisera √† une perte d'entra√Ænement √©lev√©e. Pouvez-vous trouver ce que c'est ?

Un indice cod√© en ROT13, si vous √™tes coinc√© : Vs lbh ybbx ng gur bhgchgf bs FrdhraprPynffvsvpngvba zbqryf va Genafsbezref, gurve svefg bhgchg vf `ybtvgf`. Jung ner ybtvgf ?

Et un deuxi√®me indice : Jura lbh fcrpvsl bcgvzvmref, npgvingvbaf be ybffrf jvgu fgevatf, Xrenf frgf ny gur nethzrag inyhrf gb gurve qrsnhygf. Jung nethzragf qbrf FcnefrPngrtbevpnyPebffragebcl unir, naq jung ner gurve qrsnhygf ?

</Tip>

Maintenant, essayons d'entra√Æner. Nous devrions obtenir des gradients maintenant, donc avec un peu de chance nous pouvons juste appeler `model.fit()` et tout fonctionnera bien !

```python out
  246/24543 [..............................] - ETA: 15:52 - loss: nan
```

Oh non. 

`nan` n'est pas une valeur de perte tr√®s encourageante. Pourtant, nous avons v√©rifi√© nos donn√©es et elles semblent plut√¥t bonnes. Si ce n'est pas le probl√®me, quelle est la prochaine √©tape ? La prochaine √©tape √©vidente est de...

### V√©rifier votre mod√®le

`model.fit()` est une fonction tr√®s pratique dans Keras, mais elle fait beaucoup de choses pour vous. Cela peut rendre plus difficile de trouver exactement o√π un probl√®me est survenu. Si vous d√©boguez votre mod√®le, une strat√©gie qui peut vraiment vous aider est de passer un seul batch au mod√®le et d'examiner les sorties de ce batch en d√©tail. Une autre astuce vraiment utile est de `compiler()` le mod√®le avec `run_eagerly=True`. Cela le rendra beaucoup plus lent mais les messages d'erreur seront beaucoup plus compr√©hensibles car ils indiqueront exactement o√π le probl√®me est survenu dans le code de votre mod√®le.

Pour l'instant, cependant, nous n'avons pas besoin de `run_eagerly`. Ex√©cutons le `batch` que nous avons obtenu pr√©c√©demment √† travers le mod√®le et voyons √† quoi ressemblent les r√©sultats :

```py
model(batch)
```

```python out
TFSequenceClassifierOutput(loss=<tf.Tensor: shape=(16,), dtype=float32, numpy=
array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
       nan, nan, nan], dtype=float32)>, logits=<tf.Tensor: shape=(16, 2), dtype=float32, numpy=
array([[nan, nan],
       [nan, nan],
       [nan, nan],
       [nan, nan],
       [nan, nan],
       [nan, nan],
       [nan, nan],
       [nan, nan],
       [nan, nan],
       [nan, nan],
       [nan, nan],
       [nan, nan],
       [nan, nan],
       [nan, nan],
       [nan, nan],
       [nan, nan]], dtype=float32)>, hidden_states=None, attentions=None)
```

Eh bien, c'est d√©licat. Tout est "nan" ! Mais c'est √©trange, n'est-ce pas ? Comment tous nos logits pourraient-ils devenir `nan` ? "NAN" signifie "*not a number*". Les valeurs `nan` apparaissent souvent quand on effectue une op√©ration interdite comme la division par z√©ro. Mais une chose tr√®s importante √† savoir sur `nan` en apprentissage automatique est que cette valeur a tendance √† *se propager*. Si vous multipliez un nombre par `nan`, le r√©sultat sera √©galement `nan`. Et si vous obtenez une valeur `nan` n'importe o√π dans votre sortie, votre perte ou votre gradient, alors elle se propagera rapidement √† travers tout votre mod√®le. 
Ceci parce que lorsque cette valeur `nan` est propag√©e √† travers votre r√©seau, vous obtiendrez des gradients `nan`, et lorsque les mises √† jour des poids sont calcul√©es avec ces gradients, vous obtiendrez des poids `nan`, et ces poids calculeront encore plus de sorties `nan` ! Tr√®s vite, le r√©seau entier ne sera plus qu'un gros bloc de `nan`. Une fois que cela arrive, il est assez difficile de voir o√π le probl√®me a commenc√©. Comment peut-on isoler l'endroit o√π les `nan` se sont introduits en premier ?

La r√©ponse est d'essayer de *reinitialiser* notre mod√®le. Une fois que nous avons commenc√© l'entra√Ænement, nous avons eu un `nan` quelque part et il s'est rapidement propag√© √† travers tout le mod√®le. Donc, chargeons le mod√®le √† partir d'un checkpoint et ne faisons aucune mise √† jour de poids, et voyons o√π nous obtenons une valeur `nan` :

```py
model = TFAutoModelForSequenceClassification.from_pretrained(model_checkpoint)
model(batch)
```

Quand on fait √ßa, on obtient :

```py out
TFSequenceClassifierOutput(loss=<tf.Tensor: shape=(16,), dtype=float32, numpy=
array([0.6844486 ,        nan,        nan, 0.67127866, 0.7068601 ,
              nan, 0.69309855,        nan, 0.65531296,        nan,
              nan,        nan, 0.675402  ,        nan,        nan,
       0.69831556], dtype=float32)>, logits=<tf.Tensor: shape=(16, 2), dtype=float32, numpy=
array([[-0.04761693, -0.06509043],
       [-0.0481936 , -0.04556257],
       [-0.0040929 , -0.05848458],
       [-0.02417453, -0.0684005 ],
       [-0.02517801, -0.05241832],
       [-0.04514256, -0.0757378 ],
       [-0.02656011, -0.02646275],
       [ 0.00766164, -0.04350497],
       [ 0.02060014, -0.05655622],
       [-0.02615328, -0.0447021 ],
       [-0.05119278, -0.06928903],
       [-0.02859691, -0.04879177],
       [-0.02210129, -0.05791225],
       [-0.02363213, -0.05962167],
       [-0.05352269, -0.0481673 ],
       [-0.08141848, -0.07110836]], dtype=float32)>, hidden_states=None, attentions=None)
```

*Maintenant* on arrive √† quelque chose ! Il n'y a pas de valeurs `nan` dans nos logits, ce qui est rassurant. Mais nous voyons quelques valeurs `nan` dans notre perte ! Y a-t-il quelque chose dans ces √©chantillons en particulier qui cause ce probl√®me ? Voyons de quels √©chantillons il s'agit (notez que si vous ex√©cutez ce code vous-m√™me, vous pouvez obtenir des indices diff√©rents parce que le jeu de donn√©es a √©t√© m√©lang√©) :

```python
import numpy as np

loss = model(batch).loss.numpy()
indices = np.flatnonzero(np.isnan(loss))
indices
```

```python out
array([ 1,  2,  5,  7,  9, 10, 11, 13, 14])
```

Examinons les √©chantillons d'o√π proviennent ces indices :

```python
input_ids = batch["input_ids"].numpy()
input_ids[indices]
```

```python out
array([[  101,  2007,  2032,  2001,  1037, 16480,  3917,  2594,  4135,
        23212,  3070,  2214, 10170,  1010,  2012,  4356,  1997,  3183,
         6838, 12953,  2039,  2000,  1996,  6147,  1997,  2010,  2606,
         1012,   102,  6838,  2001,  3294,  6625,  3773,  1996,  2214,
         2158,  1012,   102,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0],
       [  101,  1998,  6814,  2016,  2234,  2461,  2153,  1998, 13322,
         2009,  1012,   102,  2045,  1005,  1055,  2053,  3382,  2008,
         2016,  1005,  2222,  3046,  8103,  2075,  2009,  2153,  1012,
          102,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0],
       [  101,  1998,  2007,  1996,  3712,  4634,  1010,  2057,  8108,
         2025,  3404,  2028,  1012,  1996,  2616, 18449,  2125,  1999,
         1037,  9666,  1997,  4100,  8663, 11020,  6313,  2791,  1998,
         2431,  1011,  4301,  1012,   102,  2028,  1005,  1055,  5177,
         2110,  1998,  3977,  2000,  2832,  2106,  2025,  2689,  2104,
         2122,  6214,  1012,   102,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0],
       [  101,  1045,  2001,  1999,  1037, 13090,  5948,  2007,  2048,
         2308,  2006,  2026,  5001,  2043,  2026,  2171,  2001,  2170,
         1012,   102,  1045,  2001,  3564,  1999,  2277,  1012,   102,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0],
       [  101,  2195,  4279,  2191,  2039,  1996,  2181,  2124,  2004,
         1996,  2225,  7363,  1012,   102,  2045,  2003,  2069,  2028,
         2451,  1999,  1996,  2225,  7363,  1012,   102,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0],
       [  101,  2061,  2008,  1045,  2123,  1005,  1056,  2113,  2065,
         2009,  2428, 10654,  7347,  2030,  2009,  7126,  2256,  2495,
         2291,   102,  2009,  2003,  5094,  2256,  2495,  2291,  2035,
         2105,  1012,   102,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0],
       [  101,  2051,  1010,  2029,  3216,  2019,  2503,  3444,  1010,
         6732,  1996,  2265,  2038, 19840,  2098,  2125,  9906,  1998,
         2003,  2770,  2041,  1997,  4784,  1012,   102,  2051,  6732,
         1996,  2265,  2003,  9525,  1998,  4569,  1012,   102,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0],
       [  101,  1996, 10556,  2140, 11515,  2058,  1010,  2010,  2162,
         2252,  5689,  2013,  2010,  7223,  1012,   102,  2043,  1996,
        10556,  2140, 11515,  2058,  1010,  2010,  2252,  3062,  2000,
         1996,  2598,  1012,   102,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0],
       [  101, 13543,  1999,  2049,  6143,  2933,  2443,   102,  2025,
        13543,  1999,  6143,  2933,  2003,  2443,   102,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0]])
```

Il y a beaucoup de batchs ici mais rien d'inhabituel. Regardons les √©tiquettes :

```python out
labels = batch['labels'].numpy()
labels[indices]
```

```python out
array([2, 2, 2, 2, 2, 2, 2, 2, 2])
```

Ah ! Les √©chantillons `nan` ont tous le m√™me label. C'est un gros indice. Le fait que nous n'obtenions une perte de `nan` que lorsque notre √©tiquette vaut 2 sugg√®re que c'est un tr√®s bon moment pour v√©rifier le nombre d'√©tiquettes dans notre mod√®le :

```python
model.config.num_labels
```

```python out
2
```

Nous voyons maintenant le probl√®me : le mod√®le pense qu'il n'y a que deux classes, mais les √©tiquettes vont jusqu'√† 2, ce qui signifie qu'il y a en fait trois classes (car 0 est aussi une classe). C'est ainsi que nous avons obtenu un `nan`. En essayant de calculer la perte pour une classe inexistante ! Essayons de changer cela et de r√©ajuster le mod√®le :

```
model = TFAutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=3)
model.compile(optimizer='adam')
model.fit(train_dataset)
```

```python out
  869/24543 [>.............................] - ETA: 15:29 - loss: 1.1032
```

On entra√Æne ! Plus de `nan` et nos pertes diminuent... en quelque sorte. Si vous regardez pendant un certain temps, vous pouvez commencer √† vous impatienter car la valeur des pertes reste obstin√©ment √©lev√©e. Arr√™tons l'entra√Ænement ici et essayons de r√©fl√©chir √† ce qui pourrait causer ce probl√®me. √Ä ce stade, nous sommes pratiquement s√ªrs que les donn√©es et le mod√®le sont corrects, mais notre mod√®le n'apprend pas bien. Que reste-t-il d'autre ? Il est temps de...

### V√©rifier les hyperparam√®tres

Si vous regardez le code ci-dessus, vous ne verrez peut-√™tre aucun hyperparam√®tre, sauf peut-√™tre le `batch_size` qui ne semble pas √™tre un coupable probable. Cependant, ne soyez pas dupe, il y a toujours des hyperparam√®tres. Si vous ne pouvez pas les voir, cela signifie simplement que vous ne connaissez pas leur r√©glage. En particulier, souvenez-vous d'une chose essentielle √† propos de Keras : si vous d√©finissez une fonction de perte, d'optimisation ou d'activation avec une cha√Æne, _tous ses arguments seront d√©finis sur leurs valeurs par d√©faut_. Cela signifie que, m√™me si l'utilisation de cha√Ænes de caract√®res est tr√®s pratique, vous devez √™tre tr√®s prudent car cela peut facilement vous cacher des √©l√©ments critiques. (Toute personne essayant le d√©fi optionnel ci-dessus devrait prendre bonne note de ce fait).

Dans ce cas, o√π avons-nous d√©fini un argument avec une cha√Æne de caract√®res ? Au d√©part, nous d√©finissions la perte avec une cha√Æne de caract√®res, mais nous ne le faisons plus. Cependant, nous le faisons pour l'optimiseur. Cela pourrait-il nous cacher quelque chose ? Jetons un coup d'≈ìil √† [ses arguments](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam).

Y a-t-il quelque chose qui ressort ? C'est exact : le taux d'apprentissage ! Lorsque nous indiquons simplement `'adam'` nous allons obtenir le taux d'apprentissage par d√©faut qui est de 0.001 (ou 1e-3). C'est beaucoup trop √©lev√© pour un *transformer* ! En g√©n√©ral, nous recommandons d'essayer des taux d'apprentissage entre 1e-5 et 1e-4 pour vos mod√®les soit entre 10X et 100X plus petit que la valeur que nous utilisons ici. Cela semble √™tre un probl√®me majeur, alors essayons de le r√©duire. Pour ce faire, nous devons importer l'objet `optimizer`. Pendant que nous y sommes, r√©initialisons le mod√®le √† partir du *checkpoint* au cas o√π l'entra√Ænement avec un taux d'apprentissage √©lev√© aurait endommag√© ses poids :

```python
from tensorflow.keras.optimizers import Adam

model = TFAutoModelForSequenceClassification.from_pretrained(model_checkpoint)
model.compile(optimizer=Adam(5e-5))
```

<Tip>

üí° Vous pouvez √©galement importer la fonction `create_optimizer()` de ü§ó <i>Transformers</i> qui vous donnera un optimiseur AdamW avec une d√©croissance du taux des poids correcte ainsi qu'un r√©chauffement et une d√©croissance du taux d'apprentissage. Cet optimiseur produira souvent des r√©sultats l√©g√®rement meilleurs que ceux que vous obtenez avec l'optimiseur Adam par d√©faut.

</Tip>

Maintenant, nous pouvons essayer de *finetuner* le mod√®le avec le nouveau taux d'apprentissage :

```python
model.fit(train_dataset)
```

```python out
319/24543 [..............................] - ETA: 16:07 - loss: 0.9718
```

Maintenant notre perte va vraiment aller quelque part ! L'entra√Ænement semble enfin fonctionner. Il y a une le√ßon √† tirer ici : lorsque votre mod√®le fonctionne mais que la perte ne diminue pas, et que vous √™tes s√ªr que vos donn√©es sont correctes, c'est une bonne id√©e de v√©rifier les hyperparam√®tres comme le taux d'apprentissage et le taux de d√©croissance des poids. Un r√©glage trop √©lev√© de l'un ou l'autre de ces param√®tres risque fort de faire ¬´ caler ¬ª  l'entra√Ænement √† une valeur de perte √©lev√©e.

## Autres probl√®mes potentiels 

Nous avons couvert les probl√®mes dans le script ci-dessus, mais il existe plusieurs autres erreurs courantes auxquelles vous pouvez √™tre confront√©. Jetons un coup d'oeil √† une liste (tr√®s incompl√®te).

### G√©rer les erreurs de manque de m√©moire

Le signe r√©v√©lateur d'un manque de m√©moire est une erreur du type "OOM when allocating tensor" (OOM √©tant l'abr√©viation de *out of memory*). Il s'agit d'un risque tr√®s courant lorsque l'on utilise de grands mod√®les de langage. Si vous rencontrez ce probl√®me, une bonne strat√©gie consiste √† diviser par deux la taille de votre batch et √† r√©essayer. Gardez √† l'esprit, cependant, que certains mod√®les sont *tr√®s* grands. Par exemple, le mod√®le GPT-2 complet poss√®de 1,5 Go de param√®tres, ce qui signifie que vous aurez besoin de 6 Go de m√©moire rien que pour stocker le mod√®le, et 6 autres Go pour ses gradients ! Entra√Æner le mod√®le GPT-2 complet n√©cessite g√©n√©ralement plus de 20 Go de VRAM, quelle que soit la taille du batch utilis√©, ce dont seuls quelques GPUs sont dot√©s. Des mod√®les plus l√©gers comme `distilbert-base-cased` sont beaucoup plus faciles √† ex√©cuter et s'entra√Ænent aussi beaucoup plus rapidement.

<Tip>

Dans la prochaine partie du cours, nous examinerons des techniques plus avanc√©es qui peuvent vous aider √† r√©duire votre empreinte m√©moire et vous permettre de <i>finetuner</i> les plus grands mod√®les.

</Tip>

### TensorFlow affam√© ü¶õ

Une bizarrerie particuli√®re de TensorFlow dont vous devez √™tre conscient est qu'il s'alloue *toute* la m√©moire de votre GPU d√®s que vous chargez un mod√®le ou que vous effectuez un entra√Ænement. Puis il divise cette m√©moire selon les besoins. Ce comportement est diff√©rent de celui d'autres *frameworks*, comme PyTorch, qui alloue la m√©moire selon les besoins avec CUDA plut√¥t que de le faire en interne. L'un des avantages de l'approche de TensorFlow est qu'elle peut souvent donner des erreurs utiles lorsque vous manquez de m√©moire et qu'elle peut r√©cup√©rer de cet √©tat sans planter tout le noyau CUDA. Mais il y a aussi un inconv√©nient important : si vous ex√©cutez deux processus TensorFlow en m√™me temps alors **vous allez passer un mauvais moment**.

Si vous travaillez sur Colab, vous n'avez pas √† vous soucier de cela. Si vous travaillez localement, vous devez absolument faire attention. En particulier, sachez que la fermeture d'un onglet de *notebook* n'entra√Æne pas n√©cessairement la fermeture de ce *notebook* ! Vous devrez peut-√™tre s√©lectionner les *notebooks* en cours d'ex√©cution (ceux qui ont une ic√¥ne verte) et les fermer manuellement dans la liste des r√©pertoires. Tout *notebook* en cours d'ex√©cution qui utilisait TensorFlow peut encore utiliser une grande partie de la m√©moire de votre GPU, ce qui signifie que tout nouveau *notebook* que vous d√©marrez peut rencontrer des probl√®mes tr√®s √©tranges.

Si vous commencez √† obtenir des erreurs concernant CUDA, BLAS ou cuBLAS dans du code qui fonctionnait auparavant, c'est tr√®s souvent le coupable. Vous pouvez utiliser une commande comme `nvidia-smi` pour v√©rifier si la plupart de votre m√©moire est libre ou toujours utilis√©e. Si elle est toujours utilis√©e, c'est que quelque chose d'autre s'y accroche !


### V√©rifiez vos donn√©es (encore !)

Votre mod√®le n'apprendra quelque chose que s'il est r√©ellement possible d'apprendre quelque chose de vos donn√©es. S'il y a un *bug* qui corrompt les donn√©es ou si les √©tiquettes sont attribu√©es de mani√®re al√©atoire, il est tr√®s probable que vous n'obtiendrez aucun entra√Ænement de mod√®le sur votre jeu de donn√©es. Un outil utile ici est `tokenizer.decode()`. Il transformera les `input_ids` en cha√Ænes de caract√®res, afin que vous puissiez visualiser les donn√©es et voir si vos donn√©es d'entra√Ænement renseignent ce que vous voulez. Par exemple, apr√®s avoir obtenu un `batch` de votre `tf.data.Dataset` comme nous l'avons fait ci-dessus, vous pouvez d√©coder le premier √©l√©ment comme suit :


```py
input_ids = batch["input_ids"].numpy()
tokenizer.decode(input_ids[0])
```

Vous pouvez ensuite la comparer avec la premi√®re √©tiquette, comme suit :

```py
labels = batch["labels"].numpy()
label = labels[0]
```

Une fois que vous pouvez visualiser vos donn√©es de cette mani√®re, vous pouvez vous poser les questions suivantes :

- les donn√©es d√©cod√©es sont-elles compr√©hensibles ?
- √™tes-vous d'accord avec les √©tiquettes ?
- y a-t-il une √©tiquette qui est plus courante que les autres ?
- quelle devrait √™tre la perte/m√©trique si le mod√®le pr√©disait une r√©ponse al√©atoire/toujours la m√™me r√©ponse ?

Apr√®s avoir examin√© vos donn√©es, examinez quelques-unes des pr√©dictions du mod√®le. Si votre mod√®le produit des *tokens*, essayez aussi de les d√©coder ! Si le mod√®le pr√©dit toujours la m√™me chose, cela peut √™tre d√ª au fait que votre jeu de donn√©es est biais√© en faveur d'une cat√©gorie (pour les probl√®mes de classification). Des techniques telles que le sur√©chantillonnage des classes rares peuvent aider. D'autre part, cela peut √©galement √™tre d√ª √† des probl√®mes d'entra√Ænement tels que de mauvais r√©glages des hyperparam√®tres.

Si la perte/la m√©trique que vous obtenez sur votre mod√®le initial avant entra√Ænement est tr√®s diff√©rente de la perte/la m√©trique √† laquelle vous vous attendez pour des pr√©dictions al√©atoires, v√©rifiez la fa√ßon dont votre perte ou votre m√©trique est calcul√©e. Il y a probablement un bug. Si vous utilisez plusieurs pertes que vous ajoutez √† la fin, assurez-vous qu'elles sont de la m√™me √©chelle.

Lorsque vous √™tes s√ªr que vos donn√©es sont parfaites, vous pouvez voir si le mod√®le est capable de s'entra√Æner sur elles gr√¢ce √† un test simple.

### Surentra√Ænement du mod√®le sur un seul batch

Le surentra√Ænement est g√©n√©ralement une chose que nous essayons d'√©viter lors de l'entra√Ænement car cela signifie que le mod√®le n'apprend pas √† reconna√Ætre les caract√©ristiques g√©n√©rales que nous voulons qu'il reconnaisse et se contente de m√©moriser les √©chantillons d'entra√Ænement. Cependant, essayer d'entra√Æner votre mod√®le sur un batch encore et encore est un bon test pour v√©rifier si le probl√®me tel que vous l'avez formul√© peut √™tre r√©solu par le mod√®le que vous essayez d'entra√Æner. Cela vous aidera √©galement √† voir si votre taux d'apprentissage initial est trop √©lev√©.

Une fois que vous avez d√©fini votre `mod√®le`, c'est tr√®s facile. Il suffit de prendre un batch de donn√©es d'entra√Ænement, puis de le traiter comme votre jeu de donn√©es entier que vous *finetunez* sur un grand nombre d'√©poques :


```py
for batch in train_dataset:
    break

# Assurez-vous que vous avez ex√©cut√© model.compile() et d√©fini votre optimiseur,
# et vos pertes/m√©triques si vous les utilisez.

model.fit(batch, epochs=20)
```

<Tip>

üí° Si vos donn√©es d'entra√Ænement ne sont pas √©quilibr√©es, veillez √† cr√©er un batch de donn√©es d'entra√Ænement contenant toutes les √©tiquettes.

</Tip>

Le mod√®le r√©sultant devrait avoir des r√©sultats proches de la perfection sur le `batch`, avec une perte diminuant rapidement vers 0 (ou la valeur minimale pour la perte que vous utilisez).

Si vous ne parvenez pas √† ce que votre mod√®le obtienne des r√©sultats parfaits comme celui-ci, cela signifie qu'il y a quelque chose qui ne va pas dans la fa√ßon dont vous avez formul√© le probl√®me ou dans vos donn√©es et vous devez donc y rem√©dier. Ce n'est que lorsque vous parviendrez √† passer le test de surentra√Ænement que vous pourrez √™tre s√ªr que votre mod√®le peut r√©ellement apprendre quelque chose.

<Tip warning={true}>

‚ö†Ô∏è Vous devrez recr√©er votre mod√®le et votre `Trainer` apr√®s ce test, car le mod√®le obtenu ne sera probablement pas capable de r√©cup√©rer et d'apprendre quelque chose d'utile sur votre jeu de donn√©es complet.

</Tip>

### Ne r√©glez rien tant que vous n'avez pas une premi√®re ligne de base

Le r√©glage des hyperparam√®tres est toujours consid√©r√© comme la partie la plus difficile de l'apprentissage automatique mais c'est juste la derni√®re √©tape pour vous aider √† gagner un peu sur la m√©trique. La plupart du temps, les hyperparam√®tres par d√©faut du `Trainer` fonctionneront tr√®s bien pour vous donner de bons r√©sultats. Donc ne vous lancez pas dans une recherche d'hyperparam√®tres longue et co√ªteuse jusqu'√† ce que vous ayez quelque chose qui batte la ligne de base que vous avez sur votre jeu de donn√©es.

Une fois que vous avez un mod√®le suffisamment bon, vous pouvez commencer √† le *finetuner* un peu. N'essayez pas de lancer un millier d'ex√©cutions avec diff√©rents hyperparam√®tres mais comparez quelques ex√©cutions avec diff√©rentes valeurs pour un hyperparam√®tre afin de vous faire une id√©e de celui qui a le plus d'impact.

Si vous modifiez le mod√®le lui-m√™me, restez simple et n'essayez rien que vous ne puissiez raisonnablement justifier. Veillez toujours √† revenir au test de surentra√Ænement pour v√©rifier que votre modification n'a pas eu de cons√©quences inattendues.

### Demander de l'aide

Nous esp√©rons que vous avez trouv√© dans cette section des conseils qui vous ont aid√© √† r√©soudre votre probl√®me. Si ce n'est pas le cas, n'oubliez pas que vous pouvez toujours demander de l'aide √† la communaut√© sur le [forum](https://discuss.huggingface.co/). 

Voici quelques ressources (en anglais) suppl√©mentaires qui peuvent s'av√©rer utiles :

- [La reproductibilit√© comme vecteur des meilleures pratiques d'ing√©nierie](https://docs.google.com/presentation/d/1yHLPvPhUs2KGI5ZWo0sU-PKU3GimAk3iTsI38Z-B5Gw/edit#slide=id.p) par Joel Grus
- [Liste de contr√¥le pour le d√©bogage des r√©seaux de neurones](https://towardsdatascience.com/checklist-for-debugging-neural-networks-d8b2a9434f21) par Cecelia Shao
- [Comment tester unitairement le code d'apprentissage automatique](https://medium.com/@keeper6928/how-to-unit-test-machine-learning-code-57cf6fd81765) par Chase Roberts
- [Une recette pour entra√Æner les r√©seaux de neurones](http://karpathy.github.io/2019/04/25/recipe/) par Andrej Karpathy

Bien s√ªr, tous les probl√®mes rencontr√©s lors de l'entra√Ænement ne sont pas forc√©ment de votre faute ! Si vous rencontrez quelque chose dans la biblioth√®que ü§ó *Transformers* ou ü§ó *Datasets* qui ne semble pas correct, vous avez peut-√™tre trouver un *bug*. Vous devez absolument nous en parler pour qu'on puisse le corriger. Dans la section suivante, nous allons vous expliquer exactement comment faire.
