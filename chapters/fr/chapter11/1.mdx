# Finetuning supervis√©

Dans [la section 2 du chapitre 2](/course/fr/chapter2/2), nous avons vu que les mod√®les de langage g√©n√©ratifs peuvent √™tre finetun√©s sur des t√¢ches sp√©cifiques telles que le r√©sum√© et la r√©ponse aux questions. Cependant, de nos jours, il est beaucoup plus courant de finetuner les mod√®les de langage sur un large √©ventail de t√¢ches simultan√©ment ; une m√©thode connue sous le nom de *finetuning* supervis√© (SFT pour *supervised fine-tuning*). Ce processus permet aux mod√®les de devenir plus polyvalents et capables de g√©rer divers cas d'utilisation. La plupart des grands mod√®les de langage avec lesquels les individus interagissent sur des plateformes telles que ChatGPT ont √©t√© soumis √† un SFT afin de les rendre plus utiles et de les aligner sur les pr√©f√©rences humaines. Ce chapitre est divis√© en quatre sections :

## 1Ô∏è‚É£ Gabarits de chat (*chat template*)

Les gabarits de chat structurent les interactions entre les utilisateurs et les mod√®les d'IA, garantissant des r√©ponses coh√©rentes et appropri√©es. Ils comprennent des √©l√©ments tels que les instructions (*prompts* en anglais) du syst√®me et des balises attribuant les tours de r√¥le.

## 2Ô∏è‚É£ *Finetuning* supervis√©

Le *finetuning* supervis√© est un processus essentiel pour adapter les mod√®les de langage pr√©-entra√Æn√©s √† des t√¢ches sp√©cifiques. Il s'agit d'entra√Æner le mod√®le sur un jeu de donn√©es sp√©cifique √† la t√¢che avec des exemples √©tiquet√©s. Pour un guide d√©taill√© sur le *finetuning*, y compris les √©tapes cl√©s et les meilleures pratiques, voir [la section sur le *finetuning* supervis√© de la documentation de la biblioth√®que *TRL*](https://huggingface.co/docs/trl/en/sft_trainer).

## 3Ô∏è‚É£ *Low Rank Adaptation* (LoRA)

*Low Rank Adaptation* (LoRA) est une technique de *finetuning* ajoutant des matrices de rangs inf√©rieurs aux couches du mod√®le de langage. Cela permet un *finetuning* efficace tout en pr√©servant les connaissances pr√©-entra√Æn√©es du mod√®le. L'un des principaux avantages de la m√©thode LoRA r√©side dans les √©conomies de m√©moire consid√©rables qu'elle offre, ce qui permet de finetuner des mod√®les de grande taille sur des ressources mat√©rielles limit√©es.

## 4Ô∏è‚É£ √âvaluation

L'√©valuation est une √©tape cruciale du processus de *finetuning*. Elle nous permet de mesurer les performances du mod√®le sur un jeu de donn√©es sp√©cifique √† une t√¢che.

<Tip>
‚ö†Ô∏è Afin de b√©n√©ficier de toutes les fonctionnalit√©s disponibles du Hub d'Hugging Face et  de ü§ó *Transformers*, nous recommandons <a href="https://huggingface.co/join">la cr√©ation d'un compte</a>.</Tip>

## R√©ferences

- [La documentation de *Transformers* sur les gabarits de chat](https://huggingface.co/docs/transformers/main/en/chat_templating)
- [Script pour le *finetuning* supervis√© dans *TRL*](https://github.com/huggingface/trl/blob/main/trl/scripts/sft.py)
- [`SFTTrainer` dans *TRL*](https://huggingface.co/docs/trl/main/en/sft_trainer)
- [Papier de la m√©thode *Direct Preference Optimization* (DPO)](https://arxiv.org/abs/2305.18290)
- [La documentation de *TRL* sur le *finetuning* supervis√©](https://huggingface.co/docs/trl/sft_trainer)
- [Comment finetuner le mod√®le Gemma de Google avec *ChatML* et *TRL*](https://github.com/huggingface/alignment-handbook)  
- [*Finetuning* d'un LLM pour g√©n√©rer des catalogues de produits en persan au format JSON](https://huggingface.co/learn/cookbook/en/fine_tuning_llm_to_generate_persian_product_catalogs_in_json_format)
