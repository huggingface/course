<CourseFloatingBanner chapter={11}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "English", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter11/section3.ipynb"},
	{label: "Fran√ßais", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter10/section3.ipynb"},
    {label: "English", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/fr/chapter11/section3.ipynb"},
    {label: "Fran√ßais", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/fr/chapter11/section3.ipynb"},
]} />

# *Finetuning* supervis√©

Le *finetuning* supervis√© (SFT) est un processus principalement utilis√© pour adapter des mod√®les de langage pr√©-entra√Æn√©s afin qu'ils suivent des instructions, engagent un dialogue et utilisent des formats de sortie sp√©cifiques. Alors que les mod√®les pr√©-entra√Æn√©s ont des capacit√©s g√©n√©rales impressionnantes, le SFT permet de les transformer en mod√®les de type assistant qui peuvent mieux comprendre et r√©pondre aux instructions de l'utilisateur. Pour ce faire, il faut g√©n√©ralement entra√Æner sur des jeux de donn√©es de conversations et d'instructions √©crites par des humains.

Cette page fournit un guide √©tape par √©tape pour finetuner le mod√®le [`deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B`](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B) en utilisant le [`SFTTrainer`](https://huggingface.co/docs/trl/en/sft_trainer). En suivant ces √©tapes, vous pouvez adapter le mod√®le pour effectuer des t√¢ches sp√©cifiques plus efficacement. 

## Quand utiliser le SFT ?

Avant de se lancer dans son impl√©mentation, il est important de comprendre quand le SFT est le bon choix pour votre projet. Dans un premier temps, vous devez vous demander si l'utilisation d'un mod√®le existant instruit avec des instructions bien con√ßues suffirait pour votre cas d'utilisation. Le SFT implique des ressources de calcul et des efforts d'ing√©nierie consid√©rables, et ne doit donc √™tre envisag√© que lorsque les instructions des mod√®les existants s'av√®rent insuffisantes.

<Tip>
N'envisagez le SFT que si vous :
- Vous avez besoin de performances suppl√©mentaires par rapport √† ce que les instructions peuvent r√©aliser.<br>
- Vus avez un cas d'utilisation sp√©cifique pour lequel le co√ªt d'utilisation d'un grand mod√®le polyvalent l'emporte sur le co√ªt du *finetuning* d'un mod√®le plus petit<br>
- Vous avez besoin de formats de sortie sp√©cialis√©s ou de connaissances sp√©cifiques √† un domaine que les mod√®les existantsne ma√Ætrisent pas.
</Tip>

Si vous d√©terminez que le SFT est n√©cessaire, la d√©cision de proc√©der d√©pend de deux facteurs principaux :

### Contr√¥le des gabarits
Le SFT permet un contr√¥le pr√©cis de la structure de sortie du mod√®le. Ceci est particuli√®rement utile lorsque vous avez besoin que le mod√®le :
1. G√©n√©re des r√©ponses dans un format de gabarits de chat sp√©cifique.
2. Suivre des sch√©mas de sortie stricts
3. Maintenir un style coh√©rent dans les r√©ponses

### Adaptation au domaine
Lorsque l'on travaille dans des domaines sp√©cialis√©s, le SFT permet d'aligner le mod√®le sur les imp√©ratifs propres au domaine en :
1. Enseignant la terminologie et les concepts du domaine
2. Appliquant les normes professionnelles
3. Traitant les questions techniques de mani√®re appropri√©e
4. Suivant les lignes directrices sp√©cifiques √† l'industrie

<Tip>
Avant de commencer √† utiliser le SFT, √©valuez si votre cas d'utilisation n√©cessite :<br>
- un formatage pr√©cis des r√©sultats<br>
- des connaissances sp√©cifiques √† un domaine<br>
- des sch√©mas de r√©ponse coh√©rents<br>
- le respect de lignes directrices sp√©cifiques.

Cette √©valuation vous aidera √† d√©terminer si le SFT est la bonne approche pour vos besoins.
</Tip>

## Pr√©paration du jeu de donn√©es

Le processus de *finetuning* supervis√© n√©cessite un jeu de donn√©es sp√©cifique √† la t√¢che, structur√© avec des paires entr√©e-sortie. Chaque paire doit comprendre
1. Une instruction d'entr√©e
2. La r√©ponse attendue du mod√®le
3. Tout contexte ou m√©tadonn√©e suppl√©mentaire

La qualit√© de vos donn√©es d'entra√Ænement est cruciale pour un *finetuning* r√©ussi. Voyons comment pr√©parer et valider votre jeu de donn√©es :

<iframe
  src="https://huggingface.co/datasets/HuggingFaceTB/smoltalk/embed/viewer/all/train?row=0"
  frameborder="0"
  width="100%"
  height="360px"
></iframe>

## Configuration de l'entra√Ænement

La configuration de `SFTTrainer` n√©cessite la prise en compte de plusieurs param√®tres qui contr√¥lent le processus d`entrainement. Examinons chaque param√®tre et son utilit√© :

1. **Param√®tres concernant la dur√©e de l'entra√Ænement**:
   - `num_train_epochs`: Contr√¥le la dur√©e totale de l'entra√Ænement
   - `max_steps`: Alternative aux √©poques, d√©finit le nombre maximum d'√©tapes d'entra√Ænement.
   - Un plus grand nombre d'√©poques permet un meilleur apprentissage, mais risque d'entra√Æner un surentra√Ænement.

2. **Param√®tres concernant la taille des batchs**:
   - `per_device_train_batch_size`: D√©termine l'utilisation de la m√©moire et la stabilit√© de l'entra√Ænement
   - `gradient_accumulation_steps`: Permet d'augmenter la taille des batchs
   - Des lots batchs plus grands permettent d'obtenir des gradients plus stables mais n√©cessitent plus de m√©moire

3. **Param√®tres concernant le taux d'apprentissage**:
   - `learning_rate`: Contr√¥le les mises √† jour de la taille des poids
   - `warmup_ratio`: Partie de l'entra√Ænement utilis√©e pour l'√©chauffement du taux d'apprentissage
   - Un taux trop √©lev√© peut provoquer une instabilit√©, un taux trop faible entra√Æne un apprentissage lent.

4. **Param√®tres de contr√¥le**:
   - `logging_steps`: Fr√©quence de l'enregistrement des m√©triques
   - `eval_steps`: Fr√©quence d'√©valuation sur les donn√©es de validation
   - `save_steps`: Fr√©quence des sauvegardes des points de contr√¥le du mod√®le

<Tip>
Commencez par des valeurs prudentes et ajustez-les en fonction du contr√¥le :
- Commencer avec 1-3 √©poques<br>
- Utiliser des batchs de plus petite taille dans un premier temps<br>
- Surveiller de pr√®s les m√©triques de validation<br>
- Ajuster le taux d'apprentissage si l'entra√Ænement est instable<br>
</Tip>

## Impl√©mentation avec TRL

Maintenant que nous comprenons les composants cl√©s, mettons en ≈ìuvre l'entra√Ænement avec une validation et un suivi appropri√©s. Nous allons utiliser la classe `SFTTrainer` de la biblioth√®que *Transformers Reinforcement Learning* (TRL), qui est construite au-dessus de la biblioth√®que ü§ó *Transformers*. Voici un exemple complet utilisant la biblioth√®que TRL :

```python
from datasets import load_dataset
from trl import SFTConfig, SFTTrainer
import torch

# D√©finir l'appareil
device = "cuda" if torch.cuda.is_available() else "cpu"

# Charger le jeu de donn√©es
dataset = load_dataset("HuggingFaceTB/smoltalk", "all")

# Configurer les arguments de la classe Trainer
training_args = SFTConfig(
    output_dir="./sft_output",
    max_steps=1000,
    per_device_train_batch_size=4,
    learning_rate=5e-5,
    logging_steps=10,
    save_steps=100,
    eval_strategy="steps",
    eval_steps=50,
)

# Initialisation de la classe Trainer
trainer = SFTTrainer(
    model=model,
    args=training_args,
    train_dataset=dataset["train"],
    eval_dataset=dataset["test"],
    processing_class=tokenizer,
)

# D√©buter l'entra√Ænement
trainer.train()
```

<Tip>
Lorsqu'on utilise un jeu de donn√©es avec un champ ¬´ messages ¬ª (comme l'exemple ci-dessus), SFTTrainer applique automatiquement le gabarit de chat du mod√®le depuis le <i>Hub</i>. Cela signifie que vous n'avez pas besoin de configuration suppl√©mentaire pour g√©rer les conversations de type chat : la classe Trainer formatera les messages selon le format de gabarits attendu par le mod√®le.
</Tip>

## Empaquetage du jeu de donn√©es

SFTTrainer supporte l'empaquetage des exemples afin d'optimiser l'efficacit√© de l'entra√Ænement. Cette fonctionnalit√© permet de regrouper plusieurs exemples courts dans la m√™me s√©quence d'entr√©e, maximisant ainsi l'utilisation du GPU pendant l'entra√Ænement. Pour activer cette fonctionnalit√©, il suffit de mettre `packing=True` dans le constructeur SFTConfig. Lorsque vous utilisez des jeux de donn√©es avec `max_steps`, soyez conscient que vous pouvez entra√Æner pendant plus d'√©poques que pr√©vu en fonction de votre configuration d'empaquetage. Vous pouvez personnaliser la fa√ßon dont les exemples sont combin√©s en utilisant une fonction de formatage. C'est particuli√®rement utile lorsque vous travaillez avec des jeux de donn√©es qui ont plusieurs champs comme les paires question-r√©ponse. Pour les jeux de donn√©es d'√©valuation, vous pouvez d√©sactiver l'empaquetage en r√©glant `eval_packing=False` dans SFTConfig. Voici un exemple basique de personnalisation de la configuration d'empaquetage :

```python
# Configuration
training_args = SFTConfig(packing=True)

trainer = SFTTrainer(model=model, train_dataset=dataset, args=training_args)

trainer.train()
```

Lorsque le jeu de donn√©es est rempli de plusieurs champs, vous pouvez d√©finir une fonction de formatage personnalis√©e pour combiner les champs en une seule s√©quence d'entr√©e. Cette fonction doit prendre une liste d'exemples et renvoyer un dictionnaire contenant la s√©quence d'entr√©e condens√©e. Voici un exemple de fonction de formatage personnalis√©e :

```python
def formatting_func(example):
    text = f"### Question: {example['question']}\n ### Answer: {example['answer']}"
    return text


training_args = SFTConfig(packing=True)
trainer = SFTTrainer(
    "facebook/opt-350m",
    train_dataset=dataset,
    args=training_args,
    formatting_func=formatting_func,
)
```

## Suivi des progr√®s de l'entra√Ænement

Un suivi efficace est essentiel pour un *finetuning* r√©ussi. Voyons ce qu'il faut surveiller pendant l'entra√Ænement :

### Comprendre les sch√©mas de la perte

La fonction de perte de l'entra√Ænement suit g√©n√©ralement trois phases distinctes :
1. Chute brutale initiale : Adaptation rapide √† la nouvelle distribution des donn√©es
2. Stabilisation progressive : Le taux d'apprentissage ralentit au fur et √† mesure du *finetuning* du mod√®le.
3. Convergence : Les valeurs de la perte se stabilisent, ce qui indique que l'entra√Ænement est termin√©.

<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/nlp_course_sft_loss_graphic.png" alt="SFTTrainer Training" />

### M√©triques √† surveiller

Un suivi efficace implique le traquage de param√®tres quantitatifs et l'√©valuation de param√®tres qualitatifs. Les mesures disponibles sont les suivantes :
- Perte d'entra√Ænement
- Perte de validation
- Progression du taux d'apprentissage
- Normes du gradient

<Tip warning={true}>
Soyez attentif √† ces signes d'alerte pendant l'entra√Ænement :<br>
1. La perte de validation augmente alors que la perte d'entra√Ænement diminue (surentra√Ænement)<br>
2. Pas d'am√©lioration significative des valeurs de la perte (sousentra√Ænement)<br>
3. Valeurs de perte extr√™mement faibles (m√©morisation potentielle)<br>
4. Formatage incoh√©rent des r√©sultats (probl√®mes d'apprentissage des gabarits)
</Tip>

### Le chemin vers la convergence

Au fur et √† mesure que l'entra√Ænement progresse, les courbes des pertes devraientt se stabiliser progressivement. L'indicateur cl√© d'un entra√Ænement sain est un faible √©cart entre la perte d'entra√Ænement et la perte de validation, ce qui sugg√®re que le mod√®le apprend des sch√©mas g√©n√©ralisables plut√¥t que de m√©moriser des exemples sp√©cifiques. Les valeurs de perte absolues varient en fonction de la t√¢che et de le jeu de donn√©es.

### Suivi de la progression de l'entra√Ænement

Le graphique ci-dessus illustre une progression typique de l'entra√Ænement. Remarquez que les pertes d'entra√Ænement et de validation diminuent fortement au d√©but, puis se stabilisent progressivement. Ce sch√©ma indique que le mod√®le apprend efficacement tout en conservant sa capacit√© de g√©n√©ralisation.

### Signes d'alerte √† surveiller

Plusieurs sch√©mas dans les courbes de perte peuvent indiquer des probl√®mes potentiels. Nous illustrons ci-dessous les signes d'alerte courants et les solutions que nous pouvons envisager.

<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/sft_loss_1.png" alt="SFTTrainer Training" />

Si la perte de validation diminue √† un rythme nettement plus lent que la perte d'entra√Ænement, votre mod√®le est probablement surentra√Æn√© par rapport aux donn√©es d'entra√Ænement. Envisagez de :
- R√©duire le nombres d'√©tapes de l'entra√Ænement
- Augmenter la taille du jeu de donn√©es
- Valider la qualit√© et la diversit√© du jeu de donn√©es

<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/sft_loss_2.png" alt="SFTTrainer Training" />

Si la perte ne montre pas d'am√©lioration significative, le mod√®le pourrait :
- Apprendre trop lentement (essayez d'augmenter le taux d'apprentissage)
- Avoir des difficult√©s avec la t√¢che (v√©rifiez la qualit√© des donn√©es et la complexit√© de la t√¢che)
- Se heurter aux limites de l'architecture (envisager un autre mod√®le)

<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/sft_loss_3.png" alt="SFTTrainer Training" />

Des valeurs de perte extr√™mement faibles peuvent sugg√©rer une m√©morisation plut√¥t qu'un apprentissage. Ceci est particuli√®rement inqui√©tant si
- Le mod√®le donne des r√©sultats m√©diocres sur de nouveaux exemples similaires.
- Les r√©sultats manquent de diversit√©
- Les r√©ponses sont trop similaires aux exemples d'entra√Ænement.

<Tip warning={true}>
Surveillez √† la fois les valeurs de perte et les sorties r√©elles du mod√®le pendant l'entra√Ænement. Parfois, la perte peut sembler bonne alors que le mod√®le d√©veloppe des comportements ind√©sirables. Une √©valuation qualitative r√©guli√®re des r√©ponses du mod√®le permet de d√©celer des probl√®mes que les mesures seules pourraient ne pas d√©celer.
</Tip>

Il convient de noter que l'interpr√©tation des valeurs de la perte que nous d√©crivons ici vise le cas le plus courant, et qu'en fait, elles peuvent se comporter de diverses mani√®res en fonction du mod√®le, du jeu de donn√©es, des param√®tres d'entra√Ænement, etc. Si vous souhaitez en savoir plus sur les sch√©mas d√©crits, nous vous invitons √† consulter cet article de blog de l'√©quipe de [Fast AI](https://www.fast.ai/posts/2023-09-04-learning-jumps/).

## √âvaluation apr√®s SFT

Dans la section [11.4](/fr/chapter11/4), nous apprendrons √† √©valuer le mod√®le √† l'aide de jeux de donn√©es d'√©valuation. Pour l'instant, nous nous concentrerons sur l'√©valuation qualitative du mod√®le.

Apr√®s avoir termin√© le SFT, envisagez les actions de suivi suivantes :
1. √âvaluer le mod√®le de mani√®re approfondie sur des donn√©es de test conserv√©es.
2. Valider le respect des gabarits pour les diff√©rentes donn√©es d'entr√©e.
3. Tester la r√©tention des connaissances sp√©cifiques au domaine
4. Contr√¥ler les mesures de performance dans le monde r√©el

<Tip>
Documentez votre processus d'entra√Ænement, y compris :
- Les caract√©ristiques du jeu de donn√©es
- Les param√®tres d'entra√Ænement
- Les m√©triques de performance
- Les limites connues.
Cette documentation sera pr√©cieuse pour les it√©rations futures du mod√®le.
</Tip>

## Quiz

### 1. Quels sont les param√®tres qui d√©terminent la dur√©e de l'entra√Ænement dans le cadre du SFT ?

<Question
	choices={[
		{
			text: "num_train_epochs et max_steps",
			explain: "C'est exact ! Ces param√®tres d√©terminent la dur√©e de l'entra√Ænement du mod√®le, soit par le nombre d'√©poques, soit par le nombre total d'√©tapes.",
			correct: true
		},
		{
			text: "batch_size et learning_rate",
			explain: "Si ces √©l√©ments ont une incidence sur l'entra√Ænement, ils n'en contr√¥lent pas directement la dur√©e."
		},
		{
			text: "gradient_checkpointing et warmup_ratio",
			explain: "Ces param√®tres ont une incidence sur l'efficacit√© et la stabilit√© de l'entra√Ænement, et non sur sa dur√©e."
		}
	]}
/>

### 2. Quelle sch√©ma dans les courbes de perte indique un surentra√Ænement potentiel ?

<Question
    choices={[
        {
            text: "La perte de validation augmente tandis que la perte d'entra√Ænement continue √† diminuer",
            explain: "C'est exact ! Cette divergence entre les pertes d'entra√Ænement et de validation est un signe classique de surentra√Ænement.",
            correct: true
        },
        {
            text: "Les pertes li√©es √† l'entra√Ænement et √† la validation diminuent r√©guli√®rement",
            explain: "Ce sch√©ma indique en fait un entra√Ænement sain."
        },
        {
            text: "La perte d'entra√Ænement reste constante alors que la perte de validation diminue",
            explain: "Il s'agit d'un sch√©ma inhabituel qui n'indique pas un surentra√Ænement."
        }
    ]}
/>

### 3. √Ä quoi sert la fonction gradient_accumulation_steps ?

<Question
    choices={[
        {
            text: "Pour augmenter la taille effective des batchs sans utiliser plus de m√©moire",
            explain: "C'est exact ! Il accumule les gradients sur plusieurs passages avant de mettre √† jour les poids.",
            correct: true
        },
        {
            text: "Pour enregistrer des checkpoints pendant l'entra√Ænement",
            explain: "Ceci est g√©r√© par les param√®tres save_steps et save_strategy."
        },
        {
            text: "Pour contr√¥ler le programme du taux d'apprentissage",
            explain: "Le programme du taux d'apprentissage est contr√¥l√©e par learning_rate et warmup_ratio."
        }
    ]}
/>

### 4. Que faut-il surveiller pendant l'entra√Ænement SFT ?

<Question
    choices={[
        {
            text: "Des mesures quantitatives et des r√©sultats qualitatifs",
            explain: "C'est exact ! Le contr√¥le des deux types de m√©triques permet de d√©tecter tous les probl√®mes potentiels.",
            correct: true
        },
        {
            text: "Seulement la perte d'entra√Ænement",
            explain: "La perte d'entra√Ænement ne suffit pas √† garantir un bon comportement du mod√®le."
        },
        {
            text: "Seulement la qualit√© des sorties du mod√®le",
            explain: "Bien qu'importante, l'√©valuation qualitative seule passe √† c√¥t√© d'une dynamique d'entra√Ænement importante."
        }
    ]}
/>

### 5. Qu'est-ce qui indique une convergence saine pendant l'entra√Ænement ?

<Question
    choices={[
        {
            text: "Un faible √©cart entre les pertes d'entra√Ænement et de validation",
            explain: "C'est exact ! Cela indique que le mod√®le apprend des sch√©mas g√©n√©ralisables.",
            correct: true
        },
        {
            text: "La perte d'entra√Ænement atteint z√©ro",
            explain: "Des valeurs de perte extr√™mement faibles peuvent indiquer une m√©morisation plut√¥t qu'un apprentissage."
        },
        {
            text: "Perte de validation inf√©rieure √† la perte d'entra√Ænement",
            explain: "Cela serait inhabituel et pourrait indiquer des probl√®mes avec l'ensemble de validation."
        }
    ]}
/>

## üíê Beau travail !

Vous avez appris √† finetuner des mod√®les √† l'aide du SFT ! Pour poursuivre votre apprentissage :
1. Essayez le *notebook* avec diff√©rents param√®tres
2. Exp√©rimentez avec d'autres jeux de donn√©es
3. Contribuer √† l'am√©lioration du mat√©riel de cours

## Additional Resources

- [Documentation de *TRL*](https://huggingface.co/docs/trl)
- [R√©pertoire contenant des exemples de SFT](https://github.com/huggingface/trl/blob/main/trl/scripts/sft.py)
- [Les bonnes pratiques pour le *finetuning*](https://huggingface.co/docs/transformers/training)
