<CourseFloatingBanner chapter={11}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "English", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter11/section2.ipynb"},
	{label: "Fran√ßais", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter10/section2.ipynb"},
    {label: "English", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/fr/chapter11/section2.ipynb"},
    {label: "Fran√ßais", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/fr/chapter11/section2.ipynb"},
]} />
# Gabarits de chat

## Introduction

Les gabarits de chat sont essentiels pour structurer les interactions entre les mod√®les de langage et les utilisateurs. Que vous construisiez un simple robot conversationnel ou un [agent complexe](https://huggingface.co/learn/agents-course/fr/unit0/introduction), il est essentiel de comprendre comment formater correctement vos conversations pour obtenir les meilleurs r√©sultats en utilisant votre mod√®le. Dans ce guide, nous allons explorer ce que sont les gabarits de chat, pourquoi ils sont importants et comment les utiliser efficacement.

<Tip>
Les gabarits de chat sont essentiels pour :<br>
- Maintenir une structure de conversation coh√©rente<br>
- Assurer une identification correcte des r√¥les<br>
- G√©rer le contexte √† travers plusieurs tours<br>
- Prendre en charge des fonctions avanc√©es telles que l'utilisation d'outils
</Tip>

## Types de mod√®les et gabarits

### Mod√®les de base vs. mod√®les instruits
Un mod√®le de base est entra√Æn√© sur des donn√©es textuelles brutes pour pr√©dire le prochain *token*, tandis qu'un mod√®le instruit est finetun√© sp√©cifiquement pour suivre des instructions et converser. Par exemple, [`SmolLM2-135M`](https://huggingface.co/HuggingFaceTB/SmolLM2-135M) est un mod√®le de base, tandis que [`SmolLM2-135M-Instruct`](https://huggingface.co/HuggingFaceTB/SmolLM2-135M-Instruct) est sa variante finetun√©e sur des instructions.  

Les mod√®les instruits sont entra√Æn√©s √† suivre une structure conversationnelle sp√©cifique, ce qui les rend plus adapt√©s aux applications de chatbot. De plus, les mod√®les d'instruction peuvent g√©rer des interactions complexes (y compris l'utilisation d'outils), les entr√©es multimodales et l'appel de fonctions.

Pour qu'un mod√®le de base se comporte comme un mod√®le instruit, nous devons formater nos instructions d'une mani√®re coh√©rente que le mod√®le peut comprendre. C'est l√† qu'interviennent les gabarits de chat. ChatML (pour *Chat Markup Language*) est un de ces gabarits qui structure les conversations avec des indicateurs de r√¥le clairs (syst√®me, utilisateur, assistant). Vous pouvez trouver un guide sur ChatML [ici](https://huggingface.co/HuggingFaceTB/SmolLM2-135M-Instruct/blob/e2c3f7557efbdec707ae3a336371d169783f1da1/tokenizer_config.json#L146).

<Tip warning={true}>
Lorsque vous utilisez un mod√®le instruit, v√©rifiez toujours que vous utilisez le bon format de gabarits de chat. L'utilisation d'un mauvais gabarit peut conduire √† de mauvaises performances du mod√®le ou √† un comportement inattendu. La fa√ßon la plus simple de s'en assurer est de v√©rifier la configuration du *tokenizer* du mod√®le sur le *Hub*. Par exemple, le mod√®le `SmolLM2-135M-Instruct` utilise <a href="https://huggingface.co/HuggingFaceTB/SmolLM2-135M-Instruct/blob/e2c3f7557efbdec707ae3a336371d169783f1da1/tokenizer_config.json#L146">cette configuration</a>.  
</Tip>

### Formats de gabarits courants

Avant de se plonger dans des impl√©mentations sp√©cifiques, il est important de comprendre le formatage des conversations attendu par diff√©rents mod√®les. Explorons quelques gabarits courants √† l'aide d'un simple exemple de conversation.

Nous utiliserons la structure de conversation suivante pour tous les exemples :

```python
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Hello!"},
    {"role": "assistant", "content": "Hi! How can I help you today?"},
    {"role": "user", "content": "What's the weather?"},
]
```

Voici le gabarit ChatML utilis√© dans des mod√®les tels que SmolLM2 et les Qwen 2 :

```python
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
Hello!<|im_end|>
<|im_start|>assistant
Hi! How can I help you today?<|im_end|>
<|im_start|>user
What's the weather?<|im_start|>assistant
```

Voici le format de gabarits utilis√© par Mistral :
```python
<s>[INST] You are a helpful assistant. [/INST]
Hi! How can I help you today?</s>
[INST] Hello! [/INST]
```

Les principales diff√©rences entre ces formats sont les suivantes :
1. **Gestion du message syst√®me** : 
   - Llama 2 ins√®re les messages du syst√®me dans des balises `<<SYS>>`
   - Llama 3 utilise des balises `<|system|>` avec des fins `</s>`
   - Mistral inclut un message syst√®me dans la premi√®re instruction
   - Qwen utilise le r√¥le `system` explicite avec les balises `<|im_start|>`
   - ChatGPT utilise le pr√©fixe `SYSTEM:`

2. **D√©limitation des messages**:
   - Llama 2 utilise les balises `[INST]` et `[/INST]`
   - Llama 3 utilise des balises sp√©cifiques pour chaque r√¥le (`<|system|>`, `<|user|>`, `<|assistant|>`) avec `</s>` comme fin
   - Mistral utilise `[INST]` et `[/INST]` avec `<s>` utilise `</s>`
   - Qwen utilise des *token* de d√©but et de fin sp√©cifiques pour chaque r√¥le

3. **Tokens sp√©ciaux**:
   - Llama 2 utilise `<s>` et `</s>` pour les limites de la conversation
   - Llama 3 utilise `</s>` pour terminer chaque message
   - Mistral utilise `<s>` et `</s>` pour les limites des tours
   - Qwen utilise des *token* de d√©but et de fin sp√©cifiques pour chaque r√¥le

Comprendre ces diff√©rences est essentiel pour travailler avec diff√©rents mod√®les. Voyons comment la biblioth√®que ü§ó *Transformers* nous aide √† g√©rer ces variations automatiquement :

```python
from transformers import AutoTokenizer

# Cela utilisera automatiquement des gabarits diff√©rents
mistral_tokenizer = AutoTokenizer.from_pretrained("mistralai/Mistral-7B-Instruct-v0.1")
qwen_tokenizer = AutoTokenizer.from_pretrained("Qwen/Qwen-7B-Chat")
smol_tokenizer = AutoTokenizer.from_pretrained("HuggingFaceTB/SmolLM2-135M-Instruct")

messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Hello!"},
]

# Chaque mod√®le sera format√© en fonction de son gabarit
mistral_chat = mistral_tokenizer.apply_chat_template(messages, tokenize=False)
qwen_chat = qwen_tokenizer.apply_chat_template(messages, tokenize=False)
smol_chat = smol_tokenizer.apply_chat_template(messages, tokenize=False)
```

<details>
<summary>Cliquer pour voir des exemples de gabarits</summary>

Gabarits ChatML de Qwen 2 et SmolLM2 :

```sh
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
Hello!<|im_end|>
<|im_start|>assistant
Hi! How can I help you today?<|im_end|>
<|im_start|>user
What's the weather?<|im_start|>assistant
```

Gabarit de Mistral :

```sh
<s>[INST] You are a helpful assistant. [/INST]
Hi! How can I help you today?</s>
[INST] Hello! [/INST]
```

</details>


### Fonctionnalit√©s avanc√©es
Les gabarits de chat peuvent g√©rer des sc√©narios plus complexes que les simples interactions conversationnelles, notamment :

1. **Utilisation d'outils** : lorsque les mod√®les doivent interagir avec des outils externes ou des API.
2. **Entr√©es multimodales** : pour g√©rer les images, le son ou d'autres types de m√©dias
3. **Appel de fonction** : pour l'ex√©cution de fonctions structur√©es
4. **Contexte multi-tour** : pour conserver l'historique des conversations

<Tip>
Lors de l'impl√©mentation de fonctions avanc√©es :
- Testez minutieusement votre mod√®le. Les applications de vision et les outils utilisent des gabarits particuli√®rement vari√©s.<br>
- Surveillez attentivement l'utilisation des <i>tokens</i> entre chaque fonctionnalit√© et chaque mod√®le.<br>
- Documenter le format attendu pour chaque fonctionnalit√©
</Tip>

Pour les conversations multimodales, les gabarits peuvent inclure des r√©f√©rences d'images ou des images cod√©es en base64 :
```python
messages = [
    {
        "role": "system",
        "content": "You are a helpful vision assistant that can analyze images.",
    },
    {
        "role": "user",
        "content": [
            {"type": "text", "text": "What's in this image?"},
            {"type": "image", "image_url": "https://example.com/image.jpg"},
        ],
    },
]
```

Voici un exemple de gabarits de chat avec l'utilisation d'un outil :

```python
messages = [
    {
        "role": "system",
        "content": "You are an AI assistant that can use tools. Available tools: calculator, weather_api",
    },
    {"role": "user", "content": "What's 123 * 456 and is it raining in Paris?"},
    {
        "role": "assistant",
        "content": "Let me help you with that.",
        "tool_calls": [
            {
                "tool": "calculator",
                "parameters": {"operation": "multiply", "x": 123, "y": 456},
            },
            {"tool": "weather_api", "parameters": {"city": "Paris", "country": "France"}},
        ],
    },
    {"role": "tool", "tool_name": "calculator", "content": "56088"},
    {
        "role": "tool",
        "tool_name": "weather_api",
        "content": "{'condition': 'rain', 'temperature': 15}",
    },
]
```

## Bonnes pratiques

### Principes g√©n√©raux
Lorsque vous travaillez avec des gabarits de chat, respectez les pratiques suivantes :

1. **Formatage coh√©rent** : Utilisez toujours le m√™me format de gabarits pour l'ensemble de votre application.
2. **D√©finition claire des r√¥les** : Sp√©cifiez clairement les r√¥les (syst√®me, utilisateur, assistant, outil) pour chaque message.
3. **Gestion du contexte** : Tenir compte de la limite du nombre de *tokens* lors de la gestion de l'historique des conversations.
4. **Gestion des erreurs** : Inclure une gestion appropri√©e des erreurs pour les appels d'outils et les entr√©es multimodales.
5. **Validation** : Valider la structure du message avant de l'envoyer au mod√®le


<Tip warning={true}>
Les pi√®ges √† √©viter :
- M√©langer diff√©rents gabarits dans la m√™me application<br>
- D√©passer la limite du nombre de <i>token</i> avec de longs historiques de conversation<br>
- Ne pas escamoter correctement les caract√®res sp√©ciaux dans les messages<br>
- Oublier de valider la structure des messages d'entr√©e<br>
- Ignorer les exigences de gabarits sp√©cifiques √† un mod√®le
</Tip>

## Exercice pratique

Entra√Ænons-nous √† mettre en ≈ìuvre des gabarits de chat √† l'aide d'un exemple concret.

<Tip>
Suivez les √©tapes suivantes pour convertir le jeu de donn√©es `HuggingFaceTB/smoltalk` au format ChatML :

1. Chargez le jeu de donn√©es :
```python
from datasets import load_dataset

dataset = load_dataset("HuggingFaceTB/smoltalk")
```

2. Cr√©er une fonction de traitement :
```python
def convert_to_chatml(example):
    return {
        "messages": [
            {"role": "user", "content": example["input"]},
            {"role": "assistant", "content": example["output"]},
        ]
    }
```

3. Appliquer le gabarit de chat en utilisant le *tokenizer* du mod√®le choisi.

N'oubliez pas de v√©rifier que le format de sortie correspond aux exigences du mod√®le choisi !
</Tip>

## Ressources compl√©mentaires

- [Guide sur les gabarits de chat dans la documentation d'Hugging Face](https://huggingface.co/docs/transformers/main/en/chat_templating)
- [Documentation de ü§ó *Transformers*](https://huggingface.co/docs/transformers)
- [D√©p√¥t Github contenant des exemples de gabarits de chat](https://github.com/chujiezheng/chat_templates)