# Ma√Ætriser le <i>NLP</i>

Si vous √™tes arriv√© jusqu'ici dans le cours, f√©licitations ! Vous avez maintenant toutes les connaissances et les outils n√©cessaires pour aborder (presque) n'importe quelle t√¢che de *NLP* avec ü§ó *Transformers* et l'√©cosyst√®me d'*Hugging Face* !

Nous avons vu beaucoup de collecteurs de donn√©es diff√©rents, c'est pourquoi nous avons fait cette petite vid√©o pour vous aider √† trouver lequel utiliser pour chaque t√¢che :

<Youtube id="-RPeakdlHYo"/>

Apr√®s avoir termin√© ce tour d'horizon des principales t√¢ches de *NLP*, vous devriez :

* savoir quelles architectures (encodeur, d√©codeur ou encodeur-d√©codeur) sont les mieux adapt√©es √† chaque t√¢che,
* comprendre la diff√©rence entre le pr√©-entra√Ænement et le *finetuning* d'un mod√®le de langage,
* savoir comment entra√Æner des *transformers* en utilisant soit l'API `Trainer` et les fonctionnalit√©s d'entra√Ænement distribu√© d' ü§ó *Accelerate* ou TensorFlow et Keras selon la piste que vous avez suivie,
* comprendre la signification et les limites de m√©triques comme ROUGE et BLEU pour les t√¢ches de g√©n√©ration de texte,
* savoir comment interagir avec vos mod√®les *finetun√©s*, √† la fois sur le *Hub* et en utilisant la `pipeline` de ü§ó *Transformers*.

Malgr√© toutes ces connaissances, il arrivera un moment o√π vous rencontrerez un *bug* difficile dans votre code ou aurez une question sur la fa√ßon de r√©soudre un probl√®me de *NLP* particulier. Heureusement, la communaut√© d'*Hugging Face* est l√† pour vous aider ! Dans le dernier chapitre de cette partie du cours, nous allons explorer comment vous pouvez d√©boguer vos mod√®les et demander de l'aide efficacement.