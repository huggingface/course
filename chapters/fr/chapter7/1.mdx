<FrameworkSwitchCourse {fw} />

# Introduction

Dans le [Chapitre 3](/course/fr/chapter3), vous avez vu comment *finetuner* un modÃ¨le de classification de texte. Dans ce chapitre, nous nous attaquons aux tÃ¢ches de NLP courantes suivantes :

- la classification de *tokens*,
- la modÃ©lisation du langage masquÃ© (comme BERT),
- les rÃ©sumÃ©s,
- la traduction,
- le prÃ©-entraÃ®nement Ã  la modÃ©lisation causale du langage (comme GPT-2),
- la rÃ©ponse aux questions.

{#if fw === 'pt'}

Pour ce faire, vous devrez tirer parti de tout ce que vous avez appris sur l'API `Trainer` et la bibliothÃ¨que ğŸ¤— *Accelerate* au [Chapitre 3](/course/fr/chapitre3), la bibliothÃ¨que ğŸ¤— *Datasets* au [Chapitre 5](/course/fr/chapiter5), et la bibliothÃ¨que ğŸ¤— *Tokenizers* au [Chapitre 6](/course/fr/chapiter6). Nous tÃ©lÃ©chargerons Ã©galement nos rÃ©sultats sur le *Hub*, comme nous l'avons fait dans le [Chapitre 4](/course/fr/chapiter4), donc c'est vraiment le chapitre oÃ¹ tout est rÃ©uni !

Chaque section peut Ãªtre lue indÃ©pendamment et vous montrera comment entraÃ®ner un modÃ¨le avec l'API `Trainer` ou avec votre propre boucle d'entraÃ®nement, en utilisant ğŸ¤— *Accelerate*. N'hÃ©sitez pas Ã  sauter l'une ou l'autre partie et Ã  vous concentrer sur celle qui vous intÃ©resse le plus : l'API `Trainer` est idÃ©ale pour affiner ou entraÃ®ner votre modÃ¨le sans vous soucier de ce qui se passe en coulisses, tandis que la boucle d'entraÃ®nement avec `Accelerate` vous permettra de personnaliser plus facilement toutes les parties que vous souhaitez.

{:else}

Pour ce faire, vous devrez tirer parti de tout ce que vous avez appris sur l'entraÃ®nement des modÃ¨les avec l'API Keras dans le [Chapitre 3](/course/fr/chapiter3), la bibliothÃ¨que ğŸ¤— *Datasets* dans le [Chapitre 5](/course/fr/chapiter5), et la bibliothÃ¨que ğŸ¤— *Tokenizers* dans le [Chapitre 6](/course/fr/chapiter6). Nous tÃ©lÃ©chargerons Ã©galement nos rÃ©sultats sur le *Hub*, comme nous l'avons fait dans le [Chapitre 4](/course/fr/chapiter4), donc c'est vraiment le chapitre oÃ¹ tout est rÃ©uni !

Chaque section peut Ãªtre lue indÃ©pendamment.

{/if}


<Tip>

Si vous lisez les sections dans l'ordre, vous remarquerez qu'elles ont beaucoup de code et de prose en commun. La rÃ©pÃ©tition est intentionnelle, afin de vous permettre de vous plonger (ou de revenir plus tard) dans une tÃ¢che qui vous intÃ©resse et de trouver un exemple fonctionnel complet.

</Tip>
