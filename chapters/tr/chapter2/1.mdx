# GiriÅŸ

<CourseFloatingBanner
    chapter={2}
    classNames="absolute z-10 right-0 top-0"
/>

[Birinci bÃ¶lÃ¼mde](/course/chapter1) gÃ¶rdÃ¼ÄŸÃ¼nÃ¼z gibi, Transformer modelleri genellikle oldukÃ§a bÃ¼yÃ¼ktÃ¼r. Milyonlarca, hatta milyarlarca, parametreleri olan bu modellerin eÄŸitimi ve Ã¼retime geÃ§irilmesi oldukÃ§a karmaÅŸÄ±k bir giriÅŸimdir. Bunun yanÄ±sÄ±ra, hemen hemen her gÃ¼n, herbirinin kendine Ã¶zgÃ¼ uygulamasÄ± olan yeni modellerin yayÄ±nlamasÄ±, bu yeni modellerinin hepsini birden denemeyi daha da zor bir hale getirmektedir.

ğŸ¤— Transformers kÃ¼tÃ¼phanesi bu sorunu Ã§Ã¶zmek iÃ§in oluÅŸturuldu. Bu kÃ¼tÃ¼phanenin amacÄ±, herhangi bir Transformer modelini tek bir API (uygulama programÄ± arabirimi) aracÄ±lÄ±ÄŸÄ± ile yÃ¼kleme, eÄŸitme, ve kaydetmeyi saÄŸlamaktÄ±r. KÃ¼tÃ¼phanenin baÅŸlÄ±ca Ã¶zellikleri ÅŸunlardÄ±r:

- **KullanÄ±m kolaylÄ±ÄŸÄ±**: En son geliÅŸtirilen NLP modellerini indirme, yÃ¼kleme ve kullanma yalnÄ±zca iki satÄ±r kod ile yapÄ±labilir.
- **Esneklik**: BÃ¼tÃ¼n modeller temelinde sadece ya PyTorch `nn.Module` ya da TensorFlow `tf.keras.Model` sÄ±nÄ±fÄ±dÄ±r ve her bir model, ait olduÄŸu kÃ¼tÃ¼phanesindeki diÄŸer herhangi bir model gibi iÅŸlenebilir.
- **Sadelik**: KÃ¼tÃ¼phane iÃ§erisinde neredeyse hiÃ§ bir soyutlama yapÄ±lmamaktadÄ±r. â€œHersey tek bir dosya iÃ§erisindeâ€ ifadesi, kÃ¼tÃ¼phanenin ana kavramÄ±nÄ± oluÅŸturuyor. Bir modelin â€œforward passâ€ aÅŸamasÄ±, kodun anlaÅŸÄ±lÄ±r olmasÄ± ve kolayca modifiye edilebilmesini saÄŸlamak amacÄ± ile tamamiyle tek bir dosya iÃ§erisinde tanÄ±mlanÄ±r. 

Bu son Ã¶zellik ğŸ¤— Transformers kÃ¼tÃ¼phanesini diÄŸer makine Ã¶ÄŸrenmesi kÃ¼tÃ¼phanelerinden oldukÃ§a farklÄ± kÄ±lmaktadÄ±r. Modeller dosyalar arasÄ±nda paylaÅŸÄ±lan modÃ¼ller Ã¼zerinde kurulmamÄ±ÅŸtÄ±r. Bunun yerine, her bir model kendine ait katmanlara sahiptir. Bu Ã¶zellik, modelleri ulaÅŸÄ±labilir ve anlaÅŸÄ±lÄ±r hale getirmenin yanÄ±sÄ±ra, diÄŸer modelleri etkilemeden, tek bir model Ã¼zerinde kolayca deneyler yapabilmenize olanak saÄŸlamaktadÄ±r.

Bu bÃ¶lÃ¼m, bir model ve simgeleleÅŸtirici (tokenizer) kullanarak, birinci bÃ¶lÃ¼mde tanÄ±tÄ±lan `pipeline()` fonksiyonunun bir kopyasÄ±nÄ± yapmak iÃ§in baÅŸtan sona (end-to-end) uygulayacaÄŸÄ±mÄ±z bir Ã¶rnekle baÅŸlamaktadÄ±r. 
Bunun ardÄ±ndan, kÃ¼tÃ¼phanenin model APIâ€™Ä±ndan bahsedeceÄŸiz: Model ve konfigÃ¼rasyon sÄ±nÄ±flarÄ±na detaylÄ±ca bakÄ±p, bir modeli nasÄ±l yÃ¼kleyebileceÄŸinizi ve bir modelin sayÄ±sal giriÅŸ verilerini nasÄ±l Ã§Ä±kÄ±ÅŸ Ã¶ngÃ¶rÃ¼leri olarak iÅŸlediÄŸini gÃ¶receÄŸiz. 

Daha sonra, `pipeline()` fonksiyonunun diÄŸer ana parÃ§asÄ± olan simgeleÅŸtirici APIâ€™Ä±na gÃ¶z atacaÄŸÄ±z. SimgeleÅŸtiriciler, sinir aÄŸÄ±nÄ±n metni sayÄ±sal giriÅŸ verilerine ve gerektiÄŸinde bu sayÄ±sal verileri tekrar metne dÃ¶nÃ¼ÅŸtÃ¼ren ilk ve son iÅŸlem aÅŸamalarÄ±ndan sorumludur. Son olarak, birden fazla cÃ¼mleyi hazÄ±r bir grup halinde bir modele nasÄ±l gÃ¶nderebileceÄŸinizi gÃ¶sterip, `tokenizer()` fonksiyonuna yakÄ±ndan bakarak bu bÃ¶lÃ¼mÃ¼ tamamlayacaÄŸÄ±z. 

<Tip>
âš ï¸ Model Hub ve ğŸ¤— Transformers kÃ¼tÃ¼phanesinde yeralan bÃ¼tÃ¼n Ã¶zelliklerden yararlanabilmeniz icin, <a href="https://huggingface.co/join">bir hesap oluÅŸturmanÄ±zÄ±</a> tavsiye ediyoruz.
</Tip>
