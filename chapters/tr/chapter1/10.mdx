<!-- DISABLE-FRONTMATTER-SECTIONS -->

# End-of-chapter quiz

Bu bölümde çok fazla şey işledik! Eğer bütün detaylar oturmadıysa endişelenme; önümüzdeki bölümlerde bu konuları daha derinlemesine işleyeceğiz. 

Şimdilik, bu bölümde öğrendiklerini test edelim!


### 1. Hub'a girin ve `roberta-large-mnli` checkpointini arayın. Hangi task için eğitilmiş bir modeldir?


<Question
	choices={[
		{
			text: "Özetleme",
			explain: "<a href=\"https://huggingface.co/roberta-large-mnli\">roberta-large-mnli sayfasını</a> tekrar kontrol et!"
		},
		{
			text: "Metin Sınıflandırma",
			explain: "Daha spesifik olarak iki cümlenin mantıksal olarak bağlılığını 3 label'da (karşı çıkma, nötr, destekleme) sınıflandırıyor. — buna aynı zamanda <em>doğal dil çıkarımı</em> da denir.",
			correct: true
		},
		{
			text: "Metin üretme",
			explain: "<a href=\"https://huggingface.co/roberta-large-mnli\">roberta-large-mnli sayfasını</a> tekrar kontrol et!"
		}
	]}
/>

### 2. Aşağıdaki kod ne döndürür?

```py
from transformers import pipeline

ner = pipeline("ner", grouped_entities=True)
ner("My name is Sylvain and I work at Hugging Face in Brooklyn.")
```

<Question
	choices={[
		{
			text: "Bu cümledeki sınıflandırma puanlarını \"positive\" veya \"negative\" labelları ile döndürecek.",
			explain: "Cevabınız yanlış — bu <code>sentiment-analysis</code> pipeline'ı olurdu."
		},
		{
			text: "Cümleyi tamamlayan metni üretip döndürür.",
			explain: "Cevabınız yanlış — bu <code>text-generation</code> pipeline'ı olurdu.",
		},
		{
			text: "Kişileri, kurum-kuruluşları veya mekanları niteleyen kelimeleri döndürür.",
			explain: "Dahası, <code>grouped_entities=True</code> yazarsanız aynı varlığa ait kelimeleri gruplar. Örnek: \"Hugging Face\".",
			correct: true
		}
	]}
/>

### 3. ...'yı doldurun.

```py
from transformers import pipeline

filler = pipeline("fill-mask", model="bert-base-cased")
result = filler("...")
```

<Question
	choices={[
		{
			text: "This <mask> has been waiting for you.",
			explain: "Cevabınız yanlış. <code>bert-base-cased</code> model kartına bakın ve hatanızı anlamaya çalışın."
		},
		{
			text: "This [MASK] has been waiting for you.",
			explain: "Doğru! Bu modelin mask token'ı [MASK].",
			correct: true
		},
		{
			text: "This man has been waiting for you.",
			explain: "Cevabınız yanlış. Bu pipeline masked word'leri (silinmiş kelimeleri) dolduruyor, bu yüzden cümlenin bir yerinde mask token olması gerekiyor."
		}
	]}
/>

### 4. Bu kod neden çalışmaz?

```py
from transformers import pipeline

classifier = pipeline("zero-shot-classification")
result = classifier("This is a course about the Transformers library")
```

<Question
	choices={[
		{
			text: "Bu pipeline'ın metni sınıflandırması için labelların verilmesi gerekiyor.",
			explain: "Doğru — doğru kodda <code>candidate_labels=[...]</code> yazılması gerekiyor.",
			correct: true
		},
		{
			text: "Bu pipeline birden fazla cümle gerektirir.",
			explain: "Cevabınız yanlış, bu pipeline birden fazla cümle alabilir (diğer hepsi gibi) fakat sorun bu değil."
		},
		{
			text: "🤗 Transformers kütüphanesi saçmalıyor (her zamanki gibi).",
			explain: "Bunu işaretlediyseniz size hiçbir şey demiyoruz!"
		},
		{
			text: "This pipeline requires longer inputs; this one is too short.",
			explain: "Cevabınız yanlış. Sorun bu değil ama unutmayın ki çok uzun bir metin bu pipeline tarafından işlenirken kısaltılır."
		}
	]}
/>

### 5. "transfer learning" ne anlama gelir?

<Question
	choices={[
		{
			text: "Daha önceden eğitilmiş bir modeli aynı verisetiyle tekrar eğiterek bilgisini yeni modele geçirmek.",
			explain: "Hayır eğer bunu yaparsak aynı modelden 2 tane elde ederdik."
		},
		{
			text: "İkinci bir modeli ilk modelin weightleri ile başlatıp ilk modelin bilgisini yeni modele geçirmek.",
			explain: "Doğru: ikinci modeli yeni bir iş için eğittiğimizde birinci modelin bilgisini *transfers* (geçirir).",
			correct: true
		},
		{
			text: "Transferring the knowledge of a pretrained model to a new model by building the second model with the same architecture as the first model.",
			explain: "The architecture is just the way the model is built; there is no knowledge shared or transferred in this case."
		}
	]}
/>

### 6. True or false? A language model usually does not need labels for its pretraining.


<Question
	choices={[
		{
			text: "True",
			explain: "The pretraining is usually <em>self-supervised</em>, which means the labels are created automatically from the inputs (like predicting the next word or filling in some masked words).",
			correct: true
		},
		{
			text: "False",
			explain: "This is not the correct answer."
		}
	]}
/>

### 7. "model," "architecture," (mimari) ve "weights." (ağırlıklar) kelimeleri arasındaki fark nedir?

<Question
	choices={[
		{
			text: "Eğer model bir binaysa mimarisi bina planı ve ağırlıklar içinde yaşayan insanlar olurdu.",
			explain: "Bu metafora göre, ağırlıklar, tuğlalar ve binayı yapmak için kullanılan diğer malzemeler olurdu."
		},
		{
			text: "Mimari bir model yapmak için harita olsaydı ağırlıkları haritanın üzerindeki şehirler olurdu.",
			explain: "Bu metafora göre bir mimari için birden fazla ağırlık mümkün olmazdı. (Türkiye haritasında sadece bir tane İstanbul var.)"
		},
		{
			text: "Bir mimari bir modeli ve ağırlıkları oluşturmak için kullanılan matematiksel fonksiyonların bir dizisidir ve ağırlıklar bu fonksiyonların parametreleridir.",
			explain: "Aynı matematiksel fonksiyonlar (mimari) farklı parametreler (ağırlıklar) kullanılarak farklı modeller oluşturmak için kullanılabilir.",
			correct: true
		}
	]}
/>


### 8. Hangi model türünü promptları metin üreterek tamamlamak için kullanırsınız?

<Question
	choices={[
		{
			text: "Encoder (kodlayıcı) model",
			explain: "Encoder modeller bütün cümleyi temsil eden bir gösterim oluşturur ve bu gösterim sınıflandırma gibi işler için daha uygundur."
		},
		{
			text: "Decoder (kod çözücü) model",
			explain: "Decoder modeller bu iş için mükemmeldir.",
			correct: true
		},
		{
			text: "Sequence-to-sequence model",
			explain: "Sequence-to-sequence models are better suited for tasks where you want to generate sentences in relation to the input sentences, not a given prompt. Sequences-to-sequence modeller input cümlelerle ilişkili cümleler üretmek için daha uygundur, verilen bir prompt için değil."
		}
	]}
/>

### 9. Özetleme için hangi model türünü kullanırsınız?

<Question
	choices={[
		{
			text: "Encoder model",
			explain: "Encoder modeller bütün cümleyi temsil eden bir gösterim oluşturur ve bu gösterim sınıflandırma gibi işler için daha uygundur."
		},
		{
			text: "Decoder model",
			explain: "Decoder modeller çıktı metinleri (özetler gibi) üretmek için iyidir, fakat bütün metni özetlemek için gerekli olan bağlamı kullanma yeteneğine sahip değillerdir."
		},
		{
			text: "Sequence-to-sequence model",
			explain: "Sequence-to-sequence modeller özetleme işi için mükemmeldir.",
			correct: true
		}
	]}
/>

### 10. Hangi model türünü metin inputlarını belirli labellarına göre sınıflandırmak için kullanırsınız?

<Question
	choices={[
		{
			text: "Encoder model",
			explain: "Encoder modeller bütün cümleyi temsil eden bir gösterim oluşturur ve bu gösterim sınıflandırma gibi işler için mükemmeldir.",
			correct: true
		},
		{
			text: "Decoder model",
			explain: "Decoder models are good for generating output texts, not extracting a label out of a sentence. Decoder modeller çıktı metinleri üretmek için iyidir falakat bir cümleden label çıkaramazlar."
		},
		{
			text: "Sequence-to-sequence model",
			explain: "Sequence-to-sequence modeller input cümlelerle ilişkili cümleler üretmek için daha uygundur, label çıkaramazlar.",
		}
	]}
/>

### 11. Modelinizde bir önyargı gözlemlediğinizde bunun kaynağı ne olabilir?

<Question
	choices={[
		{
			text: "Fine-tune yaptığınızda ilk modelin önyargısı fine-tuned modele geçmiş olabilir.",
			explain: "Transfer Learning yaparken, kullanılan önceden eğitilmiş modelin önyargısı fine-tuned modelde de silinmez.",
			correct: true
		},
		{
			text: "Modelin eğitildiği veriseti önyargılı olabilir.",
			explain: "En basit önyargı kaynağı bu fakat tek değil.",
			correct: true
		},
		{
			text: "The metric the model was optimizing for is biased. Modelin optimize ettiği metrik önyargılı olabilir.",
			explain: "Görmesi daha zor bir önyargı kaynağı modelin eğitildiği metriktir. Modeliniz seçtiğiniz metriğe körü körüne odaklanır.",
			correct: true
		}
	]}
/>
