
<FrameworkSwitchCourse {fw} />

# Fine-tuningul unui model cu API-ul Trainer[[fine-tuning-a-model-with-the-trainer-api]]

<CourseFloatingBanner chapter={3}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[ 
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter3/section3.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter3/section3.ipynb"},
]} />

<Youtube id="nvBXf7s7vTI"/>

ğŸ¤— Transformers oferÄƒ o clasÄƒ `Trainer` pentru a vÄƒ ajuta sÄƒ faceÈ›i fine-tune pe oricare dintre modelurile preantrenate pe care le oferÄƒ pe datasetul dvs. OdatÄƒ ce aÈ›i terminat preprocesarea datelor din ultima secÈ›iune, mai aveÈ›i doar cÃ¢teva paÈ™i rÄƒmaÈ™i pentru a defini `Trainerul`. Partea cea mai grea este probabil pregÄƒtirea environmentul pentru a rula `Trainer.train()`, deoarece va lua mult timp pe un CPU. DacÄƒ nu aveÈ›i niciun GPU configurat, puteÈ›i accesa gratuit GPUuri sau TPUuri pe [Google Colab](https://colab.research.google.com/).

Exemplele de cod de mai jos presupune cÄƒ aÈ›i executat exemplele din secÈ›iunea anterioarÄƒ. Aici este o scurtÄƒ recapitulare despre ce aveÈ›i nevoie:

```py
from datasets import load_dataset
from transformers import AutoTokenizer, DataCollatorWithPadding

raw_datasets = load_dataset("glue", "mrpc")
checkpoint = "bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)


def tokenize_function(example):
    return tokenizer(example["sentence1"], example["sentence2"], truncation=True)


tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)
data_collator = DataCollatorWithPadding(tokenizer=tokenizer)
```

### Antrenarea[[training]]

Ãnainte de a putea defini `Trainerul`, trebuie sÄƒ definim o clasÄƒ `TrainingArguments` care va conÈ›ine toÈ›i hyperparameters pe care `Trainer` le va folosi pentru antrenare È™i evaluare. Singurul argument pe care trebuie sÄƒ-l oferiÈ›i este un folder Ã®n care modelul anternat va fi salvat, precum È™i checkpointurile de-a lungul drumului. Toate celelalte pot fi lÄƒsate ca valori default, care ar trebui sÄƒ funcÈ›ioneze destul de bine pentru un fine-tune de bazÄƒ.

```py
from transformers import TrainingArguments

training_args = TrainingArguments("test-trainer")
```

<Tip>

ğŸ’¡ DacÄƒ doriÈ›i sÄƒ Ã®ncÄƒrcaÈ›i automat modelul pe Hub Ã®n timpul antrenÄƒrii, transmiteÈ›i `push_to_hub=True` Ã®n `TrainingArguments`. Ne vom Ã®ntoarce la acest subiect Ã®n [Capitolul 4](/course/chapter4/3)

</Tip>

A doua etapÄƒ este definiÈ›ia modelului nostru. Ca Ã®n capitolul anterior, vom folosi clasa `AutoModelForSequenceClassification`, cu douÄƒ labeluri:

```py
from transformers import AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)
```

ObservÄƒm cÄƒ, spre deosebire de [Capitolul 2](/course/chapter2), se emite o avertizare dupÄƒ crearea acestui model preantrenat. Acest lucru este datorit faptului cÄƒ BERT nu a fost antrenat pentru clasificarea perechilor de propoziÈ›ii, astfel Ã®ncÃ¢t Ã®nceputul modelului preantrenat a fost eliminat È™i un nou Ã®nceput adecvat pentru clasificarea secvenÈ›elor a fost adÄƒugat Ã®n loc. AvertizÄƒrile indicÄƒ faptul cÄƒ anumite weights nu au fost utilizate (cele care corespundeau Ã®nceputul eliminat) È™i celelalte au fost iniÈ›ializate aleatoriu (cele pentru noul Ã®nceput). Aceasta se terminÄƒ cu o recomandare de a antrena modelul, ceea ce vom face acum.

OdatÄƒ ce am definit modelul nostru, putem defini `Trainer` prin transmiterea tuturor obiectelor construite pÃ¢nÄƒ acum â€” `model`, `training_args`, a training È™i validation datasets, `data_collator`, È™i `tokenizer`:

```py
from transformers import Trainer

trainer = Trainer(
    model,
    training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    tokenizer=tokenizer,
)
```

ObservÄƒm cÄƒ, dacÄƒ transmitem `tokenizer`, atunci defaultul `data_collator` folosit de `Trainer` va fi un `DataCollatorWithPadding` similar celui definit mai devreme. Din acest motiv, puteÈ›i omite linia `data_collator=data_collator` aici. A fost important sÄƒ vÄƒ arÄƒtÄƒm aceastÄƒ parte Ã®n secÈ›iunea 2!

Pentru a face fine-tune modelului pe datasetul nostru, trebuie sÄƒ apelÄƒm metoda `train()` a `Trainerului`:

```py
trainer.train()
```

Acest lucru va Ã®ncepe fine-tuningul (care ar trebui sÄƒ dureze cÃ¢teva minute pe un GPU) È™i va raporta training loss la fiecare 500 de paÈ™i. TotuÈ™i, nu va raporta cÃ¢t de bine sau rÄƒu se descurcÄƒ modelul. Acest lucru este datorat:

1. Nu am transmis `Trainerului` sÄƒ efectueze evaluarea Ã®n timpul antrenÄƒrii, prin setarea `evaluation_strategy` la `"steps"` (evaluaÈ›i la fiecare `eval_steps`) sau `"epoch"` (evaluaÈ›i la finalul fiecÄƒrei epoch).
2. Nu am oferit `Trainerului` o funcÈ›ie `compute_metrics()` pentru a calcula metricele Ã®n timpul evaluÄƒri(altminter evalurea ar fi printat doar lossul, care nu este un numÄƒr foarte intuitiv).

### Evaluare[[evaluation]]

SÄƒ vedem cum putem construi o funcÈ›ie `compute_metrics()` folositoare È™i sÄƒ o utilizÄƒm la urmÄƒtoarea antrenare. FuncÈ›ia trebuie sÄƒ primeascÄƒ obiectul `EvalPrediction` (un named tuple cu fieldul `predictions` È™i altul `label_ids`) È™i sÄƒ returneze un dicÈ›ionar ce le asociazÄƒ fÄƒcÃ¢nd mapping valorilor string la valori float (stringurile fiind denumirile metricelor returnate, È™i valorile floats al acestora). Pentru a obÈ›ine cÃ¢teva predicÈ›ii din model, putem folosi comanda `Trainer.predict()`:

```py
predictions = trainer.predict(tokenized_datasets["validation"])
print(predictions.predictions.shape, predictions.label_ids.shape)
```

```python out
(408, 2) (408,)
```

Outputul metodei `predict()` este un named tuple  cu trei fielduri: `predictions`, `label_ids` È™i `metrics`. CÃ¢mpul `metrics` va conÈ›ine doar lossul asupra datasetului transmis, precum È™i o serie de metrice de timp (cÃ¢t de mult a luat prezicerea È™i timpul mediu). OdatÄƒ ce vom completa funcÈ›ia `compute_metrics()` È™i Ã®l vom oferi `Trainerului`, atunci acel field va conÈ›ine È™i metricele returnate de `compute_metrics()`.

DupÄƒ cum puteÈ›i vedea, `predictions` este un array bi-dimensional cu shapeul 408x2 (408 fiind numÄƒrul de elemente Ã®n datasetul folosit). Acestea sunt logiturile pentru fiecare element al datasetului pe care le-am oferit funcÈ›iei `predict()` (cum aÈ›i vÄƒzut Ã®n [capitolul anterior](/course/chapter2), toate modelel Transformer returneÄƒ logituri). Pentru a le transforma Ã®n predicÈ›ii pe care sÄƒ le comparÄƒm cu labelurile noastre, noi trebui sÄƒ luÄƒm indexul cu cea mai mare valoare pe axa a doua:


```py
import numpy as np

preds = np.argmax(predictions.predictions, axis=-1)
```

Acum putem compara `preds` cu labelurile. Ca sÄƒ construim funcÈ›ioa noastrÄƒ `compute_metric()`, o sÄƒ ne bazÄƒm pe metricele de la librÄƒria ğŸ¤— [Evaluate](https://github.com/huggingface/evaluate/). Putem Ã®ncÄƒrca metricele asociate cu datasetul MRPC la fel de uÈ™or cum am Ã®ncÄƒrcat datasetul, de data asta cu funcÈ›ia `evaluate.load()`. Obiectul returnat are o metodÄƒ `compute()` pe care o putem folosi ca sÄƒ facem calcularea metricelor:

```py
import evaluate

metric = evaluate.load("glue", "mrpc")
metric.compute(predictions=np.argmax(predictions.predictions, axis=-1), references=predictions.label_ids)
```

```python out
{'accuracy': 0.8578431372549019, 'f1': 0.8996539792387542}
```

Rezultatele exacte pe care le veÈ›i obÈ›ine pot varia, deoarece iniÈ›ializarea aleatoare a Ã®nceputului modelului care poate schimba metricele pe care le-a atins. Aici putem vedea cÄƒ modelul nostru are o precizie de 85.78% Ã®n setul de validare È™i un scor F1 de 89.97. Acestea sunt exact aceleaÈ™i metrice folosite pentru evaluarea rezultatelor pe datasetul MRPC pentru GLUE benchmark. Tabelul din [BERT Paper](https://arxiv.org/pdf/1810.04805.pdf) a raportat un scor F1 de 88.9 pentru modelul de bazÄƒ. Acela a fost un `uncased` model, dar noi utilizÄƒm acum un `cased` model, ceea ce explicÄƒ rezultatul mai bun.

Pentru a reuni toate acestea Ã®ntr-o singurÄƒ funcÈ›ie `compute_metrics()`, putem scrie:

```py
def compute_metrics(eval_preds):
    metric = evaluate.load("glue", "mrpc")
    logits, labels = eval_preds
    predictions = np.argmax(logits, axis=-1)
    return metric.compute(predictions=predictions, references=labels)
```

SÄƒ vedem acum cum putem utiliza aceastÄƒ funcÈ›ie pentru a raporta metricele la sfÃ¢rÈ™itu fiecÄƒrei epoch, mai jos puteÈ›i vedea cum definim un nou `Trainer` cu funcÈ›ia compute:

```py
training_args = TrainingArguments("test-trainer", evaluation_strategy="epoch")
model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)

trainer = Trainer(
    model,
    training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
)
```

ObservÄƒm cÄƒ am creat un nou `TrainingArguments` cu `evaluation_strategy` setat la `"epoch"` È™i o nouÄƒ instanÈ›Äƒ a modelului. Ãn cazul nostru, ar fi fost suficient sÄƒ continuam antrenarea prezentatÄƒ anterior.

Pentru a lansa o nouÄƒ antrenare, putem executa:

```py
trainer.train()
```

De data aceasta, acesta va raporta validation loss È™i metricele la sfÃ¢rÈ™itul fiecÄƒrui epocÄƒ pe lÃ¢ngÄƒ training loss. Dar acurateÈ›ea/scorul F1 pe care Ã®l atingeÈ›i poate fi puÈ›in diferit faÈ›Äƒ de ceea ce am gÄƒsit, datoritÄƒ iniÈ›ializÄƒrii aleatoare a Ã®nceputului modelului, dar ar trebui sÄƒ nu difere foarte mult.

`Trainerul` va funcÈ›iona Ã®n mod automat pe mai multe GPU-uri sau TPU-uri È™i oferÄƒ multe opÈ›iuni, cum ar fi mixed-precision training(folosiÈ›i `fp16 = True` Ã®n argumentele de antrenare). Vom discuta despre toate opÈ›iunile pe care le are Ã®n Capitolul 10.

Cu aceasta terminÄƒm introducerea fine-tuningului folosind API-ul `Trainer`. Un exemplu de a face acest lucru pentru majoritatea sarcinilor NLP va fi dat Ã®n [Capitolul 7](/course/chapter7), dar pentru moment sÄƒ vedem cum putem face acelaÈ™i lucru doar cu PyTorch.

<Tip>

âœï¸ **ÃncearcÄƒ!** FÄƒ fine-tune unui model pe datasetul GLUE SST-2, folosind procesarea de date efectuatÄƒ Ã®n secÈ›iunea 2.

</Tip>
