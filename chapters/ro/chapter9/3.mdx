# 칉n탵elegerea clasei Interface[[understanding-the-interface-class]]

<CourseFloatingBanner chapter={9}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter9/section3.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter9/section3.ipynb"},
]} />

칉n aceast캒 sec탵iune, vom examina mai 칥ndeaproape clasa `Interface` 탳i vom 칥n탵elege
parametrii principali folosi탵i pentru a crea una.

## Cum s캒 crea탵i o Interface[[how-to-create-an-interface]]

Ve탵i observa c캒 clasa `Interface` are 3 parametri necesari:

`Interface(fn, inputs, outputs, ...)`

Ace탳ti parametri sunt:

  - `fn`: func탵ia de predic탵ie care este 칥ncapsulat캒 de interfa탵a Gradio. Aceast캒 func탵ie poate lua unul sau mai mul탵i parametri 탳i poate returna una sau mai multe valori
  - `inputs`: tipul(tipurile) componentei de intrare. Gradio ofer캒 multe componente pre-construite precum `"image"` sau `"mic"`.
  - `outputs`: tipul(tipurile) componentei de ie탳ire. Din nou, Gradio ofer캒 multe componente pre-construite de ex. `"image"` sau `"label"`.

Pentru o list캒 complet캒 a componentelor, [consulta탵i documenta탵ia Gradio](https://gradio.app/docs). Fiecare component캒 pre-construit캒 poate fi personalizat캒 prin instan탵ierea clasei corespunz캒toare componentei.

De exemplu, a탳a cum am v캒zut 칥n [sec탵iunea anterioar캒](/course/chapter9/2),
칥n loc s캒 transmite탵i `"textbox"` la parametrul `inputs`, pute탵i transmite o component캒 `Textbox(lines=7, label="Prompt")` pentru a crea o cutie de text cu 7 linii 탳i o etichet캒.

S캒 arunc캒m o privire la un alt exemplu, de data aceasta cu o component캒 `Audio`.

## Un exemplu simplu cu audio[[a-simple-example-with-audio]]

A탳a cum am men탵ionat mai devreme, Gradio ofer캒 multe intr캒ri 탳i ie탳iri diferite.
Deci s캒 construim o `Interface` care func탵ioneaz캒 cu audio.

칉n acest exemplu, vom construi o func탵ie audio-la-audio care prime탳te un
fi탳ier audio 탳i pur 탳i simplu 칥l inverseaz캒.

Vom folosi pentru intrare componenta `Audio`. C칙nd folosi탵i componenta `Audio`,
pute탵i specifica dac캒 dori탵i ca `source`-ul audio s캒 fie un fi탳ier pe care utilizatorul
칥l 칥ncarc캒 sau un microfon cu care utilizatorul 칥탳i 칥nregistreaz캒 vocea. 칉n acest caz, s캒
o set캒m la `"microphone"`. Doar pentru distrac탵ie, vom ad캒uga o etichet캒 la `Audio`-ul nostru care spune
"Vorbi탵i aici...".

칉n plus, am dori s캒 primim audio-ul ca un array numpy pentru a putea cu u탳urin탵캒
s캒 칥l "invers캒m". Deci vom seta `"type"`-ul s캒 fie `"numpy"`, care transmite datele de intrare
ca un tuplu de (`sample_rate`, `data`) 칥n func탵ia noastr캒.

Vom folosi 탳i componenta de ie탳ire `Audio` care poate reda automat
un tuplu cu o rat캒 de e탳antionare 탳i un array numpy de date ca fi탳ier audio redabil.
칉n acest caz, nu avem nevoie s캒 facem nicio personalizare, deci vom folosi scurt캒tura string
`"audio"`.


```py
import numpy as np
import gradio as gr


def reverse_audio(audio):
    sr, data = audio
    reversed_audio = (sr, np.flipud(data))
    return reversed_audio


mic = gr.Audio(source="microphone", type="numpy", label="Vorbi탵i aici...")
gr.Interface(reverse_audio, mic, "audio").launch()
```

Codul de mai sus va produce o interfa탵캒 ca cea de mai jos (dac캒 browserul dvs. nu
v캒 cere permisiuni pentru microfon, <a href="https://huggingface.co/spaces/course-demos/audio-reverse" target="_blank">deschide탵i demo-ul 칥ntr-o fil캒 separat캒</a>.)

<iframe src="https://course-demos-audio-reverse.hf.space" frameBorder="0" height="250" title="Gradio app" class="container p-0 flex-grow space-iframe" allow="accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking" sandbox="allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"></iframe>

Acum ar trebui s캒 pute탵i s캒 v캒 칥nregistra탵i vocea 탳i s캒 v캒 auzi탵i vorbind 칥n sens invers - 칥nfrico탳캒tor 游놑!

## Gestionarea intr캒rilor 탳i ie탳irilor multiple[[handling-multiple-inputs-and-outputs]]

S캒 spunem c캒 avem o func탵ie mai complicat캒, cu intr캒ri 탳i ie탳iri multiple.
칉n exemplul de mai jos, avem o func탵ie care prime탳te un index dropdown, o valoare slider 탳i un num캒r,
탳i returneaz캒 un e탳antion audio al unui ton muzical.

Privi탵i cum transmitem o list캒 de componente de intrare 탳i ie탳ire,
탳i vede탵i dac캒 pute탵i urm캒ri ce se 칥nt칙mpl캒.

Cheia aici este c캒 atunci c칙nd transmite탵i:
* o list캒 de componente de intrare, fiecare component캒 corespunde unui parametru 칥n ordine.
* o list캒 de componente de ie탳ire, fiecare component캒 corespunde unei valori returnate.

Fragmentul de cod de mai jos arat캒 cum trei componente de intrare se aliniaz캒 cu cei trei argumente ai func탵iei `generate_tone()`:

```py
import numpy as np
import gradio as gr

notes = ["C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B"]


def generate_tone(note, octave, duration):
    sr = 48000
    a4_freq, tones_from_a4 = 440, 12 * (octave - 4) + (note - 9)
    frequency = a4_freq * 2 ** (tones_from_a4 / 12)
    duration = int(duration)
    audio = np.linspace(0, duration, duration * sr)
    audio = (20000 * np.sin(audio * (2 * np.pi * frequency))).astype(np.int16)
    return (sr, audio)


gr.Interface(
    generate_tone,
    [
        gr.Dropdown(notes, type="index"),
        gr.Slider(minimum=4, maximum=6, step=1),
        gr.Number(value=1, label="Durata 칥n secunde"),
    ],
    "audio",
).launch()
```

<iframe src="https://course-demos-generate-tone.hf.space" frameBorder="0" height="450" title="Gradio app" class="container p-0 flex-grow space-iframe" allow="accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking" sandbox="allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"></iframe>


### Metoda `launch()`[[the-launch-method]]

P칙n캒 acum, am folosit metoda `launch()` pentru a lansa interfa탵a, dar nu
am discutat cu adev캒rat ce face.

칉n mod implicit, metoda `launch()` va lansa demo-ul 칥ntr-un server web care
ruleaz캒 local. Dac캒 rula탵i codul 칥ntr-un notebook Jupyter sau Colab, atunci
Gradio va incorpora interfa탵a GUI demo 칥n notebook pentru a o putea folosi cu u탳urin탵캒.

Pute탵i personaliza comportamentul `launch()` prin parametri diferi탵i:

  - `inline` - dac캒 s캒 afi탳eze interfa탵a inline 칥n notebook-urile Python.
  - `inbrowser` - dac캒 s캒 lanseze automat interfa탵a 칥ntr-o fil캒 nou캒 칥n browserul implicit.
  - `share` - dac캒 s캒 creeze un link partajabil public de pe calculatorul dvs. pentru interfa탵캒. Cam ca un link Google Drive!

Vom acoperi parametrul `share` 칥n mult mai multe detalii 칥n urm캒toarea sec탵iune!

## 九勇 S캒 aplic캒m![[lets-apply-it]]

S캒 construim o interfa탵캒 care v캒 permite s캒 demonstra탵i un model de **recunoa탳tere vocal캒**.
Pentru a o face interesant캒, vom accepta *fie* o intrare de microfon, fie un fi탳ier 칥nc캒rcat.

Ca de obicei, vom 칥nc캒rca modelul nostru de recunoa탳tere vocal캒 folosind func탵ia `pipeline()` din 游뱅 Transformers.
Dac캒 ave탵i nevoie de o re칥mprosp캒tare rapid캒, pute탵i s캒 v캒 칥ntoarce탵i la [acea sec탵iune din Capitolul 1](/course/chapter1/3). Urm캒torul, vom implementa o func탵ie `transcribe_audio()` care proceseaz캒 audio-ul 탳i returneaz캒 transcrierea. 칉n final, vom 칥ncapsula aceast캒 func탵ie 칥ntr-o `Interface` cu componentele `Audio` pentru intr캒ri 탳i doar text pentru ie탳ire. 칉n ansamblu, codul pentru aceast캒 aplica탵ie este urm캒torul:

```py
from transformers import pipeline
import gradio as gr

model = pipeline("automatic-speech-recognition")


def transcribe_audio(audio):
    transcription = model(audio)["text"]
    return transcription


gr.Interface(
    fn=transcribe_audio,
    inputs=gr.Audio(type="filepath"),
    outputs="text",
).launch()
```

Dac캒 browserul dvs. nu v캒 cere permisiuni pentru microfon, <a href="https://huggingface.co/spaces/course-demos/audio-reverse" target="_blank">deschide탵i demo-ul 칥ntr-o fil캒 separat캒</a>.

<iframe src="https://course-demos-asr.hf.space" frameBorder="0" height="550" title="Gradio app" class="container p-0 flex-grow space-iframe" allow="accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking" sandbox="allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"></iframe>


Asta e! Acum pute탵i folosi aceast캒 interfa탵캒 pentru a transcrie audio. Observa탵i aici c캒
prin transmiterea parametrului `optional` ca `True`, permitem utilizatorului s캒 ofere fie
un microfon, fie un fi탳ier audio (sau niciunul, dar asta va returna un mesaj de eroare).

Continua탵i s캒 vede탵i cum s캒 v캒 partaja탵i interfa탵a cu al탵ii! 