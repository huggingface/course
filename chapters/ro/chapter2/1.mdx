# Introducere[[introducere]]

<CourseFloatingBanner
    chapter={2}
    classNames="absolute z-10 right-0 top-0"
/>

DupÄƒ cum aÈ›i vÄƒzut Ã®n [Capitolul 1](/course/chapter1), modelele Transformer sunt de obicei foarte voluminoase. Fiind alcÄƒtuite din milioane pÃ¢nÄƒ la zeci de *miliarde* de parametri, instruirea È™i implementarea acestor modele este o sarcinÄƒ complicatÄƒ. Ãn plus, cu noi modele lansate aproape zilnic È™i fiecare avÃ¢nd propria sa implementare, testarea tuturor acestora nu este o sarcinÄƒ uÈ™oarÄƒ.

Biblioteca ğŸ¤— Transformers a fost creatÄƒ pentru a rezolva aceastÄƒ problemÄƒ. Scopul sÄƒu este de a oferi un singur API prin care orice model Transformer poate fi Ã®ncÄƒrcat, antrenat È™i salvat. Principalele caracteristici ale bibliotecii sunt:

- **Simplitate Ã®n utilizare**: DescÄƒrcarea, Ã®ncÄƒrcarea È™i utilizarea unui model NLP de ultimÄƒ generaÈ›ie pentru inferenÈ›Äƒ pot fi realizate Ã®n doar douÄƒ linii de cod.
- **Flexibilitate**: Ãn esenÈ›a lor, toate modelele sunt simple clase PyTorch `nn.Module` sau TensorFlow `tf.keras.Model` È™i pot fi manipulate ca orice alte modele Ã®n framework-urile lor respective de Ã®nvÄƒÈ›are automatÄƒ (ML).
- **Simplitate**: Aproape cÄƒ nu se fac abstractizÄƒri Ã®n Ã®ntreaga bibliotecÄƒ. "All in one file" este un concept de bazÄƒ: trecerea Ã®nainte a unui model este definitÄƒ Ã®n Ã®ntregime Ã®ntr-un singur fiÈ™ier, astfel Ã®ncÃ¢t codul Ã®n sine sÄƒ fie uÈ™or de Ã®nÈ›eles È™i de modificat.

AceastÄƒ ultimÄƒ caracteristicÄƒ face "ğŸ¤— Transformers" destul de diferitÄƒ de alte biblioteci ML. Modelele nu sunt construite pe module 
care sunt partajate Ã®ntre fiÈ™iere; Ã®n schimb, fiecare model are propriile sale straturi. Ãn plus, pe lÃ¢ngÄƒ faptul cÄƒ modelele sunt mai uÈ™or de abordat È™i de Ã®nÈ›eles, acest lucru vÄƒ permite sÄƒ experimentaÈ›i cu uÈ™urinÈ›Äƒ pe un model fÄƒrÄƒ a le afecta pe celelalte.

Acest capitol va Ã®ncepe cu un exemplu end-to-end Ã®n care folosim Ã®mpreunÄƒ un model È™i un tokenizer pentru a replica funcÈ›ia `pipeline()` introdusÄƒ Ã®n [Capitolul 1](/course/chapter1). Ãn continuare, vom discuta despre API-ul modelului: vom analiza clasele de model È™i de configurare È™i vÄƒ vom arÄƒta cum sÄƒ Ã®ncÄƒrcaÈ›i un model È™i cum acesta proceseazÄƒ intrÄƒrile numerice pentru a genera predicÈ›ii. 

Apoi vom analiza API-ul tokenizer, care este cealaltÄƒ componentÄƒ principalÄƒ a funcÈ›iei `pipeline()`. Tokenizerii se ocupÄƒ de prima È™i ultima etapÄƒ de procesare, gestionÃ¢nd conversia de la text la intrÄƒri numerice pentru reÈ›eaua neuronalÄƒ È™i conversia Ã®napoi la text atunci cÃ¢nd este necesar. Ãn cele din urmÄƒ, vÄƒ vom arÄƒta cum sÄƒ vÄƒ ocupaÈ›i de trimiterea mai multor propoziÈ›ii printr-un model Ã®n cadrul unui batch pregÄƒtit, apoi vom Ã®ncheia totul cu o examinare mai atentÄƒ a funcÈ›iei  `tokenizer()`.


> [!TIP]
> âš ï¸  
> Pentru a beneficia de toate funcÈ›iile disponibile cu Model Hub È™i ğŸ¤— Transformers, vÄƒ recomandÄƒm <a href="https://huggingface.co/join">sÄƒ vÄƒ creaÈ›i un cont</a>.