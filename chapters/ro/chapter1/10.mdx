<!-- DISABLE-FRONTMATTER-SECTIONS -->

# Quiz de sfÃ¢rÈ™it de capitol[[test-de-sfÃ¢rÈ™it-de-capitol]]

<CourseFloatingBanner
    chapter={1}
    classNames="absolute z-10 right-0 top-0"
/>

Acest capitol a acoperit o mulÈ›ime de subiecte! Nu vÄƒ faceÈ›i griji dacÄƒ nu aÈ›i Ã®nÈ›eles toate detaliile; capitolele urmÄƒtoare vÄƒ vor ajuta sÄƒ Ã®nÈ›elegeÈ›i cum funcÈ›ioneazÄƒ lucrurile Ã®n mecanismele lor interne.

Mai Ã®ntÃ¢i, Ã®nsÄƒ, sÄƒ testÄƒm ceea ce aÈ›i Ã®nvÄƒÈ›at Ã®n acest capitol!


### 1. ExploraÈ›i Hub-ul È™i cÄƒutaÈ›i checkpoint-ul `roberta-large-mnli`. Ce sarcinÄƒ Ã®ndeplineÈ™te acesta?


<Question
	choices={[
		{
			text: "Sumarizare",
			explain: "UitaÈ›i-vÄƒ din nou pe pagina <a href=\"https://huggingface.co/roberta-large-mnli\">roberta-large-mnli</a>."
		},
		{
			text: "Clasificare de text",
			explain: "Mai precis, clasificÄƒ dacÄƒ douÄƒ propoziÈ›ii sunt legate logic folosind trei etichete (contradicÈ›ie, neutru, implicaÈ›ie) â€” o sarcinÄƒ numitÄƒ È™i <em>inferenÈ›Äƒ Ã®n limbaj natural</em>.",
			correct: true
		},
		{
			text: "Generare de text",
			explain: "UitaÈ›i-vÄƒ din nou pe pagina <a href=\"https://huggingface.co/roberta-large-mnli\">roberta-large-mnli</a>."
		}
	]}
/>

### 2. Ce va returna urmÄƒtorul cod?

```py
from transformers import pipeline

ner = pipeline("ner", grouped_entities=True)
ner("My name is Sylvain and I work at Hugging Face in Brooklyn.")
```

<Question
	choices={[
		{
			text: "Va returna scoruri de clasificare pentru aceastÄƒ propoziÈ›ie, cu etichetele \"pozitiv\" sau \"negativ\".",
			explain: "Aceasta este incorect â€” acesta ar fi un pipeline de <code>sentiment-analysis</code>."
		},
		{
			text: "Va returna un text generat care completeazÄƒ aceastÄƒ propoziÈ›ie.",
			explain: "Aceasta este incorect â€” ar fi un pipeline de <code>text-generation</code>.",
		},
		{
			text: "Va returna cuvintele care reprezintÄƒ persoane, organizaÈ›ii sau locaÈ›ii.",
			explain: "Ãn plus, cu <code>grouped_entities=True</code>, va grupa Ã®mpreunÄƒ cuvintele care aparÈ›in aceleiaÈ™i entitÄƒÈ›i, precum \"Hugging Face\".",
			correct: true
		}
	]}
/>

### 3. Ce ar trebui sÄƒ Ã®nlocuiascÄƒ ... Ã®n acest exemplu de cod?

```py
from transformers import pipeline

filler = pipeline("fill-mask", model="bert-base-cased")
result = filler("...")
```

<Question
	choices={[
		{
			text: "This &#60;mask> has been waiting for you.",
			explain: "Aceasta este incorect. VerificaÈ›i cardul modelului <code>bert-base-cased</code> È™i Ã®ncercaÈ›i sÄƒ identificaÈ›i greÈ™eala."
		},
		{
			text: "This [MASK] has been waiting for you.",
			explain: "Corect! Token-ul de mascÄƒ al acestui model este [MASK].",
			correct: true
		},
		{
			text: "This man has been waiting for you.",
			explain: "Aceasta este incorect. Acest pipeline completeazÄƒ cuvinte mascate, deci are nevoie de un token de mascÄƒ undeva."
		}
	]}
/>

### 4. De ce nu va funcÈ›iona acest cod?

```py
from transformers import pipeline

classifier = pipeline("zero-shot-classification")
result = classifier("This is a course about the Transformers library")
```

<Question
	choices={[
		{
			text: "Acest pipeline necesitÄƒ sÄƒ fie furnizate etichete pentru a clasifica acest text.",
			explain: "Corect â€” codul corect trebuie sÄƒ includÄƒ <code>candidate_labels=[...]</code>.",
			correct: true
		},
		{
			text: "Acest pipeline necesitÄƒ mai multe propoziÈ›ii, nu doar una.",
			explain: "Aceasta este incorect, deÈ™i atunci cÃ¢nd este utilizat corespunzÄƒtor, acest pipeline poate primi o listÄƒ de propoziÈ›ii de procesat (ca toate celelalte pipeline-uri)."
		},
		{
			text: "Biblioteca ğŸ¤— Transformers este defectÄƒ, ca de obicei.",
			explain: "Nu vom onora acest rÄƒspuns cu un comentariu!"
		},
		{
			text: "Acest pipeline necesitÄƒ intrÄƒri mai lungi; aceasta este prea scurtÄƒ.",
			explain: "Aceasta este incorect. ReÈ›ineÈ›i cÄƒ un text foarte lung va fi trunchiat atunci cÃ¢nd este procesat de acest pipeline."
		}
	]}
/>

### 5. Ce Ã®nseamnÄƒ â€transfer learning"?

<Question
	choices={[
		{
			text: "Transferul cunoÈ™tinÈ›elor unui model preantrenat cÄƒtre un model nou prin antrenarea acestuia pe acelaÈ™i set de date.",
			explain: "Nu, aceasta ar Ã®nsemna douÄƒ versiuni ale aceluiaÈ™i model."
		},
		{
			text: "Transferul cunoÈ™tinÈ›elor unui model preantrenat cÄƒtre un model nou prin iniÈ›ializarea celui de-al doilea model cu ponderile primului model.",
			explain: "Corect: cÃ¢nd al doilea model este antrenat pe o nouÄƒ sarcinÄƒ, acesta *transferÄƒ* cunoÈ™tinÈ›ele primului model.",
			correct: true
		},
		{
			text: "Transferul cunoÈ™tinÈ›elor unui model preantrenat cÄƒtre un model nou prin construirea celui de-al doilea model cu aceeaÈ™i arhitecturÄƒ ca primul model.",
			explain: "Arhitectura este doar modul Ã®n care este construit modelul; nu existÄƒ cunoÈ™tinÈ›e Ã®mpÄƒrtÄƒÈ™ite sau transferate Ã®n acest caz."
		}
	]}
/>

### 6. AdevÄƒrat sau fals? De obicei, un model lingvistic nu are nevoie de etichete pentru preinstruire.

<Question
	choices={[
		{
			text: "AdevÄƒrat",
			explain: "Preantrenarea este de obicei <em>auto-supervizatÄƒ</em>, ceea ce Ã®nseamnÄƒ cÄƒ etichetele sunt create automat din intrÄƒri (cum ar fi prezicerea urmÄƒtorului cuvÃ¢nt sau completarea unor cuvinte mascate).",
			correct: true
		},
		{
			text: "Fals",
			explain: "Incorect."
		}
	]}
/>

### 7. SelectaÈ›i propoziÈ›ia care descrie cel mai bine termenii â€model", â€arhitecturÄƒ" È™i â€greutÄƒÈ›i".

<Question
	choices={[
		{
			text: "DacÄƒ un model este o clÄƒdire, arhitectura sa este planul È™i greutÄƒÈ›ile sunt oamenii care locuiesc Ã®n interior.",
			explain: "UrmÃ¢nd aceastÄƒ metaforÄƒ, greutÄƒÈ›ile ar fi cÄƒrÄƒmizile È™i alte materiale utilizate pentru construirea clÄƒdirii."
		},
		{
			text: "O arhitecturÄƒ este o hartÄƒ pentru a construi un model, iar greutÄƒÈ›ile sale sunt oraÈ™ele reprezentate pe hartÄƒ.",
			explain: "Problema cu aceastÄƒ metaforÄƒ este cÄƒ o hartÄƒ reprezintÄƒ de obicei o realitate existentÄƒ (existÄƒ doar un singur oraÈ™ Ã®n FranÈ›a numit Paris). Pentru o arhitecturÄƒ datÄƒ, sunt posibile multiple greutÄƒÈ›i."
		},
		{
			text: "O arhitecturÄƒ este o succesiune de funcÈ›ii matematice pentru a construi un model, iar greutÄƒÈ›ile sale sunt parametrii acelor funcÈ›ii.",
			explain: "AcelaÈ™i set de funcÈ›ii matematice (arhitecturÄƒ) poate fi utilizat pentru a construi modele diferite prin utilizarea unor parametri diferiÈ›i (greutÄƒÈ›i).",
			correct: true
		}
	]}
/>


### 8. Care dintre aceste tipuri de modele le-aÈ›i folosi pentru a completa prompt-urile cu text generat?

<Question
	choices={[
		{
			text: "Un model encoder",
			explain: "Un model encoder genereazÄƒ o reprezentare a Ã®ntregii propoziÈ›ii care este mai potrivitÄƒ pentru sarcini precum clasificarea."
		},
		{
			text: "Un model decoder",
			explain: "Modelele decoder sunt perfect potrivite pentru generarea de text din prompt-uri.",
			correct: true
		},
		{
			text: "Un model sequence-to-sequence",
			explain: "Modelele sequence-to-sequence sunt mai potrivite pentru sarcini Ã®n care doriÈ›i sÄƒ generaÈ›i propoziÈ›ii Ã®n relaÈ›ie cu propoziÈ›iile de intrare, nu cu un prompt dat."
		}
	]}
/>

### 9. Care dintre aceste tipuri de modele le-aÈ›i folosi pentru a rezuma texte?

<Question
	choices={[
		{
			text: "Un model encoder",
			explain: "Un model encoder genereazÄƒ o reprezentare a Ã®ntregii propoziÈ›ii care este mai potrivitÄƒ pentru sarcini precum clasificarea."
		},
		{
			text: "Un model decoder",
			explain: "Modelele decoder sunt bune pentru generarea de text de ieÈ™ire (cum ar fi rezumatele), dar nu au capacitatea de a exploata un context precum Ã®ntregul text de rezumat."
		},
		{
			text: "Un model sequence-to-sequence",
			explain: "Modelele sequence-to-sequence sunt perfect potrivite pentru o sarcinÄƒ de sumarizare.",
			correct: true
		}
	]}
/>

### 10. Care dintre aceste tipuri de modele le-aÈ›i utiliza pentru a clasifica intrÄƒrile de text Ã®n funcÈ›ie de anumite etichete?

<Question
	choices={[
		{
			text: "Un model encoder",
			explain: "Un model encoder genereazÄƒ o reprezentare a Ã®ntregii propoziÈ›ii care este perfect potrivitÄƒ pentru o sarcinÄƒ precum clasificarea.",
			correct: true
		},
		{
			text: "Un model decoder",
			explain: "Modelele decoder sunt bune pentru generarea de texte de ieÈ™ire, nu pentru extragerea unei etichete dintr-o propoziÈ›ie."
		},
		{
			text: "Un model sequence-to-sequence",
			explain: "Modelele sequence-to-sequence sunt mai potrivite pentru sarcini Ã®n care doriÈ›i sÄƒ generaÈ›i text bazat pe o propoziÈ›ie de intrare, nu o etichetÄƒ.",
		}
	]}
/>

### 11. Ce sursÄƒ posibilÄƒ poate avea prejudecata observatÄƒ Ã®ntr-un model?

<Question
	choices={[
		{
			text: "Modelul este o versiune fine-tuned a unui model preantrenat È™i a preluat prejudecata de la acesta.",
			explain: "CÃ¢nd aplicaÈ›i Transfer Learning, prejudecata din modelul preantrenat utilizat persistÄƒ Ã®n modelul fine-tuned.",
			correct: true
		},
		{
			text: "Datele pe care a fost antrenat modelul sunt pÄƒrtinitoare.",
			explain: "Aceasta este cea mai evidentÄƒ sursÄƒ de prejudecatÄƒ, dar nu singura.",
			correct: true
		},
		{
			text: "Metrica pe care modelul o optimiza este pÄƒrtinitoare.",
			explain: "O sursÄƒ mai puÈ›in evidentÄƒ de prejudecatÄƒ este modul Ã®n care modelul este antrenat. Modelul dvs. va optimiza orb pentru orice metricÄƒ aÈ›i ales, fÄƒrÄƒ alte consideraÈ›ii.",
			correct: true
		}
	]}
/>
