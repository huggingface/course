# Introducere[[introduction]]

<CourseFloatingBanner
    chapter={5}
    classNames="absolute z-10 right-0 top-0"
/>

Ãn [Capitolul 3](/course/chapter3) aÈ›i Ã®ncercat biblioteca ğŸ¤—Datasets È™i aÈ›i vÄƒzut cÄƒ existau trei paÈ™i principali atunci cÃ¢nd vine vorba de fine-tuningul unui model:

1. ÃncÄƒrcaÈ›i un dataset din Hugging Face Hub.
2. PreprocesaÈ›i datele cu `Dataset.map()`.
3. ÃncÄƒrcaÈ›i È™i calculaÈ›i metricele.

Dar aceasta este doar o micÄƒ parte a ceea ce poate face ğŸ¤— Datasets! Ãn acest capitol, ne vom aprofunda Ã®n aceastÄƒ bibliotecÄƒ. Pe parcurs, vom gÄƒsi rÄƒspunsuri la urmÄƒtoarele Ã®ntrebÄƒri:

* Ce faceÈ›i atunci cÃ¢nd datasetul tÄƒu nu este pe Hub?
* Cum puteÈ›i tÄƒia È™i Ã®mpÄƒrÈ›i un dataset? (È˜i ce dacÄƒ tu _really_ trebuie sÄƒ foloseÈ™ti Pandas?)
* Ce faceÈ›i atunci cÃ¢nd datasetul este uriaÈ™ È™i va topi RAM-ul laptopului dumneavoastrÄƒ?
* Ce este "memory mapping" È™i Apache Arrow?
* Cum puteÈ›i crea propriul dataset È™i sÄƒ-l trimiteÈ›i pe Hub?

Tehnicile pe care le veÈ›i Ã®nvÄƒÈ›a aici vÄƒ vor pregÄƒti pentru sarcinile avansate de tokenizare È™i fine-tuning din [Capitolul 6](/course/chapter6) È™i [Capitolul 7](/course/chapter7) -- deci luaÈ›i o cafea sau douÄƒ È™i sÄƒ Ã®ncepem!