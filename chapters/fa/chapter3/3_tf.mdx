<FrameworkSwitchCourse {fw} />

<div dir="rtl">

# ฺฉูฺฉ ฺฉุฑุฏู ูุฏูโูุง ุจุง ุงุณุชูุงุฏู ุงุฒ ฺฉูุฑุงุณ

<DocNotebookDropdown
  classNames="absolute z-10 right-0 top-0"
  options={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter3/section3_tf.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter3/section3_tf.ipynb"},
]} />

ุฒูุงู ฺฉู ููู ฺฉุงุฑูุง ูพุดโูพุฑุฏุงุฒุด ุฏุฑ ุจุฎุด ูุจู ุฑุง ุงูุฌุงู ุฏุงุฏุฏุ ููุท ฺูุฏ ูุฑุญูู ุจุงโูโูุงูุฏู ุชุง ุชุนูู ูุฏู ุฏุงุฑุฏ. ุจุง ุงู ุญุงูุ ุชูุฌู ุฏุงุดุชู ุจุงุดุฏ ฺฉู ุฏุณุชูุฑ <span dir="ltr">`model.fit()`</span> ุฑู CPU ุจุณุงุฑ ุขูุณุชู ุงุฌุฑุง ุฎูุงูุฏ ุดุฏ. ุงฺฏุฑ GPU ูุฏุงุฑุฏุ ูโุชูุงูุฏ ุงุฒ GPU ุง TPU ูุฌุงู ุฑู [ฺฏูฺฏู ฺฉูููุจ](https://colab.research.google.com/) ุงุณุชูุงุฏู ฺฉูุฏ.

ููููู ฺฉุฏูุง ุฒุฑ ูุฑุถ ูโฺฉููุฏ ฺฉู ุดูุง ูุซุงูโูุง ุจุฎุด ูุจู ุฑุง ุงุฒ ูพุด ุงุฌุฑุง ฺฉุฑุฏูโุงุฏ. ุงู ฺฉ ุฎูุงุตู ฺฉูุชุงู ุงุณุช ุฌูุช ุงุฏุขูุฑ ุขูฺู ูุงุฒ ุฏุงุฑุฏ:

<div dir="ltr">

```py
from datasets import load_dataset
from transformers import AutoTokenizer, DataCollatorWithPadding
import numpy as np

raw_datasets = load_dataset("glue", "mrpc")
checkpoint = "bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)


def tokenize_function(example):
    return tokenizer(example["sentence1"], example["sentence2"], truncation=True)


tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)

data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors="tf")

tf_train_dataset = tokenized_datasets["train"].to_tf_dataset(
    columns=["attention_mask", "input_ids", "token_type_ids"],
    label_cols=["labels"],
    shuffle=True,
    collate_fn=data_collator,
    batch_size=8,
)

tf_validation_dataset = tokenized_datasets["validation"].to_tf_dataset(
    columns=["attention_mask", "input_ids", "token_type_ids"],
    label_cols=["labels"],
    shuffle=False,
    collate_fn=data_collator,
    batch_size=8,
)
```

</div>


### ุชุนูู

ูุฏูโูุง ุชููุณูุฑูููู ฺฉู ุงุฒ ุชุฑููุณููุฑููุฑูุง ูุงฺฏูฺฏโููุณ ูุงุฑุฏ ุดุฏูโุงูุฏ ุงุฒ ูพุด ูุฏูโูุง ฺฉูุฑุงุณ ูุณุชูุฏ. ุงู ูู ููุฏููโุง ฺฉูุชุงู ุจู ฺฉูุฑุงุณ.

<Youtube id="rnTGBy2ax1c"/>

ุงู ุจู ุงู ูุนู ุงุณุช ฺฉู ุจู ูุญุถ ุงูฺฉู ุฏุงุฏูโูุงู ุฑุง ุฏุฑ ุงุฎุชุงุฑ ุจฺฏุฑูุ ฺฉุงุฑ ุจุณุงุฑ ฺฉู ูุงุฒู ุงุณุช ุชุง ุชุนูู ุฑุง ุฑู ุขู ุดุฑูุน ฺฉูู.

<Youtube id="AUozVp78dhk"/>

ูุงููุฏ [ูุตู ูุจู](/course/chapter2)ุ ูุง ุงุฒ ฺฉูุงุณ `TFAutoModelForSequenceClassification` ุจุง ุฏู ุจุฑฺุณุจ ุฏุณุชู ุงุณุชูุงุฏู ุฎูุงูู ฺฉุฑุฏ:

<div dir="ltr">

```py
from transformers import TFAutoModelForSequenceClassification

model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)
```

</div>

ุดูุง ูุชูุฌู ุฎูุงูุฏ ุดุฏ ฺฉู ุจุฑุฎูุงู [ูุตู ฒ](/course/chapter2)ุ ุจุนุฏ ุงุฒ ุณุงุฎุชู ุงู ูุฏู ุงุฒ ูพุดโ ุชุนูู ุฏุฏู ฺฉ ูุดุฏุงุฑ ุฏุฑุงูุช ูโฺฉูุฏ. ุงู ุจู ุงู ุฎุงุทุฑ ุงุณุช ฺฉู BERT ุจุฑุง ุฏุณุชูโุจูุฏ ุฏู ุฌูููโูุง ุงุฒ ูพุดโ ุชุนูู ูุฏุฏู ุงุณุชุ ุจูุงุจุฑุงู ูุงู ุณูุฑ ูุฏู ุงุฒ ูพุดโ ุชุนูู ุฏุฏู ุญุฐู ุดุฏู ู ฺฉ ูุงู ุณูุฑ ููุงุณุจ ุฌูุช ุฏุณุชู ุจูุฏ ุฑุดุชูโโโูุง ุจู ุฌุง ุขู ูุฑุงุฑ ฺฏุฑูุชู ุงุณุช. ูุดุฏุงุฑูุง ูุดุงู ูโุฏููุฏ ฺฉู ุจุฑุฎ ุงุฒ ูุฒูโูุง ูุฏู ุงุณุชูุงุฏู ูุดุฏูโุงูุฏ (ุขููุง ฺฉู ูุฑุจูุท ุจู ูุงูโ ุณูุฑ ุญุฐู ุดุฏู ูุฏู ุงุฒ ูพุด ุชุนูู ุฏุฏู ูุณุชูุฏ) ู ุจุฑุฎ ุฏฺฏุฑ ุจู ุตูุฑุช ุชุตุงุฏู ููุฏุงุฑโ ุฏู ุดุฏูโโุงูุฏ (ุขููุง ฺฉู ูุฑุจูุท ุจู ูุงูโ ุณูุฑ ุฌุฏุฏ ูุณุชูุฏ). ุฏุฑ ูุชุฌู ุงู ุงูุฑ ุดูุง ุฑุง ุชุดูู ุจู ุชุนูู ูุฏู ูโฺฉูุฏุ ฺฉู ุฏููุง ููุงู ฺฉุงุฑ ุงุณุช ฺฉู ูโุฎูุงูู ุงฺฉููู ุงูุฌุงู ุฏูู.

ุจุฑุง ฺฉูฺฉโ ฺฉุฑุฏู ูุฏู ุฑู ุฏูุชุงุณูุชโูุงูุ ูุง ููุท ุจุงุฏ ูุฏู ุฑุง <span dir="ltr">`compile()`</span> ฺฉูู ู ุณูพุณ ุฏุงุฏูโูุงู ุฑุง ุจู ุชุงุจุน <span dir="ltr">`fit()`</span> ุงุฑุณุงู ฺฉูู. ุงู ฺฉุงุฑ ูุฑุงูุฏ ฺฉูฺฉโ ฺฉุฑุฏู ุฑุง ุดุฑูุน ูโฺฉูุฏ (ฺฉู ุจุงุฏ ฺูุฏ ุฏููู ุฑู GPU ุทูู ุจฺฉุดุฏ) ู ุฏุฑ ููู ุญู ูุฒูู `training` ู ูุฒูู `validation` ุฑุง ุฏุฑ ุงูุชูุง ูุฑ epoch ฺฏุฒุงุฑุด ูโุฏูุฏ.

<Tip>

ุชูุฌู ุฏุงุดุชู ุจุงุดุฏ ฺฉู ูุฏูโูุง ุชุฑููุณููุฑููุฑ ูุงฺฏูฺฏโููุณ ูุงุจูุช ูฺูโุง ุฏุงุฑูุฏ ฺฉู ุจุณุงุฑ ุงุฒ ูุฏูโูุง ฺฉูุฑุงุณ ูุฏุงุฑูุฏ - ุขููุง ูโุชูุงููุฏ ุจู ุตูุฑุช ุฎูุฏฺฉุงุฑ ุงุฒ ฺฉ ุชุงุจุน ูุฒูู ููุงุณุจ ฺฉู ุจู ุตูุฑุช ุฏุงุฎู ูุญุงุณุจู ูโฺฉููุฏ ุงุณุชูุงุฏู ฺฉููุฏ. ุฏุฑ ุตูุฑุช ฺฉู ุดูุง ุขุฑฺฏููุงู ุจุฑุง ุชุงุจุน ูุฒูู ุฏุฑ ุฒูุงู <span dir="ltr">`compile()`</span> ุชุนู ูฺฉูุฏ ุขููุง ุงุฒ ุงู ุชุงุจุน ูุฒูู ุจู ุตูุฑุช ูพุดโูุฑุถ ุงุณุชูุงุฏู ุฎูุงููุฏ ฺฉุฑุฏ. ุชูุฌู ุฏุงุดุชู ุจุงุดุฏ ฺฉู ุฌูุช ุงุณุชูุงุฏู ุงุฒ ุชุงุจุน ูุฒูู ุฏุงุฎู ุดูุง ูุงุฒ ุฎูุงูุฏ ุฏุงุดุช ุจุฑฺุณุจ ุฏุณุชูโูุง ุฎูุฏุชุงู ุฑุง ุจู ุนููุงู ุจุฎุด ุงุฒ ูุฑูุฏุ ูู ุจู ุตูุฑุช ฺฉ ุจุฑฺุณุจ ุฏุณุชู ูุฌุฒุง ฺฉู ุฑูุด ูุนููู ุงุณุชูุงุฏู ุงุฒ ุจุฑฺุณุจ ุฏุณุชูโูุง ุฏุฑ ูุฏูโูุง ฺฉูุฑุงุณ ูโุจุงุดุฏุ ุงุฑุณุงู ฺฉูุฏ. ุดูุง ูุซุงูโูุง ุงุฒ ุงู ุฑุง ุฏุฑ ุจุฎุด ฒ ุงู ุฏุฑุณ ุฎูุงูุฏ ุฏุฏุ ุฌุง ฺฉู ุชุนู ุชุงุจุน ูุฒููโ ุฏุฑุณุช ูโุชูุงูุฏ ุชุง ุงูุฏุงุฒูโุง ูพฺุฏู ุจุงุดุฏ. ุจู ูุฑ ุญุงูุ ุจุฑุง ุฏุณุชูโุจูุฏ ุฑุดุชูโโโูุงุ ฺฉ ุชุงุจุน ูุฒูู ุงุณุชุงูุฏุงุฏ ฺฉูุฑุงุณ ุจู ุฎูุจ ฺฉุงุฑ ูโฺฉูุฏุ ฺุฒ ฺฉู ูุง ุฏุฑ ุงูุฌุง ุงุณุชูุงุฏู ุฎูุงูู ฺฉุฑุฏ.

</Tip>

<div dir="ltr">

```py
from tensorflow.keras.losses import SparseCategoricalCrossentropy

model.compile(
    optimizer="adam",
    loss=SparseCategoricalCrossentropy(from_logits=True),
    metrics=["accuracy"],
)
model.fit(
    tf_train_dataset,
    validation_data=tf_validation_dataset,
)
```

</div>

<Tip warning={true}>

ุฏุฑ ุงูุฌุง ุชูุฌู ุดูุง ุฑุง ุจู ฺฉ ูุณุฆูู ุนุงู ุฌูุจ ูโฺฉูู - ุดูุง *ูโุชูุงูุฏ* ููุท ูุงู ุชุงุจุน ูุฒูู ุฑุง ุจู ุตูุฑุช ฺฉ ูุชุบุฑ ูุชู ุจุฑุง ฺฉูุฑุงุณ ุงุฑุณุงู ฺฉูุฏุ ุงูุง ฺฉูุฑุงุณ ุจู ุตูุฑุช ูพุดโูุฑุถ ูฺฉุฑ ูโฺฉูุฏ ุดูุง ฺฉ ูุงู softmax ุงุฒ ูพุด ุจู ุฎุฑูุฌโุชุงู ุงุนูุงู ฺฉุฑุฏูโุงุฏ. ุจุง ุงู ุญุงูุ ุจุณุงุฑ ุงุฒ ูุฏูโูุง ููุงุฏุฑ ุฑุง ุฏุฑุณุช ูุจู ุงุฒ ุงูฺฉู softmax ุจู ุขููุง ุงุนูุงู ุดูุฏ ุจู ุฎุฑูุฌ ูโุฏููุฏุ ฺฉู ููฺูู ุจู ุนููุงู *logits* ุดูุงุฎุชู ูโุดููุฏ. ูุง ูุงุฒ ุฏุงุฑู ฺฉู ุจู ุชุงุจุน ูุฒูู ุจฺฏููุ ุงู ฺฉุงุฑ ุงุณุช ฺฉู ูุฏูโูุงู ุงูุฌุงู ูโุฏูุฏ ู ุชููุง ุฑุงู ฺฏูุชู ุขู ุงู ุงุณุช ฺฉู ุจู ุฌุง ุงุฑุณุงู ูุงู ุชุงุจุน ูุฒูู ุจู ุตูุฑุช ูุชุบุฑ ูุชูุ ุขู ุฑุง ุจู ุตูุฑุช ูุณุชูู ุตุฏุง ุจุฒูู.

</Tip>

### ุจูุจูุฏ ฺฉุงุฑุง ุชุนูู

<Youtube id="cpzq6ESSM5c"/>

ุงฺฏุฑ ฺฉุฏ ุจุงูุง ุฑุง ุงูุชุญุงู ฺฉูุฏุ ูุทุนุง ุงุฌุฑุง ุฎูุงูุฏ ุดุฏุ ุงูุง ูุชูุฌู ุฎูุงูุฏ ุดุฏ ฺฉู ูุฒูู ุจุณุงุฑ ุขูุณุชู ุง ุจู ุตูุฑุช ฺฏุงู ู ุจฺฏุงู ฺฉุงูุด ูโุงุจุฏ. ุนูุช ุงุตู ุงู ุงูุฑ *ูุฑุฎ ุงุฏฺฏุฑ* ูโุจุงุดุฏ. ูุงููุฏ ุชุงุจุน ูุฒููุ ููุช ฺฉู ูุง ูุงู ุจูููโุณุงุฒ ุฑุง ุจู ุตูุฑุช ฺฉ ูุชุบุฑ ูุชู ุจู ฺฉูุฑุงุณ ุงุฑุณุงู ูโฺฉููุ ฺฉูุฑุงุณ ููู ูพุงุฑุงูุชุฑูุง ุขูุ ุดุงูู ูุฑุฎ ุงุฏฺฏุฑุ ุฑุง ุจุง ููุงุฏุฑ ูพุดโูุฑุถ ููุฏุงุฑุฏู ุงููู ูโฺฉูุฏ. ุจู ุชุฌุฑุจู ุทููุงูุ ูุง ูโุฏุงูู ฺฉู ูุฏูโูุง ุชุฑููุณููุฑููุฑ ุงุฒ ูุฑุฎโูุง ุงุฏฺฏุฑ ุจุณุงุฑ ฺฉูฺฺฉโุชุฑ ุจูุฑู ุจุดุชุฑ ูโุจุฑูุฏ ุชุง ููุฏุงุฑ ูพุดโูุฑุถ ุจุฑุง ุจูููโุณุงุฒ Adamุ ฺฉู <span dir="ltr">ฑe-ณ</span> ูโุจุงุดุฏ ู ุจู ุตูุฑุชโ ฑฐ ุจู ุชูุงู <span dir="ltr">-ณ</span> ุง ฐุฐฐฑ ูุฒ ููุดุชู ูโุดูุฏ.

ุนูุงูู ุจุฑ ฺฉู ฺฉุฑุฏู ฺฉุจุงุฑู ูุฑุฎ ุงุฏฺฏุฑุ ุชุฑููุฏ ุฏฺฏุฑ ูุฒ ุฏุฑ ุขุณุชู ุฏุงุฑู: ูุง ูโุชูุงูู ูุฑุฎ ุงุฏฺฏุฑ ุฑุง ุจู ุขูุณุชฺฏ ุฏุฑ ุทูู ุฏูุฑู ุชุนูู ฺฉุงูุด ุฏูู. ฺฏุงูุง ุฎูุงูุฏ ุฏุฏ ฺฉู ุงุฒ ุงู ุฑูุด ุฏุฑ ูุชูู ูุดุงุจู ุจุง ุนููุงู ูุฑุฎ ุงุฏฺฏุฑ *ูุญู ุดููุฏู* ุง *ุจุงุฒูพูุฎุช* ุงุฏ ูโุดูุฏ. ุจูุชุฑู ุฑูุด ุจุฑุง ุงูุฌุงู ุงู ฺฉุงุฑ ุฏุฑ ฺฉูุฑุงุณ ุงุณุชูุงุฏู ุงุฒ ุฒูุงูโุจูุฏ ูุฑุฎ ุงุฏฺฏุฑ ุงุณุช. ฺฉ ุฒูุงูโุจูุฏ ุฎูุจ ุจุฑุง ุงุณุชูุงุฏูุ ุฒูุงูโุจูุฏ `PolynomialDecay` ูโุจุงุดุฏ - ุงู ุฒูุงูโุจูุฏ ุจุฑุฎูุงู ูุงูุด ูุฑุฎ ุงุฏฺฏุฑ ุฑุง ุฏุฑ ุญุงูุช ูพุดโูุฑุถ ุจู ุตูุฑุช ุฎุท ุงุฒ ููุฏุงุฑ ุงููู ุชุง ููุฏุงุฑ ููุง  ุฏุฑ ุทูู ุฏูุฑู ุชุนูู ฺฉุงูุด ูโุฏูุฏ ฺฉู ุฏููุง ููุงู ฺุฒ ุงุณุช ฺฉู ูุง ูโุฎูุงูู. ุจู ููุธูุฑ ุงุณุชูุงุฏู ุฏุฑุณุช ุงุฒ ุฒูุงูโุจูุฏ ูุง ูุงุฒ ุฏุงุฑู ฺฉู ุจู ุขู ุจฺฏูู ุทูู ุฒูุงู ุชุนูู ฺูุฏุฑ ุฎูุงูุฏ ุจูุฏ. ุฏุฑ ุฒุฑ ูุง ุขู ุฑุง ุจู ุนููุงู `num_train_steps` ูุญุงุณุจู ูโฺฉูู.  

<div dir="ltr">

```py
from tensorflow.keras.optimizers.schedules import PolynomialDecay

batch_size = 8
num_epochs = 3
# The number of training steps is the number of samples in the dataset, divided by the batch size then multiplied
# by the total number of epochs. Note that the tf_train_dataset here is a batched tf.data.Dataset,
# not the original Hugging Face Dataset, so its len() is already num_samples // batch_size.
num_train_steps = len(tf_train_dataset) * num_epochs
lr_scheduler = PolynomialDecay(
    initial_learning_rate=5e-5, end_learning_rate=0.0, decay_steps=num_train_steps
)
from tensorflow.keras.optimizers import Adam

opt = Adam(learning_rate=lr_scheduler)
```

</div>

<Tip>

ฺฉุชุงุจุฎุงูู ุชุฑูุณููุฑูุฑูุง ูุงฺฏูฺฏโููุณ ููฺูู ฺฉ ุชุงุจุน <span dir="ltr">`create_optimizer()`</span> ุฏุงุฑุฏ ฺฉู ุจูููโุณุงุฒ ุงุฒ ููุน `AdamW`ุ ุฏุงุฑุง ูุฒุงู ฺฉุงูุด ูุฑุฎ ุงุฏฺฏุฑ ูโุณุงุฒุฏ. ุงู ฺฉ ูุงูโุจุฑ ููุงุณุจ ุงุณุช ฺฉู ุขูโ ุฑุง ุจุง ุฌุฒุฆุงุช ุฏุฑ ุจุฎุดโูุง ุจุนุฏ ุงู ุขููุฒุด ุฎูุงูุฏ ุฏุฏ.

</Tip>

ุงฺฉููู ุจูููโุณุงุฒ ฺฉุงููุง ุฌุฏุฏูุงู ุฑุง ุฏุฑ ุงุฎุชุงุฑ ุฏุงุฑู ู ูโุชูุงูู ุขู ุฑุง ุชุนูู ุฏูู. ุงุจุชุฏุงุ ุงุฌุงุฒู ุฏูุฏ ูุฏู ุฑุง ูุฌุฏุฏุง ุจุงุฑฺฏุฐุงุฑ ฺฉูู ุชุง ุชุบุฑุงุช ุงุฌุงุฏ ุดุฏู ุจุฑ ูุฒููุง ฺฉู ุฏุฑ ุชุนูู ูุจู ุงุนูุงู ุดุฏูโุงูุฏ ุฑุง ุจู ุญุงูุช ุงููู ุจุงุฒฺฏุฑุฏุงููุ ุณูพุณ ูโุชูุงูู ูุฏู ุฑุง ุจุง ุจููู ุณุงุฒ ุฌุฏุฏ ุชุฏูู ฺฉูู: 

<div dir="ltr">

```py
import tensorflow as tf

model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)
loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
model.compile(optimizer=opt, loss=loss, metrics=["accuracy"])
```

</div>

ุญุงูุง ุฏูุจุงุฑู ูุฏู ุฑุง ูุช ูโฺฉูู:

<div dir="ltr">

```py
model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=3)
```

</div>


<Tip>

๐ก ุงฺฏุฑ ูุงูุฏ ูุฏูุชุงู ุฑุง ุฏุฑ ุญู ุชุนูู ุจู ุตูุฑุช ุฎูุฏฺฉุงุฑ ุฏุฑ ูุงุจ ุจุงุฑฺฏุฐุงุฑ ฺฉูุฏุ ูโุชูุงูุฏ ูพุงุฑุงูุชุฑ `PushToHubCallback` ุฑุง ุฏุฑ ุชุงุจุน <span dir="ltr">`model.fit()`</span> ุงุฑุณุงู ฺฉูุฏ. ุฏุฑ [ูุตู ด](/course/chapter4/3) ุฏุฑ ุงู ููุฑุฏ ุจุดุชุฑ ุฎูุงูู ุขููุฎุช. 

</Tip>

### ูพุดโุจูโูุง ูุฏู

<Youtube id="nx10eh4CoOs"/>

ุชุนูู ู ุชูุงุดุง ูพุงู ุฑูุชู ูุฒูู ุฎู ุฎูุจ ุงุณุชุ ุงูุง ุงฺฏุฑ ูุงูุนุง ุจุฎูุงูู ุงุฒ ูุฏู ุชุนูู ุฏุฏูโูุงูุ ฺู ุจุฑุง ูุญุงุณุจู ุจุฑุฎ ูุนุงุฑโูุง ู ฺู ุจุฑุง ุงุณุชูุงุฏู ุฏุฑ ุฎุท ุชููุฏุ ุฎุฑูุฌ ุฏุฑุงูุช ฺฉูู ุจุงุฏ ฺู ฺฉุงุฑ ฺฉููุ ุจุฑุง ุงู ููุธูุฑ ูโุชูุงูู ุงุฒ ุชุงุจุน <span dir="ltr">`predict()`</span> ุงุณุชูุงุฏู ฺฉูู. ุงู ฺฉุงุฑ ุจู ุงุฒุง ูุฑ ฺฉูุงุณ ฺฉ  *logits* ุงุฒ ูุงูโ ุณูุฑ ุฎุฑูุฌ ูุฏู ุจุงุฒ ูโฺฏุฑุฏุงูุฏ.


<div dir="ltr">

```py
preds = model.predict(tf_validation_dataset)["logits"]
```

</div>

ุณูพุณ ูโุชูุงูู `logits` ุฑุง ุจุง ุงุณุชูุงุฏู ุงุฒ `argmax` ุจุฑุง ุงูุชู ุจุฒุฑฺฏโุชุฑู `logit`ุ ฺฉู ููุงูุฏู ูุญุชููโุชุฑู ุฏุณุชู ูโุจุงุดุฏุ ุจู ูพุดโุจูโูุง ุฏุณุชู ูุฏู ุชุจุฏู ฺฉูู:

<div dir="ltr">

```py
class_preds = np.argmax(preds, axis=1)
print(preds.shape, class_preds.shape)
```

</div>

<div dir="ltr">

```python out
(408, 2) (408,)
```

</div>

ุงฺฉูููุ ุงุฌุงุฒู ุฏูุฏ ุงุฒ `preds` ุจุฑุง ูุญุงุณุจู ุจุฑุฎ ูุนุงุฑูุง ุงุณุชูุงุฏู ฺฉูู! ูุง ูโุชูุงูู ูุนุงุฑูุง ูุฑุชุจุท ุจุง ุฏุชุงุณูุช MRPC ุฑุงุ ุจู ููุงู ุขุณุงู ฺฉู ุฏุชุงุณูุช ุฑุง ุจุงุฑฺฏุฐุงุฑ ฺฉุฑุฏูุ ุจุงุฑฺฏุฐุงุฑ ฺฉูู ุงูุง ุงู ุจุงุฑ ุจุง ุงุณุชูุงุฏู ุงุฒ ุชุงุจุน <span dir="ltr">`load_metric()`</span>. ุดุก ุจุงุฒ ฺฏุฑุฏุงูุฏู ุดุฏู ุชุงุจุน ุจู ูุงู <span dir="ltr">`compute()`</span> ุฏุงุฑุฏ ฺฉู ูโุชูุงูู ุจุฑุง ูุญุงุณุจู ูุนุงุฑูุง ุงุฒ ุขู ุงุณุชูุงุฏู ฺฉูู:

<div dir="ltr">

```py
from datasets import load_metric

metric = load_metric("glue", "mrpc")
metric.compute(predictions=class_preds, references=raw_datasets["validation"]["label"])
```

</div>

<div dir="ltr">

```python out
{'accuracy': 0.8578431372549019, 'f1': 0.8996539792387542}
```

</div>

ุงุฒ ุขูุฌุง ฺฉู ููุฏุงุฑุฏู ุงููู ุชุตุงุฏู ุฏุฑ ูุงูโ ุณูุฑ ูุฏู ููฺฉู ุงุณุช ููุงุฏุฑ ูุนุงุฑูุง ุญุงุตู ุฑุง ุชุบุฑ ุฏูุฏุ ูุชุงุฌ ุฏุฑุงูุช ุดูุง ูโุชูุงููุฏ ูุชูุงูุช ุจุงุดูุฏ. ุฏุฑ ุงูุฌุง ูโุจูู ฺฉู ูุฏู ูุง ุฏูุช ูุนุงุฏู ธต.ทธูช ู <span dir="ltr">F1 score</span> ูุนุงุฏู ธน.นทูช ุฑู ูุฌููุนู `validation` ุฏุงุฑุฏ. ุงูโโูุง ุฏู ูุนุงุฑ ูุณุชูุฏ ฺฉู ุฌูุช ุณูุฌุด ูุชุงุฌ ุฑู ุฏุงุฏู MRPC ุฏุฑ ูุญฺฉ GLUE ุจู ฺฉุงุฑ ุฑูุชูโุงูุฏ. ุฌุฏูู ูุชุงุฌ ุฏุฑ ููุงูู [BERT](https://arxiv.org/pdf/1810.04805.pdf)ุ <span dir="ltr">F1 score</span> ุจุฑุงุจุฑ ุจุง ธธ.น ุจุฑุง ูุฏู ูพุงู ฺฏุฒุงุฑุด ฺฉุฑุฏู ุงุณุช. ุชูุฌู ุฏุงุดุชู ุจุงุดุฏ ฺฉู ุขู ูุฏู `uncased` ุจูุฏ ุฏุฑ ุญุงู ฺฉู ุงฺฉููู ูุง ุงุฒ ูุฏู `cased` ุงุณุชูุงุฏู ูโฺฉููุ ฺฉู ูุชุงุฌ ุจูุชุฑ ุฑุง ุชูุฌุญ ูโฺฉูุฏ.

ุจู ุงู ุชุฑุชุจ ููุฏูู ฺฉูฺฉ ฺฉุฑุฏู ุจุง ุงุณุชูุงุฏู ุงุฒ `API` ฺฉูุฑุงุณ ุจู ูพุงุงู ูโุฑุณุฏ. ุฏุฑ ูุตู ท ฺฉ ูุซุงู ุงุฒ ุงูุฌุงู ุงู ฺฉุงุฑ ุจุฑุง ูุนูููโุชุฑู ูุณุฆููโูุง `NLP` ุงุฑุงุฆู ุฎูุงูุฏ ุดุฏ. ุงฺฏุฑ ูุงูุฏ ููุงุฑุชโูุง ุฎูุฏ ุฑุง ุฑู `API` ฺฉูุฑุงุณ ุชููุช ฺฉูุฏุ ุณุน ฺฉูุฏ ูุฏู ุฑุง ุฑู ูุณุฆูู <span dir="ltr">`GLUE SST-2`</span>ุ ุจุง ุงุณุชูุงุฏู ุงุฒ ุฑูุด ูพุฑุฏุงุฒุด ุฏุงุฏูโ ฺฉู ุฏุฑ ุจุฎุด ฒ ุงูุฌุงู ุฏุงุฏุฏุ ฺฉูฺฉ ฺฉูุฏ.


</div>