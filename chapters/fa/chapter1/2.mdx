# پردازش زبان طبیعی و مدل‌های زبانی بزرگ[[natural-language-processing-and-large-language-models]]

<CourseFloatingBanner
    chapter={1}
    classNames="absolute z-10 right-0 top-0"
/>

قبل از آنکه وارد بحث مدل‌های ترنسفورمر شویم، بیایید نگاهی سریع بیندازیم به این‌که پردازش زبان طبیعی (NLP) چیست، مدل‌های زبانی بزرگ چگونه این حوزه را متحول کرده‌اند و چرا این موضوع برای ما اهمیت دارد.

## NLP چیست؟[[what-is-nlp]]

<Youtube id="iNzlxWUAjd4" />

NLP شاخه‌ای میان‌رشته‌ای از زبان‌شناسی و یادگیری ماشین است که بر درک همه‌ی جنبه‌های زبان انسان تمرکز دارد. هدف از وظایف NLP صرفاً درک واژه‌ها به‌صورت جداگانه نیست، بلکه توانایی درک **زمینه و مفهوم واژه‌ها در متن** است.

در ادامه، فهرستی از وظایف رایج در NLP آمده است همراه با چند نمونه برای هرکدام:

- **دسته‌بندی جملات کامل**: تشخیص احساسات یک نظر، شناسایی هرزنامه بودن ایمیل، بررسی درستی گرامری جمله یا تشخیص منطقی بودن ارتباط دو جمله
- **برچسب‌گذاری هر واژه در جمله**: شناسایی اجزای دستوری جمله (اسم، فعل، صفت) یا موجودیت‌های نامدار مانند نام افراد، مکان‌ها یا سازمان‌ها
- **تولید محتوای متنی**: ادامه دادن یک ورودی متنی با استفاده از متن تولیدشده خودکار، یا تکمیل جای‌خالی‌ها در یک متن با واژه‌های مناسب
- **استخراج پاسخ از یک متن**: با داشتن یک سوال و یک متن زمینه، استخراج پاسخ مناسب بر اساس اطلاعات ارائه‌شده در آن متن
- **تولید جمله جدید از روی یک متن ورودی**: ترجمه‌ی یک متن به زبان دیگر، یا خلاصه‌سازی آن

NLP تنها محدود به متن نوشتاری نیست. این حوزه همچنین با چالش‌های پیچیده‌تری در حوزه‌های **تشخیص گفتار و بینایی ماشین** نیز مواجه است؛ مانند: تولید متن از روی فایل صوتی یا توصیف یک تصویر.

## ظهور مدل‌های زبانی بزرگ (LLMs)[[rise-of-llms]]

در سال‌های اخیر، حوزه‌ی NLP با ظهور مدل‌های زبانی بزرگ (LLMs) دگرگون شده است. این مدل‌ها که معماری‌هایی مانند GPT (مخفف Generative Pre-trained Transformer) و [Llama](https://huggingface.co/meta-llama) را شامل می‌شوند، مرزهای جدیدی را در پردازش زبان گشوده‌اند.

<Tip>

یک مدل زبانی بزرگ (LLM)، مدلی از هوش مصنوعی است که با حجم عظیمی از داده‌های متنی آموزش دیده و می‌تواند متنی مشابه زبان انسان تولید کند، الگوهای زبانی را تشخیص دهد و طیف وسیعی از وظایف زبانی را بدون نیاز به آموزش اختصاصی انجام دهد. این مدل‌ها پیشرفتی چشمگیر در حوزه‌ی پردازش زبان طبیعی به شمار می‌آیند.

</Tip>

ویژگی‌های اصلی LLMها عبارت‌اند از:

- **مقیاس‌پذیری**: شامل میلیون‌ها تا صدها میلیارد پارامتر هستند
- **توانمندی عمومی**: می‌توانند وظایف مختلفی را بدون آموزش خاص انجام دهند
- **یادگیری درون‌متنی**: از مثال‌هایی که در پرامپت ارائه می‌شوند یاد می‌گیرند
- **قابلیت‌های نوظهور**: هر چه بزرگ‌تر می‌شوند، قابلیت‌هایی بروز می‌کنند که در طراحی اولیه پیش‌بینی نشده‌اند

ظهور LLMها، پارادایم طراحی مدل‌های خاص برای وظایف جداگانه را به سمت استفاده از یک مدل بزرگ و عمومی که قابل تنظیم یا هدایت با پرامپت است تغییر داده. این کار باعث دسترسی آسان‌تر به پردازش پیشرفته زبان شده، اما چالش‌هایی در زمینه‌هایی چون بهره‌وری، اخلاق و استقرار مدل نیز به همراه آورده است.

### با این حال، LLMها محدودیت‌هایی نیز دارند:

- **توهم‌زایی (Hallucination)**: تولید اطلاعات نادرست با اطمینان بالا
- **فقدان درک واقعی**: صرفاً بر اساس الگوهای آماری عمل می‌کنند و فاقد فهم عمیق از جهان هستند
- **سوگیری**: ممکن است سوگیری‌های موجود در داده‌های آموزشی یا ورودی را بازتولید کنند
- **محدودیت پنجره‌ی متنی**: توانایی پردازش تنها مقدار محدودی از متن در یک‌زمان (که البته در حال بهبود است)
- **نیاز به منابع محاسباتی بالا**: اجرای این مدل‌ها نیازمند سخت‌افزارهای قدرتمند است

## چرا پردازش زبان چالش‌برانگیز است؟[[why-is-it-challenging]]

کامپیوترها اطلاعات را همانند انسان‌ها پردازش نمی‌کنند. برای مثال، وقتی جمله‌ی «من گرسنه‌ام» را می‌خوانیم، به‌سادگی معنی آن را متوجه می‌شویم. همچنین، اگر دو جمله مانند «من گرسنه‌ام» و «من ناراحتم» را ببینیم، می‌توانیم میزان شباهت آن‌ها را تشخیص دهیم. اما برای مدل‌های یادگیری ماشین، انجام چنین کارهایی به مراتب دشوارتر است.

متن باید به شیوه‌ای بازنمایی شود که برای مدل‌ها قابل یادگیری باشد. از آن‌جایی که زبان بسیار پیچیده است، باید در مورد چگونگی پردازش آن به‌دقت فکر کرد. تحقیقات زیادی در مورد نحوه‌ی بازنمایی متن انجام شده که در فصل بعدی به برخی از این روش‌ها خواهیم پرداخت.

با وجود پیشرفت‌های بزرگ در مدل‌های زبانی، همچنان چالش‌های بنیادینی باقی مانده‌اند؛ از جمله درک ابهام، زمینه‌های فرهنگی، کنایه و شوخ‌طبعی. LLMها این چالش‌ها را با آموزش گسترده روی داده‌های متنوع تا حدی حل کرده‌اند، اما همچنان در بسیاری از موقعیت‌های پیچیده، از سطح درک انسانی فاصله دارند.
