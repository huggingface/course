<div dir="rtl">
# مقدمه

## به دوره‌ آموزشی هاگینگ‌فِیس خوش آمدید

<Youtube id="00GKzGyWFEs" />

در این دوره آموزشی، پردازش زبان طبیعی[^1] را با استفاده از کتابخانه‌های اکوسیستم [هاگینگ‌فِیس](https://huggingface.co/) یعنی [Transformers](https://github.com/huggingface/transformers), [Datasets](https://github.com/huggingface/datasets), [Tokenizers](https://github.com/huggingface/tokenizers), [Accelerate](https://github.com/huggingface/accelerate) و همچنین [هاب هاگینگ‌فِیس](https://huggingface.co/models) می‌آموزید. این دوره کاملا رایگان و بدون تبلیغات است.

## در این دوره چه چیزهایی را می‌آموزیم؟

دید کلی کوتاه از مباحث این دوره آموزشی:

<div class="flex justify-center">
<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary.svg" alt="دید کلی کوتاه از مباحث این دوره آموزشی">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary-dark.svg" alt="دید کلی کوتاه از مباحث این دوره آموزشی">
</div>

- از فصل ۱ تا ۴ مقدمه‌ای از مباحث‌ پایه‌‌ای کتابخانه‌ی ترنسفورمرز هاگینگ‌فِیس ارائه می‌شود. در پایان این فصل، شما با شیوه‌ی عملکرد مدل‌های ترنسفومر آشنا می‌شوید و می‌آموزید که چگونه از یک مدل در [هاب هاگینگ‌فِیس](https://huggingface.co/models) استفاده کنید، آن را برای مجموعه داده خود کوک کنید و نتایج خود را در هاب به اشتراک بگذارید.
- در فصل‌های ۵ تا ۸، اصول پایه‌‌ی کتابخانه‌های Datasets و Tokenizers، پیش از آن که وارد مسائل کلاسیک NLP شویم،‌ آموزش داده می‌شوند. در پایان این فصول، قادر خواهید بود مسائل متداول NLP را به تنهایی حل کنید.
- فصل‌های ۹ تا ۱۲ به مباحث فراتر از NLP و استفاده از مدل‌های ترنسفورمر برای حل مسائل پردازش گفتار و بینایی ماشین می‌پردازند. در طی این مسیر، فرا می‌گیرید که چگونه مدلی جدید ساخته، نمونه اولیه از آن را عرضه کرده و برای محیط استقرار نرم‌افزار بهینه‌اش کنید. در پایان این فصل، آماده‌ی استفاده از ترنسفورمرهای هاگینگ‌فِیس برای (تقریبا) همه مسائل یادگیری ماشین خواهید بود.

این دوره آموزشی:

- به سطح خوبی از دانش پایتون نیاز دارد.
- بهتر است پس از یک دوره آموزشی آشنایی با یادگیری عمیق، مانند دوره آموزشی یادگیری عمیق عملی برای برنامه‌نویس‌ها از [fast.ai](https://www.fast.ai/) و یا یکی از دوره‌های ارائه شده توسط [DeepLearning.AI](https://www.deeplearning.ai/)، دنبال شود.
- نیازمند دانش پیشین [پایتورچ](https://pytorch.org/) یا [تِنسورفِلو](https://www.tensorflow.org/) نیست، با این حال آشنایی با هر کدام از آنها می‌تواند کمک‌کننده باشد.

پس از اینکه این دوره آموزشی را به پایان رساندید، توصیه می‌کنیم نگاهی به [دوره آموزشی تخصصی پردازش زبان طبیعی](https://www.coursera.org/specializations/natural-language-processing) که توسط [DeepLearning.AI](https://www.deeplearning.ai/) ارائه شده است، بیاندازید. این دوره، بخش اعظمی از مدل‌های سنتی‌ NLP مانند دسته‌بندی‌کننده بیز ساده و LSTMها را شامل می‌شود که شناخت آن‌ها ارزشمند است.

## ما چه کسانی هستیم؟

درباره نویسندگان:

**متیو کاریگن**[^2] مهندس یادگیری ماشین در هاگینگ‌فِیس است. او در دوبلین ایرلند زندگی می‌کند و پیش‌تر بعنوان مهندس یادگیری ماشین در [Parse.ly](https://www.parse.ly/) مشغول به کار بوده است. او دوره‌ی تحقیقات پسادکترای خود را در کالج ترینیتی دوبلین به پایان رسانده است. به عقیده‌ی وی هوش جامع مصنوعی[^3] با افزایش مقیاس معماری‌های فعلی حاصل نخواهد شد، با این حال او امید بسیاری به جاودانگی انسان در قالب رباتی دارد.

**لیسندره دبوت**[^4] مهندس یادگیری ماشین در هاگینگ‌فِیس است و از ابتدا، بر روی کتابخانه‌ی ترنفسورمرهای هاگینگ‌فِیس کار کرده است. هدف او دسترس‌پذیر کردن NLP برای همگان با توسعه ابزارهایی با API بسیار ساده است.

**سیلوین گوجر**[^5] مهندس محقق در هاگینگ‌فِیس است و از هسته‌ی تیم مدیریت‌کنندگان کتابخانه‌ی ترنفسورمرهای هاگینگ‌فِیس محسوب می‌شود. او قبل‌تر مهندس محقق در fast.ai بود و [کتاب یادگیری عمیق عملی برای برنامه‌نویس‌ها](https://learning.oreilly.com/library/view/deep-learning-for/9781492045519/) با استفاده از [fast.ai](https://www.fast.ai/) و پایتورچ را با همکاری جرمی هاوارد[^6] نگاشته است. تمرکز اصلی تحقیقات وی بر دسترس‌پذیرتر کردن یادگیری عمیق است. او برای این کار از طراحی و پیش‌برد شیوه‌هایی استفاده می‌کند که امکان یادگیری سریع با منابع محدود را برای مدل‌ها پدید می‌آورد.

**مروه نویان**[^7] توسعه‌ی دهنده در هاگینگ‌فِیس است و بر روی توسعه‌ی ابزارها و تولید محتوا برای آن‌ها کار می‌کند. هدف او دسترس‌پذیر کردن یادگیری ماشین برای همگان است.

**لوسیله ساولنیر**[^8] مهندس یادگیری ماشین در هاگینگ‌فِیس است و بر روی توسعه و پشتیبانی از ابزارهای متن‌باز تمرکز دارد. وی همچنین بصورت فعالانه‌ای در بسیاری از پروژهای تحقیقاتی در حوزه پردازش زبان طبیعی، مانند یادگیری مشارکتی و بیگ‌ساینس مشارکت دارد.

**لویس تونستال**[^9] مهندس یادگیری ماشین در هاگینگ‌فِیس است. تمرکز اصلی او توسعه‌ی ابزارهای متن باز و دسترس‌پذیر کردن آنها برای جامعه‌ی گسترده‌تری از کاربران است. او همچنین از نویسندگان [کتاب انتشارات اُریلی[^10] درباره‌ی ترنسفورمرها](https://www.oreilly.com/library/view/natural-language-processing/9781098103231/) است.

**لئاندرو ون ورا**[^11] مهندس یادگیری ماشین در تیم متن‌باز هاگینگ‌فِیس و از نویسندگان [کتاب انتشارات اُریلی درباره‌ی ترنسفورمرها](https://www.oreilly.com/library/view/natural-language-processing/9781098103231/) است. وی تجربه‌ی چندین سال کار در صنعت را دارد. او با کار در تمام جنبه‌های یادگیری ماشین، پروژه‌های متن‌باز را از مرحله‌ی تحقیق به استقرار در صنایع می‌رساند.

آماده‌ی ورود به این دوره هستید؟ در این فصل شما می‌آموزید که:

- چگونه می‌توان از تابع <span dir="ltr">pipeline()</span> برای حل مسائل NLP مانند تولید متن و دسته‌بندی استفاده کرد.
- معماری ترنسفورمرها چگونه است.
- چگونه معماری‌های مختلف انکودر، دیکودر و انکودر-دیکودر را از یکدیگر تشخصی داد و کاربردهای آن‌ها در چیست.

[^1]: Natural Language Processing (NLP)
[^2]: Matthew Carrigan
[^3]: Artificial General Intelligence (AGI)
[^4]: Lysandre Debut
[^5]: Sylvain Gugger
[^6]: Jeremy Howard
[^7]: Merve Noyan
[^8]: Lucile Saulnier
[^9]: Lewis Tunstall
[^10]: O'Reilly
[^11]: Leandro von Werra

</div>
