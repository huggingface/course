<div dir="rtl">
# مقدمه


همان طور که در [فصل اول](/course/chapter1) دیدید، مدل‌های ترنسفورمر معمولا بسیار بزرگ هستند. با داشتن میلیون‌ها یا حتی ده‌ها میلیارد پارامتر، تعلیم و بکارگیری این مدل‌ها کار بسیار پیچیده‌ای است. علاوه بر این،‌ تقریبا هر روز مدل‌های جدیدی عرضه می‌شوند که هرکدام شیوه پیاده‌سازی خود را دارند و امتحان کردن تمام آن‌ها کار آسانی نیست.

کتابخانه ترنسفومرهای هاگینگ‌فیس برای حل این مشکل تولید شده است. هدف آن، ارائه یک API واحد برای بارگذاری، تعلیم و ذخیره‌سازی مدل‌های ترنسفورمر است. ویژگی های اصلی این کتابخانه از این قرار است:


<div dir="RTL">
  <ul>
    <li><b>آسانی استفاده</b>: دانلود، بارگذاری و استفاده از مدل‌های NLP روز دنیا برای تولید نتیجه عملیاتی، فقط با دو خط کد امکان‌پذیر است.</li>
    <li><b>انعطاف</b>: تمام مدل‌ها در واقع کلاس‌های معمولی پایتورچ مانند nn.Module یا کلاس های تنسورفلو مانند tf.keras.Model هستند و مانند هر مدل دیگری در فریمورک خود در دسترسی قرار دارند.</li>
    <li><b>سادگی</b>: در طراحی کتابخانه انتزاعات بسیار کمی به کار رفته‌ است. اصل «قائم به خود» بودن مدل ها بسیار مهم بوده به طوری که یکبار اجرای رو به جلوی آن‌ها تنها در یک فایل تعریف می‌شود تا کد آن قابل فهم و تغییر باشد.</li>
  </ul>
</div>

این ویژگی آخر باعث می‌شود ترنسفورمرهای هاگینگ‌فیس بسیار متفاوت با نمونه‌های مشابه در کتابخانه‌های یادگیری ماشین دیگر باشند. مدل‌ها روی ماژول های متفاوتی که در فایل‌های مختلف قرار دارند بنا نشده‌اند؛ بلکه هر مدل محتوی لایه‌های خود است. علاوه بر ساده‌تر و قابل فهم‌تر کردن مدل‌ها، این ویژگی به شما اجازه می‌دهد به راحتی یک مدل را دستکاری کنید بدون این که بر مدل‌های دیگر تاثیر بگذارید.

این فصل با یک مثال کامل شروع می شود که در آن یک مدل و یک توکنایزر را با هم استفاده می‌کنیم تا عملیات <span dir="ltr">pipeline()</span> که در فصل اول معرفی کردیم را شبیه سازی کنیم. سپس API مربوط به مدل‌ها را بررسی می‌کنیم و وارد پیچیدگی‌های کلاس‌های مدل و کلاس‌های تنظیمات می‌شویم تا نشان دهیم چگونه می‌توان مدل‌ها را بارگذاری نمود و این مدل‌ها چطور ورودی‌های عددی را پردازش می‌کنند تا در خروجی پیش‌بینی‌ها را تولید کنند.

سپس نگاهی به API مربوط به توکنایزر خواهیم داشت که بخش دیگر پیاده‌سازی عملیات <span dir="ltr">pipeline()</span> است. توکنایزرها مرحله اول و مرحله آخر پردازش را انجام می‌دهند که در طی آن‌ها داده‌های نوشتاری را به ورودی‌های عددی برای شبکه عصبی تبدیل نموده و هنگام نیاز باز داده‌های عددی را به نوشتار تبدیل می‌کنند. در انتها، به شما نشان خواهیم داد چگونه چندین جمله را همزمان در یک بتچ از پیش آماده شده از مدل عبور دهید و سپس ان را با یک نگاه نزدیکتر به عملیات بالادستی <span dir="ltr">tokenizer()</span> به اتمام خواهیم برد.


برای استفاده بردن از تمامی ویژگی‌های موجود در Model Hub و ترنسفورمرهای هاگینگ‌فیس پیشنهاد می کنیم که <a href="https://huggingface.co/join"> حساب کاربری بسازید.</a>

</div>
