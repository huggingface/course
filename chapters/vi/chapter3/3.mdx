<FrameworkSwitchCourse {fw} />

# Tinh ch·ªânh m·ªôt m√¥ h√¨nh v·ªõi Trainer API

<CourseFloatingBanner chapter={3}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/vi/chapter3/section3.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/vi/chapter3/section3.ipynb"},
]} />

<Youtube id="nvBXf7s7vTI"/>

ü§ó Transformers cung c·∫•p l·ªõp `Trainer` ƒë·ªÉ gi√∫p b·∫°n tinh ch·ªânh b·∫•t k·ª≥ m√¥ h√¨nh hu·∫•n luy·ªán tr∆∞·ªõc n√†o m√† n√≥ cung c·∫•p tr√™n t·∫≠p d·ªØ li·ªáu c·ªßa b·∫°n. Khi b·∫°n ƒë√£ ho√†n th√†nh t·∫•t c·∫£ c√¥ng vi·ªác ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu trong ph·∫ßn cu·ªëi c√πng, b·∫°n ch·ªâ c√≤n m·ªôt v√†i b∆∞·ªõc ƒë·ªÉ ƒë·ªãnh nghƒ©a `Trainer`. Ph·∫ßn kh√≥ nh·∫•t c√≥ th·ªÉ l√† chu·∫©n b·ªã m√¥i tr∆∞·ªùng ƒë·ªÉ ch·∫°y `Trainer.train()`, v√¨ n√≥ s·∫Ω ch·∫°y r·∫•t ch·∫≠m tr√™n CPU. N·∫øu b·∫°n ch∆∞a thi·∫øt l·∫≠p GPU, b·∫°n c√≥ th·ªÉ c√≥ quy·ªÅn truy c·∫≠p v√†o GPU ho·∫∑c TPU mi·ªÖn ph√≠ tr√™n [Google Colab](https://colab.research.google.com/).

C√°c v√≠ d·ª• m√£ b√™n d∆∞·ªõi gi·∫£ s·ª≠ b·∫°n ƒë√£ th·ª±c hi·ªán c√°c v√≠ d·ª• trong ph·∫ßn tr∆∞·ªõc. D∆∞·ªõi ƒë√¢y l√† m·ªôt b·∫£n t√≥m t·∫Øt ng·∫Øn t√≥m t·∫Øt l·∫°i nh·ªØng g√¨ b·∫°n c·∫ßn:

```py
from datasets import load_dataset
from transformers import AutoTokenizer, DataCollatorWithPadding

raw_datasets = load_dataset("glue", "mrpc")
checkpoint = "bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)


def tokenize_function(example):
    return tokenizer(example["sentence1"], example["sentence2"], truncation=True)


tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)
data_collator = DataCollatorWithPadding(tokenizer=tokenizer)
```

### Hu·∫•n luy·ªán

B∆∞·ªõc ƒë·∫ßu ti√™n tr∆∞·ªõc khi ch√∫ng ta c√≥ th·ªÉ ƒë·ªãnh nghƒ©a `Trainer` c·ªßa m√¨nh l√† ƒë·ªãnh nghƒ©a m·ªôt l·ªõp `TrainingArguments` s·∫Ω ch·ª©a t·∫•t c·∫£ c√°c si√™u tham s·ªë m√† `Trainer` s·∫Ω s·ª≠ d·ª•ng ƒë·ªÉ hu·∫•n luy·ªán v√† ƒë√°nh gi√°. Tham s·ªë duy nh·∫•t b·∫°n ph·∫£i cung c·∫•p l√† m·ªôt th∆∞ m·ª•c n∆°i m√¥ h√¨nh ƒë∆∞·ª£c hu·∫•n luy·ªán s·∫Ω ƒë∆∞·ª£c l∆∞u, c≈©ng nh∆∞ c√°c checkpoint ƒëi k√®m. ƒê·ªëi v·ªõi t·∫•t c·∫£ ph·∫ßn c√≤n l·∫°i, b·∫°n c√≥ th·ªÉ ƒë·ªÉ m·∫∑c ƒë·ªãnh, n√≥ s·∫Ω ho·∫°t ƒë·ªông kh√° t·ªët v·ªõi tinh ch·ªânh c∆° b·∫£n.

```py
from transformers import TrainingArguments

training_args = TrainingArguments("test-trainer")
```

> [!TIP]
> üí° N·∫øu b·∫°n mu·ªën t·ª± ƒë·ªông t·∫£i m√¥ h√¨nh c·ªßa m√¨nh l√™n Hub trong qu√° tr√¨nh hu·∫•n luy·ªán, h√£y chuy·ªÉn sang ph·∫ßn `push_to_hub=True` trong ph·∫ßn `TrainingArguments`. Ch√∫ng ta s·∫Ω t√¨m hi·ªÉu th√™m v·ªÅ ƒëi·ªÅu n√†y trong [Ch∆∞∆°ng 4](/course/chapter4/3)

B∆∞·ªõc th·ª© hai l√† x√°c ƒë·ªãnh m√¥ h√¨nh c·ªßa ch√∫ng ta. Nh∆∞ trong [ch∆∞∆°ng tr∆∞·ªõc](/course/chapter2), ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng l·ªõp `AutoModelForSequenceClassification`, v·ªõi hai nh√£n:

```py
from transformers import AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)
```

B·∫°n s·∫Ω nh·∫≠n th·∫•y r·∫±ng kh√¥ng nh∆∞ trong [Ch∆∞∆°ng 2](/course/chapter2), b·∫°n nh·∫≠n ƒë∆∞·ª£c m·ªôt c·∫£nh b√°o sau khi kh·ªüi t·∫°o m√¥ h√¨nh ƒë∆∞·ª£c hu·∫•n luy·ªán tr∆∞·ªõc n√†y. ƒê√¢y l√† do BERT ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán tr∆∞·ªõc v·ªÅ ph√¢n lo·∫°i c√°c c·∫∑p c√¢u, v√¨ v·∫≠y ph·∫ßn ƒë·∫ßu c·ªßa m√¥ h√¨nh ƒë∆∞·ª£c hu·∫•n luy·ªán tr∆∞·ªõc ƒë√£ b·ªã lo·∫°i b·ªè v√† ph·∫ßn ƒë·∫ßu m·ªõi ph√π h·ª£p ƒë·ªÉ ph√¢n lo·∫°i chu·ªói ƒë√£ ƒë∆∞·ª£c ch√®n v√†o thay th·∫ø. C√°c c·∫£nh b√°o ch·ªâ ra r·∫±ng m·ªôt s·ªë tr·ªçng s·ªë ƒë√£ kh√¥ng ƒë∆∞·ª£c s·ª≠ d·ª•ng (nh·ªØng tr·ªçng s·ªë t∆∞∆°ng ·ª©ng v·ªõi ƒë·∫ßu hu·∫•n luy·ªán tr∆∞·ªõc b·ªã r·ª•ng) v√† m·ªôt s·ªë tr·ªçng s·ªë kh√°c kh√°c ƒë∆∞·ª£c kh·ªüi t·∫°o ng·∫´u nhi√™n (nh·ªØng tr·ªçng s·ªë d√†nh cho ƒë·∫ßu m·ªõi). N√≥ k·∫øt th√∫c b·∫±ng c√°ch khuy·∫øn kh√≠ch b·∫°n hu·∫•n luy·ªán m√¥ h√¨nh, ƒë√≥ ch√≠nh x√°c l√† nh·ªØng g√¨ ch√∫ng ta s·∫Ω l√†m b√¢y gi·ªù.

Khi ch√∫ng ta c√≥ m√¥ h√¨nh c·ªßa m√¨nh, ch√∫ng ta c√≥ th·ªÉ x√°c ƒë·ªãnh m·ªôt `Trainer` b·∫±ng c√°ch truy·ªÅn v√†o t·∫•t c·∫£ c√°c ƒë·ªëi t∆∞·ª£ng ƒë∆∞·ª£c x√¢y d·ª±ng t·ª´ tr∆∞·ªõc ƒë·∫øn nay - `model`, `training_args`, t·∫≠p hu·∫•n luy·ªán v√† ki·ªÉm ƒë·ªãnh,`data_collator` v√† `tokenizer`:

```py
from transformers import Trainer

trainer = Trainer(
    model,
    training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    tokenizer=tokenizer,
)
```

L∆∞u √Ω r·∫±ng khi b·∫°n truy·ªÅn `tokenizer` nh∆∞ ch√∫ng ta ƒë√£ l√†m ·ªü ƒë√¢y, m·∫∑c ƒë·ªãnh `data_collator` ƒë∆∞·ª£c s·ª≠ d·ª•ng b·ªüi `Trainer` s·∫Ω l√† `DataCollatorWithPadding` nh∆∞ ƒë√£ ƒë·ªãnh nghƒ©a tr∆∞·ªõc ƒë√≥, v√¨ v·∫≠y b·∫°n c√≥ th·ªÉ b·ªè qua d√≤ng `data_collator = data_collator` trong l·ªánh g·ªçi n√†y. ƒêi·ªÅu quan tr·ªçng l√† ph·∫£i cho b·∫°n th·∫•y ph·∫ßn n√†y c·ªßa qu√° tr√¨nh trong ph·∫ßn 2!

ƒê·ªÉ tinh ch·ªânh m√¥ h√¨nh tr√™n t·∫≠p d·ªØ li·ªáu, ch√∫ng ta ch·ªâ c·∫ßn g·ªçi ph∆∞∆°ng th·ª©c `train()` c·ªßa `Trainer`:

```py
trainer.train()
```

Thao t√°c n√†y s·∫Ω b·∫Øt ƒë·∫ßu qu√° tr√¨nh tinh ch·ªânh (s·∫Ω m·∫•t v√†i ph√∫t tr√™n GPU) v√† b√°o c√°o l·ªói ƒë√†o t·∫°o sau m·ªói 500 b∆∞·ªõc. Tuy nhi√™n, n√≥ s·∫Ω kh√¥ng cho b·∫°n bi·∫øt m√¥ h√¨nh c·ªßa b·∫°n ƒëang ho·∫°t ƒë·ªông t·ªët (ho·∫∑c t·ªìi t·ªá nh∆∞ th·∫ø n√†o). ƒêi·ªÅu n√†y l√† do:

1. Ch√∫ng ta ƒë√£ kh√¥ng y√™u c·∫ßu `Trainer` ƒë√°nh gi√° trong qu√° tr√¨nh hu·∫•n luy·ªán b·∫±ng c√°ch c√†i ƒë·∫∑t `eval_strategy` th√†nh `"steps"` (ƒë√°nh gi√° m·ªçi `eval_steps`) ho·∫∑c `"epoch"` (ƒë√°nh gi√° v√†o cu·ªëi m·ªói epoch).
2. Ch√∫ng ta ƒë√£ kh√¥ng cung c·∫•p cho `Trainer` m·ªôt h√†m `compute_metrics()` ƒë·ªÉ t√≠nh to√°n ch·ªâ s·ªë trong qu√° tr√¨nh ƒë√°nh gi√° n√≥i tr√™n (n·∫øu kh√¥ng, ƒë√°nh gi√° s·∫Ω ch·ªâ in ra l·ªó, ƒë√¢y kh√¥ng ph·∫£i l√† m·ªôt ch·ªâ s·ªë tr·ª±c quan cho l·∫Øm).

### ƒê√°nh gi√°

H√£y xem c√°ch ch√∫ng ta c√≥ th·ªÉ x√¢y d·ª±ng m·ªôt h√†m `compute_metrics()` h·ªØu √≠ch v√† s·ª≠ d·ª•ng n√≥ trong l·∫ßn hu·∫•n luy·ªán ti·∫øp theo. H√†m ph·∫£i nh·∫≠n m·ªôt ƒë·ªëi t∆∞·ª£ng `EvalPrediction` (l√† m·ªôt tuple ƒë∆∞·ª£c ƒë·∫∑t t√™n v·ªõi tr∆∞·ªùng `predictions` v√† tr∆∞·ªùng `label_ids`) v√† s·∫Ω tr·∫£ v·ªÅ m·ªôt chu·ªói √°nh x·∫° t·ª´ th√†nh s·ªë th·ª±c (c√°c chu·ªói l√† t√™n c·ªßa c√°c ch·ªâ s·ªë ƒë∆∞·ª£c tr·∫£ v·ªÅ v√† c√°c gi√° tr·ªã c·ªßa ch√∫ng √©p v·ªÅ ki·ªÉu s·ªë th·ª±c). ƒê·ªÉ nh·∫≠n ƒë∆∞·ª£c d·ª± ƒëo√°n t·ª´ m√¥ h√¨nh, ch√∫ng ta c√≥ th·ªÉ s·ª≠ d·ª•ng l·ªánh `Trainer.predict()`:

```py
predictions = trainer.predict(tokenized_datasets["validation"])
print(predictions.predictions.shape, predictions.label_ids.shape)
```

```python out
(408, 2) (408,)
```
ƒê·∫ßu ra c·ªßa ph∆∞∆°ng th·ª©c `predict()` l√† m·ªôt tuple c√≥ t√™n kh√°c v·ªõi ba tr∆∞·ªùng: `predictions`, `label_ids`, v√† `metrics`. Tr∆∞·ªùng `metrics` s·∫Ω ch·ªâ ch·ª©a s·ª± m·∫•t m√°t tr√™n t·∫≠p d·ªØ li·ªáu ƒë√£ truy·ªÅn v√†o, c≈©ng nh∆∞ m·ªôt s·ªë ch·ªâ s·ªë th·ªùi gian (t·ªïng c·ªông v√† trung b√¨nh m·∫•t bao l√¢u ƒë·ªÉ d·ª± ƒëo√°n). Sau khi ch√∫ng ta ho√†n th√†nh h√†m `compute_metrics()` v√† truy·ªÅn n√≥ v√†o `Trainer`, tr∆∞·ªùng ƒë√≥ c≈©ng s·∫Ω ch·ª©a c√°c ch·ªâ s·ªë ƒë∆∞·ª£c tr·∫£ v·ªÅ b·ªüi` compute_metrics()`.

Nh∆∞ b·∫°n c√≥ th·ªÉ th·∫•y, `predictions` l√† m·ªôt m·∫£ng hai chi·ªÅu c√≥ h√¨nh d·∫°ng 408 x 2 (408 l√† s·ªë ph·∫ßn t·ª≠ trong t·∫≠p d·ªØ li·ªáu ta ƒë√£ s·ª≠ d·ª•ng). ƒê√≥ l√† c√°c logit cho t·ª´ng ph·∫ßn t·ª≠ c·ªßa t·∫≠p d·ªØ li·ªáu m√† ch√∫ng ta ƒë√£ truy·ªÅn v√†o cho`predict()` ( nh∆∞ b·∫°n ƒë√£ th·∫•y trong [ch∆∞∆°ng tr∆∞·ªõc](/course/chapter2), t·∫•t c·∫£ c√°c m√¥ h√¨nh Transformer ƒë·ªÅu tr·∫£ v·ªÅ logit). ƒê·ªÉ chuy·ªÉn ƒë·ªïi ch√∫ng th√†nh c√°c d·ª± ƒëo√°n m√† ch√∫ng ta c√≥ th·ªÉ so s√°nh v·ªõi c√°c nh√£n c·ªßa m√¨nh, ch√∫ng ta c·∫ßn l·∫•y ch·ªâ s·ªë c√≥ gi√° tr·ªã l·ªõn nh·∫•t tr√™n tr·ª•c th·ª© hai:

```py
import numpy as np

preds = np.argmax(predictions.predictions, axis=-1)
```

Gi·ªù ch√∫ng ta c√≥ th·ªÉ so s√°nh c√°c `preds` ƒë√≥ v·ªõi c√°c nh√£n. ƒê·ªÉ x√¢y d·ª±ng h√†m `compute_metric()`, ch√∫ng ta s·∫Ω d·ª±a v√†o c√°c ch·ªâ s·ªë t·ª´ th∆∞ vi·ªán ü§ó [ƒê√°nh gi√°](https://github.com/huggingface/evaluate/). Ch√∫ng ta c√≥ th·ªÉ t·∫£i c√°c ch·ªâ s·ªë ƒë∆∞·ª£c li√™n k·∫øt v·ªõi t·∫≠p d·ªØ li·ªáu MRPC d·ªÖ d√†ng nh∆∞ khi ch√∫ng ta t·∫£i t·∫≠p d·ªØ li·ªáu, l·∫ßn n√†y l√† v·ªõi h√†m `evaluate.load()`. ƒê·ªëi t∆∞·ª£ng ƒë∆∞·ª£c tr·∫£ v·ªÅ c√≥ ph∆∞∆°ng th·ª©c `compute()` m√† ch√∫ng ta c√≥ th·ªÉ s·ª≠ d·ª•ng ƒë·ªÉ th·ª±c hi·ªán t√≠nh to√°n s·ªë li·ªáu:

```py
import evaluate

metric = evaluate.load("glue", "mrpc")
metric.compute(predictions=preds, references=predictions.label_ids)
```

```python out
{'accuracy': 0.8578431372549019, 'f1': 0.8996539792387542}
```

K·∫øt qu·∫£ ch√≠nh x√°c b·∫°n nh·∫≠n ƒë∆∞·ª£c c√≥ th·ªÉ kh√°c nhau, v√¨ vi·ªác kh·ªüi t·∫°o ng·∫´u nhi√™n ph·∫ßn ƒë·∫ßu m√¥ h√¨nh c√≥ th·ªÉ thay ƒë·ªïi c√°c ch·ªâ s·ªë m√† n√≥ ƒë·∫°t ƒë∆∞·ª£c. ·ªû ƒë√¢y, ch√∫ng ta c√≥ th·ªÉ th·∫•y m√¥ h√¨nh c√≥ ƒë·ªô ch√≠nh x√°c 85.78% tr√™n t·∫≠p ki·ªÉm ƒë·ªãnh v√† ƒëi·ªÉm F1 l√† 89.97. ƒê√≥ l√† hai ch·ªâ s·ªë ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ƒë√°nh gi√° k·∫øt qu·∫£ tr√™n t·∫≠p d·ªØ li·ªáu MRPC theo ƒëi·ªÉm chu·∫©n GLUE. B·∫£ng trong [b√†i b√°o BERT](https://arxiv.org/pdf/1810.04805.pdf) b√°o c√°o ƒëi·ªÉm F1 l√† 88.9 cho m√¥ h√¨nh c∆° s·ªü. ƒê√≥ l√† m√¥ h√¨nh `kh√¥ng ph√¢n bi·ªát` vi·∫øt hoa vi·∫øt th∆∞·ªùng trong khi ch√∫ng ta hi·ªán ƒëang s·ª≠ d·ª•ng m√¥ h√¨nh `c√≥ ph√¢n bi·ªát`, ƒëi·ªÅu n√†y gi·∫£i th√≠ch k·∫øt qu·∫£ t·ªët h∆°n.

K·∫øt h·ª£p m·ªçi th·ª© l·∫°i v·ªõi nhau, ch√∫ng ta nh·∫≠n ƒë∆∞·ª£c h√†m `compute_metrics()`:

```py
def compute_metrics(eval_preds):
    metric = evaluate.load("glue", "mrpc")
    logits, labels = eval_preds
    predictions = np.argmax(logits, axis=-1)
    return metric.compute(predictions=predictions, references=labels)
```

V√† ƒë·ªÉ xem n√≥ ƒë∆∞·ª£c s·ª≠ d·ª•ng trong th·ª±c ti·ªÖn ƒë·ªÉ b√°o c√°o c√°c ch·ªâ s·ªë ·ªü cu·ªëi m·ªói epoch nh∆∞ th·∫ø n√†o, ƒë√¢y l√† c√°ch ch√∫ng t√¥i ƒë·ªãnh nghƒ©a m·ªôt `Trainer` m·ªõi v·ªõi h√†m `compute_metrics()` n√†y:


```py
training_args = TrainingArguments("test-trainer", evaluation_strategy="epoch")
model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)

trainer = Trainer(
    model,
    training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
)
```

L∆∞u √Ω r·∫±ng ch√∫ng ta t·∫°o m·ªôt `TrainingArguments` m·ªõi v·ªõi `eval_strategy` c·ªßa n√≥ ƒë∆∞·ª£c ƒë·∫∑t th√†nh `"epoch"` v√† m·ªôt m√¥ h√¨nh m·ªõi - n·∫øu kh√¥ng, ch√∫ng ta s·∫Ω ti·∫øp t·ª•c hu·∫•n luy·ªán m√¥ h√¨nh ta ƒë√£ hu·∫•n luy·ªán. ƒê·ªÉ kh·ªüi ch·∫°y m·ªôt ƒë·ª£t hu·∫•n luy·ªán m·ªõi, ch√∫ng ta th·ª±c hi·ªán:

```
trainer.train()
```

L·∫ßn n√†y, n√≥ s·∫Ω b√°o c√°o th√¥ng s·ªë m·∫•t m√°t ki·ªÉm ƒë·ªãnh v√† ch·ªâ s·ªë ·ªü cu·ªëi m·ªói epoch √™n c·∫°nh th√¥ng s·ªë m·∫•t m√°t tr√™n t·∫≠p hu·∫•n luy·ªán. M·ªôt l·∫ßn n·ªØa, ƒë·ªô ch√≠nh x√°c tuy·ªát ƒë·ªëi/ƒëi·ªÉm F1 m√† b·∫°n ƒë·∫°t ƒë∆∞·ª£c c√≥ th·ªÉ h∆°i kh√°c so v·ªõi nh·ªØng g√¨ ch√∫ng t√¥i t√¨m th·∫•y, do vi·ªác kh·ªüi t·∫°o ƒë·∫ßu ng·∫´u nhi√™n c·ªßa m√¥ h√¨nh, nh∆∞ng n√≥ ph·∫£i ·ªü trong c√πng m·ªôt kho·∫£ng.

`Trainer` s·∫Ω ho·∫°t ƒë·ªông hi·ªáu qu·∫£ tr√™n nhi·ªÅu GPU ho·∫∑c TPU v√† cung c·∫•p nhi·ªÅu t√πy ch·ªçn, ch·∫≥ng h·∫°n nh∆∞ hu·∫•n luy·ªán v·ªÅ ƒë·ªô ch√≠nh x√°c h·ªón h·ª£p (s·ª≠ d·ª•ng `fp16=True` trong tham s·ªë hu·∫•n luy·ªán c·ªßa b·∫°n). Ch√∫ng ta s·∫Ω xem x√©t m·ªçi th·ª© m√† n√≥ h·ªó tr·ª£ trong Ch∆∞∆°ng 10.

Ph·∫ßn n√†y k·∫øt th√∫c ph·∫ßn gi·ªõi thi·ªáu v·ªÅ c√°ch tinh ch·ªânh b·∫±ng API `Trainer`. M·ªôt v√≠ d·ª• v·ªÅ vi·ªác th·ª±c hi·ªán ƒëi·ªÅu n√†y ƒë·ªëi v·ªõi h·∫ßu h·∫øt c√°c t√°c v·ª• NLP ph·ªï bi·∫øn s·∫Ω ƒë∆∞·ª£c ƒë∆∞a ra trong [Ch∆∞∆°ng 7](/course/chapter7), nh∆∞ng ·ªü th·ªùi ƒëi·ªÉm n√†y ch√∫ng ta h√£y xem c√°ch th·ª±c hi·ªán ƒëi·ªÅu t∆∞∆°ng t·ª± trong PyTorch thu·∫ßn t√∫y.

> [!TIP]
> ‚úèÔ∏è **Th·ª≠ nghi·ªám th√¥i!** Tinh ch·ªânh m√¥ h√¨nh tr√™n t·∫≠p d·ªØ li·ªáu GLUE SST-2, s·ª≠ d·ª•ng qu√° tr√¨nh x·ª≠ l√Ω d·ªØ li·ªáu b·∫°n ƒë√£ th·ª±c hi·ªán trong ph·∫ßn 2.
