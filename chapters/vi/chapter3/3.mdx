<FrameworkSwitchCourse {fw} />

# Tinh chá»‰nh má»™t mÃ´ hÃ¬nh vá»›i Trainer API

<CourseFloatingBanner chapter={3}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/vi/chapter3/section3.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/vi/chapter3/section3.ipynb"},
]} />

<Youtube id="nvBXf7s7vTI"/>

ğŸ¤— Transformers cung cáº¥p lá»›p `Trainer` Ä‘á»ƒ giÃºp báº¡n tinh chá»‰nh báº¥t ká»³ mÃ´ hÃ¬nh huáº¥n luyá»‡n trÆ°á»›c nÃ o mÃ  nÃ³ cung cáº¥p trÃªn táº­p dá»¯ liá»‡u cá»§a báº¡n. Khi báº¡n Ä‘Ã£ hoÃ n thÃ nh táº¥t cáº£ cÃ´ng viá»‡c tiá»n xá»­ lÃ½ dá»¯ liá»‡u trong pháº§n cuá»‘i cÃ¹ng, báº¡n chá»‰ cÃ²n má»™t vÃ i bÆ°á»›c Ä‘á»ƒ Ä‘á»‹nh nghÄ©a `Trainer`. Pháº§n khÃ³ nháº¥t cÃ³ thá»ƒ lÃ  chuáº©n bá»‹ mÃ´i trÆ°á»ng Ä‘á»ƒ cháº¡y `Trainer.train()`, vÃ¬ nÃ³ sáº½ cháº¡y ráº¥t cháº­m trÃªn CPU. Náº¿u báº¡n chÆ°a thiáº¿t láº­p GPU, báº¡n cÃ³ thá»ƒ cÃ³ quyá»n truy cáº­p vÃ o GPU hoáº·c TPU miá»…n phÃ­ trÃªn [Google Colab](https://colab.research.google.com/).

CÃ¡c vÃ­ dá»¥ mÃ£ bÃªn dÆ°á»›i giáº£ sá»­ báº¡n Ä‘Ã£ thá»±c hiá»‡n cÃ¡c vÃ­ dá»¥ trong pháº§n trÆ°á»›c. DÆ°á»›i Ä‘Ã¢y lÃ  má»™t báº£n tÃ³m táº¯t ngáº¯n tÃ³m táº¯t láº¡i nhá»¯ng gÃ¬ báº¡n cáº§n:

```py
from datasets import load_dataset
from transformers import AutoTokenizer, DataCollatorWithPadding

raw_datasets = load_dataset("glue", "mrpc")
checkpoint = "bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)


def tokenize_function(example):
    return tokenizer(example["sentence1"], example["sentence2"], truncation=True)


tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)
data_collator = DataCollatorWithPadding(tokenizer=tokenizer)
```

### Huáº¥n luyá»‡n

BÆ°á»›c Ä‘áº§u tiÃªn trÆ°á»›c khi chÃºng ta cÃ³ thá»ƒ Ä‘á»‹nh nghÄ©a `Trainer` cá»§a mÃ¬nh lÃ  Ä‘á»‹nh nghÄ©a má»™t lá»›p `TrainingArguments` sáº½ chá»©a táº¥t cáº£ cÃ¡c siÃªu tham sá»‘ mÃ  `Trainer` sáº½ sá»­ dá»¥ng Ä‘á»ƒ huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡. Tham sá»‘ duy nháº¥t báº¡n pháº£i cung cáº¥p lÃ  má»™t thÆ° má»¥c nÆ¡i mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n sáº½ Ä‘Æ°á»£c lÆ°u, cÅ©ng nhÆ° cÃ¡c checkpoint Ä‘i kÃ¨m. Äá»‘i vá»›i táº¥t cáº£ pháº§n cÃ²n láº¡i, báº¡n cÃ³ thá»ƒ Ä‘á»ƒ máº·c Ä‘á»‹nh, nÃ³ sáº½ hoáº¡t Ä‘á»™ng khÃ¡ tá»‘t vá»›i tinh chá»‰nh cÆ¡ báº£n.

```py
from transformers import TrainingArguments

training_args = TrainingArguments("test-trainer")
```

<Tip>

ğŸ’¡ Náº¿u báº¡n muá»‘n tá»± Ä‘á»™ng táº£i mÃ´ hÃ¬nh cá»§a mÃ¬nh lÃªn Hub trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n, hÃ£y chuyá»ƒn sang pháº§n `push_to_hub=True` trong pháº§n `TrainingArguments`. ChÃºng ta sáº½ tÃ¬m hiá»ƒu thÃªm vá» Ä‘iá»u nÃ y trong [ChÆ°Æ¡ng 4](/course/chapter4/3)

</Tip>

BÆ°á»›c thá»© hai lÃ  xÃ¡c Ä‘á»‹nh mÃ´ hÃ¬nh cá»§a chÃºng ta. NhÆ° trong [chÆ°Æ¡ng trÆ°á»›c](/course/chapter2), chÃºng ta sáº½ sá»­ dá»¥ng lá»›p `AutoModelForSequenceClassification`, vá»›i hai nhÃ£n:

```py
from transformers import AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)
```

Báº¡n sáº½ nháº­n tháº¥y ráº±ng khÃ´ng nhÆ° trong [ChÆ°Æ¡ng 2](/course/chapter2), báº¡n nháº­n Ä‘Æ°á»£c má»™t cáº£nh bÃ¡o sau khi khá»Ÿi táº¡o mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c nÃ y. ÄÃ¢y lÃ  do BERT chÆ°a Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c vá» phÃ¢n loáº¡i cÃ¡c cáº·p cÃ¢u, vÃ¬ váº­y pháº§n Ä‘áº§u cá»§a mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c Ä‘Ã£ bá»‹ loáº¡i bá» vÃ  pháº§n Ä‘áº§u má»›i phÃ¹ há»£p Ä‘á»ƒ phÃ¢n loáº¡i chuá»—i Ä‘Ã£ Ä‘Æ°á»£c chÃ¨n vÃ o thay tháº¿. CÃ¡c cáº£nh bÃ¡o chá»‰ ra ráº±ng má»™t sá»‘ trá»ng sá»‘ Ä‘Ã£ khÃ´ng Ä‘Æ°á»£c sá»­ dá»¥ng (nhá»¯ng trá»ng sá»‘ tÆ°Æ¡ng á»©ng vá»›i Ä‘áº§u huáº¥n luyá»‡n trÆ°á»›c bá»‹ rá»¥ng) vÃ  má»™t sá»‘ trá»ng sá»‘ khÃ¡c khÃ¡c Ä‘Æ°á»£c khá»Ÿi táº¡o ngáº«u nhiÃªn (nhá»¯ng trá»ng sá»‘ dÃ nh cho Ä‘áº§u má»›i). NÃ³ káº¿t thÃºc báº±ng cÃ¡ch khuyáº¿n khÃ­ch báº¡n huáº¥n luyá»‡n mÃ´ hÃ¬nh, Ä‘Ã³ chÃ­nh xÃ¡c lÃ  nhá»¯ng gÃ¬ chÃºng ta sáº½ lÃ m bÃ¢y giá».

Khi chÃºng ta cÃ³ mÃ´ hÃ¬nh cá»§a mÃ¬nh, chÃºng ta cÃ³ thá»ƒ xÃ¡c Ä‘á»‹nh má»™t `Trainer` báº±ng cÃ¡ch truyá»n vÃ o táº¥t cáº£ cÃ¡c Ä‘á»‘i tÆ°á»£ng Ä‘Æ°á»£c xÃ¢y dá»±ng tá»« trÆ°á»›c Ä‘áº¿n nay - `model`, `training_args`, táº­p huáº¥n luyá»‡n vÃ  kiá»ƒm Ä‘á»‹nh,`data_collator` vÃ  `tokenizer`:

```py
from transformers import Trainer

trainer = Trainer(
    model,
    training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    tokenizer=tokenizer,
)
```

LÆ°u Ã½ ráº±ng khi báº¡n truyá»n `tokenizer` nhÆ° chÃºng ta Ä‘Ã£ lÃ m á»Ÿ Ä‘Ã¢y, máº·c Ä‘á»‹nh `data_collator` Ä‘Æ°á»£c sá»­ dá»¥ng bá»Ÿi `Trainer` sáº½ lÃ  `DataCollatorWithPadding` nhÆ° Ä‘Ã£ Ä‘á»‹nh nghÄ©a trÆ°á»›c Ä‘Ã³, vÃ¬ váº­y báº¡n cÃ³ thá»ƒ bá» qua dÃ²ng `data_collator = data_collator` trong lá»‡nh gá»i nÃ y. Äiá»u quan trá»ng lÃ  pháº£i cho báº¡n tháº¥y pháº§n nÃ y cá»§a quÃ¡ trÃ¬nh trong pháº§n 2!

Äá»ƒ tinh chá»‰nh mÃ´ hÃ¬nh trÃªn táº­p dá»¯ liá»‡u, chÃºng ta chá»‰ cáº§n gá»i phÆ°Æ¡ng thá»©c `train()` cá»§a `Trainer`:

```py
trainer.train()
```

Thao tÃ¡c nÃ y sáº½ báº¯t Ä‘áº§u quÃ¡ trÃ¬nh tinh chá»‰nh (sáº½ máº¥t vÃ i phÃºt trÃªn GPU) vÃ  bÃ¡o cÃ¡o lá»—i Ä‘Ã o táº¡o sau má»—i 500 bÆ°á»›c. Tuy nhiÃªn, nÃ³ sáº½ khÃ´ng cho báº¡n biáº¿t mÃ´ hÃ¬nh cá»§a báº¡n Ä‘ang hoáº¡t Ä‘á»™ng tá»‘t (hoáº·c tá»“i tá»‡ nhÆ° tháº¿ nÃ o). Äiá»u nÃ y lÃ  do:

1. ChÃºng ta Ä‘Ã£ khÃ´ng yÃªu cáº§u `Trainer` Ä‘Ã¡nh giÃ¡ trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n báº±ng cÃ¡ch cÃ i Ä‘áº·t `eval_strategy` thÃ nh `"steps"` (Ä‘Ã¡nh giÃ¡ má»i `eval_steps`) hoáº·c `"epoch"` (Ä‘Ã¡nh giÃ¡ vÃ o cuá»‘i má»—i epoch).
2. ChÃºng ta Ä‘Ã£ khÃ´ng cung cáº¥p cho `Trainer` má»™t hÃ m `compute_metrics()` Ä‘á»ƒ tÃ­nh toÃ¡n chá»‰ sá»‘ trong quÃ¡ trÃ¬nh Ä‘Ã¡nh giÃ¡ nÃ³i trÃªn (náº¿u khÃ´ng, Ä‘Ã¡nh giÃ¡ sáº½ chá»‰ in ra lá»—, Ä‘Ã¢y khÃ´ng pháº£i lÃ  má»™t chá»‰ sá»‘ trá»±c quan cho láº¯m).

### ÄÃ¡nh giÃ¡

HÃ£y xem cÃ¡ch chÃºng ta cÃ³ thá»ƒ xÃ¢y dá»±ng má»™t hÃ m `compute_metrics()` há»¯u Ã­ch vÃ  sá»­ dá»¥ng nÃ³ trong láº§n huáº¥n luyá»‡n tiáº¿p theo. HÃ m pháº£i nháº­n má»™t Ä‘á»‘i tÆ°á»£ng `EvalPrediction` (lÃ  má»™t tuple Ä‘Æ°á»£c Ä‘áº·t tÃªn vá»›i trÆ°á»ng `predictions` vÃ  trÆ°á»ng `label_ids`) vÃ  sáº½ tráº£ vá» má»™t chuá»—i Ã¡nh xáº¡ tá»« thÃ nh sá»‘ thá»±c (cÃ¡c chuá»—i lÃ  tÃªn cá»§a cÃ¡c chá»‰ sá»‘ Ä‘Æ°á»£c tráº£ vá» vÃ  cÃ¡c giÃ¡ trá»‹ cá»§a chÃºng Ã©p vá» kiá»ƒu sá»‘ thá»±c). Äá»ƒ nháº­n Ä‘Æ°á»£c dá»± Ä‘oÃ¡n tá»« mÃ´ hÃ¬nh, chÃºng ta cÃ³ thá»ƒ sá»­ dá»¥ng lá»‡nh `Trainer.predict()`:

```py
predictions = trainer.predict(tokenized_datasets["validation"])
print(predictions.predictions.shape, predictions.label_ids.shape)
```

```python out
(408, 2) (408,)
```
Äáº§u ra cá»§a phÆ°Æ¡ng thá»©c `predict()` lÃ  má»™t tuple cÃ³ tÃªn khÃ¡c vá»›i ba trÆ°á»ng: `predictions`, `label_ids`, vÃ  `metrics`. TrÆ°á»ng `metrics` sáº½ chá»‰ chá»©a sá»± máº¥t mÃ¡t trÃªn táº­p dá»¯ liá»‡u Ä‘Ã£ truyá»n vÃ o, cÅ©ng nhÆ° má»™t sá»‘ chá»‰ sá»‘ thá»i gian (tá»•ng cá»™ng vÃ  trung bÃ¬nh máº¥t bao lÃ¢u Ä‘á»ƒ dá»± Ä‘oÃ¡n). Sau khi chÃºng ta hoÃ n thÃ nh hÃ m `compute_metrics()` vÃ  truyá»n nÃ³ vÃ o `Trainer`, trÆ°á»ng Ä‘Ã³ cÅ©ng sáº½ chá»©a cÃ¡c chá»‰ sá»‘ Ä‘Æ°á»£c tráº£ vá» bá»Ÿi` compute_metrics()`.

NhÆ° báº¡n cÃ³ thá»ƒ tháº¥y, `predictions` lÃ  má»™t máº£ng hai chiá»u cÃ³ hÃ¬nh dáº¡ng 408 x 2 (408 lÃ  sá»‘ pháº§n tá»­ trong táº­p dá»¯ liá»‡u ta Ä‘Ã£ sá»­ dá»¥ng). ÄÃ³ lÃ  cÃ¡c logit cho tá»«ng pháº§n tá»­ cá»§a táº­p dá»¯ liá»‡u mÃ  chÃºng ta Ä‘Ã£ truyá»n vÃ o cho`predict()` ( nhÆ° báº¡n Ä‘Ã£ tháº¥y trong [chÆ°Æ¡ng trÆ°á»›c](/course/chapter2), táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh Transformer Ä‘á»u tráº£ vá» logit). Äá»ƒ chuyá»ƒn Ä‘á»•i chÃºng thÃ nh cÃ¡c dá»± Ä‘oÃ¡n mÃ  chÃºng ta cÃ³ thá»ƒ so sÃ¡nh vá»›i cÃ¡c nhÃ£n cá»§a mÃ¬nh, chÃºng ta cáº§n láº¥y chá»‰ sá»‘ cÃ³ giÃ¡ trá»‹ lá»›n nháº¥t trÃªn trá»¥c thá»© hai:

```py
import numpy as np

preds = np.argmax(predictions.predictions, axis=-1)
```

Giá» chÃºng ta cÃ³ thá»ƒ so sÃ¡nh cÃ¡c `preds` Ä‘Ã³ vá»›i cÃ¡c nhÃ£n. Äá»ƒ xÃ¢y dá»±ng hÃ m `compute_metric()`, chÃºng ta sáº½ dá»±a vÃ o cÃ¡c chá»‰ sá»‘ tá»« thÆ° viá»‡n ğŸ¤— [ÄÃ¡nh giÃ¡](https://github.com/huggingface/evaluate/). ChÃºng ta cÃ³ thá»ƒ táº£i cÃ¡c chá»‰ sá»‘ Ä‘Æ°á»£c liÃªn káº¿t vá»›i táº­p dá»¯ liá»‡u MRPC dá»… dÃ ng nhÆ° khi chÃºng ta táº£i táº­p dá»¯ liá»‡u, láº§n nÃ y lÃ  vá»›i hÃ m `evaluate.load()`. Äá»‘i tÆ°á»£ng Ä‘Æ°á»£c tráº£ vá» cÃ³ phÆ°Æ¡ng thá»©c `compute()` mÃ  chÃºng ta cÃ³ thá»ƒ sá»­ dá»¥ng Ä‘á»ƒ thá»±c hiá»‡n tÃ­nh toÃ¡n sá»‘ liá»‡u:

```py
import evaluate

metric = evaluate.load("glue", "mrpc")
metric.compute(predictions=preds, references=predictions.label_ids)
```

```python out
{'accuracy': 0.8578431372549019, 'f1': 0.8996539792387542}
```

Káº¿t quáº£ chÃ­nh xÃ¡c báº¡n nháº­n Ä‘Æ°á»£c cÃ³ thá»ƒ khÃ¡c nhau, vÃ¬ viá»‡c khá»Ÿi táº¡o ngáº«u nhiÃªn pháº§n Ä‘áº§u mÃ´ hÃ¬nh cÃ³ thá»ƒ thay Ä‘á»•i cÃ¡c chá»‰ sá»‘ mÃ  nÃ³ Ä‘áº¡t Ä‘Æ°á»£c. á» Ä‘Ã¢y, chÃºng ta cÃ³ thá»ƒ tháº¥y mÃ´ hÃ¬nh cÃ³ Ä‘á»™ chÃ­nh xÃ¡c 85.78% trÃªn táº­p kiá»ƒm Ä‘á»‹nh vÃ  Ä‘iá»ƒm F1 lÃ  89.97. ÄÃ³ lÃ  hai chá»‰ sá»‘ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ káº¿t quáº£ trÃªn táº­p dá»¯ liá»‡u MRPC theo Ä‘iá»ƒm chuáº©n GLUE. Báº£ng trong [bÃ i bÃ¡o BERT](https://arxiv.org/pdf/1810.04805.pdf) bÃ¡o cÃ¡o Ä‘iá»ƒm F1 lÃ  88.9 cho mÃ´ hÃ¬nh cÆ¡ sá»Ÿ. ÄÃ³ lÃ  mÃ´ hÃ¬nh `khÃ´ng phÃ¢n biá»‡t` viáº¿t hoa viáº¿t thÆ°á»ng trong khi chÃºng ta hiá»‡n Ä‘ang sá»­ dá»¥ng mÃ´ hÃ¬nh `cÃ³ phÃ¢n biá»‡t`, Ä‘iá»u nÃ y giáº£i thÃ­ch káº¿t quáº£ tá»‘t hÆ¡n.

Káº¿t há»£p má»i thá»© láº¡i vá»›i nhau, chÃºng ta nháº­n Ä‘Æ°á»£c hÃ m `compute_metrics()`:

```py
def compute_metrics(eval_preds):
    metric = evaluate.load("glue", "mrpc")
    logits, labels = eval_preds
    predictions = np.argmax(logits, axis=-1)
    return metric.compute(predictions=predictions, references=labels)
```

VÃ  Ä‘á»ƒ xem nÃ³ Ä‘Æ°á»£c sá»­ dá»¥ng trong thá»±c tiá»…n Ä‘á»ƒ bÃ¡o cÃ¡o cÃ¡c chá»‰ sá»‘ á»Ÿ cuá»‘i má»—i epoch nhÆ° tháº¿ nÃ o, Ä‘Ã¢y lÃ  cÃ¡ch chÃºng tÃ´i Ä‘á»‹nh nghÄ©a má»™t `Trainer` má»›i vá»›i hÃ m `compute_metrics()` nÃ y:


```py
training_args = TrainingArguments("test-trainer", evaluation_strategy="epoch")
model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)

trainer = Trainer(
    model,
    training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
)
```

LÆ°u Ã½ ráº±ng chÃºng ta táº¡o má»™t `TrainingArguments` má»›i vá»›i `eval_strategy` cá»§a nÃ³ Ä‘Æ°á»£c Ä‘áº·t thÃ nh `"epoch"` vÃ  má»™t mÃ´ hÃ¬nh má»›i - náº¿u khÃ´ng, chÃºng ta sáº½ tiáº¿p tá»¥c huáº¥n luyá»‡n mÃ´ hÃ¬nh ta Ä‘Ã£ huáº¥n luyá»‡n. Äá»ƒ khá»Ÿi cháº¡y má»™t Ä‘á»£t huáº¥n luyá»‡n má»›i, chÃºng ta thá»±c hiá»‡n:

```
trainer.train()
```

Láº§n nÃ y, nÃ³ sáº½ bÃ¡o cÃ¡o thÃ´ng sá»‘ máº¥t mÃ¡t kiá»ƒm Ä‘á»‹nh vÃ  chá»‰ sá»‘ á»Ÿ cuá»‘i má»—i epoch Ãªn cáº¡nh thÃ´ng sá»‘ máº¥t mÃ¡t trÃªn táº­p huáº¥n luyá»‡n. Má»™t láº§n ná»¯a, Ä‘á»™ chÃ­nh xÃ¡c tuyá»‡t Ä‘á»‘i/Ä‘iá»ƒm F1 mÃ  báº¡n Ä‘áº¡t Ä‘Æ°á»£c cÃ³ thá»ƒ hÆ¡i khÃ¡c so vá»›i nhá»¯ng gÃ¬ chÃºng tÃ´i tÃ¬m tháº¥y, do viá»‡c khá»Ÿi táº¡o Ä‘áº§u ngáº«u nhiÃªn cá»§a mÃ´ hÃ¬nh, nhÆ°ng nÃ³ pháº£i á»Ÿ trong cÃ¹ng má»™t khoáº£ng.

`Trainer` sáº½ hoáº¡t Ä‘á»™ng hiá»‡u quáº£ trÃªn nhiá»u GPU hoáº·c TPU vÃ  cung cáº¥p nhiá»u tÃ¹y chá»n, cháº³ng háº¡n nhÆ° huáº¥n luyá»‡n vá» Ä‘á»™ chÃ­nh xÃ¡c há»—n há»£p (sá»­ dá»¥ng `fp16=True` trong tham sá»‘ huáº¥n luyá»‡n cá»§a báº¡n). ChÃºng ta sáº½ xem xÃ©t má»i thá»© mÃ  nÃ³ há»— trá»£ trong ChÆ°Æ¡ng 10.

Pháº§n nÃ y káº¿t thÃºc pháº§n giá»›i thiá»‡u vá» cÃ¡ch tinh chá»‰nh báº±ng API `Trainer`. Má»™t vÃ­ dá»¥ vá» viá»‡c thá»±c hiá»‡n Ä‘iá»u nÃ y Ä‘á»‘i vá»›i háº§u háº¿t cÃ¡c tÃ¡c vá»¥ NLP phá»• biáº¿n sáº½ Ä‘Æ°á»£c Ä‘Æ°a ra trong [ChÆ°Æ¡ng 7](/course/chapter7), nhÆ°ng á»Ÿ thá»i Ä‘iá»ƒm nÃ y chÃºng ta hÃ£y xem cÃ¡ch thá»±c hiá»‡n Ä‘iá»u tÆ°Æ¡ng tá»± trong PyTorch thuáº§n tÃºy.

<Tip>

âœï¸ **Thá»­ nghiá»‡m thÃ´i!** Tinh chá»‰nh mÃ´ hÃ¬nh trÃªn táº­p dá»¯ liá»‡u GLUE SST-2, sá»­ dá»¥ng quÃ¡ trÃ¬nh xá»­ lÃ½ dá»¯ liá»‡u báº¡n Ä‘Ã£ thá»±c hiá»‡n trong pháº§n 2.

</Tip>
