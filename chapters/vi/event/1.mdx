# Sá»± kiá»‡n PhÃ¡t hÃ nh Pháº§n 2

Äá»ƒ phÃ¡t hÃ nh pháº§n 2 cá»§a khÃ³a há»c, chÃºng tÃ´i Ä‘Ã£ tá»• chá»©c má»™t sá»± kiá»‡n trá»±c tiáº¿p vá»›i hai ngÃ y chia sáº». Náº¿u báº¡n Ä‘Ã£ bá» lá»¡ nÃ³, báº¡n cÃ³ thá»ƒ theo dÃµi cÃ¡c bÃ i nÃ³i chuyá»‡n Ä‘Æ°á»£c liá»‡t kÃª dÆ°á»›i Ä‘Ã¢y!

## NgÃ y 1: Má»™t cÃ¡i nhÃ¬n cáº¥p cao vá» Transformer vÃ  cÃ¡ch huáº¥n luyá»‡n chÃºng

**Thomas Wolf:** *Há»c chuyá»ƒn giao vÃ  sá»± ra Ä‘á»i cá»§a thÆ° viá»‡n Transformers*

<div class="flex justify-center">
<Youtube id="wCYVeahJES0"/>
</div>

<p align="center">
<img src="https://i.imgur.com/9eq8oUi.png" alt="TÃ³m táº¯t hÃ¬nh áº£nh vá» bÃ i chia sáº» cá»§a Thom" width="80%"/>
</p>

Thomas Wolf lÃ  Ä‘á»“ng sÃ¡ng láº­p vÃ  GiÃ¡m Ä‘á»‘c Khoa há»c cá»§a Hugging Face. CÃ¡c cÃ´ng cá»¥ do Thomas Wolf vÃ  nhÃ³m Hugging Face táº¡o ra Ä‘Æ°á»£c sá»­ dá»¥ng trÃªn hÆ¡n 5,000 tá»• chá»©c nghiÃªn cá»©u bao gá»“m Facebook Artificial Intelligence Research, Google Research, DeepMind, Amazon Research, Apple, Allen Institute for Artificial Intelligence cÅ©ng nhÆ° háº§u háº¿t cÃ¡c khoa cá»§a trÆ°á»ng Ä‘áº¡i há»c. Thomas Wolf lÃ  ngÆ°á»i khá»Ÿi xÆ°á»›ng vÃ  lÃ  chá»§ tá»‹ch cáº¥p cao cá»§a sá»± há»£p tÃ¡c nghiÃªn cá»©u lá»›n nháº¥t tá»«ng tá»“n táº¡i trong TrÃ­ tuá»‡ nhÃ¢n táº¡o: [â€œBigScienceâ€](https://bigscience.huggingface.co), cÅ©ng nhÆ° má»™t bá»™ [cÃ¡c thÆ° viá»‡n vÃ  cÃ´ng cá»¥ Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i](https://github.com/huggingface/). Thomas Wolf cÅ©ng lÃ  má»™t nhÃ  giÃ¡o dá»¥c xuáº¥t sáº¯c, má»™t nhÃ  lÃ£nh Ä‘áº¡o tÆ° tÆ°á»Ÿng trong lÄ©nh vá»±c TrÃ­ tuá»‡ NhÃ¢n táº¡o vÃ  Xá»­ lÃ½ NgÃ´n ngá»¯ Tá»± nhiÃªn, vÃ  lÃ  má»™t diá»…n giáº£ thÆ°á»ng xuyÃªn Ä‘Æ°á»£c má»i tham dá»± cÃ¡c há»™i nghá»‹ trÃªn toÃ n tháº¿ giá»›i [https://thomwolf.io](https://thomwolf.io ).

**Jay Alammar:** *Pháº§n giá»›i thiá»‡u trá»±c quan nháº¹ nhÃ ng vá» cÃ¡c mÃ´ hÃ¬nh Transformer*

<div class="flex justify-center">
<Youtube id="VzvG23gmcYU"/>
</div>

<p align="center">
<img src="https://i.imgur.com/rOZAuE9.png" alt="TÃ³m táº¯t hÃ¬nh áº£nh vá» bÃ i chia sáº» cá»§a Jay" width="80%"/>
</p>

ThÃ´ng qua blog Há»c mÃ¡y (ML) ná»•i tiáº¿ng cá»§a mÃ¬nh, Jay Ä‘Ã£ giÃºp hÃ ng triá»‡u nhÃ  nghiÃªn cá»©u vÃ  ká»¹ sÆ° hiá»ƒu trá»±c quan cÃ¡c cÃ´ng cá»¥ vÃ  khÃ¡i niá»‡m ML tá»« cÆ¡ báº£n (vá»›i cÃ¡c tÃ i liá»‡u vá» NumPy, Pandas) Ä‘áº¿n tiÃªn tiáº¿n (Transformers, BERT, GPT-3).

**Margaret Mitchell:** *Vá» giÃ¡ trá»‹ trong phÃ¡t triá»ƒn Há»c mÃ¡y*

<div class="flex justify-center">
<Youtube id="8j9HRMjh_s8"/>
</div>

<p align="center">
<img src="https://i.imgur.com/NuIsnY3.png" alt="TÃ³m táº¯t hÃ¬nh áº£nh vá» bÃ i chia sáº» cá»§a Margaret" width="80%"/>
</p>

Margaret Mitchell lÃ  má»™t nhÃ  nghiÃªn cá»©u lÃ m viá»‡c vá» Äáº¡o Ä‘á»©c TrÃ­ tuá»‡ nhÃ¢n táº¡o, hiá»‡n Ä‘ang táº­p trung vÃ o nhá»¯ng Ä‘iá»ƒm cáº§n thiáº¿t cá»§a sá»± phÃ¡t triá»ƒn AI cÃ³ nháº­n thá»©c vá» Ä‘áº¡o Ä‘á»©c trong cÃ´ng nghá»‡. CÃ´ Ä‘Ã£ xuáº¥t báº£n hÆ¡n 50 bÃ i bÃ¡o vá» táº¡o ngÃ´n ngá»¯ tá»± nhiÃªn, cÃ´ng nghá»‡ há»— trá»£, thá»‹ giÃ¡c mÃ¡y tÃ­nh, vÃ  Ä‘áº¡o Ä‘á»©c AI, Ä‘á»“ng thá»i náº¯m giá»¯ nhiá»u báº±ng sÃ¡ng cháº¿ trong cÃ¡c lÄ©nh vá»±c táº¡o há»™i thoáº¡i vÃ  phÃ¢n loáº¡i cáº£m xÃºc. TrÆ°á»›c Ä‘Ã¢y, cÃ´ Ä‘Ã£ lÃ m viá»‡c táº¡i Google AI vá»›i tÆ° cÃ¡ch lÃ  ChuyÃªn viÃªn nghiÃªn cá»©u khoa há»c, nÆ¡i cÃ´ thÃ nh láº­p vÃ  Ä‘á»“ng lÃ£nh Ä‘áº¡o nhÃ³m Ä‘áº¡o Ä‘á»©c AI cá»§a Google, táº­p trung vÃ o nghiÃªn cá»©u ná»n táº£ng Ä‘áº¡o Ä‘á»©c AI vÃ  váº­n hÃ nh Ä‘áº¡o Ä‘á»©c AI trong ná»™i bá»™ Google. TrÆ°á»›c khi gia nháº­p Google, cÃ´ áº¥y lÃ  nhÃ  nghiÃªn cá»©u táº¡i Microsoft Research, táº­p trung vÃ o viá»‡c chuyá»ƒn Ä‘á»•i hÃ¬nh áº£nh sang ngÃ´n ngá»¯; vÃ  lÃ  má»™t háº­u nghiÃªn cá»©u sinh táº¡i Johns Hopkins, táº­p trung vÃ o mÃ´ hÃ¬nh Bayes vÃ  trÃ­ch xuáº¥t thÃ´ng tin. CÃ´ cÃ³ báº±ng Tiáº¿n sÄ© Khoa há»c MÃ¡y tÃ­nh táº¡i Äáº¡i há»c Aberdeen vÃ  Tháº¡c sÄ© ngÃ´n ngá»¯ há»c mÃ¡y tÃ­nh cá»§a Äáº¡i há»c Washington. Trong lÃºc chá» láº¥y báº±ng, cÃ´ cÅ©ng Ä‘Ã£ lÃ m viá»‡c tá»« nÄƒm 2005-2012 vá» há»c mÃ¡y, rá»‘i loáº¡n tháº§n kinh, vÃ  cÃ´ng nghá»‡ há»— trá»£ táº¡i Äáº¡i há»c Khoa há»c vÃ  Sá»©c khá»e Oregon. CÃ´ áº¥y Ä‘Ã£ dáº«n Ä‘áº§u má»™t sá»‘ há»™i tháº£o vÃ  sÃ¡ng kiáº¿n â€‹â€‹vá» giao Ä‘iá»ƒm cá»§a sá»± Ä‘a dáº¡ng, hÃ²a nháº­p, khoa há»c mÃ¡y tÃ­nh, vÃ  Ä‘áº¡o Ä‘á»©c. CÃ´ng viá»‡c cá»§a cÃ´ Ä‘Ã£ nháº­n Ä‘Æ°á»£c giáº£i thÆ°á»Ÿng tá»« Bá»™ trÆ°á»Ÿng Quá»‘c phÃ²ng Ash Carter vÃ  Quá»¹ NgÆ°á»i mÃ¹ Hoa Ká»³, Ä‘á»“ng thá»i Ä‘Æ°á»£c thá»±c hiá»‡n bá»Ÿi nhiá»u cÃ´ng ty cÃ´ng nghá»‡. CÃ´ áº¥y thÃ­ch lÃ m vÆ°á»n, nuÃ´i chÃ³ vÃ  mÃ¨o.

**Matthew Watson and Chen Qian:** *Quy trÃ¬nh NLP vá»›i Keras*

<div class="flex justify-center">
<Youtube id="gZIP-_2XYMM"/>
</div>

<p align="center">
<img src="https://i.imgur.com/1vD2az8.png" alt="TÃ³m táº¯t hÃ¬nh áº£nh vá» bÃ i chia sáº» cá»§a Matt vÃ  Chen" width="80%"/>
</p>

Matthew Watson lÃ  má»™t ká»¹ sÆ° há»c mÃ¡y trong nhÃ³m Keras, táº­p trung vÃ o cÃ¡c API mÃ´ hÃ¬nh hÃ³a cáº¥p cao. Anh há»c Äá»“ há»a mÃ¡y tÃ­nh á»Ÿ Ä‘áº¡i há»c vÃ  cÃ³ báº±ng Tháº¡c sÄ© táº¡i Äáº¡i há»c Stanford. LÃ  má»™t sinh viÃªn gáº§n nhÆ° chuyÃªn ngÃ nh tiáº¿ng Anh chuyá»ƒn sang ngÃ nh khoa há»c mÃ¡y tÃ­nh, anh áº¥y Ä‘am mÃª lÃ m viá»‡c trÃªn nhiá»u lÄ©nh vá»±c vÃ  giÃºp cho NLP cÃ³ thá»ƒ tiáº¿p cáº­n vá»›i nhiá»u Ä‘á»‘i tÆ°á»£ng hÆ¡n.

Chen Qian lÃ  ká»¹ sÆ° pháº§n má»m tá»« nhÃ³m Keras, táº­p trung vÃ o cÃ¡c API mÃ´ hÃ¬nh hÃ³a cáº¥p cao. Chen cÃ³ báº±ng Tháº¡c sÄ© Ká»¹ thuáº­t Äiá»‡n táº¡i Äáº¡i há»c Stanford vÃ  anh áº¥y Ä‘áº·c biá»‡t quan tÃ¢m Ä‘áº¿n viá»‡c Ä‘Æ¡n giáº£n hÃ³a viá»‡c triá»ƒn khai mÃ£ cá»§a cÃ¡c tÃ¡c vá»¥ ML vÃ  ML quy mÃ´ lá»›n.

**Mark Saroufim:** *CÃ¡ch Huáº¥n luyá»‡n má»™t MÃ´ hÃ¬nh vá»›i Pytorch*

<div class="flex justify-center">
<Youtube id="KmvPlW2cbIo"/>
</div>

<p align="center">
<img src="https://i.imgur.com/TPmlkm8.png" alt="TÃ³m táº¯t hÃ¬nh áº£nh vá» bÃ i chia sáº» cá»§a Mark" width="80%"/>
</p>

Mark Saroufim lÃ  Ká»¹ sÆ° Ä‘á»‘i tÃ¡c táº¡i Pytorch lÃ m viá»‡c trÃªn cÃ¡c cÃ´ng cá»¥ sáº£n xuáº¥t OSS bao gá»“m TorchServe vÃ  Pytorch Enterprise. TrÆ°á»›c Ä‘Ã³, Mark lÃ  NhÃ  khoa há»c á»©ng dá»¥ng vÃ  GiÃ¡m Ä‘á»‘c sáº£n pháº©m táº¡i Graphcore, [yuri.ai](http://yuri.ai/), Microsoft vÃ  NASA's JPL. Niá»m Ä‘am mÃª chÃ­nh cá»§a anh áº¥y lÃ  lÃ m cho viá»‡c láº­p trÃ¬nh trá»Ÿ nÃªn thÃº vá»‹ hÆ¡n.

**Jakob Uszkoreit:** *NÃ³ khÃ´ng há»ng nÃªn <del>Äá»«ng sá»­a</del> HÃ£y phÃ¡ nÃ³ Ä‘i*

<div class="flex justify-center">
<Youtube id="C6jweXYFHSA"/>
</div>

<p align="center">
<img src="https://i.imgur.com/5dWQeNB.png" alt="TÃ³m táº¯t hÃ¬nh áº£nh vá» bÃ i chia sáº» cá»§a Jakob" width="80%"/>
</p>

Jakob Uszkoreit lÃ  Ä‘á»“ng sÃ¡ng láº­p cá»§a Inception. Inception thiáº¿t káº¿ cÃ¡c phÃ¢n tá»­ RNA cho váº¯c-xin vÃ  liá»‡u phÃ¡p Ä‘iá»u trá»‹ báº±ng cÃ¡ch sá»­ dá»¥ng há»c sÃ¢u quy mÃ´ lá»›n trong má»™t vÃ²ng láº·p cháº·t cháº½ vá»›i cÃ¡c thÃ­ nghiá»‡m thÃ´ng lÆ°á»£ng cao vá»›i má»¥c tiÃªu lÃ m cho cÃ¡c loáº¡i thuá»‘c dá»±a trÃªn RNA trá»Ÿ nÃªn dá»… tiáº¿p cáº­n hÆ¡n, hiá»‡u quáº£ hÆ¡n vÃ  cÃ³ thá»ƒ Ã¡p dá»¥ng rá»™ng rÃ£i hÆ¡n. TrÆ°á»›c Ä‘Ã¢y, Jakob Ä‘Ã£ lÃ m viá»‡c táº¡i Google hÆ¡n má»™t tháº­p ká»·, lÃ£nh Ä‘áº¡o cÃ¡c nhÃ³m nghiÃªn cá»©u vÃ  phÃ¡t triá»ƒn trong Google Brain, NghiÃªn cá»©u vÃ  TÃ¬m kiáº¿m, lÃ m viá»‡c vá» cÃ¡c nguyÃªn táº¯c cÆ¡ báº£n vá» há»c sÃ¢u, thá»‹ giÃ¡c mÃ¡y tÃ­nh, vÃ  hiá»ƒu ngÃ´n ngá»¯ vÃ  dá»‹ch mÃ¡y.

## NgÃ y 2: CÃ¡c cÃ´ng cá»¥ sá»­ dá»¥ng

**Lewis Tunstall:** *Huáº¥n luyá»‡n Ä‘Æ¡n giáº£n vá»›i ğŸ¤— Transformers Trainer*

<div class="flex justify-center">
<Youtube id="u--UVvH-LIQ"/>
</div>

Lewis lÃ  má»™t ká»¹ sÆ° mÃ¡y há»c táº¡i Hugging Face, táº­p trung vÃ o viá»‡c phÃ¡t triá»ƒn cÃ¡c cÃ´ng cá»¥ mÃ£ nguá»“n má»Ÿ vÃ  giÃºp chÃºng cÃ³ thá»ƒ tiáº¿p cáº­n vá»›i cá»™ng Ä‘á»“ng rá»™ng lá»›n hÆ¡n. Anh cÅ©ng lÃ  Ä‘á»“ng tÃ¡c giáº£ cá»§a cuá»‘n sÃ¡ch Oâ€™Reilly [Natural Language Processing with Transformers](https://www.oreilly.com/library/view/natural-language-processing/9781098136789/). Báº¡n cÃ³ thá»ƒ theo dÃµi anh áº¥y trÃªn Twitter (@_lewtun) Ä‘á»ƒ biáº¿t cÃ¡c máº¹o vÃ  thá»§ thuáº­t NLP!

**Matthew Carrigan:** * CÃ¡c tÃ­nh nÄƒng TensorFlow má»›i cho ğŸ¤— Transformers vÃ  ğŸ¤— Datasets*

<div class="flex justify-center">
<Youtube id="gQUlXp1691w"/>
</div>

Matt chá»‹u trÃ¡ch nhiá»‡m báº£o trÃ¬ TensorFlow táº¡i Transformers, vÃ  cuá»‘i cÃ¹ng sáº½ dáº«n Ä‘áº§u má»™t cuá»™c Ä‘áº£o chÃ­nh chá»‘ng láº¡i phe PyTorch Ä‘Æ°Æ¡ng nhiá»‡m, cÃ³ kháº£ nÄƒng thÃ´ng qua tÃ i khoáº£n Twitter @carrigmat cá»§a anh ta.

** Lysandre Debut: ** *Hugging Face Hub nhÆ° má»™t phÆ°Æ¡ng tiá»‡n Ä‘á»ƒ cá»™ng tÃ¡c vÃ  chia sáº» cÃ¡c dá»± Ã¡n Há»c mÃ¡y*

<div class="flex justify-center">
<Youtube id="RBw1TmdEZp0"/>
</div>

<p align="center">
<img src="https://i.imgur.com/TarIPCz.png" alt="TÃ³m táº¯t hÃ¬nh áº£nh vá» bÃ i chia sáº» cá»§a Lysandre" width="80%"/>
</p>

Lysandre lÃ  Ká»¹ sÆ° Há»c mÃ¡y táº¡i Hugging Face, nÆ¡i anh áº¥y tham gia vÃ o nhiá»u dá»± Ã¡n mÃ£ nguá»“n má»Ÿ. Má»¥c Ä‘Ã­ch cá»§a Ã´ng lÃ  lÃ m cho Há»c mÃ¡y cÃ³ thá»ƒ truy cáº­p Ä‘Æ°á»£c vá»›i táº¥t cáº£ má»i ngÆ°á»i báº±ng cÃ¡ch phÃ¡t triá»ƒn cÃ¡c cÃ´ng cá»¥ máº¡nh máº½ vá»›i má»™t API ráº¥t Ä‘Æ¡n giáº£n.

**Lucile Saulnier:** *Táº¡o ra tokenizer cá»§a riÃªng báº¡nğŸ¤— Transformers & ğŸ¤— Tokenizers*

<div class="flex justify-center">
<Youtube id="UkNmyTFKriI"/>
</div>

Lucile lÃ  má»™t ká»¹ sÆ° há»c mÃ¡y táº¡i Hugging Face, phÃ¡t triá»ƒn vÃ  há»— trá»£ viá»‡c sá»­ dá»¥ng cÃ¡c cÃ´ng cá»¥ mÃ£ nguá»“n má»Ÿ. CÃ´ cÅ©ng tÃ­ch cá»±c tham gia vÃ o nhiá»u dá»± Ã¡n nghiÃªn cá»©u trong lÄ©nh vá»±c Xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn nhÆ° huáº¥n luyá»‡n há»£p tÃ¡c vÃ  BigScience.

**Sylvain Gugger:** *TÄƒng cÆ°á»ng vÃ²ng láº·p huáº¥n luyá»‡n PyTorch cá»§a báº¡n vá»›i ğŸ¤— Accelerate*

<div class="flex justify-center">
<Youtube id="t8Krzu-nSeY"/>
</div>

Sylvain lÃ  Ká»¹ sÆ° nghiÃªn cá»©u táº¡i Hugging Face vÃ  lÃ  má»™t trong nhá»¯ng ngÆ°á»i báº£o trÃ¬ cá»‘t lÃµi cá»§a ğŸ¤— Transformers vÃ  lÃ  nhÃ  phÃ¡t triá»ƒn Ä‘áº±ng sau ğŸ¤— Accelerate. Anh áº¥y thÃ­ch lÃ m cho nhá»¯ng mÃ´ hÃ¬nh huáº¥n luyá»‡n trá»Ÿ nÃªn dá»… tiáº¿p cáº­n hÆ¡n.

**Merve Noyan:** *Giá»›i thiá»‡u cÃ¡c báº£n demo mÃ´ hÃ¬nh cá»§a báº¡n vá»›i ğŸ¤— Spaces*

<div class="flex justify-center">
<Youtube id="vbaKOa4UXoM"/>
</div>

Merve lÃ  chuyÃªn gia vá» quan há»‡ láº­p trÃ¬nh viÃªn táº¡i Hugging Face, Ä‘ang lÃ m viá»‡c Ä‘á»ƒ phÃ¡t triá»ƒn cÃ¡c cÃ´ng cá»¥ vÃ  xÃ¢y dá»±ng ná»™i dung xung quanh chÃºng Ä‘á»ƒ giÃºp há»c mÃ¡y cÃ³ thá»ƒ tiáº¿p cáº­n tá»›i táº¥t cáº£ má»i ngÆ°á»i.

**Abubakar Abid:** *XÃ¢y dá»±ng á»¨ng dá»¥ng Há»c mÃ¡y nhanh chÃ³ng*

<div class="flex justify-center">
<Youtube id="c7mle2yYpwQ"/>
</div>

<p align="center">
<img src="https://i.imgur.com/qWIFeiF.png" alt="TÃ³m táº¯t hÃ¬nh áº£nh vá» bÃ i chia sáº» cá»§a Abubakar" width="80%"/>
</p>

Abubakar Abid lÃ  GiÃ¡m Ä‘á»‘c Ä‘iá»u hÃ nh cá»§a [Gradio](www.gradio.app). Anh áº¥y nháº­n báº±ng Cá»­ nhÃ¢n Khoa há»c vá» Ká»¹ thuáº­t Äiá»‡n vÃ  Khoa há»c MÃ¡y tÃ­nh tá»« MIT vÃ o nÄƒm 2015 vÃ  Tiáº¿n sÄ© vá» MÃ¡y há»c á»¨ng dá»¥ng tá»« Stanford vÃ o nÄƒm 2021. Vá»›i vai trÃ² lÃ  GiÃ¡m Ä‘á»‘c Ä‘iá»u hÃ nh cá»§a Gradio, Abubakar lÃ m viá»‡c Ä‘á»ƒ lÃ m cho cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y dá»… dÃ ng demo, gá»¡ lá»—i vÃ  triá»ƒn khai hÆ¡n.

**Mathieu DesvÃ©:** *AWS ML Vision: LÃ m cho MÃ¡y há»c cÃ³ thá»ƒ dá»… dÃ ng truy cáº­p Ä‘Æ°á»£c bá»Ÿi táº¥t cáº£ khÃ¡ch hÃ ng*

<div class="flex justify-center">
<Youtube id="O2e3pXO4aRE"/>
</div>

<p align="center">
<img src="https://i.imgur.com/oLdZTKy.png" alt="TÃ³m táº¯t hÃ¬nh áº£nh vá» bÃ i chia sáº» cá»§a Mathieu" width="80%"/>
</p>

Mathieu DesvÃ© lÃ  ngÆ°á»i Ä‘am mÃª cÃ´ng nghá»‡, nhÃ  sáº£n xuáº¥t vÃ o thá»i gian ráº£nh. áº nh thÃ­ch thá»­ thÃ¡ch vÃ  giáº£i quyáº¿t váº¥n Ä‘á» cá»§a khÃ¡ch hÃ ng vÃ  ngÆ°á»i dÃ¹ng, Ä‘á»“ng thá»i lÃ m viá»‡c vá»›i nhá»¯ng ngÆ°á»i tÃ i nÄƒng Ä‘á»ƒ há»c há»i má»—i ngÃ y. Ká»ƒ tá»« nÄƒm 2004, anh lÃ m viá»‡c á»Ÿ nhiá»u vá»‹ trÃ­ chuyá»ƒn Ä‘á»•i tá»« frontend, backend, cÆ¡ sá»Ÿ háº¡ táº§ng, hoáº¡t Ä‘á»™ng vÃ  quáº£n lÃ½. Anh cá»‘ gáº¯ng giáº£i quyáº¿t cÃ¡c váº¥n Ä‘á» liÃªn quan Ä‘áº¿n ká»¹ thuáº­t vÃ  quáº£n lÃ½ theo cÃ¡ch nhanh nháº¹n.

**Philipp Schmid:** *Quáº£n lÃ½ huáº¥n luyá»‡n vá»›i Amazon SageMaker vÃ  ğŸ¤— Transformers*

<div class="flex justify-center">
<Youtube id="yG6J2Zfo8iw"/>
</div>

Philipp Schmid lÃ  Ká»¹ sÆ° MÃ¡y há»c vÃ  TrÆ°á»Ÿng nhÃ³m CÃ´ng nghá»‡ táº¡i Hugging Face, nÆ¡i anh lÃ£nh Ä‘áº¡o sá»± há»£p tÃ¡c vá»›i nhÃ³m Amazon SageMaker. Anh áº¥y Ä‘am mÃª sáº£n xuáº¥t cÃ¡c mÃ´ hÃ¬nh NLP tiÃªn tiáº¿n vÃ  cáº£i thiá»‡n tÃ­nh dá»… sá»­ dá»¥ng cho Há»c sÃ¢u.
