# Giá»›i thiá»‡u

<CourseFloatingBanner
    chapter={1}
    classNames="absolute z-10 right-0 top-0"
/>

## ChÃ o má»«ng tá»›i ğŸ¤— KhoÃ¡ há»c!

<Youtube id="00GKzGyWFEs" />

KhÃ³a há»c nÃ y sáº½ dáº¡y báº¡n vá» Xá»­ lÃ½ NgÃ´n ngá»¯ Tá»± nhiÃªn (NLP) sá»­ dá»¥ng cÃ¡c thÆ° viá»‡n tá»« há»‡ sinh thÃ¡i [Hugging Face](https://huggingface.co/) â€” [ğŸ¤— Transformers](https://github.com/huggingface/transformers), [ğŸ¤— Datasets](https://github.com/huggingface/datasets), [ğŸ¤— Tokenizers](https://github.com/huggingface/tokenizers), vÃ  [ğŸ¤— Accelerate](https://github.com/huggingface/accelerate) â€” cÅ©ng nhÆ° [Hugging Face Hub](https://huggingface.co/models). KhoÃ¡ há»c hoÃ n toÃ n miá»…n phÃ­ vÃ  khÃ´ng cÃ³ quáº£ng cÃ¡o.

## KhÃ³a há»c cÃ³ gÃ¬?

DÆ°á»›i Ä‘Ã¢y lÃ  tá»•ng quan ngáº¯n gá»n vá» khÃ³a há»c:

<div class="flex justify-center">
<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary.svg" alt="Brief overview of the chapters of the course.">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary-dark.svg" alt="Brief overview of the chapters of the course.">
</div>

- CÃ¡c chÆ°Æ¡ng tá»« 1 Ä‘áº¿n 4 giá»›i thiá»‡u cÃ¡c khÃ¡i niá»‡m chÃ­nh cá»§a thÆ° viá»‡n ğŸ¤— Transformers. Äáº¿n cuá»‘i há»c pháº§n nÃ y, báº¡n sáº½ quen thuá»™c vá»›i cÃ¡ch hoáº¡t Ä‘á»™ng cá»§a cÃ¡c mÃ´ hÃ¬nh Transformer vÃ  sáº½ biáº¿t cÃ¡ch sá»­ dá»¥ng mÃ´ hÃ¬nh tá»« [Hugging Face Hub](https://huggingface.co/models), tinh chá»‰nh nÃ³ trÃªn má»™t táº­p dá»¯ liá»‡u cá»¥ thá»ƒ, vÃ  chia sáº» káº¿t quáº£ cá»§a báº¡n lÃªn Hub!
- CÃ¡c chÆ°Æ¡ng tá»« 5 Ä‘áº¿n 8 dáº¡y cÃ¡c kiáº¿n thá»©c cÆ¡ báº£n vá» ğŸ¤— Datasets vÃ  ğŸ¤— Tokenizers trÆ°á»›c khi Ä‘i sÃ¢u vÃ o cÃ¡c tÃ¡c vá»¥ NLP kinh Ä‘iá»ƒn. Äáº¿n cuá»‘i há»c pháº§n nÃ y, báº¡n sáº½ cÃ³ thá»ƒ tá»± mÃ¬nh giáº£i quyáº¿t cÃ¡c váº¥n Ä‘á» NLP phá»• biáº¿n nháº¥t.
- CÃ¡c chÆ°Æ¡ng tá»« 9 Ä‘áº¿n 12 vÆ°á»£t ra ngoÃ i pháº¡m vi NLP vÃ  khÃ¡m phÃ¡ cÃ¡ch sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh Transformer Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c tÃ¡c vá»¥ trong xá»­ lÃ½ giá»ng nÃ³i vÃ  thá»‹ giÃ¡c mÃ¡y tÃ­nh. Trong quÃ¡ trÃ¬nh nÃ y, báº¡n sáº½ há»c cÃ¡ch xÃ¢y dá»±ng vÃ  chia sáº» cÃ¡c báº£n demo vá» mÃ´ hÃ¬nh cá»§a mÃ¬nh cÅ©ng nhÆ° cÃ¡ch tá»‘i Æ°u hÃ³a chÃºng cho mÃ´i trÆ°á»ng sáº£n xuáº¥t. Äáº¿n cuá»‘i há»c pháº§n nÃ y, báº¡n sáº½ sáºµn sÃ ng Ã¡p dá»¥ng ğŸ¤— Transformers cho (háº§u háº¿t) báº¥t ká»³ váº¥n Ä‘á» há»c mÃ¡y nÃ o!

KhoÃ¡ há»c:

- YÃªu cáº§u cÃ³ kiáº¿n thá»©c tá»‘t vá» Python.
- NÃªn tÃ¬m hiá»ƒu sau khi Ä‘Ã£ hoÃ n thÃ nh má»™t khÃ³a nháº­p mÃ´n vá» Há»c sÃ¢u, cháº³ng háº¡n nhÆ° [Practical Deep Learning for Coders](https://course.fast.ai/) cá»§a [fast.ai](https://www.fast.ai/) hoáº·c má»™t trong nhá»¯ng chÆ°Æ¡ng trÃ¬nh Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi [DeepLearning.AI](https://www.deeplearning.ai/).
- KhÃ´ng yÃªu cáº§u biáº¿t trÆ°á»›c cÃ¡c kiáº¿n thá»©c vá» [PyTorch](https://pytorch.org/) hoáº·c [TensorFlow](https://www.tensorflow.org/), máº·c dÃ¹ quen thuá»™c vá»›i má»™t sá»‘ kiáº¿n thá»©c nÃ y sáº½ há»¯u Ã­ch.

Sau khi báº¡n hoÃ n thÃ nh khÃ³a há»c nÃ y, chÃºng tÃ´i khuyáº¿n khÃ­ch báº¡n xem thÃªm khoÃ¡ [Natural Language Processing Specialization](https://www.coursera.org/specializations/natural-language-processing?utm_source=deeplearning-ai&utm_medium=institutions&utm_campaign=20211011-nlp-2-hugging_face-page-nlp-refresh) cá»§a DeepLearning.AI vá»›i ná»™i dung bao gá»“m má»™t loáº¡t cÃ¡c mÃ´ hÃ¬nh NLP truyá»n thá»‘ng Ä‘Ã¡ng Ä‘á»ƒ biáº¿t nhÆ° Naive Bayes vÃ  LSTM!

## ChÃºng ta lÃ  ai?

Giá»›i thiá»‡u vá» tÃ¡c giáº£:

[**Abubakar Abid**](https://huggingface.co/abidlabs) Ä‘Ã£ hoÃ n thÃ nh chÆ°Æ¡ng trÃ¬nh Tiáº¿n sÄ© vá» há»c mÃ¡y á»©ng dá»¥ng táº¡i Stanford. Trong thá»i gian há»c tiáº¿n sÄ©, anh áº¥y Ä‘Ã£ táº¡o ra [Gradio](https://github.com/gradio-app/gradio), má»™t thÆ° viá»‡n Python mÃ£ nguá»“n má»Ÿ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ xÃ¢y dá»±ng hÆ¡n 600,000 báº£n demo há»c mÃ¡y. Gradio Ä‘Æ°á»£c mua láº¡i bá»Ÿi Hugging Face, nÆ¡i Abubakar hiá»‡n Ä‘Ã³ng vai trÃ² lÃ  trÆ°á»Ÿng nhÃ³m há»c mÃ¡y.

[**Matthew Carrigan**](https://huggingface.co/Rocketknight1) lÃ  má»™t Ká»¹ sÆ° Há»c mÃ¡y táº¡i Hugging Face. Anh áº¥y sá»‘ng á»Ÿ Dublin, Ireland, trÆ°á»›c Ä‘Ã¢y lÃ  ká»¹ sÆ° Há»c mÃ¡y táº¡i Parse.ly vÃ  trÆ°á»›c Ä‘Ã³ lÃ  nhÃ  nghiÃªn cá»©u sau tiáº¿n sÄ© táº¡i Trinity College Dublin. Anh áº¥y khÃ´ng tin ráº±ng chÃºng ta sáº½ Ä‘áº¡t Ä‘Æ°á»£c AGI báº±ng cÃ¡ch má»Ÿ rá»™ng cÃ¡c kiáº¿n â€‹â€‹trÃºc hiá»‡n cÃ³, nhÆ°ng cÃ³ niá»m tin vÃ o sá»± báº¥t tá»­ cá»§a robot.

[**Lysandre Debut**](https://huggingface.co/lysandre) lÃ  má»™t Ká»¹ sÆ° Há»c mÃ¡y táº¡i Hugging Face vÃ  Ä‘Ã£ lÃ m viá»‡c vá»›i thÆ° viá»‡n ğŸ¤— Transformers tá»« nhá»¯ng giai Ä‘oáº¡n Ä‘áº§u phÃ¡t triá»ƒn. Má»¥c tiÃªu cá»§a anh áº¥y lÃ  lÃ m cho NLP cÃ³ thá»ƒ dá»… dÃ ng truy cáº­p Ä‘Æ°á»£c tá»« táº¥t cáº£ má»i ngÆ°á»i báº±ng cÃ¡ch phÃ¡t triá»ƒn cÃ¡c cÃ´ng cá»¥ vá»›i má»™t API ráº¥t Ä‘Æ¡n giáº£n.

[**Sylvain Gugger**](https://huggingface.co/sgugger) lÃ  Ká»¹ sÆ° nghiÃªn cá»©u táº¡i Hugging Face vÃ  lÃ  má»™t trong nhá»¯ng thÃ nh viÃªn cá»‘t lÃµi cá»§a thÆ° viá»‡n ğŸ¤— Transformers. TrÆ°á»›c Ä‘Ã¢y, anh áº¥y lÃ  NhÃ  nghiÃªn cá»©u khoa há»c táº¡i fast.ai vÃ  anh áº¥y lÃ  Ä‘á»“ng sÃ¡ng tÃ¡c Ä‘áº§u sÃ¡ch _[Deep Learning for Coders with fastai and PyTorch](https://learning.oreilly.com/library/view/deep-learning-for/9781492045519/)_ cÃ¹ng vá»›i Jeremy Howard. HÆ°á»›ng nghiÃªn cá»©u chÃ­nh cá»§a anh áº¥y lÃ  lÃ m cho viá»‡c há»c sÃ¢u trá»Ÿ nÃªn dá»… tiáº¿p cáº­n hÆ¡n, báº±ng cÃ¡ch thiáº¿t káº¿ vÃ  cáº£i tiáº¿n cÃ¡c ká»¹ thuáº­t cho phÃ©p cÃ¡c mÃ´ hÃ¬nh huáº¥n luyá»‡n nhanh trÃªn cÃ¡c tÃ i nguyÃªn háº¡n cháº¿.

[**Dawood Khan**](https://huggingface.co/dawoodkhan82) lÃ  má»™t Ká»¹ sÆ° Há»c mÃ¡y táº¡i Hugging Face. Anh áº¥y Ä‘áº¿n tá»« New York vÃ  tá»‘t nghiá»‡p Äáº¡i há»c New York chuyÃªn ngÃ nh Khoa há»c mÃ¡y tÃ­nh. Sau khi lÃ m viá»‡c vá»›i tÆ° cÃ¡ch lÃ  Ká»¹ sÆ° iOS trong má»™t vÃ i nÄƒm, Dawood Ä‘Ã£ nghá»‰ viá»‡c Ä‘á»ƒ báº¯t Ä‘áº§u phÃ¡t triá»ƒn Gradio cÃ¹ng vá»›i nhá»¯ng ngÆ°á»i Ä‘á»“ng sÃ¡ng láº­p cá»§a mÃ¬nh. Gradio cuá»‘i cÃ¹ng Ä‘Ã£ Ä‘Æ°á»£c mua láº¡i bá»Ÿi Hugging Face.

[**Merve Noyan**](https://huggingface.co/merve) lÃ  ChuyÃªn gia vá» Quan há»‡ láº­p trÃ¬nh viÃªn táº¡i Hugging Face, hiá»‡n Ä‘ang phÃ¡t triá»ƒn cÃ¡c cÃ´ng cá»¥ vÃ  xÃ¢y dá»±ng ná»™i dung xung quanh chÃºng Ä‘á»ƒ táº¥t cáº£ má»i ngÆ°á»i cÃ³ thá»ƒ tiáº¿p cáº­n há»c mÃ¡y dá»… dÃ ng hÆ¡n.

[**Lucile Saulnier**](https://huggingface.co/SaulLu) lÃ  má»™t Ká»¹ sÆ° Há»c mÃ¡y táº¡i Hugging Face, phÃ¡t triá»ƒn vÃ  há»— trá»£ viá»‡c sá»­ dá»¥ng cÃ¡c cÃ´ng cá»¥ mÃ£ nguá»“n má»Ÿ. CÃ´ cÅ©ng tÃ­ch cá»±c tham gia vÃ o nhiá»u dá»± Ã¡n nghiÃªn cá»©u trong lÄ©nh vá»±c Xá»­ lÃ½ NgÃ´n ngá»¯ Tá»± nhiÃªn nhÆ° huáº¥n luyá»‡n cá»™ng tÃ¡c vÃ  BigScience.

[**Lewis Tunstall**](https://huggingface.co/lewtun) lÃ  má»™t Ká»¹ sÆ° Há»c mÃ¡y táº¡i Hugging Face, táº­p trung vÃ o viá»‡c phÃ¡t triá»ƒn cÃ¡c cÃ´ng cá»¥ mÃ£ nguá»“n má»Ÿ vÃ  giÃºp chÃºng cÃ³ thá»ƒ tiáº¿p cáº­n Ä‘Æ°á»£c vá»›i cá»™ng Ä‘á»“ng rá»™ng lá»›n hÆ¡n. Anh cÅ©ng lÃ  Ä‘á»“ng tÃ¡c giáº£ cá»§a cuá»‘n sÃ¡ch Oâ€™Reilly [Natural Language Processing with Transformers](https://www.oreilly.com/library/view/natural-language-processing/9781098136789/).

[**Leandro von Werra**](https://huggingface.co/lvwerra) lÃ  má»™t Ká»¹ sÆ° Há»c mÃ¡y trong nhÃ³m mÃ£ nguá»“n má»Ÿ táº¡i Hugging Face vÃ  cÅ©ng lÃ  Ä‘á»“ng tÃ¡c giáº£ cá»§a cuá»‘n sÃ¡ch O'Reilly [Natural Language Processing with Transformers](https://www.oreilly.com/library/view/natural-language-processing/9781098136789/). Anh áº¥y cÃ³ nhiá»u nÄƒm kinh nghiá»‡m thá»±c táº¿ triá»ƒn khai cÃ¡c dá»± Ã¡n NLP vÃ o sáº£n xuáº¥t báº±ng cÃ¡ch lÃ m viá»‡c trÃªn toÃ n bá»™ há»‡ thá»‘ng há»c mÃ¡y.

Báº¡n Ä‘Ã£ sáºµn sÃ ng chÆ°a? Trong chÆ°Æ¡ng nÃ y, báº¡n sáº½ há»c:

- CÃ¡ch sá»­ dá»¥ng hÃ m `pipeline()` Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c tÃ¡c vá»¥ NLP nhÆ° táº¡o vÃ  phÃ¢n loáº¡i vÄƒn báº£n.
- Vá» cáº¥u trÃºc cá»§a máº¡ng Transformer.
- LÃ m tháº¿ nÃ o Ä‘á»ƒ phÃ¢n biá»‡t giá»¯a cÃ¡c kiáº¿n trÃºc encoder, decoder, vÃ  encoder-decoder cÅ©ng nhÆ° cÃ¡c trÆ°á»ng há»£p sá»­ dá»¥ng.
