# Giá»›i thiá»‡u

<CourseFloatingBanner
    chapter={6}
    classNames="absolute z-10 right-0 top-0"
/>

Trong [ChÆ°Æ¡ng 3](/course/chapter3), chÃºng ta Ä‘Ã£ xem xÃ©t cÃ¡ch tinh chá»‰nh má»™t mÃ´ hÃ¬nh trong má»™t tÃ¡c vá»¥ nháº¥t Ä‘á»‹nh. Khi lÃ m Ä‘iá»u Ä‘Ã³, chÃºng ta sá»­ dá»¥ng cÃ¹ng má»™t trÃ¬nh tokenizer mÃ  mÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c - nhÆ°ng chÃºng ra pháº£i lÃ m gÃ¬ khi muá»‘n huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh tá»« Ä‘áº§u? Trong nhá»¯ng trÆ°á»ng há»£p nÃ y, viá»‡c sá»­ dá»¥ng trÃ¬nh tokenizer Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c trÃªn má»™t kho ngá»¯ liá»‡u tá»« má»™t lÄ©nh vá»±c hoáº·c ngÃ´n ngá»¯ khÃ¡c thÆ°á»ng lÃ  khÃ´ng tá»‘i Æ°u. VÃ­ dá»¥: má»™t tokenizer Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn ngá»¯ liá»‡u tiáº¿ng Anh sáº½ hoáº¡t Ä‘á»™ng kÃ©m trÃªn ngá»¯ liá»‡u vÄƒn báº£n tiáº¿ng Nháº­t vÃ¬ viá»‡c sá»­ dá»¥ng dáº¥u cÃ¡ch vÃ  dáº¥u cÃ¢u trong hai ngÃ´n ngá»¯ ráº¥t khÃ¡c nhau.

Trong chÆ°Æ¡ng nÃ y, báº¡n sáº½ há»c cÃ¡ch huáº¥n luyá»‡n má»™t trÃ¬nh tokenize hoÃ n toÃ n má»›i trÃªn kho ngá»¯ liá»‡u vÄƒn báº£n, do Ä‘Ã³, nÃ³ cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ huáº¥n luyá»‡n trÆ°á»›c má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯. Táº¥t cáº£ Ä‘iá»u nÃ y sáº½ Ä‘Æ°á»£c thá»±c hiá»‡n vá»›i sá»± trá»£ giÃºp cá»§a thÆ° viá»‡n [ğŸ¤— Tokenizers](https://github.com/huggingface/tokenizers), nÆ¡i cung cáº¥p cÃ¡c tokenizer "nhanh" trong thÆ° viá»‡n [ğŸ¤— Transformers](https://github.com/huggingface/transformers). ChÃºng ta sáº½ xem xÃ©t ká»¹ cÃ¡c tÃ­nh nÄƒng mÃ  thÆ° viá»‡n nÃ y cung cáº¥p vÃ  khÃ¡m phÃ¡ cÃ¡ch cÃ¡c báº£n tokenizer nhanh khÃ¡c so vá»›i cÃ¡c phiÃªn báº£n "cháº­m".

CÃ¡c chá»§ Ä‘á» chÃºng ta sáº½ Ä‘á» cáº­p bao gá»“m:

- CÃ¡ch huáº¥n luyá»‡n má»™t trÃ¬nh tokenize má»›i tÆ°Æ¡ng tá»± nhÆ° má»™t trÃ¬nh Ä‘Æ°á»£c sá»­ dá»¥ng bá»Ÿi má»™t checkpoint nháº¥t Ä‘á»‹nh trÃªn má»™t kho vÄƒn báº£n má»›i
- CÃ¡c tÃ­nh nÄƒng Ä‘áº·c biá»‡t cá»§a tokenizer nhanh
- Sá»± khÃ¡c biá»‡t giá»¯a ba thuáº­t toÃ¡n tokenize tá»« phá»¥ Ä‘Æ°á»£c sá»­ dá»¥ng trong NLP ngÃ y nay
- CÃ¡ch xÃ¢y dá»±ng má»™t tokenizer tá»« Ä‘áº§u vá»›i thÆ° viá»‡n ğŸ¤— Tokenizer vÃ  huáº¥n luyá»‡n nÃ³ trÃªn má»™t sá»‘ dá»¯ liá»‡u

CÃ¡c ká»¹ thuáº­t Ä‘Æ°á»£c giá»›i thiá»‡u trong chÆ°Æ¡ng nÃ y sáº½ giÃºp báº¡n chuáº©n bá»‹ cho pháº§n trong [ChÆ°Æ¡ng 7](/course/chapter7/6), nÆ¡i chÃºng ta xem xÃ©t viá»‡c táº¡o mÃ´ hÃ¬nh ngÃ´n ngá»¯ cho mÃ£ nguá»“n Python. HÃ£y báº¯t Ä‘áº§u báº±ng cÃ¡ch xem xÃ©t Ã½ nghÄ©a cá»§a viá»‡c "huáº¥n luyá»‡n" má»™t tokenizer ngay tá»« Ä‘áº§u.
