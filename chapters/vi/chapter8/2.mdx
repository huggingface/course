# Pháº£i lÃ m gÃ¬ khi báº¡n gáº·p lá»—i

<DocNotebookDropdown
  classNames="absolute z-10 right-0 top-0"
  options={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/vi/chapter8/section2.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/vi/chapter8/section2.ipynb"},
]} />

Trong pháº§n nÃ y, chÃºng ta sáº½ xem xÃ©t má»™t sá»‘ lá»—i phá»• biáº¿n cÃ³ thá»ƒ xáº£y ra khi báº¡n Ä‘ang cá»‘ gáº¯ng táº¡o dá»± Ä‘oÃ¡n tá»« mÃ´ hÃ¬nh Transformer má»›i Ä‘Æ°á»£c Ä‘iá»u chá»‰nh cá»§a mÃ¬nh. Äiá»u nÃ y sáº½ giÃºp báº¡n chuáº©n bá»‹ cho [section 4](/course/chapter8/section4), nÆ¡i chÃºng ta sáº½ khÃ¡m phÃ¡ cÃ¡ch gá»¡ lá»—i chÃ­nh giai Ä‘oáº¡n huáº¥n luyá»‡n.

<Youtube id="DQ-CpJn6Rc4"/>

ChÃºng tÃ´i Ä‘Ã£ chuáº©n bá»‹ [kho lÆ°u trá»¯ mÃ´ hÃ¬nh máº«u](https://huggingface.co/lewtun/distilbert-base-uncased-finetuned-squad-d5716d28) cho pháº§n nÃ y vÃ  náº¿u báº¡n muá»‘n cháº¡y mÃ£ trong chÆ°Æ¡ng nÃ y, trÆ°á»›c tiÃªn, báº¡n cáº§n sao chÃ©p mÃ´ hÃ¬nh vÃ o tÃ i khoáº£n cá»§a báº¡n trÃªn [Hugging Face Hub](https://huggingface.co). Äá»ƒ lÃ m nhÆ° váº­y, trÆ°á»›c tiÃªn hÃ£y Ä‘Äƒng nháº­p báº±ng cÃ¡ch cháº¡y má»™t trong hai thao tÃ¡c sau trong notebook Jupyter:

```python
from huggingface_hub import notebook_login

notebook_login()
```

hoáº·c sau trong terminal yÃªu thÃ­ch cá»§a báº¡n:

```bash
huggingface-cli login
```

Thao tÃ¡c nÃ y sáº½ nháº¯c báº¡n nháº­p tÃªn ngÆ°á»i dÃ¹ng vÃ  máº­t kháº©u cá»§a mÃ¬nh, Ä‘á»“ng thá»i sáº½ lÆ°u token dÆ°á»›i *~/.cache/huggingface/*. Khi báº¡n Ä‘Ã£ Ä‘Äƒng nháº­p, báº¡n cÃ³ thá»ƒ sao chÃ©p kho máº«u vá»›i hÃ m sau:

```python
from distutils.dir_util import copy_tree
from huggingface_hub import Repository, snapshot_download, create_repo, get_full_repo_name


def copy_repository_template():
    # Sao chÃ©p kho vÃ  trÃ­ch xuáº¥t Ä‘Æ°á»ng dáº«n cá»¥c bá»™
    template_repo_id = "lewtun/distilbert-base-uncased-finetuned-squad-d5716d28"
    commit_hash = "be3eaffc28669d7932492681cd5f3e8905e358b4"
    template_repo_dir = snapshot_download(template_repo_id, revision=commit_hash)
    # Táº¡o ra má»™t kho rá»—ng trÃªn Hub
    model_name = template_repo_id.split("/")[1]
    create_repo(model_name, exist_ok=True)
    # Sao chÃ©p kho rá»—ng
    new_repo_id = get_full_repo_name(model_name)
    new_repo_dir = model_name
    repo = Repository(local_dir=new_repo_dir, clone_from=new_repo_id)
    # Sao chÃ©p cÃ¡c tá»‡p
    copy_tree(template_repo_dir, new_repo_dir)
    # Äáº©y lÃªn Hub
    repo.push_to_hub()
```

Giá» khi báº¡n gá»i `copy_repository_template()`, nÃ³ sáº½ táº¡o ra má»™t báº£n sao kho lÆ°u trá»¯ máº«u dÆ°á»›i tÃ i khoáº£n cá»§a báº¡n.

## Gá»¡ lá»—i pipeline ğŸ¤— Transformers

Äá»ƒ báº¯t Ä‘áº§u cuá»™c hÃ nh trÃ¬nh cá»§a chÃºng ta vÃ o tháº¿ giá»›i tuyá»‡t vá»i cá»§a viá»‡c gá»¡ lá»—i cÃ¡c mÃ´ hÃ¬nh Transformer, hÃ£y xem xÃ©t tÃ¬nh huá»‘ng sau: báº¡n Ä‘ang lÃ m viá»‡c vá»›i má»™t Ä‘á»“ng nghiá»‡p trong má»™t dá»± Ã¡n há»i Ä‘Ã¡p Ä‘á»ƒ giÃºp khÃ¡ch hÃ ng cá»§a má»™t trang web thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­ tÃ¬m tháº¥y cÃ¢u tráº£ lá»i vá» cÃ¡c sáº£n pháº©m tiÃªu dÃ¹ng. Äá»“ng nghiá»‡p cá»§a báº¡n gá»­i cho báº¡n má»™t tin nháº¯n nhÆ°:

> ChÃºc báº¡n má»™t ngÃ y tá»‘t lÃ nh! TÃ´i vá»«a cháº¡y má»™t thá»­ nghiá»‡m báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t trong [ChÆ°Æ¡ng 7](/course/chapter7/7) cá»§a khÃ³a há»c Hugging Face vÃ  nháº­n Ä‘Æ°á»£c má»™t sá»‘ káº¿t quáº£ tuyá»‡t vá»i trÃªn SQuAD! TÃ´i nghÄ© chÃºng ta cÃ³ thá»ƒ sá»­ dá»¥ng mÃ´ hÃ¬nh nÃ y nhÆ° má»™t Ä‘iá»ƒm khá»Ÿi Ä‘áº§u cho dá»± Ã¡n cá»§a mÃ¬nh. ID mÃ´ hÃ¬nh trÃªn Hub lÃ  "lewtun/distillbert-base-uncased-finetuned-squad-d5716d28". HÃ£y thá»­ nghiá»‡m nÃ³ xem :)

vÃ  Ä‘iá»u Ä‘áº§u tiÃªn báº¡n nghÄ© Ä‘áº¿n lÃ  táº£i mÃ´ hÃ¬nh báº±ng cÃ¡ch sá»­ dá»¥ng `pipeline` tá»« ğŸ¤— Transformers:

```python
from transformers import pipeline

model_checkpoint = get_full_repo_name("distillbert-base-uncased-finetuned-squad-d5716d28")
reader = pipeline("question-answering", model=model_checkpoint)
```

```python out
"""
OSError: Can't load config for 'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28'. Make sure that:

- 'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28' is a correct model identifier listed on 'https://huggingface.co/models'

- or 'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28' is the correct path to a directory containing a config.json file
"""
```

Ã”i khÃ´ng, cÃ³ váº» nhÆ° cÃ³ gÃ¬ Ä‘Ã³ khÃ´ng á»•n! Náº¿u báº¡n lÃ  ngÆ°á»i má»›i láº­p trÃ¬nh, nhá»¯ng lá»—i kiá»ƒu nÃ y thoáº¡t Ä‘áº§u cÃ³ váº» hÆ¡i khÃ³ hiá»ƒu (tháº­m chÃ­ `OSError` lÃ  gÃ¬ ?!). Lá»—i Ä‘Æ°á»£c hiá»ƒn thá»‹ á»Ÿ Ä‘Ã¢y chá»‰ lÃ  pháº§n cuá»‘i cÃ¹ng cá»§a má»™t bÃ¡o cÃ¡o lá»—i lá»›n hÆ¡n nhiá»u Ä‘Æ°á»£c gá»i lÃ  _Python traceback_ (hay cÃ²n gá»i lÃ  Ä‘Ã¡u váº¿t ngÄƒn xáº¿p). VÃ­ dá»¥: náº¿u báº¡n Ä‘ang cháº¡y Ä‘oáº¡n mÃ£ nÃ y trÃªn Google Colab, báº¡n sáº½ tháº¥y má»™t cÃ¡i gÃ¬ Ä‘Ã³ giá»‘ng nhÆ° áº£nh chá»¥p mÃ n hÃ¬nh sau:

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter8/traceback.png" alt="A Python traceback." width="100%"/>
</div>

CÃ³ ráº¥t nhiá»u thÃ´ng tin cÃ³ trong cÃ¡c bÃ¡o cÃ¡o nÃ y, vÃ¬ váº­y chÃºng ta hÃ£y cÃ¹ng nhau xem qua cÃ¡c pháº§n chÃ­nh. Äiá»u Ä‘áº§u tiÃªn cáº§n lÆ°u Ã½ lÃ  theo dÃµi pháº£i Ä‘Æ°á»£c Ä‘á»c _tá»« dÆ°á»›i lÃªn trÃªn_. Äiá»u nÃ y nghe cÃ³ váº» ká»³ láº¡ náº¿u báº¡n Ä‘Ã£ quen Ä‘á»c vÄƒn báº£n tiáº¿ng Anh tá»« trÃªn xuá»‘ng dÆ°á»›i, nhÆ°ng nÃ³ pháº£n Ã¡nh thá»±c táº¿ lÃ  báº£n truy xuáº¥t hiá»ƒn thá»‹ chuá»—i cÃ¡c lá»‡nh gá»i hÃ m mÃ  `pipeline` thá»±c hiá»‡n khi táº£i xuá»‘ng mÃ´ hÃ¬nh vÃ  trÃ¬nh tokenizer. (Xem [ChÆ°Æ¡ng 2](/course/chapter2) Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t vá» cÃ¡ch hoáº¡t Ä‘á»™ng cá»§a `pipeline`.)

<Tip>

ğŸš¨ Báº¡n cÃ³ tháº¥y há»™p mÃ u xanh lam xung quanh "6 frames" trong pháº§n truy xuáº¥t tá»« Google Colab khÃ´ng? ÄÃ³ lÃ  má»™t tÃ­nh nÄƒng Ä‘áº·c biá»‡t cá»§a Colab, nÃ©n pháº§n truy xuáº¥t vÃ o cÃ¡c "frames". Náº¿u báº¡n dÆ°á»ng nhÆ° khÃ´ng thá»ƒ tÃ¬m ra nguá»“n gá»‘c cá»§a lá»—i, hÃ£y Ä‘áº£m báº£o ráº±ng báº¡n má»Ÿ rá»™ng toÃ n bá»™ theo dÃµi báº±ng cÃ¡ch nháº¥p vÃ o hai mÅ©i tÃªn nhá» Ä‘Ã³.

</Tip>

Äiá»u nÃ y cÃ³ nghÄ©a lÃ  dÃ²ng cuá»‘i cÃ¹ng cá»§a truy xuáº¥t cho biáº¿t thÃ´ng bÃ¡o lá»—i cuá»‘i cÃ¹ng vÃ  cung cáº¥p tÃªn cá»§a ngoáº¡i lá»‡ Ä‘Ã£ Ä‘Æ°á»£c nÃªu ra. Trong trÆ°á»ng há»£p nÃ y, loáº¡i ngoáº¡i lá»‡ lÃ  `OSError`, cho biáº¿t lá»—i liÃªn quan Ä‘áº¿n há»‡ thá»‘ng. Náº¿u chÃºng ta Ä‘á»c thÃ´ng bÃ¡o lá»—i kÃ¨m theo, chÃºng ta cÃ³ thá»ƒ tháº¥y ráº±ng dÆ°á»ng nhÆ° cÃ³ sá»± cá»‘ vá»›i tá»‡p *config.json* cá»§a mÃ´ hÃ¬nh vÃ  ta sáº½ Ä‘Æ°a ra hai Ä‘á» xuáº¥t Ä‘á»ƒ kháº¯c phá»¥c:

```python out
"""
Make sure that:

- 'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28' is a correct model identifier listed on 'https://huggingface.co/models'

- or 'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28' is the correct path to a directory containing a config.json file
"""
```

<Tip>

ğŸ’¡ Náº¿u báº¡n gáº·p pháº£i thÃ´ng bÃ¡o lá»—i khÃ³ hiá»ƒu, chá»‰ cáº§n sao chÃ©p vÃ  dÃ¡n thÃ´ng bÃ¡o Ä‘Ã³ vÃ o thanh tÃ¬m kiáº¿m Google hoáº·c [Stack Overflow](https://stackoverflow.com/) (vÃ¢ng, thá»±c sá»±!). CÃ³ nhiá»u kháº£ nÄƒng báº¡n khÃ´ng pháº£i lÃ  ngÆ°á»i Ä‘áº§u tiÃªn gáº·p pháº£i lá»—i vÃ  Ä‘Ã¢y lÃ  má»™t cÃ¡ch tá»‘t Ä‘á»ƒ tÃ¬m giáº£i phÃ¡p mÃ  nhá»¯ng ngÆ°á»i khÃ¡c trong cá»™ng Ä‘á»“ng Ä‘Ã£ Ä‘Äƒng. VÃ­ dá»¥: tÃ¬m kiáº¿m `OSError: Can't load config for` trÃªn Stack Overflow mang láº¡i nhiá»u [láº§n truy cáº­p](https://stackoverflow.com/search?q=OSError%3A+Can%27t+load+config+for+) cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng nhÆ° má»™t Ä‘iá»ƒm khá»Ÿi Ä‘áº§u Ä‘á»ƒ giáº£i quyáº¿t váº¥n Ä‘á».

</Tip>

Äá» xuáº¥t Ä‘áº§u tiÃªn lÃ  yÃªu cáº§u ta kiá»ƒm tra xem ID mÃ´ hÃ¬nh cÃ³ thá»±c sá»± chÃ­nh xÃ¡c hay khÃ´ng, vÃ¬ váº­y, viá»‡c Ä‘áº§u tiÃªn ta lÃ m lÃ  sao chÃ©p chá»‰ sá»‘ nháº­n dáº¡ng vÃ  dÃ¡n nÃ³ vÃ o thanh tÃ¬m kiáº¿m cá»§a Hub:

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter8/wrong-model-id.png" alt="The wrong model name." width="100%"/>
</div>

Ráº¥t tiáº¿c, cÃ³ váº» nhÆ° mÃ´ hÃ¬nh cá»§a anh Ä‘á»“ng nghiá»‡p khÃ´ng cÃ³ trÃªn Hub ... aha, nhÆ°ng cÃ³ má»™t lá»—i Ä‘Ã¡nh mÃ¡y trong tÃªn cá»§a mÃ´ hÃ¬nh! DistilBERT chá»‰ cÃ³ má»™t chá»¯ "l" trong tÃªn cá»§a nÃ³, vÃ¬ váº­y hÃ£y sá»­a lá»—i Ä‘Ã³ vÃ  tÃ¬m "lewtun/distilbert-base-unsased-finetuned-Squad-d5716d28" thay tháº¿:

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter8/true-model-id.png" alt="The right model name." width="100%"/>
</div>

ÄÆ°á»£c rá»“i, Ä‘iá»u nÃ y Ä‘Ã£ thÃ nh cÃ´ng. BÃ¢y giá», hÃ£y thá»­ táº£i xuá»‘ng mÃ´ hÃ¬nh má»™t láº§n ná»¯a vá»›i Ä‘Ãºng ID mÃ´ hÃ¬nh:

```python
model_checkpoint = get_full_repo_name("distilbert-base-uncased-finetuned-squad-d5716d28")
reader = pipeline("question-answering", model=model_checkpoint)
```

```python out
"""
OSError: Can't load config for 'lewtun/distilbert-base-uncased-finetuned-squad-d5716d28'. Make sure that:

- 'lewtun/distilbert-base-uncased-finetuned-squad-d5716d28' is a correct model identifier listed on 'https://huggingface.co/models'

- or 'lewtun/distilbert-base-uncased-finetuned-squad-d5716d28' is the correct path to a directory containing a config.json file
"""
```

Argh, láº¡i tháº¥t báº¡i - chÃ o má»«ng báº¡n Ä‘áº¿n vá»›i cuá»™c sá»‘ng hÃ ng ngÃ y cá»§a má»™t ká»¹ sÆ° há»c mÃ¡y! VÃ¬ chÃºng ta Ä‘Ã£ sá»­a ID mÃ´ hÃ¬nh, váº¥n Ä‘á» pháº£i náº±m á»Ÿ chÃ­nh kho lÆ°u trá»¯. Má»™t cÃ¡ch nhanh chÃ³ng Ä‘á»ƒ truy cáº­p ná»™i dung cá»§a má»™t kho lÆ°u trá»¯ trÃªn ğŸ¤— Hub lÃ  thÃ´ng qua hÃ m `list_repo_files()` cá»§a thÆ° viá»‡n `huggingface_hub`:

```python
from huggingface_hub import list_repo_files

list_repo_files(repo_id=model_checkpoint)
```

```python out
['.gitattributes', 'README.md', 'pytorch_model.bin', 'special_tokens_map.json', 'tokenizer_config.json', 'training_args.bin', 'vocab.txt']
```

Tháº­t thÃº vá»‹ - dÆ°á»ng nhÆ° khÃ´ng cÃ³ tá»‡p *config.json* trong kho lÆ°u trá»¯! KhÃ´ng cÃ³ gÃ¬ ngáº¡c nhiÃªn khi `pipeline` khÃ´ng thá»ƒ táº£i mÃ´ hÃ¬nh; Ä‘á»“ng nghiá»‡p cá»§a chÃºng ta cháº¯c háº³n Ä‘Ã£ quÃªn Ä‘áº©y tá»‡p nÃ y vÃ o Hub sau khi Ä‘Ã£ tinh chá»‰nh nÃ³. Trong trÆ°á»ng há»£p nÃ y, váº¥n Ä‘á» cÃ³ váº» khÃ¡ Ä‘Æ¡n giáº£n Ä‘á»ƒ kháº¯c phá»¥c: chÃºng ta cÃ³ thá»ƒ yÃªu cáº§u há» thÃªm tá»‡p hoáº·c, vÃ¬ chÃºng ta cÃ³ thá»ƒ tháº¥y tá»« ID mÃ´ hÃ¬nh mÃ  mÃ´ hÃ¬nh huáº¥n luyá»‡n trÆ°á»›c Ä‘Ã£ sá»­ dá»¥ng lÃ  [`distilbert-base-uncased`](https://huggingface.co/distilbert-base-uncased), chÃºng ta cÃ³ thá»ƒ táº£i xuá»‘ng cáº¥u hÃ¬nh cho mÃ´ hÃ¬nh nÃ y vÃ  Ä‘áº©y nÃ³ vÃ o kho lÆ°u trá»¯ cá»§a mÃ¬nh Ä‘á»ƒ xem liá»‡u Ä‘iá»u Ä‘Ã³ cÃ³ giáº£i quyáº¿t Ä‘Æ°á»£c sá»± cá»‘ hay khÃ´ng. HÃ£y thá»­ Ä‘iá»u Ä‘Ã³. Sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t chÃºng ta Ä‘Ã£ há»c trong [ChÆ°Æ¡ng 2](/course/chapter2), chÃºng ta cÃ³ thá»ƒ táº£i xuá»‘ng cáº¥u hÃ¬nh cá»§a mÃ´ hÃ¬nh vá»›i lá»›p `AutoConfig`:

```python
from transformers import AutoConfig

pretrained_checkpoint = "distilbert-base-uncased"
config = AutoConfig.from_pretrained(pretrained_checkpoint)
```

<Tip warning={true}>

ğŸš¨ CÃ¡ch tiáº¿p cáº­n mÃ  chÃºng tÃ´i Ä‘ang thá»±c hiá»‡n á»Ÿ Ä‘Ã¢y khÃ´ng pháº£i lÃ  hoÃ n háº£o, vÃ¬ Ä‘á»“ng nghiá»‡p cá»§a chÃºng ta cÃ³ thá»ƒ Ä‘Ã£ chá»‰nh sá»­a cáº¥u hÃ¬nh cá»§a `distilbert-base-uncased` trÆ°á»›c khi tinh chá»‰nh mÃ´ hÃ¬nh. Trong thá»±c táº¿, chÃºng ta muá»‘n kiá»ƒm tra vá»›i há» trÆ°á»›c, nhÆ°ng vá»›i má»¥c Ä‘Ã­ch cá»§a pháº§n nÃ y, chÃºng ta sáº½ giáº£ Ä‘á»‹nh ráº±ng há» Ä‘Ã£ sá»­ dá»¥ng cáº¥u hÃ¬nh máº·c Ä‘á»‹nh.

</Tip>

Sau Ä‘Ã³, chÃºng ta cÃ³ thá»ƒ Ä‘áº©y nÃ³ vÃ o kho lÆ°u trá»¯ mÃ´ hÃ¬nh cá»§a mÃ¬nh báº±ng hÃ m `push_to_hub()` cá»§a cáº¥u hÃ¬nh:

```python
config.push_to_hub(model_checkpoint, commit_message="Add config.json")
```

BÃ¢y giá» chÃºng ta cÃ³ thá»ƒ kiá»ƒm tra xem Ä‘iá»u nÃ y cÃ³ hoáº¡t Ä‘á»™ng hay khÃ´ng báº±ng cÃ¡ch táº£i mÃ´ hÃ¬nh tá»« cam káº¿t má»›i nháº¥t trÃªn nhÃ¡nh `main`:

```python
reader = pipeline("question-answering", model=model_checkpoint, revision="main")

context = r"""
Extractive Question Answering is the task of extracting an answer from a text
given a question. An example of a question answering dataset is the SQuAD
dataset, which is entirely based on that task. If you would like to fine-tune a
model on a SQuAD task, you may leverage the
examples/pytorch/question-answering/run_squad.py script.

ğŸ¤— Transformers is interoperable with the PyTorch, TensorFlow, and JAX
frameworks, so you can use your favourite tools for a wide variety of tasks!
"""

question = "What is extractive question answering?"
reader(question=question, context=context)
```

```python out
{'score': 0.38669535517692566,
 'start': 34,
 'end': 95,
 'answer': 'the task of extracting an answer from a text given a question'}
```

Tuyá»‡t vá»i, nÃ³ Ä‘Ã£ hoáº¡t Ä‘á»™ng! HÃ£y tÃ³m táº¯t láº¡i nhá»¯ng gÃ¬ báº¡n vá»«a há»c Ä‘Æ°á»£c:

- CÃ¡c thÃ´ng bÃ¡o lá»—i trong Python Ä‘Æ°á»£c gá»i lÃ  _tracebacks_ vÃ  Ä‘Æ°á»£c Ä‘á»c tá»« dÆ°á»›i lÃªn trÃªn. DÃ²ng cuá»‘i cÃ¹ng cá»§a thÃ´ng bÃ¡o lá»—i thÆ°á»ng chá»©a thÃ´ng tin báº¡n cáº§n Ä‘á»ƒ xÃ¡c Ä‘á»‹nh nguá»“n gá»‘c cá»§a váº¥n Ä‘á».
- Náº¿u dÃ²ng cuá»‘i cÃ¹ng khÃ´ng chá»©a Ä‘á»§ thÃ´ng tin, hÃ£y lÃ m theo cÃ¡ch cá»§a báº¡n Ä‘á»ƒ truy xuáº¥t láº¡i vÃ  xem liá»‡u báº¡n cÃ³ thá»ƒ xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c lá»—i xáº£y ra á»Ÿ Ä‘Ã¢u trong mÃ£ nguá»“n hay khÃ´ng.
- Náº¿u khÃ´ng cÃ³ thÃ´ng bÃ¡o lá»—i nÃ o cÃ³ thá»ƒ giÃºp báº¡n gá»¡ lá»—i, hÃ£y thá»­ tÃ¬m kiáº¿m trá»±c tuyáº¿n giáº£i phÃ¡p cho váº¥n Ä‘á» tÆ°Æ¡ng tá»±.
- CÃ¡c thÆ° viá»‡n `huggingface_hub` // ğŸ¤— Hub? cung cáº¥p má»™t bá»™ cÃ´ng cá»¥ mÃ  báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng Ä‘á»ƒ tÆ°Æ¡ng tÃ¡c vÃ  gá»¡ lá»—i cÃ¡c kho lÆ°u trá»¯ trÃªn Hub.

BÃ¢y giá» báº¡n Ä‘Ã£ biáº¿t cÃ¡ch gá»¡ lá»—i má»™t Ä‘Æ°á»ng dáº«n, chÃºng ta hÃ£y xem má»™t vÃ­ dá»¥ phá»©c táº¡p hÆ¡n trong bÆ°á»›c truyá»n tháº³ng cá»§a chÃ­nh mÃ´ hÃ¬nh.

## Gá»¡ lá»—i truyá»n tháº³ng mÃ´ hÃ¬nh cá»§a báº¡n

Máº·c dÃ¹ `pipeline` tuyá»‡t vá»i cho háº§u háº¿t cÃ¡c á»©ng dá»¥ng mÃ  báº¡n cáº§n nhanh chÃ³ng táº¡o dá»± Ä‘oÃ¡n, Ä‘Ã´i khi báº¡n sáº½ cáº§n truy cáº­p nháº­t kÃ½ cá»§a mÃ´ hÃ¬nh (giáº£ sá»­, náº¿u báº¡n cÃ³ má»™t sá»‘ háº­u xá»­ lÃ½ tÃ¹y chá»‰nh mÃ  báº¡n muá»‘n Ã¡p dá»¥ng). Äá»ƒ xem Ä‘iá»u gÃ¬ cÃ³ thá»ƒ sai trong trÆ°á»ng há»£p nÃ y, trÆ°á»›c tiÃªn hÃ£y láº¥y mÃ´ hÃ¬nh vÃ  trÃ¬nh tokenize tá»« `pipeline` cá»§a mÃ¬nh:

```python
tokenizer = reader.tokenizer
model = reader.model
```

Tiáº¿p theo, chÃºng ta cáº§n má»™t cÃ¢u há»i, vÃ¬ váº­y hÃ£y xem liá»‡u cÃ¡c khung yÃªu thÃ­ch cá»§a chÃºng ta cÃ³ Ä‘Æ°á»£c há»— trá»£ khÃ´ng:

```python
question = "Which frameworks can I use?"
```

NhÆ° Ä‘Ã£ tháº¥y trong [ChÆ°Æ¡ng 7](/course/chapter7), cÃ¡c bÆ°á»›c thÃ´ng thÆ°á»ng ta cáº§n lÃ m Ä‘Ã³ lÃ  tokenize Ä‘áº§u vÃ o, trÃ­ch xuáº¥t cÃ¡c logit cá»§a token báº¯t Ä‘áº§u vÃ  káº¿t thÃºc, rá»“i sau Ä‘Ã³ giáº£i mÃ£ cÃ¡c khoáº£ng tráº£ lá»i: 

```python
import torch

inputs = tokenizer(question, context, add_special_tokens=True)
input_ids = inputs["input_ids"][0]
outputs = model(**inputs)
answer_start_scores = outputs.start_logits
answer_end_scores = outputs.end_logits
# Láº¥y pháº§n cÃ³ kháº£ nÄƒng lÃ  báº¯t Ä‘áº§u cá»§a cÃ¢u tráº£ lá»i nháº¥t vá»›i argmax cá»§a Ä‘iá»ƒm tráº£ vá»
answer_start = torch.argmax(answer_start_scores)
# Láº¥y pháº§n cÃ³ kháº£ nÄƒng lÃ  káº¿t thÃºc cá»§a cÃ¢u tráº£ lá»i nháº¥t vá»›i argmax cá»§a Ä‘iá»ƒm tráº£ vá»
answer_end = torch.argmax(answer_end_scores) + 1
answer = tokenizer.convert_tokens_to_string(
    tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end])
)
print(f"Question: {question}")
print(f"Answer: {answer}")
```

```python out
"""
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
/var/folders/28/k4cy5q7s2hs92xq7_h89_vgm0000gn/T/ipykernel_75743/2725838073.py in <module>
      1 inputs = tokenizer(question, text, add_special_tokens=True)
      2 input_ids = inputs["input_ids"]
----> 3 outputs = model(**inputs)
      4 answer_start_scores = outputs.start_logits
      5 answer_end_scores = outputs.end_logits

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)
   1049         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
   1050                 or _global_forward_hooks or _global_forward_pre_hooks):
-> 1051             return forward_call(*input, **kwargs)
   1052         # Do not call functions when jit is used
   1053         full_backward_hooks, non_full_backward_hooks = [], []

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py in forward(self, input_ids, attention_mask, head_mask, inputs_embeds, start_positions, end_positions, output_attentions, output_hidden_states, return_dict)
    723         return_dict = return_dict if return_dict is not None else self.config.use_return_dict
    724
--> 725         distilbert_output = self.distilbert(
    726             input_ids=input_ids,
    727             attention_mask=attention_mask,

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)
   1049         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
   1050                 or _global_forward_hooks or _global_forward_pre_hooks):
-> 1051             return forward_call(*input, **kwargs)
   1052         # Do not call functions when jit is used
   1053         full_backward_hooks, non_full_backward_hooks = [], []

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py in forward(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)
    471             raise ValueError("You cannot specify both input_ids and inputs_embeds at the same time")
    472         elif input_ids is not None:
--> 473             input_shape = input_ids.size()
    474         elif inputs_embeds is not None:
    475             input_shape = inputs_embeds.size()[:-1]

AttributeError: 'list' object has no attribute 'size'
"""
```

Ã”i trá»i, cÃ³ váº» nhÆ° chÃºng ta cÃ³ má»™t lá»—i trong Ä‘oáº¡n mÃ£ cá»§a mÃ¬nh! NhÆ°ng chÃºng ta khÃ´ng sá»£ gá»¡ lá»—i chÃºt nÃ o. Báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng trÃ¬nh gá»¡ lá»—i Python trong notebook:

<Youtube id="rSPyvPw0p9k"/>

hoáº·c trong terminal:

<Youtube id="5PkZ4rbHL6c"/>

á» Ä‘Ã¢y, khi Ä‘á»c thÃ´ng bÃ¡o lá»—i cho chÃºng ta biáº¿t ráº±ng Ä‘á»‘i tÆ°á»£ng `'list' object has no attribute 'size'` vÃ  chÃºng ta cÃ³ thá»ƒ tháº¥y má»™t mÅ©i tÃªn `-->` trá» Ä‘áº¿n dÃ²ng nÆ¡i váº¥n Ä‘á» Ä‘Ã£ Ä‘Æ°á»£c nÃªu ra trong `model(** input)`. Báº¡n cÃ³ thá»ƒ gá»¡ lá»—i Ä‘iá»u nÃ y má»™t cÃ¡ch tÆ°Æ¡ng tá»± báº±ng cÃ¡ch sá»­ dá»¥ng trÃ¬nh gá»¡ lá»—i Python, nhÆ°ng bÃ¢y giá» chÃºng ta chá»‰ cáº§n in ra má»™t pháº§n cá»§a `inputs` Ä‘á»ƒ xem nhá»¯ng gÃ¬ chÃºng ta cÃ³:

Here, reading the error message tells us that `'list' object has no attribute 'size'`, and we can see a `-->` arrow pointing to the line where the problem was raised in `model(**inputs)`.You can debug this interactively using the Python debugger, but for now we'll simply print out a slice of `inputs` to see what we have:

```python
inputs["input_ids"][:5]
```

```python out
[101, 2029, 7705, 2015, 2064]
```

Äiá»u nÃ y cháº¯c cháº¯n trÃ´ng giá»‘ng nhÆ° má»™t `list` Python bÃ¬nh thÆ°á»ng, nhÆ°ng hÃ£y kiá»ƒm tra ká»¹ loáº¡i:

```python
type(inputs["input_ids"])
```

```python out
list
```

VÃ¢ng, Ä‘Ã³ cháº¯c cháº¯n lÃ  má»™t `list` Python. Váº­y Ä‘iá»u gÃ¬ Ä‘Ã£ xáº£y ra? Nhá»› láº¡i tá»« [ChÆ°Æ¡ng 2](/course/chapter2) ráº±ng cÃ¡c lá»›p `AutoModelForXxx` trong ğŸ¤— Transformers hoáº¡t Ä‘á»™ng trÃªn _tensors_ (trong PyTorch hoáº·c TensorFlow) vÃ  hoáº¡t Ä‘á»™ng phá»• biáº¿n lÃ  trÃ­ch xuáº¥t cÃ¡c kÃ­ch thÆ°á»›c cá»§a tensor báº±ng cÃ¡ch sá»­ dá»¥ng `Tensor.size()` trong PyTorch. ChÃºng ta hÃ£y xem xÃ©t láº¡i quÃ¡ trÃ¬nh truy váº¿t, Ä‘á»ƒ xem dÃ²ng nÃ o Ä‘Ã£ kÃ­ch hoáº¡t ngoáº¡i lá»‡:

```
~/miniconda3/envs/huggingface/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py in forward(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)
    471             raise ValueError("You cannot specify both input_ids and inputs_embeds at the same time")
    472         elif input_ids is not None:
--> 473             input_shape = input_ids.size()
    474         elif inputs_embeds is not None:
    475             input_shape = inputs_embeds.size()[:-1]

AttributeError: 'list' object has no attribute 'size'
```

CÃ³ váº» nhÆ° mÃ£ cá»§a chÃºng ta Ä‘Ã£ cá»‘ gáº¯ng gá»i `input_ids.size()`, nhÆ°ng Ä‘iá»u nÃ y rÃµ rÃ ng sáº½ khÃ´ng hoáº¡t Ä‘á»™ng Ä‘á»‘i vá»›i má»™t `list` Python, vá»‘n chá»‰ lÃ  má»™t vÃ¹ng chá»©a. LÃ m tháº¿ nÃ o chÃºng ta cÃ³ thá»ƒ giáº£i quyáº¿t váº¥n Ä‘á» nÃ y? TÃ¬m kiáº¿m thÃ´ng bÃ¡o lá»—i trÃªn Stack Overflow Ä‘Æ°a ra má»™t sá»‘ [lÆ°á»£t truy cáº­p](https://stackoverflow.com/search?q=AttributeError%3A+%27list%27+object+has+no+attribute+%27size%27&s=c15ec54c-63cb-481d-a749-408920073e8f) liÃªn quan. Nháº¥p vÃ o cÃ¢u há»i Ä‘áº§u tiÃªn sáº½ hiá»ƒn thá»‹ má»™t cÃ¢u há»i tÆ°Æ¡ng tá»± nhÆ° cÃ¢u há»i cá»§a chÃºng ta, vá»›i cÃ¢u tráº£ lá»i Ä‘Æ°á»£c hiá»ƒn thá»‹ trong áº£nh chá»¥p mÃ n hÃ¬nh bÃªn dÆ°á»›i:

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter8/stack-overflow.png" alt="An answer from Stack Overflow." width="100%"/>
</div>

CÃ¢u tráº£ lá»i khuyÃªn chÃºng ta nÃªn thÃªm `return_tensors='pt'` vÃ o tokenizer, vÃ¬ váº­y hÃ£y xem Ä‘iá»u Ä‘Ã³ cÃ³ phÃ¹ há»£p vá»›i chÃºng ta khÃ´ng:

```python out
inputs = tokenizer(question, context, add_special_tokens=True, return_tensors="pt")
input_ids = inputs["input_ids"][0]
outputs = model(**inputs)
answer_start_scores = outputs.start_logits
answer_end_scores = outputs.end_logits
# Láº¥y pháº§n cÃ³ kháº£ nÄƒng lÃ  báº¯t Ä‘áº§u cá»§a cÃ¢u tráº£ lá»i nháº¥t vá»›i argmax cá»§a Ä‘iá»ƒm tráº£ vá» 
answer_start = torch.argmax(answer_start_scores)
# Láº¥y pháº§n cÃ³ kháº£ nÄƒng lÃ  káº¿t thÃºc cá»§a cÃ¢u tráº£ lá»i nháº¥t vá»›i argmax cá»§a Ä‘iá»ƒm tráº£ vá» 
answer_end = torch.argmax(answer_end_scores) + 1
answer = tokenizer.convert_tokens_to_string(
    tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end])
)
print(f"Question: {question}")
print(f"Answer: {answer}")
```

```python out
"""
Question: Which frameworks can I use?
Answer: pytorch, tensorflow, and jax
"""
```

Tá»‘t, nÃ³ Ä‘Ã£ hoáº¡t Ä‘á»™ng! ÄÃ¢y lÃ  má»™t vÃ­ dá»¥ tuyá»‡t vá»i vá» má»©c Ä‘á»™ há»¯u Ã­ch cá»§a Stack Overflow: báº±ng cÃ¡ch xÃ¡c Ä‘á»‹nh má»™t váº¥n Ä‘á» tÆ°Æ¡ng tá»±, chÃºng ta cÃ³ thá»ƒ hÆ°á»Ÿng lá»£i tá»« kinh nghiá»‡m cá»§a nhá»¯ng ngÆ°á»i khÃ¡c trong cá»™ng Ä‘á»“ng. Tuy nhiÃªn, má»™t tÃ¬m kiáº¿m nhÆ° tháº¿ nÃ y khÃ´ng pháº£i lÃºc nÃ o cÅ©ng mang láº¡i cÃ¢u tráº£ lá»i phÃ¹ há»£p, váº­y báº¡n cÃ³ thá»ƒ lÃ m gÃ¬ trong nhá»¯ng trÆ°á»ng há»£p nhÆ° váº­y? May máº¯n thay, cÃ³ má»™t cá»™ng Ä‘á»“ng cÃ¡c nhÃ  phÃ¡t triá»ƒn chÃ o Ä‘Ã³n trÃªn [diá»…n Ä‘Ã n Hugging Face](https://discuss.huggingface.co/) cÃ³ thá»ƒ giÃºp báº¡n! Trong pháº§n tiáº¿p theo, chÃºng ta sáº½ xem xÃ©t cÃ¡ch báº¡n cÃ³ thá»ƒ táº¡o ra cÃ¡c cÃ¢u há»i tá»‘t trÃªn diá»…n Ä‘Ã n cÃ³ kháº£ nÄƒng Ä‘Æ°á»£c tráº£ lá»i.
