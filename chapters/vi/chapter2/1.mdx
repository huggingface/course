# Giá»›i thiá»‡u

<CourseFloatingBanner
    chapter={2}
    classNames="absolute z-10 right-0 top-0"
/>

NhÆ° báº¡n Ä‘Ã£ tháº¥y trong [ChÆ°Æ¡ng 1](/course/chapter1), cÃ¡c mÃ´ hÃ¬nh Transformer thÆ°á»ng ráº¥t lá»›n. Vá»›i hÃ ng triá»‡u Ä‘áº¿n hÃ ng chá»¥c *tá»·* thÃ´ng sá»‘, viá»‡c huáº¥n luyá»‡n vÃ  triá»ƒn khai cÃ¡c mÃ´ hÃ¬nh nÃ y lÃ  má»™t cÃ´ng viá»‡c phá»©c táº¡p. HÆ¡n ná»¯a, vá»›i viá»‡c cÃ¡c mÃ´ hÃ¬nh má»›i Ä‘Æ°á»£c phÃ¡t hÃ nh gáº§n nhÆ° hÃ ng ngÃ y vÃ  má»—i mÃ´ hÃ¬nh cÃ³ cÃ¡ch triá»ƒn khai riÃªng, viá»‡c thá»­ táº¥t cáº£ chÃºng khÃ´ng pháº£i lÃ  nhiá»‡m vá»¥ dá»… dÃ ng.

ThÆ° viá»‡n ğŸ¤— Transformers Ä‘Æ°á»£c táº¡o ra Ä‘á»ƒ giáº£i quyáº¿t váº¥n Ä‘á» nÃ y. Má»¥c tiÃªu cá»§a nÃ³ lÃ  cung cáº¥p má»™t API duy nháº¥t mÃ  qua Ä‘Ã³ báº¥t ká»³ mÃ´ hÃ¬nh Transformer nÃ o cÅ©ng cÃ³ thá»ƒ Ä‘Æ°á»£c táº£i, huáº¥n luyá»‡n, vÃ  lÆ°u. CÃ¡c tÃ­nh nÄƒng chÃ­nh cá»§a thÆ° viá»‡n gá»“m:

- **TÃ­nh dá»… sá»­ dá»¥ng**: Viá»‡c táº£i xuá»‘ng, táº£i vÃ  sá»­ dá»¥ng mÃ´ hÃ¬nh NLP tá»‘i tÃ¢n Ä‘á»ƒ luáº­n suy cÃ³ thá»ƒ Ä‘Æ°á»£c thá»±c hiá»‡n chá»‰ trong hai dÃ²ng mÃ£.
- **TÃ­nh linh hoáº¡t**: Vá» cá»‘t lÃµi, táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh Ä‘á»u lÃ  cÃ¡c lá»›p PyTorch `nn.Module` hoáº·c TensorFlow` tf.keras.Model` Ä‘Æ¡n giáº£n vÃ  cÃ³ thá»ƒ Ä‘Æ°á»£c xá»­ lÃ½ giá»‘ng nhÆ° báº¥t ká»³ mÃ´ hÃ¬nh nÃ o khÃ¡c trong khuÃ´n khá»• há»c mÃ¡y (ML) tÆ°Æ¡ng á»©ng cá»§a chÃºng.
- **TÃ­nh Ä‘Æ¡n giáº£n**: Háº§u nhÆ° khÃ´ng cÃ³ báº¥t ká»³ sá»± trá»«u tÆ°á»£ng nÃ o Ä‘Æ°á»£c thá»±c hiá»‡n trÃªn toÃ n bá»™ thÆ° viá»‡n. "All in one file" ("Táº¥t cáº£ trong má»™t tá»‡p") lÃ  khÃ¡i niá»‡m cá»‘t lÃµi: bÆ°á»›c lan truyá»n tháº³ng cá»§a má»™t mÃ´ hÃ¬nh Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh hoÃ n toÃ n trong má»™t tá»‡p duy nháº¥t giÃºp báº£n thÃ¢n Ä‘oáº¡n mÃ£ dá»… hiá»ƒu vÃ  cÃ³ thá»ƒ hack Ä‘Æ°á»£c.

TÃ­nh nÄƒng cuá»‘i cÃ¹ng nÃ y lÃ m cho ğŸ¤— Transformers khÃ¡ khÃ¡c biá»‡t so vá»›i cÃ¡c thÆ° viá»‡n ML khÃ¡c. CÃ¡c mÃ´ hÃ¬nh khÃ´ng Ä‘Æ°á»£c xÃ¢y dá»±ng trÃªn cÃ¡c mÃ´-Ä‘un Ä‘Æ°á»£c chia sáº» trÃªn cÃ¡c tá»‡p; thay vÃ o Ä‘Ã³, má»—i mÃ´ hÃ¬nh cÃ³ cÃ¡c lá»›p riÃªng cá»§a nÃ³. NgoÃ i viá»‡c lÃ m cho cÃ¡c mÃ´ hÃ¬nh dá»… tiáº¿p cáº­n vÃ  dá»… hiá»ƒu hÆ¡n, Ä‘iá»u nÃ y cho phÃ©p báº¡n dá»… dÃ ng thá»­ nghiá»‡m trÃªn má»™t mÃ´ hÃ¬nh mÃ  khÃ´ng áº£nh hÆ°á»Ÿng Ä‘áº¿n cÃ¡c mÃ´ hÃ¬nh khÃ¡c.

ChÆ°Æ¡ng nÃ y sáº½ báº¯t Ä‘áº§u vá»›i má»™t vÃ­ dá»¥ tá»« Ä‘áº§u Ä‘áº¿n cuá»‘i, trong Ä‘Ã³ chÃºng ta sá»­ dá»¥ng má»™t mÃ´ hÃ¬nh vÃ  má»™t tokenizer cÃ¹ng nhau Ä‘á»ƒ sao chÃ©p hÃ m `pipeline()` Ä‘Æ°á»£c giá»›i thiá»‡u trong [Chapter 1](/course/chapter1). Tiáº¿p theo, chÃºng ta sáº½ tháº£o luáº­n vá» API mÃ´ hÃ¬nh: chÃºng ta sáº½ Ä‘i sÃ¢u vÃ o cÃ¡c lá»›p cáº¥u hÃ¬nh vÃ  mÃ´ hÃ¬nh, Ä‘á»“ng thá»i chá»‰ cho báº¡n cÃ¡ch táº£i má»™t mÃ´ hÃ¬nh vÃ  cÃ¡ch nÃ³ xá»­ lÃ½ cÃ¡c Ä‘áº§u vÃ o dáº¡ng sá»‘ Ä‘á»ƒ Ä‘Æ°a ra cÃ¡c dá»± Ä‘oÃ¡n Ä‘áº§u ra.

Sau Ä‘Ã³, chÃºng ta sáº½ xem xÃ©t API tokenizer, má»™t thÃ nh pháº§n chÃ­nh khÃ¡c cá»§a hÃ m `pipeline()`. Tokenizers thá»±c hiá»‡n cÃ¡c bÆ°á»›c xá»­ lÃ½ Ä‘áº§u tiÃªn vÃ  cuá»‘i cÃ¹ng, xá»­ lÃ½ viá»‡c chuyá»ƒn Ä‘á»•i tá»« vÄƒn báº£n Ä‘áº§u vÃ o thÃ nh dáº¡ng sá»‘ cho máº¡ng nÆ¡-ron vÃ  chuyá»ƒn Ä‘á»•i trá»Ÿ láº¡i vÄƒn báº£n khi cáº§n. Cuá»‘i cÃ¹ng, chÃºng tÃ´i sáº½ chá»‰ cho báº¡n cÃ¡ch xá»­ lÃ½ viá»‡c gá»­i nhiá»u cÃ¢u vÃ o má»™t mÃ´ hÃ¬nh trong má»™t batch (lÃ´) Ä‘Ã£ chuáº©n bá»‹, sau Ä‘Ã³ tÃ³m táº¯t táº¥t cáº£ báº±ng cÃ¡ch xem xÃ©t ká»¹ hÆ¡n hÃ m `tokenizer()` á»Ÿ báº­c cao.

<Tip>
âš ï¸ Äá»ƒ cÃ³ thá»ƒ táº­n dá»¥ng táº¥t cáº£ cÃ¡c tÃ­nh nÄƒng cÃ³ sáºµn vá»›i Model Hub vÃ  ğŸ¤— Transformers, chÃºng tÃ´i khuyáº¿n khÃ­ch báº¡n <a href="https://huggingface.co/join">táº¡o tÃ i khoáº£n </a>.
</Tip>
