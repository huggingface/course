# Sáº¯p xáº¿p dá»¯ liá»‡u

<CourseFloatingBanner chapter={5}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/vi/chapter5/section3.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/vi/chapter5/section3.ipynb"},
]} />

Háº§u háº¿t thá»i gian, dá»¯ liá»‡u báº¡n lÃ m viá»‡c sáº½ chÆ°a Ä‘Æ°á»£c chuáº©n bá»‹ hoÃ n háº£o cho cÃ¡c mÃ´ hÃ¬nh huáº¥n luyá»‡n. Trong pháº§n nÃ y, chÃºng ta sáº½ khÃ¡m phÃ¡ cÃ¡c tÃ­nh nÄƒng khÃ¡c nhau mÃ  ğŸ¤— Datasets cung cáº¥p Ä‘á»ƒ lÃ m sáº¡ch cÃ¡c táº­p dá»¯ liá»‡u cá»§a báº¡n.

<Youtube id="tqfSFcPMgOI"/>

## Sáº¯p xáº¿p dá»¯ liá»‡u cá»§a chÃºng ta

TÆ°Æ¡ng tá»± nhÆ° Pandas, ğŸ¤— Datasets cung cáº¥p má»™t sá»‘ tÃ­nh nÄƒng Ä‘á»ƒ thao tÃºng ná»™i dung cá»§a `Dataset` vÃ  `DatasetDict`. ChÃºng ta Ä‘Ã£ gáº·p phÆ°Æ¡ng thá»©c `Dataset.map()` trong [ChÆ°Æ¡ng 3](/course/chapter3) vÃ  trong pháº§n nÃ y, chÃºng ta sáº½ khÃ¡m phÃ¡ má»™t sá»‘ hÃ m khÃ¡c theo Ã½ cá»§a chÃºng ta.

Äá»‘i vá»›i vÃ­ dá»¥ nÃ y, chÃºng tÃ´i sáº½ sá»­ dá»¥ng [Bá»™ dá»¯ liá»‡u Ä‘Ã¡nh giÃ¡ thuá»‘c](https://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+%28Drugs.com%29) Ä‘Æ°á»£c lÆ°u trá»¯ trÃªn [Kho lÆ°u trá»¯ Há»c mÃ¡y UC Irvine](https://archive.ics.uci.edu/ml/index.php), chá»©a cÃ¡c Ä‘Ã¡nh giÃ¡ cá»§a bá»‡nh nhÃ¢n vá» cÃ¡c loáº¡i thuá»‘c khÃ¡c nhau, cÃ¹ng vá»›i tÃ¬nh tráº¡ng Ä‘ang Ä‘Æ°á»£c Ä‘iá»u trá»‹ vÃ  xáº¿p háº¡ng 10 sao vá» má»©c Ä‘á»™ hÃ i lÃ²ng cá»§a bá»‡nh nhÃ¢n.

TrÆ°á»›c tiÃªn, chÃºng ta cáº§n táº£i xuá»‘ng vÃ  giáº£i nÃ©n dá»¯ liá»‡u, cÃ³ thá»ƒ thá»±c hiá»‡n báº±ng lá»‡nh `wget` vÃ   `unzip`:

```py
!wget "https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip"
!unzip drugsCom_raw.zip
```

VÃ¬ TSV chá»‰ lÃ  má»™t biáº¿n thá»ƒ cá»§a CSV sá»­ dá»¥ng dáº¥u tab thay vÃ¬ dáº¥u pháº©y lÃ m dáº¥u phÃ¢n cÃ¡ch, chÃºng ta cÃ³ thá»ƒ táº£i cÃ¡c tá»‡p nÃ y báº±ng cÃ¡ch sá»­ dá»¥ng táº­p lá»‡nh táº£i `csv` vÃ  chá»‰ Ä‘á»‹nh Ä‘á»‘i sá»‘ `delimiter` trong hÃ m `load_dataset()` nhÆ° sau:

```py
from datasets import load_dataset

data_files = {"train": "drugsComTrain_raw.tsv", "test": "drugsComTest_raw.tsv"}
# \t is the tab character in Python
drug_dataset = load_dataset("csv", data_files=data_files, delimiter="\t")
```

Má»™t thá»±c tiá»…n khi thá»±c hiá»‡n báº¥t ká»³ loáº¡i phÃ¢n tÃ­ch dá»¯ liá»‡u nÃ o lÃ  láº¥y má»™t máº«u ngáº«u nhiÃªn nhá» Ä‘á»ƒ cÃ³ thá»ƒ cáº£m nháº­n nhanh vá» loáº¡i dá»¯ liá»‡u báº¡n Ä‘ang lÃ m viá»‡c. Trong ğŸ¤— Datasets, chÃºng ta cÃ³ thá»ƒ táº¡o má»™t máº«u ngáº«u nhiÃªn báº±ng cÃ¡ch xÃ¢u chuá»—i cÃ¡c hÃ m `Dataset.shuffle()` vÃ  `Dataset.select()` vá»›i nhau:

```py
drug_sample = drug_dataset["train"].shuffle(seed=42).select(range(1000))
# Xem qua má»™t sá»‘ vÃ­ dá»¥ Ä‘áº§u tiÃªn
drug_sample[:3]
```

```python out
{'Unnamed: 0': [87571, 178045, 80482],
 'drugName': ['Naproxen', 'Duloxetine', 'Mobic'],
 'condition': ['Gout, Acute', 'ibromyalgia', 'Inflammatory Conditions'],
 'review': ['"like the previous person mention, I&#039;m a strong believer of aleve, it works faster for my gout than the prescription meds I take. No more going to the doctor for refills.....Aleve works!"',
  '"I have taken Cymbalta for about a year and a half for fibromyalgia pain. It is great\r\nas a pain reducer and an anti-depressant, however, the side effects outweighed \r\nany benefit I got from it. I had trouble with restlessness, being tired constantly,\r\ndizziness, dry mouth, numbness and tingling in my feet, and horrible sweating. I am\r\nbeing weaned off of it now. Went from 60 mg to 30mg and now to 15 mg. I will be\r\noff completely in about a week. The fibro pain is coming back, but I would rather deal with it than the side effects."',
  '"I have been taking Mobic for over a year with no side effects other than an elevated blood pressure.  I had severe knee and ankle pain which completely went away after taking Mobic.  I attempted to stop the medication however pain returned after a few days."'],
 'rating': [9.0, 3.0, 10.0],
 'date': ['September 2, 2015', 'November 7, 2011', 'June 5, 2013'],
 'usefulCount': [36, 13, 128]}
```

LÆ°u Ã½ ráº±ng chÃºng ta Ä‘Ã£ sá»­a seed trong `Dataset.shuffle()` cho má»¥c Ä‘Ã­ch tÃ¡i táº¡o.  `Dataset.select()` mong Ä‘á»£i má»™t chá»‰ sá»‘ cÃ³ thá»ƒ láº·p láº¡i, vÃ¬ váº­y chÃºng ta truyá»n vÃ o khoáº£ng `range(1000)` Ä‘á»ƒ láº¥y 1,000 máº«u Ä‘áº§u tiÃªn tá»« táº­p dá»¯ liá»‡u Ä‘Ã£ xÃ¡o trá»™n. Tá»« máº«u nÃ y, ta Ä‘Ã£ cÃ³ thá»ƒ tháº¥y má»™t sá»‘ Ä‘iá»u ká»³ quáº·c trong táº­p dá»¯ liá»‡u:

* Cá»™t `Unnamed: 0`  trÃ´ng Ä‘Ã¡ng ngá» giá»‘ng nhÆ° má»™t ID áº©n danh cho má»—i bá»‡nh nhÃ¢n.
* Cá»™t `condition` bao gá»“m sá»± káº¿t há»£p giá»¯a cÃ¡c nhÃ£n chá»¯ hoa vÃ  chá»¯ thÆ°á»ng.
* CÃ¡c bÃ i Ä‘Ã¡nh giÃ¡ cÃ³ Ä‘á»™ dÃ i khÃ¡c nhau vÃ  chá»©a há»—n há»£p cÃ¡c dáº¥u phÃ¢n tÃ¡ch dÃ²ng Python (`\r\n`) cÅ©ng nhÆ° cÃ¡c mÃ£ kÃ½ tá»± HTML nhÆ° `&\#039;`.

HÃ£y xem cÃ¡ch chÃºng ta cÃ³ thá»ƒ sá»­ dá»¥ng ğŸ¤— Datasets Ä‘á»ƒ giáº£i quyáº¿t tá»«ng váº¥n Ä‘á» nÃ y. Äá»ƒ kiá»ƒm tra giáº£ thuyáº¿t ID bá»‡nh nhÃ¢n cho cá»™t `Unnamed: 0`, ta cÃ³ thá»ƒ sá»­ dá»¥ng hÃ m  `Dataset.unique()` Ä‘á»ƒ xÃ¡c minh ráº±ng sá»‘ lÆ°á»£ng ID khá»›p vá»›i sá»‘ hÃ ng trong má»—i láº§n tÃ¡ch:

```py
for split in drug_dataset.keys():
    assert len(drug_dataset[split]) == len(drug_dataset[split].unique("Unnamed: 0"))
```
Äiá»u nÃ y dÆ°á»ng nhÆ° xÃ¡c nháº­n giáº£ thuyáº¿t cá»§a chÃºng tÃ´i, vÃ¬ váº­y hÃ£y dá»n dáº¹p táº­p dá»¯ liá»‡u má»™t chÃºt báº±ng cÃ¡ch Ä‘á»•i tÃªn cá»™t `Unname: 0` thÃ nh má»™t cÃ¡i gÃ¬ Ä‘Ã³ dá»… hiá»ƒu hÆ¡n má»™t chÃºt. ChÃºng ta cÃ³ thá»ƒ sá»­ dá»¥ng hÃ m `DatasetDict.rename_column()` Ä‘á»ƒ Ä‘á»•i tÃªn cá»™t trÃªn cáº£ hai táº­p con trong má»™t láº§n:

```py
drug_dataset = drug_dataset.rename_column(
    original_column_name="Unnamed: 0", new_column_name="patient_id"
)
drug_dataset
```

```python out
DatasetDict({
    train: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],
        num_rows: 161297
    })
    test: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],
        num_rows: 53766
    })
})
```

<Tip>

âœï¸ **Thá»­ nghiá»‡m thÃ´i!** Sá»­ dá»¥ng hÃ m `Dataset.unique()` Ä‘á»ƒ tÃ¬m sá»‘ lÆ°á»£ng thuá»‘c Ä‘á»™c nháº¥t vÃ  Ä‘iá»u kiá»‡n trong táº­p huáº¥n luyá»‡n vÃ  kiá»ƒm thá»­.

</Tip>

Tiáº¿p theo, hÃ£y chuáº©n hÃ³a táº¥t cáº£ cÃ¡c nhÃ£n `condition` báº±ng cÃ¡ch sá»­ dá»¥ng `Dataset.map()`. NhÆ° chÃºng ta Ä‘Ã£ lÃ m vá»›i tokenize trong [ChÆ°Æ¡ng 3](/course/chapter3), chÃºng ta cÃ³ thá»ƒ xÃ¡c Ä‘á»‹nh má»™t hÃ m Ä‘Æ¡n giáº£n cÃ³ thá»ƒ Ä‘Æ°á»£c Ã¡p dá»¥ng trÃªn táº¥t cáº£ cÃ¡c hÃ ng cá»§a má»—i táº­p trong `drug_dataset`:

```py
def lowercase_condition(example):
    return {"condition": example["condition"].lower()}


drug_dataset.map(lowercase_condition)
```

```python out
AttributeError: 'NoneType' object has no attribute 'lower'
```

á»’ khÃ´ng, chÃºng ta Ä‘Ã£ gáº·p sá»± cá»‘ vá»›i chá»©c nÄƒng ná»‘i cá»§a mÃ¬nh! Tá»« lá»—i, chÃºng ta cÃ³ thá»ƒ suy ra ráº±ng má»™t sá»‘ má»¥c nháº­p trong cá»™t `condition` lÃ  `None`, khÃ´ng thá»ƒ viáº¿t thÆ°á»ng vÃ¬ chÃºng khÃ´ng pháº£i lÃ  chuá»—i. HÃ£y bá» cÃ¡c hÃ ng nÃ y báº±ng cÃ¡ch sá»­ dá»¥ng `Dataset.filter()`, hoáº¡t Ä‘á»™ng theo cÃ¡ch tÆ°Æ¡ng tá»± nhÆ° `Dataset.map()` vÃ  mong Ä‘á»£i má»™t hÃ m nháº­n Ä‘Æ°á»£c má»™t máº«u vá» táº­p dá»¯ liá»‡u. Thay vÃ¬ viáº¿t má»™t hÃ m rÃµ rÃ ng nhÆ°:

```py
def filter_nones(x):
    return x["condition"] is not None
```

vÃ  sau Ä‘Ã³ cháº¡y `drug_dataset.filter(filter_nones)`, chÃºng ta cÃ³ thá»ƒ thá»±c hiá»‡n viá»‡c nÃ y trong má»™t dÃ²ng báº±ng cÃ¡ch sá»­ dá»¥ng _hÃ m lambda_. Trong Python, cÃ¡c hÃ m lambda lÃ  cÃ¡c hÃ m nhá» mÃ  báº¡n cÃ³ thá»ƒ Ä‘á»‹nh nghÄ©a mÃ  khÃ´ng cáº§n Ä‘áº·t tÃªn rÃµ rÃ ng. ChÃºng cÃ³ dáº¡ng chung:

```
lambda <arguments> : <expression>
```

á»Ÿ Ä‘Ã¢y `lambda` lÃ  má»™t trong nhá»¯ng [tá»« khÃ³a](https://docs.python.org/3/reference/lexical_analysis.html#keywords) Ä‘áº·c biá»‡t cá»§a Python, `<arguments>` lÃ  danh sÃ¡ch / táº­p há»£p cÃ¡c giÃ¡ trá»‹ Ä‘Æ°á»£c phÃ¢n tÃ¡ch báº±ng dáº¥u pháº©y xÃ¡c Ä‘á»‹nh cÃ¡c Ä‘áº§u vÃ o cho hÃ m vÃ  `<expression>`  Ä‘áº¡i diá»‡n cho cÃ¡c hoáº¡t Ä‘á»™ng báº¡n muá»‘n thá»±c hiá»‡n. VÃ­ dá»¥, chÃºng ta cÃ³ thá»ƒ Ä‘á»‹nh nghÄ©a má»™t hÃ m lambda Ä‘Æ¡n giáº£n bÃ¬nh phÆ°Æ¡ng má»™t sá»‘ nhÆ° sau:

```
lambda x : x * x
```

Äá»ƒ Ã¡p dá»¥ng hÃ m nÃ y cho má»™t Ä‘áº§u vÃ o, chÃºng ta cáº§n Ä‘áº·t nÃ³ vÃ  Ä‘áº§u vÃ o trong dáº¥u ngoáº·c Ä‘Æ¡n:

```py
(lambda x: x * x)(3)
```

```python out
9
```

TÆ°Æ¡ng tá»±, chÃºng ta cÃ³ thá»ƒ Ä‘á»‹nh nghÄ©a cÃ¡c hÃ m lambda vá»›i nhiá»u tham sá»‘ báº±ng cÃ¡ch phÃ¢n tÃ¡ch chÃºng báº±ng dáº¥u pháº©y. VÃ­ dá»¥, chÃºng ta cÃ³ thá»ƒ tÃ­nh diá»‡n tÃ­ch cá»§a má»™t tam giÃ¡c nhÆ° sau:

```py
(lambda base, height: 0.5 * base * height)(4, 8)
```

```python out
16.0
```

CÃ¡c hÃ m Lambda ráº¥t há»¯u Ã­ch khi báº¡n muá»‘n Ä‘á»‹nh nghÄ©a cÃ¡c hÃ m nhá», sá»­ dá»¥ng má»™t láº§n (Ä‘á»ƒ biáº¿t thÃªm thÃ´ng tin vá» chÃºng, chÃºng tÃ´i khuyÃªn báº¡n nÃªn Ä‘á»c [HÆ°á»›ng dáº«n Python Ä‘Ã­ch thá»±c](https://realpython.com/python-lambda/) cá»§a Andre Burgaud). Trong ngá»¯ cáº£nh ğŸ¤— Datasets, chÃºng ta cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡c hÃ m lambda Ä‘á»ƒ xÃ¡c Ä‘á»‹nh cÃ¡c hoáº¡t Ä‘á»™ng ná»‘i vÃ  lá»c Ä‘Æ¡n giáº£n, vÃ¬ váº­y hÃ£y sá»­ dá»¥ng thá»§ thuáº­t nÃ y Ä‘á»ƒ loáº¡i bá» cÃ¡c pháº§n `None` trong táº­p dá»¯ liá»‡u:

```py
drug_dataset = drug_dataset.filter(lambda x: x["condition"] is not None)
```

Vá»›i `None` Ä‘Ã£ bá»‹ xÃ³a, chÃºng ta  cÃ³ thá»ƒ chuáº©n hÃ³a cá»™t `condition`:

```py
drug_dataset = drug_dataset.map(lowercase_condition)
# Kiá»ƒm tra xem chá»¯ viáº¿t thÆ°á»ng Ä‘Ã£ hoáº¡t Ä‘á»™ng chÆ°a
drug_dataset["train"]["condition"][:3]
```

```python out
['left ventricular dysfunction', 'adhd', 'birth control']
```

NÃ³ hoáº¡t Ä‘á»™ng! Váº­y lÃ  chÃºng ta Ä‘Ã£ lÃ m sáº¡ch cÃ¡c nhÃ£n, giá» chÃºng ta hÃ£y xem xÃ©t viá»‡c lÃ m sáº¡ch cÃ¡c bÃ i Ä‘Ã¡nh giÃ¡.

## Táº¡o ra cÃ¡c cá»™t má»›i

Báº¥t cá»© khi nÃ o báº¡n xá»­ lÃ½ cÃ¡c bÃ i Ä‘Ã¡nh giÃ¡ cá»§a khÃ¡ch hÃ ng, má»™t phÆ°Æ¡ng phÃ¡p hay Ä‘Ã³ lÃ  kiá»ƒm tra sá»‘ lÆ°á»£ng tá»« trong má»—i bÃ i Ä‘Ã¡nh giÃ¡. BÃ i Ä‘Ã¡nh giÃ¡ cÃ³ thá»ƒ chá»‰ lÃ  má»™t tá»« duy nháº¥t nhÆ° "Tuyá»‡t vá»i!" hoáº·c má»™t bÃ i luáº­n Ä‘áº§y Ä‘á»§ vá»›i hÃ ng nghÃ¬n tá»«, vÃ  tÃ¹y thuá»™c vÃ o trÆ°á»ng há»£p sá»­ dá»¥ng, báº¡n sáº½ cáº§n xá»­ lÃ½ nhá»¯ng thÃ¡i cá»±c nÃ y theo cÃ¡ch khÃ¡c nhau. Äá»ƒ tÃ­nh toÃ¡n sá»‘ lÆ°á»£ng tá»« trong má»—i bÃ i Ä‘Ã¡nh giÃ¡, chÃºng tÃ´i sáº½ sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p phá»ng Ä‘oÃ¡n sÆ¡ bá»™ dá»±a trÃªn viá»‡c tÃ¡ch tá»«ng vÄƒn báº£n theo khoáº£ng tráº¯ng.

HÃ£y Ä‘á»‹nh nghÄ©a má»™t hÃ m Ä‘Æ¡n giáº£n Ä‘áº¿m sá»‘ tá»« trong má»—i bÃ i Ä‘Ã¡nh giÃ¡:

```py
def compute_review_length(example):
    return {"review_length": len(example["review"].split())}
```

KhÃ´ng giá»‘ng nhÆ° hÃ m `lowercase_condition()`, `compute_review_length()` tráº£ vá» má»™t tá»« Ä‘iá»ƒn cÃ³ khÃ³a khÃ´ng tÆ°Æ¡ng á»©ng vá»›i má»™t trong cÃ¡c tÃªn cá»™t trong táº­p dá»¯ liá»‡u. Trong trÆ°á»ng há»£p nÃ y, khi `compute_review_length()` Ä‘Æ°á»£c truyá»n vÃ o `Dataset.map()`, nÃ³ sáº½ Ä‘Æ°á»£c Ã¡p dá»¥ng cho táº¥t cáº£ cÃ¡c hÃ ng trong táº­p dá»¯ liá»‡u Ä‘á»ƒ táº¡o cá»™t má»›i `review_length`:

```py
drug_dataset = drug_dataset.map(compute_review_length)
# Kiá»ƒm tra máº«u huáº¥n luyá»‡n Ä‘áº§u tiÃªn
drug_dataset["train"][0]
```

```python out
{'patient_id': 206461,
 'drugName': 'Valsartan',
 'condition': 'left ventricular dysfunction',
 'review': '"It has no side effect, I take it in combination of Bystolic 5 Mg and Fish Oil"',
 'rating': 9.0,
 'date': 'May 20, 2012',
 'usefulCount': 27,
 'review_length': 17}
```

NhÆ° mong Ä‘á»£i, chÃºng ta cÃ³ thá»ƒ tháº¥y cá»™t `review_length` Ä‘Ã£ Ä‘Æ°á»£c thÃªm vÃ o táº­p huáº¥n luyá»‡n cá»§a chÃºng ta. ChÃºng ta cÃ³ thá»ƒ sáº¯p xáº¿p cá»™t má»›i nÃ y vá»›i `Dataset.sort()` Ä‘á»ƒ xem cÃ¡c giÃ¡ trá»‹ cá»±c Ä‘áº¡i trÃ´ng nhÆ° tháº¿ nÃ o:

```py
drug_dataset["train"].sort("review_length")[:3]
```

```python out
{'patient_id': [103488, 23627, 20558],
 'drugName': ['Loestrin 21 1 / 20', 'Chlorzoxazone', 'Nucynta'],
 'condition': ['birth control', 'muscle spasm', 'pain'],
 'review': ['"Excellent."', '"useless"', '"ok"'],
 'rating': [10.0, 1.0, 6.0],
 'date': ['November 4, 2008', 'March 24, 2017', 'August 20, 2016'],
 'usefulCount': [5, 2, 10],
 'review_length': [1, 1, 1]}
```

NhÆ° ta Ä‘Ã£ nghi váº¥n, má»™t sá»‘ Ä‘Ã¡nh giÃ¡ chá»‰ chá»©a má»™t tá»« duy nháº¥t, máº·c dÃ¹ cÃ³ thá»ƒ á»•n Ä‘á»ƒ phÃ¢n tÃ­ch sáº¯c thÃ¡i, nhÆ°ng sáº½ khÃ´ng cÃ³ nhiá»u thÃ´ng tin náº¿u chÃºng tÃ´i muá»‘n dá»± Ä‘oÃ¡n tÃ¬nh tráº¡ng bá»‡nh.

<Tip>

ğŸ™‹ Má»™t cÃ¡ch thay tháº¿ Ä‘á»ƒ thÃªm cÃ¡c cá»™t má»›i vÃ o táº­p dá»¯ liá»‡u lÃ  sá»­ dá»¥ng hÃ m `Dataset.add_column()`. Äiá»u nÃ y cho phÃ©p báº¡n cung cáº¥p cá»™t dÆ°á»›i dáº¡ng danh sÃ¡ch Python hoáº·c máº£ng NumPy vÃ  cÃ³ thá»ƒ há»¯u Ã­ch trong cÃ¡c trÆ°á»ng há»£p mÃ  `Dataset.map()` khÃ´ng phÃ¹ há»£p cho phÃ¢n tÃ­ch cá»§a báº¡n.

</Tip>

HÃ£y sá»­ dá»¥ng hÃ m `Dataset.filter()` Ä‘á»ƒ xÃ³a cÃ¡c bÃ i Ä‘Ã¡nh giÃ¡ cÃ³ Ã­t hÆ¡n 30 tá»«. TÆ°Æ¡ng tá»± nhÆ° nhá»¯ng gÃ¬ chÃºng ta Ä‘Ã£ lÃ m vá»›i cá»™t `condition`, chÃºng ta cÃ³ thá»ƒ lá»c ra cÃ¡c bÃ i Ä‘Ã¡nh giÃ¡ ráº¥t ngáº¯n báº±ng cÃ¡ch yÃªu cáº§u cÃ¡c bÃ i Ä‘Ã¡nh giÃ¡ cÃ³ Ä‘á»™ dÃ i trÃªn ngÆ°á»¡ng nÃ y:

```py
drug_dataset = drug_dataset.filter(lambda x: x["review_length"] > 30)
print(drug_dataset.num_rows)
```

```python out
{'train': 138514, 'test': 46108}
```

NhÆ° báº¡n cÃ³ thá»ƒ tháº¥y, Ä‘iá»u nÃ y Ä‘Ã£ loáº¡i bá» khoáº£ng 15% bÃ i Ä‘Ã¡nh giÃ¡ khá»i bá»™ huáº¥n luyá»‡n vÃ  kiá»ƒm thá»­ ban Ä‘áº§u.

<Tip>

âœï¸ **Thá»­ nghiá»‡m thÃ´i!** Sá»­ dá»¥ng hÃ m `Dataset.sort()` Ä‘á»ƒ kiá»ƒm tra cÃ¡c bÃ i Ä‘Ã¡nh giÃ¡ cÃ³ sá»‘ lÆ°á»£ng tá»« lá»›n nháº¥t. Tham kháº£o [tÃ i liá»‡u](https://huggingface.co/docs/datasets/package_reference/main_classes#datasets.Dataset.sort) Ä‘á»ƒ biáº¿t báº¡n cáº§n sá»­ dá»¥ng tham sá»‘ nÃ o Ä‘á»ƒ sáº¯p xáº¿p cÃ¡c bÃ i Ä‘Ã¡nh giÃ¡ theo thá»© tá»± giáº£m dáº§n.

</Tip>

Äiá»u cuá»‘i cÃ¹ng chÃºng ta cáº§n giáº£i quyáº¿t lÃ  sá»± hiá»‡n diá»‡n cá»§a kÃ½ tá»± HTML trong cÃ¡c bÃ i Ä‘Ã¡nh giÃ¡ cá»§a chÃºng ta. ChÃºng ta cÃ³ thá»ƒ sá»­ dá»¥ng mÃ´-Ä‘un `html` cá»§a Python Ä‘á»ƒ loáº¡i bá» qua cÃ¡c kÃ½ tá»± nÃ y, nhÆ° sau:

```py
import html

text = "I&#039;m a transformer called BERT"
html.unescape(text)
```

```python out
"I'm a transformer called BERT"
```

Ta sáº½ sá»­ dá»¥ng `Dataset.map()` Ä‘á»ƒ há»§y táº¥t cáº£ cÃ¡c kÃ½ tá»± HTML trong kho tÃ i liá»‡u cá»§a mÃ¬nh:

```python
drug_dataset = drug_dataset.map(lambda x: {"review": html.unescape(x["review"])})
```

NhÆ° báº¡n cÃ³ thá»ƒ tháº¥y, phÆ°Æ¡ng thá»©c `Dataset.map()` khÃ¡ há»¯u Ã­ch Ä‘á»ƒ xá»­ lÃ½ dá»¯ liá»‡u - vÃ  chÃºng ta tháº­m chÃ­ cÃ²n chÆ°a rÃµ táº¥t má»i thá»© mÃ  nÃ³ cÃ³ thá»ƒ lÃ m!

## SiÃªu sá»©c máº¡nh cá»§a hÃ m `map()`

PhÆ°Æ¡ng thá»©c `Dataset.map ()` nháº­n tham sá»‘ `batched`, náº¿u Ä‘Æ°á»£c Ä‘áº·t thÃ nh `True`, nÃ³ sáº½ gá»­i má»™t loáº¡t cÃ¡c máº«u Ä‘áº¿n hÃ m map cÃ¹ng má»™t lÃºc (ta cÃ³ thá»ƒ cáº¥u hÃ¬nh kÃ­ch thÆ°á»›c lÃ´ nhÆ°ng máº·c Ä‘á»‹nh lÃ  1,000). VÃ­ dá»¥: hÃ m map trÆ°á»›c Ä‘Ã³ loáº¡i bá» táº¥t cáº£ HTML Ä‘Ã£ máº¥t má»™t chÃºt thá»i gian Ä‘á»ƒ cháº¡y (báº¡n cÃ³ thá»ƒ Ä‘á»c thá»i gian thá»±c hiá»‡n tá»« cÃ¡c thanh tiáº¿n trÃ¬nh). ChÃºng ta cÃ³ thá»ƒ tÄƒng tá»‘c Ä‘á»™ nÃ y báº±ng cÃ¡ch xá»­ lÃ½ má»™t sá»‘ pháº§n tá»­ cÃ¹ng lÃºc thÃ´ng qua sá»­ dá»¥ng bao hÃ m.

Khi báº¡n chá»‰ Ä‘á»‹nh `batched=True`, hÃ m sáº½ nháº­n má»™t tá»« Ä‘iá»ƒn vá»›i cÃ¡c trÆ°á»ng cá»§a táº­p dá»¯ liá»‡u, nhÆ°ng má»—i giÃ¡ trá»‹ bÃ¢y giá» lÃ  má»™t _danh sÃ¡ch cÃ¡c giÃ¡ trá»‹_ vÃ  khÃ´ng chá»‰ lÃ  má»™t giÃ¡ trá»‹ duy nháº¥t. GiÃ¡ trá»‹ tráº£ vá» cá»§a `Dataset.map()` pháº£i giá»‘ng nhau: má»™t tá»« Ä‘iá»ƒn vá»›i cÃ¡c trÆ°á»ng ta muá»‘n cáº­p nháº­t hoáº·c thÃªm vÃ o táº­p dá»¯ liá»‡u cá»§a mÃ¬nh vÃ  má»™t danh sÃ¡ch cÃ¡c giÃ¡ trá»‹. VÃ­ dá»¥: Ä‘Ã¢y lÃ  má»™t cÃ¡ch khÃ¡c Ä‘á»ƒ há»§y táº¥t cáº£ cÃ¡c kÃ½ tá»± HTML, nhÆ°ng sá»­ dá»¥ng `batched=True`:

```python
new_drug_dataset = drug_dataset.map(
    lambda x: {"review": [html.unescape(o) for o in x["review"]]}, batched=True
)
```

Náº¿u báº¡n Ä‘ang cháº¡y Ä‘oáº¡n mÃ£ nÃ y trÃªn notebook, báº¡n sáº½ tháº¥y ráº±ng lá»‡nh nÃ y thá»±c thi nhanh hÆ¡n lá»‡nh trÆ°á»›c Ä‘Ã³. VÃ  Ä‘Ã³ khÃ´ng pháº£i lÃ  do cÃ¡c bÃ i Ä‘Ã¡nh giÃ¡ cá»§a chÃºng tÃ´i Ä‘Ã£ Ä‘Æ°á»£c loáº¡i Ä‘i HTML - náº¿u báº¡n thá»±c hiá»‡n láº¡i hÆ°á»›ng dáº«n tá»« pháº§n trÆ°á»›c (khÃ´ng cÃ³ `batch = True`), nÃ³ sáº½ máº¥t cÃ¹ng má»™t khoáº£ng thá»i gian nhÆ° trÆ°á»›c. Äiá»u nÃ y lÃ  do viá»‡c bao hÃ m thÆ°á»ng nhanh hÆ¡n viá»‡c thá»±c thi cÃ¹ng má»™t Ä‘oáº¡n mÃ£ trong vÃ²ng láº·p `for` vÃ  chÃºng ta cÅ©ng Ä‘áº¡t Ä‘Æ°á»£c má»™t sá»‘ hiá»‡u suáº¥t báº±ng cÃ¡ch truy cáº­p nhiá»u pháº§n tá»­ cÃ¹ng má»™t lÃºc thay vÃ¬ tá»«ng pháº§n tá»­ má»™t.

Sá»­ dá»¥ng `Dataset.map()` vá»›i `batched=True` sáº½ lÃ  Ä‘iá»u cáº§n thiáº¿t Ä‘á»ƒ má»Ÿ khÃ³a tá»‘c Ä‘á»™ cá»§a cÃ¡c trÃ¬nh tokenize "nhanh" mÃ  chÃºng ta sáº½ gáº·p trong [ChÆ°Æ¡ng 6](/course/chap6), cÃ³ thá»ƒ nhanh chÃ³ng tokenize cÃ¡c danh sÃ¡ch lá»›n cÃ¡c vÄƒn báº£n. VÃ­ dá»¥: Ä‘á»ƒ tokenize táº¥t cáº£ cÃ¡c Ä‘Ã¡nh giÃ¡ thuá»‘c báº±ng trÃ¬nh tokenize nhanh, ta cÃ³ thá»ƒ sá»­ dá»¥ng má»™t hÃ m nhÆ° sau:

```python
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")


def tokenize_function(examples):
    return tokenizer(examples["review"], truncation=True)
```

NhÆ° báº¡n Ä‘Ã£ tháº¥y trong [ChÆ°Æ¡ng 3](/course/chapter3), chÃºng ta cÃ³ thá»ƒ truyá»n vÃ o má»™t hoáº·c nhiá»u máº«u cho tokenizer, vÃ¬ váº­y ta cÃ³ thá»ƒ sá»­ dá»¥ng hÃ m nÃ y vá»›i `batched=True` hoáº·c khÃ´ng. HÃ£y cÅ©ng coi Ä‘Ã¢y lÃ  má»™t cÆ¡ há»™i Ä‘á»ƒ so sÃ¡nh hiá»‡u nÄƒng cá»§a hai tuá»³ chá»n nÃ y. Trong má»™t notebook, báº¡n cÃ³ thá»ƒ báº¥m giá» chá»‰ vá»›i má»™t dÃ²ng lá»‡nh `%time` trÆ°á»›c dÃ²ng mÃ£ báº¡n muá»‘n tÃ¬nh thá»i gian:

```python no-format
%time tokenized_dataset = drug_dataset.map(tokenize_function, batched=True)
```

Báº¡n cÅ©ng cÃ³ thá»ƒ tÃ­nh thá»i gian cho toÃ n bá»™ Ã´ báº±ng cÃ¡ch Ä‘áº·t `%%time` á»Ÿ Ä‘áº§u cá»§a Ã´ mÃ£. TrÃªn pháº§n cá»©ng mÃ  chÃºng ta thá»±c hiá»‡n, nÃ³ hiá»ƒn thá»‹ 10.8 giÃ¢y cho lá»‡nh nÃ y (Ä‘Ã³ lÃ  sá»‘ Ä‘Æ°á»£c viáº¿t sau "Wall time").

<Tip>

âœï¸ **Thá»­ nghiá»‡m thÃ´i!** Thá»±c hiá»‡n cÃ¹ng má»™t hÆ°á»›ng dáº«n cÃ³ vÃ  khÃ´ng cÃ³ `batched=True`, sau Ä‘Ã³ thá»­ nÃ³ vá»›i tokenizer cháº­m (thÃªm `use_fast=False` vÃ o `AutoTokenizer.from_pretrained()`) Ä‘á»ƒ báº¡n cÃ³ thá»ƒ tháº¥y giÃ¡ trá»‹ báº¡n nháº­n Ä‘Æ°á»£c trÃªn pháº§n cá»©ng cá»§a mÃ¬nh.

</Tip>

DÆ°á»›i Ä‘Ã¢y lÃ  káº¿t quáº£ thu Ä‘Æ°á»£c khi cÃ³ vÃ  khÃ´ng cÃ³ tÃ­nh nÄƒng phÃ¢n lÃ´, vá»›i tokenizer nhanh vÃ  cháº­m:

Tuá»³ chá»n         | Tokenizer nhanh | Tokenizer cháº­m
:--------------:|:--------------:|:-------------:
`batched=True`  | 10.8s          | 4min41s
`batched=False` | 59.2s          | 5min3s

Äiá»u nÃ y cÃ³ nghÄ©a lÃ  viá»‡c sá»­ dá»¥ng má»™t tokenizer nhanh vá»›i tÃ¹y chá»n `batched=True` sáº½ nhanh hÆ¡n 30 láº§n so vá»›i phiÃªn báº£n cháº­m mÃ  khÃ´ng cÃ³ lÃ´ - Ä‘iá»u nÃ y thá»±c sá»± tuyá»‡t vá»i! ÄÃ³ lÃ  lÃ½ do chÃ­nh táº¡i sao tokenizer nhanh lÃ  máº·c Ä‘á»‹nh khi sá»­ dá»¥ng `AutoTokenizer` (vÃ  táº¡i sao chÃºng Ä‘Æ°á»£c gá»i lÃ  "nhanh"). ChÃºng cÃ³ thá»ƒ Ä‘áº¡t Ä‘Æ°á»£c tá»‘c Ä‘á»™ nhÆ° váº­y bá»Ÿi vÃ¬ phÃ­a sau, Ä‘oáº¡n mÃ£ token hÃ³a Ä‘Æ°á»£c thá»±c thi báº±ng Rust, Ä‘Ã¢y lÃ  má»™t ngÃ´n ngá»¯ giÃºp dá»… dÃ ng thá»±c hiá»‡n Ä‘oáº¡n mÃ£ song song.

Song song hÃ³a cÅ©ng lÃ  lÃ½ do giáº£i thÃ­ch cho tá»‘c Ä‘á»™ tÄƒng gáº§n gáº¥p 6 láº§n mÃ  trÃ¬nh tokenize nhanh Ä‘áº¡t Ä‘Æ°á»£c vá»›i viá»‡c phÃ¢n lÃ´: báº¡n khÃ´ng thá»ƒ song song má»™t thao tÃ¡c tokenize Ä‘Æ¡n láº», nhÆ°ng khi báº¡n muá»‘n tokenize nhiá»u vÄƒn báº£n cÃ¹ng má»™t lÃºc, báº¡n cÃ³ thá»ƒ chá»‰ cáº§n chia nhá» viá»‡c thá»±c thi trÃªn nhiá»u quy trÃ¬nh, má»—i ngÆ°á»i chá»‹u trÃ¡ch nhiá»‡m vá» cÃ¡c vÄƒn báº£n cá»§a riÃªng mÃ¬nh.

`Dataset.map()` cÅ©ng tá»± cÃ³ má»™t sá»‘ kháº£ nÄƒng tÃ­nh toÃ¡n song song. VÃ¬ chÃºng khÃ´ng Ä‘Æ°á»£c há»— trá»£ bá»Ÿi Rust, nÃªn chÃºng sáº½ khÃ´ng Ä‘á»ƒ má»™t trÃ¬nh tokenizer cháº­m báº¯t ká»‹p vá»›i má»™t tokenizer nhanh, nhÆ°ng chÃºng váº«n cÃ³ thá»ƒ há»¯u Ã­ch (Ä‘áº·c biá»‡t náº¿u báº¡n Ä‘ang sá»­ dá»¥ng má»™t tokenizer khÃ´ng cÃ³ phiÃªn báº£n nhanh). Äá»ƒ báº­t xá»­ lÃ½ Ä‘a luá»“ng, hÃ£y sá»­ dá»¥ng tham sá»‘ `num_proc` vÃ  chá»‰ Ä‘á»‹nh sá»‘ lÆ°á»£ng quy trÃ¬nh sáº½ sá»­ dá»¥ng trong lá»‡nh gá»i cá»§a báº¡n tá»›i `Dataset.map()`:

```py
slow_tokenizer = AutoTokenizer.from_pretrained("bert-base-cased", use_fast=False)


def slow_tokenize_function(examples):
    return slow_tokenizer(examples["review"], truncation=True)


tokenized_dataset = drug_dataset.map(slow_tokenize_function, batched=True, num_proc=8)
```

Báº¡n cÃ³ thá»ƒ thá»­ nghiá»‡m má»™t chÃºt vá»›i thá»i gian Ä‘á»ƒ xÃ¡c Ä‘á»‹nh sá»‘ lÆ°á»£ng quy trÃ¬nh tá»‘i Æ°u Ä‘á»ƒ sá»­ dá»¥ng; trong trÆ°á»ng há»£p cá»§a chÃºng ta, 8 dÆ°á»ng nhÆ° táº¡o ra tá»‘c Ä‘á»™ tÄƒng tá»‘t nháº¥t. DÆ°á»›i Ä‘Ã¢y lÃ  nhá»¯ng con sá»‘ chÃºng tÃ´i nháº­n Ä‘Æ°á»£c khi cÃ³ vÃ  khÃ´ng cÃ³ xá»­ lÃ½ Ä‘a luá»“ng:

Tuá»³ chá»n         | Tokenizer nhanh | Tokenizer cháº­m
:--------------:|:--------------:|:-------------:
`batched=True`  | 10.8s          | 4min41s
`batched=False` | 59.2s          | 5min3s
`batched=True`, `num_proc=8`  | 6.52s          | 41.3s
`batched=False`, `num_proc=8` | 9.49s          | 45.2s

ÄÃ³ lÃ  nhá»¯ng káº¿t quáº£ há»£p lÃ½ hÆ¡n nhiá»u Ä‘á»‘i vá»›i tokenizer cháº­m, nhÆ°ng hiá»‡u suáº¥t cá»§a tokenizer nhanh cÅ©ng Ä‘Ã£ Ä‘Æ°á»£c cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ. Tuy nhiÃªn, lÆ°u Ã½ ráº±ng Ä‘iá»u Ä‘Ã³ khÃ´ng pháº£i lÃºc nÃ o cÅ©ng Ä‘Ãºng - Ä‘á»‘i vá»›i cÃ¡c giÃ¡ trá»‹ cá»§a `num_proc` khÃ¡c 8, cÃ¡c thá»­ nghiá»‡m cá»§a chÃºng tÃ´i cho tháº¥y ráº±ng sá»­ dá»¥ng `batched=True` mÃ  khÃ´ng cÃ³ tÃ¹y chá»n nÃ y sáº½ nhanh hÆ¡n. NÃ³i chung, chÃºng tÃ´i khuyÃªn báº¡n khÃ´ng nÃªn sá»­ dá»¥ng xá»­ lÃ½ Ä‘a luá»“ng Python cho cÃ¡c trÃ¬nh tokenize nhanh vá»›i `batched=True`.

<Tip>

Sá»­ dá»¥ng `num_proc` Ä‘á»ƒ tÄƒng tá»‘c quÃ¡ trÃ¬nh xá»­ lÃ½ cá»§a báº¡n thÆ°á»ng lÃ  má»™t Ã½ tÆ°á»Ÿng tuyá»‡t vá»i, miá»…n lÃ  hÃ m báº¡n Ä‘ang sá»­ dá»¥ng chÆ°a thá»±c hiá»‡n má»™t sá»‘ kiá»ƒu xá»­ lÃ½ Ä‘a xá»­ lÃ½ cá»§a riÃªng nÃ³.

</Tip>

Táº¥t cáº£ cÃ¡c chá»©c nÄƒng nÃ y Ä‘Æ°á»£c cÃ´ Ä‘á»ng trong má»™t phÆ°Æ¡ng phÃ¡p Ä‘Ã£ khÃ¡ tuyá»‡t vá»i, nhÆ°ng cÃ²n nhiá»u hÆ¡n tháº¿ ná»¯a! Vá»›i `Dataset.map()` vÃ  `batched=True`, báº¡n cÃ³ thá»ƒ thay Ä‘á»•i sá»‘ lÆ°á»£ng pháº§n tá»­ trong táº­p dá»¯ liá»‡u cá»§a mÃ¬nh. Äiá»u nÃ y cá»±c ká»³ há»¯u Ã­ch trong nhiá»u trÆ°á»ng há»£p mÃ  báº¡n muá»‘n táº¡o má»™t sá»‘ Ä‘áº·c trÆ°ng huáº¥n luyá»‡n tá»« má»™t máº«u vÃ  chÃºng ta sáº½ cáº§n thá»±c hiá»‡n Ä‘iá»u nÃ y nhÆ° má»™t pháº§n cá»§a quÃ¡ trÃ¬nh tiá»n xá»­ lÃ½ cho má»™t sá»‘ tÃ¡c vá»¥ NLP sáº½ thá»±c hiá»‡n trong [ChÆ°Æ¡ng 7](/course/chapter7).

<Tip>

ğŸ’¡ Trong há»c mÃ¡y, má»™t _máº«u_ thÆ°á»ng Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a lÃ  táº­p há»£p _Ä‘áº·c trÆ°ng_ mÃ  chÃºng ta cung cáº¥p cho mÃ´ hÃ¬nh. Trong má»™t sá»‘ ngá»¯ cáº£nh, cÃ¡c Ä‘áº·c trÆ°ng nÃ y sáº½ lÃ  táº­p há»£p thÃ nh cÃ¡c cá»™t trong `Dataset`, nhÆ°ng trong cÃ¡c trÆ°á»ng há»£p khÃ¡c (nhÆ° á»Ÿ Ä‘Ã¢y vÃ  Ä‘á»ƒ phá»¥c vá»¥ há»i Ä‘Ã¡p), nhiá»u Ä‘áº·c trÆ°ng cÃ³ thá»ƒ Ä‘Æ°á»£c trÃ­ch xuáº¥t tá»« má»™t máº«u vÃ  thuá»™c vá» má»™t cá»™t duy nháº¥t.

</Tip>

ChÃºng ta hÃ£y xem nÃ³ hoáº¡t Ä‘á»™ng nhÆ° tháº¿ nÃ o! á» Ä‘Ã¢y, ta sáº½ tokenize cÃ¡c máº«u cá»§a mÃ¬nh vÃ  cáº¯t chÃºng vá» Ä‘á»™ dÃ i tá»‘i Ä‘a lÃ  128, nhÆ°ng ta sáº½ yÃªu cáº§u trÃ¬nh tokenize tráº£ vá» *táº¥t cáº£* cÃ¡c Ä‘oáº¡n vÄƒn báº£n thay vÃ¬ chá»‰ Ä‘oáº¡n vÄƒn báº£n Ä‘áº§u tiÃªn. Äiá»u nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c thá»±c hiá»‡n vá»›i `return_overflowing_tokens=True`:

```py
def tokenize_and_split(examples):
    return tokenizer(
        examples["review"],
        truncation=True,
        max_length=128,
        return_overflowing_tokens=True,
    )
```

HÃ£y kiá»ƒm tra Ä‘iá»u nÃ y trÃªn má»™t máº«u trÆ°á»›c khi sá»­ dá»¥ng `Dataset.map()` trÃªn toÃ n bá»™ táº­p dá»¯ liá»‡u:

```py
result = tokenize_and_split(drug_dataset["train"][0])
[len(inp) for inp in result["input_ids"]]
```

```python out
[128, 49]
```

VÃ¬ váº­y, máº«u Ä‘áº§u tiÃªn trong táº­p huáº¥n luyá»‡n Ä‘Ã£ trá»Ÿ thÃ nh hai Ä‘áº·c trÆ°ng vÃ¬ nÃ³ Ä‘Ã£ Ä‘Æ°á»£c tokenize nhiá»u hÆ¡n sá»‘ lÆ°á»£ng token tá»‘i Ä‘a mÃ  chÃºng tÃ´i Ä‘Ã£ chá»‰ Ä‘á»‹nh: cÃ¡i Ä‘áº§u tiÃªn cÃ³ Ä‘á»™ dÃ i 128 vÃ  cÃ¡i thá»© hai cÃ³ Ä‘á»™ dÃ i 49. BÃ¢y giá» hÃ£y lÃ m Ä‘iá»u nÃ y cho táº¥t cáº£ cÃ¡c pháº§n tá»­ cá»§a táº­p dá»¯ liá»‡u!

```py
tokenized_dataset = drug_dataset.map(tokenize_and_split, batched=True)
```

```python out
ArrowInvalid: Column 1 named condition expected length 1463 but got length 1000
```

Ã”i khÃ´ng! NÃ³ Ä‘Ã£ khÃ´ng hoáº¡t Ä‘á»™ng! Táº¡i sao khÃ´ng? NhÃ¬n vÃ o thÃ´ng bÃ¡o lá»—i sáº½ cho chÃºng ta manh má»‘i: cÃ³ sá»± khÃ´ng khá»›p vá» Ä‘á»™ dÃ i cá»§a má»™t trong cÃ¡c cá»™t, má»™t cá»™t cÃ³ Ä‘á»™ dÃ i 1,463 vÃ  cá»™t cÃ²n láº¡i cÃ³ Ä‘á»™ dÃ i 1,000. Náº¿u báº¡n Ä‘Ã£ xem [tÃ i liá»‡u](https://huggingface.co/docs/datasets/package_reference/main_classes#datasets.Dataset.map) vá» `Dataset.map()`, báº¡n cÃ³ thá»ƒ nhá»› ráº±ng Ä‘Ã³ lÃ  sá»‘ cÃ¡c máº«u Ä‘Æ°á»£c truyá»n vÃ o hÃ m mÃ  chÃºng ta Ä‘ang Ã¡nh xáº¡; á»Ÿ Ä‘Ã¢y 1,000 máº«u Ä‘Ã³ Ä‘Ã£ cung cáº¥p 1,463 Ä‘áº·c trÆ°ng má»›i, dáº«n Ä‘áº¿n lá»—i hÃ¬nh dáº¡ng.

Váº¥n Ä‘á» lÃ  chÃºng ta Ä‘ang cá»‘ gáº¯ng káº¿t há»£p hai táº­p dá»¯ liá»‡u khÃ¡c nhau vá»›i cÃ¡c kÃ­ch thÆ°á»›c khÃ¡c nhau: cá»™t `drug_dataset` sáº½ cÃ³ má»™t sá»‘ máº«u nháº¥t Ä‘á»‹nh (lá»—i phÃ­a chÃºng ta lÃ  1,000), nhÆ°ng `tokenized_dataset`  mÃ  chÃºng ta Ä‘ang xÃ¢y dá»±ng sáº½ cÃ³ nhiá»u hÆ¡n (1,463 trong thÃ´ng bÃ¡o lá»—i). Äiá»u nÃ y khÃ´ng hoáº¡t Ä‘á»™ng Ä‘á»‘i vá»›i `Dataset`, vÃ¬ váº­y chÃºng ta cáº§n xÃ³a cÃ¡c cá»™t khá»i táº­p dá»¯ liá»‡u cÅ© hoáº·c lÃ m cho chÃºng cÃ³ cÃ¹ng kÃ­ch thÆ°á»›c vá»›i chÃºng trong táº­p dá»¯ liá»‡u má»›i. ChÃºng ta cÃ³ thá»ƒ thá»±c hiá»‡n Ä‘iá»u Ä‘áº§u thÃ´ng qua tham sá»‘ `remove_columns`:

```py
tokenized_dataset = drug_dataset.map(
    tokenize_and_split, batched=True, remove_columns=drug_dataset["train"].column_names
)
```

BÃ¢y giá» nÃ³ hoáº¡t Ä‘á»™ng mÃ  khÃ´ng cÃ³ lá»—i. ChÃºng ta cÃ³ thá»ƒ kiá»ƒm tra xem táº­p dá»¯ liá»‡u má»›i cá»§a mÃ¬nh cÃ³ nhiá»u pháº§n tá»­ hÆ¡n táº­p dá»¯ liá»‡u gá»‘c hay khÃ´ng báº±ng cÃ¡ch so sÃ¡nh Ä‘á»™ dÃ i:

```py
len(tokenized_dataset["train"]), len(drug_dataset["train"])
```

```python out
(206772, 138514)
```

ChÃºng tÃ´i Ä‘Ã£ Ä‘á» cáº­p ráº±ng chÃºng ta cÅ©ng cÃ³ thá»ƒ giáº£i quyáº¿t váº¥n Ä‘á» chiá»u dÃ i khÃ´ng khá»›p báº±ng cÃ¡ch lÃ m cho cÃ¡c cá»™t cÅ© cÃ³ cÃ¹ng kÃ­ch thÆ°á»›c vá»›i cÃ¡c cá»™t má»›i. Äá»ƒ thá»±c hiá»‡n viá»‡c nÃ y, chÃºng ta sáº½ cáº§n trÆ°á»ng `overflow_to_sample_mapping` mÃ  tokenizer tráº£ vá» khi chÃºng ta Ä‘áº·t `return_overflowing_tokens=True`. NÃ³ cung cáº¥p cho chÃºng ta má»™t Ã¡nh xáº¡ tá»« má»™t chá»‰ má»¥c Ä‘áº·c trÆ°ng má»›i Ä‘áº¿n chá»‰ má»¥c cá»§a máº«u mÃ  nÃ³ báº¯t nguá»“n tá»« Ä‘Ã³. Sá»­ dá»¥ng Ä‘iá»u nÃ y, chÃºng ta cÃ³ thá»ƒ liÃªn káº¿t má»—i khÃ³a cÃ³ trong táº­p dá»¯ liá»‡u ban Ä‘áº§u vá»›i má»™t danh sÃ¡ch cÃ¡c giÃ¡ trá»‹ cÃ³ kÃ­ch thÆ°á»›c phÃ¹ há»£p báº±ng cÃ¡ch láº·p láº¡i cÃ¡c giÃ¡ trá»‹ cá»§a má»—i vÃ­ dá»¥ nhiá»u láº§n khi nÃ³ táº¡o ra cÃ¡c Ä‘áº·c trÆ°ng má»›i:

```py
def tokenize_and_split(examples):
    result = tokenizer(
        examples["review"],
        truncation=True,
        max_length=128,
        return_overflowing_tokens=True,
    )
    # Extract mapping between new and old indices
    sample_map = result.pop("overflow_to_sample_mapping")
    for key, values in examples.items():
        result[key] = [values[i] for i in sample_map]
    return result
```

ChÃºng ta cÃ³ thá»ƒ tháº¥y nÃ³ hoáº¡t Ä‘á»™ng vá»›i `Dataset.map()` mÃ  chÃºng ta khÃ´ng cáº§n xÃ³a cÃ¡c cá»™t cÅ©:

```py
tokenized_dataset = drug_dataset.map(tokenize_and_split, batched=True)
tokenized_dataset
```

```python out
DatasetDict({
    train: Dataset({
        features: ['attention_mask', 'condition', 'date', 'drugName', 'input_ids', 'patient_id', 'rating', 'review', 'review_length', 'token_type_ids', 'usefulCount'],
        num_rows: 206772
    })
    test: Dataset({
        features: ['attention_mask', 'condition', 'date', 'drugName', 'input_ids', 'patient_id', 'rating', 'review', 'review_length', 'token_type_ids', 'usefulCount'],
        num_rows: 68876
    })
})
```

ChÃºng ta nháº­n Ä‘Æ°á»£c cÃ¹ng sá»‘ Ä‘áº·c trÆ°ng huáº¥n luyá»‡n nhÆ° trÆ°á»›c Ä‘Ã³, nhÆ°ng á»Ÿ Ä‘Ã¢y ta Ä‘Ã£ giá»¯ láº¡i táº¥t cáº£ cÃ¡c trÆ°á»ng cÅ©. Náº¿u báº¡n cáº§n chÃºng Ä‘á»ƒ háº­u xá»­ lÃ½ sau khi Ã¡p dá»¥ng mÃ´ hÃ¬nh cá»§a mÃ¬nh, báº¡n cÃ³ thá»ƒ muá»‘n sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p nÃ y.

BÃ¢y giá» báº¡n Ä‘Ã£ tháº¥y cÃ¡ch ğŸ¤— Datasets cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ tiá»n xá»­ lÃ½ má»™t táº­p dá»¯ liá»‡u theo nhiá»u cÃ¡ch khÃ¡c nhau. Máº·c dÃ¹ cÃ¡c chá»©c nÄƒng xá»­ lÃ½ cá»§a ğŸ¤— Datasets sáº½ Ä‘Ã¡p á»©ng háº§u háº¿t cÃ¡c nhu cáº§u huáº¥n luyá»‡n mÃ´ hÃ¬nh cá»§a báº¡n,
cÃ³ thá»ƒ Ä‘Ã´i khi báº¡n cáº§n chuyá»ƒn sang Pandas Ä‘á»ƒ truy cáº­p cÃ¡c tÃ­nh nÄƒng máº¡nh máº½ hÆ¡n, cháº³ng háº¡n nhÆ°  `DataFrame.groupby()` hoáº·c cÃ¡c API cáº¥p cao Ä‘á»ƒ trá»±c quan hÃ³a. May máº¯n thay, ğŸ¤— Datasets Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ cÃ³ thá»ƒ tÆ°Æ¡ng tÃ¡c vá»›i cÃ¡c thÆ° viá»‡n nhÆ° Pandas, NumPy, PyTorch, TensorFlow vÃ  JAX. ChÃºng ta hÃ£y xem cÃ¡ch nÃ y hoáº¡t Ä‘á»™ng nhÆ° tháº¿ nÃ o.

## Tá»« `Dataset` tá»›i `DataFrame` vÃ  ngÆ°á»£c láº¡i

<Youtube id="tfcY1067A5Q"/>

Äá»ƒ cho phÃ©p chuyá»ƒn Ä‘á»•i giá»¯a cÃ¡c thÆ° viá»‡n bÃªn thá»© ba khÃ¡c nhau, ğŸ¤— Datasets cung cáº¥p hÃ m `Dataset.set_format()`. HÃ m nÃ y chá»‰ thay Ä‘á»•i _Ä‘á»‹nh dáº¡ng Ä‘áº§u ra_ cá»§a táº­p dá»¯ liá»‡u, vÃ¬ váº­y báº¡n cÃ³ thá»ƒ dá»… dÃ ng chuyá»ƒn sang Ä‘á»‹nh dáº¡ng khÃ¡c mÃ  khÃ´ng áº£nh hÆ°á»Ÿng Ä‘áº¿n _Ä‘á»‹nh dáº¡ng Ä‘áº§u ra_ bÃªn dÆ°á»›i, Ä‘Ã³ lÃ  Apache Arrow. Viá»‡c Ä‘á»‹nh dáº¡ng Ä‘Æ°á»£c thá»±c hiá»‡n táº¡i chá»—. Äá»ƒ chá»©ng minh, hÃ£y chuyá»ƒn Ä‘á»•i táº­p dá»¯ liá»‡u cá»§a chÃºng tÃ´i thÃ nh Pandas:

```py
drug_dataset.set_format("pandas")
```

Giá» khi chÃºng ta truy cáº­p cÃ¡c pháº§n tá»­ cá»§a táº­p dá»¯ liá»‡u, ta nháº­n Ä‘Æ°á»£c `pandas.DataFrame` thay vÃ¬ tá»« Ä‘iá»ƒn:

```py
drug_dataset["train"][:3]
```

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>patient_id</th>
      <th>drugName</th>
      <th>condition</th>
      <th>review</th>
      <th>rating</th>
      <th>date</th>
      <th>usefulCount</th>
      <th>review_length</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>95260</td>
      <td>Guanfacine</td>
      <td>adhd</td>
      <td>"My son is halfway through his fourth week of Intuniv..."</td>
      <td>8.0</td>
      <td>April 27, 2010</td>
      <td>192</td>
      <td>141</td>
    </tr>
    <tr>
      <th>1</th>
      <td>92703</td>
      <td>Lybrel</td>
      <td>birth control</td>
      <td>"I used to take another oral contraceptive, which had 21 pill cycle, and was very happy- very light periods, max 5 days, no other side effects..."</td>
      <td>5.0</td>
      <td>December 14, 2009</td>
      <td>17</td>
      <td>134</td>
    </tr>
    <tr>
      <th>2</th>
      <td>138000</td>
      <td>Ortho Evra</td>
      <td>birth control</td>
      <td>"This is my first time using any form of birth control..."</td>
      <td>8.0</td>
      <td>November 3, 2015</td>
      <td>10</td>
      <td>89</td>
    </tr>
  </tbody>
</table>

HÃ£y táº¡o ra má»™t `pandas.DataFrame` cho toÃ n bá»™ táº­p huáº¥n luyá»‡n báº±ng cÃ¡ch chá»n táº¥t cáº£ cÃ¡c pháº§n tá»­ trong `drug_dataset["train"]`:

```py
train_df = drug_dataset["train"][:]
```

<Tip>

ğŸš¨ BÃªn dÆ°á»›i `Dataset.set_format()` thay Ä‘á»•i Ä‘á»‹nh dáº¡ng tráº£ vá» cho phÆ°Æ¡ng thá»©c `__getitem __()` cá»§a táº­p dá»¯ liá»‡u. Äiá»u nÃ y cÃ³ nghÄ©a lÃ  khi chÃºng ta muá»‘n táº¡o má»™t Ä‘á»‘i tÆ°á»£ng má»›i nhÆ° `train_df` tá»« `Dataset` á»Ÿ Ä‘á»‹nh dáº¡ng `"pandas"`, chÃºng ta cáº§n cáº¯t toÃ n bá»™ táº­p dá»¯ liá»‡u Ä‘á»ƒ cÃ³ Ä‘Æ°á»£c má»™t `pandas.DataFrame`. Báº¡n cÃ³ thá»ƒ tá»± xÃ¡c minh xem kiá»ƒu dá»¯ liá»‡u cá»§a `drug_dataset["train"]` cÃ³ pháº£i lÃ  `Dataset`, báº¥t ká»ƒ Ä‘á»‹nh dáº¡ng Ä‘áº§u ra lÃ  gÃ¬.

</Tip>

Tá»« Ä‘Ã¢y, ta cÃ³ thá»ƒ sá»­ dá»¥ng táº¥t cáº£ cÃ¡c chá»©c nÄƒng cá»§a Pandas mÃ  ta muá»‘n. VÃ­ dá»¥, chÃºng ta cÃ³ thá»ƒ thá»±c hiá»‡n chuá»—i láº¡ máº¯t Ä‘á»ƒ tÃ­nh toÃ¡n phÃ¢n phá»‘i lá»›p giá»¯a cÃ¡c `condition`:

```py
frequencies = (
    train_df["condition"]
    .value_counts()
    .to_frame()
    .reset_index()
    .rename(columns={"index": "condition", "condition": "frequency"})
)
frequencies.head()
```

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>condition</th>
      <th>frequency</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>birth control</td>
      <td>27655</td>
    </tr>
    <tr>
      <th>1</th>
      <td>depression</td>
      <td>8023</td>
    </tr>
    <tr>
      <th>2</th>
      <td>acne</td>
      <td>5209</td>
    </tr>
    <tr>
      <th>3</th>
      <td>anxiety</td>
      <td>4991</td>
    </tr>
    <tr>
      <th>4</th>
      <td>pain</td>
      <td>4744</td>
    </tr>
  </tbody>
</table>

VÃ  khi chÃºng ta hoÃ n thÃ nh phÃ¢n tÃ­ch Pandas cá»§a mÃ¬nh, chÃºng ta luÃ´n cÃ³ thá»ƒ táº¡o má»™t Ä‘á»‘i tÆ°á»£ng `Dataset` má»›i báº±ng cÃ¡ch sá»­ dá»¥ng hÃ m `Dataset.from_pandas()` nhÆ° sau:

```py
from datasets import Dataset

freq_dataset = Dataset.from_pandas(frequencies)
freq_dataset
```

```python out
Dataset({
    features: ['condition', 'frequency'],
    num_rows: 819
})
```

<Tip>

âœï¸ **Thá»­ nghiá»‡m thÃ´i!** TÃ­nh xáº¿p háº¡ng trung bÃ¬nh cho má»—i loáº¡i thuá»‘c vÃ  lÆ°u trá»¯ káº¿t quáº£ á»Ÿ dáº¡ng `Dataset` má»›i.

</Tip>

Pháº§n nÃ y káº¿t thÃºc chuyáº¿n tham quan cá»§a chÃºng ta vá» cÃ¡c ká»¹ thuáº­t tiá»n xá»­ lÃ½ khÃ¡c nhau cÃ³ sáºµn trong ğŸ¤— Datasets. Äá»ƒ hoÃ n thiá»‡n pháº§n nÃ y, hÃ£y táº¡o má»™t tá»‡p kiá»ƒm Ä‘á»‹nh Ä‘á»ƒ chuáº©n bá»‹ táº­p dá»¯ liá»‡u cho viá»‡c huáº¥n luyá»‡n má»™t trÃ¬nh phÃ¢n loáº¡i. TrÆ°á»›c khi lÃ m nhÆ° váº­y, chÃºng ta sáº½ Ä‘áº·t láº¡i Ä‘á»‹nh dáº¡ng Ä‘áº§u ra cá»§a `drug_dataset` tá»« `"pandas"` thÃ nh `"arrow"`:

```python
drug_dataset.reset_format()
```

## Táº¡o ra má»™t tá»‡p kiá»ƒm Ä‘á»‹nh

Máº·c dÃ¹ chÃºng ta cÃ³ má»™t bá»™ dá»¯ liá»‡u kiá»ƒm thá»­ cÃ³ thá»ƒ sá»­ dá»¥ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡, nhÆ°ng báº¡n nÃªn giá»¯ nguyÃªn bá»™ kiá»ƒm thá»­ vÃ  táº¡o má»™t bá»™ kiá»ƒm Ä‘á»‹nh riÃªng trong quÃ¡ trÃ¬nh phÃ¡t triá»ƒn. Khi báº¡n hÃ i lÃ²ng vá»›i hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh cá»§a mÃ¬nh trÃªn bá»™ kiá»ƒm Ä‘á»‹nh, báº¡n cÃ³ thá»ƒ thá»±c hiá»‡n kiá»ƒm tra láº§n cuá»‘i Ä‘á»‘i vá»›i bá»™ kiá»ƒm thá»­. Quy trÃ¬nh nÃ y giÃºp giáº£m thiá»ƒu rá»§i ro ráº±ng báº¡n sáº½ trang bá»‹ quÃ¡ má»©c cho bá»™ kiá»ƒm thá»­ vÃ  triá»ƒn khai má»™t mÃ´ hÃ¬nh khÃ´ng thÃ nh cÃ´ng trÃªn dá»¯ liá»‡u trong tháº¿ giá»›i thá»±c.

ğŸ¤— Datasets cung cáº¥p má»™t hÃ m `Dataset.train_test_split()` dá»±a trÃªn tÃ­nh nÄƒng ná»•i tiáº¿ng tá»« `scikit-learn`. HÃ£y cÃ¹ng dÃ¹ng nÃ³ Ä‘á»ƒ chia táº­p huáº¥n luyá»‡n thÃ nh cÃ¡c táº­p `train` vÃ  `validation` (ta Ä‘áº·t tham sá»‘ `seed` cho má»¥c Ä‘Ã­nh tÃ¡i táº¡o):

```py
drug_dataset_clean = drug_dataset["train"].train_test_split(train_size=0.8, seed=42)
# Thay Ä‘á»•i tÃªn máº·c Ä‘á»‹nh "test" thÃ nh "validation"
drug_dataset_clean["validation"] = drug_dataset_clean.pop("test")
# ThÃªm "test" vÃ o `DatasetDict`
drug_dataset_clean["test"] = drug_dataset["test"]
drug_dataset_clean
```

```python out
DatasetDict({
    train: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'review_clean'],
        num_rows: 110811
    })
    validation: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'review_clean'],
        num_rows: 27703
    })
    test: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'review_clean'],
        num_rows: 46108
    })
})
```

Tuyá»‡t vá»i, ta hiá»‡n Ä‘Ã£ chuáº©n bá»‹ má»™t táº­p dá»¯ liá»‡u sáºµn sÃ ng Ä‘á»ƒ huáº¥n luyá»‡n má»™t sá»‘ mÃ´ hÃ¬nh! Trong [pháº§n 5](/course/chapter5/5), chÃºng tÃ´i sáº½ chá»‰ cho báº¡n cÃ¡ch táº£i táº­p dá»¯ liá»‡u lÃªn Hugging Face Hub, nhÆ°ng bÃ¢y giá» hÃ£y quen vá»›i phÃ¢n tÃ­ch cá»§a chÃºng tÃ´i báº±ng cÃ¡ch xem xÃ©t má»™t sá»‘ cÃ¡ch báº¡n cÃ³ thá»ƒ lÆ°u táº­p dá»¯ liá»‡u trÃªn mÃ¡y cá»¥c bá»™ cá»§a mÃ¬nh.

## LÆ°u má»™t bá»™ dá»¯ liá»‡u

<Youtube id="blF9uxYcKHo"/>

Máº·c dÃ¹ ğŸ¤— Datasets sáº½ lÆ°u vÃ o bá»™ nhá»› cache má»i táº­p dá»¯ liá»‡u Ä‘Ã£ táº£i xuá»‘ng vÃ  cÃ¡c hoáº¡t Ä‘á»™ng Ä‘Æ°á»£c thá»±c hiá»‡n trÃªn nÃ³, nhÆ°ng Ä‘Ã´i khi báº¡n sáº½ muá»‘n lÆ°u táº­p dá»¯ liá»‡u vÃ o Ä‘Ä©a (vÃ­ dá»¥: trong trÆ°á»ng há»£p bá»™ nhá»› cache bá»‹ xÃ³a). NhÆ° thá»ƒ hiá»‡n trong báº£ng bÃªn dÆ°á»›i, ğŸ¤— Datasets cung cáº¥p ba chá»©c nÄƒng chÃ­nh Ä‘á»ƒ lÆ°u táº­p dá»¯ liá»‡u cá»§a báº¡n á»Ÿ cÃ¡c Ä‘á»‹nh dáº¡ng khÃ¡c nhau:

| Äá»‹nh dáº¡ng dá»¯ liá»‡u |        HÃ m        |
| :---------: | :--------------------: |
|    Arrow    | `Dataset.save_to_disk()` |
|     CSV     |    `Dataset.to_csv()`    |
|    JSON     |   `Dataset.to_json()`    |

VÃ­ dá»¥, hÃ£y cÃ¹ng lÆ°u dá»¯ liá»‡u sáº¡ch cá»§a chÃºng ta vá» Ä‘á»‹nh dáº¡ng Arrow:

```py
drug_dataset_clean.save_to_disk("drug-reviews")
```

NÃ³ sáº½ táº¡o ra má»™t kho lÆ°u trá»¯ vá»›i cáº¥u trÃºc nhÆ° sau:

```
drug-reviews/
â”œâ”€â”€ dataset_dict.json
â”œâ”€â”€ test
â”‚   â”œâ”€â”€ dataset.arrow
â”‚   â”œâ”€â”€ dataset_info.json
â”‚   â””â”€â”€ state.json
â”œâ”€â”€ train
â”‚   â”œâ”€â”€ dataset.arrow
â”‚   â”œâ”€â”€ dataset_info.json
â”‚   â”œâ”€â”€ indices.arrow
â”‚   â””â”€â”€ state.json
â””â”€â”€ validation
    â”œâ”€â”€ dataset.arrow
    â”œâ”€â”€ dataset_info.json
    â”œâ”€â”€ indices.arrow
    â””â”€â”€ state.json
```

nÆ¡i chÃºng ta cÃ³ thá»ƒ tháº¥y ráº±ng má»—i pháº§n tÃ¡ch ra Ä‘Æ°á»£c liÃªn káº¿t vá»›i báº£ng *dataset.arrow* cá»§a riÃªng nÃ³ vÃ  má»™t sá»‘ siÃªu dá»¯ liá»‡u trong *dataset_info.json* vÃ  *state.json*. Báº¡n cÃ³ thá»ƒ coi Ä‘á»‹nh dáº¡ng Arrow nhÆ° má»™t báº£ng gá»“m cÃ¡c cá»™t vÃ  hÃ ng Æ°a thÃ­ch Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a Ä‘á»ƒ xÃ¢y dá»±ng cÃ¡c á»©ng dá»¥ng hiá»‡u suáº¥t cao xá»­ lÃ½ vÃ  váº­n chuyá»ƒn cÃ¡c táº­p dá»¯ liá»‡u lá»›n.

Sau khi táº­p dá»¯ liá»‡u Ä‘Æ°á»£c lÆ°u, chÃºng ta cÃ³ thá»ƒ táº£i nÃ³ báº±ng cÃ¡ch sá»­ dá»¥ng hÃ m `load_from_disk()` nhÆ° sau:

```py
from datasets import load_from_disk

drug_dataset_reloaded = load_from_disk("drug-reviews")
drug_dataset_reloaded
```

```python out
DatasetDict({
    train: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],
        num_rows: 110811
    })
    validation: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],
        num_rows: 27703
    })
    test: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],
        num_rows: 46108
    })
})
```
Äá»‘i vá»›i Ä‘á»‹nh dáº¡ng CSV vÃ  JSON, chÃºng ta pháº£i lÆ°u trá»¯ tá»«ng pháº§n thÃ nh má»™t tá»‡p riÃªng biá»‡t. Má»™t cÃ¡ch Ä‘á»ƒ lÃ m Ä‘iá»u nÃ y lÃ  láº·p láº¡i cÃ¡c khÃ³a vÃ  giÃ¡ trá»‹ trong Ä‘á»‘i tÆ°á»£ng `DatasetDict`:

```py
for split, dataset in drug_dataset_clean.items():
    dataset.to_json(f"drug-reviews-{split}.jsonl")
```

NÃ³ sáº½ lÆ°u má»—i pháº§n dá»¯ liá»‡u vÃ o[Ä‘á»‹nh dáº¡ng JSON Lines](https://jsonlines.org), nÆ¡i má»—i dÃ²ng trong bá»™ dá»¯ liá»‡u Ä‘Æ°á»£c lÆ°u trá»¯ trÃªn má»™t dÃ²ng JSON. ÄÃ¢y lÃ  má»™t vÃ­ dá»¥ vá» hÃ¬nh hÃ i cua nÃ³:

```py
!head -n 1 drug-reviews-train.jsonl
```

```python out
{"patient_id":141780,"drugName":"Escitalopram","condition":"depression","review":"\"I seemed to experience the regular side effects of LEXAPRO, insomnia, low sex drive, sleepiness during the day. I am taking it at night because my doctor said if it made me tired to take it at night. I assumed it would and started out taking it at night. Strange dreams, some pleasant. I was diagnosed with fibromyalgia. Seems to be helping with the pain. Have had anxiety and depression in my family, and have tried quite a few other medications that haven't worked. Only have been on it for two weeks but feel more positive in my mind, want to accomplish more in my life. Hopefully the side effects will dwindle away, worth it to stick with it from hearing others responses. Great medication.\"","rating":9.0,"date":"May 29, 2011","usefulCount":10,"review_length":125}
```

ChÃºng ta sau Ä‘Ã³ cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t trong [pháº§n 2](/course/chapter5/2) Ä‘á»ƒ táº£i tá»‡p JSON nhÆ° sau:

```py
data_files = {
    "train": "drug-reviews-train.jsonl",
    "validation": "drug-reviews-validation.jsonl",
    "test": "drug-reviews-test.jsonl",
}
drug_dataset_reloaded = load_dataset("json", data_files=data_files)
```

VÃ  Ä‘Ã³ lÃ  nÃ³ cho chuyáº¿n du ngoáº¡n cá»§a chÃºng ta vá»›i sáº¯p xáº¿p dá»¯ liá»‡u sá»­ dá»¥ng ğŸ¤— Datasets! Giá» ta Ä‘Ã£ cÃ³ má»™t táº­p dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c lÃ m sáº¡ch Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh, Ä‘Ã¢y lÃ  má»™t vÃ i Ã½ tÆ°á»Ÿng mÃ  báº¡n cÃ³ thá»ƒ thá»­:

1. Sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t tá»« [ChÆ°Æ¡ng 3](/course/chapter3) Ä‘á»ƒ huáº¥n luyá»‡n má»™t bá»™ phÃ¢n loáº¡i cÃ³ thá»ƒ dá»± Ä‘oÃ¡n tÃ¬nh tráº¡ng bá»‡nh nhÃ¢n dá»±a trÃªn cÃ¡c pháº£n há»“i vá» thuá»‘c.
2. Sá»­ dá»¥ng pipeline `summarization` tá»« [ChÆ°Æ¡ng 1](/course/chapter1) Ä‘á»ƒ táº¡o cÃ¡c báº£n tÃ³m táº¯t cÃ¡c bÃ i Ä‘Ã¡nh giÃ¡.

Tiáº¿p theo, chÃºng ta sáº½ xem xÃ©t cÃ¡ch ğŸ¤— Datasets cÃ³ thá»ƒ cho phÃ©p báº¡n lÃ m viá»‡c vá»›i nhá»¯ng táº­p dá»¯ liá»‡u khá»•ng lá»“ mÃ  khÃ´ng lÃ m há»ng mÃ¡y tÃ­nh xÃ¡ch tay cá»§a báº¡n!
