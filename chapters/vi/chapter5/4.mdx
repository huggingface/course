# D·ªØ li·ªáu l·ªõn? ü§ó B·ªô d·ªØ li·ªáu ƒë·ªÉ gi·∫£i c·ª©u!

<CourseFloatingBanner chapter={5}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {
      label: "Google Colab",
      value:
        "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/vi/chapter5/section4.ipynb",
    },
    {
      label: "Aws Studio",
      value:
        "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/vi/chapter5/section4.ipynb",
    },
  ]}
/>

Ng√†y nay, kh√¥ng c√≥ g√¨ l·∫° khi b·∫°n ƒëang l√†m vi·ªác v·ªõi c√°c b·ªô d·ªØ li·ªáu nhi·ªÅu gigabyte, ƒë·∫∑c bi·ªát n·∫øu b·∫°n ƒëang c√≥ k·∫ø ho·∫°ch hu·∫•n luy·ªán tr∆∞·ªõc m·ªôt m√¥ h√¨nh Transformer nh∆∞ BERT ho·∫∑c GPT-2 t·ª´ ƒë·∫ßu. Trong nh·ªØng tr∆∞·ªùng h·ª£p n√†y, th·∫≠m ch√≠ _t·∫£i_ d·ªØ li·ªáu c√≥ th·ªÉ l√† m·ªôt th√°ch th·ª©c. V√≠ d·ª•: kho d·ªØ li·ªáu WebText ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ hu·∫•n luy·ªán tr∆∞·ªõc GPT-2 bao g·ªìm h∆°n 8 tri·ªáu t√†i li·ªáu v√† 40 GB vƒÉn b·∫£n - vi·ªác t·∫£i d·ªØ li·ªáu n√†y v√†o RAM c·ªßa m√°y t√≠nh x√°ch tay c·ªßa b·∫°n c√≥ th·ªÉ khi·∫øn b·∫°n b·ªã ƒëau tim!

May m·∫Øn thay, ü§ó Datasets ƒë√£ ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ kh·∫Øc ph·ª•c nh·ªØng h·∫°n ch·∫ø n√†y. N√≥ gi·∫£i ph√≥ng b·∫°n kh·ªèi c√°c v·∫•n ƒë·ªÅ v·ªÅ qu·∫£n l√Ω b·ªô nh·ªõ b·∫±ng c√°ch coi c√°c t·∫≠p d·ªØ li·ªáu l√† t·ªáp _√°nh x·∫° b·ªô nh·ªõ_ v√† tho√°t kh·ªèi gi·ªõi h·∫°n ·ªï c·ª©ng b·∫±ng c√°ch _truy·ªÅn t·∫£i tr·ª±c ti·∫øp_ c√°c m·ª•c trong m·ªôt kho ng·ªØ li·ªáu.

<Youtube id="JwISwTCPPWo" />

Trong ph·∫ßn n√†y, ch√∫ng ta s·∫Ω kh√°m ph√° c√°c t√≠nh nƒÉng n√†y c·ªßa ü§ó Datasets v·ªõi kho d·ªØ li·ªáu 825 GB kh·ªïng l·ªì ƒë∆∞·ª£c g·ªçi l√† [Pile](https://pile.eleuther.ai). B·∫Øt ƒë·∫ßu th√¥i!

## Pile l√† g√¨?

The Pile l√† m·ªôt kho ng·ªØ li·ªáu ti·∫øng Anh ƒë∆∞·ª£c t·∫°o ra b·ªüi [EleutherAI](https://www.eleuther.ai) ƒë·ªÉ hu·∫•n luy·ªán c√°c m√¥ h√¨nh ng√¥n ng·ªØ quy m√¥ l·ªõn. N√≥ bao g·ªìm m·ªôt lo·∫°t c√°c b·ªô d·ªØ li·ªáu, c√°c b√†i b√°o khoa h·ªçc tr·∫£i d√†i, kho m√£ GitHub v√† vƒÉn b·∫£n web ƒë∆∞·ª£c l·ªçc. Kho t√†i li·ªáu hu·∫•n luy·ªán c√≥ s·∫µn trong [kh·ªëi 14GB](https://the-eye.eu/public/AI/pile/) v√† b·∫°n c≈©ng c√≥ th·ªÉ t·∫£i xu·ªëng m·ªôt s·ªë [th√†nh ph·∫ßn ri√™ng l·∫ª](https://the-eye.eu/public/AI/pile_preliminary_components/). H√£y b·∫Øt ƒë·∫ßu b·∫±ng c√°ch xem qua t·∫≠p d·ªØ li·ªáu PubMed Abstracts, t·∫≠p d·ªØ li·ªáu t√≥m t·∫Øt t·ª´ 15 tri·ªáu ·∫•n ph·∫©m y sinh tr√™n [PubMed](https://pubmed.ncbi.nlm.nih.gov/). T·∫≠p d·ªØ li·ªáu ·ªü [ƒë·ªãnh d·∫°ng JSON Lines](https://jsonlines.org) v√† ƒë∆∞·ª£c n√©n b·∫±ng th∆∞ vi·ªán `zstandard`, v√¨ v·∫≠y tr∆∞·ªõc ti√™n ch√∫ng ta c·∫ßn c√†i ƒë·∫∑t:

```py
!pip install zstandard
```

Ti·∫øp theo, ch√∫ng ta c√≥ th·ªÉ t·∫£i t·∫≠p d·ªØ li·ªáu b·∫±ng ph∆∞∆°ng ph√°p cho c√°c t·ªáp t·ª´ xa m√† ch√∫ng ta ƒë√£ h·ªçc trong [ph·∫ßn 2](/course/chapter5/2):

```py
from datasets import load_dataset

# Qu√° tr√¨nh n√†y m·∫•t m·ªôt v√†i ph√∫t ƒë·ªÉ ch·∫°y, v√¨ v·∫≠y h√£y l√†m c·ªëc tr√† ho·∫∑c c√† ph√™ trong khi ch·ªù ƒë·ª£i :)
data_files = "https://the-eye.eu/public/AI/pile_preliminary_components/PUBMED_title_abstracts_2019_baseline.jsonl.zst"
pubmed_dataset = load_dataset("json", data_files=data_files, split="train")
pubmed_dataset
```

```python out
Dataset({
    features: ['meta', 'text'],
    num_rows: 15518009
})
```

Ch√∫ng ta c√≥ th·ªÉ th·∫•y r·∫±ng c√≥ 15,518,009 h√†ng v√† 2 c·ªôt trong t·∫≠p d·ªØ li·ªáu c·ªßa ch√∫ng t√¥i - ƒë√≥ l√† r·∫•t nhi·ªÅu!

> [!TIP]
> ‚úé Theo m·∫∑c ƒë·ªãnh, ü§ó Datasets s·∫Ω gi·∫£i n√©n c√°c t·ªáp c·∫ßn thi·∫øt ƒë·ªÉ t·∫£i t·∫≠p d·ªØ li·ªáu. N·∫øu b·∫°n mu·ªën b·∫£o to√†n dung l∆∞·ª£ng ·ªï c·ª©ng, b·∫°n c√≥ th·ªÉ truy·ªÅn `DownloadConfig(delete_extracted=True)` v√†o tham s·ªë `download_config` c·ªßa `load_dataset()`. Xem [t√†i li·ªáu](https://huggingface.co/docs/datasets/package_reference/builder_classes#datasets.DownloadConfig) ƒë·ªÉ bi·∫øt th√™m chi ti·∫øt.

H√£y ki·ªÉm tra n·ªôi dung c·ªßa m·∫´u ƒë·∫ßu ti√™n:

```py
pubmed_dataset[0]
```

```python out
{'meta': {'pmid': 11409574, 'language': 'eng'},
 'text': 'Epidemiology of hypoxaemia in children with acute lower respiratory infection.\nTo determine the prevalence of hypoxaemia in children aged under 5 years suffering acute lower respiratory infections (ALRI), the risk factors for hypoxaemia in children under 5 years of age with ALRI, and the association of hypoxaemia with an increased risk of dying in children of the same age ...'}
```

ƒê∆∞·ª£c r·ªìi, ƒë√¢y gi·ªëng nh∆∞ ph·∫ßn t√≥m t·∫Øt t·ª´ m·ªôt b√†i b√°o y khoa. B√¢y gi·ªù ch√∫ng ta h√£y xem ch√∫ng ta ƒë√£ s·ª≠ d·ª•ng bao nhi√™u RAM ƒë·ªÉ t·∫£i t·∫≠p d·ªØ li·ªáu!

## S·ª± k·ª≥ di·ªáu c·ªßa √°nh x·∫° b·ªô nh·ªõ

M·ªôt c√°ch ƒë∆°n gi·∫£n ƒë·ªÉ ƒëo m·ª©c s·ª≠ d·ª•ng b·ªô nh·ªõ trong Python l√† s·ª≠ d·ª•ng th∆∞ vi·ªán [`psutil`](https://psutil.readthedocs.io/en/latest/), c√≥ th·ªÉ ƒë∆∞·ª£c c√†i ƒë·∫∑t b·∫±ng `pip` nh∆∞ sau:

```python
!pip install psutil
```

N√≥ cung c·∫•p m·ªôt l·ªõp `Process` cho ph√©p ch√∫ng ta ki·ªÉm tra vi·ªác s·ª≠ d·ª•ng b·ªô nh·ªõ c·ªßa ti·∫øn tr√¨nh hi·ªán t·∫°i nh∆∞ sau:

```py
import psutil

# Process.memory_info ƒë∆∞·ª£c bi·ªÉu th·ªã b·∫±ng bytes, sau ƒë√≥ chuy·ªÉn sang megabytes
print(f"RAM used: {psutil.Process().memory_info().rss / (1024 * 1024):.2f} MB")
```

```python out
RAM used: 5678.33 MB
```

·ªû ƒë√¢y thu·ªôc t√≠nh `rss` ƒë·ªÅ c·∫≠p ƒë·∫øn _resident set size_, l√† ph·∫ßn b·ªô nh·ªõ m√† m·ªôt ti·∫øn tr√¨nh chi·∫øm trong RAM. Ph√©p ƒëo n√†y c≈©ng bao g·ªìm b·ªô nh·ªõ ƒë∆∞·ª£c s·ª≠ d·ª•ng b·ªüi tr√¨nh th√¥ng d·ªãch Python v√† c√°c th∆∞ vi·ªán m√† ch√∫ng t√¥i ƒë√£ t·∫£i, do ƒë√≥, l∆∞·ª£ng b·ªô nh·ªõ th·ª±c t·∫ø ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ t·∫£i t·∫≠p d·ªØ li·ªáu nh·ªè h∆°n m·ªôt ch√∫t. ƒê·ªÉ so s√°nh, h√£y xem t·∫≠p d·ªØ li·ªáu tr√™n ƒëƒ©a l·ªõn nh∆∞ th·∫ø n√†o, s·ª≠ d·ª•ng thu·ªôc t√≠nh `dataset_size`. V√¨ k·∫øt qu·∫£ ƒë∆∞·ª£c th·ªÉ hi·ªán b·∫±ng byte nh∆∞ tr∆∞·ªõc ƒë√¢y, ch√∫ng t√¥i c·∫ßn chuy·ªÉn ƒë·ªïi th·ªß c√¥ng n√≥ th√†nh gigabyte:

```py
print(f"Number of files in dataset : {pubmed_dataset.dataset_size}")
size_gb = pubmed_dataset.dataset_size / (1024**3)
print(f"Dataset size (cache file) : {size_gb:.2f} GB")
```

```python out
Number of files in dataset : 20979437051
Dataset size (cache file) : 19.54 GB
```

Tuy·ªát v·ªùi - m·∫∑c d√π n√≥ g·∫ßn 20 GB, ch√∫ng ta c√≥ th·ªÉ t·∫£i v√† truy c·∫≠p t·∫≠p d·ªØ li·ªáu v·ªõi RAM √≠t h∆°n nhi·ªÅu!

> [!TIP]
> ‚úèÔ∏è **Th·ª≠ nghi·ªám th√¥i!** Ch·ªçn m·ªôt trong c√°c [t·∫≠p h·ª£p con](https://the-eye.eu/public/AI/pile_preliminary_components/) t·ª´ Pile sao cho l·ªõn h∆°n RAM c·ªßa m√°y t√≠nh x√°ch tay ho·∫∑c m√°y t√≠nh ƒë·ªÉ b√†n c·ªßa b·∫°n, t·∫£i n√≥ v·ªõi ü§ó Datasets, v√† ƒëo dung l∆∞·ª£ng RAM ƒë∆∞·ª£c s·ª≠ d·ª•ng. L∆∞u √Ω r·∫±ng ƒë·ªÉ c√≥ ƒë∆∞·ª£c m·ªôt ph√©p ƒëo ch√≠nh x√°c, b·∫°n s·∫Ω mu·ªën th·ª±c hi·ªán vi·ªác n√†y trong m·ªôt quy tr√¨nh m·ªõi. B·∫°n c√≥ th·ªÉ t√¨m th·∫•y c√°c k√≠ch th∆∞·ªõc ƒë√£ gi·∫£i n√©n c·ªßa t·ª´ng t·∫≠p h·ª£p con trong B·∫£ng 1 c·ªßa [b√†i b√°o v·ªÅ Pile](https://arxiv.org/abs/2101.00027).

N·∫øu b·∫°n ƒë√£ quen thu·ªôc v·ªõi Pandas, k·∫øt qu·∫£ n√†y c√≥ th·ªÉ g√¢y b·∫•t ng·ªù v√¨ theo [quy t·∫Øc ng√≥n tay c√°i](https://wesmckinney.com/blog/apache-arrow-pandas-internals/) n·ªïi ti·∫øng c·ªßa Wes Kinney, b·∫°n th∆∞·ªùng c·∫ßn g·∫•p 5 g·∫•p 10 l·∫ßn RAM so v·ªõi k√≠ch th∆∞·ªõc c·ªßa t·∫≠p d·ªØ li·ªáu c·ªßa b·∫°n. V·∫≠y ü§ó Datasets gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ qu·∫£n l√Ω b·ªô nh·ªõ n√†y nh∆∞ th·∫ø n√†o? ü§ó Datasets coi m·ªói t·∫≠p d·ªØ li·ªáu nh∆∞ m·ªôt [t·ªáp √°nh x·∫° b·ªô nh·ªõ](https://en.wikipedia.org/wiki/Memory-mapped_file), cung c·∫•p √°nh x·∫° gi·ªØa RAM v√† b·ªô nh·ªõ h·ªá th·ªëng t·ªáp cho ph√©p th∆∞ vi·ªán truy c·∫≠p v√† ho·∫°t ƒë·ªông tr√™n c√°c ph·∫ßn t·ª≠ c·ªßa t·∫≠p d·ªØ li·ªáu m√† kh√¥ng c·∫ßn t·∫£i ƒë·∫ßy ƒë·ªß v√†o b·ªô nh·ªõ.

C√°c t·ªáp ƒë∆∞·ª£c √°nh x·∫° b·ªô nh·ªõ c≈©ng c√≥ th·ªÉ ƒë∆∞·ª£c chia s·∫ª tr√™n nhi·ªÅu quy tr√¨nh, cho ph√©p c√°c ph∆∞∆°ng th·ª©c nh∆∞ `Dataset.map()` ƒë∆∞·ª£c th·ª±c thi song song m√† kh√¥ng c·∫ßn di chuy·ªÉn ho·∫∑c sao ch√©p t·∫≠p d·ªØ li·ªáu. B√™n c·∫°nh ƒë√≥, t·∫•t c·∫£ c√°c kh·∫£ nƒÉng n√†y ƒë·ªÅu ƒë∆∞·ª£c th·ª±c hi·ªán b·ªüi ƒë·ªãnh d·∫°ng b·ªô nh·ªõ [Apache Arrow](https://arrow.apache.org) v√† th∆∞ vi·ªán[`pyarrow`](https://arrow.apache.org/docs/python/index.html), gi√∫p t·∫£i v√† x·ª≠ l√Ω d·ªØ li·ªáu nhanh nh∆∞ ch·ªõp. (ƒê·ªÉ bi·∫øt th√™m chi ti·∫øt v·ªÅ Apache Arrow v√† so s√°nh v·ªõi Pandas, h√£y xem [B√†i ƒëƒÉng tr√™n blog c·ªßa Dejan Simic](https://towardsdatascience.com/apache-arrow-read-dataframe-with-zero-memory-69634092b1a).) trong th·ª±c t·∫ø, h√£y ch·∫°y m·ªôt b√†i ki·ªÉm tra t·ªëc ƒë·ªô nh·ªè b·∫±ng c√°ch l·∫∑p l·∫°i t·∫•t c·∫£ c√°c ph·∫ßn t·ª≠ trong t·∫≠p d·ªØ li·ªáu PubMed Abstracts:

```py
import timeit

code_snippet = """batch_size = 1000

for idx in range(0, len(pubmed_dataset), batch_size):
    _ = pubmed_dataset[idx:idx + batch_size]
"""

time = timeit.timeit(stmt=code_snippet, number=1, globals=globals())
print(
    f"Iterated over {len(pubmed_dataset)} examples (about {size_gb:.1f} GB) in "
    f"{time:.1f}s, i.e. {size_gb/time:.3f} GB/s"
)
```

```python out
'Iterated over 15518009 examples (about 19.5 GB) in 64.2s, i.e. 0.304 GB/s'
```

·ªû ƒë√¢y ch√∫ng ta ƒë√£ s·ª≠ d·ª•ng m√¥-ƒëun `timeit` c·ªßa Python ƒë·ªÉ ƒëo th·ªùi gian th·ª±c thi ƒë∆∞·ª£c th·ª±c hi·ªán b·ªüi `code_snippet`. Th√¥ng th∆∞·ªùng, b·∫°n s·∫Ω c√≥ th·ªÉ l·∫∑p l·∫°i t·∫≠p d·ªØ li·ªáu v·ªõi t·ªëc ƒë·ªô t·ª´ v√†i ph·∫ßn m∆∞·ªùi GB/s ƒë·∫øn v√†i GB/s. ƒêi·ªÅu n√†y ho·∫°t ƒë·ªông hi·ªáu qu·∫£ v·ªõi ƒë·∫°i ƒëa s·ªë c√°c ·ª©ng d·ª•ng, nh∆∞ng ƒë√¥i khi b·∫°n s·∫Ω ph·∫£i l√†m vi·ªác v·ªõi m·ªôt t·∫≠p d·ªØ li·ªáu qu√° l·ªõn, th·∫≠m ch√≠ kh√¥ng th·ªÉ l∆∞u tr·ªØ tr√™n ·ªï c·ª©ng c·ªßa m√°y t√≠nh x√°ch tay c·ªßa b·∫°n. V√≠ d·ª•: n·∫øu ch√∫ng t√¥i c·ªë g·∫Øng t·∫£i xu·ªëng to√†n b·ªô Pile, ch√∫ng t√¥i s·∫Ω c·∫ßn 825 GB dung l∆∞·ª£ng ƒëƒ©a tr·ªëng! ƒê·ªÉ x·ª≠ l√Ω nh·ªØng tr∆∞·ªùng h·ª£p n√†y, ü§ó Datasets cung c·∫•p t√≠nh nƒÉng ph√°t tr·ª±c tuy·∫øn cho ph√©p ch√∫ng t√¥i t·∫£i xu·ªëng v√† truy c·∫≠p c√°c ph·∫ßn t·ª≠ m·ªôt c√°ch nhanh ch√≥ng m√† kh√¥ng c·∫ßn t·∫£i xu·ªëng to√†n b·ªô t·∫≠p d·ªØ li·ªáu. Ch√∫ng ta h√£y xem c√°ch n√†y ho·∫°t ƒë·ªông nh∆∞ th·∫ø n√†o.

> [!TIP]
> üí° Trong s·ªï ghi ch√©p Jupyter, b·∫°n c√≥ th·ªÉ ƒë·ªãnh th·ªùi gian cho c√°c √¥ b·∫±ng c√°ch s·ª≠ d·ª•ng[h√†m ma thu·∫≠t `%%timeit`](https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-timeit).

## Truy·ªÅn tr·ª±c tuy·∫øn t·∫≠p d·ªØ li·ªáu

ƒê·ªÉ b·∫≠t t√≠nh nƒÉng ph√°t tr·ª±c tuy·∫øn t·∫≠p d·ªØ li·ªáu, b·∫°n ch·ªâ c·∫ßn truy·ªÅn tham s·ªë `streaming=True` v√†o h√†m `load_dataset()`. V√≠ d·ª•: h√£y t·∫£i l·∫°i t·∫≠p d·ªØ li·ªáu PubMed Abstracts, nh∆∞ng ·ªü ch·∫ø ƒë·ªô ph√°t tr·ª±c tuy·∫øn:

```py
pubmed_dataset_streamed = load_dataset(
    "json", data_files=data_files, split="train", streaming=True
)
```

Thay v√¨ `Dataset` quen thu·ªôc m√† ch√∫ng ta ƒë√£ g·∫∑p ·ªü nh·ªØng n∆°i kh√°c trong ch∆∞∆°ng n√†y, ƒë·ªëi t∆∞·ª£ng ƒë∆∞·ª£c tr·∫£ v·ªÅ v·ªõi `streaming=True` l√† m·ªôt `IterableDataset`. Nh∆∞ c√°i t√™n cho th·∫•y, ƒë·ªÉ truy c·∫≠p c√°c ph·∫ßn t·ª≠ c·ªßa m·ªôt `IterableDataset`, ch√∫ng ta c·∫ßn ph·∫£i l·∫∑p l·∫°i n√≥. Ch√∫ng t√¥i c√≥ th·ªÉ truy c·∫≠p ph·∫ßn t·ª≠ ƒë·∫ßu ti√™n c·ªßa t·∫≠p d·ªØ li·ªáu ƒë∆∞·ª£c ph√°t tr·ª±c tuy·∫øn c·ªßa ch√∫ng t√¥i nh∆∞ sau:

```py
next(iter(pubmed_dataset_streamed))
```

```python out
{'meta': {'pmid': 11409574, 'language': 'eng'},
 'text': 'Epidemiology of hypoxaemia in children with acute lower respiratory infection.\nTo determine the prevalence of hypoxaemia in children aged under 5 years suffering acute lower respiratory infections (ALRI), the risk factors for hypoxaemia in children under 5 years of age with ALRI, and the association of hypoxaemia with an increased risk of dying in children of the same age ...'}
```

C√°c ph·∫ßn t·ª≠ t·ª´ m·ªôt t·∫≠p d·ªØ li·ªáu ƒë∆∞·ª£c truy·ªÅn tr·ª±c tuy·∫øn c√≥ th·ªÉ ƒë∆∞·ª£c x·ª≠ l√Ω nhanh ch√≥ng b·∫±ng c√°ch s·ª≠ d·ª•ng `IterableDataset.map()`, r·∫•t h·ªØu √≠ch trong qu√° tr√¨nh hu·∫•n luy·ªán n·∫øu b·∫°n c·∫ßn tokenize c√°c ƒë·∫ßu v√†o. Quy tr√¨nh ho√†n to√†n gi·ªëng v·ªõi quy tr√¨nh ch√∫ng ta ƒë√£ s·ª≠ d·ª•ng ƒë·ªÉ tokenize t·∫≠p d·ªØ li·ªáu c·ªßa m√¨nh trong [Ch∆∞∆°ng 3](/course/chapter3), v·ªõi s·ª± kh√°c bi·ªát duy nh·∫•t l√† c√°c ƒë·∫ßu ra ƒë∆∞·ª£c tr·∫£ v·ªÅ t·ª´ng c√°i m·ªôt:

```py
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased")
tokenized_dataset = pubmed_dataset_streamed.map(lambda x: tokenizer(x["text"]))
next(iter(tokenized_dataset))
```

```python out
{'input_ids': [101, 4958, 5178, 4328, 6779, ...], 'attention_mask': [1, 1, 1, 1, 1, ...]}
```

> [!TIP]
> üí° ƒê·ªÉ tƒÉng t·ªëc ƒë·ªô tr√¨nh tokenize v·ªõi t√≠nh nƒÉng ph√°t tr·ª±c tuy·∫øn, b·∫°n c√≥ th·ªÉ v∆∞·ª£t qua `batched=True`, nh∆∞ ch√∫ng ta ƒë√£ th·∫•y trong ph·∫ßn tr∆∞·ªõc. N√≥ s·∫Ω x·ª≠ l√Ω h√†ng lo·∫°t c√°c v√≠ d·ª•; k√≠ch th∆∞·ªõc l√¥ m·∫∑c ƒë·ªãnh l√† 1,000 v√† c√≥ th·ªÉ ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh b·∫±ng tham s·ªë `batch_size`.

B·∫°n c≈©ng c√≥ th·ªÉ x√°o tr·ªôn m·ªôt t·∫≠p d·ªØ li·ªáu ƒë∆∞·ª£c ph√°t tr·ª±c tuy·∫øn b·∫±ng c√°ch s·ª≠ d·ª•ng `IterableDataset.shuffle()`, nh∆∞ng kh√¥ng gi·ªëng nh∆∞ `Dataset.shuffle()` ƒëi·ªÅu n√†y ch·ªâ x√°o tr·ªôn c√°c ph·∫ßn t·ª≠ trong m·ªôt `buffer_size` ƒë∆∞·ª£c ƒë·ªãnh tr∆∞·ªõc:

```py
shuffled_dataset = pubmed_dataset_streamed.shuffle(buffer_size=10_000, seed=42)
next(iter(shuffled_dataset))
```

```python out
{'meta': {'pmid': 11410799, 'language': 'eng'},
 'text': 'Randomized study of dose or schedule modification of granulocyte colony-stimulating factor in platinum-based chemotherapy for elderly patients with lung cancer ...'}
```

Trong v√≠ d·ª• n√†y, ch√∫ng ta ƒë√£ ch·ªçn m·ªôt m·∫´u ng·∫´u nhi√™n t·ª´ 10,000 m·∫´u ƒë·∫ßu ti√™n trong b·ªô ƒë·ªám. Khi m·ªôt m·∫´u ƒë∆∞·ª£c truy c·∫≠p, v·ªã tr√≠ c·ªßa n√≥ trong b·ªô ƒë·ªám s·∫Ω ƒë∆∞·ª£c l·∫•p ƒë·∫ßy b·∫±ng v√≠ d·ª• ti·∫øp theo trong kho t√†i li·ªáu (t·ª©c l√† v√≠ d·ª• th·ª© 10,001 trong tr∆∞·ªùng h·ª£p tr√™n). B·∫°n c≈©ng c√≥ th·ªÉ ch·ªçn c√°c ph·∫ßn t·ª≠ t·ª´ m·ªôt t·∫≠p d·ªØ li·ªáu ƒë∆∞·ª£c truy·ªÅn tr·ª±c tuy·∫øn b·∫±ng c√°ch s·ª≠ d·ª•ng c√°c h√†m `IterableDataset.take()` v√† `IterableDataset.skip()`, ho·∫°t ƒë·ªông theo c√°ch t∆∞∆°ng t·ª± nh∆∞ `Dataset.select()`. V√≠ d·ª•, ƒë·ªÉ ch·ªçn 5 m·∫´u ƒë·∫ßu ti√™n trong t·∫≠p d·ªØ li·ªáu PubMed Abstracts, ch√∫ng ta c√≥ th·ªÉ l√†m nh∆∞ sau:

```py
dataset_head = pubmed_dataset_streamed.take(5)
list(dataset_head)
```

```python out
[{'meta': {'pmid': 11409574, 'language': 'eng'},
  'text': 'Epidemiology of hypoxaemia in children with acute lower respiratory infection ...'},
 {'meta': {'pmid': 11409575, 'language': 'eng'},
  'text': 'Clinical signs of hypoxaemia in children with acute lower respiratory infection: indicators of oxygen therapy ...'},
 {'meta': {'pmid': 11409576, 'language': 'eng'},
  'text': "Hypoxaemia in children with severe pneumonia in Papua New Guinea ..."},
 {'meta': {'pmid': 11409577, 'language': 'eng'},
  'text': 'Oxygen concentrators and cylinders ...'},
 {'meta': {'pmid': 11409578, 'language': 'eng'},
  'text': 'Oxygen supply in rural africa: a personal experience ...'}]
```

T∆∞∆°ng t·ª±, b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng h√†m `IterableDataset.skip()` ƒë·ªÉ t·∫°o c√°c t·∫≠p hu·∫•n luy·ªán v√† ki·ªÉm ƒë·ªãnh t·ª´ m·ªôt t·∫≠p d·ªØ li·ªáu x√°o tr·ªôn nh∆∞ sau:

```py
# B·ªè qua 1,000 m·∫´u ƒë·∫ßu ti√™n v√† ƒë∆∞a ph·∫ßn c√≤n l·∫°i v√†o t·∫≠p hu·∫•n luy·ªán
train_dataset = shuffled_dataset.skip(1000)
# L·∫•y 1,000 v√≠ d·ª• ƒë·∫ßu ti√™n cho t·∫≠p ki·ªÉm ƒë·ªãnh
validation_dataset = shuffled_dataset.take(1000)
```

H√£y ho√†n th√†nh vi·ªác kh√°m ph√° c·ªßa ch√∫ng ta v·ªÅ vi·ªác truy·ªÅn tr·ª±c tuy·∫øn t·∫≠p d·ªØ li·ªáu v·ªõi m·ªôt ·ª©ng d·ª•ng ph·ªï bi·∫øn: k·∫øt h·ª£p nhi·ªÅu t·∫≠p d·ªØ li·ªáu v·ªõi nhau ƒë·ªÉ t·∫°o ra m·ªôt kho d·ªØ li·ªáu duy nh·∫•t. ü§ó Datasets cung c·∫•p m·ªôt h√†m `interleave_datasets()` ƒë·ªÉ chuy·ªÉn ƒë·ªïi danh s√°ch c√°c ƒë·ªëi t∆∞·ª£ng `IterableDataset` th√†nh m·ªôt `IterableDataset` duy nh·∫•t, trong ƒë√≥ c√°c ph·∫ßn t·ª≠ c·ªßa t·∫≠p d·ªØ li·ªáu m·ªõi ƒë∆∞·ª£c l·∫•y b·∫±ng c√°ch xen k·∫Ω gi·ªØa c√°c m·∫´u g·ªëc. H√†m n√†y ƒë·∫∑c bi·ªát h·ªØu √≠ch khi b·∫°n ƒëang c·ªë g·∫Øng k·∫øt h·ª£p c√°c t·∫≠p d·ªØ li·ªáu l·ªõn, v√¨ v·∫≠y, ƒë·ªÉ l√†m v√≠ d·ª•, h√£y truy·ªÅn tr·ª±c tuy·∫øn t·∫≠p con FreeLaw c·ªßa Pile, l√† t·∫≠p d·ªØ li·ªáu 51 GB v·ªÅ c√°c √Ω ki·∫øn ph√°p l√Ω t·ª´ c√°c t√≤a √°n Hoa K·ª≥:

```py
law_dataset_streamed = load_dataset(
    "json",
    data_files="https://the-eye.eu/public/AI/pile_preliminary_components/FreeLaw_Opinions.jsonl.zst",
    split="train",
    streaming=True,
)
next(iter(law_dataset_streamed))
```

```python out
{'meta': {'case_ID': '110921.json',
  'case_jurisdiction': 'scotus.tar.gz',
  'date_created': '2010-04-28T17:12:49Z'},
 'text': '\n461 U.S. 238 (1983)\nOLIM ET AL.\nv.\nWAKINEKONA\nNo. 81-1581.\nSupreme Court of United States.\nArgued January 19, 1983.\nDecided April 26, 1983.\nCERTIORARI TO THE UNITED STATES COURT OF APPEALS FOR THE NINTH CIRCUIT\n*239 Michael A. Lilly, First Deputy Attorney General of Hawaii, argued the cause for petitioners. With him on the brief was James H. Dannenberg, Deputy Attorney General...'}
```

T·∫≠p d·ªØ li·ªáu n√†y ƒë·ªß l·ªõn ƒë·ªÉ k√≠ch ho·∫°t RAM c·ªßa h·∫ßu h·∫øt c√°c m√°y t√≠nh x√°ch tay, nh∆∞ng ch√∫ng ta v·∫´n c√≥ th·ªÉ t·∫£i v√† truy c·∫≠p n√≥ m√† kh√¥ng ph·∫£i ƒë·ªï m·ªì h√¥i! B√¢y gi·ªù ch√∫ng ta h√£y k·∫øt h·ª£p c√°c m·∫´u t·ª´ b·ªô d·ªØ li·ªáu FreeLaw v√† PubMed Abstracts v·ªõi h√†m `interleave_datasets()`:

```py
from itertools import islice
from datasets import interleave_datasets

combined_dataset = interleave_datasets([pubmed_dataset_streamed, law_dataset_streamed])
list(islice(combined_dataset, 2))
```

```python out
[{'meta': {'pmid': 11409574, 'language': 'eng'},
  'text': 'Epidemiology of hypoxaemia in children with acute lower respiratory infection ...'},
 {'meta': {'case_ID': '110921.json',
   'case_jurisdiction': 'scotus.tar.gz',
   'date_created': '2010-04-28T17:12:49Z'},
  'text': '\n461 U.S. 238 (1983)\nOLIM ET AL.\nv.\nWAKINEKONA\nNo. 81-1581.\nSupreme Court of United States.\nArgued January 19, 1983.\nDecided April 26, 1983.\nCERTIORARI TO THE UNITED STATES COURT OF APPEALS FOR THE NINTH CIRCUIT\n*239 Michael A. Lilly, First Deputy Attorney General of Hawaii, argued the cause for petitioners. With him on the brief was James H. Dannenberg, Deputy Attorney General...'}]
```

·ªû ƒë√¢y ch√∫ng ta ƒë√£ s·ª≠ d·ª•ng h√†m `islice()` t·ª´ m√¥-ƒëun `itertools` c·ªßa Python ƒë·ªÉ ch·ªçn hai m·∫´u ƒë·∫ßu ti√™n t·ª´ t·∫≠p d·ªØ li·ªáu k·∫øt h·ª£p v√† ch√∫ng ta c√≥ th·ªÉ th·∫•y r·∫±ng ch√∫ng kh·ªõp v·ªõi c√°c v√≠ d·ª• ƒë·∫ßu ti√™n t·ª´ m·ªói trong hai t·∫≠p d·ªØ li·ªáu ngu·ªìn.

Cu·ªëi c√πng, n·∫øu b·∫°n mu·ªën ph√°t tr·ª±c tuy·∫øn to√†n b·ªô 825 GB c·ªßa Pile, b·∫°n c√≥ th·ªÉ l·∫•y t·∫•t c·∫£ c√°c t·ªáp ƒë√£ chu·∫©n b·ªã nh∆∞ sau:

```py
base_url = "https://the-eye.eu/public/AI/pile/"
data_files = {
    "train": [base_url + "train/" + f"{idx:02d}.jsonl.zst" for idx in range(30)],
    "validation": base_url + "val.jsonl.zst",
    "test": base_url + "test.jsonl.zst",
}
pile_dataset = load_dataset("json", data_files=data_files, streaming=True)
next(iter(pile_dataset["train"]))
```

```python out
{'meta': {'pile_set_name': 'Pile-CC'},
 'text': 'It is done, and submitted. You can play ‚ÄúSurvival of the Tastiest‚Äù on Android, and on the web...'}
```

> [!TIP]
> ‚úèÔ∏è **Th·ª≠ nghi·ªám th√¥i!** S·ª≠ d·ª•ng m·ªôt trong nh·ªØng kho t√†i li·ªáu Common Crawl l·ªõn nh∆∞ [`mc4`](https://huggingface.co/datasets/mc4) ho·∫∑c [`oscar`](https://huggingface.co/datasets/oscar) ƒë·ªÉ t·∫°o t·∫≠p d·ªØ li·ªáu ƒëa ng√¥n ng·ªØ tr·ª±c tuy·∫øn th·ªÉ hi·ªán t·ª∑ l·ªá n√≥i c·ªßa c√°c ng√¥n ng·ªØ ·ªü qu·ªëc gia b·∫°n ch·ªçn. V√≠ d·ª•: b·ªën ng√¥n ng·ªØ qu·ªëc gia ·ªü Th·ª•y Sƒ© l√† ti·∫øng ƒê·ª©c, ti·∫øng Ph√°p, ti·∫øng √ù v√† ti·∫øng La M√£, v√¨ v·∫≠y b·∫°n c√≥ th·ªÉ th·ª≠ t·∫°o m·ªôt kho ng·ªØ li·ªáu ti·∫øng Th·ª•y Sƒ© b·∫±ng c√°ch l·∫•y m·∫´u c√°c t·∫≠p h·ª£p con Oscar theo t·ª∑ l·ªá n√≥i c·ªßa ch√∫ng.

Gi·ªù ƒë√¢y, b·∫°n c√≥ t·∫•t c·∫£ c√°c c√¥ng c·ª• c·∫ßn thi·∫øt ƒë·ªÉ t·∫£i v√† x·ª≠ l√Ω c√°c t·∫≠p d·ªØ li·ªáu ·ªü m·ªçi h√¨nh d·∫°ng v√† k√≠ch th∆∞·ªõc - nh∆∞ng tr·ª´ khi b·∫°n ƒë·∫∑c bi·ªát may m·∫Øn, s·∫Ω ƒë·∫øn m·ªôt th·ªùi ƒëi·ªÉm trong h√†nh tr√¨nh NLP c·ªßa b·∫°n, n∆°i b·∫°n s·∫Ω ph·∫£i th·ª±c s·ª± t·∫°o m·ªôt t·∫≠p d·ªØ li·ªáu ƒë·ªÉ gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ v·∫•n ƒë·ªÅ trong t·∫ßm tay. ƒê√≥ l√† ch·ªß ƒë·ªÅ c·ªßa ph·∫ßn ti·∫øp theo!
