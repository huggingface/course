<CourseFloatingBanner chapter={2}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/smol-course/blob/main/1_instruction_tuning/notebooks/sft_finetuning_example.ipynb"},
]} />

# Supervised Fine-Tuning

Supervised Fine-Tuning (SFT) is a process for adapting pre-trained language models to specific tasks or domains. While pre-trained models have impressive general capabilities, they often need to be customized to excel at particular use cases. SFT bridges this gap by further training the model on relevant datasets with human-validated examples.

This page provides a step-by-step guide to fine-tuning the [`deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B`](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B) model using the [`SFTTrainer`](https://huggingface.co/docs/trl/en/sft_trainer). By following these steps, you can adapt the model to perform specific tasks more effectively. 

## When to Use SFT
The supervised structure of the task enables models to learn specific output formats and behaviors. For example, SFT can teach a model to consistently use chat templates or follow domain-specific guidelines. The decision to use Supervised Fine-Tuning depends on two primary factors:

### Template Control
SFT allows precise control over the model's output structure. This is particularly valuable when you need the model to:
1. Generate responses in a specific chat template format
2. Follow strict output schemas
3. Maintain consistent styling across responses

### Domain Adaptation
When working in specialized domains, SFT helps align the model with domain-specific requirements by:
1. Teaching domain terminology and concepts
2. Enforcing professional standards
3. Handling technical queries appropriately
4. Following industry-specific guidelines

<Tip>
Before starting SFT, evaluate whether your use case requires:
- Precise output formatting
- Domain-specific knowledge
- Consistent response patterns
- Adherence to specific guidelines

This evaluation will help determine if SFT is the right approach for your needs.
</Tip>

## Dataset Preparation

The supervised fine-tuning process requires a task-specific dataset structured with input-output pairs. Each pair should consist of:
1. An input prompt
2. The expected model response
3. Any additional context or metadata

The data format must be compatible with your model's chat template. Here's an example dataset suitable for supervised fine-tuning:

<iframe
  src="https://huggingface.co/datasets/HuggingFaceTB/smoltalk/embed/viewer/all/train?row=0"
  frameborder="0"
  width="100%"
  height="360px"
></iframe>

## Training Configuration

### Parameters

The SFTTrainer configuration requires consideration of several parameters that control the training process:

| Parameter | Description |
|-----------|-------------|
| num_train_epochs | The total number of training epochs to run (e.g., 1-3 epochs) |
| per_device_train_batch_size | The number of training examples processed per GPU in one forward/backward pass (typically 2-8 for large models) |
| gradient_accumulation_steps | Number of updates to accumulate before performing a backward pass, effectively increasing batch size |
| learning_rate | The step size for model weight updates during training (typically 2e-4 for fine-tuning) |
| gradient_checkpointing | Memory optimization technique that trades computation for memory by recomputing intermediate activations |
| warmup_ratio | Portion of training steps used for learning rate warmup (e.g., 0.03 = 3% of steps) |
| logging_steps | Frequency of logging training metrics and progress (e.g., every 10 steps) |
| save_strategy | When to save model checkpoints (e.g., "epoch" saves after each epoch, "steps" saves every N steps) |

### Core Parameters Explained

1. **Training Duration Parameters**:
   - `num_train_epochs`: Controls total training duration
   - `max_steps`: Alternative to epochs, sets maximum number of training steps
   - More epochs allow better learning but risk overfitting

2. **Batch Size Parameters**:
   - `per_device_train_batch_size`: Determines memory usage and training stability
   - `gradient_accumulation_steps`: Enables larger effective batch sizes
   - Larger batches provide more stable gradients but require more memory

3. **Learning Rate Parameters**:
   - `learning_rate`: Controls size of weight updates
   - `warmup_ratio`: Portion of training used for learning rate warmup
   - Too high can cause instability, too low results in slow learning

4. **Monitoring Parameters**:
   - `logging_steps`: Frequency of metric logging
   - `eval_steps`: How often to evaluate on validation data
   - `save_steps`: Frequency of model checkpoint saves

<Tip>
Start with conservative values and adjust based on monitoring:
- Begin with 1-3 epochs
- Use smaller batch sizes initially
- Monitor validation metrics closely
- Adjust learning rate if training is unstable
</Tip>

## Implementation with TRL

We will use the `SFTTrainer` class from the Transformers Reinforcement Learning (TRL) library, which is built on top of the `transformers` library. Here's a complete example using the TRL library:

```python
from datasets import load_dataset
from trl import SFTConfig, SFTTrainer
import torch

# Set device
device = "cuda" if torch.cuda.is_available() else "cpu"

# Load dataset
dataset = load_dataset("HuggingFaceTB/smoltalk")

# Configure trainer
training_args = SFTConfig(
    output_dir="./sft_output",
    max_steps=1000,
    per_device_train_batch_size=4,
    learning_rate=5e-5,
    logging_steps=10,
    save_steps=100,
    evaluation_strategy="steps",
    eval_steps=50,
)

# Initialize trainer
trainer = SFTTrainer(
    model=model,
    args=training_args,
    train_dataset=dataset["train"],
    eval_dataset=dataset["test"],
    tokenizer=tokenizer,
)

# Start training
trainer.train()
```

## Monitoring Training Progress

### Understanding Loss Patterns

Training loss typically follows three distinct phases:
1. Initial Sharp Drop: Rapid adaptation to new data distribution
2. Gradual Stabilization: Learning rate slows as model fine-tunes
3. Convergence: Loss values stabilize, indicating training completion

<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/nlp_course_sft_loss_graphic.png" alt="SFTTrainer Training" />

### Metrics to Monitor

Effective monitoring involves tracking quantitative metrics, and evaluating qualitative metrics. Available metrics are:

- Training loss
- Validation loss
- Learning rate progression
- Gradient norms

<Tip warning={true}>
Watch for these warning signs during training:
1. Validation loss increasing while training loss decreases (overfitting)
2. No significant improvement in loss values (underfitting)
3. Extremely low loss values (potential memorization)
4. Inconsistent output formatting (template learning issues)
</Tip>

### The Path to Convergence

As training progresses, the loss curve should gradually stabilize. The key indicator of healthy training is a small gap between training and validation loss, suggesting 
the model is learning generalizable patterns rather than memorizing specific examples. The absolute loss values will vary depending on your task and dataset.

### Monitoring Training Progress

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter11/loss_curve.png" alt="Training and validation loss curves 
    showing healthy convergence" width="600"/>
</div>

The graph above shows a typical training progression. Notice how both training and validation loss decrease sharply at first, then gradually level off. This pattern indicates the model is learning effectively while maintaining generalization ability.

### Warning Signs to Watch For

Several patterns in the loss curves can indicate potential issues:

1. If the validation loss starts increasing while training loss continues to decrease, your model is likely overfitting to the training data. Consider:
   - Reducing the model size or training time
   - Adding regularization
   - Increasing the dataset size
   - Using techniques like early stopping

2. If the loss doesn't show significant improvement, the model might be:
   - Learning too slowly (try increasing the learning rate)
   - Struggling with the task (check data quality and task complexity)
   - Hitting architecture limitations (consider a different model)

3. Extremely low loss values could suggest memorization rather than learning. This is particularly concerning if:
   - The model performs poorly on new, similar examples
   - The outputs lack diversity
   - The responses are too similar to training examples

<Tip warning={true}>

Monitor both the loss values and the model's actual outputs during training. Sometimes the loss can look good while the model develops unwanted behaviors. Regular 
qualitative evaluation of the model's responses helps catch issues that metrics alone might miss.

</Tip>

## Evaluation after SFT

In section [11.4](/en/chapter11/4) we will learn how to evaluate the model using benchmark datasets. For now, we will focus on the qualitative evaluation of the model.

After completing SFT, consider these follow-up actions:

1. Evaluate the model thoroughly on held-out test data
2. Validate template adherence across various inputs
3. Test domain-specific knowledge retention
4. Monitor real-world performance metrics

<Tip>
Document your training process, including:
- Dataset characteristics
- Training parameters
- Performance metrics
- Known limitations
This documentation will be valuable for future model iterations.
</Tip>

## Additional Resources

- [TRL Documentation](https://huggingface.co/docs/trl)
- [SFT Examples Repository](https://github.com/huggingface/trl/tree/main/examples/sft)
- [Fine-tuning Best Practices](https://huggingface.co/docs/transformers/training)

## Quiz

### 1. What parameters control the training duration in SFT?

<Question
	choices={[
		{
			text: "num_train_epochs and max_steps",
			explain: "Correct! These parameters determine how long the model will train, either by number of epochs or total steps.",
			correct: true
		},
		{
			text: "batch_size and learning_rate",
			explain: "While these affect training, they don't directly control the duration."
		},
		{
			text: "gradient_checkpointing and warmup_ratio",
			explain: "These parameters affect training efficiency and stability, not duration."
		}
	]}
/>

### 2. Which pattern in the loss curves indicates potential overfitting?

<Question
    choices={[
        {
            text: "Validation loss increases while training loss continues to decrease",
            explain: "Correct! This divergence between training and validation loss is a classic sign of overfitting.",
            correct: true
        },
        {
            text: "Both training and validation loss decrease steadily",
            explain: "This pattern actually indicates healthy training."
        },
        {
            text: "Training loss remains constant while validation loss decreases",
            explain: "This would be an unusual pattern and doesn't indicate overfitting."
        }
    ]}
/>

### 3. What is gradient_accumulation_steps used for?

<Question
    choices={[
        {
            text: "To increase effective batch size without using more memory",
            explain: "Correct! It accumulates gradients across multiple forward passes before updating weights.",
            correct: true
        },
        {
            text: "To save checkpoints during training",
            explain: "This is handled by save_steps and save_strategy parameters."
        },
        {
            text: "To control the learning rate schedule",
            explain: "Learning rate scheduling is controlled by learning_rate and warmup_ratio."
        }
    ]}
/>

### 4. What should you monitor during SFT training?

<Question
    choices={[
        {
            text: "Both quantitative metrics and qualitative outputs",
            explain: "Correct! Monitoring both types of metrics helps catch all potential issues.",
            correct: true
        },
        {
            text: "Only the training loss",
            explain: "Training loss alone isn't sufficient to ensure good model behavior."
        },
        {
            text: "Only the model's output quality",
            explain: "While important, qualitative evaluation alone misses important training dynamics."
        }
    ]}
/>

### 5. What indicates healthy convergence during training?

<Question
    choices={[
        {
            text: "A small gap between training and validation loss",
            explain: "Correct! This indicates the model is learning generalizable patterns.",
            correct: true
        },
        {
            text: "Training loss reaching zero",
            explain: "Extremely low loss values might indicate memorization rather than learning."
        },
        {
            text: "Validation loss being lower than training loss",
            explain: "This would be unusual and might indicate problems with the validation set."
        }
    ]}
/>

## üíê Nice work!

You've learned how to fine-tune models using SFT! To continue your learning:
1. Try the notebook with different parameters
2. Experiment with other datasets
3. Contribute improvements to the course material

## Additional Resources

- [TRL Documentation](https://huggingface.co/docs/trl)
- [SFT Examples Repository](https://github.com/huggingface/trl/tree/main/examples/sft)
- [Fine-tuning Best Practices](https://huggingface.co/docs/transformers/training)