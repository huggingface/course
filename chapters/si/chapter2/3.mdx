<FrameworkSwitchCourse {fw} />

# ආකෘති[[models]]

{#if fw === 'pt'}

<CourseFloatingBanner chapter={2}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter2/section2_pt.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter2/section2_pt.ipynb"},
]} />

{:else}

<CourseFloatingBanner chapter={2}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter2/section2_tf.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter2/section2_tf.ipynb"},
]} />

{/if}

{#if fw === 'pt'}

<Youtube id="AhChOFRegn4"/>
{:else}
<Youtube id="d3JVgghSOew"/>
{/if}

{#if fw === 'pt'}
මෙම කොටසේදී අපි ආකෘතියක් නිර්මාණය කිරීම සහ භාවිතා කිරීම දෙස සමීපව බලමු. අපි ඔබට මුරපොලකින් ඕනෑම ආකෘතියක් ක්ෂණිකව ලබා ගැනීමට අවශ්‍ය විට පහසු වන `AutoModel` පන්තිය භාවිතා කරන්නෙමු.

`AutoModel` පන්තිය සහ එහි සියලුම ඥාතීන් library යේ ඇති විවිධාකාර ආකෘති වලට වඩා සරල දවටන වේ. එය ඔබේ මුරපොල සඳහා සුදුසු ආදර්ශ නිර්මිත ස්වයංක්‍රීයව අනුමාන කළ හැකි අතර, මෙම නිර්මිත සමඟ ආකෘතියක් ක්ෂණිකව ලබා ගත හැකි බැවින් එය දක්ෂ දවටනයකි.

{:else}
මෙම කොටසේදී අපි ආකෘතියක් නිර්මාණය කිරීම සහ භාවිතා කිරීම දෙස සමීපව බලමු. අපි ඔබට මුරපොලකින් ඕනෑම ආකෘතියක් ක්ෂණිකව ලබා ගැනීමට අවශ්‍ය විට පහසු වන `TFAutoModel` පන්තිය භාවිතා කරන්නෙමු..

`TFAutoModel` පන්තිය සහ එහි සියලුම ඥාතීන් library යේ ඇති විවිධාකාර ආකෘති වලට වඩා සරල දවටන වේ. එය ඔබේ මුරපොල සඳහා සුදුසු ආදර්ශ නිර්මිත ස්වයංක්‍රීයව අනුමාන කළ හැකි අතර, මෙම නිර්මිත සමඟ ආකෘතියක් ක්ෂණිකව ලබා ගත හැකි බැවින් එය දක්ෂ දවටනයකි.

{/if}

කෙසේ වෙතත්, ඔබට භාවිතා කිරීමට අවශ්‍ය ආකෘතියේ වර්ගය ඔබ දන්නේ නම්, ඔබට එහි නිර්මිතය කෙලින්ම නිර්වචනය කරන පන්තිය භාවිතා කළ හැකිය. අපි BERT ආකෘති මගින් මෙය ක්‍රියා කරන ආකාරය බලමු.

## පරිවර්තකයක් නිර්මාණය කිරීම[[creating-a-transformer]]

BERT ආකෘතියක් ආරම්භ කිරීමට අප කළ යුතු පළමු දෙය නම් වින්‍යාස වස්තුවක් පුරණය කිරීමයි:

{#if fw === 'pt'}

```py
from transformers import BertConfig, BertModel

# Building the config
config = BertConfig()

# Building the model from the config
model = BertModel(config)
```

{:else}

```py
from transformers import BertConfig, TFBertModel

# Building the config
config = BertConfig()

# Building the model from the config
model = TFBertModel(config)
```

{/if}

වින්‍යාසය, ආකෘතිය ගොඩනැගීමට භාවිතා කරන බොහෝ ගුණාංග අඩංගු වේ:

```py
print(config)
```

```python out
BertConfig {
  [...]
  "hidden_size": 768,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  [...]
}
```

ඔබ තවමත් මෙම ගුණාංග සියල්ල කරන්නේ කුමක්දැයි දැක නැති අතර, ඔබ ඒවායින් සමහරක් හඳුනා ගත යුතුය: `hidden_size' ගුණාංගය `hidden_states`දෛශිකයේ ප්‍රමාණය නිර්වචනය කරයි, සහ`num_hidden_layers` ට්‍රාන්ස්ෆෝමර් ආකෘතියේ ඇති ස්ථර ගණන නිර්වචනය කරයි.

### විවිධ පුරණ ක්‍රම[[different-loading-methods]]

පෙරනිමි වින්‍යාසයෙන් ආකෘතියක් සෑදීම අහඹු අගයන් සමඟ එය ආරම්භ කරයි:

{#if fw === 'pt'}

```py
from transformers import BertConfig, BertModel

config = BertConfig()
model = BertModel(config)

# Model is randomly initialized!
```

{:else}

```py
from transformers import BertConfig, TFBertModel

config = BertConfig()
model = TFBertModel(config)

# Model is randomly initialized!
```

{/if}

මෙම අවස්ථාවේ ආකෘතිය භාවිතා කළ හැක, නමුත් එය විකාරරූපී දෑ ප්‍රතිදානය කරනු ඇත; එය මුලින්ම පුහුණු කළ යුතුය. අපට පැවරී ඇති කාර්යය මත මුල සිටම ආකෘතිය පුහුණු කළ හැක, නමුත් ඔබ [පළමු පරිච්ඡේදය](/course/chapter1) හි දැක ඇති පරිදි, මේ සඳහා දිගු කාලයක් සහ දත්ත විශාල ප්‍රමාණයක් අවශ්‍ය වනු ඇති අතර, එයට නොසැලකිය නොහැකි පරිසර බලපෑමක් ඇත. අනවශ්‍ය සහ අනුපිටපත් කරන ලද උත්සාහයන් වළක්වා ගැනීම සඳහා, දැනටමත් පුහුණු කර ඇති ආකෘති බෙදා ගැනීමට සහ නැවත භාවිතා කිරීමට හැකි වීම අත්‍යවශ්‍ය වේ.

දැනටමත් පුහුණු කර ඇති පරිවර්තක ආකෘතියක් පූරණය කිරීම සරලයි — අපට මෙය `from_pretrained()` ක්‍රමය භාවිතයෙන් කළ හැක.:

{#if fw === 'pt'}

```py
from transformers import BertModel

model = BertModel.from_pretrained("bert-base-cased")
```

ඔබ කලින් දැක ඇති පරිදි, අපට `BertModel` වෙනුවට සමාන `AutoModel` පන්තිය ප්‍රතිස්ථාපනය කළ හැක. මෙය මුරපොල-අඥෙයවාදී කේතය නිපදවන බැවින් අපි මෙතැන් සිට මෙය කරන්නෙමු; ඔබගේ කේතය එක් මුරපොලක් සඳහා ක්‍රියා කරන්නේ නම්, එය තවත් මුරපොලක් සමඟ බාධාවකින් තොරව ක්‍රියා කළ යුතුය. මුරපොල සමාන කාර්යයක් සඳහා පුහුණු කර ඇති තාක් කල්, නිර්මිතය වෙනස් වුවද (උදාහරණයක් ලෙස, හැඟීම් විශ්ලේෂණ කාර්යයක්) මෙය අදාළ වේ.

{:else}

```py
from transformers import TFBertModel

model = TFBertModel.from_pretrained("bert-base-cased")
```

ඔබ කලින් දැක ඇති පරිදි, අපට `TFBertModel` වෙනුවට සමාන `TFAutoModel` පන්තිය ප්‍රතිස්ථාපනය කළ හැක. මෙය මුරපොල-අඥෙයවාදී කේතය නිපදවන බැවින් අපි මෙතැන් සිට මෙය කරන්නෙමු; ඔබගේ කේතය එක් මුරපොලක් සඳහා ක්‍රියා කරන්නේ නම්, එය තවත් මුරපොලක් සමඟ බාධාවකින් තොරව ක්‍රියා කළ යුතුය. මුරපොල සමාන කාර්යයක් සඳහා පුහුණු කර ඇති තාක් කල්, නිර්මිතය වෙනස් වුවද (උදාහරණයක් ලෙස, හැඟීම් විශ්ලේෂණ කාර්යයක්) මෙය අදාළ වේ.

{/if}

ඉහත කේත සාම්පලයේ අපි `BertConfig` භාවිත නොකළ අතර, ඒ වෙනුවට `bert-base-cased` හඳුනාගැනීම හරහා පෙර පුහුණු කළ ආකෘතියක් පූරණය කළෙමු. මෙය BERT හි කතුවරුන් විසින්ම පුහුණු කරන ලද ආකෘති මුරපොලකි; ඔබට එය පිළිබඳ වැඩි විස්තර එහි [ආකෘති කාඩ්පත](https://huggingface.co/bert-base-cased) තුළ සොයා ගත හැක.

මෙම ආකෘතිය දැන් මුරපොලේ සියලුම භාර සමඟ ආරම්භ කර ඇත. එය පුහුණු කරන ලද කාර්යයන් පිළිබඳ නිගමන සඳහා සෘජුවම භාවිතා කළ හැකි අතර, එය නව කාර්යයක් මත මනාව සකස් කළ හැකිය. මුල සිට නොව පූර්ව පුහුණු භාර සමඟ පුහුණු කිරීමෙන්, අපට ඉක්මනින් හොඳ ප්‍රතිපල ලබා ගත හැකිය.

_~/.cache/huggingface/transformers_ වෙත පෙරනිමි වන හැඹිලි ෆෝල්ඩරය තුළ බර බාගත කර හැඹිලිගත කර ඇත (එබැවින් `from_pretrained()` ක්‍රමයට අනාගත ඇමතුම් ඒවා නැවත බාගැනීම සිදු නොවේ). ඔබට `HF_HOME` පරිසර විචල්‍යය සැකසීමෙන් ඔබේ හැඹිලි ෆෝල්ඩරය අභිරුචිකරණය කළ හැක.

BERT නිර්මිතයට අනුකූල වන තාක්, ආකෘතිය පුරණය සඳහා භාවිතා කරන හඳුනාගැනීම, ආකෘති කේන්ද්‍රය හි ඕනෑම ආකෘතියක හඳුනාගැනීම විය හැක. පවතින BERT මුරපොලවල් වල සම්පූර්ණ ලැයිස්තුව [මෙතනින්](https://huggingface.co/models?filter=bert) සොයා ගත හැක.

### සුරැකි ක්‍රම[[saving-methods]]

ආකෘතියක් සුරැකීම එකක් පූරණය කිරීම තරම්ම පහසුයි — අපි `save_pretrained()` ක්‍රමය භාවිතා කරමු, එය `from_pretrained()` ක්‍රමයට සමාන වේ:

```py
model.save_pretrained("directory_on_my_computer")
```

මෙය ඔබගේ තැටියට ගොනු දෙකක් සුරකියි:

{#if fw === 'pt'}

```
ls directory_on_my_computer

config.json pytorch_model.bin
```

{:else}

```
ls directory_on_my_computer

config.json tf_model.h5
```

{/if}

ඔබ _config.json_ ගොනුව දෙස බැලුවහොත්, ආදර්ශ නිර්මිතය ගොඩනැගීමට අවශ්‍ය ගුණාංග ඔබ හඳුනා ගනු ඇත. මෙම ගොනුවේ මුරපොල ආරම්භ වූ ස්ථානය සහ ඔබ අවසන් වරට මුරපොල සුරකින විට ඔබ භාවිතා කළ 🤗 පරිවර්තක අනුවාදය වැනි සමහර පාර-දත්ත ද අඩංගු වේ.

{#if fw === 'pt'}
_pytorch_model.bin_ ගොනුව _state dictionary_ ලෙස හැඳින්වේ; එහි ඔබගේ සියලුම ආකෘතියේ භාර අඩංගු වේ. ගොනු දෙක අත්වැල් බැඳගෙන; ඔබේ ආකෘතියේ නිර්මිතය දැන ගැනීමට වින්‍යාසය අවශ්‍ය වන අතර, ආදර්ශ භාර ඔබේ ආකෘතියේ පරාමිතීන් වේ.

{:else}
_tf_model.h5_ ගොනුව _state dictionary_ ලෙස හැඳින්වේ; එහි ඔබගේ සියලුම ආකෘතියේ භාර අඩංගු වේ. ගොනු දෙක අත්වැල් බැඳගෙන; ඔබේ ආකෘතියේ නිර්මිතය දැන ගැනීමට වින්‍යාසය අවශ්‍ය වන අතර, ආදර්ශ භාර ඔබේ ආකෘතියේ පරාමිතීන් වේ.

{/if}

## නිගමනය සඳහා පරිවර්තක ආකෘතියක් භාවිතා කිරීම[[using-a-transformer-model-for-inference]]

දැන් ඔබ ආකෘතියක් පුරණය සහ සුරැකීම ගැන දන්නා බැවින්, පුරෝකථන කිහිපයක් කිරීමට එය භාවිතා කිරීමට උත්සාහ කරමු. පරිවර්තක ආකෘති වලට ක්‍රියාවට නැංවිය හැක්කේ අංක - ටෝකනකාරක විසින් ජනනය කරන සංඛ්‍යා පමණි. නමුත් අපි ටෝකනකාරක ගැන සාකච්ඡා කිරීමට පෙර, ආකෘතිය පිළිගන්නා යෙදවුම් මොනවාදැයි සොයා බලමු.

ටෝකනකාරක වලට යෙදවුම් සුදුසු රාමුවේ ආතානක වෙත යැවීම ගැන සැලකිලිමත් විය හැක, නමුත් ඔබට සිදුවන්නේ කුමක්ද යන්න තේරුම් ගැනීමට උදවු කිරීම සඳහා, අපි ආදාන ආකෘතියට යැවීමට පෙර කළ යුතු දේ පිළිබඳව ඉක්මනින් විමසා බලමු.

අපි බලමු අපිට අනුපිළිවෙලවල් කිහිපයක් තිබෙන අවස්ථාවක්:

```py
sequences = ["Hello!", "Cool.", "Nice!"]
```

ටෝකනකාරක මේවා සාමාන්‍යයෙන් _ආදාන හැඳුනුම්පත්_ ලෙස හඳුන්වන වාග්මාලා දර්ශක බවට පරිවර්තනය කරයි. සෑම අනුක්‍රමයක්ම දැන් සංඛ්‍යා ලැයිස්තුවකි! ප්‍රතිපලය ප්‍රතිදානය වන්නේ:

```py no-format
encoded_sequences = [
    [101, 7592, 999, 102],
    [101, 4658, 1012, 102],
    [101, 3835, 999, 102],
]
```

මෙය කේතාංකනය කල අනුපිළිවෙල ලැයිස්තුවකි: ලැයිස්තු ලැයිස්තුවකි. ආතානක සෘජුකෝණාස්‍රාකාර හැඩයන් පමණක් පිළිගනී (න්‍යාස යැයි සිතන්න). මෙම "අරාව" දැනටමත් සෘජුකෝණාස්‍රාකාර හැඩයක් ඇත, එබැවින් එය ආතානක බවට පරිවර්තනය කිරීම පහසුය:

{#if fw === 'pt'}

```py
import torch

model_inputs = torch.tensor(encoded_sequences)
```

{:else}

```py
import tensorflow as tf

model_inputs = tf.constant(encoded_sequences)
```

{/if}

### ආකෘතියට ආදාන ලෙස ආතානක භාවිතා කිරීම[[using-the-tensors-as-inputs-to-the-model]]

ආකෘතිය සමඟ ආතානක භාවිතා කිරීම අතිශයින්ම සරලයි - අපි ආදාන සමඟ ආකෘතිය ක්‍රියාකරවමු:

```py
output = model(model_inputs)
```

ආකෘතිය විවිධ විස්තාර රාශියක් පිළිගන්නා අතර, ආදාන හැඳුනුම් පත් පමණක් අවශ්‍යය වේ. අනෙක් විස්තාර කරන්නේ කුමක්ද සහ ඒවා අවශ්‍ය විට අපි පසුව පැහැදිලි කරන්නෙමු,
නමුත් පළමුව අපි පරිවර්තක ආකෘතියකට තේරුම් ගත හැකි යෙදවුම් ගොඩනඟන ටෝකනකාරක දෙස සමීපව බැලිය යුතුය.
