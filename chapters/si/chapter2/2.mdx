<FrameworkSwitchCourse {fw} />

# Pipeline ‡∑Ñ‡∑í ‡∂Ö‡∂∑‡∑ä‚Äç‡∂∫‡∂±‡∑ä‡∂≠‡∂ª‡∂∫[[behind-the-pipeline]]

{#if fw === 'pt'}

<CourseFloatingBanner chapter={2}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter2/section2_pt.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter2/section2_pt.ipynb"},
]} />

{:else}

<CourseFloatingBanner chapter={2}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter2/section2_tf.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter2/section2_tf.ipynb"},
]} />

{/if}

<Tip>
  ‡∂¥‡∑Ö‡∂∏‡∑î ‡∂ö‡∑ú‡∂ß‡∑É ‡∂î‡∂∂ PyTorch ‡∑Ñ‡∑ù TensorFlow ‡∂∑‡∑è‡∑Ä‡∑í‡∂≠‡∑è ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏ ‡∂∏‡∂≠ ‡∂¥‡∂Ø‡∂±‡∂∏‡∑ä‡∑Ä ‡∂≠‡∂ª‡∂∏‡∂ö‡∑ä ‡∑Ä‡∑ô‡∂±‡∑É‡∑ä ‡∑Ä‡∑ö. ‡∂î‡∂∂
  ‡∂ö‡∑ê‡∂∏‡∂≠‡∑í ‡∂ö‡∑ä‚Äç‡∂ª‡∂∏‡∂∫ ‡∂≠‡∑ù‡∂ª‡∑è ‡∂ú‡∑ê‡∂±‡∑ì‡∂∏‡∂ß ‡∂∏‡∑è‡∂≠‡∑ò‡∂ö‡∑è‡∑Ä‡∂ß ‡∂â‡∑Ñ‡∑Ö‡∑í‡∂±‡∑ä ‡∂á‡∂≠‡∑í ‡∑É‡∑ä‡∑Ä‡∑í‡∂†‡∂∫ ‡∂ß‡∑ú‡∂ú‡∂Ω‡∑ä ‡∂ö‡∂ª‡∂±‡∑ä‡∂±.
</Tip>

{#if fw === 'pt'}

<Youtube id="1pedAIvTWXk"/>
{:else}
<Youtube id="wVN12smEvqg"/>
{/if}

‡∂Ö‡∂¥‡∑í ‡∑É‡∂∏‡∑ä‡∂¥‡∑ñ‡∂ª‡∑ä‡∂´ ‡∂ã‡∂Ø‡∑è‡∑Ñ‡∂ª‡∂´‡∂∫‡∂ö‡∑í‡∂±‡∑ä [‡∂¥‡∂ª‡∑í‡∂†‡∑ä‡∂°‡∑ö‡∂Ø‡∂∫ 1](/course/chapter1) ‡∑Ñ‡∑í ‡∂¥‡∑Ñ‡∂≠ ‡∂ö‡∑ö‡∂≠‡∂∫ ‡∂ö‡∑ä‚Äç‡∂ª‡∑í‡∂∫‡∑è‡∂≠‡∑ä‡∂∏‡∂ö ‡∂ö‡∑Ö ‡∑Ä‡∑í‡∂ß ‡∂≠‡∑í‡∂ª‡∂∫ ‡∂¥‡∑í‡∂ß‡∑î‡∂¥‡∑É ‡∑É‡∑í‡∂Ø‡∑î ‡∑Ä‡∑ñ ‡∂Ø‡∑ö ‡∂Ø‡∑ô‡∑É ‡∂∂‡∂Ω‡∑è ‡∂¥‡∂ß‡∂±‡∑ä ‡∂ú‡∂±‡∑í‡∂∏‡∑î:

```python
from transformers import pipeline

classifier = pipeline("sentiment-analysis")
classifier(
    [
        "I've been waiting for a HuggingFace course my whole life.",
        "I hate this so much!",
    ]
)
```

‡∂Ω‡∂∂‡∑è ‡∂ú‡∂≠‡∑ä ‡∂Ø‡∑ö:

```python out
[{'label': 'POSITIVE', 'score': 0.9598047137260437},
 {'label': 'NEGATIVE', 'score': 0.9994558095932007}]
```

‡∂Ö‡∂¥‡∑í [‡∂¥‡∂ª‡∑í‡∂†‡∑ä‡∂°‡∑ö‡∂Ø‡∂∫ 1](/course/chapter1) ‡∑Ñ‡∑í ‡∂Ø‡∑î‡∂ß‡∑î ‡∂¥‡∂ª‡∑í‡∂Ø‡∑í, ‡∂∏‡∑ô‡∂∏ pipeline ‡∂¥‡∑í‡∂∫‡∑Ä‡∂ª ‡∂≠‡∑î‡∂±‡∂ö‡∑ä ‡∂ë‡∂ö‡∂ß ‡∂ö‡∑è‡∂´‡∑ä‡∂©‡∂ú‡∂≠ ‡∂ö‡∂ª‡∂∫‡∑í: ‡∂¥‡∑ñ‡∂ª‡∑ä‡∑Ä ‡∑É‡∑ê‡∂ö‡∑É‡∑ì‡∂∏, ‡∂Ü‡∂Ø‡∑è‡∂± ‡∂Ü‡∂Ø‡∂ª‡∑ä‡∑Å‡∂∫ ‡∑Ñ‡∂ª‡∑Ñ‡∑è ‡∂∫‡∑ê‡∑Ä‡∑ì‡∂∏ ‡∑É‡∑Ñ ‡∂¥‡∑É‡∑î ‡∑É‡∑ê‡∂ö‡∑É‡∑î‡∂∏‡∑ä:

<div class="flex justify-center">
  <img
    class="block dark:hidden"
    src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/full_nlp_pipeline.svg"
    alt="The full NLP pipeline: tokenization of text, conversion to IDs, and inference through the Transformer model and the model head."
  />
  <img
    class="hidden dark:block"
    src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/full_nlp_pipeline-dark.svg"
    alt="The full NLP pipeline: tokenization of text, conversion to IDs, and inference through the Transformer model and the model head."
  />
</div>

‡∂Ö‡∂¥‡∑í ‡∂∏‡∑ö ‡∑É‡∑ë‡∂∏ ‡∂ë‡∂ö‡∂ö‡∑ä ‡∂ú‡∑ê‡∂±‡∂∏ ‡∂Ø‡∂Ω ‡∂Ö‡∂Ø‡∑Ñ‡∑É‡∂ö‡∑ä ‡∂ú‡∂±‡∑í‡∂∏‡∑î.

## ‡∂ß‡∑ù‡∂ö‡∂±‡∂ö‡∑è‡∂ª‡∂ö ‡∑É‡∂∏‡∂ü ‡∂¥‡∑ô‡∂ª ‡∑É‡∑ê‡∂ö‡∑É‡∑ì‡∂∏[[preprocessing-with-a-tokenizer]]

‡∂Ö‡∂±‡∑ô‡∂ö‡∑î‡∂≠‡∑ä ‡∑É‡∑ä‡∂±‡∑è‡∂∫‡∑î‡∂ö ‡∂¢‡∑è‡∂Ω ‡∂∏‡∑ô‡∂±‡∑ä, ‡∂¥‡∂ª‡∑í‡∑Ä‡∂ª‡∑ä‡∂≠‡∂ö ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í ‡∑Ä‡∂Ω‡∂ß ‡∂Ö‡∂∏‡∑î ‡∂Ö‡∂ö‡∑î‡∂ª‡∑î ‡∑É‡∑ò‡∂¢‡∑î‡∑Ä‡∂∏ ‡∑É‡∑ê‡∂ö‡∑É‡∑í‡∂∫ ‡∂±‡∑ú‡∑Ñ‡∑ê‡∂ö, ‡∂ë‡∂∂‡∑ê‡∑Ä‡∑í‡∂±‡∑ä ‡∂Ö‡∂¥‡∂ú‡∑ö pipeline ‡∂∫‡∑ö ‡∂¥‡∑Ö‡∂∏‡∑î ‡∂¥‡∑í‡∂∫‡∑Ä‡∂ª ‡∑Ä‡∂±‡∑ä‡∂±‡∑ö ‡∂¥‡∑è‡∂® ‡∂Ü‡∂Ø‡∑è‡∂±‡∂∫‡∂±‡∑ä ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í‡∂∫‡∂ß ‡∂≠‡∑ö‡∂ª‡∑î‡∂∏‡∑ä ‡∂ú‡∂≠ ‡∑Ñ‡∑ê‡∂ö‡∑í ‡∑É‡∂Ç‡∂õ‡∑ä‚Äç‡∂∫‡∑è ‡∂∂‡∑Ä‡∂ß ‡∂¥‡∂ª‡∑í‡∑Ä‡∂ª‡∑ä‡∂≠‡∂±‡∂∫ ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏‡∂∫‡∑í. ‡∂Ö‡∂¥‡∑í ‡∂∏‡∑ô‡∂∫ ‡∑É‡∑í‡∂Ø‡∑î ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏ ‡∑É‡∂≥‡∑Ñ‡∑è ‡∑Ä‡∂ú‡∂ö‡∑í‡∑Ä ‡∂∫‡∑î‡∂≠‡∑î, _‡∂ß‡∑ù‡∂ö‡∂±‡∂ö‡∑è‡∂ª‡∂ö_ ‡∂∑‡∑è‡∑Ä‡∑í‡∂≠‡∑è ‡∂ö‡∂ª‡∂∏‡∑î.

- ‡∂Ü‡∂Ø‡∑è‡∂±‡∂∫ _‡∂ß‡∑ù‡∂ö‡∂±_ ‡∂Ω‡∑ô‡∑É ‡∑Ñ‡∂≥‡∑î‡∂±‡∑ä‡∑Ä‡∂± ‡∑Ä‡∂†‡∂±, ‡∂ã‡∂¥‡∂¥‡∂Ø, ‡∑Ñ‡∑ù ‡∑É‡∂Ç‡∂ö‡∑ö‡∂≠ (‡∑Ä‡∑í‡∂ª‡∑è‡∂∏ ‡∂Ω‡∂ö‡∑î‡∂´‡∑î ‡∑Ä‡∑ê‡∂±‡∑í) ‡∑Ä‡∂Ω‡∂ß ‡∂∂‡∑ô‡∂Ø‡∑ì‡∂∏
- ‡∑É‡∑ë‡∂∏ ‡∑É‡∂Ç‡∂ö‡∑ö‡∂≠‡∂∫‡∂ö‡∑ä‡∂∏ ‡∂¥‡∑ñ‡∂ª‡∑ä‡∂´ ‡∑É‡∂Ç‡∂õ‡∑ä‚Äç‡∂∫‡∑è‡∑Ä‡∂ö‡∂ß ‡∑É‡∑í‡∂≠‡∑í‡∂∫‡∂∏‡∑ä‡∂ú‡∂≠ ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏
- ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í‡∂∫‡∂ß ‡∂¥‡∑ä‚Äç‡∂ª‡∂∫‡∑ù‡∂¢‡∂±‡∑Ä‡∂≠‡∑ä ‡∑Ä‡∑í‡∂∫ ‡∑Ñ‡∑ê‡∂ö‡∑í ‡∂Ö‡∂≠‡∑í‡∂ª‡∑ö‡∂ö ‡∂∫‡∑ô‡∂Ø‡∑Ä‡∑î‡∂∏‡∑ä ‡∂ë‡∂ö‡∂≠‡∑î ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏

‡∂∏‡∑ô‡∂∏ ‡∑É‡∑í‡∂∫‡∂Ω‡∑î ‡∂¥‡∑ñ‡∂ª‡∑ä‡∑Ä ‡∑É‡∑ê‡∂ö‡∑É‡∑î‡∂∏‡∑ä ‡∑Ñ‡∂ª‡∑í‡∂∫‡∂ß‡∂∏ ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í‡∂∫ ‡∂¥‡∑ô‡∂ª ‡∂¥‡∑î‡∑Ñ‡∑î‡∂´‡∑î ‡∂ö‡∑Ö ‡∂Ü‡∂ö‡∑è‡∂ª‡∂∫‡∂ß‡∂∏ ‡∑É‡∑í‡∂Ø‡∑î ‡∂ö‡∑Ö ‡∂∫‡∑î‡∂≠‡∑î‡∂∫, ‡∂ë‡∂∂‡∑ê‡∑Ä‡∑í‡∂±‡∑ä ‡∂Ö‡∂¥‡∑í ‡∂∏‡∑î‡∂Ω‡∑í‡∂±‡∑ä‡∂∏ ‡∂ë‡∂∏ ‡∂≠‡∑ú‡∂ª‡∂≠‡∑î‡∂ª‡∑î [‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í ‡∂ö‡∑ö‡∂±‡∑ä‡∂Ø‡∑ä‚Äç‡∂ª‡∂∫](https://huggingface.co/models) ‡∑Ä‡∑ô‡∂≠‡∑í‡∂±‡∑ä ‡∂∂‡∑è‡∂ú‡∂≠ ‡∂ö‡∑Ö ‡∂∫‡∑î‡∂≠‡∑î‡∂∫. ‡∂∏‡∑ô‡∂∫ ‡∑É‡∑í‡∂Ø‡∑î ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏ ‡∑É‡∂≥‡∑Ñ‡∑è, ‡∂Ö‡∂¥‡∑í 'AutoTokenizer' ‡∂¥‡∂±‡∑ä‡∂≠‡∑í‡∂∫ ‡∑É‡∑Ñ ‡∂ë‡∑Ñ‡∑í 'from_pretrained()' ‡∂ö‡∑ä‚Äç‡∂ª‡∂∏‡∂∫ ‡∂∑‡∑è‡∑Ä‡∑í‡∂≠‡∑è ‡∂ö‡∂ª‡∂∏‡∑î. ‡∂Ö‡∂¥‡∂ú‡∑ö ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í‡∂∫‡∑ö ‡∂∏‡∑î‡∂ª‡∂¥‡∑ú‡∂Ω ‡∂±‡∂∏ ‡∂∑‡∑è‡∑Ä‡∑í‡∂≠‡∑è ‡∂ö‡∂ª‡∂∏‡∑í‡∂±‡∑ä, ‡∂ë‡∂∫ ‡∑É‡∑ä‡∑Ä‡∂∫‡∂Ç‡∂ö‡∑ä‚Äç‡∂ª‡∑ì‡∂∫‡∑Ä ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í‡∂∫‡∑ö ‡∂ß‡∑ù‡∂ö‡∂±‡∂ö‡∑è‡∂ª‡∂ö ‡∑Ñ‡∑è ‡∑É‡∂∏‡∑ä‡∂∂‡∂±‡∑ä‡∂∞ ‡∂Ø‡∂≠‡∑ä‡∂≠ ‡∂Ω‡∂∂‡∑è‡∂ú‡∑ô‡∂± ‡∂ë‡∂∫ ‡∑Ñ‡∑ê‡∂π‡∑í‡∂Ω‡∑í‡∂ú‡∂≠ ‡∂ö‡∂ª‡∂∫‡∑í (‡∂ë‡∂∂‡∑ê‡∑Ä‡∑í‡∂±‡∑ä ‡∂ë‡∂∫ ‡∂∂‡∑è‡∂ú‡∂≠ ‡∑Ä‡∂±‡∑ä‡∂±‡∑ö ‡∂î‡∂∂ ‡∂¥‡∑Ñ‡∂≠ ‡∂ö‡∑ö‡∂≠‡∂∫ ‡∂∞‡∑è‡∑Ä‡∂±‡∂∫ ‡∂ö‡∂ª‡∂± ‡∂¥‡∑Ö‡∂∏‡∑î ‡∑Ä‡∂≠‡∑è‡∑Ä‡∂ß ‡∂¥‡∂∏‡∂´‡∑í).

'‡∑Ñ‡∑ê‡∂ü‡∑ì‡∂∏‡∑ä-‡∑Ä‡∑í‡∑Å‡∑ä‡∂Ω‡∑ö‡∑Ç‡∂´‡∂∫' pipeline ‡∂∫‡∑ö ‡∂¥‡∑ô‡∂ª‡∂±‡∑í‡∂∏‡∑í ‡∂∏‡∑î‡∂ª‡∂¥‡∑ú‡∂Ω 'distilbert-base-uncased-finetuned-sst-2-english' ‡∂∂‡∑ê‡∑Ä‡∑í‡∂±‡∑ä (‡∂î‡∂∂‡∂ß ‡∂ë‡∑Ñ‡∑í ‡∂Ü‡∂Ø‡∂ª‡∑ä‡∑Å ‡∂ö‡∑è‡∂©‡∑ä‡∂¥‡∂≠ [‡∂∏‡∑ô‡∂≠‡∑ê‡∂±‡∑í‡∂±‡∑ä](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)), ‡∂Ö‡∂¥‡∑í ‡∂¥‡∑Ñ‡∂≠ ‡∑É‡∂≥‡∑Ñ‡∂±‡∑ä ‡∂Ø‡∑ö ‡∂ö‡∑ä‚Äç‡∂ª‡∑í‡∂∫‡∑è‡∂≠‡∑ä‡∂∏‡∂ö ‡∂ö‡∂ª‡∂∏‡∑î:

```python
from transformers import AutoTokenizer

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
```

‡∂Ö‡∂¥‡∑í ‡∂ß‡∑ù‡∂ö‡∂±‡∂ö‡∑è‡∂ª‡∂ö ‡∂Ω‡∂∂‡∑è ‡∂ú‡∂≠‡∑ä ‡∂¥‡∑É‡∑î, ‡∂Ö‡∂¥‡∂ß ‡∂Ö‡∂¥‡∂ú‡∑ö ‡∑Ä‡∑è‡∂ö‡∑ä‚Äç‡∂∫ ‡∂ö‡∑ô‡∂Ω‡∑í‡∂±‡∑ä‡∂∏ ‡∂ë‡∂∫‡∂ß ‡∂∫‡∑ú‡∂∏‡∑î ‡∂ö‡∑Ö ‡∑Ñ‡∑ê‡∂ö‡∑í ‡∂Ö‡∂≠‡∂ª ‡∂Ö‡∂¥‡∂ú‡∑ö ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í‡∂∫‡∂ß ‡∂¥‡∑ù‡∑Ç‡∂´‡∂∫ ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏‡∂ß ‡∑É‡∑ñ‡∂Ø‡∑è‡∂±‡∂∏‡∑ä ‡∑Å‡∂∂‡∑ä‡∂Ø ‡∂ö‡∑ù‡∑Ç‡∂∫‡∂ö‡∑ä ‡∂Ö‡∂¥‡∂ß ‡∂±‡∑ê‡∑Ä‡∂≠ ‡∂Ω‡∑ê‡∂∂‡∑ô‡∂±‡∑î ‡∂á‡∂≠! ‡∂Ö‡∂¥‡∂ß ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏‡∂ß ‡∂â‡∂≠‡∑í‡∂ª‡∑í‡∑Ä ‡∂á‡∂≠‡∑ä‡∂≠‡∑ö ‡∂Ü‡∂Ø‡∑è‡∂± ‡∑Ñ‡∑ê‡∂≥‡∑î‡∂±‡∑î‡∂∏‡∑ä‡∂¥‡∂≠‡∑ä ‡∂Ω‡∑ê‡∂∫‡∑í‡∑É‡∑ä‡∂≠‡∑î‡∑Ä ‡∂Ü‡∂≠‡∑è‡∂±‡∂ö ‡∂∂‡∑Ä‡∂ß ‡∂¥‡∂ª‡∑í‡∑Ä‡∂ª‡∑ä‡∂≠‡∂±‡∂∫ ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏ ‡∂¥‡∂∏‡∂´‡∑í.

‡∂î‡∂∂‡∂ß ü§ó ‡∂¥‡∂ª‡∑í‡∑Ä‡∂ª‡∑ä‡∂≠‡∂ö ‡∂∑‡∑è‡∑Ä‡∑í‡∂≠‡∑è ‡∂ö‡∑Ö ‡∑Ñ‡∑ê‡∂ö‡∑ä‡∂ö‡∑ö ‡∂ö‡∑î‡∂∏‡∂± ML ‡∂ª‡∑è‡∂∏‡∑î‡∑Ä ‡∂¥‡∑É‡∑î‡∂≠‡∂Ω‡∂∫‡∂ö‡∑ä ‡∂Ω‡∑ô‡∑É ‡∂∑‡∑è‡∑Ä‡∑í‡∂≠‡∑è ‡∂ö‡∂ª‡∂∏‡∑í‡∂±‡∑ä ‡∂Ø ‡∂∫‡∂±‡∑ä‡∂± ‡∂ú‡∑ê‡∂± ‡∂ö‡∂ª‡∂Ø‡∂ª ‡∂±‡∑ú‡∑Ä‡∑ì; ‡∂ë‡∂∫ ‡∑É‡∂∏‡∑Ñ‡∂ª ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í ‡∑É‡∂≥‡∑Ñ‡∑è PyTorch ‡∑Ñ‡∑ù TensorFlow ‡∑Ñ‡∑ù Flax ‡∑Ä‡∑í‡∂∫ ‡∑Ñ‡∑ê‡∂ö. ‡∂ö‡∑ô‡∑É‡∑ö ‡∑Ä‡∑ô‡∂≠‡∂≠‡∑ä, ‡∂¥‡∂ª‡∑í‡∑Ä‡∂ª‡∑ä‡∂≠‡∂ö ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í ‡∂Ω‡∑ô‡∑É ‡∂¥‡∑í‡∑Ö‡∑í‡∂ú‡∂±‡∑ä‡∂±‡∑ö _‡∂Ü‡∂≠‡∑è‡∂±‡∂ö_ ‡∂¥‡∂∏‡∂´‡∑í. ‡∂Ü‡∂≠‡∑è‡∂±‡∂ö ‡∂ú‡∑ê‡∂± ‡∂î‡∂∂ ‡∂Ö‡∑É‡∂± ‡∂¥‡∑Ö‡∂∏‡∑î ‡∂Ö‡∑Ä‡∑É‡∑ä‡∂Æ‡∑è‡∑Ä ‡∂∏‡∑ô‡∂∫ ‡∂±‡∂∏‡∑ä, ‡∂í ‡∑Ä‡∑ô‡∂±‡∑î‡∑Ä‡∂ß ‡∂î‡∂∂‡∂ß ‡∂í‡∑Ä‡∑è NumPy ‡∂Ö‡∂ª‡∑è ‡∂Ω‡∑ô‡∑É ‡∑É‡∑í‡∂≠‡∑í‡∂∫ ‡∑Ñ‡∑ê‡∂ö. NumPy ‡∂Ö‡∂ª‡∑è‡∑Ä‡∂ö‡∑ä ‡∂¥‡∂ª‡∑í‡∂∏‡∑è‡∂´‡∂∫‡∂ö‡∑ä (0D), ‡∂Ø‡∑õ‡∑Å‡∑í‡∂ö‡∂∫‡∂ö‡∑ä (1D), ‡∂±‡∑ä‚Äç‡∂∫‡∑è‡∑É‡∂∫‡∂ö‡∑ä (2D) ‡∑Ñ‡∑ù ‡∑Ä‡∑ê‡∂©‡∑í ‡∂∏‡∑è‡∂±‡∂∫‡∂±‡∑ä ‡∂≠‡∑í‡∂∂‡∑í‡∂∫ ‡∑Ñ‡∑ê‡∂ö. ‡∂í‡∑Ä‡∑è ‡∂µ‡∂Ω‡∂Ø‡∑è‡∂∫‡∑ì ‡∂Ω‡∑ô‡∑É ‡∂Ü‡∂≠‡∑è‡∂±‡∂ö‡∂∫‡∂ö‡∑í; ‡∂Ö‡∂±‡∑ô‡∂ö‡∑î‡∂≠‡∑ä ML ‡∂ª‡∑è‡∂∏‡∑î ‡∑Ä‡∂Ω ‡∂Ü‡∂≠‡∑è‡∂±‡∂ö ‡∑É‡∂∏‡∑è‡∂± ‡∂Ω‡∑ô‡∑É ‡∑Ñ‡∑ê‡∑É‡∑í‡∂ª‡∑ô‡∂± ‡∂Ö‡∂≠‡∂ª, ‡∑É‡∑è‡∂∏‡∑è‡∂±‡∑ä‚Äç‡∂∫‡∂∫‡∑ô‡∂±‡∑ä NumPy ‡∂Ö‡∂ª‡∑è‡∑Ä‡∂±‡∑ä ‡∂∏‡∑ô‡∂±‡∑ä ‡∑É‡∂ª‡∂Ω‡∑Ä ‡∂ö‡∑ä‡∑Ç‡∂´‡∑í‡∂ö ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏‡∂ß ‡∑Ñ‡∑ê‡∂ö‡∑í‡∑Ä‡∑ö.

‡∂Ö‡∂¥‡∂ß ‡∂Ü‡∂¥‡∑É‡∑î ‡∂Ω‡∂∂‡∑è ‡∂ú‡∑ê‡∂±‡∑ì‡∂∏‡∂ß ‡∂Ö‡∑Ä‡∑Å‡∑ä‚Äç‡∂∫ ‡∂Ü‡∂≠‡∑è‡∂±‡∂ö ‡∑Ä‡∂ª‡∑ä‡∂ú‡∂∫ ‡∑É‡∂≥‡∑Ñ‡∂±‡∑ä ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏‡∂ß (PyTorch, TensorFlow, ‡∑Ñ‡∑ù plain NumPy), ‡∂Ö‡∂¥‡∑í `return_tensors` ‡∑Ä‡∑í‡∑É‡∑ä‡∂≠‡∑è‡∂ª‡∂∫ ‡∂∑‡∑è‡∑Ä‡∑í‡∂≠‡∑è ‡∂ö‡∂ª‡∂∏‡∑î:

{#if fw === 'pt'}

```python
raw_inputs = [
    "I've been waiting for a HuggingFace course my whole life.",
    "I hate this so much!",
]
inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors="pt")
print(inputs)
```

{:else}

```python
raw_inputs = [
    "I've been waiting for a HuggingFace course my whole life.",
    "I hate this so much!",
]
inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors="tf")
print(inputs)
```

{/if}

‡∂≠‡∑Ä‡∂∏‡∂≠‡∑ä ‡∂¥‡∑í‡∂ª‡∑Ä‡∑î‡∂∏ ‡∑É‡∑Ñ ‡∂ö‡∂¥‡∑ä‡∂¥‡∑è‡∂Ø‡∑î‡∑Ä ‡∂ú‡∑ê‡∂± ‡∂ö‡∂ª‡∂Ø‡∂ª ‡∂±‡∑ú‡∑Ä‡∂±‡∑ä‡∂±; ‡∂Ö‡∂¥‡∑í ‡∂í‡∑Ä‡∑è ‡∂¥‡∑É‡∑î‡∑Ä ‡∂¥‡∑ê‡∑Ñ‡∑ê‡∂Ø‡∑í‡∂Ω‡∑í ‡∂ö‡∂ª‡∂±‡∑ä‡∂±‡∑ô‡∂∏‡∑î. ‡∂∏‡∑ô‡∑Ñ‡∑í‡∂Ø‡∑ì ‡∂∏‡∂≠‡∂ö ‡∂≠‡∂∂‡∑è ‡∂ú‡∂≠ ‡∂∫‡∑î‡∂≠‡∑î ‡∂¥‡∑ä‚Äç‡∂ª‡∂∞‡∑è‡∂± ‡∂ö‡∂ª‡∑î‡∂´‡∑î ‡∂±‡∂∏‡∑ä, ‡∂î‡∂∂‡∂ß ‡∂ë‡∂ö‡∑ä ‡∑Ä‡∑è‡∂ö‡∑ä‚Äç‡∂∫‡∂∫‡∂ö‡∑ä ‡∑Ñ‡∑ù ‡∑Ä‡∑è‡∂ö‡∑ä‚Äç‡∂∫ ‡∂Ω‡∑ê‡∂∫‡∑í‡∑É‡∑ä‡∂≠‡∑î‡∑Ä‡∂ö‡∑ä ‡∂Ω‡∂∂‡∑è‡∂Ø‡∑í‡∂∫ ‡∑Ñ‡∑ê‡∂ö‡∑í ‡∂Ö‡∂≠‡∂ª, ‡∂î‡∂∂‡∂ß ‡∂Ü‡∂¥‡∑É‡∑î ‡∂Ω‡∂∂‡∑è ‡∂ú‡∑ê‡∂±‡∑ì‡∂∏‡∂ß ‡∂Ö‡∑Ä‡∑Å‡∑ä‚Äç‡∂∫ ‡∂Ü‡∂≠‡∑è‡∂±‡∂ö ‡∑Ä‡∂ª‡∑ä‡∂ú‡∂∫ ‡∑É‡∂≥‡∑Ñ‡∂±‡∑ä ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏ (‡∂ö‡∑í‡∑É‡∑í‡∂Ø‡∑î ‡∑Ä‡∂ª‡∑ä‡∂ú‡∂∫‡∂ö‡∑ä ‡∂Ω‡∂∂‡∑è‡∂Ø‡∑ì ‡∂±‡∑ú‡∂∏‡∑ê‡∂≠‡∑í ‡∂±‡∂∏‡∑ä, ‡∂¥‡∑ä‚Äç‡∂ª‡∂≠‡∑í‡∂µ‡∂Ω‡∂∫‡∂ö‡∑ä ‡∂Ω‡∑ô‡∑É ‡∂î‡∂∂‡∂ß ‡∂Ω‡∑ê‡∂∫‡∑í‡∑É‡∑ä‡∂≠‡∑î ‡∂Ω‡∑ê‡∂∫‡∑í‡∑É‡∑ä‡∂≠‡∑î‡∑Ä‡∂ö‡∑ä ‡∂Ω‡∑ê‡∂∂‡∑ô‡∂±‡∑î ‡∂á‡∂≠) .

{#if fw === 'pt'}

‡∂∏‡∑ô‡∑Ñ‡∑í ‡∂¥‡∑ä‚Äç‡∂ª‡∂≠‡∑í‡∂µ‡∂Ω PyTorch ‡∂Ü‡∂≠‡∑è‡∂±‡∂ö ‡∂Ω‡∑ô‡∑É ‡∂¥‡∑ô‡∂±‡∑ô‡∂±‡∑ä‡∂±‡∑ö ‡∂ö‡∑ô‡∑É‡∑ö‡∂Ø ‡∂∫‡∂±‡∑ä‡∂±‡∂∫‡∑í:

```python out
{
    'input_ids': tensor([
        [  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172, 2607,  2026,  2878,  2166,  1012,   102],
        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,     0,     0,     0,     0,     0,     0]
    ]),
    'attention_mask': tensor([
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]
    ])
}
```

{:else}

TensorFlow ‡∂Ü‡∂≠‡∑è‡∂±‡∂ö ‡∂Ω‡∑ô‡∑É ‡∂¥‡∑ä‚Äç‡∂ª‡∂≠‡∑í‡∂µ‡∂Ω ‡∂¥‡∑ô‡∂±‡∑ô‡∂± ‡∂Ü‡∂ö‡∑è‡∂ª‡∂∫ ‡∂∏‡∑ô‡∂±‡∑ä‡∂±:

```python out
{
    'input_ids': <tf.Tensor: shape=(2, 16), dtype=int32, numpy=
        array([
            [  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,  2607,  2026,  2878,  2166,  1012,   102],
            [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,     0,     0,     0,     0,     0,     0]
        ], dtype=int32)>,
    'attention_mask': <tf.Tensor: shape=(2, 16), dtype=int32, numpy=
        array([
            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
            [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]
        ], dtype=int32)>
}
```

{/if}

‡∂¥‡∑ä‚Äç‡∂ª‡∂≠‡∑í‡∂Ø‡∑è‡∂±‡∂∫ ‡∂∫‡∂±‡∑î `input_ids` ‡∑É‡∑Ñ `attention_mask` ‡∂∫‡∂± ‡∂∫‡∂≠‡∑î‡∂ª‡∑î ‡∂Ø‡∑ô‡∂ö‡∂ö‡∑ä ‡∂Ö‡∂©‡∂Ç‡∂ú‡∑î ‡∂Ö‡∂ö‡∑è‡∂ª‡∑è‡∂Ø‡∑í ‡∂Ø‡∂≠‡∑ä‡∂≠ ‡∂Ü‡∂ö‡∑è‡∂ª‡∂∫ ‡∂ö‡∑í. `input_ids` ‡∑Ñ‡∑í ‡∂±‡∑í‡∂õ‡∑í‡∂Ω ‡∂¥‡∑ö‡∑Ö‡∑í ‡∂Ø‡∑ô‡∂ö‡∂ö‡∑ä (‡∂ë‡∂ö‡∑ä ‡∂ë‡∂ö‡∑ä ‡∑Ä‡∑è‡∂ö‡∑ä‚Äç‡∂∫‡∂∫‡∂ö‡∂ß ‡∂ë‡∂ö‡∂ö‡∑ä) ‡∂ë‡∂ö‡∑ä ‡∂ë‡∂ö‡∑ä ‡∑Ä‡∑è‡∂ö‡∑ä‚Äç‡∂∫‡∂∫‡∑ö ‡∂ß‡∑ù‡∂ö‡∂±‡∑Ä‡∂Ω ‡∂Ö‡∂±‡∂±‡∑ä‚Äç‡∂∫ ‡∑Ñ‡∂≥‡∑î‡∂±‡∑è‡∂ú‡∑ê‡∂±‡∑ì‡∂∏‡∑ä ‡∑Ä‡∑ö. ‡∂Ö‡∂¥‡∑í `attention_mask` ‡∂∫‡∂±‡∑î ‡∂ö‡∑î‡∂∏‡∂ö‡∑ä‡∂Ø‡∑ê‡∂∫‡∑í ‡∂¥‡∑É‡∑î‡∑Ä ‡∂∏‡∑ô‡∂∏ ‡∂¥‡∂ª‡∑í‡∂†‡∑ä‡∂°‡∑ö‡∂Ø‡∂∫‡∑ô‡∂±‡∑ä ‡∂¥‡∑ê‡∑Ñ‡∑ê‡∂Ø‡∑í‡∂Ω‡∑í ‡∂ö‡∂ª‡∂±‡∑ä‡∂±‡∑ô‡∂∏‡∑î.

## ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í‡∂∫ ‡∑Ñ‡∂ª‡∑Ñ‡∑è ‡∂ú‡∂∏‡∂±‡∑ä ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏[[going-through-the-model]]

{#if fw === 'pt'}
‡∂Ö‡∂¥‡∂ú‡∑ö ‡∂ß‡∑ù‡∂ö‡∂±‡∂ö‡∑è‡∂ª‡∂ö ‡∑É‡∂∏‡∂ü ‡∂Ö‡∂¥ ‡∂ö‡∑Ö ‡∂Ü‡∂ö‡∑è‡∂ª‡∂∫‡∂ß‡∂∏ ‡∂Ö‡∂¥‡∂ú‡∑ö ‡∂¥‡∑ñ‡∂ª‡∑ä‡∑Ä ‡∂¥‡∑î‡∑Ñ‡∑î‡∂´‡∑î ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í‡∂∫ ‡∂∂‡∑è‡∂ú‡∂≠ ‡∂ö‡∑Ö ‡∑Ñ‡∑ê‡∂ö‡∑í‡∂∫. ü§ó ‡∂¥‡∂ª‡∑í‡∑Ä‡∂ª‡∑ä‡∂≠‡∂ö ‡∂∏‡∂ü‡∑í‡∂±‡∑ä `from_pretrained()` ‡∂ö‡∑ä‚Äç‡∂ª‡∂∏‡∂∫‡∂ö‡∑ä ‡∂Ø ‡∂á‡∂≠‡∑í `AutoModel` ‡∂¥‡∂±‡∑ä‡∂≠‡∑í‡∂∫‡∂ö‡∑ä ‡∑É‡∂¥‡∂∫‡∂∫‡∑í:

```python
from transformers import AutoModel

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
model = AutoModel.from_pretrained(checkpoint)
```

{:else}
‡∂Ö‡∂¥‡∂ú‡∑ö ‡∂ß‡∑ù‡∂ö‡∂±‡∂ö‡∑è‡∂ª‡∂ö ‡∑É‡∂∏‡∂ü ‡∂Ö‡∂¥ ‡∂ö‡∑Ö ‡∂Ü‡∂ö‡∑è‡∂ª‡∂∫‡∂ß‡∂∏ ‡∂Ö‡∂¥‡∂ú‡∑ö ‡∂¥‡∑ñ‡∂ª‡∑ä‡∑Ä ‡∂¥‡∑î‡∑Ñ‡∑î‡∂´‡∑î ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í‡∂∫ ‡∂∂‡∑è‡∂ú‡∂≠ ‡∂ö‡∑Ö ‡∑Ñ‡∑ê‡∂ö‡∑í‡∂∫. ü§ó ‡∂¥‡∂ª‡∑í‡∑Ä‡∂ª‡∑ä‡∂≠‡∂ö ‡∂∏‡∂ü‡∑í‡∂±‡∑ä `from_pretrained()` ‡∂ö‡∑ä‚Äç‡∂ª‡∂∏‡∂∫‡∂ö‡∑ä ‡∂Ø ‡∂á‡∂≠‡∑í `TFAutoModel` ‡∂¥‡∂±‡∑ä‡∂≠‡∑í‡∂∫‡∂ö‡∑ä ‡∑É‡∂¥‡∂∫‡∂∫‡∑í:

```python
from transformers import TFAutoModel

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
model = TFAutoModel.from_pretrained(checkpoint)
```

{/if}

‡∂∏‡∑ô‡∂∏ ‡∂ö‡∑ö‡∂≠ ‡∂ö‡∑ú‡∂ß‡∑É‡∑ô‡∑Ñ‡∑í, ‡∂Ö‡∂¥‡∑í ‡∂∏‡∑ì‡∂ß ‡∂¥‡∑ô‡∂ª ‡∂Ö‡∂¥‡∂ú‡∑ö pipeline ‡∂∫‡∑ö ‡∂∑‡∑è‡∑Ä‡∑í‡∂≠‡∑è ‡∂ö‡∑Ö ‡∂∏‡∑î‡∂ª‡∂¥‡∑ú‡∂Ω‡∂∏ ‡∂∂‡∑è‡∂ú‡∂≠ ‡∂ö‡∂ª ‡∂á‡∂≠ (‡∂ë‡∂∫ ‡∂á‡∂≠‡∑ä‡∂≠ ‡∑Ä‡∑Å‡∂∫‡∑ô‡∂±‡∑ä‡∂∏ ‡∂Ø‡∑ê‡∂±‡∂ß‡∂∏‡∂≠‡∑ä ‡∑Ñ‡∑ê‡∂π‡∑í‡∂Ω‡∑í‡∂ú‡∂≠ ‡∂ö‡∂ª ‡∂≠‡∑í‡∂∂‡∑í‡∂∫ ‡∂∫‡∑î‡∂≠‡∑î‡∂∫) ‡∑É‡∑Ñ ‡∂ë‡∂∫ ‡∑É‡∂∏‡∂ü ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í‡∂∫‡∂ö‡∑ä ‡∂ö‡∑ä‡∑Ç‡∂´‡∑í‡∂ö‡∑Ä ‡∂Ω‡∂∂‡∑è ‡∂Ø‡∑ì ‡∂á‡∂≠.

‡∂∏‡∑ô‡∂∏ ‡∂±‡∑í‡∂ª‡∑ä‡∂∏‡∑í‡∂≠‡∂∫‡∑ö ‡∂Ö‡∂©‡∂Ç‡∂ú‡∑î ‡∑Ä‡∂±‡∑ä‡∂±‡∑ö ‡∂∏‡∑ñ‡∂Ω‡∑í‡∂ö ‡∂¥‡∂ª‡∑í‡∑Ä‡∂ª‡∑ä‡∂≠‡∂ö ‡∂∏‡∑è‡∂≠‡∑í‡∂ö‡∑è‡∑Ä ‡∂¥‡∂∏‡∂´‡∑í: ‡∑É‡∂∏‡∑Ñ‡∂ª ‡∂∫‡∑ô‡∂Ø‡∑Ä‡∑î‡∂∏‡∑ä ‡∂Ω‡∂∂‡∑è ‡∂Ø‡∑ì ‡∂á‡∂≠‡∑í ‡∂Ö‡∂≠‡∂ª, ‡∂ë‡∂∫ ‡∂Ö‡∂¥ ‡∑Ä‡∑í‡∑É‡∑í‡∂±‡∑ä _‡∑É‡∑ê‡∂ü‡∑Ä‡∑î‡∂´‡∑î ‡∂Ö‡∑Ä‡∑É‡∑ä‡∂Æ‡∑è_ ‡∂Ω‡∑ô‡∑É ‡∑Ñ‡∂≥‡∑î‡∂±‡∑ä‡∑Ä‡∂± ‡∂Ø‡∑ö ‡∂¥‡∑ä‚Äç‡∂ª‡∂≠‡∑í‡∂Ø‡∑è‡∂±‡∂∫ ‡∂ö‡∂ª‡∂∫‡∑í, ‡∂ë‡∂∫ _‡∂Ω‡∂ö‡∑ä‡∑Ç‡∂´_ ‡∂Ω‡∑ô‡∑É‡∂Ø ‡∑Ñ‡∑ê‡∂≥‡∑í‡∂±‡∑ä‡∑Ä‡∑ö. ‡∂ë‡∂ö‡∑ä ‡∂ë‡∂ö‡∑ä ‡∂Ü‡∂Ø‡∂ª‡∑ä‡∑Å ‡∂Ü‡∂Ø‡∑è‡∂±‡∂∫ ‡∑É‡∂≥‡∑Ñ‡∑è, ‡∂Ö‡∂¥‡∑í ‡∂¥‡∂ª‡∑í‡∑Ä‡∂ª‡∑ä‡∂≠‡∂ö ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í‡∂∫‡∑ô‡∂±‡∑ä ** ‡∂ë‡∂∏ ‡∂Ü‡∂Ø‡∑è‡∂±‡∂∫ ‡∂¥‡∑í‡∑Ö‡∑í‡∂∂‡∂≥ ** ‡∑É‡∂±‡∑ä‡∂Ø‡∂ª‡∑ä‡∂∑ ‡∂Ö‡∑Ä‡∂∂‡∑ù‡∂∞‡∂∫ ‡∂±‡∑í‡∂∫‡∑ù‡∂¢‡∂±‡∂∫ ‡∂ö‡∂ª‡∂± ‡∂Ö‡∂∞‡∑í-‡∂∏‡∑è‡∂± ‡∂Ø‡∑õ‡∑Å‡∑í‡∂ö‡∂∫‡∂ö‡∑ä ‡∂Ω‡∂∂‡∑è ‡∂ú‡∂±‡∑í‡∂∏‡∑î.

‡∂∏‡∑ô‡∂∫ ‡∂≠‡∑ö‡∂ª‡∑î‡∂∏‡∂ö‡∑ä ‡∂±‡∑ê‡∂≠‡∑í ‡∂±‡∂∏‡∑ä, ‡∂í ‡∂ú‡∑ê‡∂± ‡∂ö‡∂ª‡∂Ø‡∂ª ‡∂±‡∑ú‡∑Ä‡∂±‡∑ä‡∂±. ‡∂Ö‡∂¥‡∑í ‡∂í ‡∑É‡∑í‡∂∫‡∂Ω‡∑ä‡∂Ω ‡∂¥‡∑É‡∑î‡∑Ä ‡∂¥‡∑ê‡∑Ñ‡∑ê‡∂Ø‡∑í‡∂Ω‡∑í ‡∂ö‡∂ª‡∂±‡∑ä‡∂±‡∑ô‡∂∏‡∑î.

‡∂∏‡∑ô‡∂∏ ‡∑É‡∑ê‡∂ü‡∑Ä‡∑î‡∂´‡∑î ‡∂≠‡∂≠‡∑ä‡∑Ä‡∂∫‡∂±‡∑ä ‡∂≠‡∂∏‡∂±‡∑ä‡∂ß‡∂∏ ‡∂¥‡∑ä‚Äç‡∂ª‡∂∫‡∑ù‡∂¢‡∂±‡∑Ä‡∂≠‡∑ä ‡∑Ä‡∑í‡∂∫ ‡∑Ñ‡∑ê‡∂ö‡∑í ‡∂Ö‡∂≠‡∂ª, ‡∂í‡∑Ä‡∑è ‡∑É‡∑è‡∂∏‡∑è‡∂±‡∑ä‚Äç‡∂∫‡∂∫‡∑ô‡∂±‡∑ä _‡∑Ñ‡∑í‡∑É_ ‡∂Ω‡∑ô‡∑É ‡∑Ñ‡∑ê‡∂≥‡∑í‡∂±‡∑ä‡∑Ä‡∑ô‡∂± ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í‡∂∫‡∑ö ‡∑Ä‡∑ô‡∂±‡∂≠‡∑ä ‡∂ö‡∑ú‡∂ß‡∑É‡∂ö‡∂ß ‡∂∫‡∑ô‡∂Ø‡∑Ä‡∑î‡∂∏‡∑ä ‡∑Ä‡∑ö. [‡∂¥‡∑Ö‡∂∏‡∑î ‡∂¥‡∂ª‡∑í‡∂†‡∑ä‡∂°‡∑ö‡∂Ø‡∂∫](/course/chapter1), ‡∑Ä‡∑í‡∑Ä‡∑í‡∂∞ ‡∂ö‡∑è‡∂ª‡∑ä‡∂∫‡∂∫‡∂±‡∑ä ‡∂ë‡∂ö‡∂∏ ‡∂±‡∑í‡∂ª‡∑ä‡∂∏‡∑í‡∂≠‡∂∫ ‡∑É‡∂∏‡∂ü ‡∑É‡∑í‡∂Ø‡∑î ‡∂ö‡∑Ö ‡∑Ñ‡∑ê‡∂ö‡∑í‡∑Ä ‡∂≠‡∑í‡∂∂‡∑î‡∂´‡∂≠‡∑ä, ‡∂∏‡∑ô‡∂∏ ‡∂ë‡∂ö‡∑ä ‡∂ë‡∂ö‡∑ä ‡∂ö‡∑è‡∂ª‡∑ä‡∂∫‡∂∫‡∂ß ‡∂í ‡∑Ñ‡∑è ‡∑É‡∂∏‡∑ä‡∂∂‡∂±‡∑ä‡∂∞ ‡∑Ä‡∑ô‡∂±‡∑É‡∑ä ‡∑Ñ‡∑í‡∑É‡∂ö‡∑ä ‡∂á‡∂≠.

### ‡∂Ö‡∂∞‡∑í-‡∂∏‡∑è‡∂± ‡∂Ø‡∑õ‡∑Å‡∑í‡∂ö‡∂∫‡∂ö‡∑ä?[[a-high-dimensional-vector]]

‡∂¥‡∂ª‡∑í‡∑Ä‡∂ª‡∑ä‡∂≠‡∂ö ‡∂∏‡∑è‡∂≠‡∑í‡∂ö‡∑è‡∑Ä ‡∂∏‡∂ú‡∑í‡∂±‡∑ä ‡∂Ø‡∑õ‡∑Å‡∑í‡∂ö ‡∂¥‡∑ä‚Äç‡∂ª‡∂≠‡∑í‡∂Ø‡∑è‡∂±‡∂∫ ‡∑É‡∑è‡∂∏‡∑è‡∂±‡∑ä‚Äç‡∂∫‡∂∫‡∑ô‡∂±‡∑ä ‡∑Ä‡∑í‡∑Å‡∑è‡∂Ω ‡∑Ä‡∑ö. ‡∂ë‡∂∫ ‡∑É‡∑è‡∂∏‡∑è‡∂±‡∑ä‚Äç‡∂∫‡∂∫‡∑ô‡∂±‡∑ä ‡∂∏‡∑è‡∂± ‡∂≠‡∑î‡∂±‡∂ö‡∑ä ‡∂á‡∂≠:

- **‡∂ö‡∑è‡∂´‡∑ä‡∂© ‡∂¥‡∑ä‚Äç‡∂ª‡∂∏‡∑è‡∂´‡∂∫**: ‡∑Ä‡∂ª‡∂ö‡∂ß ‡∑É‡∂ö‡∑É‡∂± ‡∂Ω‡∂Ø ‡∂Ö‡∂±‡∑î‡∂¥‡∑í‡∑Ö‡∑í‡∑Ä‡∑ô‡∂Ω‡∑Ä‡∂Ω‡∑ä ‡∂ú‡∂´‡∂± (‡∂Ö‡∂¥‡∂ú‡∑ö ‡∂ã‡∂Ø‡∑è‡∑Ñ‡∂ª‡∂´‡∂∫‡∑ö 2).
- **‡∂Ö‡∂±‡∑î‡∂¥‡∑í‡∑Ö‡∑í‡∑Ä‡∑ô‡∂Ω ‡∂Ø‡∑í‡∂ú**: ‡∂Ö‡∂±‡∑î‡∂¥‡∑í‡∑Ö‡∑í‡∑Ä‡∑ô‡∂Ω‡∑ô‡∑Ñ‡∑í ‡∑É‡∂Ç‡∂õ‡∑ä‚Äç‡∂∫‡∑è‡∂≠‡∑ä‡∂∏‡∂ö ‡∂±‡∑í‡∂ª‡∑ñ‡∂¥‡∂´‡∂∫‡∑ö ‡∂Ø‡∑í‡∂ú (‡∂Ö‡∂¥‡∂ú‡∑ö ‡∂ã‡∂Ø‡∑è‡∑Ñ‡∂ª‡∂´‡∂∫‡∑ö 16).
- **‡∑É‡∑ê‡∂ü‡∑Ä‡∑î‡∂´‡∑î ‡∂¥‡∑ä‚Äç‡∂ª‡∂∏‡∑è‡∂´‡∂∫**: ‡∂ë‡∂ö‡∑ä ‡∂ë‡∂ö‡∑ä ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í ‡∂Ü‡∂Ø‡∑è‡∂±‡∂∫‡∑ö ‡∂Ø‡∑õ‡∑Å‡∑í‡∂ö ‡∂∏‡∑è‡∂±‡∂∫.

‡∂Ö‡∑Ä‡∑É‡∑è‡∂± ‡∂Ö‡∂ú‡∂∫ ‡∂±‡∑í‡∑É‡∑è ‡∂ë‡∂∫ "‡∂â‡∑Ñ‡∑Ö ‡∂∏‡∑è‡∂±‡∂∫" ‡∂∫‡∑ê‡∂∫‡∑í ‡∂ö‡∑í‡∂∫‡∂±‡∑î ‡∂Ω‡∑ê‡∂∂‡∑ö. ‡∑É‡∑ê‡∂ü‡∑Ä‡∑î‡∂´‡∑î ‡∂¥‡∑ä‚Äç‡∂ª‡∂∏‡∑è‡∂´‡∂∫ ‡∂â‡∂≠‡∑è ‡∑Ä‡∑í‡∑Å‡∑è‡∂Ω ‡∑Ä‡∑í‡∂∫ ‡∑Ñ‡∑ê‡∂ö (768 ‡∂ö‡∑î‡∂©‡∑è ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í ‡∑É‡∂≥‡∑Ñ‡∑è ‡∂¥‡∑ú‡∂Ø‡∑î ‡∑Ä‡∂± ‡∂Ö‡∂≠‡∂ª ‡∑Ä‡∑í‡∑Å‡∑è‡∂Ω ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í ‡∑Ä‡∂Ω ‡∂∏‡∑ô‡∂∫ 3072 ‡∑Ñ‡∑ù ‡∂ä‡∂ß ‡∑Ä‡∑ê‡∂©‡∑í ‡∑Ä‡∑í‡∂∫ ‡∑Ñ‡∑ê‡∂ö).

‡∂Ö‡∂¥‡∑í ‡∂¥‡∑ô‡∂ª ‡∑É‡∑ê‡∂ö‡∑É‡∑ñ ‡∂∫‡∑ô‡∂Ø‡∑Ä‡∑î‡∂∏‡∑ä ‡∂Ö‡∂¥‡∂ú‡∑ö ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í‡∂∫‡∂ß ‡∂¥‡∑ù‡∑Ç‡∂´‡∂∫ ‡∂ö‡∑Ö‡∑Ñ‡∑ú‡∂≠‡∑ä ‡∂Ö‡∂¥‡∂ß ‡∂∏‡∑ô‡∂∫ ‡∂Ø‡∑ê‡∂ö‡∑í‡∂∫ ‡∑Ñ‡∑ê‡∂ö‡∑í‡∂∫:

{#if fw === 'pt'}

```python
outputs = model(**inputs)
print(outputs.last_hidden_state.shape)
```

```python out
torch.Size([2, 16, 768])
```

{:else}

```py
outputs = model(inputs)
print(outputs.last_hidden_state.shape)
```

```python out
(2, 16, 768)
```

{/if}

ü§ó ‡∂¥‡∂ª‡∑í‡∑Ä‡∂ª‡∑ä‡∂≠‡∂ö ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í ‡∑Ä‡∂Ω ‡∂¥‡∑ä‚Äç‡∂ª‡∂≠‡∑í‡∂Ø‡∑è‡∂±‡∂∫‡∂±‡∑ä `namedtuple` ‡∑Ñ‡∑ù ‡∂Ö‡∂ö‡∑è‡∂ª‡∑è‡∂Ø‡∑í ‡∂Ø‡∂≠‡∑ä‡∂≠ ‡∂Ü‡∂ö‡∑è‡∂ª ‡∂Ω‡∑ô‡∑É ‡∑Ñ‡∑ê‡∑É‡∑í‡∂ª‡∑ô‡∂± ‡∂∂‡∑Ä ‡∑É‡∂Ω‡∂ö‡∂±‡∑ä‡∂±. ‡∂î‡∂∂‡∂ß ‡∂∏‡∑ñ‡∂Ω‡∂Ø‡∑ä‚Äç‡∂ª‡∑Ä‡∑ä‚Äç‡∂∫ ‡∑Ä‡∑ô‡∂≠ ‡∂ã‡∂¥‡∂Ω‡∂ö‡∑ä‡∑Ç‡∂´ ‡∂∏‡∂ú‡∑í‡∂±‡∑ä ‡∂¥‡∑ä‚Äç‡∂ª‡∑Ä‡∑ö‡∑Å ‡∑Ä‡∑í‡∂∫ ‡∑Ñ‡∑ê‡∂ö (‡∂Ö‡∂¥‡∑í ‡∂ö‡∑Ö‡∑è‡∂ö‡∑ä ‡∂∏‡∑ô‡∂±‡∑ä) ‡∑Ñ‡∑ù ‡∂∫‡∂≠‡∑î‡∂ª (`outputs["last_hidden_state"]`), ‡∑Ñ‡∑ù ‡∂î‡∂∂ ‡∑É‡∑ú‡∂∫‡∂± ‡∂Ø‡∑ô‡∂∫ ‡∑Ñ‡∂ª‡∑í‡∂∫‡∂ß‡∂∏ ‡∂ö‡∑ú‡∂≠‡∑ê‡∂±‡∂Ø‡∑ê‡∂∫‡∑í ‡∂î‡∂∂ ‡∂Ø‡∂±‡∑ä‡∂±‡∑ö ‡∂±‡∂∏‡∑ä ‡∑É‡∑î‡∂†‡∑í‡∂∫ ‡∂∏‡∂ú‡∑í‡∂±‡∑ä (`outputs[0]`) .

### ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í ‡∑Å‡∑í‡∂ª‡∑ä‡∑Ç: ‡∂â‡∂Ω‡∂ö‡∑ä‡∂ö‡∂∏‡∑ä ‡∑Ä‡∂Ω‡∑í‡∂±‡∑ä ‡∂Ö‡∂ª‡∑ä‡∂Æ‡∂∫‡∂ö‡∑ä ‡∂Ω‡∂∂‡∑è‡∂ú‡∑ê‡∂±‡∑ì‡∂∏[[model-heads-making-sense-out-of-numbers]]

‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í ‡∑Å‡∑í‡∂ª‡∑ä‡∑Ç, ‡∑É‡∑ê‡∂ü‡∑Ä‡∑î‡∂´‡∑î ‡∂Ö‡∑Ä‡∑É‡∑ä‡∂Æ‡∑è ‡∑Ä‡∂Ω ‡∂Ö‡∂∞‡∑í‡∂∏‡∑è‡∂± ‡∂Ø‡∑õ‡∑Å‡∑í‡∂ö‡∂∫ ‡∂Ü‡∂Ø‡∑è‡∂±‡∂∫ ‡∂Ω‡∑ô‡∑É ‡∂ú‡∑ô‡∂± ‡∂í‡∑Ä‡∑è ‡∑Ä‡∑ô‡∂±‡∂≠‡∑ä ‡∂∏‡∑è‡∂±‡∂∫‡∂ö‡∂ß ‡∂¥‡∑ä‚Äç‡∂ª‡∂ö‡∑ä‡∑Ç‡∑ö‡∂¥‡∂´‡∂∫ ‡∂ö‡∂ª‡∂∫‡∑í. ‡∂í‡∑Ä‡∑è ‡∑É‡∑è‡∂∏‡∑è‡∂±‡∑ä‚Äç‡∂∫‡∂∫‡∑ô‡∂±‡∑ä ‡∂ª‡∑ö‡∂õ‡∑ì‡∂∫ ‡∑É‡∑ä‡∂Æ‡∂ª ‡∂ë‡∂ö‡∂ö‡∑í‡∂±‡∑ä ‡∑Ñ‡∑ù ‡∂ö‡∑í‡∑Ñ‡∑í‡∂¥‡∂∫‡∂ö‡∑í‡∂±‡∑ä ‡∑É‡∂∏‡∂±‡∑ä‡∑Ä‡∑í‡∂≠ ‡∑Ä‡∑ö:

<div class="flex justify-center">
  <img
    class="block dark:hidden"
    src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/transformer_and_head.svg"
    alt="A Transformer network alongside its head."
  />
  <img
    class="hidden dark:block"
    src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/transformer_and_head-dark.svg"
    alt="A Transformer network alongside its head."
  />
</div>

‡∂¥‡∂ª‡∑í‡∑Ä‡∂ª‡∑ä‡∂≠‡∂ö ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í‡∂∫‡∑ö ‡∂¥‡∑ä‚Äç‡∂ª‡∂≠‡∑í‡∂Ø‡∑è‡∂±‡∂∫ ‡∑É‡∑ê‡∂ö‡∑É‡∑ì‡∂∏‡∂ß ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í ‡∑Å‡∑í‡∂ª‡∑ä‡∑Ç ‡∑Ä‡∑ô‡∂≠ ‡∂ö‡∑ô‡∂Ω‡∑í‡∂±‡∑ä‡∂∏ ‡∂∫‡∑Ä‡∂±‡∑î ‡∂Ω‡∑ê‡∂∂‡∑ö.

‡∂∏‡∑ô‡∂∏ ‡∂ª‡∑ñ‡∂¥ ‡∑É‡∂ß‡∑Ñ‡∂±‡∑ô‡∑Ñ‡∑í, ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í‡∂∫ ‡∂ë‡∑Ñ‡∑í ‡∂ö‡∑è‡∑Ä‡∑ê‡∂Ø‡∑ä‡∂Ø‡∑ì‡∂∏‡∑ä ‡∑É‡∑ä‡∂Æ‡∂ª‡∂∫ ‡∑É‡∑Ñ ‡∂¥‡∑É‡∑î‡∑Ä ‡∂á‡∂≠‡∑í ‡∑É‡∑ä‡∂Æ‡∂ª ‡∂∏‡∂ú‡∑í‡∂±‡∑ä ‡∂±‡∑í‡∂ª‡∑ñ‡∂¥‡∂´‡∂∫ ‡∂ö‡∑ô‡∂ª‡∑ö. ‡∂ö‡∑è‡∑Ä‡∑ê‡∂Ø‡∑ä‡∂Ø‡∑ì‡∂∏‡∑ö ‡∑É‡∑ä‡∂Æ‡∂ª‡∂∫ ‡∂ß‡∑ù‡∂ö‡∂±‡∑ì‡∂ö‡∂ª‡∂´‡∂∫ ‡∂ö‡∂ª‡∂± ‡∂Ω‡∂Ø ‡∂Ü‡∂Ø‡∑è‡∂±‡∂∫‡∑ö ‡∂ë‡∂ö‡∑ä ‡∂ë‡∂ö‡∑ä ‡∂Ü‡∂Ø‡∑è‡∂± ‡∑Ñ‡∑ê‡∂≥‡∑î‡∂±‡∑î‡∂∏‡∑ä‡∂¥‡∂≠ ‡∑É‡∂∏‡∑ä‡∂∂‡∂±‡∑ä‡∂∞‡∑í‡∂≠ ‡∂ß‡∑ù‡∂ö‡∂±‡∂∫ ‡∂±‡∑í‡∂∫‡∑ù‡∂¢‡∂±‡∂∫ ‡∂ö‡∂ª‡∂± ‡∂Ø‡∑õ‡∑Å‡∑í‡∂ö‡∂∫‡∂ö‡∑ä ‡∂∂‡∑Ä‡∂ß ‡∂¥‡∂ª‡∑í‡∑Ä‡∂ª‡∑ä‡∂≠‡∂±‡∂∫ ‡∂ö‡∂ª‡∂∫‡∑í. ‡∑Ä‡∑è‡∂ö‡∑ä‚Äç‡∂∫‡∑Ä‡∂Ω ‡∂Ö‡∑Ä‡∑É‡∑è‡∂± ‡∂±‡∑í‡∂ª‡∑ñ‡∂¥‡∂´‡∂∫ ‡∂±‡∑í‡∂¥‡∂Ø‡∑Ä‡∑ì‡∂∏‡∂ß ‡∂Ö‡∑Ä‡∂∞‡∑è‡∂±‡∂∫ ‡∂∫‡∑ú‡∂∏‡∑î ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏‡∑ö ‡∂∫‡∑è‡∂±‡∑ä‡∂≠‡∑ä‚Äç‡∂ª‡∂´‡∂∫ ‡∂∑‡∑è‡∑Ä‡∑í‡∂≠‡∑è ‡∂ö‡∂ª‡∂∏‡∑í‡∂±‡∑ä ‡∂¥‡∑É‡∑î‡∂ö‡∑è‡∂Ω‡∑ì‡∂± ‡∑É‡∑ä‡∂Æ‡∂ª ‡∂ë‡∂∏ ‡∂Ø‡∑õ‡∑Å‡∑í‡∂ö ‡∑Ñ‡∑É‡∑î‡∂ª‡∑î‡∑Ä‡∂∫‡∑í.

ü§ó ‡∂¥‡∂ª‡∑í‡∑Ä‡∂ª‡∑ä‡∂≠‡∂ö ‡∑Ä‡∂Ω ‡∑Ä‡∑í‡∑Ä‡∑í‡∂∞ ‡∂±‡∑í‡∂ª‡∑ä‡∂∏‡∑í‡∂≠ ‡∂ª‡∑è‡∑Å‡∑í‡∂∫‡∂ö‡∑ä ‡∂á‡∂≠, ‡∂í ‡∑É‡∑ë‡∂∏ ‡∂ë‡∂ö‡∂ö‡∑ä‡∂∏ ‡∂±‡∑í‡∑Å‡∑ä‡∂†‡∑í‡∂≠ ‡∂ö‡∑è‡∂ª‡∑ä‡∂∫‡∂∫‡∂ö‡∂ß ‡∂∏‡∑î‡∑Ñ‡∑î‡∂´ ‡∂Ø‡∑ì‡∂∏ ‡∑Ä‡∂ß‡∑è ‡∂±‡∑í‡∂ª‡∑ä‡∂∏‡∑è‡∂´‡∂∫ ‡∂ö‡∂ª ‡∂á‡∂≠. ‡∂∏‡∑ô‡∂±‡∑ä‡∂± ‡∑É‡∂∏‡∑ä‡∂¥‡∑ñ‡∂ª‡∑ä‡∂´ ‡∂±‡∑ú‡∑Ä‡∂± ‡∂Ω‡∑ê‡∂∫‡∑í‡∑É‡∑ä‡∂≠‡∑î‡∑Ä‡∂ö‡∑ä:

- `*Model` (‡∑É‡∑ê‡∂ü‡∑Ä‡∑î‡∂´‡∑î ‡∂≠‡∂≠‡∑ä‡∂≠‡∑ä‡∑Ä‡∂∫‡∂±‡∑ä ‡∂Ω‡∂∂‡∑è‡∂ú‡∂±‡∑ä‡∂±)
- `*ForCausalLM`
- `*ForMaskedLM`
- `*ForMultipleChoice`
- `*ForQuestionAnswering`
- `*ForSequenceClassification`
- `*ForTokenClassification`
- ‡∑É‡∑Ñ ‡∑Ä‡∑ô‡∂±‡∂≠‡∑ä ü§ó

{#if fw === 'pt'}
‡∂Ö‡∂¥‡∂ú‡∑ö ‡∂ã‡∂Ø‡∑è‡∑Ñ‡∂ª‡∂´‡∂∫ ‡∑É‡∂≥‡∑Ñ‡∑è, ‡∂Ö‡∂¥‡∂ß ‡∂Ö‡∂±‡∑î‡∂ö‡∑ä‚Äç‡∂ª‡∂∏‡∑í‡∂ö ‡∑Ä‡∂ª‡∑ä‡∂ú‡∑ì‡∂ö‡∂ª‡∂´ ‡∑Ñ‡∑í‡∑É‡∂ö‡∑ä ‡∑É‡∑Ñ‡∑í‡∂≠ ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í‡∂∫‡∂ö‡∑ä ‡∂Ö‡∑Ä‡∑Å‡∑ä‚Äç‡∂∫ ‡∑Ä‡∂±‡∑î ‡∂á‡∂≠ (‡∑Ä‡∑è‡∂ö‡∑ä‚Äç‡∂∫ ‡∂∞‡∂± ‡∑Ñ‡∑ù ‡∑É‡∑ò‡∂´ ‡∂Ω‡∑ô‡∑É ‡∑Ä‡∂ª‡∑ä‡∂ú‡∑ì‡∂ö‡∂ª‡∂´‡∂∫ ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏‡∂ß ‡∑Ñ‡∑ê‡∂ö‡∑í ‡∑Ä‡∑ì‡∂∏ ‡∑É‡∂≥‡∑Ñ‡∑è). ‡∂ë‡∂∂‡∑ê‡∑Ä‡∑í‡∂±‡∑ä, ‡∂Ö‡∂¥‡∑í ‡∂á‡∂≠‡∑ä‡∂≠ ‡∑Ä‡∑Å‡∂∫‡∑ô‡∂±‡∑ä‡∂∏ `AutoModel` ‡∂¥‡∂±‡∑ä‡∂≠‡∑í‡∂∫ ‡∂∑‡∑è‡∑Ä‡∑í‡∂≠‡∑è ‡∂±‡∑ú‡∂ö‡∂ª‡∂∏‡∑î, ‡∂±‡∂∏‡∑î‡∂≠‡∑ä `AutoModelForSequenceClassification`:

```python
from transformers import AutoModelForSequenceClassification

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
model = AutoModelForSequenceClassification.from_pretrained(checkpoint)
outputs = model(**inputs)
```

{:else}
‡∂Ö‡∂¥‡∂ú‡∑ö ‡∂ã‡∂Ø‡∑è‡∑Ñ‡∂ª‡∂´‡∂∫ ‡∑É‡∂≥‡∑Ñ‡∑è, ‡∂Ö‡∂¥‡∂ß ‡∂Ö‡∂±‡∑î‡∂ö‡∑ä‚Äç‡∂ª‡∂∏‡∑í‡∂ö ‡∑Ä‡∂ª‡∑ä‡∂ú‡∑ì‡∂ö‡∂ª‡∂´ ‡∑Ñ‡∑í‡∑É‡∂ö‡∑ä ‡∑É‡∑Ñ‡∑í‡∂≠ ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í‡∂∫‡∂ö‡∑ä ‡∂Ö‡∑Ä‡∑Å‡∑ä‚Äç‡∂∫ ‡∑Ä‡∂±‡∑î ‡∂á‡∂≠ (‡∑Ä‡∑è‡∂ö‡∑ä‚Äç‡∂∫ ‡∂∞‡∂± ‡∑Ñ‡∑ù ‡∑É‡∑ò‡∂´ ‡∂Ω‡∑ô‡∑É ‡∑Ä‡∂ª‡∑ä‡∂ú‡∑ì‡∂ö‡∂ª‡∂´‡∂∫ ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏‡∂ß ‡∑Ñ‡∑ê‡∂ö‡∑í ‡∑Ä‡∑ì‡∂∏ ‡∑É‡∂≥‡∑Ñ‡∑è). ‡∂ë‡∂∂‡∑ê‡∑Ä‡∑í‡∂±‡∑ä, ‡∂Ö‡∂¥‡∑í ‡∂á‡∂≠‡∑ä‡∂≠ ‡∑Ä‡∑Å‡∂∫‡∑ô‡∂±‡∑ä‡∂∏ `FAutoModel` ‡∂¥‡∂±‡∑ä‡∂≠‡∑í‡∂∫ ‡∂∑‡∑è‡∑Ä‡∑í‡∂≠‡∑è ‡∂±‡∑ú‡∂ö‡∂ª‡∂∏‡∑î, ‡∂±‡∂∏‡∑î‡∂≠‡∑ä `TFAutoModelForSequenceClassification`:

```python
from transformers import TFAutoModelForSequenceClassification

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)
outputs = model(inputs)
```

{/if}

‡∂Ø‡∑ê‡∂±‡∑ä ‡∂Ö‡∂¥‡∑í ‡∂Ö‡∂¥‡∑ö ‡∂¥‡∑ä‚Äç‡∂ª‡∂≠‡∑í‡∂Ø‡∑è‡∂± ‡∑Ä‡∂Ω ‡∑Ñ‡∑ê‡∂©‡∂∫ ‡∂Ø‡∑ô‡∑É ‡∂∂‡∑ê‡∂Ω‡∑î‡∑Ä‡∑Ñ‡∑ú‡∂≠‡∑ä, ‡∂∏‡∑è‡∂±‡∂∫ ‡∂∂‡∑ú‡∑Ñ‡∑ù ‡∂Ö‡∂©‡∑î ‡∑Ä‡∂±‡∑î ‡∂á‡∂≠: ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í ‡∑Å‡∑í‡∂ª‡∑ä‡∑Ç ‡∂Ö‡∂¥ ‡∂¥‡∑ô‡∂ª ‡∂Ø‡∑î‡∂ß‡∑î ‡∂Ö‡∂∞‡∑í-‡∂∏‡∑è‡∂± ‡∂Ø‡∑õ‡∑Å‡∑í‡∂ö ‡∂Ü‡∂Ø‡∑è‡∂±‡∂∫ ‡∂Ω‡∑ô‡∑É ‡∂ú‡∂±‡∑ä‡∂±‡∑è ‡∂Ö‡∂≠‡∂ª ‡∂Ö‡∂ú‡∂∫‡∂±‡∑ä ‡∂Ø‡∑ô‡∂ö‡∂ö‡∑ä ‡∂Ö‡∂©‡∂Ç‡∂ú‡∑î ‡∂Ø‡∑õ‡∑Å‡∑í‡∂ö ‡∂¥‡∑ä‚Äç‡∂ª‡∂≠‡∑í‡∂Ø‡∑è‡∂±‡∂∫ ‡∂ö‡∂ª‡∂∫‡∑í (‡∂Ω‡∑ö‡∂∂‡∂Ω‡∂∫‡∂ö‡∂ß ‡∂ë‡∂ö‡∂ö‡∑ä):

```python
print(outputs.logits.shape)
```

{#if fw === 'pt'}

```python out
torch.Size([2, 2])
```

{:else}

```python out
(2, 2)
```

{/if}

‡∂Ö‡∂¥‡∂ß ‡∂á‡∂≠‡∑ä‡∂≠‡∑ö ‡∑Ä‡∑è‡∂ö‡∑ä‚Äç‡∂∫ ‡∂Ø‡∑ô‡∂ö‡∂ö‡∑ä ‡∑É‡∑Ñ ‡∂Ω‡∑ö‡∂∂‡∂Ω‡∑ä ‡∂Ø‡∑ô‡∂ö‡∂ö‡∑ä ‡∂¥‡∂∏‡∂´‡∂ö‡∑ä ‡∂∂‡∑ê‡∑Ä‡∑í‡∂±‡∑ä, ‡∂Ö‡∂¥‡∂ú‡∑ö ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í‡∂∫‡∑ô‡∂±‡∑ä ‡∂Ö‡∂¥‡∂ß ‡∂Ω‡∑ê‡∂∂‡∑ô‡∂± ‡∂¥‡∑ä‚Äç‡∂ª‡∂≠‡∑í‡∂µ‡∂Ω‡∂∫‡∑ö ‡∑Ñ‡∑ê‡∂©‡∂∫ 2 x 2 ‡∑Ä‡∑ö.

## ‡∂¥‡∑ä‚Äç‡∂ª‡∂≠‡∑í‡∂Ø‡∑è‡∂±‡∂∫ ‡∂¥‡∑É‡∑î ‡∑É‡∑ê‡∂ö‡∑É‡∑ì‡∂∏[[postprocessing-the-output]]

‡∂Ö‡∂¥‡∂ú‡∑ö ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í‡∂∫‡∑ô‡∂±‡∑ä ‡∂¥‡∑ä‚Äç‡∂ª‡∂≠‡∑í‡∂Ø‡∑è‡∂±‡∂∫ ‡∂Ω‡∑ô‡∑É ‡∂Ö‡∂¥‡∂ß ‡∂Ω‡∑ê‡∂∂‡∑ô‡∂± ‡∂Ö‡∂ú‡∂∫‡∂±‡∑ä ‡∂Ö‡∑Ä‡∑Å‡∑ä‚Äç‡∂∫‡∂∫‡∑ô‡∂±‡∑ä‡∂∏ ‡∂≠‡∂∏‡∂±‡∑ä ‡∑Ä‡∑í‡∑É‡∑í‡∂±‡∑ä‡∂∏ ‡∂Ö‡∂ª‡∑ä‡∂Æ‡∑Ä‡∂≠‡∑ä ‡∂±‡∑ú‡∑Ä‡∑ö. ‡∂Ö‡∂¥‡∑í ‡∂∂‡∂Ω‡∂∏‡∑î:

```python
print(outputs.logits)
```

{#if fw === 'pt'}

```python out
tensor([[-1.5607,  1.6123],
        [ 4.1692, -3.3464]], grad_fn=<AddmmBackward>)
```

{:else}

```python out
<tf.Tensor: shape=(2, 2), dtype=float32, numpy=
    array([[-1.5606991,  1.6122842],
           [ 4.169231 , -3.3464472]], dtype=float32)>
```

{/if}

‡∂Ö‡∂¥‡∂ú‡∑ö ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í‡∂∫ ‡∂¥‡∑Ö‡∂∏‡∑î ‡∑Ä‡∑è‡∂ö‡∑ä‚Äç‡∂∫‡∂∫‡∂ß `[-1.5607, 1.6123]` ‡∑É‡∑Ñ ‡∂Ø‡∑ô‡∑Ä‡∑ê‡∂±‡∑ä‡∂± ‡∑É‡∂≥‡∑Ñ‡∑è `[ 4.1692, -3.3464]` ‡∂¥‡∑î‡∂ª‡∑ù‡∂ö‡∂Æ‡∂±‡∂∫ ‡∂ö‡∂ª‡∂± ‡∂Ω‡∂Ø‡∑ì. ‡∂í‡∑Ä‡∑è ‡∑É‡∂∏‡∑ä‡∂∑‡∑è‡∑Ä‡∑í‡∂≠‡∑è‡∑Ä‡∂±‡∑ä ‡∂±‡∑ú‡∑Ä _‡∂Ω‡∂ù‡∑î‡∂ö‡∂∫_, ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í‡∂∫‡∑ö ‡∂Ö‡∑Ä‡∑É‡∑è‡∂± ‡∑É‡∑ä‡∂Æ‡∂ª‡∂∫ ‡∂∏‡∂ü‡∑í‡∂±‡∑ä ‡∂¥‡∑ä‚Äç‡∂ª‡∂≠‡∑í‡∂Ø‡∑è‡∂±‡∂∫ ‡∂ö‡∂ª‡∂± ‡∂Ω‡∂Ø ‡∂Ö‡∂∏‡∑î, ‡∂Ö‡∑É‡∑è‡∂∏‡∑è‡∂±‡∑ä‚Äç‡∂∫ ‡∂Ω‡∂ö‡∑î‡∂´‡∑î ‡∑Ä‡∑ö. ‡∑É‡∂∏‡∑ä‡∂∑‡∑è‡∑Ä‡∑í‡∂≠‡∑è‡∑Ä‡∂±‡∑ä ‡∂∂‡∑Ä‡∂ß ‡∂¥‡∂ª‡∑í‡∑Ä‡∂ª‡∑ä‡∂≠‡∂±‡∂∫ ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏ ‡∑É‡∂≥‡∑Ñ‡∑è, ‡∂î‡∑Ä‡∑î‡∂±‡∑ä [SoftMax](https://en.wikipedia.org/wiki/Softmax_function) ‡∑É‡∑ä‡∂Æ‡∂ª‡∂∫‡∂ö‡∑ä ‡∑Ñ‡∂ª‡∑Ñ‡∑è ‡∂∫‡∑è ‡∂∫‡∑î‡∂≠‡∑î‡∂∫ (‡∑É‡∑í‡∂∫‡∂Ω‡∑î ü§ó ‡∂¥‡∂ª‡∑í‡∑Ä‡∂ª‡∑ä‡∂≠‡∂ö ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í ‡∂Ω‡∂ù‡∑î‡∂ö‡∂∫ ‡∂¥‡∑ä‚Äç‡∂ª‡∂≠‡∑í‡∂Ø‡∑è‡∂±‡∂∫ ‡∂ö‡∂ª‡∂∫‡∑í. ‡∂∏‡∂±‡∑ä‡∂Ø, ‡∂¥‡∑î‡∑Ñ‡∑î‡∂´‡∑î‡∑Ä ‡∑É‡∂≥‡∑Ñ‡∑è ‡∑Ä‡∂± ‡∂¥‡∑è‡∂©‡∑î ‡∑Å‡∑ä‚Äç‡∂ª‡∑í‡∂≠‡∂∫ ‡∑É‡∑è‡∂∏‡∑è‡∂±‡∑ä‚Äç‡∂∫‡∂∫‡∑ô‡∂±‡∑ä ‡∑Ñ‡∂ª‡∑É‡∑ä ‡∂ë‡∂±‡∑ä‡∂ß‡∑ä‚Äç‡∂ª‡∑ú‡∂¥‡∑í‡∂∫ ‡∑Ä‡∑ê‡∂±‡∑í ‡∑É‡∂≠‡∑ä‚Äç‡∂∫ ‡∂Ö‡∂Ω‡∑è‡∂∑ ‡∑Å‡∑ä‚Äç‡∂ª‡∑í‡∂≠‡∂∫ ‡∑É‡∂∏‡∂ü SoftMax ‡∑Ä‡∑ê‡∂±‡∑í ‡∂Ö‡∑Ä‡∑É‡∑è‡∂± ‡∑É‡∂ö‡∑ä‚Äç‡∂ª‡∑ì‡∂∫ ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏‡∑ö ‡∑Å‡∑ä‚Äç‡∂ª‡∑í‡∂≠‡∂∫ ‡∑Ä‡∑í‡∂Ω‡∂∫‡∂±‡∂∫ ‡∂ö‡∂ª‡∂∫‡∑í.):

{#if fw === 'pt'}

```py
import torch

predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
print(predictions)
```

{:else}

```py
import tensorflow as tf

predictions = tf.math.softmax(outputs.logits, axis=-1)
print(predictions)
```

{/if}

{#if fw === 'pt'}

```python out
tensor([[4.0195e-02, 9.5980e-01],
        [9.9946e-01, 5.4418e-04]], grad_fn=<SoftmaxBackward>)
```

{:else}

```python out
tf.Tensor(
[[4.01951671e-02 9.59804833e-01]
 [9.9945587e-01 5.4418424e-04]], shape=(2, 2), dtype=float32)
```

{/if}

‡∂Ø‡∑ê‡∂±‡∑ä ‡∂Ö‡∂¥‡∂ß ‡∂¥‡∑ô‡∂±‡∑ô‡∂±‡∑ä‡∂±‡∑ö ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í‡∂∫ ‡∂¥‡∑Ö‡∂∏‡∑î ‡∑Ä‡∑è‡∂ö‡∑ä‚Äç‡∂∫‡∂∫‡∂ß `[0.0402, 0.9598]` ‡∑É‡∑Ñ ‡∂Ø‡∑ô‡∑Ä‡∑ê‡∂±‡∑ä‡∂± ‡∑É‡∂≥‡∑Ñ‡∑è `[0.9995, 0.0005]` ‡∂Ω‡∑ô‡∑É ‡∂¥‡∑î‡∂ª‡∑ù‡∂ö‡∂Æ‡∂±‡∂∫ ‡∂ö‡∂ª ‡∂á‡∂≠‡∑í ‡∂∂‡∑Ä‡∂∫‡∑í. ‡∂∏‡∑ö‡∑Ä‡∑è ‡∑Ñ‡∂≥‡∑î‡∂±‡∑è‡∂ú‡∂≠ ‡∑Ñ‡∑ê‡∂ö‡∑í ‡∑É‡∂∏‡∑ä‡∂∑‡∑è‡∑Ä‡∑í‡∂≠‡∑è ‡∂Ω‡∂ö‡∑î‡∂´‡∑î ‡∑Ä‡∑ö.

‡∂ë‡∂ö‡∑ä ‡∂ë‡∂ö‡∑ä ‡∑É‡∑ä‡∂Æ‡∑è‡∂±‡∂∫‡∂ß ‡∂Ö‡∂±‡∑î‡∂ª‡∑ñ‡∂¥ ‡∂Ω‡∑ö‡∂∂‡∂Ω ‡∂Ω‡∂∂‡∑è ‡∂ú‡∑ê‡∂±‡∑ì‡∂∏ ‡∑É‡∂≥‡∑Ñ‡∑è, ‡∂Ö‡∂¥‡∂ß ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í ‡∑Ä‡∑í‡∂±‡∑ä‚Äç‡∂∫‡∑è‡∑É‡∂∫‡∑ô‡∑Ñ‡∑í `id2label` ‡∂ú‡∑î‡∂´‡∑è‡∂Ç‡∂ú‡∂∫ ‡∂¥‡∂ª‡∑ì‡∂ö‡∑ä‡∑Ç‡∑è ‡∂ö‡∑Ö ‡∑Ñ‡∑ê‡∂ö (‡∂∏‡∑ö ‡∂ú‡∑ê‡∂± ‡∑Ä‡∑ê‡∂©‡∑í ‡∑Ä‡∑í‡∑É‡∑ä‡∂≠‡∂ª ‡∂ä‡∑Ö‡∂ü ‡∂ö‡∑ú‡∂ß‡∑É‡∑ö):

```python
model.config.id2label
```

```python out
{0: 'NEGATIVE', 1: 'POSITIVE'}
```

‡∂Ø‡∑ê‡∂±‡∑ä ‡∂Ö‡∂¥‡∂ß ‡∂±‡∑í‡∂ú‡∂∏‡∂±‡∂∫ ‡∂ö‡∑Ö ‡∑Ñ‡∑ê‡∂ö‡∑ä‡∂ö‡∑ö ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í‡∂∫ ‡∂¥‡∑Ñ‡∂≠ ‡∑É‡∂≥‡∑Ñ‡∂±‡∑ä ‡∂Ø‡∑ö ‡∂¥‡∑î‡∂ª‡∑ù‡∂ö‡∂Æ‡∂±‡∂∫ ‡∂ö‡∑Ö ‡∂∂‡∑Ä‡∂∫‡∑í:

- ‡∂¥‡∑Ö‡∂∏‡∑î ‡∑Ä‡∑ê‡∂ö‡∑í‡∂∫: NEGATIVE: 0.0402, POSITIVE: 0.9598
- ‡∂Ø‡∑ô‡∑Ä‡∂± ‡∑Ä‡∑ê‡∂ö‡∑í‡∂∫: NEGATIVE: 0.9995, POSITIVE: 0.0005

‡∂Ö‡∂¥‡∑í pipeline ‡∂∫‡∑ö ‡∂¥‡∑í‡∂∫‡∑Ä‡∂ª ‡∂≠‡∑î‡∂± ‡∑É‡∑è‡∂ª‡∑ä‡∂Æ‡∂ö‡∑Ä ‡∂¥‡∑ä‚Äç‡∂ª‡∂≠‡∑í‡∂±‡∑í‡∑Ç‡∑ä‡∂¥‡∑è‡∂Ø‡∂±‡∂∫ ‡∂ö‡∂ª ‡∂á‡∂≠: ‡∂ß‡∑ù‡∂ö‡∂±‡∂ö‡∑è‡∂ª‡∂ö ‡∑É‡∂∏‡∂ü ‡∂¥‡∑ô‡∂ª ‡∑É‡∑ê‡∂ö‡∑É‡∑î‡∂∏‡∑ä, ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í‡∂∫ ‡∑Ñ‡∂ª‡∑Ñ‡∑è ‡∂∫‡∑ô‡∂Ø‡∑Ä‡∑î‡∂∏‡∑ä ‡∂∫‡∑ê‡∑Ä‡∑ì‡∂∏ ‡∑É‡∑Ñ ‡∂¥‡∑É‡∑î ‡∑É‡∑ê‡∂ö‡∑É‡∑î‡∂∏‡∑ä! ‡∂Ø‡∑ê‡∂±‡∑ä ‡∂Ö‡∂¥‡∑í ‡∂í ‡∑É‡∑ë‡∂∏ ‡∂¥‡∑í‡∂∫‡∑Ä‡∂ª‡∂ö‡∂ß‡∂∏ ‡∂ú‡∑ê‡∂π‡∑î‡∂ª‡∂ß ‡∂ö‡∑í‡∂∏‡∑í‡∂Ø‡∑ì‡∂∏‡∂ß ‡∂∫‡∂∏‡∑ä ‡∂ö‡∑è‡∂Ω‡∂∫‡∂ö‡∑ä ‡∂ú‡∂≠ ‡∂ö‡∂ª‡∂∏‡∑î.

<Tip>

‚úèÔ∏è **‡∂ã‡∂≠‡∑ä‡∑É‡∑è‡∑Ñ ‡∂ö‡∂ª‡∂±‡∑ä‡∂±!** ‡∂î‡∂∂‡∑ö‡∂∏ ‡∂¥‡∑è‡∂® ‡∂Ø‡∑ô‡∂ö‡∂ö‡∑ä (‡∑Ñ‡∑ù ‡∑Ä‡∑ê‡∂©‡∑í ‡∂ú‡∂´‡∂±‡∂ö‡∑ä) ‡∂≠‡∑ù‡∂ª‡∑è ‡∂í‡∑Ä‡∑è `sentiment-analysis` pipeline ‡∑Ñ‡∂ª‡∑Ñ‡∑è ‡∂∞‡∑è‡∑Ä‡∂±‡∂∫ ‡∂ö‡∂ª‡∂±‡∑ä‡∂±. ‡∂â‡∂±‡∑ä‡∂¥‡∑É‡∑î ‡∂î‡∂∂ ‡∂∏‡∑ô‡∑Ñ‡∑í ‡∂Ø‡∑ê‡∂ö ‡∂á‡∂≠‡∑í ‡∂¥‡∑í‡∂∫‡∑Ä‡∂ª ‡∂î‡∂∂‡∂∏ ‡∂Ö‡∂±‡∑î‡∂ö‡∂ª‡∂´‡∂∫ ‡∂ö‡∂ª ‡∂î‡∂∂‡∂ß ‡∂ë‡∂∏ ‡∂¥‡∑ä‚Äç‡∂ª‡∂≠‡∑í‡∂µ‡∂Ω ‡∂Ω‡∂∂‡∑è ‡∂ú‡∑ê‡∂±‡∑ì‡∂∏‡∂ß ‡∑Ñ‡∑ê‡∂ö‡∑í ‡∂Ø‡∑ê‡∂∫‡∑í ‡∂¥‡∂ª‡∑ì‡∂ö‡∑ä‡∑Ç‡∑è ‡∂ö‡∂ª‡∂±‡∑ä‡∂±!

</Tip>
