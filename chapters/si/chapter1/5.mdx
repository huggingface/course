# සංකේතක ආකෘති[[encoder-models]]

<CourseFloatingBanner chapter={1} classNames="absolute z-10 right-0 top-0" />

<Youtube id="MUqNwgPjJvQ" />

සංකේතක ආකෘති භාවිතා කරන්නේ පරිවර්තක ආකෘතියේ කේතකය පමණි. එක් එක් අදියරේදී, අවධානය ස්ථරවලට ආරම්භක වාක්‍යයේ සියලුම වචන වෙත ප්‍රවේශ විය හැක. මෙම ආකෘති බොහෝ විට "ද්වි-දිශානුගත" අවධානයක් ඇති ලෙස සංලක්ෂිත වන අතර බොහෝ විට _auto-encoding models_ ලෙස හැඳින්වේ.

මෙම ආකෘතිවල පූර්ව පුහුණුව සාමාන්‍යයෙන් හැසිරෙන්නේ, දී ඇති වාක්‍යයක් කෙසේ හෝ දූෂිත කිරීම (උදාහරණයක් ලෙස, එහි අහඹු වචන වසන් කිරීම මගින්) සහ ආරම්භක වාක්‍ය සෙවීම හෝ ප්‍රතිනිර්මාණය කිරීම ආකෘතියට පැවරීමයි.

වාක්‍ය වර්ගීකරණය, නම් කරන ලද භූතාර්ථ හඳුනාගැනීම (සහ සාමාන්‍යයෙන් වචන වර්ගීකරණය) සහ නිස්සාරිත ප්‍රශ්නවලට පිළිතුරු සැපයීම වැනි සම්පූර්ණ වාක්‍යය පිළිබඳ අවබෝධයක් අවශ්‍ය කාර්යයන් සඳහා සංකේතක ආකෘති වඩාත් සුදුසු වේ.

මෙම ආකෘති පවුලේ නියෝජිතයින් නම්:

- [ALBERT](https://huggingface.co/transformers/model_doc/albert.html)
- [BERT](https://huggingface.co/transformers/model_doc/bert.html)
- [DistilBERT](https://huggingface.co/transformers/model_doc/distilbert.html)
- [ELECTRA](https://huggingface.co/transformers/model_doc/electra.html)
- [RoBERTa](https://huggingface.co/transformers/model_doc/roberta.html)
