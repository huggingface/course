# Uvod

<CourseFloatingBanner chapter={1} classNames="absolute z-10 right-0 top-0" />

## DobrodoÅ¡li na ğŸ¤— kurs!

<Youtube id="00GKzGyWFEs" />

Ovaj kurs Ä‡e vas nauÄiti o obradi prirodnog jezika (NLP) koristeÄ‡i biblioteke iz [Hugging Face](https://huggingface.co/) ekosistema â€” [ğŸ¤— Transformers](https://github.com/huggingface/transformers), [ğŸ¤— Datasets](https://github.com/huggingface/datasets), [ğŸ¤— Tokenizers](https://github.com/huggingface/tokenizers), [ğŸ¤— Accelerate](https://github.com/huggingface/accelerate) â€” kao i [Hugging Face Hub](https://huggingface.co/models). Kurs je potpuno besplatan i bez reklama.

## Å ta moÅ¾ete oÄekivati?

Evo kratkog pregleda kursa:

<div class="flex justify-center">
<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary.svg" alt="Evo kratkog pregleda kursa.">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary-dark.svg" alt="Evo kratkog pregleda kursa.">
</div>

- Poglavlja od 1 do 4 pruÅ¾aju uvod u glavne koncepte biblioteke ğŸ¤— Transformers. Do kraja ovog dela kursa, biÄ‡ete upoznati s radom Transformer modela i znaÄ‡ete kako da koristite model sa [Hugging Face Hub](https://huggingface.co/models), da fine-tune-ujete na dataset-u i kako da delite svoje rezultate na Hubu!
- Poglavlja od 5 do 8 uÄe osnove ğŸ¤— Datasets i ğŸ¤— Tokenizers pre nego Å¡to se zaroni u klasiÄne NLP zadatke. Do kraja ovog dela, biÄ‡ete sposobni da samostalno reÅ¡avate najÄeÅ¡Ä‡e NLP probleme.
- Poglavlja od 9 do 12 idu dalje od NLP-a i istraÅ¾uju kako se Transformer modeli mogu koristiti za zadatke u obradi govora i raÄunarskog vida. Usput Ä‡ete nauÄiti kako da pravite i delite demo verzije vaÅ¡ih modela i kako da ih optimizujete za produkcijsko okruÅ¾enje. Do kraja ovog dela, biÄ‡ete spremni da primenite ğŸ¤— Transformers na (skoro) svaki problem maÅ¡inskog uÄenja!

Ovaj kurs:

- Zahteva dobro znanje Pythona
- Najbolje je pohaÄ‘ati nakon uvodnog kursa iz dubokog uÄ‡enja (deep learning), kao Å¡to je [fast.ai-ov](https://www.fast.ai/) [Practical Deep Learning for Coders](https://course.fast.ai/) ili jedan od programa koje je razvio [DeepLearning.AI](https://www.deeplearning.ai/)
- Ne oÄekuje prethodno znanje [PyTorch](https://pytorch.org/) ili [TensorFlow](https://www.tensorflow.org/), iako Ä‡e neka upoznatost sa bilo kojim od njih pomoÄ‡i

Nakon Å¡to zavrÅ¡ite ovaj kurs, preporuÄujemo da pogledate specijalizaciju DeepLearning.AI-a [Natural Language Processing Specialization](https://www.coursera.org/specializations/natural-language-processing?utm_source=deeplearning-ai&utm_medium=institutions&utm_campaign=20211011-nlp-2-hugging_face-page-nlp-refresh), koja pokriva Å¡irok spektar tradicionalnih NLP modela kao Å¡to su naivni Bayes i LSTM-ovi koji su vredni poznavanja!

## Ko smo mi?

O autirima:

[**Abubakar Abid**](https://huggingface.co/abidlabs) zavrÅ¡io je doktorat na Stanfordu iz primenjenog maÅ¡inskog uÄenja. Tokom svojih doktorskih studija, osnovao je [Gradio](https://github.com/gradio-app/gradio), open-source Python biblioteku koja je koriÅ¡Ä‡ena za izradu preko 600,000 demoa maÅ¡inskog uÄenja. Gradio je kasnije akviziran od strane Hugging Face, gde Abubakar sada radi kao voÄ‘a tima za maÅ¡insko uÄenje.

[**Matthew Carrigan**](https://huggingface.co/Rocketknight1) je inÅ¾enjer maÅ¡inskog uÄenja u Hugging Face-u. Å½ivi u Dablinu, Irska i prethodno je radio kao ML inÅ¾enjer u Parse.ly i pre toga kao post-doktorski istraÅ¾ivaÄ na Trinity College Dublin. Ne veruje da Ä‡emo doÄ‡i do AGI-ja skaliranjem postojeÄ‡ih arhitektura, ali ipak ima velike nade za besmrtnost robota.

[**Lysandre Debut**](https://huggingface.co/lysandre) je inÅ¾enjer maÅ¡inskog uÄenja u Hugging Face-u i radio je na biblioteci ğŸ¤— Transformers od samih poÄetaka razvoja. Njegov cilj je da uÄini NLP dostupnim svima razvijanjem alata sa vrlo jednostavnim API-em.

[**Sylvain Gugger**](https://huggingface.co/sgugger) je istraÅ¾ivaÄ inÅ¾enjer u Hugging Face i jedan od glavnih odrÅ¾avalaca biblioteke ğŸ¤— Transformers. Prethodno je bio istraÅ¾ivaÄ nauÄnik u fast.ai, i su-napisao je _[Deep Learning for Coders with fastai and PyTorch](https://learning.oreilly.com/library/view/deep-learning-for/9781492045519/)_ sa Jeremy Howardom. Glavni fokus njegovog istraÅ¾ivanja je uÄiniti duboko uÄenje dostupnijim, dizajniranjem i poboljÅ¡anjem tehnika koje omoguÄ‡avaju modelima da se brzo obuÄavaju na ograniÄenim resursima.

[**Dawood Khan**](https://huggingface.co/dawoodkhan82) je inÅ¾enjer maÅ¡inskog uÄenja u Hugging Face-u. Iz NYC-a je i diplomirao je na Univerzitetu u New Yorku na smeru RaÄunarskih nauka. Nakon Å¡to je radio kao iOS inÅ¾enjer nekoliko godina, Dawood je dao otkaz da bi pokrenuo Gradio sa svojim suosnivaÄima. Gradio je na kraju akviziran od strane Hugging Face.

[**Merve Noyan**](https://huggingface.co/merve) je zastupnik za razvoj u Hugging Face, radeÄ‡i na razvoju alata i izradi sadrÅ¾aja oko njih da bi se demokratizovalo maÅ¡insko uÄenje za sve.

[**Lucile Saulnier**](https://huggingface.co/SaulLu) je inÅ¾enjer maÅ¡inskog uÄenja u Hugging Face-u, razvija i podrÅ¾ava upotrebu open-source alata. TakoÄ‘e je aktivno ukljuÄena u mnoge istraÅ¾ivaÄke projekte u oblasti obrade prirodnog jezika kao Å¡to su kolaborativni trening i BigScience.

[**Lewis Tunstall**](https://huggingface.co/lewtun) je inÅ¾enjer maÅ¡inskog uÄenja u Hugging Face-u, fokusiran na razvoj open-source alata i kako ih uÄinit dostupnim Å¡iroj zajednici. TakoÄ‘e je koautor knjige Oâ€™Reilly [Natural Language Processing with Transformers](https://www.oreilly.com/library/view/natural-language-processing/9781098136789/).

[**Leandro von Werra**](https://huggingface.co/lvwerra) je inÅ¾enjer maÅ¡inskog uÄenja u open-source timu u Hugging Face i takoÄ‘e koautor knjige Oâ€™Reilly [Natural Language Processing with Transformers](https://www.oreilly.com/library/view/natural-language-processing/9781098136789/). Ima nekoliko godina iskustva u industriji uvoÄ‘enja NLP projekata u produkciju radeÄ‡i na celokupnom steku maÅ¡inskog uÄenja.

## ÄŒesto postavljana pitanja

Evo nekih odgovora na Äesto postavljana pitanja:

- **Da li zavrÅ¡etak ovog kursa vodi do sertifikata?**
  Trenutno nemamo sertifikat za ovaj kurs. MeÄ‘utim, radimo na programu sertifikacije za Hugging Face ekosistem â€” ostanite uz nas!

- **Koliko vremena treba da posvetim ovom kursu?**
  Svako poglavlje ovog kursa je dizajnirano da se zavrÅ¡i za 1 nedelju, sa otprilike 6-8 sati rada nedeljno. MeÄ‘utim, moÅ¾ete uloÅ¾iti koliko god vremena vam je potrebno da zavrÅ¡ite kurs.

- **Gde mogu postaviti pitanje ako ga imam?**
  Ako imate pitanje o bilo kojem delu kursa, samo kliknite na baner "_Ask a question_" na vrhu stranice da biste automatski bili preusmereni na odgovarajuÄ‡i deo [Hugging Face forums](https://discuss.huggingface.co/):

<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/forum-button.png" alt="Link do the Hugging Face forums" width="75%">

Lista koja sadrÅ¾i [ideje za projekte](https://discuss.huggingface.co/c/course/course-event/25) je takoÄ‘e dostupna na forumima ako Å¾elite da veÅ¾bate viÅ¡e nakon Å¡to zavrÅ¡ite kurs.

- **Gde mogu da naÄ‘em kod za kurs?**
  Za svaki odeljak kliknite na baner na vrhu stranice da pokrenete kod u Google Colab ili Amazon SageMaker Studio Lab:

<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/notebook-buttons.png" alt="Link do Hugging Face course notebooks" width="75%">

Jupyter sveske koje sadrÅ¾e sav kod iz kursa se nalaze u repozitorijumu [`huggingface/notebooks`](https://github.com/huggingface/notebooks). Ako Å¾elite da ih generiÅ¡ete lokalno, pogledajte uputstva u [`course`](https://github.com/huggingface/course#-jupyter-notebooks) repoztorijumu na GitHub.

- **Kako mogu doprineti kursu?**
  Postoji mnogo naÄina da doprinesete kursu! Ako pronaÄ‘ete greÅ¡ku ili bag, molimo otvorite problem na [`course`](https://github.com/huggingface/course) repozitorijumu. Ako Å¾elite da pomognete u prevodu kursa na vaÅ¡ maternji jezik, pogledajte uputstva [here](https://github.com/huggingface/course#translating-the-course-into-your-language).

- ** Koje su odluke donete za svaki prevod?**
  Svaki prevod ima reÄnik i `TRANSLATING.txt` fajl koja detaljno opisuje odluke koje su donete za terminologiju maÅ¡inskog uÄenja itd. Primer za nemaÄki moÅ¾ete naÄ‡i [ovde](https://github.com/huggingface/course/blob/main/chapters/de/TRANSLATING.txt).

- **Da li mogu ponovo da iskoristim ovaj kurs?**
  Naravno! Kurs je objavljen pod dozvolom [Apache 2 license](https://www.apache.org/licenses/LICENSE-2.0.html). o znaÄi da morate dati odgovarajuÄ‡e priznanje, obezbediti link do licence i naznaÄiti ako su izmene napravljene. To moÅ¾ete uraditi na bilo koji razuman naÄin, ali ne na naÄin koji sugeriÅ¡e da licencodavac podrÅ¾ava vas ili vaÅ¡u upotrebu. Ako Å¾elite da citirate kurs, molimo koristite sledeÄ‡i BibTeX:

```
@misc{huggingfacecourse,
  author = {Hugging Face},
  title = {The Hugging Face Course, 2022},
  howpublished = "\url{https://huggingface.co/course}",
  year = {2022},
  note = "[Online; accessed <today>]"
}
```

## Hajde da krenemo

Da li ste spremni? U ovom poglavlju nauÄiÄ‡ete:

* Kako da koristite `pipeline()` funkciju da reÅ¡ite NLP zadatke poput generisanja teksta i klasifikacije
* O Transformerskoj arhitekturi
* Kako da razlikujete izmedju enkoder, dekoder i enkoder/dekoder arhitektura i sluÄaja kada se koriste
