# ì—ëŸ¬ê°€ ë°œìƒí–ˆì„ ë•Œ ëŒ€ì‘ ë°©ë²•

<CourseFloatingBanner chapter={8}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter8/section2.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter8/section2.ipynb"},
]} />

ì´ë²ˆ ì¥ì—ì„œëŠ” Transformer ëª¨ë¸ì„ ìƒˆë¡­ê²Œ íŠœë‹ í›„ ì˜ˆì¸¡ì„ í•˜ë ¤ê³  í•  ë•Œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ëª‡ê°€ì§€ ì¼ë°˜ì ì¸ ì—ëŸ¬ë¥¼ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.

<Youtube id="DQ-CpJn6Rc4"/>

ì´ë²ˆ ì¥ì—ì„œ [ëª¨ë¸ì˜ ì €ì¥ì†Œ í…œí”Œë¦¿](https://huggingface.co/lewtun/distilbert-base-uncased-finetuned-squad-d5716d28)ì´ ì¤€ë¹„ë˜ì–´ ìˆìŠµë‹ˆë‹¤. 
ë§Œì•½ ì´ë²ˆ ë‹¨ì›ì—ì„œ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë ¤ë©´ ëª¨ë¸ì„ [Huggingface Hub](https://huggingface.co)ì˜ ê°œì¸ ê³„ì •ì— ëª¨ë¸ì„ ë³µì‚¬í•´ì•¼ í•©ë‹ˆë‹¤.
ëª¨ë¸ì„ ê³„ì •ì˜ ì €ì¥ì†Œì— ë³µì œí•˜ê¸° ìœ„í•´ ì£¼í”¼í„° ë…¸íŠ¸ë¶ì—ì„œ ì•„ë˜ì˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ê±°ë‚˜:

```python
from huggingface_hub import notebook_login

notebook_login()
```

ë˜ëŠ” ì•„ë˜ì˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì›í•˜ëŠ” í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰í•©ë‹ˆë‹¤:

```bash
huggingface-cli login
```

í„°ë¯¸ë„ì—ì„œ ì•„ì´ë””ì™€ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ëŠ” í”„ë¡¬í”„íŠ¸ê°€ ë‚˜íƒ€ë‚˜ë©°, ì‹ë³„ í† í°ì€ *~/.cache/huggingface/*ì— ì €ì¥ë©ë‹ˆë‹¤. í•œë²ˆ ë¡œê·¸ì¸ í•˜ê³  ë‚˜ë©´ ëª¨ë¸ì˜ ì €ì¥ì†Œ í…œí”Œë¦¿ì„ ì•„ë˜ì˜ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ ë³µì‚¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
from distutils.dir_util import copy_tree
from huggingface_hub import Repository, snapshot_download, create_repo, get_full_repo_name


def copy_repository_template():
    # Clone the repo and extract the local path
    template_repo_id = "lewtun/distilbert-base-uncased-finetuned-squad-d5716d28"
    commit_hash = "be3eaffc28669d7932492681cd5f3e8905e358b4"
    template_repo_dir = snapshot_download(template_repo_id, revision=commit_hash)
    # Create an empty repo on the Hub
    model_name = template_repo_id.split("/")[1]
    create_repo(model_name, exist_ok=True)
    # Clone the empty repo
    new_repo_id = get_full_repo_name(model_name)
    new_repo_dir = model_name
    repo = Repository(local_dir=new_repo_dir, clone_from=new_repo_id)
    # Copy files
    copy_tree(template_repo_dir, new_repo_dir)
    # Push to Hub
    repo.push_to_hub()
```
ì´ì œ `copy_repository_template()`ë¥¼ í˜¸ì¶œí•˜ë©´ ëª¨ë¸ ì €ì¥ì†Œì˜ í…œí”Œë¦¿ì´ ê³„ì •ì— ë³µì‚¬ ë©ë‹ˆë‹¤.

## ğŸ¤— Transformersì˜ íŒŒì´í”„ë¼ì¸ ë””ë²„ê¹…

Transformer ëª¨ë¸ë“¤ì˜ ë©‹ì§„ ë””ë²„ê¹… ì„¸ê³„ë¡œ ì—¬ì •ì„ ë– ë‚˜ê¸° ìœ„í•´, ë‹¤ìŒì˜ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìƒê°í•´ë³´ì„¸ìš”: ì—¬ëŸ¬ë¶„ì€ E-commerce ì‚¬ì´íŠ¸ì˜ ê³ ê°ì´ ì†Œë¹„ì ìƒí’ˆì— ëŒ€í•œ ë‹µë³€ì„ ì°¾ê¸° ìœ„í•œ ì§ˆë¬¸ ë° ë‹µë³€ í”„ë¡œì íŠ¸ì—ì„œ ë™ë£Œì™€ í•¨ê»˜ ì¼í•˜ê³  ìˆìœ¼ë©°, ë™ë£Œê°€ ë‹¹ì‹ ì—ê²Œ ë‹¤ìŒê³¼ ê°™ì€ ë©”ì„¸ì§€ë¥¼ ë³´ëƒˆìŠµë‹ˆë‹¤:

> ì•ˆë…•í•˜ì„¸ìš”! Hugging Face ì½”ìŠ¤ì— ìˆëŠ” [7 ë‹¨ì›](/course/chapter7/7)ì˜ ê¸°ìˆ ì„ í™œìš©í•´ì„œ ì‹¤í—˜ì„ í•´ë´¤ëŠ”ë°, SQuADì—ì„œ ì¢‹ì€ ê²°ê³¼ë¥¼ ì–»ì—ˆìŠµë‹ˆë‹¤. ì €í¬ í”„ë¡œì íŠ¸ë¥¼ ì´ ëª¨ë¸ë¡œ ì‹œì‘í•  ìˆ˜ ìˆë‹¤ê³  ìƒê°ì´ ë©ë‹ˆë‹¤. í—ˆë¸Œì— ìˆëŠ” ëª¨ë¸ ì•„ì´ë””ëŠ” "lewtun/distillbert-base-uncased-finetuned-squad-d5716d28" ì…ë‹ˆë‹¤. ë§ˆìŒ ê» í…ŒìŠ¤íŠ¸ í•´ë³´ì„¸ìš”. :)

ğŸ¤— Transformersì˜ `pipeline`ì„ ì‚¬ìš©ëŠ” ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ê¸° ìœ„í•´ ìš°ì„  ê³ ë ¤í•´ì•¼ í•  ê²ƒì´ ìˆìŠµë‹ˆë‹¤:

```python
from transformers import pipeline

model_checkpoint = get_full_repo_name("distillbert-base-uncased-finetuned-squad-d5716d28")
reader = pipeline("question-answering", model=model_checkpoint)
```

```python out
"""
OSError: Can't load config for 'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28'. make sure that:

- 'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28'ì´ë¼ëŠ” ëª¨ë¸ëª…ì´ 'https://huggingface.co/models'ì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê±°ë‚˜

'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28'ì´ë¼ëŠ” ê²½ë¡œ ë˜ëŠ” í´ë”ê°€ config.json íŒŒì¼ í¬í•¨í•˜ê³  ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
"""
```

ì•„ ì´ëŸ°, ë­”ê°€ ì˜ëª»ëœ ê²ƒ ê°™ë„¤ìš”! ë§Œì•½ í”„ë¡œê·¸ë˜ë°ì´ ì²˜ìŒì´ë¼ë©´, ì´ëŸ° ì¢…ë¥˜ì˜ ì—ëŸ¬ê°€ ì²˜ìŒì—ëŠ” ë‹¤ì†Œ ì‹ ë¹„í•˜ê²Œ(`OSError`ë€ ë„ëŒ€ì²´..) ë³´ì¼ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì—ì„œ ë³´ì´ëŠ” ì—ëŸ¬ëŠ” íŒŒì´ì¬ì˜ traceback(stack traceë¡œ ì•Œë ¤ì ¸ìˆìŒ)ìœ¼ë¡œ ë¶ˆë¦¬ëŠ” ì¢€ ë” í° ì—ëŸ¬ ë¦¬í¬íŠ¸ì˜ ë§ˆì§€ë§‰ ë¶€ë¶„ ì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ì´ ì½”ë“œë¥¼ Googleì˜ Colabì—ì„œ ì‹¤í–‰í•œë‹¤ë©´ ì•„ë˜ì™€ ê°™ì€ ìŠ¤í¬ë¦°ìƒ·ì„ ë³´ê²Œ ë ê²ë‹ˆë‹¤:

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter8/traceback.png" alt="A Python traceback." width="100%"/>
</div>

ì´ ë¦¬í¬íŠ¸ì—ëŠ” ë§ì€ ì •ë³´ë¥¼ ë‹´ê³  ìˆìœ¼ë‹ˆ, ê°™ì´ í•µì‹¬ ë¶€ë¶„ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤. ìš°ì„  ëª…ì‹¬í•´ì•¼í•  ê²ƒì€ tracebacksì€ _ì•„ë˜ë¶€í„° ìœ„ë¡œ_ ì½ì–´ì•¼ í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ë§ì€ ì˜ì–´ í…ìŠ¤íŠ¸ë¥¼ ìœ„ì—ì„œ ì•„ë˜ë¡œ ì½ì–´ì˜¤ê³¤ í–ˆë‹¤ë©´ ì´ìƒí•˜ê²Œ ë“¤ë¦´ ìˆ˜ ìˆê² ì§€ë§Œ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë‹¤ìš´ë¡œë“œ í•  ë•Œ `pipeline`ì´ ë§Œë“œëŠ” í•¨ìˆ˜ í˜¸ì¶œ ìˆœì„œë¥¼ ë³´ì—¬ì£¼ëŠ” tracebackì„ ë°˜ì˜í–ˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ë‚´ë¶€ì—ì„œ `pipeline`ì´ ì‘ë™í•˜ëŠ” ë°©ì‹ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ [ë‹¨ì› 2](/course/chapter2)ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.

<Tip>

Google Colabì˜ tracebackì—ì„œ "6 frames" ì£¼ë³€ì˜ íŒŒë€ ìƒìë¥¼ ë³´ì…¨ë‚˜ìš”?  tracebackì„ "frames"ë¡œ ì••ì¶•í•˜ëŠ” Colabì˜ íŠ¹ë³„í•œ ê¸°ëŠ¥ì…ë‹ˆë‹¤. ë§Œì•½ ì˜¤ë¥˜ì˜ ì›ì¸ì„ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´, ë‘ê°œì˜ ì‘ì€ í™”ì‚´í‘œë¥¼ í´ë¦­í•´ì„œ ì „ì²´ tracebackì„ í™•ì¥ë˜ì–´ ìˆëŠ”ì§€ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ì„¸ìš”.

</Tip>

ì¦‰ ë§ˆì§€ë§‰ ì—ëŸ¬ ë©”ì‹œì§€ì™€ ë°œìƒí•œ ì˜ˆì™¸ì˜ ì´ë¦„ì„ ê°€ë¦¬í‚¤ëŠ” tracebackì˜ ë§ˆì§€ë§‰ ì¤„ì„ ëœ»í•©ë‹ˆë‹¤. ì´ ê²½ìš°ì˜ ì˜ˆì™¸ ìœ í˜•ì€ ì‹œìŠ¤í…œ ê´€ë ¨ ì˜¤ë¥˜ë¥¼ ë‚˜íƒ€ë‚´ëŠ” OS Error ì…ë‹ˆë‹¤. ì²¨ë¶€ëœ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ì½ìœ¼ë©´ ëª¨ë¸ì˜ *config.json* íŒŒì¼ì— ë¬¸ì œê°€ ìˆëŠ” ê²ƒìœ¼ë¡œ ë³´ì´ë©° ì´ë¥¼ ìˆ˜ì •í•˜ê¸° ìœ„í•´ ë‘ ê°€ì§€ ì„ íƒì§€ê°€ ìˆìŠµë‹ˆë‹¤:

```python out
"""
make sure that:

- 'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28' is a correct model identifier listed on 'https://huggingface.co/models'

- or 'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28' is the correct path to a directory containing a config.json file
"""
```

<Tip>

ğŸ’¡ ì´í•´í•˜ê¸° ì–´ë ¤ìš´ ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ ì ‘í•˜ê²Œ ëœë‹¤ë©´, ë©”ì„¸ì§€ë¥¼ ë³µì‚¬í•´ì„œ Google ë˜ëŠ” [ìŠ¤íƒì˜¤ë²„í”Œë¡œìš°](https://stackoverflow.com/) ê²€ìƒ‰ì°½ì— ë¶™ì—¬ ë„£ê¸°ë§Œ í•˜ì„¸ìš”(ë„¤ ì§„ì§­ë‹ˆë‹¤!). ì´ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí•œ ì²« ì‚¬ëŒì´ ì•„ë‹ ê°€ëŠ¥ì„±ì´ ë†’ì„ë¿ë”ëŸ¬, ì»¤ë®¤ë‹ˆí‹°ì˜ ë‹¤ë¥¸ ì‚¬ëŒë“¤ì´ ê²Œì‹œí•œ ì†”ë£¨ì…˜ì„ ì°¾ëŠ” ì¢‹ì€ ë°©ë²•ì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ìŠ¤íƒì˜¤ë²„í”Œë¡œìš°ì—ì„œ 'OSError: Can't load config for'ë¥¼ ê²€ìƒ‰í•˜ë©´ ì—¬ëŸ¬ [í•´ë‹µ](https://stackoverflow.com/search?q=OSError%3A+Can%27t+load+config+for+)ì„ ì œê³µí•˜ë©° ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ì¶œë°œì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

</Tip>

ì²« ë²ˆì§¸ ì œì•ˆì€ ëª¨ë¸ IDê°€ ì‹¤ì œë¡œ ì •í™•í•œì§€ í™•ì¸í•˜ë„ë¡ ìš”ì²­í•˜ëŠ” ê²ƒìœ¼ë¡œ ë¹„ì¦ˆë‹ˆìŠ¤ì˜ ì²« ìˆœì„œëŠ” ì‹ë³„ì(ëª¨ë¸ ì´ë¦„)ë¥¼ ë³µì‚¬í•˜ì—¬ Hubì˜ ê²€ìƒ‰ ì°½ì— ë¶™ì—¬ë„£ëŠ” ê²ƒì…ë‹ˆë‹¤:

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter8/wrong-model-id.png" alt="The wrong model name." width="100%"/>
</div>

ìŒ, ë™ë£Œì˜ ëª¨ë¸ì´ í—ˆë¸Œì— ì—†ëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤... ì•„í•˜, ëª¨ë¸ì˜ ì´ë¦„ì— ì˜¤íƒ€ê°€ ìˆì—ˆìŠµë‹ˆë‹¤! DistilBERTëŠ” ì´ë¦„ì— "l"ì´ í•˜ë‚˜ë§Œ ìˆìœ¼ë¯€ë¡œ ì´ë¥¼ ìˆ˜ì •í•˜ê³  ëŒ€ì‹  "lewtun/distilbert-base-uncased-finetuned-squad-d5716d28"ì„ ì°¾ì•„ë³´ê² ìŠµë‹ˆë‹¤:

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter8/true-model-id.png" alt="The right model name." width="100%"/>
</div>

ì¢‹ìŠµë‹ˆë‹¤, ì„±ê³µí–ˆêµ°ìš”. ì´ì œ ì˜¬ë°”ë¥¸ ëª¨ë¸ IDë¡œ ëª¨ë¸ì„ ë‹¤ì‹œ ë‹¤ìš´ë¡œë“œ í•´ë´…ì‹œë‹¤:

```python
model_checkpoint = get_full_repo_name("distilbert-base-uncased-finetuned-squad-d5716d28")
reader = pipeline("question-answering", model=model_checkpoint)
```

```python out
"""
OSError: Can't load config for 'lewtun/distilbert-base-uncased-finetuned-squad-d5716d28'. Make sure that:

- 'lewtun/distilbert-base-uncased-finetuned-squad-d5716d28' is a correct model identifier listed on 'https://huggingface.co/models'

- or 'lewtun/distilbert-base-uncased-finetuned-squad-d5716d28' is the correct path to a directory containing a config.json file
"""
```

ì•„ì˜¤ ë˜ ì‹¤íŒ¨ì…ë‹ˆë‹¤. ë¨¸ì‹ ëŸ¬ë‹ ì—”ì§€ë‹ˆì–´ì˜ ì¼ìƒì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤! ëª¨ë¸ IDë¥¼ ìˆ˜ì •í–ˆìœ¼ë¯€ë¡œ ë¬¸ì œëŠ” ì €ì¥ì†Œ ìì²´ì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤. ğŸ¤— Hubì˜ ì €ì¥ì†Œ ì»¨í…ì¸ ì— ë¹ ë¥´ê²Œ ì•¡ì„¸ìŠ¤í•˜ëŠ” ë°©ë²•ì€ `huggingface_hub` ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ `list_repo_files()` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤:

```python
from huggingface_hub import list_repo_files

list_repo_files(repo_id=model_checkpoint)
```

```python out
['.gitattributes', 'README.md', 'pytorch_model.bin', 'special_tokens_map.json', 'tokenizer_config.json', 'training_args.bin', 'vocab.txt']
```

í¥ë¯¸ë¡­ë„¤ìš” -- ì´ ì €ì¥ì†Œì—ëŠ” *config.json*ê°€ ë³´ì´ì§€ ì•ŠìŠµë‹ˆë‹¤! ìš°ë¦¬ì˜ `pipeline`ì´ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ëŠ” ê²ƒì´ ë‹¹ì—°í–ˆêµ°ìš”; ë™ë£Œê°€ íŒŒì¸íŠœë‹ í›„ì— í—ˆë¸Œì— í‘¸ì‹œí•˜ëŠ” ê²ƒì„ ìŠì–´ë²„ë¦° ëª¨ì–‘ì…ë‹ˆë‹¤. ì´ ê²½ìš°, ë¬¸ì œëŠ” ë§¤ìš° ê°„ë‹¨í•˜ê²Œ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤: ë™ë£Œì—ê²Œ íŒŒì¼ì„ ì¶”ê°€í•˜ë„ë¡ ìš”ì²­í•˜ê±°ë‚˜, ì‚¬ì „ í›ˆë ¨(pretrained)ëœ ëª¨ë¸ì´ [`distilbert-base-uncased`](https://huggingface.co/distilbert-base-uncased)ì¸ ê²ƒì„ í™•ì¸ í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì´ ëª¨ë¸ì— ëŒ€í•œ configë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³  ì €ì¥ì†Œì— í‘¸ì‹œí•˜ì—¬ ë¬¸ì œê°€ í•´ê²°ë˜ëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹œë„ í•´ë´…ì‹œë‹¤. [ë‹¨ì› 2](/course/chapter2)ì—ì„œ ë°°ìš´ ê¸°ìˆ ì„ ì‚¬ìš©í•´ `AutoConfig` í´ë˜ìŠ¤ë¡œ ëª¨ë¸ì˜ config íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
from transformers import AutoConfig

pretrained_checkpoint = "distilbert-base-uncased"
config = AutoConfig.from_pretrained(pretrained_checkpoint)
```

<Tip warning={true}>

ğŸš¨ ì—¬ê¸°ì—ì„œ í•˜ëŠ” ì ‘ê·¼ ë°©ì‹ì€ ë™ë£Œê°€ 'distilbert-base-uncased'ì˜ configë¥¼ ìˆ˜ì •í–ˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì´ ì ‘ê·¼ ë°©ì‹ì€ ì™„ì „í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” ë™ë£Œì—ê²Œ ë¨¼ì € í™•ì¸í•˜ê³  ì‹¶ê² ì§€ë§Œ, ì´ë²ˆ ì¥ì—ì„œì˜ ëª©ì ìƒ, ë™ë£Œê°€ ë””í´íŠ¸ configë¥¼ ì‚¬ìš©í–ˆë‹¤ê³  ê°€ì •í•˜ê² ìŠµë‹ˆë‹¤.

</Tip>

ê·¸ëŸ° ë‹¤ìŒ config í´ë˜ìŠ¤ì˜ `push_to_hub()` ê¸°ëŠ¥ì„ ì‚¬ìš©í•´ì„œ config íŒŒì¼ì„ ëª¨ë¸ ì €ì¥ì†Œë¡œ í‘¸ì‹œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
We can then push this to our model repository with the configuration's `push_to_hub()` function:

```python
config.push_to_hub(model_checkpoint, commit_message="Add config.json")
```

ì´ì œ `main` ë¸Œëœì¹˜ì˜ ìµœì‹  ì»¤ë°‹ì—ì„œ ëª¨ë¸ì„ ë¡œë“œí•´ì„œ ì‘ë™ ì—¬ë¶€ë¥¼ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
reader = pipeline("question-answering", model=model_checkpoint, revision="main")

context = r"""
Extractive Question Answering is the task of extracting an answer from a text
given a question. An example of a question answering dataset is the SQuAD
dataset, which is entirely based on that task. If you would like to fine-tune a
model on a SQuAD task, you may leverage the
examples/pytorch/question-answering/run_squad.py script.

ğŸ¤— Transformers is interoperable with the PyTorch, TensorFlow, and JAX
frameworks, so you can use your favourite tools for a wide variety of tasks!
"""

question = "What is extractive question answering?"
reader(question=question, context=context)
```

```python out
{'score': 0.38669535517692566,
 'start': 34,
 'end': 95,
 'answer': 'the task of extracting an answer from a text given a question'}
```

ìœ í›„, ë™ì‘í•˜ë„¤ìš”! ë°©ê¸ˆ ë°°ìš´ ë‚´ìš©ì„ ìš”ì•½ í•´ë³´ê² ìŠµë‹ˆë‹¤:

- Pythonì˜ ì˜¤ë¥˜ ë©”ì‹œì§€ëŠ” _tracebacks_ë¡œ ì•Œë ¤ì ¸ ìˆìœ¼ë©° ì•„ë˜ì—ì„œ ìœ„ë¡œ ì½ìŠµë‹ˆë‹¤. ì˜¤ë¥˜ ë©”ì‹œì§€ì˜ ë§ˆì§€ë§‰ ì¤„ì—ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ë¬¸ì œì˜ ì›ì¸ì„ ì°¾ëŠ” ë° í•„ìš”í•œ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
- ë§ˆì§€ë§‰ ì¤„ì— ì¶©ë¶„í•œ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆì§€ ì•Šìœ¼ë©´ tracebackì„ ìœ„ë¡œ í›‘ì–´ë³´ê³  ì†ŒìŠ¤ ì½”ë“œì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí•œ ìœ„ì¹˜ë¥¼ ì‹ë³„í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
- ì˜¤ë¥˜ ë©”ì‹œì§€ê°€ ë¬¸ì œë¥¼ ë””ë²„ê·¸í•˜ëŠ” ë° ë„ì›€ì´ ë˜ì§€ ì•Šìœ¼ë©´ ì˜¨ë¼ì¸ì—ì„œ ìœ ì‚¬í•œ ë¬¸ì œì— ëŒ€í•œ í•´ê²°ì±…ì„ ê²€ìƒ‰í•´ ë³´ì„¸ìš”.
- `huggingface_hub` 
// ğŸ¤— Hub?
ì´ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” í—ˆë¸Œì˜ ì €ì¥ì†Œì™€ ìƒí˜¸ ì‘ìš©í•˜ê³  ë””ë²„ê·¸í•˜ëŠ” ë° ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” íˆ´ë“¤ì„ ì œê³µí•©ë‹ˆë‹¤.

ì´ì œ íŒŒì´í”„ë¼ì¸ì„ ë””ë²„ê¹…í•˜ëŠ” ë°©ë²•ì„ ì•Œì•˜ìœ¼ë‹ˆ ëª¨ë¸ ìì²´ì˜ forward passì—ì„œ ë” ê¹Œë‹¤ë¡œìš´ ì˜ˆë¥¼ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.

## ëª¨ë¸ì˜ foward pass ë””ë²„ê¹…

'pipeline'ì€ ë¹ ë¥´ê²Œ ì˜ˆì¸¡ì„ ìƒì„±í•´ì•¼ í•˜ëŠ” ëŒ€ë¶€ë¶„ì˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì— ì í•©í•˜ì§€ë§Œ ë•Œë¡œëŠ” ëª¨ë¸ì˜ logitsê°’ì— ì ‘ê·¼í•´ì•¼ í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤(ì˜ˆ: ì ìš©í•˜ë ¤ëŠ” ì»¤ìŠ¤í…€ í›„ì²˜ë¦¬ ê³¼ì •ì´ ìˆëŠ” ê²½ìš°). ì´ ê²½ìš° ë¬´ì—‡ì´ ì˜ëª»ë  ìˆ˜ ìˆëŠ”ì§€ ì•Œì•„ë³´ê¸° ìœ„í•´ ë¨¼ì € `pipeline`ì—ì„œ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ê°€ì ¸ì™€ ë³´ê² ìŠµë‹ˆë‹¤:

```python
tokenizer = reader.tokenizer
model = reader.model
```
ë‹¤ìŒìœ¼ë¡œ ì§ˆë¬¸ì´ í•„ìš”í•©ë‹ˆë‹¤. ì„ í˜¸í•˜ëŠ” í”„ë ˆì„ì›Œí¬ê°€ ì§€ì›ë˜ëŠ”ì§€ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤:

```python
question = "Which frameworks can I use?"
```
[ë‹¨ì› 7](/course/chapter7)ì—ì„œ ë³´ì•˜ë“¯ì´ ì¼ë°˜ì ì¸ ë‹¨ê³„ëŠ” ì…ë ¥ì„ í† í°í™”í•˜ê³  ì‹œì‘ê³¼ ë§ˆì§€ë§‰ í† í°ì˜ logitsë¥¼ ì¶”ì¶œí•œ ë‹¤ìŒ ì‘ë‹µ ë¶€ë¶„ì„ ë””ì½”ë”©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤:

```python
import torch

inputs = tokenizer(question, context, add_special_tokens=True)
input_ids = inputs["input_ids"][0]
outputs = model(**inputs)
answer_start_scores = outputs.start_logits
answer_end_scores = outputs.end_logits
# Get the most likely beginning of answer with the argmax of the score
answer_start = torch.argmax(answer_start_scores)
# Get the most likely end of answer with the argmax of the score
answer_end = torch.argmax(answer_end_scores) + 1
answer = tokenizer.convert_tokens_to_string(
    tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end])
)
print(f"Question: {question}")
print(f"Answer: {answer}")
```

```python out
"""
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
/var/folders/28/k4cy5q7s2hs92xq7_h89_vgm0000gn/T/ipykernel_75743/2725838073.py in <module>
      1 inputs = tokenizer(question, text, add_special_tokens=True)
      2 input_ids = inputs["input_ids"]
----> 3 outputs = model(**inputs)
      4 answer_start_scores = outputs.start_logits
      5 answer_end_scores = outputs.end_logits

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)
   1049         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
   1050                 or _global_forward_hooks or _global_forward_pre_hooks):
-> 1051             return forward_call(*input, **kwargs)
   1052         # Do not call functions when jit is used
   1053         full_backward_hooks, non_full_backward_hooks = [], []

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py in forward(self, input_ids, attention_mask, head_mask, inputs_embeds, start_positions, end_positions, output_attentions, output_hidden_states, return_dict)
    723         return_dict = return_dict if return_dict is not None else self.config.use_return_dict
    724
--> 725         distilbert_output = self.distilbert(
    726             input_ids=input_ids,
    727             attention_mask=attention_mask,

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)
   1049         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
   1050                 or _global_forward_hooks or _global_forward_pre_hooks):
-> 1051             return forward_call(*input, **kwargs)
   1052         # Do not call functions when jit is used
   1053         full_backward_hooks, non_full_backward_hooks = [], []

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py in forward(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)
    471             raise ValueError("You cannot specify both input_ids and inputs_embeds at the same time")
    472         elif input_ids is not None:
--> 473             input_shape = input_ids.size()
    474         elif inputs_embeds is not None:
    475             input_shape = inputs_embeds.size()[:-1]

AttributeError: 'list' object has no attribute 'size'
"""
```

ì´ëŸ°, ì½”ë“œì— ë²„ê·¸ê°€ ìˆëŠ” ê²ƒ ê°™ë„¤ìš”! í•˜ì§€ë§Œ ì•½ê°„ì˜ ë””ë²„ê¹…ì€ ë‘ë µì§€ ì•ŠìŠµë‹ˆë‹¤. ë…¸íŠ¸ë¶ì—ì„œ íŒŒì´ì¬ ë””ë²„ê±°ë¥¼ ì‚¬ìš© í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

<Youtube id="rSPyvPw0p9k"/>

ë˜ëŠ” í„°ë¯¸ë„ì—ì„œ:

<Youtube id="5PkZ4rbHL6c"/>

ì—¬ê¸°ì—ì„œ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ì½ìœ¼ë©´ `'list' ê°ì²´ì—ëŠ” 'size' ì†ì„±ì´ ì—†ìœ¼ë©° `model(**inputs)'ì—ì„œ ë¬¸ì œê°€ ë°œìƒí•œ ë¼ì¸ì„ ê°€ë¦¬í‚¤ëŠ” `-->` í™”ì‚´í‘œë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. `.Python ë””ë²„ê±°ë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€í™”ì‹ìœ¼ë¡œ ë””ë²„ê·¸í•  ìˆ˜ ìˆì§€ë§Œ ì§€ê¸ˆì€ ë‹¨ìˆœíˆ `inputs` ë¶€ë¶„ì„ ìŠ¬ë¼ì´ìŠ¤í•˜ì—¬ ì–´ë–¤ ê°’ì´ ìˆëŠ”ì§€ ë³¼ ê²ƒì…ë‹ˆë‹¤:

```python
inputs["input_ids"][:5]
```

```python out
[101, 2029, 7705, 2015, 2064]
```

í™•ì‹¤íˆ ì¼ë°˜ì ì¸ Python `list`ì²˜ëŸ¼ ë³´ì´ì§€ë§Œ íƒ€ì…ì„ ë‹¤ì‹œ í™•ì¸í•©ì‹œë‹¤:

```python
type(inputs["input_ids"])
```

```python out
list
```

ë„¤, í™•ì‹¤íˆ íŒŒì´ì¬ì˜ `list`ì…ë‹ˆë‹¤. ë¬´ì—‡ì´ ì˜ëª»ë˜ì—ˆì„ê¹Œìš”? [ë‹¨ì› 2](/course/chapter2)ì—ì„œ ğŸ¤— Transformersì˜ `AutoModelForXxx` í´ë˜ìŠ¤ëŠ” _tensors_(PyTorch ë˜ëŠ” TensorFlow í¬í•¨)ì—ì„œ ì‘ë™í•˜ë©° tensorì˜ dimensionsë¥¼ ì¶”ì¶œí•˜ê¸° ìœ„í•´ ì¼ë°˜ì ì¸ ë°©ë²•ìœ¼ë¡œ PyTorchì˜ `Tensor.size()`ë¥¼ í™œìš©í•©ë‹ˆë‹¤. ì–´ë–¤ ë¼ì¸ì´ ì˜ˆì™¸ë¥¼ ë°œìƒì‹œì¼°ëŠ”ì§€ ì•Œì•„ë³´ê¸° ìœ„í•´ tracebackì„ ë‹¤ì‹œ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤:

```
~/miniconda3/envs/huggingface/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py in forward(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)
    471             raise ValueError("You cannot specify both input_ids and inputs_embeds at the same time")
    472         elif input_ids is not None:
--> 473             input_shape = input_ids.size()
    474         elif inputs_embeds is not None:
    475             input_shape = inputs_embeds.size()[:-1]

AttributeError: 'list' object has no attribute 'size'
```

ì½”ë“œê°€ `input_ids.size()`ë¥¼ í˜¸ì¶œí•˜ë ¤ê³  í•˜ì§€ë§Œ, Python `list`ì—ì„œëŠ” ì ˆëŒ€ ë™ì‘í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì´ ë¬¸ì œë¥¼ ì–´ë–»ê²Œ í•´ê²°í•  ìˆ˜ ìˆì„ê¹Œìš”? ìŠ¤íƒì˜¤ë²„í”Œë¡œìš°ì—ì„œ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ê²€ìƒ‰í•˜ë©´ ê½¤ ë§ì€ ê´€ë ¨ [í•´ê²°ì±…](https://stackoverflow.com/search?q=AttributeError%3A+%27list%27+object+has+no+attribute+%27size%27&s=c15ec54c-63cb-481d-a749-408920073e8f)ì„ ì œê³µí•©ë‹ˆë‹¤. ì²« ë²ˆì§¸ ì§ˆë¬¸ì„ í´ë¦­í•˜ë©´ ì•„ë˜ ìŠ¤í¬ë¦°ìƒ·ì— í‘œì‹œëœ ë‹µë³€ê³¼ í•¨ê»˜ ìš°ë¦¬ì™€ ìœ ì‚¬í•œ ì§ˆë¬¸ì´ í‘œì‹œë©ë‹ˆë‹¤:

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter8/stack-overflow.png" alt="An answer from Stack Overflow." width="100%"/>
</div>

ëŒ€ë‹µì€ í† í¬ë‚˜ì´ì €ì— `return_tensors='pt'`ë¥¼ ì¶”ê°€í•  ê²ƒì„ ê¶Œì¥í•˜ëŠ”ë°, ì´ê²Œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•´ ë³´ê² ìŠµë‹ˆë‹¤:

```python out
inputs = tokenizer(question, context, add_special_tokens=True, return_tensors="pt")
input_ids = inputs["input_ids"][0]
outputs = model(**inputs)
answer_start_scores = outputs.start_logits
answer_end_scores = outputs.end_logits
# Get the most likely beginning of answer with the argmax of the score
answer_start = torch.argmax(answer_start_scores)
# Get the most likely end of answer with the argmax of the score
answer_end = torch.argmax(answer_end_scores) + 1
answer = tokenizer.convert_tokens_to_string(
    tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end])
)
print(f"Question: {question}")
print(f"Answer: {answer}")
```

```python out
"""
Question: Which frameworks can I use?
Answer: pytorch, tensorflow, and jax
"""
```

ì˜ ë™ì‘í•˜ë„¤ìš”! ì´ê²Œ ë°”ë¡œ ìŠ¤íƒì˜¤ë²„í”Œë¡œìš°ê°€ ì–¼ë§ˆë‚˜ ìœ ìš©í•œì§€ ë³´ì—¬ì£¼ëŠ” ì¢‹ì€ ì˜ˆì…ë‹ˆë‹¤. ìœ ì‚¬í•œ ë¬¸ì œë¥¼ ì‹ë³„í•˜ì—¬ ì»¤ë®¤ë‹ˆí‹°ì˜ ë‹¤ë¥¸ ì‚¬ëŒë“¤ì˜ ê²½í—˜ì„ í™œìš©í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ì™€ ê°™ì€ ê²€ìƒ‰ì´ í•­ìƒ ì ì ˆí•œ ë‹µë³€ì„ ì œê³µí•˜ëŠ” ê²ƒì€ ì•„ë‹™ë‹ˆë‹¤. ì´ëŸ¬í•œ ê²½ìš°ì— ë¬´ì—‡ì„ í•  ìˆ˜ ìˆì„ê¹Œìš”? ë‹¤í–‰íˆë„ [Hugging Face forums](https://discuss.huggingface.co/)ì— ì—¬ëŸ¬ë¶„ì„ ë°˜ê¸°ê³  ë„ì™€ì¤„ ìˆ˜ ìˆëŠ” ê°œë°œì ì»¤ë®¤ë‹ˆí‹°ê°€ ìˆìŠµë‹ˆë‹¤! ë‹¤ìŒ ì¥ì—ì„œëŠ” ë‹µë³€ì„ ì–»ì„ ìˆ˜ ìˆëŠ” ì¢‹ì€ í¬ëŸ¼ ì§ˆë¬¸ì„ ë§Œë“œëŠ” ë°©ë²•ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.