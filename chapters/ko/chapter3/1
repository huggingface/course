<FrameworkSwitchCourse {fw} />

# 소개[[introduction]]

<CourseFloatingBanner
    chapter={3}
    classNames="absolute z-10 right-0 top-0"
/>

[Chapter 2](/course/chapter2)에서는 토크나이저와 사전학습된 모델을 사용해 예측하는 방법을 배웠습니다.  
하지만 **특정 작업에 맞춰 사전학습 모델을 파인튜닝하고 싶다면 어떻게 해야 할까요?**  
바로 이 챕터에서 다루는 주제입니다! 이번 장에서는 다음과 같은 내용을 학습하게 됩니다:

* 최신 🤗 Datasets 기능을 활용하여 허브에서 대규모 데이터셋을 준비하는 방법
* 고수준 `Trainer` API를 사용해 현대적인 방식으로 모델을 파인튜닝하는 방법
* 사용자 정의 학습 루프를 직접 구현하고 최적화 기법을 적용하는 방법
* 🤗 Accelerate 라이브러리를 활용해 어떤 환경에서도 쉽게 분산 학습을 실행하는 방법
* 최신 파인튜닝 베스트 프랙티스를 적용해 최대 성능을 얻는 방법

<Tip>

📚 **필수 참고자료**: 시작하기 전에 [🤗 Datasets 문서](https://huggingface.co/docs/datasets/)를 읽고 데이터 처리 개념을 복습해 보세요.

</Tip>

이번 장에서는 🤗 Transformers 외에도 Hugging Face의 다양한 라이브러리를 소개합니다.  
🤗 Datasets, 🤗 Tokenizers, 🤗 Accelerate, 🤗 Evaluate 같은 도구들이  
모델을 더 효율적이고 효과적으로 학습시키는 데 어떤 도움을 주는지 살펴볼 것입니다.

각 섹션에서는 다음과 같은 주제를 다룹니다:

- **2절**: 최신 데이터 전처리 기법과 효율적인 데이터셋 처리 방법
- **3절**: 최신 기능이 반영된 Trainer API 완전 정복
- **4절**: 사용자 정의 학습 루프 구현과 Accelerate를 통한 분산 학습 이해

이 장을 마치면, 고수준 API와 사용자 정의 방식 모두를 활용해  
자신의 데이터셋에 모델을 파인튜닝할 수 있게 될 것입니다.  
또한 최신 업계 표준을 따르는 베스트 프랙티스를 적용하는 법도 배우게 됩니다.

<Tip>

🎯 **직접 만들어볼 프로젝트**:  
이 챕터가 끝나면, BERT 모델을 텍스트 분류 작업에 맞춰 파인튜닝해보게 되며,  
이 기술을 자신만의 데이터셋과 작업에 어떻게 적용할 수 있을지 이해하게 됩니다.

</Tip>

이 챕터는 **PyTorch 전용**으로 진행됩니다.  
PyTorch는 현재 딥러닝 연구 및 실무의 표준 프레임워크로 자리잡았기 때문입니다.  
Hugging Face 생태계에서 제공하는 최신 API와 베스트 프랙티스를 적극 활용할 것입니다.

훈련한 모델을 Hugging Face Hub에 업로드하려면 Hugging Face 계정이 필요합니다:  
👉 [계정 만들기](https://huggingface.co/join)
