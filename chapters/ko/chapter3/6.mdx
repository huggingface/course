<FrameworkSwitchCourse {fw} />

# 파인튜닝 완료![[fine-tuning-check]]

<CourseFloatingBanner
    chapter={3}
    classNames="absolute z-10 right-0 top-0"
/>

정말 광범위한 내용을 다뤘습니다! 처음 두 챕터에서 모델과 토크나이저에 대해 배웠고, 이제 최신 모범 사례를 사용하여 여러분의 데이터 세트로 파인튜닝하는 방법을 알게 되었습니다. 요약하자면, 이 챕터에서는 다음을 배웠습니다.

* [Hub](https://huggingface.co/datasets)의 데이터 세트와 최신 데이터 처리 기법에 대해 학습했습니다.
* 동적 패딩과 데이터 콜레이터 사용을 포함하여 데이터 세트를 효율적으로 로드하고 전처리하는 방법을 배웠습니다.
* 최신 기능을 포함한 고수준 `Trainer` API를 사용하여 파인튜닝과 평가를 구현했습니다.
* PyTorch를 사용하여 완전한 커스텀 훈련 루프를 처음부터 구현했습니다.
* 🤗 Accelerate를 사용하여 훈련 코드가 다중 GPU 또는 TPU에서 원활하게 작동하도록 했습니다.
* 혼합 정밀도 훈련과 그래디언트 누적과 같은 최신 최적화 기법을 적용했습니다.

<Tip>

🎉 **축하합니다!** 트랜스포머 모델 파인튜닝의 기초를 마스터했습니다. 이제 실제 ML 프로젝트에 도전할 준비가 되었습니다!

📖 **계속 학습하기**: 지식을 더 깊이 쌓기 위해 다음 리소스를 탐색해보세요.
- 특정 NLP 작업을 위한 [🤗 Transformers 작업 가이드](https://huggingface.co/docs/transformers/main/en/tasks/sequence_classification)
- 포괄적인 노트북을 위한 [🤗 Transformers 예제](https://huggingface.co/docs/transformers/main/en/notebooks)

🚀 **다음 단계** 
- 배운 기법을 사용하여 자신만의 데이터 세트로 파인튜닝을 시도해보세요.
- [Hugging Face Hub](https://huggingface.co/models)에서 사용 가능한 다양한 모델 아키텍처를 실험해보세요.
- [Hugging Face 커뮤니티](https://discuss.huggingface.co/)에 참여하여 프로젝트를 공유하고 도움을 받으세요.

</Tip>

이것은 🤗 Transformers와의 여정의 시작일 뿐입니다. 다음 챕터에서는 모델과 토크나이저를 커뮤니티와 공유하고 계속 성장하는 사전훈련된 모델 생태계에 기여하는 방법을 탐색할 것입니다.

여기서 여러분이 익힌 데이터 전처리, 훈련 구성, 평가, 최적화와 같은 기법들은 모든 기계학습 프로젝트의 기초입니다. 텍스트 분류, 개체 인식, 질의 응답 또는 어떤 NLP 작업을 하든 상관없이, 이러한 기법들이 큰 도움이 될 것입니다.

<Tip>

💡 **성공을 위한 전문가 팁**
- 커스텀 훈련 루프를 구현하기 전에 항상 `Trainer` API를 사용한 강력한 기준선부터 시작하세요.
- 더 나은 출발점을 🤗 Hub을 사용하여 위해 자신의 작업과 유사한 사전훈련된 모델을 찾으세요.
- 적절한 평가 지표로 훈련을 모니터링하고 체크포인트 저장을 잊지 마세요.
- 커뮤니티를 활용하세요 - 모델과 데이터 세트를 공유하여 다른 사람들을 도우고 자신의 작업에 대한 피드백을 받으세요.

</Tip>