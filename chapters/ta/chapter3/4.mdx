# роТро░рпБ роорпБро┤рпБроорпИропро╛рой рокропро┐ро▒рпНроЪро┐роЪрпН роЪрпБро▒рпНро▒рпБ[[a-full-training]]

<CourseFloatingBanner chapter={3}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/ta/chapter3/section4.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/ta/chapter3/section4.ipynb"},
]} />

<Youtube id="Dh9CL8fyG80"/>

роЗрокрпНрокрпЛродрпБ, роХроЯроирпНрод рокроХрпБродро┐ропро┐ро▓рпН роиро╛роорпН рокрпЖро▒рпНро▒ роЕродрпЗ роорпБроЯро┐ро╡рпБроХро│рпИ `Trainer` class-роРрокрпН рокропройрпНрокроЯрпБродрпНродро╛рооро▓рпН, роиро╡рпАрой PyTorch роЪро┐ро▒роирпНрод роироЯрпИроорпБро▒рпИроХро│рпБроЯройрпН роТро░рпБ рокропро┐ро▒рпНроЪро┐роЪрпН роЪрпБро▒рпНро▒рпИ рокрпБродро┐родро╛роХ роЪрпЖропро▓рпНрокроЯрпБродрпНродрпБро╡родрпБ роОрокрпНрокроЯро┐ роОройрпНро▒рпБ рокро╛ро░рпНрокрпНрокрпЛроорпН. роорпАрогрпНроЯрпБроорпН, роирпАроЩрпНроХро│рпН рокроХрпБродро┐ 2-роЗро▓рпН роЙро│рпНро│ родро░ро╡рпБ роЪрпЖропро▓ро╛роХрпНроХродрпНродрпИ роЪрпЖропрпНродрпБро╡ро┐роЯрпНроЯрпАро░рпНроХро│рпН роОройрпНро▒рпБ роХро░рпБродрпБроХро┐ро▒рпЛроорпН. роЙроЩрпНроХро│рпБроХрпНроХрпБродрпН родрпЗро╡рпИропро╛рой роЕройрпИродрпНродрпИропрпБроорпН роЙро│рпНро│роЯроХрпНроХро┐роп роТро░рпБ роХрпБро▒рпБроХро┐роп роЪрпБро░рпБроХрпНроХроорпН роЗроЩрпНроХрпЗ:

<Tip>

ЁЯПЧя╕П **рокрпБродро┐родро╛роХ рокропро┐ро▒рпНроЪро┐**: роЗроирпНродрокрпН рокроХрпБродро┐ роорпБроирпНродрпИроп роЙро│рпНро│роЯроХрпНроХродрпНродрпИ роЕроЯро┐рокрпНрокроЯрпИропро╛роХроХрпН роХрпКрогрпНроЯродрпБ. PyTorch рокропро┐ро▒рпНроЪро┐роЪрпН роЪрпБро▒рпНро▒рпБроХро│рпН рооро▒рпНро▒рпБроорпН роЪро┐ро▒роирпНрод роироЯрпИроорпБро▒рпИроХро│рпН рокро▒рпНро▒ро┐роп ро╡ро┐ро░ро┐ро╡ро╛рой ро╡ро┤ро┐роХро╛роЯрпНроЯрпБродро▓рпБроХрпНроХрпБ, [ЁЯдЧ Transformers рокропро┐ро▒рпНроЪро┐ роЖро╡рогроЩрпНроХро│рпН](https://huggingface.co/docs/transformers/main/en/training#train-in-native-pytorch) рооро▒рпНро▒рпБроорпН [родройро┐рокрпНрокропройрпН рокропро┐ро▒рпНроЪро┐ cookbook](https://huggingface.co/learn/cookbook/en/fine_tuning_code_llm_on_single_gpu#model)-роРрокрпН рокро╛ро░рпНроХрпНроХро╡рпБроорпН.

</Tip>

```py
from datasets import load_dataset
from transformers import AutoTokenizer, DataCollatorWithPadding

raw_datasets = load_dataset("glue", "mrpc")
checkpoint = "bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)


def tokenize_function(example):
    return tokenizer(example["sentence1"], example["sentence2"], truncation=True)


tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)
data_collator = DataCollatorWithPadding(tokenizer=tokenizer)
```

### рокропро┐ро▒рпНроЪро┐роХрпНроХро╛роХродрпН родропро╛ро░ро╛роХрпБродро▓рпН[[prepare-for-training]]

роироородрпБ рокропро┐ро▒рпНроЪро┐роЪрпН роЪрпБро▒рпНро▒рпИ роОро┤рпБродрпБро╡родро▒рпНроХрпБ роорпБройрпН, роиро╛роорпН роЪро┐ро▓ object-роХро│рпИ ро╡ро░рпИропро▒рпБроХрпНроХ ро╡рпЗрогрпНроЯрпБроорпН. роорпБродро▓ро╛ро╡родро╛роХ, batch-роХро│рпИ iterate роЪрпЖропрпНроп роиро╛роорпН рокропройрпНрокроЯрпБродрпНродрпБроорпН dataloader-роХро│рпН. роЖройро╛ро▓рпН роЕроирпНрод dataloader-роХро│рпИ ро╡ро░рпИропро▒рпБрокрпНрокродро▒рпНроХрпБ роорпБройрпН, роироородрпБ `tokenized_datasets`-роЗро▓рпН роЪро┐ро▓ рокро┐роирпНродрпИроп роЪрпЖропро▓ро╛роХрпНроХроЩрпНроХро│рпИроЪрпН роЪрпЖропрпНроп ро╡рпЗрогрпНроЯрпБроорпН. `Trainer` роироороХрпНроХро╛роХ родро╛ройро╛роХро╡рпЗ роЪрпЖропрпНрод роЪро┐ро▓ ро╡ро┐ро╖ропроЩрпНроХро│рпИроХрпН роХро╡ройро┐родрпНродрпБроХрпН роХрпКро│рпНро│ ро╡рпЗрогрпНроЯрпБроорпН. роХрпБро▒ро┐рокрпНрокро╛роХ, роиро╛роорпН роЪрпЖропрпНроп ро╡рпЗрогрпНроЯро┐ропро╡рпИ:

- рооро╛роЯро▓рпН роОродро┐ро░рпНрокро╛ро░рпНроХрпНроХро╛род роородро┐рокрпНрокрпБроХро│рпБроЯройрпН родрпКроЯро░рпНрокрпБроЯрпИроп роиро┐ро░ро▓рпНроХро│рпИ роирпАроХрпНроХрпБродро▓рпН (`sentence1` рооро▒рпНро▒рпБроорпН `sentence2` роиро┐ро░ро▓рпНроХро│рпН рокрпЛройрпНро▒ро╡рпИ).
- `label` роОройрпНро▒ роиро┐ро░ро▓рпИ `labels` роОройрпНро▒рпБ рокрпЖропро░рпН рооро╛ро▒рпНро▒рпБродро▓рпН (роПройрпЖройро┐ро▓рпН рооро╛роЯро▓рпН роЗроирпНрод argument-роР `labels` роОройрпНро▒рпБ роОродро┐ро░рпНрокро╛ро░рпНроХрпНроХро┐ро▒родрпБ).
- datasets-роХро│ро┐ройрпН ро╡роЯро┐ро╡родрпНродрпИ PyTorch tensor-роХро│ро╛роХродрпН родро┐ро░рпБрокрпНрокро┐родрпН родро░рпБроорпНрокроЯро┐ роЕроорпИродрпНродро▓рпН.

роироородрпБ `tokenized_datasets` роЗроирпНрод роТро╡рпНро╡рпКро░рпБ рокроЯро┐роХрпНроХрпБроорпН роТро░рпБ роорпБро▒рпИропрпИроХрпН роХрпКрогрпНроЯрпБро│рпНро│родрпБ:

```py
tokenized_datasets = tokenized_datasets.remove_columns(["sentence1", "sentence2", "idx"])
tokenized_datasets = tokenized_datasets.rename_column("label", "labels")
tokenized_datasets.set_format("torch")
tokenized_datasets["train"].column_names
```

роорпБроЯро┐ро╡ро┐ро▓рпН роироородрпБ рооро╛роЯро▓рпН роПро▒рпНро▒рпБроХрпНроХрпКро│рпНро│рпБроорпН роиро┐ро░ро▓рпНроХро│рпН роороЯрпНроЯрпБроорпЗ роЙро│рпНро│родро╛ роОройрпНрокродрпИ роиро╛роорпН роЪро░ро┐рокро╛ро░рпНроХрпНроХро▓ро╛роорпН:

```python
["attention_mask", "input_ids", "labels", "token_type_ids"]
```

роЗрокрпНрокрпЛродрпБ роЗродрпБ роорпБроЯро┐роирпНродродрпБроорпН, роироородрпБ dataloader-роХро│рпИ роОро│ро┐родро╛роХ ро╡ро░рпИропро▒рпБроХрпНроХро▓ро╛роорпН:

```py
from torch.utils.data import DataLoader

train_dataloader = DataLoader(
    tokenized_datasets["train"], shuffle=True, batch_size=8, collate_fn=data_collator
)
eval_dataloader = DataLoader(
    tokenized_datasets["validation"], batch_size=8, collate_fn=data_collator
)
```

родро░ро╡рпБ роЪрпЖропро▓ро╛роХрпНроХродрпНродро┐ро▓рпН роОроирпНродродрпН родро╡ро▒рпБроорпН роЗро▓рпНро▓рпИ роОройрпНрокродрпИ ро╡ро┐ро░рпИро╡ро╛роХроЪрпН роЪро░ро┐рокро╛ро░рпНроХрпНроХ, роТро░рпБ batch-роР роЗро╡рпНро╡ро╛ро▒рпБ роЖропрпНро╡рпБ роЪрпЖропрпНропро▓ро╛роорпН:

```py
for batch in train_dataloader:
    break
{k: v.shape for k, v in batch.items()}
```

```python out
{'attention_mask': torch.Size([8, 65]),
 'input_ids': torch.Size([8, 65]),
 'labels': torch.Size([8]),
 'token_type_ids': torch.Size([8, 65])}
```

рокропро┐ро▒рпНроЪро┐ dataloader-роХрпНроХрпБ `shuffle=True` роОройрпНро▒рпБ роЕроорпИродрпНродрпБро│рпНро│родро╛ро▓рпБроорпН, batch-роХрпНроХрпБро│рпН роЕродро┐роХрокроЯрпНроЪ роирпАро│родрпНродро┐ро▒рпНроХрпБ padding роЪрпЖропрпНро╡родро╛ро▓рпБроорпН, роЙрогрпНроорпИропро╛рой ро╡роЯро┐ро╡роЩрпНроХро│рпН роЙроЩрпНроХро│рпБроХрпНроХрпБроЪрпН роЪро▒рпНро▒рпБ ро╡ро┐родрпНродро┐ропро╛роЪрооро╛роХ роЗро░рпБроХрпНроХро▓ро╛роорпН.

роЗрокрпНрокрпЛродрпБ роиро╛роорпН родро░ро╡рпБ роорпБройрпНродропро╛ро░ро┐рокрпНрокрпИ роорпБро┤рпБроорпИропро╛роХ роорпБроЯро┐родрпНродрпБро╡ро┐роЯрпНроЯрпЛроорпН (роОроирпНродро╡рпКро░рпБ ML рокропро┐ро▒рпНроЪро┐ропро╛ро│ро░рпБроХрпНроХрпБроорпН роЗродрпБ роТро░рпБ родро┐ро░рпБрокрпНродро┐роХро░рооро╛рой роЖройро╛ро▓рпН роХроЯро┐ройрооро╛рой роЗро▓роХрпНроХрпБ), рооро╛роЯро▓рпБроХрпНроХрпБроЪрпН роЪрпЖро▓рпНро╡рпЛроорпН. роорпБроирпНродрпИроп рокроХрпБродро┐ропро┐ро▓рпН роЪрпЖропрпНродродрпИрокрпН рокрпЛро▓ро╡рпЗ роЕродрпИ роЙро░рпБро╡ро╛роХрпНроХрпБроХро┐ро▒рпЛроорпН:

```py
from transformers import AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)
```

рокропро┐ро▒рпНроЪро┐ропро┐ройрпН рокрпЛродрпБ роОро▓рпНро▓ро╛роорпН роЪрпАро░ро╛роХ роироЯроХрпНроХрпБроорпН роОройрпНрокродрпИ роЙро▒рпБродро┐рокрпНрокроЯрпБродрпНрод, роироородрпБ batch-роР роЗроирпНрод рооро╛роЯро▓рпБроХрпНроХрпБ роЕройрпБрокрпНрокрпБроХро┐ро▒рпЛроорпН:

```py
outputs = model(**batch)
print(outputs.loss, outputs.logits.shape)
```

```python out
tensor(0.5441, grad_fn=<NllLossBackward>) torch.Size([8, 2])
```

`labels` ро╡ро┤роЩрпНроХрокрпНрокроЯрпБроорпНрокрпЛродрпБ роЕройрпИродрпНродрпБ ЁЯдЧ Transformers рооро╛роЯро▓рпНроХро│рпБроорпН loss-роРродрпН родро┐ро░рпБрокрпНрокро┐родрпН родро░рпБроорпН, роорпЗро▓рпБроорпН роиро╛роорпН logits-роХро│рпИропрпБроорпН рокрпЖро▒рпБроХро┐ро▒рпЛроорпН (роироородрпБ batch-роЗро▓рпН роЙро│рпНро│ роТро╡рпНро╡рпКро░рпБ роЙро│рпНро│рпАроЯрпНроЯро┐ро▒рпНроХрпБроорпН роЗро░рогрпНроЯрпБ, роОройро╡рпЗ 8 x 2 роЕро│ро╡рпБро│рпНро│ роТро░рпБ tensor).

роироородрпБ рокропро┐ро▒рпНроЪро┐роЪрпН роЪрпБро▒рпНро▒рпИ роОро┤рпБрод роиро╛роорпН роХро┐роЯрпНроЯродрпНродроЯрпНроЯ родропро╛ро░ро╛роХро┐ро╡ро┐роЯрпНроЯрпЛроорпН! роироороХрпНроХрпБ роЗройрпНройрпБроорпН роЗро░рогрпНроЯрпБ ро╡ро┐ро╖ропроЩрпНроХро│рпН родрпЗро╡рпИ: роТро░рпБ optimizer рооро▒рпНро▒рпБроорпН роТро░рпБ learning rate scheduler. `Trainer` роЪрпЖропрпНродродрпИ роиро╛роорпЗ роорпАрогрпНроЯрпБроорпН роЪрпЖропрпНроп роорпБропро▒рпНроЪро┐рокрпНрокродро╛ро▓рпН, роЕродрпЗ роЗропро▓рпНрокрпБроиро┐ро▓рпИ роЕроорпИрокрпНрокрпБроХро│рпИрокрпН рокропройрпНрокроЯрпБродрпНродрпБро╡рпЛроорпН. `Trainer` рокропройрпНрокроЯрпБродрпНродрпБроорпН optimizer `AdamW` роЖроХрпБроорпН, роЗродрпБ Adam-роРрокрпН рокрпЛройрпНро▒родрпБ, роЖройро╛ро▓рпН weight decay regularization-роХрпНроХрпБ роТро░рпБ родро┐ро░рпБрокрпНрокродрпНродрпБроЯройрпН (Ilya Loshchilov рооро▒рпНро▒рпБроорпН Frank Hutter роОро┤рпБродро┐роп ["Decoupled Weight Decay Regularization"](https://arxiv.org/abs/1711.05101) рокро╛ро░рпНроХрпНроХро╡рпБроорпН):

```py
from torch.optim import AdamW

optimizer = AdamW(model.parameters(), lr=5e-5)
```

<Tip>

ЁЯТб **роиро╡рпАрой роорпЗроорпНрокроЯрпБродрпНродро▓рпН роХрпБро▒ро┐рокрпНрокрпБроХро│рпН**: роЗройрпНройрпБроорпН роЪро┐ро▒роирпНрод роЪрпЖропро▓рпНродро┐ро▒ройрпБроХрпНроХрпБ, роирпАроЩрпНроХро│рпН роорпБропро▒рпНроЪро┐ роЪрпЖропрпНропро▓ро╛роорпН:
- **Weight decay роЙроЯройрпН AdamW**: `AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)`
- **8-bit Adam**: роиро┐ройрпИро╡роХ-родро┐ро▒ройрпБро│рпНро│ роорпЗроорпНрокроЯрпБродрпНродро▓рпБроХрпНроХрпБ `bitsandbytes`-роРрокрпН рокропройрпНрокроЯрпБродрпНродро╡рпБроорпН
- **ро╡рпЖро╡рпНро╡рпЗро▒рпБ learning rate-роХро│рпН**: роХрпБро▒рпИроирпНрод learning rate-роХро│рпН (1e-5 роорпБродро▓рпН 3e-5 ро╡ро░рпИ) рокрпЖро░ро┐роп рооро╛роЯро▓рпНроХро│рпБроХрпНроХрпБ рокрпЖро░рпБроорпНрокро╛ро▓рпБроорпН роЪро┐ро▒рокрпНрокро╛роХроЪрпН роЪрпЖропро▓рпНрокроЯрпБроорпН

ЁЯЪА **роорпЗроорпНрокроЯрпБродрпНродро▓рпН роЖродро╛ро░роЩрпНроХро│рпН**: optimizers рооро▒рпНро▒рпБроорпН рокропро┐ро▒рпНроЪро┐ роЙродрпНродро┐роХро│рпН рокро▒рпНро▒ро┐ [ЁЯдЧ Transformers роорпЗроорпНрокроЯрпБродрпНродро▓рпН ро╡ро┤ро┐роХро╛роЯрпНроЯро┐](https://huggingface.co/docs/transformers/main/en/performance#optimizer)-роЗро▓рпН роорпЗро▓рпБроорпН роЕро▒ро┐ропро╡рпБроорпН.

</Tip>

роЗро▒рпБродро┐ропро╛роХ, роЗропро▓рпНрокро╛роХрокрпН рокропройрпНрокроЯрпБродрпНродрокрпНрокроЯрпБроорпН learning rate scheduler, роЕродро┐роХрокроЯрпНроЪ роородро┐рокрпНрокро┐ро▓ро┐ро░рпБроирпНродрпБ (5e-5) 0 ро╡ро░рпИ роТро░рпБ роирпЗро░ро┐ропро▓рпН роЪро┐родрпИро╡рпБ роЖроХрпБроорпН. роЕродрпИроЪрпН роЪро░ро┐ропро╛роХ ро╡ро░рпИропро▒рпБроХрпНроХ, роиро╛роорпН роОроЯрпБроХрпНроХрокрпН рокрпЛроХрпБроорпН рокропро┐ро▒рпНроЪро┐рокрпН рокроЯро┐роХро│ро┐ройрпН роОрогрпНрогро┐роХрпНроХрпИропрпИродрпН родрпЖро░ро┐роирпНродрпБ роХрпКро│рпНро│ ро╡рпЗрогрпНроЯрпБроорпН, роЗродрпБ роиро╛роорпН роЗропроХрпНроХ ро╡ро┐ро░рпБроорпНрокрпБроорпН epoch-роХро│ро┐ройрпН роОрогрпНрогро┐роХрпНроХрпИропрпИ рокропро┐ро▒рпНроЪро┐ batch-роХро│ро┐ройрпН роОрогрпНрогро┐роХрпНроХрпИропро╛ро▓рпН рокрпЖро░рпБроХрпНроХрпБро╡родро╛роХрпБроорпН (роЗродрпБ роироородрпБ рокропро┐ро▒рпНроЪро┐ dataloader-роЗройрпН роирпАро│роорпН). `Trainer` роЗропро▓рпНрокро╛роХ роорпВройрпНро▒рпБ epoch-роХро│рпИрокрпН рокропройрпНрокроЯрпБродрпНродрпБроХро┐ро▒родрпБ, роОройро╡рпЗ роЕродрпИрокрпН рокро┐ройрпНрокро▒рпНро▒рпБро╡рпЛроорпН:

```py
from transformers import get_scheduler

num_epochs = 3
num_training_steps = num_epochs * len(train_dataloader)
lr_scheduler = get_scheduler(
    "linear",
    optimizer=optimizer,
    num_warmup_steps=0,
    num_training_steps=num_training_steps,
)
print(num_training_steps)
```

```python out
1377
```

### рокропро┐ро▒рпНроЪро┐роЪрпН роЪрпБро▒рпНро▒рпБ[[the-training-loop]]

роЗройрпНройрпКро░рпБ роХроЯрпИроЪро┐ ро╡ро┐ро╖ропроорпН: роироорпНрооро┐роЯроорпН GPU роЗро░рпБроирпНродро╛ро▓рпН роЕродрпИрокрпН рокропройрпНрокроЯрпБродрпНрод ро╡ро┐ро░рпБроорпНрокрпБро╡рпЛроорпН (CPU-ро╡ро┐ро▓рпН, рокропро┐ро▒рпНроЪро┐ роЪро┐ро▓ роиро┐рооро┐роЯроЩрпНроХро│рпБроХрпНроХрпБрокрпН рокродро┐ро▓ро╛роХ рокро▓ роорогро┐роирпЗро░роорпН роЖроХро▓ро╛роорпН). роЗродрпИроЪрпН роЪрпЖропрпНроп, роироородрпБ рооро╛роЯро▓рпИропрпБроорпН batch-роХро│рпИропрпБроорпН ро╡рпИроХрпНроХрпБроорпН роТро░рпБ `device`-роР ро╡ро░рпИропро▒рпБроХрпНроХро┐ро▒рпЛроорпН:

```py
import torch

device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
model.to(device)
device
```

```python out
device(type='cuda')
```

роиро╛роорпН роЗрокрпНрокрпЛродрпБ рокропро┐ро▒рпНроЪро┐роХрпНроХрпБродрпН родропро╛ро░ро╛роХ роЙро│рпНро│рпЛроорпН! рокропро┐ро▒рпНроЪро┐ роОрокрпНрокрпЛродрпБ роорпБроЯро┐ро╡роЯрпИропрпБроорпН роОройрпНрокродрпИрокрпН рокро▒рпНро▒ро┐роп роТро░рпБ роЙрогро░рпНро╡рпИрокрпН рокрпЖро▒, роироородрпБ рокропро┐ро▒рпНроЪро┐рокрпН рокроЯро┐роХро│ро┐ройрпН роОрогрпНрогро┐роХрпНроХрпИропро┐ройрпН роорпАродрпБ роТро░рпБ роорпБройрпНройрпЗро▒рпНро▒рокрпН рокроЯрпНроЯро┐ропрпИроЪрпН роЪрпЗро░рпНроХрпНроХро┐ро▒рпЛроорпН, `tqdm` library-роРрокрпН рокропройрпНрокроЯрпБродрпНродро┐:

```py
from tqdm.auto import tqdm

progress_bar = tqdm(range(num_training_steps))

model.train()
for epoch in range(num_epochs):
    for batch in train_dataloader:
        batch = {k: v.to(device) for k, v in batch.items()}
        outputs = model(**batch)
        loss = outputs.loss
        loss.backward()

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(1)
```

<Tip>

ЁЯТб **роиро╡рпАрой рокропро┐ро▒рпНроЪро┐ роорпЗроорпНрокроЯрпБродрпНродро▓рпНроХро│рпН**: роЙроЩрпНроХро│рпН рокропро┐ро▒рпНроЪро┐роЪрпН роЪрпБро▒рпНро▒рпИ роЗройрпНройрпБроорпН родро┐ро▒роорпИропро╛роХ рооро╛ро▒рпНро▒, роЗро╡ро▒рпНро▒рпИроХрпН роХро╡ройро┐ропрпБроЩрпНроХро│рпН:

- **Gradient Clipping**: `optimizer.step()`-роХрпНроХрпБ роорпБройрпН `torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)`-роРроЪрпН роЪрпЗро░рпНроХрпНроХро╡рпБроорпН
- **Mixed Precision**: ро╡рпЗроХрооро╛рой рокропро┐ро▒рпНроЪро┐роХрпНроХрпБ `torch.cuda.amp.autocast()` рооро▒рпНро▒рпБроорпН `GradScaler`-роРрокрпН рокропройрпНрокроЯрпБродрпНродро╡рпБроорпН
- **Gradient Accumulation**: рокрпЖро░ро┐роп batch роЕро│ро╡рпБроХро│рпИрокрпН рокро┐ро░родро┐рокро▓ро┐роХрпНроХ рокро▓ batch-роХро│ро┐ро▓рпН gradient-роХро│рпИроХрпН роХрпБро╡ро┐роХрпНроХро╡рпБроорпН
- **Checkpointing**: рокропро┐ро▒рпНроЪро┐ родроЯрпИрокроЯрпНроЯро╛ро▓рпН роорпАрогрпНроЯрпБроорпН родрпКроЯро░, рооро╛роЯро▓рпН checkpoint-роХро│рпИ роЕро╡рпНро╡рокрпНрокрпЛродрпБ роЪрпЗрооро┐роХрпНроХро╡рпБроорпН

ЁЯФз **роЪрпЖропро▓рпНрокроЯрпБродрпНродро▓рпН ро╡ро┤ро┐роХро╛роЯрпНроЯро┐**: роЗроирпНрод роорпЗроорпНрокроЯрпБродрпНродро▓рпНроХро│ро┐ройрпН ро╡ро┐ро░ро┐ро╡ро╛рой роОроЯрпБродрпНродрпБроХрпНроХро╛роЯрпНроЯрпБроХро│рпБроХрпНроХрпБ, [ЁЯдЧ Transformers родро┐ро▒роорпИропро╛рой рокропро┐ро▒рпНроЪро┐ ро╡ро┤ро┐роХро╛роЯрпНроЯро┐](https://huggingface.co/docs/transformers/main/en/perf_train_gpu_one) рооро▒рпНро▒рпБроорпН [optimizers-роХро│ро┐ройрпН ро╡ро░роорпНрокрпБ](https://huggingface.co/docs/transformers/main/en/optimizers)-роРрокрпН рокро╛ро░рпНроХрпНроХро╡рпБроорпН.

</Tip>

рокропро┐ро▒рпНроЪро┐роЪрпН роЪрпБро▒рпНро▒ро┐ройрпН роорпИропрокрпНрокроХрпБродро┐ роЕро▒ро┐роорпБроХродрпНродро┐ро▓рпН роЙро│рпНро│родрпИрокрпН рокрпЛро▓ро╡рпЗ роЗро░рпБрокрпНрокродрпИроХрпН роХро╛рогро▓ро╛роорпН. роиро╛роЩрпНроХро│рпН роОроирпНрод роЕро▒ро┐роХрпНроХрпИропрпИропрпБроорпН роХрпЗроЯрпНроХро╡ро┐ро▓рпНро▓рпИ, роОройро╡рпЗ роЗроирпНрод рокропро┐ро▒рпНроЪро┐роЪрпН роЪрпБро▒рпНро▒рпБ рооро╛роЯро▓рпН роОрокрпНрокроЯро┐роЪрпН роЪрпЖропро▓рпНрокроЯрпБроХро┐ро▒родрпБ роОройрпНрокродрпИрокрпН рокро▒рпНро▒ро┐ роОродрпБро╡рпБроорпН роЪрпКро▓рпНро▓ро╛родрпБ. роЕродро▒рпНроХро╛роХ роТро░рпБ роородро┐рокрпНрокрпАроЯрпНроЯрпБроЪрпН роЪрпБро▒рпНро▒рпИроЪрпН роЪрпЗро░рпНроХрпНроХ ро╡рпЗрогрпНроЯрпБроорпН.


### роородро┐рокрпНрокрпАроЯрпНроЯрпБроЪрпН роЪрпБро▒рпНро▒рпБ[[the-evaluation-loop]]

роорпБройрпНрокрпБ роЪрпЖропрпНродродрпИрокрпН рокрпЛро▓ро╡рпЗ, ЁЯдЧ Evaluate library ро╡ро┤роЩрпНроХрпБроорпН роТро░рпБ роорпЖроЯрпНро░ро┐роХрпНроХрпИ роиро╛роорпН рокропройрпНрокроЯрпБродрпНродрпБро╡рпЛроорпН. роиро╛роорпН роПро▒рпНроХройро╡рпЗ `metric.compute()` роорпБро▒рпИропрпИрокрпН рокро╛ро░рпНродрпНродрпЛроорпН, роЖройро╛ро▓рпН роорпЖроЯрпНро░ро┐роХрпНроХрпБроХро│рпН роЙрогрпНроорпИропро┐ро▓рпН `add_batch()` роорпБро▒рпИропрпБроЯройрпН роХрогро┐рокрпНрокрпБроЪрпН роЪрпБро▒рпНро▒ро┐ро▓рпН роЪрпЖро▓рпНро▓рпБроорпНрокрпЛродрпБ роироороХрпНроХро╛роХ batch-роХро│рпИроХрпН роХрпБро╡ро┐роХрпНроХ роорпБроЯро┐ропрпБроорпН. роОро▓рпНро▓ро╛ batch-роХро│рпИропрпБроорпН роХрпБро╡ро┐родрпНродро╡рпБроЯройрпН, `metric.compute()` роорпВро▓роорпН роЗро▒рпБродро┐ роорпБроЯро┐ро╡рпИрокрпН рокрпЖро▒ро▓ро╛роорпН. роТро░рпБ роородро┐рокрпНрокрпАроЯрпНроЯрпБроЪрпН роЪрпБро▒рпНро▒ро┐ро▓рпН роЗродрпИ роОрокрпНрокроЯро┐роЪрпН роЪрпЖропро▓рпНрокроЯрпБродрпНродрпБро╡родрпБ роОройрпНрокродрпБ роЗроЩрпНроХрпЗ:

<Tip>

ЁЯУК **роородро┐рокрпНрокрпАроЯрпНроЯрпБ роЪро┐ро▒роирпНрод роироЯрпИроорпБро▒рпИроХро│рпН**: роорпЗро▓рпБроорпН роирпБроЯрпНрокрооро╛рой роородро┐рокрпНрокрпАроЯрпНроЯрпБ роЙродрпНродро┐роХро│рпН рооро▒рпНро▒рпБроорпН роорпЖроЯрпНро░ро┐роХрпНроХрпБроХро│рпБроХрпНроХрпБ, [ЁЯдЧ Evaluate роЖро╡рогроЩрпНроХро│рпН](https://huggingface.co/docs/evaluate/) рооро▒рпНро▒рпБроорпН [ро╡ро┐ро░ро┐ро╡ро╛рой роородро┐рокрпНрокрпАроЯрпНроЯрпБ cookbook](https://github.com/huggingface/evaluation-guidebook)-роР роЖро░ро╛ропрпБроЩрпНроХро│рпН.

</Tip>

```py
import evaluate

metric = evaluate.load("glue", "mrpc")
model.eval()
for batch in eval_dataloader:
    batch = {k: v.to(device) for k, v in batch.items()}
    with torch.no_grad():
        outputs = model(**batch)

    logits = outputs.logits
    predictions = torch.argmax(logits, dim=-1)
    metric.add_batch(predictions=predictions, references=batch["labels"])

metric.compute()
```

```python out
{'accuracy': 0.8431372549019608, 'f1': 0.8907849829351535}
```

роорпАрогрпНроЯрпБроорпН, рооро╛роЯро▓рпН родро▓рпИ родрпБро╡роХрпНроХроорпН рооро▒рпНро▒рпБроорпН родро░ро╡рпБ роХро▓роХрпНроХро▓ро┐ро▓рпН роЙро│рпНро│ роЪрпАро░ро▒рпНро▒ родройрпНроорпИ роХро╛ро░рогрооро╛роХ роЙроЩрпНроХро│рпН роорпБроЯро┐ро╡рпБроХро│рпН роЪро▒рпНро▒рпБ ро╡ро┐родрпНродро┐ропро╛роЪрооро╛роХ роЗро░рпБроХрпНроХрпБроорпН, роЖройро╛ро▓рпН роЕро╡рпИ роТро░рпЗ рооро╛родро┐ро░ро┐ропро╛рой ро╡ро░роорпНрокро┐ро▓рпН роЗро░рпБроХрпНроХ ро╡рпЗрогрпНроЯрпБроорпН.

<Tip>

тЬПя╕П **роорпБропро▒рпНроЪро┐ роЪрпЖропрпНродрпБ рокро╛ро░рпБроЩрпНроХро│рпН!** SST-2 роЯрпЗроЯрпНроЯро╛роЪрпЖроЯрпНроЯро┐ро▓рпН роЙроЩрпНроХро│рпН рооро╛роЯро▓рпИ fine-tune роЪрпЖропрпНроп роорпБроирпНродрпИроп рокропро┐ро▒рпНроЪро┐роЪрпН роЪрпБро▒рпНро▒рпИ рооро╛ро▒рпНро▒ро┐ропроорпИроХрпНроХро╡рпБроорпН.

</Tip>

### ЁЯдЧ Accelerate роорпВро▓роорпН роЙроЩрпНроХро│рпН рокропро┐ро▒рпНроЪро┐роЪрпН роЪрпБро▒рпНро▒рпИ роЪрпВрокрпНрокро░рпНроЪро╛ро░рпНроЬрпН роЪрпЖропрпНропрпБроЩрпНроХро│рпН[[supercharge-your-training-loop-with-accelerate]]

<Youtube id="s7dy8QRgjJ0" />

роиро╛роорпН роорпБройрпНрокрпБ ро╡ро░рпИропро▒рпБродрпНрод рокропро┐ро▒рпНроЪро┐роЪрпН роЪрпБро▒рпНро▒рпБ роТро░рпБ CPU роЕро▓рпНро▓родрпБ GPU-ро╡ро┐ро▓рпН роиройрпНро▒ро╛роХ ро╡рпЗро▓рпИ роЪрпЖропрпНроХро┐ро▒родрпБ. роЖройро╛ро▓рпН [ЁЯдЧ Accelerate](https://github.com/huggingface/accelerate) library-роРрокрпН рокропройрпНрокроЯрпБродрпНродро┐, роЪро┐ро▓ рооро╛ро▒рпНро▒роЩрпНроХро│рпБроЯройрпН рокро▓ GPU-роХро│рпН роЕро▓рпНро▓родрпБ TPU-роХро│ро┐ро▓рпН ро╡ро┐роиро┐ропрпЛроХро┐роХрпНроХрокрпНрокроЯрпНроЯ рокропро┐ро▒рпНроЪро┐ропрпИ роЗропроХрпНроХро▓ро╛роорпН. ЁЯдЧ Accelerate ро╡ро┐роиро┐ропрпЛроХро┐роХрпНроХрокрпНрокроЯрпНроЯ рокропро┐ро▒рпНроЪро┐, роХро▓рокрпНрокрпБ родрпБро▓рпНро▓ро┐ропроорпН рооро▒рпНро▒рпБроорпН роЪро╛родрой роТродрпБроХрпНроХрпАроЯрпБ роЖроХро┐ропро╡ро▒рпНро▒ро┐ройрпН роЪро┐роХрпНроХро▓рпНроХро│рпИродрпН родро╛ройро╛роХро╡рпЗ роХрпИропро╛ро│рпНроХро┐ро▒родрпБ. рокропро┐ро▒рпНроЪро┐ рооро▒рпНро▒рпБроорпН роЪро░ро┐рокро╛ро░рпНрокрпНрокрпБ dataloader-роХро│рпИ роЙро░рпБро╡ро╛роХрпНроХрпБро╡родро┐ро▓ро┐ро░рпБроирпНродрпБ родрпКроЯроЩрпНроХро┐, роироородрпБ роХрпИроорпБро▒рпИ рокропро┐ро▒рпНроЪро┐роЪрпН роЪрпБро▒рпНро▒рпБ роЗрокрпНрокроЯро┐ роЗро░рпБроХрпНроХрпБроорпН:

<Tip>

тЪб **Accelerate роЖро┤рпНроирпНрод рокро╛ро░рпНро╡рпИ**: ро╡ро┐роиро┐ропрпЛроХро┐роХрпНроХрокрпНрокроЯрпНроЯ рокропро┐ро▒рпНроЪро┐, роХро▓рокрпНрокрпБ родрпБро▓рпНро▓ро┐ропроорпН рооро▒рпНро▒рпБроорпН ро╡ройрпНрокрпКро░рпБро│рпН роорпЗроорпНрокроЯрпБродрпНродро▓рпН рокро▒рпНро▒ро┐ роЕройрпИродрпНродрпИропрпБроорпН [ЁЯдЧ Accelerate роЖро╡рогроЩрпНроХро│рпН](https://huggingface.co/docs/accelerate/)-роЗро▓рпН роХро▒рпНро▒рпБроХрпН роХрпКро│рпНро│рпБроЩрпНроХро│рпН рооро▒рпНро▒рпБроорпН [transformers роЖро╡рогроЩрпНроХро│рпН](https://huggingface.co/docs/transformers/main/en/accelerate)-роЗро▓рпН роироЯрпИроорпБро▒рпИ роОроЯрпБродрпНродрпБроХрпНроХро╛роЯрпНроЯрпБроХро│рпИ роЖро░ро╛ропрпБроЩрпНроХро│рпН.

</Tip>

```py
from accelerate import Accelerator
from torch.optim import AdamW
from transformers import AutoModelForSequenceClassification, get_scheduler

accelerator = Accelerator()

model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)
optimizer = AdamW(model.parameters(), lr=3e-5)

train_dl, eval_dl, model, optimizer = accelerator.prepare(
    train_dataloader, eval_dataloader, model, optimizer
)

num_epochs = 3
num_training_steps = num_epochs * len(train_dl)
lr_scheduler = get_scheduler(
    "linear",
    optimizer=optimizer,
    num_warmup_steps=0,
    num_training_steps=num_training_steps,
)

progress_bar = tqdm(range(num_training_steps))

model.train()
for epoch in range(num_epochs):
    for batch in train_dl:
        outputs = model(**batch)
        loss = outputs.loss
        accelerator.backward(loss)

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(1)
```

роЪрпЗро░рпНроХрпНроХ ро╡рпЗрогрпНроЯро┐роп роорпБродро▓рпН ро╡ро░ро┐ import ро╡ро░ро┐. роЗро░рогрпНроЯро╛ро╡родрпБ ро╡ро░ро┐ роТро░рпБ `Accelerator` object-роР роЙро░рпБро╡ро╛роХрпНроХрпБроХро┐ро▒родрпБ, роЗродрпБ роЪрпВро┤ро▓рпИрокрпН рокро╛ро░рпНродрпНродрпБ роЪро░ро┐ропро╛рой ро╡ро┐роиро┐ропрпЛроХро┐роХрпНроХрокрпНрокроЯрпНроЯ роЕроорпИрокрпНрокрпИродрпН родрпКроЯроЩрпНроХрпБроорпН. ЁЯдЧ Accelerate роЙроЩрпНроХро│рпБроХрпНроХро╛роХ роЪро╛родрой роТродрпБроХрпНроХрпАроЯрпНроЯрпИроХрпН роХрпИропро╛ро│рпНроХро┐ро▒родрпБ, роОройро╡рпЗ рооро╛роЯро▓рпИ роЪро╛родройродрпНродро┐ро▓рпН ро╡рпИроХрпНроХрпБроорпН ро╡ро░ро┐роХро│рпИ роирпАроЩрпНроХро│рпН роЕроХро▒рпНро▒ро▓ро╛роорпН (роЕро▓рпНро▓родрпБ, роирпАроЩрпНроХро│рпН ро╡ро┐ро░рпБроорпНрокро┐ройро╛ро▓рпН, роЕро╡ро▒рпНро▒рпИ `device`-роХрпНроХрпБ рокродро┐ро▓ро╛роХ `accelerator.device`-роРрокрпН рокропройрпНрокроЯрпБродрпНрод рооро╛ро▒рпНро▒ро▓ро╛роорпН).

рокро┐ройрпНройро░рпН роорпБроХрпНроХро┐роп ро╡рпЗро▓рпИ `accelerator.prepare()`-роХрпНроХрпБ dataloader-роХро│рпН, рооро╛роЯро▓рпН рооро▒рпНро▒рпБроорпН optimizer-роР роЕройрпБрокрпНрокрпБроорпН ро╡ро░ро┐ропро┐ро▓рпН роЪрпЖропрпНропрокрпНрокроЯрпБроХро┐ро▒родрпБ. роЗродрпБ роЙроЩрпНроХро│рпН ро╡ро┐роиро┐ропрпЛроХро┐роХрпНроХрокрпНрокроЯрпНроЯ рокропро┐ро▒рпНроЪро┐ роирпЛроХрпНроХроорпН рокрпЛро▓рпН роЪрпЖропро▓рпНрокроЯрпБро╡родрпИ роЙро▒рпБродро┐роЪрпЖропрпНроп роЕроирпНрод object-роХро│рпИ роЪро░ро┐ропро╛рой роХрпКро│рпНроХро▓ройро┐ро▓рпН рокрпЛро░рпНродрпНродро┐ро╡ро┐роЯрпБроорпН. роЪрпЖропрпНроп ро╡рпЗрогрпНроЯро┐роп роорпАродроорпБро│рпНро│ рооро╛ро▒рпНро▒роЩрпНроХро│рпН, batch-роР `device`-роЗро▓рпН ро╡рпИроХрпНроХрпБроорпН ро╡ро░ро┐ропрпИ роЕроХро▒рпНро▒рпБро╡родрпБ (роорпАрогрпНроЯрпБроорпН, роЗродрпИ ро╡рпИродрпНродро┐ро░рпБроХрпНроХ ро╡ро┐ро░рпБроорпНрокро┐ройро╛ро▓рпН, `accelerator.device`-роРрокрпН рокропройрпНрокроЯрпБродрпНрод рооро╛ро▒рпНро▒ро▓ро╛роорпН) рооро▒рпНро▒рпБроорпН `loss.backward()`-роР `accelerator.backward(loss)`-роЖроХ рооро╛ро▒рпНро▒рпБро╡родрпБ.

<Tip>
тЪая╕П Cloud TPU-роХро│рпН ро╡ро┤роЩрпНроХрпБроорпН ро╡рпЗроХ роЕродро┐роХро░ро┐рокрпНрокро┐ро▓ро┐ро░рпБроирпНродрпБ рокропройроЯрпИроп, tokenizer-роЗройрпН `padding="max_length"` рооро▒рпНро▒рпБроорпН `max_length` argument-роХро│рпИрокрпН рокропройрпНрокроЯрпБродрпНродро┐ роЙроЩрпНроХро│рпН рооро╛родро┐ро░ро┐роХро│рпИ роТро░рпБ роиро┐ро▓рпИропро╛рой роирпАро│родрпНродро┐ро▒рпНроХрпБ padding роЪрпЖропрпНроп рокро░ро┐роирпНродрпБро░рпИроХрпНроХро┐ро▒рпЛроорпН.
</Tip>

роирпАроЩрпНроХро│рпН роЗродрпИ роироХро▓рпЖроЯрпБродрпНродрпБ роТроЯрпНроЯро┐ ро╡ро┐ро│рпИропро╛роЯ ро╡ро┐ро░рпБроорпНрокро┐ройро╛ро▓рпН, ЁЯдЧ Accelerate роЙроЯройрпН роорпБро┤рпБроорпИропро╛рой рокропро┐ро▒рпНроЪро┐роЪрпН роЪрпБро▒рпНро▒рпБ роЗрокрпНрокроЯро┐ роЗро░рпБроХрпНроХрпБроорпН:

```py
from accelerate import Accelerator
from torch.optim import AdamW
from transformers import AutoModelForSequenceClassification, get_scheduler

accelerator = Accelerator()

model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)
optimizer = AdamW(model.parameters(), lr=3e-5)

train_dl, eval_dl, model, optimizer = accelerator.prepare(
    train_dataloader, eval_dataloader, model, optimizer
)

num_epochs = 3
num_training_steps = num_epochs * len(train_dl)
lr_scheduler = get_scheduler(
    "linear",
    optimizer=optimizer,
    num_warmup_steps=0,
    num_training_steps=num_training_steps,
)

progress_bar = tqdm(range(num_training_steps))

model.train()
for epoch in range(num_epochs):
    for batch in train_dl:
        outputs = model(**batch)
        loss = outputs.loss
        accelerator.backward(loss)

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(1)
```

роЗродрпИ роТро░рпБ `train.py` ро╕рпНроХро┐ро░ро┐рокрпНроЯро┐ро▓рпН ро╡рпИрокрпНрокродрпБ роЕроирпНрод ро╕рпНроХро┐ро░ро┐рокрпНроЯрпИ роОроирпНродро╡рпКро░рпБ ро╡ро┐роиро┐ропрпЛроХро┐роХрпНроХрокрпНрокроЯрпНроЯ роЕроорпИрокрпНрокро┐ро▓рпБроорпН роЗропроХрпНроХроХрпНроХрпВроЯро┐ропродро╛роХ рооро╛ро▒рпНро▒рпБроорпН. роЙроЩрпНроХро│рпН ро╡ро┐роиро┐ропрпЛроХро┐роХрпНроХрокрпНрокроЯрпНроЯ роЕроорпИрокрпНрокро┐ро▓рпН роЗродрпИ роорпБропро▒рпНроЪро┐роХрпНроХ, роХроЯрпНроЯро│рпИропрпИ роЗропроХрпНроХро╡рпБроорпН:

```bash
accelerate config
```

роЗродрпБ роЪро┐ро▓ роХрпЗро│рпНро╡ро┐роХро│рпБроХрпНроХрпБ рокродро┐ро▓ро│ро┐роХрпНроХ роЙроЩрпНроХро│рпИродрпН родрпВрогрпНроЯрпБроорпН рооро▒рпНро▒рпБроорпН роЙроЩрпНроХро│рпН рокродро┐ро▓рпНроХро│рпИ роЗроирпНрод роХроЯрпНроЯро│рпИропро╛ро▓рпН рокропройрпНрокроЯрпБродрпНродрокрпНрокроЯрпБроорпН роТро░рпБ роЙро│рпНро│роорпИро╡рпБ роХрпЛрокрпНрокро┐ро▓рпН роХрпКроЯрпНроЯрпБроорпН:

```
accelerate launch train.py
```

роЗродрпБ ро╡ро┐роиро┐ропрпЛроХро┐роХрпНроХрокрпНрокроЯрпНроЯ рокропро┐ро▒рпНроЪро┐ропрпИродрпН родрпКроЯроЩрпНроХрпБроорпН.

роЗродрпИ роТро░рпБ Notebook-роЗро▓рпН роорпБропро▒рпНроЪро┐роХрпНроХ ро╡ро┐ро░рпБроорпНрокро┐ройро╛ро▓рпН (роЙродро╛ро░рогрооро╛роХ, Colab-роЗро▓рпН TPU-роХро│рпБроЯройрпН роЪрпЛродро┐роХрпНроХ), роХрпБро▒ро┐ропрпАроЯрпНроЯрпИ роТро░рпБ `training_function()`-роЗро▓рпН роТроЯрпНроЯро┐, роХроЯрпИроЪро┐ роХро▓родрпНродрпИ роЗропроХрпНроХро╡рпБроорпН:

```python
from accelerate import notebook_launcher

notebook_launcher(training_function)
```

[ЁЯдЧ Accelerate repo](https://github.com/huggingface/accelerate/tree/main/examples)-роЗро▓рпН роорпЗро▓рпБроорпН роОроЯрпБродрпНродрпБроХрпНроХро╛роЯрпНроЯрпБроХро│рпИроХрпН роХро╛рогро▓ро╛роорпН.

<Tip>

ЁЯМР **ро╡ро┐роиро┐ропрпЛроХро┐роХрпНроХрокрпНрокроЯрпНроЯ рокропро┐ро▒рпНроЪро┐**: рокро▓-GPU рооро▒рпНро▒рпБроорпН рокро▓-node рокропро┐ро▒рпНроЪро┐ рокро▒рпНро▒ро┐роп ро╡ро┐ро░ро┐ро╡ро╛рой родроХро╡ро▓рпНроХро│рпБроХрпНроХрпБ, [ЁЯдЧ Transformers ро╡ро┐роиро┐ропрпЛроХро┐роХрпНроХрокрпНрокроЯрпНроЯ рокропро┐ро▒рпНроЪро┐ ро╡ро┤ро┐роХро╛роЯрпНроЯро┐](https://huggingface.co/docs/transformers/main/en/perf_train_gpu_many) рооро▒рпНро▒рпБроорпН [рокропро┐ро▒рпНроЪро┐ропрпИ роЕро│ро╡ро┐роЯрпБродро▓рпН cookbook](https://huggingface.co/docs/transformers/main/en/accelerate)-роРрокрпН рокро╛ро░рпНроХрпНроХро╡рпБроорпН.

</Tip>

### роЕроЯрпБродрпНрод рокроЯро┐роХро│рпН рооро▒рпНро▒рпБроорпН роЪро┐ро▒роирпНрод роироЯрпИроорпБро▒рпИроХро│рпН[[next-steps-and-best-practices]]

роЗрокрпНрокрпЛродрпБ роирпАроЩрпНроХро│рпН рокрпБродро┐родро╛роХ рокропро┐ро▒рпНроЪро┐ропрпИ роЪрпЖропро▓рпНрокроЯрпБродрпНродрпБро╡родрпБ роОрокрпНрокроЯро┐ роОройрпНро▒рпБ роХро▒рпНро▒рпБроХрпНроХрпКрогрпНроЯрпАро░рпНроХро│рпН, роЙро▒рпНрокродрпНродро┐ рокропройрпНрокро╛роЯрпНроЯро┐ро▒рпНроХро╛рой роЪро┐ро▓ роХрпВроЯрпБродро▓рпН рокро░ро┐роЪрпАро▓ройрпИроХро│рпН роЗроЩрпНроХрпЗ:

**рооро╛роЯро▓рпН роородро┐рокрпНрокрпАроЯрпБ**: роЙроЩрпНроХро│рпН рооро╛роЯро▓рпИ роОрокрпНрокрпЛродрпБроорпН рокро▓ роорпЖроЯрпНро░ро┐роХрпНроХрпБроХро│ро┐ро▓рпН роородро┐рокрпНрокрпАроЯрпБ роЪрпЖропрпНропрпБроЩрпНроХро│рпН, родрпБро▓рпНро▓ро┐ропроорпН роороЯрпНроЯрпБрооро▓рпНро▓. ро╡ро┐ро░ро┐ро╡ро╛рой роородро┐рокрпНрокрпАроЯрпНроЯро┐ро▒рпНроХрпБ ЁЯдЧ Evaluate library-роРрокрпН рокропройрпНрокроЯрпБродрпНродро╡рпБроорпН.

**Hyperparameter роЪро░ро┐роЪрпЖропрпНродро▓рпН**: роорпБро▒рпИропро╛рой hyperparameter роорпЗроорпНрокроЯрпБродрпНродро▓рпБроХрпНроХрпБ Optuna роЕро▓рпНро▓родрпБ Ray Tune рокрпЛройрпНро▒ library-роХро│рпИрокрпН рокропройрпНрокроЯрпБродрпНродрпБро╡родрпИроХрпН роХро╡ройро┐ропрпБроЩрпНроХро│рпН.

**рооро╛роЯро▓рпН роХрогрпНроХро╛рогро┐рокрпНрокрпБ**: рокропро┐ро▒рпНроЪро┐ роорпЖроЯрпНро░ро┐роХрпНроХрпБроХро│рпН, роХро▒рпНро▒ро▓рпН ро╡ро│рпИро╡рпБроХро│рпН рооро▒рпНро▒рпБроорпН роЪро░ро┐рокро╛ро░рпНрокрпНрокрпБ роЪрпЖропро▓рпНродро┐ро▒ройрпИ рокропро┐ро▒рпНроЪро┐ роорпБро┤рпБро╡родрпБроорпН роХрогрпНроХро╛рогро┐роХрпНроХро╡рпБроорпН.

**рооро╛роЯро▓рпН рокроХро┐ро░рпНродро▓рпН**: рокропро┐ро▒рпНроЪро┐ рокрпЖро▒рпНро▒ро╡рпБроЯройрпН, роЙроЩрпНроХро│рпН рооро╛роЯро▓рпИ Hugging Face Hub-роЗро▓рпН рокроХро┐ро░рпНроирпНродрпБ роЪроорпВроХродрпНродро┐ро▒рпНроХрпБ роХро┐роЯрпИроХрпНроХроЪрпН роЪрпЖропрпНропрпБроЩрпНроХро│рпН.

**родро┐ро▒ройрпН**: рокрпЖро░ро┐роп рооро╛роЯро▓рпНроХро│рпБроХрпНроХрпБ, gradient checkpointing, parameter-efficient fine-tuning (LoRA, AdaLoRA), роЕро▓рпНро▓родрпБ quantization роорпБро▒рпИроХро│рпН рокрпЛройрпНро▒ роирпБроЯрпНрокроЩрпНроХро│рпИроХрпН роХро╡ройро┐ропрпБроЩрпНроХро│рпН.

родройро┐рокрпНрокропройрпН рокропро┐ро▒рпНроЪро┐роЪрпН роЪрпБро▒рпНро▒рпБроХро│рпБроЯройрпН fine-tuning рокро▒рпНро▒ро┐роп роироородрпБ роЖро┤рпНроирпНрод рокро╛ро░рпНро╡рпИ роЗродрпНродрпБроЯройрпН роорпБроЯро┐ро╡роЯрпИроХро┐ро▒родрпБ. `Trainer` API ро╡ро┤роЩрпНроХрпБро╡родрпИродрпН родро╛рогрпНроЯро┐, рокропро┐ро▒рпНроЪро┐ роЪрпЖропро▓рпНроорпБро▒рпИропро┐ройрпН роорпАродрпБ роорпБро┤рпБроорпИропро╛рой роХроЯрпНроЯрпБрокрпНрокро╛роЯрпБ родрпЗро╡рпИрокрпНрокроЯрпБроорпНрокрпЛродрпБ роЕро▓рпНро▓родрпБ родройро┐рокрпНрокропройрпН рокропро┐ро▒рпНроЪро┐ родро░рпНроХрпНроХродрпНродрпИ роЪрпЖропро▓рпНрокроЯрпБродрпНрод ро╡ро┐ро░рпБроорпНрокрпБроорпНрокрпЛродрпБ роирпАроЩрпНроХро│рпН роЗроЩрпНроХрпЗ роХро▒рпНро▒рпБроХрпНроХрпКрогрпНроЯ родро┐ро▒ройрпНроХро│рпН роЙроЩрпНроХро│рпБроХрпНроХрпБ р░мр░╛р░Чр░╛ роЙродро╡рпБроорпН.

## рокроХрпБродро┐ ро╡ро┐ройро╛роЯро┐ ро╡ро┐ройро╛[[section-quiz]]

родройро┐рокрпНрокропройрпН рокропро┐ро▒рпНроЪро┐роЪрпН роЪрпБро▒рпНро▒рпБроХро│рпН рооро▒рпНро▒рпБроорпН роорпЗроорпНрокроЯрпНроЯ рокропро┐ро▒рпНроЪро┐ роирпБроЯрпНрокроЩрпНроХро│рпН рокро▒рпНро▒ро┐роп роЙроЩрпНроХро│рпН рокрпБро░ро┐родро▓рпИроЪрпН роЪрпЛродро┐роХрпНроХро╡рпБроорпН:

### 1. Adam рооро▒рпНро▒рпБроорпН AdamW optimizers-роХрпНроХрпБ роЗроЯрпИропро┐ро▓ро╛рой роорпБроХрпНроХро┐роп ро╡рпЗро▒рпБрокро╛роЯрпБ роОройрпНрой?

<Question
	choices={[
		{
			text: "AdamW ро╡рпЗро▒рпБрокроЯрпНроЯ learning rate schedule-роРрокрпН рокропройрпНрокроЯрпБродрпНродрпБроХро┐ро▒родрпБ.",
			explain: "Learning rate scheduling optimizer родрпЗро░рпНро╡ро┐ро▓ро┐ро░рпБроирпНродрпБ родройро┐рокрпНрокроЯрпНроЯродрпБ."
		},
		{
			text: "AdamW-роЗро▓рпН рокро┐ро░ро┐роХрпНроХрокрпНрокроЯрпНроЯ weight decay regularization роЙро│рпНро│родрпБ.",
			explain: "роЪро░ро┐! AdamW, gradient-роЕроЯро┐рокрпНрокроЯрпИропро┐ро▓ро╛рой роЕро│ро╡рпБро░рпБ рокрпБродрпБрокрпНрокро┐рокрпНрокрпБроХро│ро┐ро▓ро┐ро░рпБроирпНродрпБ weight decay-роРрокрпН рокро┐ро░ро┐роХрпНроХро┐ро▒родрпБ, роЗродрпБ роЪро┐ро▒роирпНрод regularization-роХрпНроХрпБ ро╡ро┤ро┐ро╡роХрпБроХрпНроХро┐ро▒родрпБ.",
            correct: true
		},
		{
			text: "AdamW only works with transformer models.",
			explain: "AdamW can be used with any model architecture, not just transformers."
		},
        {
			text: "AdamW requires less memory than Adam.",
			explain: "Both optimizers have similar memory requirements."
		}
	]}
/>

### 2. In a training loop, what is the correct order of operations?

<Question
	choices={[
		{
			text: "Forward pass тЖТ Backward pass тЖТ Optimizer step тЖТ Zero gradients",
			explain: "Close, but you should zero gradients before the next forward pass to avoid accumulating old gradients."
		},
		{
			text: "Forward pass тЖТ Backward pass тЖТ Optimizer step тЖТ Scheduler step тЖТ Zero gradients",
			explain: "Correct! This is the proper order: compute loss, compute gradients, update parameters, update learning rate, then clear gradients.",
            correct: true
		},
		{
			text: "Zero gradients тЖТ Forward pass тЖТ Optimizer step тЖТ Backward pass",
			explain: "The backward pass must come after the forward pass to compute gradients from the loss."
		},
        {
			text: "Forward pass тЖТ Zero gradients тЖТ Backward pass тЖТ Optimizer step",
			explain: "Zeroing gradients before backward pass would eliminate the gradients you just computed."
		}
	]}
/>

### 3. What does the ЁЯдЧ Accelerate library primarily help with?

<Question
	choices={[
		{
			text: "Making your models train faster by optimizing the forward pass.",
			explain: "Accelerate doesn't optimize the model architecture itself."
		},
		{
			text: "Automatically selecting the best hyperparameters.",
			explain: "Accelerate doesn't do hyperparameter optimization."
		},
		{
			text: "Enabling distributed training across multiple GPUs/TPUs with minimal code changes.",
			explain: "Correct! Accelerate handles distributed training complexity, allowing your code to run on single or multiple devices seamlessly.",
            correct: true
		},
        {
			text: "Converting models to different frameworks like TensorFlow.",
			explain: "Accelerate works within PyTorch and doesn't convert between frameworks."
		}
	]}
/>

### 4. Why do we move batches to the device in a training loop?

<Question
	choices={[
		{
			text: "To make the training faster.",
			explain: "While it can affect speed, the main reason is compatibility."
		},
		{
			text: "Because the model and data must be on the same device (CPU/GPU) for computation.",
			explain: "Correct! PyTorch requires tensors to be on the same device for operations to work.",
            correct: true
		},
		{
			text: "To save memory.",
			explain: "Moving to device doesn't inherently save memory."
		},
        {
			text: "It's required by the DataLoader.",
			explain: "DataLoader doesn't require specific device placement."
		}
	]}
/>

### 5. What does `model.eval()` do before evaluation?

<Question
	choices={[
		{
			text: "It freezes the model parameters so they can't be updated.",
			explain: "model.eval() doesn't freeze parameters - that would be done by setting requires_grad=False."
		},
		{
			text: "It changes the behavior of layers like dropout and batch normalization for inference.",
			explain: "Correct! eval() mode disables dropout and uses running statistics for batch norm instead of computing them from the current batch.",
            correct: true
		},
		{
			text: "It enables gradient computation for evaluation metrics.",
			explain: "Actually, we typically use torch.no_grad() during evaluation to disable gradient computation."
		},
        {
			text: "It automatically calculates evaluation metrics.",
			explain: "model.eval() only changes layer behavior - you still need to implement metric calculation separately."
		}
	]}
/>

### 6. What is the purpose of `torch.no_grad()` during evaluation?

<Question
	choices={[
		{
			text: "To prevent the model from making predictions.",
			explain: "torch.no_grad() doesn't prevent predictions, just gradient computation."
		},
		{
			text: "To save memory and speed up computation by disabling gradient tracking.",
			explain: "Correct! Since we don't need gradients for evaluation, disabling them saves memory and computation.",
            correct: true
		},
		{
			text: "To enable evaluation mode for the model.",
			explain: "Evaluation mode is enabled with model.eval(), not torch.no_grad()."
		},
        {
			text: "To ensure consistent results across runs.",
			explain: "Reproducibility is handled by setting random seeds, not torch.no_grad()."
		}
	]}
/>

### 7. What changes when you use ЁЯдЧ Accelerate in your training loop?

<Question
	choices={[
		{
			text: "You must rewrite your entire training loop from scratch.",
			explain: "Accelerate requires minimal changes to existing PyTorch code."
		},
		{
			text: "You wrap key objects with accelerator.prepare() and use accelerator.backward() instead of loss.backward().",
			explain: "Correct! These are the main changes - prepare your objects and use accelerator.backward() for proper distributed training.",
            correct: true
		},
		{
			text: "You need to specify the number of GPUs in your code.",
			explain: "Accelerate automatically detects available hardware."
		},
        {
			text: "You must use a different optimizer and scheduler.",
			explain: "You can use the same optimizers and schedulers with Accelerate."
		}
	]}
/>

<Tip>

ЁЯТб **Key Takeaways:**
- Manual training loops give you complete control but require understanding of the proper sequence: forward тЖТ backward тЖТ optimizer step тЖТ scheduler step тЖТ zero gradients
- AdamW with weight decay is the recommended optimizer for transformer models
- Always use `model.eval()` and `torch.no_grad()` during evaluation for correct behavior and efficiency
- ЁЯдЧ Accelerate makes distributed training accessible with minimal code changes
- Device management (moving tensors to GPU/CPU) is crucial for PyTorch operations
- Modern techniques like mixed precision, gradient accumulation, and gradient clipping can significantly improve training efficiency

</Tip>
