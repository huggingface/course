<CourseFloatingBanner chapter={2}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/main/course/en/chapter11/section3.ipynb"},
]} />

# Supervised Fine-Tuning

Supervised Fine-Tuning (SFT) ဟာ ကြိုတင်လေ့ကျင့်ထားပြီးသား language models တွေကို ညွှန်ကြားချက်တွေကို လိုက်နာဖို့၊ စကားပြောဆိုမှုတွေမှာ ပါဝင်ဖို့နဲ့ သတ်မှတ်ထားတဲ့ output formats တွေကို အသုံးပြုနိုင်ဖို့ အဓိကအသုံးပြုတဲ့ လုပ်ငန်းစဉ်တစ်ခု ဖြစ်ပါတယ်။ pre-trained models တွေမှာ အထင်ကြီးစရာကောင်းတဲ့ အထွေထွေစွမ်းရည်တွေ ရှိပေမယ့်၊ SFT က ၎င်းတို့ကို assistant-like models တွေအဖြစ် ပြောင်းလဲပေးရာမှာ ကူညီပေးပါတယ်။ ဒါမှ အသုံးပြုသူရဲ့ prompts တွေကို ပိုမိုနားလည်ပြီး တုံ့ပြန်နိုင်မှာပါ။ ဒီလိုလုပ်တာက များသောအားဖြင့် လူသားတွေရေးသားထားတဲ့ စကားပြောဆိုမှုတွေနဲ့ ညွှန်ကြားချက် datasets တွေပေါ်မှာ training လုပ်ခြင်းဖြင့် ဆောင်ရွက်ပါတယ်။

ဒီစာမျက်နှာက [`deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B`](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B) model ကို [`SFTTrainer`](https://huggingface.co/docs/trl/en/sft_trainer) ကို အသုံးပြုပြီး fine-tuning လုပ်ဖို့အတွက် အဆင့်ဆင့် လမ်းညွှန်ချက်တွေကို ပေးထားပါတယ်။ ဒီအဆင့်တွေကို လိုက်နာခြင်းဖြင့် သင်ဟာ model ကို သီးခြား tasks တွေကို ပိုမိုထိရောက်စွာ လုပ်ဆောင်နိုင်အောင် ပြုပြင်နိုင်ပါလိမ့်မယ်။

## SFT ကို ဘယ်အချိန်မှာ အသုံးပြုသင့်သလဲ

Implementation ထဲကို မဝင်ရောက်ခင်မှာ၊ SFT က သင့် project အတွက် မှန်ကန်တဲ့ ရွေးချယ်မှု ဘယ်အချိန်မှာ ဖြစ်မလဲဆိုတာ နားလည်ဖို့ အရေးကြီးပါတယ်။ ပထမအဆင့်အနေနဲ့၊ လက်ရှိ instruction-tuned model တစ်ခုကို ကောင်းမွန်စွာ ဖန်တီးထားတဲ့ prompts တွေနဲ့ အသုံးပြုတာက သင့် use case အတွက် လုံလောက်မလားဆိုတာ စဉ်းစားသင့်ပါတယ်။ SFT မှာ computational resources နဲ့ engineering effort တွေ အများအပြား ပါဝင်တဲ့အတွက်၊ လက်ရှိ models တွေကို prompting လုပ်တာက မလုံလောက်မှသာ ဒီနည်းလမ်းကို ဆက်လက်လုပ်ဆောင်သင့်ပါတယ်။

> [!TIP]
> SFT ကို အောက်ပါအခြေအနေများမှသာ စဉ်းစားပါ။
> - prompting ဖြင့် ရရှိနိုင်သည်ထက် ပိုမိုကောင်းမွန်သော စွမ်းဆောင်ရည် လိုအပ်ခြင်း။
> - large general-purpose model တစ်ခုကို အသုံးပြုခြင်း၏ ကုန်ကျစရိတ်သည် smaller model တစ်ခုကို fine-tuning လုပ်ခြင်း၏ ကုန်ကျစရိတ်ထက် ပိုများသော သီးခြား use case တစ်ခု ရှိခြင်း။
> - လက်ရှိ models များက ကိုင်တွယ်ရခက်ခဲသော specialized output formats များ သို့မဟုတ် domain-specific knowledge များ လိုအပ်ခြင်း။

SFT က လိုအပ်တယ်လို့ သင်ဆုံးဖြတ်ပြီဆိုရင်၊ ဆက်လက်လုပ်ဆောင်ဖို့ ဆုံးဖြတ်ချက်က အဓိကအချက်နှစ်ချက်ပေါ်မှာ မူတည်ပါတယ်-

### Template Control
SFT က model ရဲ့ output structure အပေါ်မှာ တိကျတဲ့ control ကို ခွင့်ပြုပါတယ်။ ဒါက model ကို အောက်ပါတို့ကို လုပ်ဆောင်ဖို့ လိုအပ်တဲ့အခါ အထူးအသုံးဝင်ပါတယ်-
၁။ သီးခြား chat template format တစ်ခုနဲ့ responses တွေ ထုတ်လုပ်ရန်။
၂။ တင်းကြပ်သော output schemas များကို လိုက်နာရန်။
၃။ responses များတစ်လျှောက် တသမတ်တည်းဖြစ်သော styling ကို ထိန်းသိမ်းရန်။

### Domain Adaptation
Specialized domains တွေမှာ အလုပ်လုပ်တဲ့အခါ၊ SFT က model ကို domain-specific requirements တွေနဲ့ ကိုက်ညီအောင် ကူညီပေးပါတယ်။ ဒါတွေကတော့...
၁။ domain terminology နဲ့ concepts တွေ သင်ကြားပေးခြင်း။
၂။ ပရော်ဖက်ရှင်နယ် စံနှုန်းများ ချမှတ်ခြင်း။
၃။ နည်းပညာဆိုင်ရာ မေးမြန်းမှုများကို သင့်လျော်စွာ ကိုင်တွယ်ဖြေရှင်းခြင်း။
၄။ Industry-specific guidelines များကို လိုက်နာခြင်း။

> [!TIP]
> SFT ကို မစတင်မီ၊ သင်၏ use case သည် အောက်ပါတို့ကို လိုအပ်ခြင်းရှိမရှိ အကဲဖြတ်ပါ။
> - တိကျသော output formatting
> - Domain-specific knowledge
> - တသမတ်တည်းသော response patterns
> - သီးခြား guidelines များကို လိုက်နာခြင်း
>
> ဤအကဲဖြတ်ခြင်းသည် SFT သည် သင့်လိုအပ်ချက်များအတွက် မှန်ကန်သောချဉ်းကပ်မှုဟုတ်မဟုတ် ဆုံးဖြတ်ရန် ကူညီလိမ့်မည်။

## Dataset Preparation

supervised fine-tuning လုပ်ငန်းစဉ်အတွက် input-output pairs များဖြင့် ဖွဲ့စည်းထားသော task-specific dataset တစ်ခု လိုအပ်ပါတယ်။ pair တစ်ခုစီမှာ အောက်ပါတို့ ပါဝင်သင့်ပါတယ်။
၁။ input prompt တစ်ခု။
၂။ မျှော်လင့်ထားသော model response။
၃။ အပိုဆောင်း context သို့မဟုတ် metadata တစ်ခုခု။

သင်၏ training data ၏ အရည်အသွေးသည် အောင်မြင်သော fine-tuning အတွက် အရေးကြီးပါတယ်။ သင်၏ dataset ကို ဘယ်လိုပြင်ဆင်ပြီး validate လုပ်ရမလဲဆိုတာ ကြည့်ရအောင်...

<iframe
  src="https://huggingface.co/datasets/HuggingFaceTB/smoltalk/embed/viewer/all/train?row=0"
  frameborder="0"
  width="100%"
  height="360px"
></iframe>

## Training Configuration

သင်၏ fine-tuning အောင်မြင်မှုသည် မှန်ကန်သော training parameters များကို ရွေးချယ်ခြင်းအပေါ် များစွာမူတည်ပါတယ်။ အရေးကြီးသော parameter တစ်ခုစီနှင့် ၎င်းတို့ကို ထိရောက်စွာ configure လုပ်နည်းကို လေ့လာကြည့်ကြပါစို့။

SFTTrainer configuration အတွက် training လုပ်ငန်းစဉ်ကို ထိန်းချုပ်သော parameters အများအပြားကို ထည့်သွင်းစဉ်းစားရန် လိုအပ်ပါတယ်။ parameter တစ်ခုစီနှင့် ၎င်းတို့၏ ရည်ရွယ်ချက်ကို လေ့လာကြည့်ကြပါစို့။

၁။ **Training Duration Parameters**:
   - `num_train_epochs`: စုစုပေါင်း training ကြာချိန်ကို ထိန်းချုပ်သည်။
   - `max_steps`: epochs ၏ အစားထိုးတစ်ခုဖြစ်ပြီး၊ အမြင့်ဆုံး training steps အရေအတွက်ကို သတ်မှတ်သည်။
   - epochs ပိုများလေ၊ သင်ယူမှု ပိုကောင်းလေဖြစ်သော်လည်း overfitting ဖြစ်နိုင်ခြေရှိသည်။

၂။ **Batch Size Parameters**:
   - `per_device_train_batch_size`: memory အသုံးပြုမှုနှင့် training stability ကို ဆုံးဖြတ်သည်။
   - `gradient_accumulation_steps`: ပိုကြီးမားသော effective batch sizes များကို လုပ်ဆောင်နိုင်စေသည်။
   - batches ပိုကြီးလေ၊ gradients ပိုမိုတည်ငြိမ်လေဖြစ်သော်လည်း memory ပိုလိုအပ်သည်။

၃။ **Learning Rate Parameters**:
   - `learning_rate`: weights များကို update လုပ်မည့် အရွယ်အစားကို ထိန်းချုပ်သည်။
   - `warmup_ratio`: training ၏ မည်သည့်အပိုင်းကို learning rate warmup အတွက် အသုံးပြုမည်နည်း။
   - မြင့်လွန်းပါက instability ဖြစ်စေနိုင်ပြီး၊ နိမ့်လွန်းပါက သင်ယူမှု နှေးကွေးစေသည်။

၄။ **Monitoring Parameters**:
   - `logging_steps`: metrics များကို မှတ်တမ်းတင်သည့် အကြိမ်ရေ။
   - `eval_steps`: validation data ပေါ်တွင် မည်မျှကြာကြာ evaluation လုပ်မည်နည်း။
   - `save_steps`: model checkpoint များကို သိမ်းဆည်းသည့် အကြိမ်ရေ။

> [!TIP]
> monitoring အပေါ် အခြေခံ၍ ကနဦးတန်ဖိုးများဖြင့် စတင်ပြီး ချိန်ညှိပါ။
> - 1-3 epochs ဖြင့် စတင်ပါ။
> - ကနဦးတွင် batch sizes ပိုသေးငယ်သည်ကို အသုံးပြုပါ။
> - validation metrics များကို အနီးကပ် စောင့်ကြည့်ပါ။
> - training သည် unstable ဖြစ်ပါက learning rate ကို ချိန်ညှိပါ။

## TRL ဖြင့် Implementation

အခု အဓိကအစိတ်အပိုင်းတွေကို ကျွန်တော်တို့ နားလည်ပြီဆိုတော့၊ သင့်လျော်တဲ့ validation နဲ့ monitoring တွေနဲ့ training ကို implement လုပ်ကြရအောင်။ ကျွန်တော်တို့ Transformers Reinforcement Learning (TRL) library မှ `SFTTrainer` class ကို အသုံးပြုပါမယ်။ ဒီ library ကို `transformers` library ရဲ့ အပေါ်မှာ တည်ဆောက်ထားတာပါ။ TRL library ကို အသုံးပြုထားတဲ့ ဥပမာအပြည့်အစုံကတော့...

```python
from datasets import load_dataset
from trl import SFTConfig, SFTTrainer
import torch

# Set device
device = "cuda" if torch.cuda.is_available() else "cpu"

# Load dataset
dataset = load_dataset("HuggingFaceTB/smoltalk", "all")

# Configure model and tokenizer
model_name = "HuggingFaceTB/SmolLM2-135M"
model = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=model_name).to(
    device
)
tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_name)
# Setup chat template
model, tokenizer = setup_chat_format(model=model, tokenizer=tokenizer)

# Configure trainer
training_args = SFTConfig(
    output_dir="./sft_output",
    max_steps=1000,
    per_device_train_batch_size=4,
    learning_rate=5e-5,
    logging_steps=10,
    save_steps=100,
    eval_strategy="steps",
    eval_steps=50,
)

# Initialize trainer
trainer = SFTTrainer(
    model=model,
    args=training_args,
    train_dataset=dataset["train"],
    eval_dataset=dataset["test"],
    processing_class=tokenizer,
)

# Start training
trainer.train()
```

> [!TIP]
> "messages" field ပါဝင်သော dataset (အပေါ်က ဥပမာလိုမျိုး) ကို အသုံးပြုတဲ့အခါ၊ SFTTrainer က model ရဲ့ chat template ကို အလိုအလျောက် အသုံးပြုပါတယ်။ ဒီ template ကို hub ကနေ ပြန်လည်ရယူတာပါ။ ဒါက chat-style conversations တွေကို ကိုင်တွယ်ဖို့ အပို configuration လုပ်ဖို့ မလိုအပ်ဘူးလို့ ဆိုလိုပါတယ်။ trainer က messages တွေကို model ရဲ့ မျှော်လင့်ထားတဲ့ template format အတိုင်း format လုပ်ပါလိမ့်မယ်။

## Dataset ကို Packing လုပ်ခြင်း

SFTTrainer က training ထိရောက်မှုကို အကောင်းဆုံးဖြစ်အောင် example packing ကို ထောက်ပံ့ပေးပါတယ်။ ဒီ feature က short examples များစွာကို တူညီတဲ့ input sequence တစ်ခုထဲကို ထည့်သွင်းနိုင်စေပြီး training လုပ်နေစဉ် GPU အသုံးပြုမှုကို အမြင့်ဆုံးဖြစ်စေပါတယ်။ packing ကို ဖွင့်ဖို့ SFTConfig constructor မှာ `packing=True` လို့ သတ်မှတ်ပေးရုံပါပဲ။ `max_steps` နဲ့ packed datasets တွေကို အသုံးပြုတဲ့အခါ၊ သင်ရဲ့ packing configuration အပေါ် မူတည်ပြီး မျှော်လင့်ထားသည်ထက် epochs ပိုများများ train လုပ်မိနိုင်ပါတယ်။ examples တွေကို ဘယ်လို ပေါင်းစပ်မလဲဆိုတာကို formatting function တစ်ခု အသုံးပြုပြီး စိတ်ကြိုက်ပြင်ဆင်နိုင်ပါတယ်။ ဒါက question-answer pairs လို multiple fields ပါဝင်တဲ့ datasets တွေနဲ့ အလုပ်လုပ်တဲ့အခါ အထူးအသုံးဝင်ပါတယ်။ evaluation datasets အတွက်၊ SFTConfig မှာ `eval_packing=False` လို့ သတ်မှတ်ခြင်းဖြင့် packing ကို disable လုပ်နိုင်ပါတယ်။ packing configuration ကို စိတ်ကြိုက်ပြင်ဆင်တဲ့ အခြေခံဥပမာတစ်ခုကတော့-

```python
# packing ကို configure လုပ်ခြင်း
training_args = SFTConfig(packing=True)

trainer = SFTTrainer(model=model, train_dataset=dataset, args=training_args)

trainer.train()
```

multiple fields ပါဝင်တဲ့ dataset ကို packing လုပ်တဲ့အခါ၊ fields တွေကို single input sequence တစ်ခုထဲ ပေါင်းစပ်ဖို့ custom formatting function တစ်ခုကို သတ်မှတ်နိုင်ပါတယ်။ ဒီ function က examples တွေရဲ့ list ကို ယူပြီး packed input sequence ပါဝင်တဲ့ dictionary တစ်ခုကို ပြန်ပေးသင့်ပါတယ်။ custom formatting function ရဲ့ ဥပမာတစ်ခုကတော့...

```python
def formatting_func(example):
    text = f"### Question: {example['question']}\n ### Answer: {example['answer']}"
    return text


training_args = SFTConfig(packing=True)
trainer = SFTTrainer(
    "facebook/opt-350m",
    train_dataset=dataset,
    args=training_args,
    formatting_func=formatting_func,
)
```

## Training Progress ကို Monitoring လုပ်ခြင်း

ထိရောက်တဲ့ monitoring ဟာ အောင်မြင်သော fine-tuning အတွက် အရေးကြီးပါတယ်။ training လုပ်နေစဉ် ဘာတွေကို စောင့်ကြည့်ရမလဲဆိုတာ လေ့လာကြည့်ကြပါစို့။

### Loss Patterns များကို နားလည်ခြင်း

Training loss က များသောအားဖြင့် ကွဲပြားတဲ့ အဆင့်သုံးဆင့်ကို လိုက်နာပါတယ်။
၁။ ကနဦး သိသိသာသာ ကျဆင်းခြင်း (Initial Sharp Drop): data distribution အသစ်နဲ့ လျင်မြန်စွာ လိုက်လျောညီထွေဖြစ်ခြင်း။
၂။ တဖြည်းဖြည်း တည်ငြိမ်လာခြင်း (Gradual Stabilization): model က fine-tune လုပ်လာတာနဲ့အမျှ သင်ယူမှု နှေးကွေးလာခြင်း။
၃။ Convergence: Loss values တွေ တည်ငြိမ်လာပြီး training ပြီးဆုံးခြင်းကို ညွှန်ပြခြင်း။

<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/nlp_course_sft_loss_graphic.png" alt="SFTTrainer Training" />

### စောင့်ကြည့်ရမည့် Metrics များ

ထိရောက်သော monitoring တွင် quantitative metrics များကို ခြေရာခံခြင်းနှင့် qualitative metrics များကို အကဲဖြတ်ခြင်းတို့ ပါဝင်ပါတယ်။ ရရှိနိုင်သော metrics များကတော့...

-   Training loss
-   Validation loss
-   Learning rate progression
-   Gradient norms

> [!WARNING]
> training လုပ်နေစဉ် ဒီသတိပေးအမှတ်အသားတွေကို ဂရုစိုက်ပါ။
> ၁။ training loss က လျော့နည်းနေချိန်မှာ validation loss က တိုးလာခြင်း (overfitting)။
> ၂။ loss values တွေမှာ သိသိသာသာ တိုးတက်မှုမရှိခြင်း (underfitting)။
> ၃။ အလွန်နိမ့်သော loss values များ (memorization ဖြစ်နိုင်ခြေ)။
> ၄။ မတသမတ်တည်းဖြစ်သော output formatting (template learning ပြဿနာများ)။

### Convergence သို့ လမ်းကြောင်း

training တိုးတက်လာသည်နှင့်အမျှ loss curve က တဖြည်းဖြည်း တည်ငြိမ်လာသင့်ပါတယ်။ ကျန်းမာသော training ၏ အဓိကညွှန်ပြချက်မှာ training နှင့် validation loss အကြား ကွာဟချက်သေးငယ်ခြင်းဖြစ်ပြီး၊ model က သီးခြားဥပမာများကို မှတ်သားထားခြင်းထက် ယေဘုယျကျသော ပုံစံများကို သင်ယူနေကြောင်း ညွှန်ပြနေသည်။ Absolute loss values တွေကတော့ သင်၏ task နှင့် dataset အပေါ် မူတည်ပြီး ကွဲပြားပါလိမ့်မယ်။

### Training Progress ကို Monitoring လုပ်ခြင်း

အပေါ်က ဂရပ်က ပုံမှန် training တိုးတက်မှုတစ်ခုကို ပြသထားပါတယ်။ training နဲ့ validation loss နှစ်ခုစလုံးက အစပိုင်းမှာ သိသိသာသာ လျော့နည်းပြီး၊ နောက်ပိုင်းမှာ တဖြည်းဖြည်း တည်ငြိမ်လာတာကို သတိပြုပါ။ ဒီပုံစံက model က ထိရောက်စွာ သင်ယူနေပြီး generalization ability ကို ထိန်းသိမ်းထားကြောင်း ညွှန်ပြပါတယ်။

### စောင့်ကြည့်ရမည့် သတိပေးအမှတ်အသားများ

loss curves တွေမှာ ပုံစံအမျိုးမျိုးက ဖြစ်နိုင်ချေရှိတဲ့ ပြဿနာတွေကို ညွှန်ပြနိုင်ပါတယ်။ အောက်မှာ common warning signs တွေနဲ့ ကျွန်တော်တို့ စဉ်းစားနိုင်တဲ့ ဖြေရှင်းနည်းတွေကို သရုပ်ပြထားပါတယ်။

<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/sft_loss_1.png" alt="SFTTrainer Training" />

အကယ်၍ validation loss က training loss ထက် သိသိသာသာ နှေးကွေးစွာ လျော့နည်းနေတယ်ဆိုရင်၊ သင့် model က training data ပေါ်မှာ overfitting ဖြစ်နေနိုင်ပါတယ်။ အောက်ပါတို့ကို စဉ်းစားပါ-
- training steps တွေ လျှော့ချပါ။
- dataset size ကို တိုးမြှင့်ပါ။
- dataset အရည်အသွေးနဲ့ မတူကွဲပြားမှုကို validate လုပ်ပါ။

<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/sft_loss_2.png" alt="SFTTrainer Training" />

အကယ်၍ loss က သိသိသာသာ တိုးတက်မှု မပြဘူးဆိုရင်၊ model က...
- အလွန်နှေးကွေးစွာ သင်ယူနေခြင်း (learning rate တိုးမြှင့်ကြည့်ပါ)။
- task နဲ့ ရုန်းကန်နေရခြင်း (data အရည်အသွေးနဲ့ task complexity ကို စစ်ဆေးပါ)။
- architecture ကန့်သတ်ချက်တွေနဲ့ တိုက်မိခြင်း (မတူညီတဲ့ model တစ်ခုကို စဉ်းစားပါ)။

<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/sft_loss_3.png" alt="SFTTrainer Training" />

အလွန်နိမ့်သော loss values တွေက သင်ယူခြင်းထက် memorization ဖြစ်နေတာကို ညွှန်ပြနိုင်ပါတယ်။ ဒါက အောက်ပါအခြေအနေတွေမှာ အထူးစိုးရိမ်စရာ ဖြစ်ပါတယ်။
- model က အသစ်၊ ဆင်တူတဲ့ examples တွေပေါ်မှာ စွမ်းဆောင်ရည် နည်းပါးခြင်း။
- outputs တွေမှာ မတူကွဲပြားမှု နည်းပါးခြင်း။
- responses တွေက training examples တွေနဲ့ အလွန်ဆင်တူခြင်း။

> [!WARNING]
> training လုပ်နေစဉ် loss values နဲ့ model ရဲ့ actual outputs နှစ်ခုလုံးကို စောင့်ကြည့်ပါ။ တစ်ခါတစ်ရံ loss က ကောင်းမွန်နေပေမယ့် model က မလိုလားအပ်တဲ့ behaviors တွေ ဖြစ်ပေါ်လာနိုင်ပါတယ်။ model ရဲ့ responses တွေကို ပုံမှန် qualitative evaluation လုပ်ခြင်းက metrics တစ်ခုတည်းနဲ့ လွတ်သွားနိုင်တဲ့ ပြဿနာတွေကို ဖမ်းမိအောင် ကူညီပေးပါတယ်။

ကျွန်တော်တို့ ဒီနေရာမှာ ဖော်ပြထားတဲ့ loss values တွေရဲ့ အဓိပ္ပာယ်ဖွင့်ဆိုချက်က အသုံးအများဆုံး အခြေအနေကို ရည်ရွယ်တာဖြစ်ပြီး၊ တကယ်တမ်းမှာတော့ model၊ dataset၊ training parameters စတာတွေအပေါ် မူတည်ပြီး loss values တွေဟာ နည်းလမ်းအမျိုးမျိုးနဲ့ အလုပ်လုပ်နိုင်ပါတယ်။ ဖော်ပြထားတဲ့ ပုံစံတွေအကြောင်း ပိုမိုလေ့လာချင်တယ်ဆိုရင် [Fast AI](https://www.fast.ai/posts/2023-09-04-learning-jumps/) က လူတွေရဲ့ ဒီ blog post ကို ကြည့်ရှုသင့်ပါတယ်။

## SFT ပြီးနောက် Evaluation

အပိုင်း [11.4](/en/chapter11/4) မှာ benchmark datasets တွေကို အသုံးပြုပြီး model ကို ဘယ်လို evaluate လုပ်ရမယ်ဆိုတာ ကျွန်တော်တို့ သင်ယူသွားပါမယ်။ အခုလောလောဆယ်မှာတော့ model ရဲ့ qualitative evaluation ကို အာရုံစိုက်ပါမယ်။

SFT ပြီးဆုံးပြီးနောက်၊ အောက်ပါ လုပ်ဆောင်မှုများကို စဉ်းစားပါ။

၁။ held-out test data ပေါ်တွင် model ကို သေချာစွာ evaluation လုပ်ပါ။
၂။ မတူညီသော inputs များတစ်လျှောက် template adherence ကို validate လုပ်ပါ။
၃။ domain-specific knowledge retention ကို စမ်းသပ်ပါ။
၄။ real-world performance metrics များကို စောင့်ကြည့်ပါ။

> [!TIP]
> သင်၏ training လုပ်ငန်းစဉ်ကို မှတ်တမ်းတင်ပါ၊ ၎င်းတွင် အောက်ပါတို့ ပါဝင်သည်-
> - Dataset characteristics
> - Training parameters
> - Performance metrics
> - သိရှိထားသော ကန့်သတ်ချက်များ
> ဤမှတ်တမ်းတင်ခြင်းသည် နောင် model iterations များအတွက် အလွန်အသုံးဝင်ပါလိမ့်မည်။

## မေးခွန်းများ

### ၁။ SFT တွင် training ကြာချိန်ကို ထိန်းချုပ်သော parameters များက ဘာတွေလဲ။

<Question
	choices={[
		{
			text: "num_train_epochs နှင့် max_steps",
			explain: "မှန်ပါတယ်! ဒီ parameters တွေက epochs အရေအတွက် ဒါမှမဟုတ် စုစုပေါင်း steps တွေနဲ့ model ဘယ်လောက်ကြာကြာ train လုပ်မလဲဆိုတာကို ဆုံးဖြတ်ပါတယ်။",
			correct: true
		},
		{
			text: "batch_size နှင့် learning_rate",
			explain: "ဒါတွေက training ကို သက်ရောက်မှုရှိပေမယ့်၊ ကြာချိန်ကို တိုက်ရိုက်ထိန်းချုပ်တာ မဟုတ်ပါဘူး။"
		},
		{
			text: "gradient_checkpointing နှင့် warmup_ratio",
			explain: "ဒီ parameters တွေက training ထိရောက်မှုနဲ့ stability ကို သက်ရောက်မှုရှိပြီး ကြာချိန်ကို မထိန်းချုပ်ပါဘူး။"
		}
	]}
/>

### ၂။ loss curves တွေမှာ ဘယ်ပုံစံက overfitting ဖြစ်နိုင်ခြေကို ညွှန်ပြသလဲ။

<Question
    choices={[
        {
            text: "training loss က ဆက်လက်လျော့နည်းနေချိန်မှာ validation loss က တိုးလာခြင်း",
            explain: "မှန်ပါတယ်! training နဲ့ validation loss ကြားက ဒီကွာဟမှုက overfitting ရဲ့ အဓိက လက္ခဏာတစ်ခုပါပဲ။",
            correct: true
        },
        {
            text: "training နဲ့ validation loss နှစ်ခုစလုံး တည်ငြိမ်စွာ လျော့နည်းခြင်း",
            explain: "ဒီပုံစံက ကျန်းမာသော training ကို ညွှန်ပြပါတယ်။"
        },
        {
            text: "validation loss က လျော့နည်းနေချိန်မှာ training loss က တသမတ်တည်းရှိနေခြင်း",
            explain: "ဒါက ပုံမှန်မဟုတ်တဲ့ ပုံစံတစ်ခုဖြစ်ပြီး overfitting ကို ညွှန်ပြတာ မဟုတ်ပါဘူး။"
        }
    ]}
/>

### ၃။ gradient_accumulation_steps ကို ဘာအတွက် အသုံးပြုသလဲ။

<Question
    choices={[
        {
            text: "memory ပိုမိုအသုံးပြုခြင်းမရှိဘဲ effective batch size ကို တိုးမြှင့်ရန်",
            explain: "မှန်ပါတယ်! ဒါက weights တွေကို update မလုပ်ခင် multiple forward passes တွေတစ်လျှောက် gradients တွေကို စုဆောင်းပါတယ်။",
            correct: true
        },
        {
            text: "training လုပ်နေစဉ် checkpoints တွေ သိမ်းဆည်းရန်",
            explain: "ဒါကို save_steps နဲ့ save_strategy parameters တွေက ကိုင်တွယ်ပါတယ်။"
        },
        {
            text: "learning rate schedule ကို ထိန်းချုပ်ရန်",
            explain: "Learning rate scheduling ကို learning_rate နဲ့ warmup_ratio တို့က ထိန်းချုပ်ပါတယ်။"
        }
    ]}
/>

### ၄။ SFT training လုပ်နေစဉ် ဘာတွေကို စောင့်ကြည့်သင့်သလဲ။

<Question
    choices={[
        {
            text: "quantitative metrics နဲ့ qualitative outputs နှစ်ခုလုံး",
            explain: "မှန်ပါတယ်! metrics နှစ်မျိုးလုံးကို စောင့်ကြည့်ခြင်းက ဖြစ်နိုင်ချေရှိတဲ့ ပြဿနာအားလုံးကို ဖမ်းမိအောင် ကူညီပေးပါတယ်။",
            correct: true
        },
        {
            text: "training loss တစ်ခုတည်းကိုသာ",
            explain: "Training loss တစ်ခုတည်းက model ရဲ့ ကောင်းမွန်တဲ့ behavior ကို သေချာစေဖို့ မလုံလောက်ပါဘူး။"
        },
        {
            text: "model ရဲ့ output quality တစ်ခုတည်းကိုသာ",
            explain: "အရေးကြီးပေမယ့်၊ qualitative evaluation တစ်ခုတည်းက အရေးကြီးတဲ့ training dynamics တွေကို လွတ်သွားနိုင်ပါတယ်။"
        }
    ]}
/>

### ၅။ training လုပ်နေစဉ် ကျန်းမာသော convergence ကို ဘာက ညွှန်ပြသလဲ။

<Question
    choices={[
        {
            text: "training နဲ့ validation loss ကြားက ကွာဟချက်သေးငယ်ခြင်း",
            explain: "မှန်ပါတယ်! ဒါက model က ယေဘုယျကျတဲ့ ပုံစံတွေကို သင်ယူနေကြောင်း ညွှန်ပြပါတယ်။",
            correct: true
        },
        {
            text: "training loss က သုညသို့ ရောက်ရှိခြင်း",
            explain: "အလွန်နိမ့်သော loss values များက သင်ယူခြင်းထက် memorization ကို ညွှန်ပြနိုင်ပါတယ်။"
        },
        {
            text: "validation loss က training loss ထက် နိမ့်နေခြင်း",
            explain: "ဒါက ပုံမှန်မဟုတ်တဲ့ အခြေအနေဖြစ်ပြီး validation set နဲ့ ပြဿနာရှိနိုင်ပါတယ်။"
        }
    ]}
/>

## 💐 ကောင်းပါပြီ!

SFT ကို အသုံးပြုပြီး models တွေကို ဘယ်လို fine-tune လုပ်ရမယ်ဆိုတာ သင်ယူခဲ့ပြီးပါပြီ! ဆက်လက်လေ့လာဖို့...
၁။ notebook ကို မတူညီတဲ့ parameters တွေနဲ့ စမ်းသပ်ကြည့်ပါ။
၂။ အခြား datasets တွေနဲ့ စမ်းသပ်ကြည့်ပါ။
၃။ သင်တန်းပစ္စည်းတွေကို တိုးတက်အောင် ပံ့ပိုးကူညီပါ။

## ထပ်ဆောင်း အရင်းအမြစ်များ

- [TRL Documentation](https://huggingface.co/docs/trl)
- [SFT Examples Repository](https://github.com/huggingface/trl/blob/main/trl/scripts/sft.py)
- [Fine-tuning Best Practices](https://huggingface.co/docs/transformers/training)

## ဝေါဟာရ ရှင်းလင်းချက် (Glossary)

*   **Supervised Fine-Tuning (SFT)**: ကြိုတင်လေ့ကျင့်ထားပြီးသား (pre-trained) မော်ဒယ်တစ်ခုကို တိကျသောလုပ်ငန်းဆောင်တာများ (specific tasks) အတွက် label ပါသော ဒေတာများကို အသုံးပြု၍ ထပ်မံလေ့ကျင့်ခြင်းနည်းလမ်း။ ၎င်းသည် မော်ဒယ်ကို ပိုမိုစွမ်းဆောင်နိုင်ပြီး ဘက်စုံသုံးနိုင်စေသည်။
*   **Generative Language Models**: စာသားအသစ်များ၊ code သို့မဟုတ် အခြားဒေတာပုံစံများကို ဖန်တီးထုတ်လုပ်နိုင်သော ဘာသာစကားမော်ဒယ်များ။
*   **Summarization**: ရှည်လျားသော စာသားတစ်ခု၏ အနှစ်ချုပ်ကို ထုတ်လုပ်ခြင်း။
*   **Question Answering**: ပေးထားသော စာသားတစ်ခုမှ မေးခွန်းတစ်ခု၏ အဖြေကို ရှာဖွေခြင်း။
*   **Language Models**: လူသားဘာသာစကား၏ ဖြန့်ဝေမှုကို နားလည်ရန် လေ့ကျင့်ထားသော AI မော်ဒယ်တစ်ခု။ ၎င်းသည် စာသားထုတ်လုပ်ခြင်း၊ ဘာသာပြန်ခြင်း စသည့်လုပ်ငန်းများတွင် အသုံးပြုနိုင်သည်။
*   **Tasks**: Artificial Intelligence (AI) သို့မဟုတ် Machine Learning (ML) မော်ဒယ်တစ်ခုက လုပ်ဆောင်ရန် ဒီဇိုင်းထုတ်ထားသော သီးခြားအလုပ်။
*   **Versatile**: ကွဲပြားသော အလုပ်များ သို့မဟုတ် အခြေအနေများစွာကို ကိုင်တွယ်နိုင်စွမ်းရှိခြင်း။
*   **Use Cases**: ထုတ်ကုန် သို့မဟုတ် စနစ်တစ်ခုကို သီးခြားအခြေအနေတစ်ခုတွင် မည်သို့အသုံးပြုသည်ကို ဖော်ပြခြင်း။
*   **LLMs (Large Language Models)**: လူသားဘာသာစကားကို နားလည်ပြီး ထုတ်လုပ်ပေးနိုင်တဲ့ အလွန်ကြီးမားတဲ့ Artificial Intelligence (AI) မော်ဒယ်တွေ ဖြစ်ပါတယ်။
*   **ChatGPT**: OpenAI မှ ဖန်တီးထားသော လူသားနှင့်ဆင်တူသော စာသားများကို ဖန်တီးနိုင်သည့် conversational AI မော်ဒယ်။
*   **Human Preferences**: လူသားများ၏ နှစ်သက်မှုများ သို့မဟုတ် ရွေးချယ်မှုများ။
*   **Chat Templates**: အသုံးပြုသူနှင့် AI မော်ဒယ်များကြား အပြန်အလှန်ဆက်သွယ်မှုများကို စနစ်တကျ ပြုလုပ်ပေးသည့် ဖွဲ့စည်းပုံများ။ ၎င်းတို့သည် တသမတ်တည်းဖြစ်ပြီး အခြေအနေနှင့်ကိုက်ညီသော တုံ့ပြန်မှုများကို သေချာစေသည်။
*   **System Prompts**: AI မော်ဒယ်တစ်ခုအား ၎င်း၏ အခန်းကဏ္ဍ၊ ပုံစံ သို့မဟုတ် လုပ်ဆောင်ရမည့်အရာများကို လမ်းညွှန်ပေးသည့် မူလညွှန်ကြားချက်များ။
*   **Role-based Messages**: AI model နှင့် အသုံးပြုသူတို့၏ သတ်မှတ်ထားသော အခန်းကဏ္ဍများ (ဥပမာ- user, assistant) အပေါ် အခြေခံ၍ ပေးပို့သော messages များ။
*   **Pre-trained Language Models**: အကြီးစား ဒေတာအမြောက်အမြားဖြင့် ကြိုတင်လေ့ကျင့်ထားပြီးဖြစ်သော ဘာသာစကားမော်ဒယ်များ။
*   **Task-specific Dataset**: သီးခြားလုပ်ငန်းတစ်ခု (ဥပမာ- sentiment analysis) အတွက် အထူးပြင်ဆင်ထားသော ဒေတာအစုအဝေး။
*   **Labeled Examples**: labels များ သို့မဟုတ် မှန်ကန်သောအဖြေများ ပါဝင်သော training data များ။
*   **TRL Documentation**: Hugging Face Transformes Reinforcement Learning (TRL) library ၏ တရားဝင် မှတ်တမ်းများ (documentation)။
*   **LoRA (Low-Rank Adaptation)**: Transformer မော်ဒယ်များကဲ့သို့သော large models များကို fine-tuning လုပ်ရာတွင် ထိရောက်မှုရှိစေရန်အတွက် model ၏ layers တွေမှာ low-rank matrices တွေကို ထပ်ထည့်သည့် နည်းပညာ။ ၎င်းသည် memory အသုံးပြုမှုကို သိသိသာသာ လျှော့ချနိုင်သည်။
*   **Low-Rank Matrices**: သင်္ချာပိုင်းဆိုင်ရာ matrix တစ်မျိုးဖြစ်ပြီး ၎င်း၏ rank သည် ၎င်း၏ dimensions များထက် သိသိသာသာ နည်းပါးသည်။ Machine Learning တွင် parameters အရေအတွက်ကို လျှော့ချရန် အသုံးပြုသည်။
*   **Model's Layers**: Neural network model တစ်ခု၏ အဆင့်များ။
*   **Pre-trained Knowledge**: မော်ဒယ်အား မူလ pre-training လုပ်ငန်းစဉ်မှ သင်ယူထားသော ဗဟုသုတများ။
*   **Memory Savings**: ကွန်ပျူတာ၏ RAM အသုံးပြုမှုကို လျှော့ချနိုင်ခြင်း။
*   **Hardware with Limited Resources**: ကွန်ပျူတာ၏ memory (RAM) သို့မဟုတ် processing power (GPU) အစွမ်းအစ အကန့်အသတ်ရှိသော devices များ။
*   **Evaluation**: fine-tuning လုပ်ငန်းစဉ်ပြီးနောက် model ၏ စွမ်းဆောင်ရည်ကို တိုင်းတာခြင်း။ ၎င်းသည် model ၏ ထိရောက်မှုနှင့် တိကျမှုကို ဆုံးဖြတ်ရန် ကူညီပေးသည်။
*   **Model Hub**: Hugging Face Hub ကို ရည်ညွှန်းပြီး AI မော်ဒယ်များ ရှာဖွေ၊ မျှဝေ၊ အသုံးပြုနိုင်သော ဗဟို platform။
*   **🤗 Transformers**: Hugging Face က ထုတ်လုပ်ထားတဲ့ library တစ်ခုဖြစ်ပြီး Transformer မော်ဒယ်တွေကို အသုံးပြုပြီး Natural Language Processing (NLP), computer vision, audio processing စတဲ့ နယ်ပယ်တွေမှာ အဆင့်မြင့် AI မော်ဒယ်တွေကို တည်ဆောက်ပြီး အသုံးပြုနိုင်စေပါတယ်။
*   **Account**: Hugging Face Hub ပေါ်ရှိ သုံးစွဲသူအကောင့်။
*   **Script**: အလိုအလျောက်လုပ်ဆောင်ရန် ရေးသားထားသော code များ။
*   **SFTTrainer**: TRL library မှ `Trainer` class ၏ extension တစ်ခုဖြစ်ပြီး Supervised Fine-Tuning လုပ်ငန်းစဉ်ကို ရိုးရှင်းစေသည်။
*   **Direct Preference Optimization (DPO)**: Reinforcement Learning from Human Feedback (RLHF) အတွက် simplified algorithm တစ်ခုဖြစ်ပြီး model output များကို လူသားနှစ်သက်မှုနှင့် ပိုမိုကိုက်ညီအောင် လုပ်ဆောင်ပေးသည်။
*   **Google Gemma**: Google မှ ထုတ်လုပ်ထားသော open-source LLM တစ်မျိုး။
*   **ChatML**: OpenAI မှ ထုတ်လုပ်ထားသော chat conversation များကို ကိုယ်စားပြုရန်အတွက် markup format တစ်ခု။
*   **Alignment Handbook**: Hugging Face မှ LLM များကို လူသားနှစ်သက်မှုနှင့် ကိုက်ညီအောင် လေ့ကျင့်ရန်အတွက် လမ်းညွှန်စာတမ်း။
*   **Persian Product Catalogs**: ပါရှန်ဘာသာစကားဖြင့် ထုတ်ကုန်စာရင်းများ။
*   **JSON Format**: ဒေတာများကို ပေါ့ပေါ့ပါးပါး ဖလှယ်နိုင်သော format ဖြစ်ပြီး လူသားများ ဖတ်ရှုရလွယ်ကူပြီး စက်များ စီမံဆောင်ရွက်ရလွယ်ကူသည်။
*   **Instruction-tuned Model**: ညွှန်ကြားချက်များကို လိုက်နာရန် အထူးလေ့ကျင့်ထားသော model။
*   **Prompts**: AI model သို့ ပေးပို့သော input စာသားများ သို့မဟုတ် ညွှန်ကြားချက်များ။
*   **Computational Resources**: Machine Learning လုပ်ငန်းများအတွက် လိုအပ်သော ကွန်ပျူတာစွမ်းအား (CPU, GPU), memory နှင့် storage။
*   **Engineering Effort**: စနစ်တစ်ခုကို တည်ဆောက်ရန် သို့မဟုတ် ထိန်းသိမ်းရန် လိုအပ်သော နည်းပညာဆိုင်ရာ အလုပ်ပမာဏ။
*   **Template Control**: Model ၏ output structure ကို တိကျစွာ ထိန်းချုပ်နိုင်ခြင်း။
*   **Output Structure**: Model မှ ထုတ်လုပ်သော ရလဒ်များ၏ ပုံစံ သို့မဟုတ် ဖွဲ့စည်းပုံ။
*   **Chat Template Format**: Chatbot dialogues များကို စနစ်တကျ ကိုယ်စားပြုသော စာသားပုံစံ။
*   **Strict Output Schemas**: Model ၏ output သည် သတ်မှတ်ထားသော စည်းမျဉ်းများ သို့မဟုတ် ပုံစံများကို တင်းကြပ်စွာ လိုက်နာရခြင်း။
*   **Consistent Styling**: Model ၏ output များတစ်လျှောက် တသမတ်တည်းဖြစ်သော ရေးသားဟန် သို့မဟုတ် ပုံစံ။
*   **Domain Adaptation**: Model ကို သီးခြားနယ်ပယ်တစ်ခု၏ အချက်အလက်များနှင့် လိုအပ်ချက်များ (ဥပမာ- ဆေးပညာ) နှင့် လိုက်လျောညီထွေဖြစ်အောင် ပြုလုပ်ခြင်း။
*   **Domain Terminology**: သီးခြားနယ်ပယ်တစ်ခုတွင် အသုံးပြုသော စကားလုံးများနှင့် အသုံးအနှုန်းများ။
*   **Professional Standards**: သီးခြားလုပ်ငန်းနယ်ပယ်တစ်ခုတွင် မျှော်လင့်ထားသော အရည်အသွေး သို့မဟုတ် စံနှုန်းများ။
*   **Technical Queries**: နည်းပညာဆိုင်ရာ မေးခွန်းများ။
*   **Industry-specific Guidelines**: သီးခြားလုပ်ငန်းနယ်ပယ်တစ်ခုအတွက် သတ်မှတ်ထားသော စည်းမျဉ်းများ သို့မဟုတ် လမ်းညွှန်ချက်များ။
*   **Dataset Preparation**: Training အတွက် dataset ကို ပြင်ဆင်ခြင်း။
*   **Input-Output Pairs**: Training dataset တွင် input နှင့် ၎င်း၏ မျှော်လင့်ထားသော output တို့ ပါဝင်သော တွဲဖက်ဒေတာ။
*   **Input Prompt**: AI model သို့ ပေးပို့သော မူလမေးခွန်း သို့မဟုတ် ညွှန်ကြားချက်။
*   **Expected Model Response**: Input prompt အတွက် model မှ မျှော်လင့်ထားသော အဖြေ။
*   **Context**: ပေးထားသော အချက်အလက်ကို နားလည်ရန် ကူညီပေးသော နောက်ခံအချက်အလက်။
*   **Metadata**: ဒေတာအကြောင်း အချက်အလက်များ (data about data)။
*   **Training Data Quality**: training အတွက် အသုံးပြုသော ဒေတာများ၏ သန့်ရှင်းမှု၊ တိကျမှုနှင့် သက်ဆိုင်မှု။
*   **Validate Dataset**: Dataset ၏ အရည်အသွေး၊ တိကျမှုနှင့် မျှတမှုကို စစ်ဆေးခြင်း။
*   **Training Configuration**: Model ကို လေ့ကျင့်ရန်အတွက် သတ်မှတ်ထားသော parameters နှင့် settings များ။
*   **Training Process**: Model ကို ဒေတာများဖြင့် လေ့ကျင့်ပေးသည့် လုပ်ငန်းစဉ်။
*   **`num_train_epochs`**: Model ကို training dataset တစ်ခုလုံးဖြင့် လေ့ကျင့်သည့် အကြိမ်အရေအတွက်။
*   **`max_steps`**: Training လုပ်ငန်းစဉ်အတွင်း လုပ်ဆောင်ရမည့် အများဆုံး training steps အရေအတွက်။
*   **Overfitting**: Model သည် training data ကို အလွန်အကျွံ သင်ယူသွားပြီး unseen data များနှင့် တွေ့ဆုံသောအခါ စွမ်းဆောင်ရည်ကျဆင်းခြင်း။
*   **`per_device_train_batch_size`**: GPU သို့မဟုတ် CPU တစ်ခုစီတွင် training လုပ်ငန်းစဉ်တစ်ခုစီအတွက် အသုံးပြုသော samples အရေအတွက်။
*   **`gradient_accumulation_steps`**: gradients များကို update မလုပ်ခင် batch များစွာမှ gradients များကို စုဆောင်းရန်။ ၎င်းသည် memory ကို ထိထိရောက်ရောက် အသုံးပြုခြင်းဖြင့် effective batch size ကို တိုးမြှင့်နိုင်စေသည်။
*   **Effective Batch Size**: `per_device_train_batch_size` ကို `gradient_accumulation_steps` ဖြင့် မြှောက်ထားသော တန်ဖိုး။
*   **Gradients**: Neural network ၏ parameters များ (weights) ကို update လုပ်ရန် အသုံးပြုသော loss function ၏ ဆင်းသက်လာသော တန်ဖိုးများ။
*   **`learning_rate`**: Training လုပ်ငန်းစဉ်အတွင်း model ၏ weights များကို မည်မျှပြောင်းလဲရမည်ကို ထိန်းချုပ်သော parameter။
*   **`warmup_ratio`**: training ၏ ကနဦးအပိုင်းတွင် learning rate ကို ဖြည်းဖြည်းချင်း တိုးမြှင့်ပေးသည့် အချိုး။
*   **Instability**: Training လုပ်နေစဉ် model ၏ performance တွင် ကြီးမားသော မတည်ငြိမ်မှုများ ဖြစ်ပေါ်ခြင်း။
*   **Monitoring Parameters**: training လုပ်ငန်းစဉ်၏ တိုးတက်မှုကို ခြေရာခံရန် အသုံးပြုသော parameters များ။
*   **`logging_steps`**: Training metrics များကို log လုပ်သော အကြိမ်ရေ။
*   **`eval_steps`**: Validation dataset ပေါ်တွင် model ကို evaluation လုပ်သော အကြိမ်ရေ။
*   **`save_steps`**: Model ၏ checkpoint များကို သိမ်းဆည်းသော အကြိမ်ရေ။
*   **Validation Metrics**: Validation dataset ပေါ်တွင် model ၏ စွမ်းဆောင်ရည်ကို တိုင်းတာရန် အသုံးပြုသော metrics များ။
*   **`AutoModelForCausalLM`**: Hugging Face Transformers library မှ class တစ်ခုဖြစ်ပြီး causal language modeling အတွက် model ကို အလိုအလျောက် load လုပ်ပေးသည်။
*   **`AutoTokenizer`**: Hugging Face Transformers library မှာ ပါဝင်တဲ့ class တစ်ခုဖြစ်ပြီး မော်ဒယ်အမည်ကို အသုံးပြုပြီး သက်ဆိုင်ရာ tokenizer ကို အလိုအလျောက် load လုပ်ပေးသည်။
*   **`setup_chat_format`**: TRL library မှ function တစ်ခုဖြစ်ပြီး model နှင့် tokenizer အတွက် chat format ကို သတ်မှတ်ပေးသည်။
*   **`SFTConfig`**: TRL library မှ Supervised Fine-Tuning ၏ training arguments များကို သတ်မှတ်ရန်အတွက် configuration class။
*   **`output_dir`**: Training outputs (models, logs) များကို သိမ်းဆည်းမည့် directory။
*   **`eval_strategy="steps"`**: Evaluation ကို steps များအပေါ် အခြေခံပြီး လုပ်ဆောင်ရန် strategy။
*   **`Trainer`**: Hugging Face Transformers library မှ model များကို လေ့ကျင့်ရန်အတွက် မြင့်မားသောအဆင့် (high-level) API။
*   **`trl` Library (Transformers Reinforcement Learning)**: Hugging Face မှ Reinforcement Learning from Human Feedback (RLHF) အတွက် ကိရိယာများနှင့် library များ။
*   **Packing**: Multiple short examples များကို 하나의 input sequence ထဲသို့ ပေါင်းစပ်ထည့်သွင်းခြင်းဖြင့် training efficiency ကို မြှင့်တင်သော နည်းလမ်း။
*   **GPU Utilization**: Graphics Processing Unit (GPU) ကို မည်မျှထိရောက်စွာ အသုံးပြုထားသည်ကို ဖော်ပြခြင်း။
*   **Formatting Function**: Multiple fields ပါဝင်သော dataset မှ data များကို single input sequence တစ်ခုအဖြစ် ပေါင်းစပ်ရန်အတွက် custom function။
*   **Training Loss**: Model training လုပ်နေစဉ်တွင် တွက်ချက်သော loss value။
*   **Validation Loss**: Validation dataset ပေါ်တွင် model ၏ စွမ်းဆောင်ရည်ကို တိုင်းတာသော loss value။
*   **Learning Rate Progression**: Training လုပ်နေစဉ် learning rate မည်သို့ပြောင်းလဲသည်ကို ပြသခြင်း။
*   **Gradient Norms**: Gradients များ၏ အရွယ်အစား။
*   **Underfitting**: Model သည် training data မှ အခြေခံပုံစံများကို ကောင်းစွာမသင်ယူနိုင်ခြင်း။
*   **Memorization**: Model သည် training data ကို အလွတ်ကျက်မှတ်ထားခြင်းဖြစ်ပြီး ယေဘုယျကျသော နားလည်မှုမရှိခြင်း။
*   **Qualitative Evaluation**: Model ၏ output များကို လူသားများက စစ်ဆေးခြင်းဖြင့် အရည်အသွေးကို အကဲဖြတ်ခြင်း။
*   **Convergence**: Training လုပ်နေစဉ် model ၏ parameters များ (weights) သည် တည်ငြိမ်သော အခြေအနေသို့ ရောက်ရှိခြင်း။
*   **Generalizable Patterns**: Model သည် unseen data များနှင့် တွေ့ဆုံသောအခါ ကောင်းစွာ စွမ်းဆောင်နိုင်ရန် သင်ယူထားသော ပုံစံများ။
*   **Held-out Test Data**: Model training သို့မဟုတ် validation တွင် အသုံးမပြုရသေးသော dataset အပိုင်း။
*   **Template Adherence**: Model ၏ output သည် သတ်မှတ်ထားသော template ပုံစံကို တသမတ်တည်း လိုက်နာခြင်းရှိမရှိ။
*   **Domain-specific Knowledge Retention**: Model သည် လေ့ကျင့်ထားသော သီးခြားနယ်ပယ်ဆိုင်ရာ ဗဟုသုတများကို မည်မျှထိန်းသိမ်းထားနိုင်ခြင်း။
*   **Real-world Performance Metrics**: လက်တွေ့အခြေအနေများတွင် model ၏ စွမ်းဆောင်ရည်ကို တိုင်းတာရန် အသုံးပြုသော metrics များ။
*   **Dataset Characteristics**: Dataset ၏ အရွယ်အစား၊ အမျိုးအစား၊ ဖြန့်ဝေမှု စသည်တို့ကဲ့သို့သော လက္ခဏာများ။
*   **Model Iterations**: Model ၏ မတူညီသော ဗားရှင်းများ သို့မဟုတ် နောက်ဆက်တွဲ ဖန်တီးမှုများ။