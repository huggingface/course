<CourseFloatingBanner chapter={2}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/main/course/en/chapter11/section2.ipynb"},
]} />

# Chat Templates များ

## နိဒါန်း

Chat templates တွေဟာ ဘာသာစကားမော်ဒယ်တွေနဲ့ အသုံးပြုသူတွေကြား အပြန်အလှန်ဆက်သွယ်မှုတွေကို ဖွဲ့စည်းရာမှာ မရှိမဖြစ်လိုအပ်ပါတယ်။ သင်ဟာ ရိုးရှင်းတဲ့ chatbot တစ်ခုတည်ဆောက်သည်ဖြစ်စေ၊ ရှုပ်ထွေးတဲ့ AI agent တစ်ခုတည်ဆောက်သည်ဖြစ်စေ၊ သင်၏ စကားပြောဆိုမှုများကို မှန်ကန်စွာ ပုံစံချနည်းကို နားလည်ထားခြင်းက သင့် model ကနေ အကောင်းဆုံးရလဒ်တွေရရှိဖို့ အရေးကြီးပါတယ်။ ဒီလမ်းညွှန်ချက်မှာ၊ chat templates တွေက ဘာတွေလဲ၊ ဘာကြောင့် အရေးကြီးတာလဲ၊ ပြီးတော့ ဘယ်လို ထိထိရောက်ရောက် အသုံးပြုရမလဲဆိုတာကို ကျွန်တော်တို့ လေ့လာသွားမှာပါ။

> [!TIP]
> Chat templates တွေက အောက်ပါတို့အတွက် မရှိမဖြစ်လိုအပ်ပါတယ်။
> - တသမတ်တည်းဖြစ်သော စကားပြောဆိုမှုဖွဲ့စည်းပုံကို ထိန်းသိမ်းရန်။
> - အခန်းကဏ္ဍများကို မှန်ကန်စွာ ဖော်ထုတ်နိုင်ရန်။
> - အလှည့်ကျ စကားပြောဆိုမှုများတစ်လျှောက် context ကို စီမံခန့်ခွဲရန်။
> - tool use ကဲ့သို့သော အဆင့်မြင့် features များကို ပံ့ပိုးရန်။

## Model အမျိုးအစားများနှင့် Templates များ

### Base Models နှင့် Instruct Models များ ကွာခြားချက်
Base model တစ်ခုကို နောက်ဆက်တွဲ token ကို ခန့်မှန်းဖို့အတွက် ကုန်ကြမ်းစာသားဒေတာ (raw text data) တွေပေါ်မှာ လေ့ကျင့်ထားပါတယ်။ instruct model တစ်ခုကတော့ ညွှန်ကြားချက်တွေကို လိုက်နာပြီး စကားပြောဆိုမှုတွေမှာ ပါဝင်ဖို့အတွက် သီးခြား fine-tune လုပ်ထားတာ ဖြစ်ပါတယ်။ ဥပမာအားဖြင့်၊ [`SmolLM2-135M`](https://huggingface.co/HuggingFaceTB/SmolLM2-135M) ဟာ base model တစ်ခုဖြစ်ပြီး၊ [`SmolLM2-135M-Instruct`](https://huggingface.co/HuggingFaceTB/SmolLM2-135M-Instruct) ကတော့ ၎င်း၏ instruction-tuned variant ဖြစ်ပါတယ်။

Instruction tuned models တွေဟာ သီးခြားစကားပြောဆိုမှုဖွဲ့စည်းပုံကို လိုက်နာဖို့ လေ့ကျင့်ထားတာကြောင့် chatbot applications တွေအတွက် ပိုမိုသင့်လျော်ပါတယ်။ ဒါ့အပြင် instruct models တွေဟာ tool use၊ multimodal inputs နဲ့ function calling အပါအဝင် ရှုပ်ထွေးတဲ့ အပြန်အလှန်ဆက်သွယ်မှုတွေကို ကိုင်တွယ်နိုင်ပါတယ်။

base model တစ်ခုကို instruct model တစ်ခုလို အလုပ်လုပ်စေဖို့၊ ကျွန်တော်တို့ရဲ့ prompts တွေကို model က နားလည်နိုင်တဲ့ တသမတ်တည်း ပုံစံချဖို့ လိုအပ်ပါတယ်။ ဒီနေရာမှာ chat templates တွေက ပါဝင်လာပါတယ်။ ChatML ဟာ ရှင်းလင်းတဲ့ အခန်းကဏ္ဍညွှန်းကိန်းတွေ (system, user, assistant) နဲ့ စကားပြောဆိုမှုတွေကို ဖွဲ့စည်းထားတဲ့ template format တစ်မျိုး ဖြစ်ပါတယ်။ [ChatML အကြောင်း လမ်းညွှန်](https://huggingface.co/HuggingFaceTB/SmolLM2-135M-Instruct/blob/e2c3f7557efbdec707ae3a336371d169783f1da1/tokenizer_config.json#L146) ကို ကြည့်ပါ။

> [!WARNING]
> instruct model တစ်ခုကို အသုံးပြုတဲ့အခါ၊ သင်မှန်ကန်တဲ့ chat template format ကို အသုံးပြုနေကြောင်း အမြဲတမ်း စစ်ဆေးပါ။ မှားယွင်းတဲ့ template ကို အသုံးပြုခြင်းက model စွမ်းဆောင်ရည် ညံ့ဖျင်းခြင်း ဒါမှမဟုတ် မမျှော်လင့်ထားတဲ့ အပြုအမူတွေ ဖြစ်ပေါ်စေနိုင်ပါတယ်။ ဒါကို သေချာစေဖို့ အလွယ်ကူဆုံးနည်းလမ်းကတော့ Hub ပေါ်ရှိ model tokenizer configuration ကို စစ်ဆေးဖို့ပါပဲ။ ဥပမာ၊ `SmolLM2-135M-Instruct` model က <a href="https://huggingface.co/HuggingFaceTB/SmolLM2-135M-Instruct/blob/e2c3f7557efbdec707ae3a336371d169783f1da1/tokenizer_config.json#L146">ဒီ configuration</a> ကို အသုံးပြုပါတယ်။

### အသုံးများသော Template Formats များ

တိကျတဲ့ implementation တွေထဲ မဝင်ခင်၊ မတူညီတဲ့ models တွေက ၎င်းတို့ရဲ့ စကားပြောဆိုမှုတွေကို ဘယ်လိုပုံစံချထားတာကို မျှော်လင့်သလဲဆိုတာ နားလည်ဖို့ အရေးကြီးပါတယ်။ ရိုးရှင်းတဲ့ ဥပမာစကားပြောဆိုမှုတစ်ခုကို အသုံးပြုပြီး အသုံးများတဲ့ template formats အချို့ကို လေ့လာကြည့်ရအောင်။

ဥပမာအားလုံးအတွက် အောက်ပါ စကားပြောဆိုမှုဖွဲ့စည်းပုံကို ကျွန်တော်တို့ အသုံးပြုပါမယ်။

```python
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Hello!"},
    {"role": "assistant", "content": "Hi! How can I help you today?"},
    {"role": "user", "content": "What's the weather?"},
]
```

ဒါက SmolLM2 နဲ့ Qwen 2 လို models တွေမှာ အသုံးပြုတဲ့ ChatML template ဖြစ်ပါတယ်။

```sh
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
Hello!<|im_end|>
<|im_start|>assistant
Hi! How can I help you today?<|im_end|>
<|im_start|>user
What's the weather?<|im_start|>assistant
```

ဒါက `mistral` template format ကို အသုံးပြုထားတာ ဖြစ်ပါတယ်-

```sh
<s>[INST] You are a helpful assistant. [/INST]
Hi! How can I help you today?</s>
[INST] Hello! [/INST]
```

ဒီ formats တွေကြားက အဓိက ကွာခြားချက်တွေကတော့...
၁။ **System Message Handling**:
   - Llama 2 က system messages တွေကို `<<SYS>>` tags တွေနဲ့ ဝန်းရံထားပါတယ်။
   - Llama 3 က `<|system|>` tags တွေကို `</s>` endings နဲ့ အသုံးပြုပါတယ်။
   - Mistral က system message ကို ပထမဆုံး instruction ထဲမှာ ထည့်သွင်းထားပါတယ်။
   - Qwen က ရှင်းလင်းတဲ့ `system` role ကို `<|im_start|>` tags တွေနဲ့ အသုံးပြုပါတယ်။
   - ChatGPT က `SYSTEM:` prefix ကို အသုံးပြုပါတယ်။

၂။ **Message Boundaries**:
   - Llama 2 က `[INST]` နဲ့ `[/INST]` tags တွေကို အသုံးပြုပါတယ်။
   - Llama 3 က role-specific tags တွေ (`<|system|>`, `<|user|>`, `<|assistant|>`) ကို `</s>` endings နဲ့ အသုံးပြုပါတယ်။
   - Mistral က `[INST]` နဲ့ `[/INST]` ကို `<s>` နဲ့ `</s>` နဲ့ အသုံးပြုပါတယ်။
   - Qwen က role-specific start/end tokens တွေကို အသုံးပြုပါတယ်။

၃။ **Special Tokens**:
   - Llama 2 က စကားပြောဆိုမှု boundaries တွေအတွက် `<s>` နဲ့ `</s>` ကို အသုံးပြုပါတယ်။
   - Llama 3 က message တစ်ခုစီရဲ့ အဆုံးသတ်ဖို့ `</s>` ကို အသုံးပြုပါတယ်။
   - Mistral က turn boundaries တွေအတွက် `<s>` နဲ့ `</s>` ကို အသုံးပြုပါတယ်။
   - Qwen က role-specific start/end tokens တွေကို အသုံးပြုပါတယ်။

ဒီကွာခြားချက်တွေကို နားလည်ထားခြင်းက models အမျိုးမျိုးနဲ့ အလုပ်လုပ်ဖို့ အဓိကသော့ချက် ဖြစ်ပါတယ်။ transformers library က ဒီပြောင်းလဲမှုတွေကို အလိုအလျောက် ကိုင်တွယ်ဖြေရှင်းရာမှာ ဘယ်လိုကူညီပေးလဲဆိုတာ ကြည့်ရအောင်။

```python
from transformers import AutoTokenizer

# ဒါတွေက မတူညီတဲ့ templates တွေကို အလိုအလျောက် အသုံးပြုပါလိမ့်မယ်
mistral_tokenizer = AutoTokenizer.from_pretrained("mistralai/Mistral-7B-Instruct-v0.1")
qwen_tokenizer = AutoTokenizer.from_pretrained("Qwen/Qwen-7B-Chat")
smol_tokenizer = AutoTokenizer.from_pretrained("HuggingFaceTB/SmolLM2-135M-Instruct")

messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Hello!"},
]

# တစ်ခုစီက ၎င်းရဲ့ model template အတိုင်း ပုံစံချပါလိမ့်မယ်
mistral_chat = mistral_tokenizer.apply_chat_template(messages, tokenize=False)
qwen_chat = qwen_tokenizer.apply_chat_template(messages, tokenize=False)
smol_chat = smol_tokenizer.apply_chat_template(messages, tokenize=False)
```

<details>
<summary>Template ဥပမာများကို ကြည့်ရန် နှိပ်ပါ</summary>

Qwen 2 နှင့် SmolLM2 ChatML template:

```sh
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
Hello!<|im_end|>
<|im_start|>assistant
Hi! How can I help you today?<|im_end|>
<|im_start|>user
What's the weather?<|im_start|>assistant
```

Mistral template:

```sh
<s>[INST] You are a helpful assistant. [/INST]
Hi! How can I help you today?</s>
[INST] Hello! [/INST]
```

</details>

### အဆင့်မြင့် Features များ
Chat templates တွေဟာ စကားပြောဆိုမှု အပြန်အလှန်ဆက်သွယ်မှုတွေထက် ပိုမိုရှုပ်ထွေးတဲ့ အခြေအနေတွေကိုလည်း ကိုင်တွယ်နိုင်ပါတယ်။ ဒါတွေမှာ...

၁။ **Tool Use**: Models တွေက ပြင်ပ tools တွေ ဒါမှမဟုတ် APIs တွေနဲ့ အပြန်အလှန်ဆက်သွယ်ဖို့ လိုအပ်တဲ့အခါ။
၂။ **Multimodal Inputs**: ပုံရိပ်တွေ၊ အသံတွေ ဒါမှမဟုတ် အခြား media အမျိုးအစားတွေကို ကိုင်တွယ်ဖို့။
၃။ **Function Calling**: ဖွဲ့စည်းပုံရှိတဲ့ function execution အတွက်။
၄။ **Multi-turn Context**: စကားပြောဆိုမှု မှတ်တမ်းကို ထိန်းသိမ်းဖို့။

> [!TIP]
> အဆင့်မြင့် features တွေကို implement လုပ်တဲ့အခါ...
> - သင့်သီးခြား model နဲ့ သေချာစွာ စမ်းသပ်ပါ။ Vision နဲ့ tool use template တွေက အထူးသဖြင့် ကွဲပြားပါတယ်။
> - feature တစ်ခုစီနဲ့ model တစ်ခုစီကြား token အသုံးပြုမှုကို သေချာစောင့်ကြည့်ပါ။
> - feature တစ်ခုစီအတွက် မျှော်မှန်းထားတဲ့ format ကို မှတ်တမ်းတင်ပါ။

multimodal စကားပြောဆိုမှုတွေအတွက်၊ chat templates တွေက image references ဒါမှမဟုတ် base64-encoded images တွေကို ထည့်သွင်းနိုင်ပါတယ်။

```python
messages = [
    {
        "role": "system",
        "content": "You are a helpful vision assistant that can analyze images.",
    },
    {
        "role": "user",
        "content": [
            {"type": "text", "text": "What's in this image?"},
            {"type": "image", "image_url": "https://example.com/image.jpg"},
        ],
    },
]
```

ဒါက tool use ပါတဲ့ chat template ဥပမာတစ်ခုပါ။

```python
messages = [
    {
        "role": "system",
        "content": "You are an AI assistant that can use tools. Available tools: calculator, weather_api",
    },
    {"role": "user", "content": "What's 123 * 456 and is it raining in Paris?"},
    {
        "role": "assistant",
        "content": "Let me help you with that.",
        "tool_calls": [
            {
                "tool": "calculator",
                "parameters": {"operation": "multiply", "x": 123, "y": 456},
            },
            {"tool": "weather_api", "parameters": {"city": "Paris", "country": "France"}},
        ],
    },
    {"role": "tool", "tool_name": "calculator", "content": "56088"},
    {
        "role": "tool",
        "tool_name": "weather_api",
        "content": "{'condition': 'rain', 'temperature': 15}",
    },
]
```

## အကောင်းဆုံး ကျင့်စဉ်များ

### အထွေထွေ လမ်းညွှန်ချက်များ
Chat templates တွေနဲ့ အလုပ်လုပ်တဲ့အခါ၊ အောက်ပါ အဓိကကျင့်စဉ်တွေကို လိုက်နာပါ။

၁။ **တသမတ်တည်း Formatting**: သင့် application တစ်လျှောက်လုံး တူညီတဲ့ template format ကို အမြဲတမ်း အသုံးပြုပါ။
၂။ **ရှင်းလင်းသော အခန်းကဏ္ဍ သတ်မှတ်ခြင်း**: message တစ်ခုစီအတွက် roles (system, user, assistant, tool) တွေကို ရှင်းလင်းစွာ သတ်မှတ်ပါ။
၃။ **Context Management**: စကားပြောဆိုမှု မှတ်တမ်းကို ထိန်းသိမ်းတဲ့အခါ token ကန့်သတ်ချက်တွေကို သတိထားပါ။
၄။ **Error Handling**: tool calls နဲ့ multimodal inputs တွေအတွက် မှန်ကန်တဲ့ error handling ကို ထည့်သွင်းပါ။
၅။ **Validation**: model ကို မပို့မီ message structure ကို စစ်ဆေးပါ။

> [!WARNING]
> ရှောင်ရှားရမည့် အဖြစ်များသော အမှားများ...
> - တူညီတဲ့ application ထဲမှာ မတူညီတဲ့ template formats တွေကို ရောနှောအသုံးပြုခြင်း။
> - ရှည်လျားတဲ့ စကားပြောဆိုမှု မှတ်တမ်းတွေနဲ့ token ကန့်သတ်ချက်တွေကို ကျော်လွန်ခြင်း။
> - messages တွေမှာ special characters တွေကို မှန်ကန်စွာ escaping မလုပ်ခြင်း။
> - input message structure ကို စစ်ဆေးဖို့ မေ့လျော့ခြင်း။
> - model-specific template လိုအပ်ချက်တွေကို လျစ်လျူရှုခြင်း။

## လက်တွေ့လေ့ကျင့်ခန်း

လက်တွေ့ကမ္ဘာ ဥပမာတစ်ခုနဲ့ chat templates တွေကို implement လုပ်တာကို လေ့ကျင့်ကြရအောင်။

> [!TIP]
> `HuggingFaceTB/smoltalk` dataset ကို chatml format သို့ ပြောင်းလဲဖို့ အောက်ပါအဆင့်တွေကို လိုက်နာပါ-
>
> ၁။ dataset ကို load လုပ်ပါ။
> ```python
> from datasets import load_dataset
>
> dataset = load_dataset("HuggingFaceTB/smoltalk")
> ```
>
> ၂။ processing function တစ်ခု ဖန်တီးပါ။
> ```python
> def convert_to_chatml(example):
>     return {
>         "messages": [
>             {"role": "user", "content": example["input"]},
>             {"role": "assistant", "content": example["output"]},
>         ]
>     }
> ```
>
> ၃။ သင်ရွေးချယ်ထားသော model ၏ tokenizer ကို အသုံးပြု၍ chat template ကို apply လုပ်ပါ။
>
> သင်၏ output format သည် သင်၏ target model ၏ လိုအပ်ချက်များနှင့် ကိုက်ညီကြောင်း သေချာစေရန် မမေ့ပါနှင့်!

## နောက်ထပ် အရင်းအမြစ်များ

- [Hugging Face Chat Templating Guide](https://huggingface.co/docs/transformers/main/en/chat_templating)
- [Transformers Documentation](https://huggingface.co/docs/transformers)
- [Chat Templates Examples Repository](https://github.com/chujiezheng/chat_templates)

## ဝေါဟာရ ရှင်းလင်းချက် (Glossary)

*   **Chat Templates**: ဘာသာစကားမော်ဒယ်တွေနဲ့ အသုံးပြုသူတွေကြား အပြန်အလှန်ဆက်သွယ်မှုတွေကို စနစ်တကျ ပြုလုပ်ပေးသည့် ဖွဲ့စည်းပုံများ။ ၎င်းတို့သည် တသမတ်တည်းဖြစ်ပြီး အခြေအနေနှင့်ကိုက်ညီသော တုံ့ပြန်မှုများကို သေချာစေသည်။
*   **Language Models**: လူသားဘာသာစကား၏ ဖြန့်ဝေမှုကို နားလည်ရန် လေ့ကျင့်ထားသော AI မော်ဒယ်တစ်ခု။ ၎င်းသည် စာသားထုတ်လုပ်ခြင်း၊ ဘာသာပြန်ခြင်း စသည့်လုပ်ငန်းများတွင် အသုံးပြုနိုင်သည်။
*   **AI Agent**: လူသားနှင့် ဆက်သွယ်နိုင်ပြီး သတ်မှတ်ထားသော လုပ်ငန်းဆောင်တာများကို လုပ်ဆောင်နိုင်သည့် Artificial Intelligence (AI) စနစ်။
*   **Chatbot**: လူသားတို့၏ စကားပြောဆိုမှုများကို တုပရန် ဒီဇိုင်းထုတ်ထားသော ကွန်ပျူတာပရိုဂရမ်။
*   **Consistent Conversation Structure**: စကားပြောဆိုမှု၏ ပုံစံသည် အမြဲတမ်း တူညီနေခြင်း။
*   **Role Identification**: စကားပြောဆိုမှုအတွင်း ပါဝင်သူများ (ဥပမာ- system, user, assistant) ၏ အခန်းကဏ္ဍများကို ရှင်းလင်းစွာ ဖော်ထုတ်ခြင်း။
*   **Context Management**: စကားပြောဆိုမှု မှတ်တမ်းကို ထိန်းသိမ်းပြီး အတိတ်က စကားပြောဆိုမှုများကို model က မှတ်မိနိုင်စေရန် စီမံခန့်ခွဲခြင်း။
*   **Tool Use**: AI model တစ်ခုက ပြင်ပကိရိယာများ (ဥပမာ- calculator, weather API) ကို ခေါ်ဆိုပြီး အသုံးပြုနိုင်ခြင်း။
*   **Base Model**: ကုန်ကြမ်းစာသားဒေတာ (raw text data) ပေါ်တွင် နောက်ဆက်တွဲ token ကို ခန့်မှန်းဖို့ လေ့ကျင့်ထားသော ဘာသာစကားမော်ဒယ်။ ၎င်းသည် သီးခြားညွှန်ကြားချက်များကို လိုက်နာရန် fine-tune လုပ်ထားခြင်း မရှိသေးပေ။
*   **Instruct Model**: ညွှန်ကြားချက်များကို လိုက်နာပြီး စကားပြောဆိုမှုများတွင် ပါဝင်ရန်အတွက် သီးခြား fine-tune လုပ်ထားသော ဘာသာစကားမော်ဒယ်။
*   **Raw Text Data**: မည်သည့် preprocessing မျှ မလုပ်ဆောင်ရသေးသော စာသားဒေတာ။
*   **Predict the Next Token**: model တစ်ခုက လက်ရှိ sequence ကို အခြေခံပြီး နောက်ဆက်တွဲဖြစ်လာမည့် စကားလုံး သို့မဟုတ် token ကို ခန့်မှန်းခြင်း။
*   **Fine-tuned**: ကြိုတင်လေ့ကျင့်ထားပြီးသား (pre-trained) မော်ဒယ်တစ်ခုကို သီးခြားလုပ်ငန်းတစ်ခု (specific task) အတွက် အနည်းငယ်သော ဒေတာနဲ့ ထပ်မံလေ့ကျင့်ပေးခြင်းကို ဆိုလိုပါတယ်။
*   **`SmolLM2-135M`**: Hugging Face မှ ထုတ်လုပ်ထားသော base language model တစ်မျိုး။
*   **`SmolLM2-135M-Instruct`**: `SmolLM2-135M` ၏ instruction-tuned version။
*   **Instruction-tuned Variant**: Base model တစ်ခုကို ညွှန်ကြားချက်များကို လိုက်နာရန်အတွက် ထပ်မံ fine-tune လုပ်ထားသော version။
*   **Chatbot Applications**: Chatbot များအတွက် ဒီဇိုင်းထုတ်ထားသော ဆော့ဖ်ဝဲလ်များ။
*   **Multimodal Inputs**: ပုံရိပ်များ၊ အသံများ သို့မဟုတ် အခြား media အမျိုးအစားများကဲ့သို့ မတူညီသော input အမျိုးအစားများ။
*   **Function Calling**: LLM က သီးခြား function တစ်ခုကို ခေါ်ဆိုပြီး လုပ်ဆောင်စေနိုင်ခြင်း။
*   **Prompts**: AI model သို့ ပေးပို့သော ညွှန်ကြားချက်များ သို့မဟုတ် မေးခွန်းများ။
*   **ChatML**: စကားပြောဆိုမှုများကို ရှင်းလင်းသော အခန်းကဏ္ဍညွှန်းကိန်းများ (system, user, assistant) ဖြင့် ဖွဲ့စည်းထားသော template format တစ်မျိုး။
*   **Role Indicators**: စကားပြောဆိုမှုအတွင်း ပါဝင်သူများ၏ အခန်းကဏ္ဍကို ဖော်ပြသော အမှတ်အသားများ။
*   **Tokenizer Configuration**: tokenizer ၏ ဖွဲ့စည်းပုံနှင့် လုပ်ဆောင်ပုံကို သတ်မှတ်ထားသော အချက်အလက်များ။
*   **Hub**: Hugging Face Hub ကို ရည်ညွှန်းပြီး AI မော်ဒယ်များ ရှာဖွေ၊ မျှဝေ၊ အသုံးပြုနိုင်သော ဗဟို platform။
*   **Llama 2 / Llama 3**: Meta AI မှ ထုတ်လုပ်သော Large Language Models များ။
*   **Mistral**: Mistral AI မှ ထုတ်လုပ်သော Large Language Model။
*   **Qwen 2**: Alibaba Cloud မှ ထုတ်လုပ်သော Large Language Model။
*   **ChatGPT**: OpenAI မှ ဖန်တီးထားသော လူသားနှင့်ဆင်တူသော စာသားများကို ဖန်တီးနိုင်သည့် conversational AI မော်ဒယ်။
*   **`system` role**: AI model ၏ အခြေခံညွှန်ကြားချက်များ သို့မဟုတ် အခန်းကဏ္ဍကို သတ်မှတ်သော message role။
*   **`user` role**: အသုံးပြုသူမှ ပေးပို့သော message role။
*   **`assistant` role**: AI model မှ ပြန်လည်တုံ့ပြန်သော message role။
*   **`[INST]` / `[/INST]` tags**: Llama 2 နှင့် Mistral templates များတွင် ညွှန်ကြားချက်များကို ဝန်းရံရန် အသုံးပြုသော tags များ။
*   **`<|im_start|>` / `<|im_end|>` tags**: ChatML template တွင် message boundaries များကို ဖော်ပြသော tokens များ။
*   **`<s>` / `</s>` tokens**: Llama 2 နှင့် Mistral templates များတွင် စကားပြောဆိုမှု သို့မဟုတ် turn boundaries များကို ဖော်ပြသော special tokens များ။
*   **`AutoTokenizer`**: Hugging Face Transformers library မှာ ပါဝင်တဲ့ class တစ်ခုဖြစ်ပြီး မော်ဒယ်အမည်ကို အသုံးပြုပြီး သက်ဆိုင်ရာ tokenizer ကို အလိုအလျောက် load လုပ်ပေးသည်။
*   **`apply_chat_template()` Method**: tokenizer ၏ method တစ်ခုဖြစ်ပြီး `messages` list ကို model အတွက် သင့်လျော်သော chat template format သို့ ပြောင်းလဲပေးသည်။
*   **`tokenize=False`**: `apply_chat_template()` method တွင် output ကို tokens များအဖြစ် ပြောင်းလဲခြင်းမရှိဘဲ formatted string အဖြစ်သာ ပြန်ပေးရန် သတ်မှတ်သည်။
*   **External Tools/APIs**: AI model နှင့် ဆက်သွယ်နိုင်သော ပြင်ပဆော့ဖ်ဝဲလ်များ သို့မဟုတ် ဝန်ဆောင်မှုများ။
*   **Base64-encoded Images**: ပုံရိပ်များကို စာသားအခြေခံ format သို့ ပြောင်းလဲခြင်း။
*   **`image_url`**: ပုံရိပ်တစ်ခု၏ URL (web address)။
*   **`tool_calls`**: AI model က ပြင်ပ tool တစ်ခုကို ခေါ်ဆိုရန် စီစဉ်ထားသော အချက်အလက်များ။
*   **`tool_name`**: ခေါ်ဆိုမည့် tool ၏ အမည်။
*   **`parameters`**: tool function သို့ ပေးပို့မည့် arguments များ။
*   **`content`**: message ၏ အကြောင်းအရာ။
*   **Consistent Formatting**: သင့် application တစ်လျှောက်လုံး တူညီတဲ့ template format ကို အမြဲတမ်း အသုံးပြုခြင်း။
*   **Clear Role Definition**: message တစ်ခုစီအတွက် roles (system, user, assistant, tool) တွေကို ရှင်းလင်းစွာ သတ်မှတ်ခြင်း။
*   **Context Management**: စကားပြောဆိုမှု မှတ်တမ်းကို ထိန်းသိမ်းပြီး model က အတိတ်က စကားပြောဆိုမှုများကို မှတ်မိနိုင်စေရန် စီမံခန့်ခွဲခြင်း။
*   **Token Limits**: model တစ်ခုက တစ်ကြိမ်တည်း လုပ်ဆောင်နိုင်သော tokens များ၏ အများဆုံးအရေအတွက်။
*   **Error Handling**: ပရိုဂရမ်တစ်ခုတွင် အမှားများဖြစ်ပေါ်လာသည့်အခါ ၎င်းတို့ကို ထိရောက်စွာ ကိုင်တွယ်ဖြေရှင်းရန် ဒီဇိုင်းထုတ်ထားသော code အပိုင်း။
*   **Validation**: input data သို့မဟုတ် message structure သည် သတ်မှတ်ထားသော စည်းမျဉ်းများနှင့် ကိုက်ညီခြင်းရှိမရှိ စစ်ဆေးခြင်း။
*   **Escaping Special Characters**: စာသားအတွင်းရှိ အထူး characters များကို ၎င်းတို့၏ စာသားတန်ဖိုးအဖြစ် အဓိပ္ပာယ်ဖွင့်ဆိုနိုင်ရန် ပြောင်းလဲခြင်း။
*   **Model-specific Template Requirements**: သီးခြား model တစ်ခုအတွက် လိုအပ်သော chat template ၏ ပုံစံများ။
*   **`HuggingFaceTB/smoltalk` Dataset**: Hugging Face မှ စမ်းသပ်မှုများအတွက် ထုတ်လုပ်ထားသော dataset တစ်မျိုး။
*   **`load_dataset()`**: Hugging Face Datasets library မှ dataset များကို download လုပ်ပြီး cache လုပ်ရန် အသုံးပြုသော function။
*   **`convert_to_chatml()`**: dataset ကို ChatML format သို့ ပြောင်းလဲရန်အတွက် processing function။