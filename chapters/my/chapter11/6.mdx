# နိဂုံးချုပ်

ဒီအခန်းမှာ၊ ကျွန်တော်တို့ဟာ language models တွေကို fine-tuning လုပ်ရာမှာ မရှိမဖြစ်လိုအပ်တဲ့ အစိတ်အပိုင်းတွေကို လေ့လာခဲ့ပါတယ်။

၁။ **Chat Templates** တွေက model ရဲ့ အပြန်အလှန်ဆက်သွယ်မှုတွေကို စနစ်တကျဖြစ်အောင် ပုံဖော်ပေးပါတယ်။ ဒါက စံပြုထားတဲ့ formatting တွေကနေတစ်ဆင့် တသမတ်တည်းဖြစ်ပြီး သင့်လျော်တဲ့ တုံ့ပြန်မှုတွေကို သေချာစေပါတယ်။

၂။ **Supervised Fine-Tuning (SFT)** က pre-trained models တွေကို ၎င်းတို့ရဲ့ အခြေခံဗဟုသုတတွေကို ထိန်းသိမ်းထားရင်း သီးခြား tasks တွေနဲ့ လိုက်လျောညီထွေဖြစ်အောင် လုပ်ဆောင်နိုင်စေပါတယ်။

၃။ **LoRA** ကတော့ model ရဲ့ စွမ်းဆောင်ရည်ကို ထိန်းသိမ်းထားရင်း trainable parameters တွေကို လျှော့ချခြင်းဖြင့် fine-tuning လုပ်ရာမှာ ထိရောက်တဲ့ ချဉ်းကပ်မှုတစ်ရပ်ကို ပံ့ပိုးပေးပါတယ်။

၄။ **Evaluation** ကတော့ metrics နဲ့ benchmarks အမျိုးမျိုးကနေတစ်ဆင့် fine-tuning ရဲ့ ထိရောက်မှုကို တိုင်းတာပြီး အတည်ပြုပေးပါတယ်။

ဒီနည်းလမ်းတွေကို ပေါင်းစပ်အသုံးပြုတဲ့အခါ၊ ကွန်ပျူတာအရင်းအမြစ်တွေကို ထိရောက်စွာ အသုံးပြုရင်း သီးခြား tasks တွေမှာ ထူးချွန်တဲ့ specialized language models တွေကို ဖန်တီးနိုင်ပါတယ်။ သင်ဟာ customer service bot ဒါမှမဟုတ် domain-specific assistant တစ်ခု တည်ဆောက်နေသည်ဖြစ်စေ၊ ဒီ concepts တွေကို နားလည်ထားတာက model ကို အောင်မြင်စွာ လိုက်လျောညီထွေဖြစ်အောင် ပြုလုပ်ဖို့ မရှိမဖြစ်လိုအပ်ပါတယ်။

## ဝေါဟာရ ရှင်းလင်းချက် (Glossary)

*   **Fine-tuning**: ကြိုတင်လေ့ကျင့်ထားပြီးသား (pre-trained) မော်ဒယ်တစ်ခုကို သီးခြားလုပ်ငန်းတစ်ခု (specific task) အတွက် အနည်းငယ်သော ဒေတာနဲ့ ထပ်မံလေ့ကျင့်ပေးခြင်းကို ဆိုလိုပါတယ်။
*   **Language Models**: လူသားဘာသာစကား၏ ဖြန့်ဝေမှုကို နားလည်ရန် လေ့ကျင့်ထားသော AI မော်ဒယ်တစ်ခု။ ၎င်းသည် စာသားထုတ်လုပ်ခြင်း၊ ဘာသာပြန်ခြင်း စသည့်လုပ်ငန်းများတွင် အသုံးပြုနိုင်သည်။
*   **Chat Templates**: အသုံးပြုသူနှင့် AI မော်ဒယ်များကြား အပြန်အလှန်ဆက်သွယ်မှုများကို စနစ်တကျ ပြုလုပ်ပေးသည့် ဖွဲ့စည်းပုံများ။ ၎င်းတို့သည် တသမတ်တည်းဖြစ်ပြီး အခြေအနေနှင့်ကိုက်ညီသော တုံ့ပြန်မှုများကို သေချာစေသည်။
*   **Standardized Formatting**: သတ်မှတ်ထားသော ပုံစံစည်းမျဉ်းများအတိုင်း စာသား သို့မဟုတ် ဒေတာများကို ပုံစံချခြင်း။
*   **Supervised Fine-Tuning (SFT)**: ကြိုတင်လေ့ကျင့်ထားပြီးသား (pre-trained) မော်ဒယ်တစ်ခုကို တိကျသောလုပ်ငန်းဆောင်တာများ (specific tasks) အတွက် label ပါသော ဒေတာများကို အသုံးပြု၍ ထပ်မံလေ့ကျင့်ခြင်းနည်းလမ်း။
*   **Pre-trained Models**: အကြီးစား ဒေတာအမြောက်အမြားဖြင့် ကြိုတင်လေ့ကျင့်ထားပြီးဖြစ်သော AI မော်ဒယ်များ။
*   **Foundational Knowledge**: model တစ်ခု၏ မူလ pre-training လုပ်ငန်းစဉ်မှ သင်ယူထားသော အခြေခံဗဟုသုတများ။
*   **LoRA (Low-Rank Adaptation)**: Transformer မော်ဒယ်များကဲ့သို့သော large models များကို fine-tuning လုပ်ရာတွင် ထိရောက်မှုရှိစေရန်အတွက် model ၏ layers တွေမှာ low-rank matrices တွေကို ထပ်ထည့်သည့် နည်းပညာ။
*   **Trainable Parameters**: model အတွင်းရှိ လေ့ကျင့်နိုင်သော weights နှင့် biases များ၏ အရေအတွက်။
*   **Model Performance**: model တစ်ခု၏ သတ်မှတ်ထားသော လုပ်ငန်းဆောင်တာများ (tasks) တွင် မည်မျှကောင်းစွာ လုပ်ဆောင်နိုင်သည်ကို ဖော်ပြခြင်း။
*   **Evaluation**: fine-tuning လုပ်ငန်းစဉ်ပြီးနောက် model ၏ စွမ်းဆောင်ရည်ကို တိုင်းတာခြင်း။ ၎င်းသည် model ၏ ထိရောက်မှုနှင့် တိကျမှုကို ဆုံးဖြတ်ရန် ကူညီပေးသည်။
*   **Metrics**: Model ၏ စွမ်းဆောင်ရည်ကို တိုင်းတာရန် အသုံးပြုသော တန်ဖိုးများ (ဥပမာ- accuracy, F1 score)။
*   **Benchmarks**: Model များကို နှိုင်းယှဉ်ရန်အတွက် အသုံးပြုသော စံပြုထားသော datasets များနှင့် evaluation metrics များ။
*   **Specialized Language Models**: သီးခြား domain သို့မဟုတ် task တစ်ခုအတွက် အထူးပြုလေ့ကျင့်ထားသော language models များ။
*   **Computationally Efficient**: ကွန်ပျူတာအရင်းအမြစ်များ (ဥပမာ- CPU, GPU, memory) ကို ထိရောက်စွာ အသုံးပြုနိုင်ခြင်း။
*   **Customer Service Bot**: အသုံးပြုသူများ၏ မေးခွန်းများကို ဖြေကြားရန် သို့မဟုတ် ဝန်ဆောင်မှုပေးရန် ဒီဇိုင်းထုတ်ထားသော AI chatbot။
*   **Domain-specific Assistant**: သီးခြားနယ်ပယ်တစ်ခု (ဥပမာ- ဆေးပညာ၊ ဥပဒေ) အတွက် အထူးပြုလေ့ကျင့်ထားသော AI assistant။
*   **Model Adaptation**: model တစ်ခုကို အခြေအနေအသစ်များ သို့မဟုတ် tasks အသစ်များအတွက် လိုက်လျောညီထွေဖြစ်အောင် ပြုလုပ်ခြင်း။