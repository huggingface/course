# သင့် Dataset ကို Argilla သို့ Load လုပ်ခြင်း[[load-your-dataset-to-argilla]]

<CourseFloatingBanner chapter={10}
  classNames="absolute z-10 right-0 top=0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter10/section3.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter10/section3.ipynb"},
]} />

သင်လုပ်ဆောင်နေတဲ့ NLP task နဲ့ သီးခြား use case ဒါမှမဟုတ် application ပေါ်မူတည်ပြီး၊ သင့် data နဲ့ annotation task က ကွဲပြားခြားနားနေပါလိမ့်မယ်။ ဒီသင်တန်းအပိုင်းအတွက်၊ ကျွန်တော်တို့ဟာ သတင်းများ စုဆောင်းထားတဲ့ dataset တစ်ခုကို အသုံးပြုပြီး tasks နှစ်ခုကို လုပ်ဆောင်ပါမယ်။ ဒါတွေကတော့ text တစ်ခုစီရဲ့ ခေါင်းစဉ်ပေါ်မှာ text classification လုပ်တာနဲ့ ဖော်ပြထားတဲ့ named entities တွေကို ဖော်ထုတ်ဖို့ token classification လုပ်တာတို့ ဖြစ်ပါတယ်။

<iframe
  src="https://huggingface.co/datasets/SetFit/ag_news/embed/viewer/default/train"
  frameborder="0"
  width="100%"
  height="560px"
></iframe>

Argilla UI ကို တိုက်ရိုက်အသုံးပြုပြီး Hub ကနေ datasets တွေကို import လုပ်ဖို့ ဖြစ်နိုင်ပါတယ်။ ဒါပေမယ့် လိုအပ်ရင် data ကို ဘယ်လို ထပ်မံပြင်ဆင်နိုင်မလဲဆိုတာ သင်ယူဖို့ SDK ကို ကျွန်တော်တို့ အသုံးပြုပါမယ်။

## သင့် Dataset ကို Configure လုပ်ပါ

ပထမအဆင့်ကတော့ ယခင်အပိုင်းမှာ လုပ်ခဲ့တဲ့အတိုင်း ကျွန်တော်တို့ရဲ့ Argilla instance ကို ချိတ်ဆက်ဖို့ပါပဲ။

```python
import argilla as rg

HF_TOKEN = "..."  # private spaces များအတွက်သာ

client = rg.Argilla(
    api_url="...",
    api_key="...",
    headers={"Authorization": f"Bearer {HF_TOKEN}"},  # private spaces များအတွက်သာ
)
```

အခု ကျွန်တော်တို့ Argilla မှာရှိတဲ့ ကျွန်တော်တို့ dataset ရဲ့ settings တွေအကြောင်း စဉ်းစားနိုင်ပါပြီ။ ဒါတွေက ကျွန်တော်တို့ data ပေါ်မှာ လုပ်ဆောင်မယ့် annotation task ကို ကိုယ်စားပြုပါတယ်။ ပထမဆုံးအနေနဲ့၊ dataset ကို Hub ကနေ load လုပ်ပြီး ၎င်းရဲ့ features တွေကို စစ်ဆေးနိုင်ပါတယ်။ ဒါမှ dataset ကို မှန်ကန်စွာ configure လုပ်ထားခြင်းရှိမရှိ သေချာစေမှာပါ။

```python
from datasets import load_dataset

data = load_dataset("SetFit/ag_news", split="train")
data.features
```

ဒါတွေကတော့ ကျွန်တော်တို့ dataset ရဲ့ features တွေပါ-

```python out
{'text': Value(dtype='string', id=None),
 'label': Value(dtype='int64', id=None),
 'label_text': Value(dtype='string', id=None)}
```

၎င်းတွင် `text` တစ်ခုပါဝင်ပြီး text classification အတွက် အစောပိုင်း labels အချို့လည်း ပါဝင်ပါတယ်။ အဲဒါတွေကို ကျွန်တော်တို့ dataset settings မှာ named entities တွေအတွက် `spans` question တစ်ခုနဲ့အတူ ထည့်သွင်းပါမယ်။

```python
settings = rg.Settings(
    fields=[rg.TextField(name="text")],
    questions=[
        rg.LabelQuestion(
            name="label", title="စာသားကို အမျိုးအစားခွဲပါ:", labels=data.unique("label_text")
        ),
        rg.SpanQuestion(
            name="entities",
            title="စာသားထဲက entities အားလုံးကို မီးမောင်းထိုးပြပါ:",
            labels=["PERSON", "ORG", "LOC", "EVENT"],
            field="text",
        ),
    ],
)
```

ဒီ settings တွေက ဘာကိုဆိုလိုသလဲဆိုတာ နည်းနည်း ပိုနက်နဲအောင် လေ့လာကြည့်ရအောင်။ ပထမဆုံး၊ ကျွန်တော်တို့ **fields** တွေကို သတ်မှတ်ခဲ့ပါတယ်။ ဒါတွေက ကျွန်တော်တို့ annotation လုပ်မယ့် အချက်အလက်တွေ ပါဝင်ပါတယ်။ ဒီအခြေအနေမှာ၊ ကျွန်တော်တို့မှာ field တစ်ခုတည်းသာ ရှိပြီး ဒါက text ပုံစံနဲ့လာတာကြောင့် `TextField` ကို ရွေးချယ်ခဲ့ပါတယ်။

ပြီးရင်၊ ကျွန်တော်တို့ data ပေါ်မှာ လုပ်ဆောင်ချင်တဲ့ tasks တွေကို ကိုယ်စားပြုတဲ့ **questions** တွေကို သတ်မှတ်ပါတယ်-

-   text classification task အတွက် ကျွန်တော်တို့ `LabelQuestion` ကို ရွေးချယ်ခဲ့ပြီး `label_text` column ရဲ့ unique values တွေကို labels အဖြစ် အသုံးပြုခဲ့ပါတယ်။ ဒါမှ question က dataset မှာ ရှိပြီးသား labels တွေနဲ့ ကိုက်ညီမှုရှိမရှိ သေချာစေမှာပါ။
-   token classification task အတွက်၊ ကျွန်တော်တို့ `SpanQuestion` တစ်ခု လိုအပ်ပါလိမ့်မယ်။ အဲဒီ task အတွက် အသုံးပြုမယ့် labels တွေအပြင်၊ spans တွေကို ဆွဲမယ့် field ကိုလည်း ကျွန်တော်တို့ သတ်မှတ်ခဲ့ပါတယ်။

ရရှိနိုင်တဲ့ fields နဲ့ questions အမျိုးအစားအားလုံးအကြောင်း၊ metadata နဲ့ vectors လိုမျိုး အခြား advanced settings တွေအကြောင်း ပိုမိုသိရှိလိုပါက [Argilla docs](https://docs.argilla.io/latest/how_to_guides/dataset/#define-dataset-settings) ကို သွားကြည့်ပါ။

## Dataset ကို Upload လုပ်ပါ

settings အချို့ကို သတ်မှတ်ပြီးပြီဆိုတော့၊ dataset ကို ဖန်တီးနိုင်ပါပြီ။

```python
dataset = rg.Dataset(name="ag_news", settings=settings)

dataset.create()
```

dataset က ကျွန်တော်တို့ရဲ့ Argilla instance မှာ ပေါ်လာပါပြီ။ ဒါပေမယ့် ဒါက ဗလာဖြစ်နေတာကို သင်တွေ့ရပါလိမ့်မယ်။

<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter10/empty_dataset.png" alt="Screenshot of the empty dataset."/>

အခု ကျွန်တော်တို့ annotation လုပ်မယ့် records တွေကို ထည့်သွင်းဖို့ လိုပါတယ်။ ဆိုလိုတာက ကျွန်တော်တို့ dataset ထဲက rows တွေပေါ့။ ဒါကိုလုပ်ဖို့၊ data ကို records အဖြစ် log လုပ်ပြီး Hub နဲ့ Argilla datasets တွေမှာ နာမည်တူမရှိတဲ့ elements တွေအတွက် mapping တစ်ခု ပံ့ပိုးပေးဖို့ပဲ လိုအပ်ပါလိမ့်မယ်။

```python
dataset.records.log(data, mapping={"label_text": "label"})
```

ကျွန်တော်တို့ရဲ့ mapping မှာ၊ dataset ထဲက `label_text` column ကို `label` ဆိုတဲ့ နာမည်ရှိတဲ့ question နဲ့ map လုပ်သင့်တယ်လို့ သတ်မှတ်ခဲ့ပါတယ်။ ဒီနည်းနဲ့၊ dataset မှာရှိပြီးသား labels တွေကို pre-annotations အဖြစ် အသုံးပြုပြီး annotation လုပ်တာကို ပိုမြန်စေမှာပါ။

records တွေ log လုပ်နေစဉ်မှာတောင်၊ သင်ဟာ Argilla UI ထဲမှာ သင့် dataset နဲ့ အလုပ်စလုပ်နိုင်ပါပြီ။ ဒီအခြေအနေမှာ၊ ဒါက အောက်ပါအတိုင်း ဖြစ်နေပါလိမ့်မယ်။

<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter10/argilla_initial_dataset.png" alt="Screenshot of the dataset in Argilla."/>

အခု ကျွန်တော်တို့ dataset က annotation လုပ်ဖို့ အဆင်သင့်ဖြစ်ပါပြီ။

## ဝေါဟာရ ရှင်းလင်းချက် (Glossary)

*   **NLP Task (Natural Language Processing Task)**: ကွန်ပျူတာတွေ လူသားဘာသာစကားကို နားလည်၊ အဓိပ္ပာယ်ဖော်ပြီး၊ ဖန်တီးနိုင်အောင် လုပ်ဆောင်ပေးတဲ့ အလုပ်တွေ။
*   **Use Case**: ထုတ်ကုန် သို့မဟုတ် စနစ်တစ်ခုကို သီးခြားအခြေအနေတစ်ခုတွင် မည်သို့အသုံးပြုသည်ကို ဖော်ပြခြင်း။
*   **Application**: သီးခြားလုပ်ငန်းဆောင်တာတစ်ခုကို လုပ်ဆောင်ရန် ဒီဇိုင်းထုတ်ထားသော ဆော့ဖ်ဝဲလ်ပရိုဂရမ်။
*   **Dataset**: Artificial Intelligence (AI) မော်ဒယ်တွေ လေ့ကျင့်ဖို့အတွက် အသုံးပြုတဲ့ ဒေတာအစုအဝေးတစ်ခု။
*   **News Collecting Dataset**: သတင်းဆောင်းပါးများ သို့မဟုတ် သတင်းအချက်အလက်များကို စုစည်းထားသော ဒေတာအစုအဝေး။
*   **Text Classification**: စာသားတစ်ခုကို သတ်မှတ်ထားသော အမျိုးအစားများ (categories) ထဲသို့ ခွဲခြားသတ်မှတ်ခြင်း လုပ်ငန်း။
*   **Token Classification**: စာသား sequence တစ်ခုအတွင်းရှိ token တစ်ခုစီကို အမျိုးအစားခွဲခြားသတ်မှတ်ခြင်း လုပ်ငန်း (ဥပမာ- Named Entity Recognition)။
*   **Named Entities**: စာသားများထဲမှ လူအမည်၊ နေရာအမည်၊ အဖွဲ့အစည်းအမည် စသော သီးခြားအမည်များ။
*   **Hugging Face Hub**: AI မော်ဒယ်တွေ၊ datasets တွေနဲ့ demo တွေကို အခြားသူတွေနဲ့ မျှဝေဖို့၊ ရှာဖွေဖို့နဲ့ ပြန်လည်အသုံးပြုဖို့အတွက် အွန်လိုင်း platform တစ်ခု ဖြစ်ပါတယ်။
*   **Argilla UI (User Interface)**: Argilla platform ကို အသုံးပြုသူများ အပြန်အလှန်ဆက်သွယ်နိုင်သော graphical interface။
*   **SDK (Software Development Kit)**: ဆော့ဖ်ဝဲလ် application များကို ဖန်တီးရန်အတွက် ကိရိယာများနှင့် library များ စုစည်းမှု။
*   **Argilla Instance**: သင်ကိုယ်တိုင် တည်ဆောက်ပြီး run ထားသော Argilla platform ၏ သီးခြား version။
*   **`argilla` (Library)**: Argilla platform နှင့် အပြန်အလှန်ဆက်သွယ်ရန်အတွက် Python library။
*   **`HF_TOKEN`**: Hugging Face Hub တွင် authentication အတွက် အသုံးပြုသော personal token။
*   **Private Spaces**: Hugging Face Spaces ပေါ်တွင် သတ်မှတ်ထားသူများသာ ဝင်ရောက်ကြည့်ရှုနိုင်သော space များ။
*   **`api_url`**: Argilla instance ၏ API (Application Programming Interface) URL။
*   **`api_key`**: Argilla instance ကို ဝင်ရောက်ကြည့်ရှုရန်အတွက် လိုအပ်သော authentication key။
*   **`headers`**: HTTP request တွင် ပေးပို့သော အချက်အလက်များ (ဥပမာ- Authorization token)။
*   **`load_dataset()` Function (🤗 Datasets)**: Hugging Face Datasets library မှ dataset များကို download လုပ်ပြီး cache လုပ်ရန် အသုံးပြုသော function။
*   **`split="train"`**: dataset ၏ training portion ကို load လုပ်ရန် သတ်မှတ်ခြင်း။
*   **`data.features`**: dataset ၏ columns များ၏ အမျိုးအစားများနှင့် အချက်အလက်များကို ပြန်ပေးသော property။
*   **`Value(dtype='string', id=None)`**: dataset feature ၏ data type သည် string ဖြစ်ကြောင်း ဖော်ပြခြင်း။
*   **`Settings` Class (Argilla)**: Argilla dataset ၏ အဓိက settings (fields, questions) များကို သတ်မှတ်ရန်။
*   **`fields`**: Argilla dataset တွင် ပါဝင်မည့် data columns များ။
*   **`rg.TextField`**: စာသား field အမျိုးအစားကို သတ်မှတ်ခြင်း။
*   **`questions`**: Annotators များ ဖြေဆိုရမည့် annotation tasks များကို သတ်မှတ်ခြင်း။
*   **`rg.LabelQuestion`**: Classification task အတွက် label ရွေးချယ်ခွင့်များကို ပံ့ပိုးပေးသော question အမျိုးအစား။
*   **`data.unique("label_text")`**: dataset ၏ `label_text` column မှ ထူးခြားသော (unique) တန်ဖိုးများကို ရယူခြင်း။
*   **`rg.SpanQuestion`**: Token classification task အတွက် စာသားအပိုင်းအစ (spans) များကို မီးမောင်းထိုးပြရန် ခွင့်ပြုသော question အမျိုးအစား။
*   **`labels`**: Annotation task တွင် အသုံးပြုနိုင်သော labels များစာရင်း။
*   **`PERSON`, `ORG`, `LOC`, `EVENT`**: Named Entity Recognition (NER) အတွက် အသုံးများသော labels များ (လူပုဂ္ဂိုလ်၊ အဖွဲ့အစည်း၊ နေရာ၊ အဖြစ်အပျက်)။
*   **`Dataset` Class (Argilla)**: Argilla platform တွင် dataset တစ်ခုကို ကိုယ်စားပြုသော class။
*   **`dataset.create()`**: Argilla instance တွင် dataset အသစ်တစ်ခုကို ဖန်တီးရန်။
*   **Records**: dataset အတွင်းရှိ တစ်ခုချင်းစီသော data entries သို့မဟုတ် rows များ။
*   **`dataset.records.log()`**: data များကို Argilla dataset ထဲသို့ log (ထည့်သွင်း) လုပ်ရန်။
*   **`mapping`**: source dataset ၏ column name များနှင့် Argilla dataset ၏ question name များကြား ချိတ်ဆက်မှုကို သတ်မှတ်သော dictionary။
*   **Pre-annotations**: Annotation လုပ်ငန်းစဉ်ကို မြန်ဆန်စေရန်အတွက် model တစ်ခုမှ ကြိုတင်ခန့်မှန်းပေးထားသော labels များ။