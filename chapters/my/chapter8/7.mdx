<!-- DISABLE-FRONTMATTER-SECTIONS -->

# အခန်း (၈) ဆိုင်ရာ မေးခွန်းများ[[end-of-chapter-quiz]]

<CourseFloatingBanner
    chapter={8}
    classNames="absolute z-10 right-0 top-0"
/>

ဒီအခန်းမှာ သင်ယူခဲ့တာတွေကို စစ်ဆေးကြည့်ရအောင်။

### ၁။ Python traceback ကို ဘယ်အစီအစဥ်အတိုင်း ဖတ်သင့်သလဲ။

<Question
	choices={[
		{
			text: "အပေါ်ကနေ အောက်ကို",
			explain: "ထပ်ကြိုးစားပါ -- အခြား programming languages အများစုက exception ကို အပေါ်မှာ ပုံနှိပ်ပေမယ့်၊ Python က ဒီကိစ္စမှာ ထူးခြားပါတယ်။"
		},
		{
			text: "အောက်ကနေ အပေါ်ကို",
			explain: "မှန်ပါတယ်။ Python ရဲ့ tracebacks တွေမှာ exception ကို အောက်ဆုံးမှာ ပြသတာရဲ့ အကျိုးကျေးဇူးတစ်ခုကတော့ terminal မှာ အလုပ်လုပ်နေချိန်မှာ debug လုပ်ဖို့ ပိုမိုလွယ်ကူစေခြင်းပဲ ဖြစ်ပါတယ်၊ ဒါက သင်တွေ့ရမယ့် နောက်ဆုံး line ပါ။",
			correct: true
		}
	]}
/>

### ၂။ Minimal reproducible example ဆိုတာ ဘာလဲ။

<Question
	choices={[
		{
			text: "သုတေသနဆောင်းပါးတစ်ခုမှ Transformer architecture ရဲ့ ရိုးရှင်းတဲ့ implementation တစ်ခု",
			explain: "သင်ကိုယ်တိုင် Transformer models တွေကို အစကနေ implement လုပ်တာဟာ အလွန်ပညာပေးတာဖြစ်ပေမယ့်၊ ဒီနေရာမှာ ကျွန်တော်တို့ ပြောနေတာ ဒါမဟုတ်ပါဘူး။"
		},
		{
			text: "private files ဒါမှမဟုတ် data တွေပေါ်မှာ မည်သည့် external dependencies မျှမပါဘဲ run နိုင်တဲ့ ကျစ်လစ်ပြီး ကိုယ်ပိုင်ပါဝင်တဲ့ code block တစ်ခု",
			explain: "မှန်ပါတယ်။ Minimal reproducible examples တွေက library ရဲ့ maintainers တွေကို သင်ကြုံတွေ့နေရတဲ့ ပြဿနာကို ပြန်လည်ဖန်တီးနိုင်စေတာကြောင့် ၎င်းတို့က ဖြေရှင်းနည်းတွေကို ပိုမိုမြန်ဆန်စွာ ရှာဖွေနိုင်ပါတယ်။",
			correct: true
		},
		{
			text: "Python traceback ရဲ့ screenshot တစ်ခု",
			explain: "ထပ်ကြိုးစားပါ -- issue တစ်ခု file လုပ်တဲ့အခါ သင်ရင်ဆိုင်နေရတဲ့ error ရဲ့ screenshot တစ်ခုကို ထည့်သွင်းချင်စိတ် ဖြစ်ပေါ်စေနိုင်ပေမယ့်၊ ဒါက တခြားသူတွေအတွက် error ကို ပြန်လည်ဖန်တီးဖို့ အလွန်ခက်ခဲစေပါတယ်။"
		},
		{
			text: "error နဲ့ မသက်ဆိုင်တဲ့ အစိတ်အပိုင်းတွေပါ အပါအဝင် သင့် analysis အားလုံးပါဝင်တဲ့ notebook တစ်ခု",
			explain: "မမှန်ပါဘူး -- error ကို ပြသတဲ့ Google Colab notebook တစ်ခုကို မျှဝေတာ အထောက်အကူဖြစ်နိုင်ပေမယ့်၊ အဲဒါက တိုတိုလေးဖြစ်ပြီး သက်ဆိုင်ရာ code ကိုသာ ပါဝင်ကြောင်း သေချာပါစေ။"
		}
	]}
/>

### ၃။ အောက်ပါ code ကို run ဖို့ ကြိုးစားပြီး error ထွက်တယ်လို့ ယူဆပါစို့-

```py
from transformers import GPT3ForSequenceClassification

# ImportError: cannot import name 'GPT3ForSequenceClassification' from 'transformers' (/Users/lewtun/miniconda3/envs/huggingface/lib/python3.8/site-packages/transformers/__init__.py)
# ---------------------------------------------------------------------------
# ImportError                               Traceback (most recent call last)
# /var/folders/28/k4cy5q7s2hs92xq7_h89_vgm0000gn/T/ipykernel_30848/333858878.py in <module>
# ----> 1 from transformers import GPT3ForSequenceClassification

# ImportError: cannot import name 'GPT3ForSequenceClassification' from 'transformers' (/Users/lewtun/miniconda3/envs/huggingface/lib/python3.8/site-packages/transformers/__init__.py)
```

အကူအညီတောင်းဖို့အတွက် forum topic ရဲ့ ခေါင်းစဉ်တစ်ခုအတွက် ဘယ်အရာက ကောင်းမွန်တဲ့ ရွေးချယ်မှု ဖြစ်နိုင်မလဲ။

<Question
	choices={[
		{
			text: "<code>ImportError: cannot import name 'GPT3ForSequenceClassification' from 'transformers' (/Users/lewtun/miniconda3/envs/huggingface/lib/python3.8/site-packages/transformers/__init__.py)</code>",
			explain: "traceback ရဲ့ နောက်ဆုံး line ကို ထည့်သွင်းတာက ဖော်ပြနိုင်ပေမယ့်၊ ဒါက topic ရဲ့ main body အတွက် ပိုသင့်တော်ပါတယ်။ ထပ်ကြိုးစားပါ။"
		},
		{
			text: "<code>from transformers import GPT3ForSequenceClassification</code> နဲ့ ပြဿနာ",
			explain: "ထပ်ကြိုးစားပါ -- ဒါက အသုံးဝင်တဲ့ အချက်အလက်တွေ ပေးပေမယ့်၊ စာသားရဲ့ main body အတွက် ပိုကောင်းပါတယ်။",
		},
		{
			text: "<code>GPT3ForSequenceClassification</code> ကို ဘာကြောင့် import လုပ်လို့ မရတာလဲ။",
			explain: "ကောင်းမွန်တဲ့ ရွေးချယ်မှုပါ! ဒီခေါင်းစဉ်က ကျစ်လစ်ပြီး စာဖတ်သူကို ဘာမှားနေနိုင်သလဲဆိုတဲ့ အရိပ်အမြွက် ပေးပါတယ် (ဆိုလိုသည်မှာ GPT-3 ကို 🤗 Transformers မှာ ထောက်ပံ့မပေးထားပါဘူး)။",
			correct: true
		},
		{
			text: "GPT-3 ကို 🤗 Transformers မှာ ထောက်ပံ့ပေးထားတာလား။",
			explain: "ကောင်းပါတယ်။ မေးခွန်းတွေကို topic titles အဖြစ် အသုံးပြုတာက community ကို ပြဿနာကို ဆက်သွယ်ဖို့ ကောင်းမွန်တဲ့ နည်းလမ်းတစ်ခုပါပဲ။",
			correct: true
		}
	]}
/>

### ၄။ သင် `trainer.train()` ကို run ဖို့ ကြိုးစားပြီး error က ဘယ်ကလာတာလဲဆိုတာ တိတိကျကျ မပြောပြတဲ့ cryptic error တစ်ခုနဲ့ ရင်ဆိုင်ရတယ်လို့ ယူဆပါ။ သင့်ရဲ့ training pipeline မှာ error တွေအတွက် ပထမဆုံး ဘယ်နေရာမှာ ရှာသင့်သလဲ။

<Question
	choices={[
		{
			text: "gradients တွေကို တွက်ချက်ပြီး backpropagation လုပ်ဆောင်တဲ့ optimization step မှာ",
			explain: "သင့် optimizer မှာ bugs တွေ ရှိနိုင်ပေမယ့်၊ ဒါက training pipeline ထဲက အဆင့်များစွာထဲက တစ်ခုဖြစ်လို့၊ အရင်ဆုံး စစ်ဆေးသင့်တဲ့ တခြားအရာတွေ ရှိပါတယ်။ ထပ်ကြိုးစားပါ။"
		},
		{
			text: "metrics တွေကို တွက်ချက်တဲ့ evaluation step မှာ",
			explain: "Evaluation ကတော့ များသောအားဖြင့် epoch အပြည့် training လုပ်ပြီးမှ လုပ်တာဖြစ်လို့၊ training pipeline မှာ အစောပိုင်းနေရာတစ်ခုကို အရင်ဆုံး စစ်ဆေးသင့်ပါတယ်။",
		},
		{
			text: "The datasets",
			explain: "မှန်ပါတယ်။ သင့် data ကို ကြည့်တာက ပထမဆုံး လုပ်သင့်တဲ့ အရာပါပဲ၊ text က သင့်လျော်စွာ encode လုပ်ထားခြင်းရှိမရှိ၊ မျှော်မှန်းထားတဲ့ features တွေ ပါဝင်ခြင်းရှိမရှိ စသည်တို့ကို သေချာစေဖို့ပါပဲ။",
			correct: true
		},
		{
			text: "The dataloaders",
			explain: "ထပ်ကြိုးစားပါ -- ဒါက သင်ပထမဆုံး စစ်ဆေးသင့်တဲ့ အရာနဲ့ အလွန်နီးစပ်ပါတယ်။ dataloaders တွေကို ဘယ် object ကို ကျွန်တော်တို့ ပေးပို့လဲဆိုတာ သင်မှတ်မိသေးလား။"
		}
	]}
/>

### ၅။ CUDA error ကို debug လုပ်ဖို့ အကောင်းဆုံးနည်းလမ်းက ဘာလဲ။

<Question
	choices={[
		{
			text: "error message ကို forums ဒါမှမဟုတ် GitHub မှာ တင်ပါ။",
			explain: "CUDA error messages တွေဟာ များသောအားဖြင့် အချက်အလက် မပြည့်စုံတာကြောင့် ဒါက ဘယ်သူ့ကိုမှ အကူအညီဖြစ်မှာ မဟုတ်ပါဘူး။"
		},
		{
			text: "CPU ပေါ်မှာ code တူတူကို execute လုပ်ပါ။",
			explain: "မှန်ပါတယ်။ ဒါက သင့်ကို ပိုကောင်းတဲ့ error message တစ်ခု ပေးပါလိမ့်မယ်။",
			correct: true
		},
		{
			text: "error ရဲ့ အကြောင်းရင်းကို ရှာဖွေဖို့ traceback ကို ဖတ်ပါ။",
			explain: "ဒါက တခြား error တွေအတွက် သင်လုပ်မယ့် အရာဖြစ်ပေမယ့်၊ CUDA errors တွေဟာ များသောအားဖြင့် ၎င်းတို့ဖြစ်ပွားတဲ့နေရာမှာ မထွက်ပေါ်ပါဘူး။ ဘာလို့လဲဆိုတော့ CUDA operations အများစုက asynchronous ဖြစ်လို့ပါ။"
		},
		{
			text: "batch size ကို လျှော့ချပါ။",
			explain: "batch size ကို လျှော့ချတာက CUDA out-of-memory errors တွေကို ကိုင်တွယ်ရာမှာ ကောင်းမွန်တဲ့ နည်းလမ်းဖြစ်ပေမယ့်၊ ဒီပြဿနာအတွက်တော့ မဟုတ်ပါဘူး။ ထပ်ကြိုးစားပါ။"
		},
		{
			text: "Jupyter kernel ကို restart လုပ်ပါ။",
			explain: "ထပ်ကြိုးစားပါ -- kernel ကို restart လုပ်တာက error ကို မှော်ဆန်စွာ ပျောက်သွားစေမှာ မဟုတ်ပါဘူး!",
		}
	]}
/>

### ၆။ GitHub ပေါ်က issue တစ်ခုကို ပြင်ဆင်ဖို့ အကောင်းဆုံးနည်းလမ်းက ဘာလဲ။

<Question
	choices={[
		{
			text: "bug ရဲ့ ပြည့်စုံတဲ့ reproducible example တစ်ခုကို တင်ပါ။",
			explain: "မှန်ပါတယ်။ ဒါက maintainers တွေကို သင့် bug ကို ရှာဖွေရာမှာ ကူညီဖို့ အကောင်းဆုံးနည်းလမ်းပါပဲ။ တခြားဘာတွေ လုပ်သင့်သေးလဲ။",
			correct: true
		},
		{
			text: "update ရှိမရှိ နေ့တိုင်းမေးပါ။",
			explain: "ဒါက သင့်ကို အကူအညီ ရရှိနိုင်ခြေ နည်းပါးစေမှာပါ၊ လူတွေက သင့်ကို ပိုပြီး လျစ်လျူရှုလာပါလိမ့်မယ်။"
		},
		{
			text: "bug ပတ်ဝန်းကျင်က source code ကို စစ်ဆေးပြီး ဘာကြောင့်ဖြစ်တာလဲဆိုတဲ့ အကြောင်းရင်းကို ရှာဖွေပါ။ ရလဒ်တွေကို issue ထဲမှာ တင်ပါ။",
			explain: "ဒါက maintainers တွေကို သေချာပေါက် ကူညီပါလိမ့်မယ်။ ပြီးတော့ သင်သာ bug ရဲ့ source နဲ့ fix ကို ရှာတွေ့ခဲ့ရင် pull request တစ်ခုတောင် ဖွင့်နိုင်ပါတယ်။ တခြားဘာတွေ လုပ်သင့်သေးလဲ။",
			correct: true
		}
	]}
/>

### ၇။ batch တစ်ခုတည်းကို overfitting လုပ်တာက ဘာကြောင့် ကောင်းမွန်တဲ့ debugging နည်းလမ်းတစ်ခု ဖြစ်တာလဲ။

<Question
	choices={[
		{
			text: "မကောင်းပါဘူး၊ overfitting က အမြဲတမ်း မကောင်းဘဲ ရှောင်ရှားသင့်ပါတယ်။",
			explain: "dataset တစ်ခုလုံးပေါ်မှာ training လုပ်တဲ့အခါ၊ overfitting က သင့် model က new examples တွေနဲ့ ကောင်းကောင်း generalize လုပ်နိုင်မှာ မဟုတ်ဘူးဆိုတဲ့ လက္ခဏာတစ်ခု ဖြစ်နိုင်ပါတယ်။ ဒါပေမယ့် debugging အတွက်ကတော့၊ ကျွန်တော်တို့က dataset တစ်ခုလုံးပေါ်မှာ ပုံမှန်အားဖြင့် train လုပ်လေ့ မရှိပါဘူး။ ထပ်ကြိုးစားပါ။"
		},
		{
			text: "model က loss ကို zero အထိ လျှော့ချနိုင်ခြင်းရှိမရှိ စစ်ဆေးနိုင်စေပါတယ်။",
			explain: "မှန်ပါတယ်။ examples နှစ်ခုလောက်ပဲ ရှိတဲ့ batch သေးသေးလေးတစ်ခုနဲ့၊ model က သင်ယူနိုင်ခြင်းရှိမရှိကို ကျွန်တော်တို့ လျင်မြန်စွာ စစ်ဆေးနိုင်ပါတယ်။",
			correct: true
		},
		{
			text: "ကျွန်တော်တို့ရဲ့ inputs နဲ့ labels တွေရဲ့ tensor shapes တွေ မှန်ကန်ခြင်းရှိမရှိ စစ်ဆေးနိုင်စေပါတယ်။",
			explain: "ထပ်ကြိုးစားပါ -- သင့် tensor shapes တွေ မှားယွင်းနေတယ်ဆိုရင်၊ single batch တစ်ခုပေါ်မှာတောင် training လုပ်နိုင်မှာ မဟုတ်ပါဘူး။",
		}
	]}
/>

### ၈။ 🤗 Transformers repo မှာ issue အသစ်တစ်ခု ဖန်တီးတဲ့အခါ သင့် compute environment အကြောင်း အသေးစိတ်အချက်အလက်တွေကို `transformers-cli env` နဲ့ ထည့်သွင်းတာက ဘာကြောင့် ကောင်းမွန်တဲ့ အကြံဥာဏ်ဖြစ်တာလဲ။

<Question
	choices={[
		{
			text: "ဒါက maintainers တွေကို သင်အသုံးပြုနေတဲ့ library version ကို နားလည်စေပါတယ်။",
			explain: "မှန်ပါတယ်။ library ရဲ့ major version တစ်ခုစီမှာ API မှာ ပြောင်းလဲမှုတွေ ရှိနိုင်တာကြောင့်၊ သင်အသုံးပြုနေတဲ့ သီးခြား version ကို သိရှိခြင်းက ပြဿနာကို ကျဉ်းမြောင်းစေဖို့ ကူညီနိုင်ပါတယ်။ တခြားဘာ အကျိုးကျေးဇူးတွေ ရှိသေးလဲ။",
			correct: true
		},
		{
			text: "ဒါက maintainers တွေကို သင် Windows, macOS, ဒါမှမဟုတ် Linux ပေါ်မှာ code run နေခြင်းရှိမရှိ သိရှိစေပါတယ်။",
			explain: "မှန်ပါတယ်။ Errors တွေဟာ သင်အသုံးပြုနေတဲ့ သီးခြား operating system ကြောင့် ဖြစ်ပေါ်လာနိုင်ပြီး၊ ဒါကို သိရှိခြင်းက maintainers တွေကို ၎င်းတို့ကို locally ပြန်လည်ဖန်တီးနိုင်ဖို့ ကူညီပေးပါတယ်။ ဒါပေမယ့် ဒါတစ်ခုတည်းသော အကြောင်းရင်းတော့ မဟုတ်ပါဘူး။",
			correct: true
		},
		{
			text: "ဒါက maintainers တွေကို သင် GPU ဒါမှမဟုတ် CPU ပေါ်မှာ code run နေခြင်းရှိမရှိ သိရှိစေပါတယ်။",
			explain: "မှန်ပါတယ်။ ဒီအခန်းမှာ ကျွန်တော်တို့ တွေ့ခဲ့ရတဲ့အတိုင်း၊ GPUs ဒါမှမဟုတ် CPUs ပေါ်မှာ run တဲ့ code က မတူညီတဲ့ ရလဒ်တွေ ဒါမှမဟုတ် errors တွေ ထုတ်လုပ်နိုင်ပြီး၊ သင်အသုံးပြုနေတဲ့ hardware ကို သိရှိခြင်းက maintainers တွေရဲ့ အာရုံစိုက်မှုကို ကူညီပေးနိုင်ပါတယ်။ ဒါပေမယ့် ဒါတစ်ခုတည်းသော အကျိုးကျေးဇူးတော့ မဟုတ်ပါဘူး...",
			correct: true
		}
	]}
/>

## ဝေါဟာရ ရှင်းလင်းချက် (Glossary)

*   **Python Traceback**: Python ပရိုဂရမ်တစ်ခု အလုပ်လုပ်နေစဉ် error တစ်ခုဖြစ်ပွားသောအခါ၊ error ဖြစ်ပွားရာ နေရာနှင့် ၎င်း၏ ခေါ်ဆိုမှုမှတ်တမ်း (call stack) ကို ပြသသော အစီရင်ခံစာ။
*   **Exception**: ပရိုဂရမ်တစ်ခု အလုပ်လုပ်နေစဉ် ဖြစ်ပေါ်လာသော ပြဿနာတစ်ခုကြောင့် ၎င်းသည် ပုံမှန်အတိုင်း ဆက်လက်လုပ်ဆောင်နိုင်ခြင်းမရှိခြင်း။
*   **Programming Languages**: ကွန်ပျူတာများကို ညွှန်ကြားချက်များ ပေးရန်အတွက် အသုံးပြုသော ဘာသာစကားများ (ဥပမာ- Python, Java, C++)။
*   **Minimal Reproducible Example (MRE)**: ပြဿနာတစ်ခုကို ပြန်လည်ဖန်တီးရန်အတွက် လိုအပ်သော အနည်းဆုံး code ပမာဏပါဝင်သည့် သီးခြားနှင့် ကျစ်လစ်သော code အပိုင်းအစ။
*   **Transformer Architecture**: Natural Language Processing (NLP) မှာ အောင်မြင်မှုများစွာရရှိခဲ့တဲ့ deep learning architecture တစ်မျိုးပါ။
*   **External Dependencies**: project တစ်ခု အလုပ်လုပ်ရန်အတွက် လိုအပ်သော အခြား library များ၊ modules များ သို့မဟုတ် files များ။
*   **Maintainers**: ဆော့ဖ်ဝဲလ် project တစ်ခုကို ထိန်းသိမ်းစောင့်ရှောက်ပြီး စီမံခန့်ခွဲသူများ။
*   **Screenshot**: ကွန်ပျူတာမျက်နှာပြင်ပေါ်ရှိ မြင်ကွင်းတစ်ခု၏ ပုံရိပ်။
*   **Error**: ပရိုဂရမ်တစ်ခု အလုပ်လုပ်နေစဉ် ဖြစ်ပေါ်လာသော ပြဿနာတစ်ခုကြောင့် ၎င်းသည် ပုံမှန်အတိုင်း ဆက်လက်လုပ်ဆောင်နိုင်ခြင်းမရှိခြင်း။
*   **Issue**: ဆော့ဖ်ဝဲလ် project တစ်ခုတွင် တွေ့ရှိရသော bug, feature request, သို့မဟုတ် ပြဿနာတစ်ခု။ ၎င်းကို GitHub Issues ကဲ့သို့သော platform များတွင် မှတ်တမ်းတင်ထားသည်။
*   **Google Colab Notebook**: Google မှ ပံ့ပိုးပေးထားသော cloud-based Jupyter Notebook environment တစ်ခုဖြစ်ပြီး Python code များကို web browser မှတစ်ဆင့် run နိုင်စေသည်။
*   **`ImportError`**: Python တွင် module တစ်ခု သို့မဟုတ် object တစ်ခုကို import လုပ်ရာတွင် ဖြစ်ပေါ်သော error။
*   **`GPT3ForSequenceClassification`**: Hugging Face Transformers library တွင် မရှိသော GPT-3 ၏ sequence classification version အတွက် အမည်မှား။ (GPT-3 သည် open source မဟုတ်သေးပါ)။
*   **`transformers` (Library)**: Hugging Face Transformers library ကို ရည်ညွှန်းသည်။
*   **Forum Topic**: အွန်လိုင်းဖိုရမ်တစ်ခုရှိ သီးခြားခေါင်းစဉ်။
*   **Concise**: တိုတိုတုတ်တုတ်နှင့် ရှင်းရှင်းလင်းလင်း။
*   **`trainer.train()`**: Hugging Face Trainer API ကို အသုံးပြုပြီး model ကို လေ့ကျင့်သော method။
*   **Cryptic Error**: အဓိပ္ပာယ်ဖော်ရခက်ခဲသော သို့မဟုတ် ရှင်းလင်းစွာ မဖော်ပြထားသော error။
*   **Training Pipeline**: Machine Learning မော်ဒယ်တစ်ခုကို data preprocessing မှစ၍ model training, evaluation အထိ ပါဝင်သော အဆင့်များစွာရှိသည့် လုပ်ငန်းစဉ်။
*   **Optimization Step**: Training လုပ်ငန်းစဉ်တွင် model ၏ parameters များကို ပြောင်းလဲခြင်းဖြင့် model စွမ်းဆောင်ရည်ကို မြှင့်တင်သည့် အဆင့်။
*   **Gradients**: Model ၏ parameters များကို update လုပ်ရန်အတွက် အသုံးပြုသော loss function ၏ ဆင်းသက်မှုများ။
*   **Backpropagation**: Neural networks များတွင် weights များကို update လုပ်ရန် gradients များကို တွက်ချက်သည့် algorithm။
*   **Optimizer**: Model ၏ weights များကို update လုပ်ရန် အသုံးပြုသော algorithm (ဥပမာ- AdamW)။
*   **Evaluation Step**: Model ၏ စွမ်းဆောင်ရည်ကို တိုင်းတာသည့် အဆင့်။
*   **Epoch**: Training dataset တစ်ခုလုံးကို model က တစ်ကြိမ် လေ့ကျင့်ပြီးစီးခြင်း။
*   **Datasets**: AI မော်ဒယ်တွေ လေ့ကျင့်ဖို့အတွက် အသုံးပြုတဲ့ ဒေတာအစုအဝေးတစ်ခုပါ။
*   **Encode**: ဒေတာများကို ကွန်ပျူတာက နားလည်နိုင်သော ပုံစံအဖြစ် ပြောင်းလဲခြင်း။
*   **Features**: Dataset အတွင်းရှိ attributes များ သို့မဟုတ် ကဏ္ဍများ။
*   **Dataloaders**: Dataset ကနေ data တွေကို batch အလိုက် load လုပ်ပေးတဲ့ PyTorch (သို့မဟုတ် TensorFlow) utility class။
*   **CUDA Error**: NVIDIA GPU များကို အသုံးပြုသည့်အခါ ဖြစ်ပေါ်တတ်သော error (Compute Unified Device Architecture)။
*   **Uninformative**: အချက်အလက်မပြည့်စုံခြင်း။
*   **Execute**: Program တစ်ခုကို run ခြင်း။
*   **CPU (Central Processing Unit)**: ကွန်ပျူတာ၏ ပင်မ processor။
*   **Asynchronous**: လုပ်ဆောင်ချက်တစ်ခု ပြီးဆုံးရန် စောင့်ဆိုင်းစရာမလိုဘဲ အခြားလုပ်ဆောင်ချက်များကို တစ်ပြိုင်နက်တည်း လုပ်ဆောင်နိုင်ခြင်း။
*   **Batch Size**: training လုပ်ငန်းစဉ်တစ်ခုစီတွင် model သို့ ပေးပို့သော input samples အရေအတွက်။
*   **CUDA Out-of-Memory Errors**: GPU memory ပြည့်သွား၍ ထပ်မံ data load လုပ်၍မရတော့သည့် error။
*   **Jupyter Kernel**: Jupyter Notebook တွင် code များကို execute လုပ်သော အင်ဂျင်။
*   **GitHub**: Version control အတွက် Git ကို အသုံးပြုသည့် web-based platform တစ်ခုဖြစ်ပြီး code များနှင့် project များကို host လုပ်သည်။
*   **Source Code**: ပရိုဂရမ်တစ်ခုကို လူသားများဖတ်နိုင်သော programming language ဖြင့် ရေးသားထားသော code။
*   **Pull Request**: Git repository တွင် မိမိ၏ ပြောင်းလဲမှုများကို main branch သို့ ပေါင်းစည်းရန် တောင်းဆိုခြင်း။
*   **Overfitting**: Model တစ်ခုသည် training data ကို အလွန်အမင်း ကောင်းစွာ မှတ်မိနေပြီး၊ new data တွင် စွမ်းဆောင်ရည် နည်းပါးခြင်း။
*   **Generalize**: Model တစ်ခုသည် training data မှ သင်ယူထားသော ပုံစံများကို new, unseen data တွင် ကောင်းစွာ အသုံးချနိုင်ခြင်း။
*   **Loss (Function)**: Model ၏ ခန့်မှန်းချက်များနှင့် အမှန်တကယ် labels များကြား ကွာခြားမှုကို တိုင်းတာသော တန်ဖိုး။
*   **Tensor Shapes**: tensors (multi-dimensional arrays) များ၏ dimensions များ။
*   **Compute Environment**: ကွန်ပျူတာ system ၏ hardware (CPU, GPU) နှင့် software (operating system, library versions) ဖွဲ့စည်းမှု။
*   **`transformers-cli env`**: Hugging Face Transformers CLI (Command Line Interface) မှ သုံးစွဲသူ၏ compute environment အကြောင်း အချက်အလက်များကို ထုတ်ပေးသော command။
*   **🤗 Transformers Repo**: Hugging Face Transformers library ၏ GitHub repository။
*   **Major Version**: ဆော့ဖ်ဝဲလ်တစ်ခု၏ အဓိက version ပြောင်းလဲမှု (ဥပမာ- v3 မှ v4)။
*   **API (Application Programming Interface)**: ဆော့ဖ်ဝဲလ် နှစ်ခုကြား အပြန်အလှန် ချိတ်ဆက်ဆောင်ရွက်နိုင်ရန် လမ်းကြောင်းဖွင့်ပေးသော အစုအဝေး (set of rules) များ။
*   **Operating System (OS)**: ကွန်ပျူတာ hardware နှင့် software အရင်းအမြစ်များကို စီမံခန့်ခွဲသော system software (ဥပမာ- Windows, macOS, Linux)။