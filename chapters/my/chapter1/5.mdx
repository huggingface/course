# Encoder မော်ဒယ်များ

<CourseFloatingBanner
    chapter={1}
    classNames="absolute z-10 right-0 top-0"
/>

<Youtube id="MUqNwgPjJvQ" />

Encoder မော်ဒယ်များသည် Transformer မော်ဒယ်၏ encoder ကိုသာ အသုံးပြုသည်။ အဆင့်တိုင်းတွင် attention layer များသည် ကနဦးစာကြောင်းရှိ စကားလုံးအားလုံးကို ဝင်ရောက်ကြည့်ရှုနိုင်သည်။ ဤမော်ဒယ်များကို "bi-directional" attention ရှိသည်ဟု ဖော်ပြလေ့ရှိပြီး *auto-encoding မော်ဒယ်များ* ဟု မကြာခဏ ခေါ်ဆိုကြသည်။

ဤမော်ဒယ်များ၏ ကြိုတင်လေ့ကျင့်မှုသည် ပေးထားသော စာကြောင်းတစ်ခုကို ပျက်စီးစေခြင်း (ဥပမာ၊ ၎င်းတွင် ကျပန်းစကားလုံးများကို ဖုံးကွယ်ခြင်း) နှင့် မော်ဒယ်အား ကနဦးစာကြောင်းကို ရှာဖွေခြင်း သို့မဟုတ် ပြန်လည်တည်ဆောက်ခြင်း တာဝန်ပေးခြင်းတို့ကို အခြေခံသည်။

Encoder မော်ဒယ်များသည် စာကြောင်း အမျိုးအစားခွဲခြားခြင်း၊ အမည်ပေး entity recognition (နှင့် ပိုမိုယေဘုယျအားဖြင့် စကားလုံး အမျိုးအစားခွဲခြားခြင်း) နှင့် ထုတ်ယူမေးခွန်း ဖြေဆိုခြင်းကဲ့သို့သော စာကြောင်းတစ်ခုလုံးကို နားလည်ရန် လိုအပ်သည့် လုပ်ငန်းများအတွက် အသင့်တော်ဆုံးဖြစ်သည်။

ဒီ မော်ဒယ်အမျိုးအစားတွေထဲမှာ ဥပမာအနေနဲ့ ပြောရရင် -

- [ALBERT](https://huggingface.co/docs/transformers/model_doc/albert)
- [BERT](https://huggingface.co/docs/transformers/model_doc/bert)
- [DistilBERT](https://huggingface.co/docs/transformers/model_doc/distilbert)
- [ELECTRA](https://huggingface.co/docs/transformers/model_doc/electra)
- [RoBERTa](https://huggingface.co/docs/transformers/model_doc/roberta)
