# Learning Curve များကို နားလည်ခြင်း[[understanding-learning-curves]]

<CourseFloatingBanner chapter={3}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter3/section7.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter3/section7.ipynb"},
]} />

<Youtube id="7q5NyFT8REg"/>

ယခု သင်သည် `Trainer` API (Application Programming Interface) နှင့် custom training loops နှစ်ခုလုံးကို အသုံးပြု၍ fine-tuning လုပ်နည်းကို သင်ယူပြီးပြီဖြစ်ရာ၊ ရလဒ်များကို မည်သို့ အဓိပ္ပာယ်ဖွင့်ဆိုရမည်ကို နားလည်ရန် အရေးကြီးသည်။ Learning curves များသည် training လုပ်နေစဉ် သင့် model ၏ စွမ်းဆောင်ရည်ကို အကဲဖြတ်ရန်နှင့် စွမ်းဆောင်ရည် မကျဆင်းမီ ဖြစ်နိုင်ခြေရှိသော ပြဿနာများကို ဖော်ထုတ်ရန် အလွန်တန်ဖိုးရှိသော ကိရိယာများဖြစ်သည်။

ဤအပိုင်းတွင် accuracy နှင့် loss curves များကို မည်သို့ဖတ်ရှု အဓိပ္ပာယ်ဖွင့်ဆိုရမည်၊ မတူညီသော curve shapes များက ကျွန်ုပ်တို့၏ model အပြုအမူနှင့် ပတ်သက်၍ ဘာတွေပြောပြသည်ကို နားလည်ရမည်၊ နှင့် အဖြစ်များသော training ပြဿနာများကို မည်သို့ ဖြေရှင်းရမည်ကို လေ့လာပါမည်။

## Learning Curves ဆိုသည်မှာ အဘယ်နည်း။[[what-are-learning-curves]]

Learning curves များသည် training လုပ်နေစဉ်အတွင်း အချိန်နှင့်အမျှ သင်၏ model ၏ စွမ်းဆောင်ရည် metrics များကို ပုံဖြင့်ပြသထားခြင်းဖြစ်သည်။ စောင့်ကြည့်ရန် အရေးကြီးဆုံး curves နှစ်ခုမှာ-

-   **Loss curves**: training steps သို့မဟုတ် epochs များတစ်လျှောက် model ၏ error (loss) မည်သို့ပြောင်းလဲသည်ကို ပြသသည်။
-   **Accuracy curves**: training steps သို့မဟုတ် epochs များတစ်လျှောက် မှန်ကန်သော ခန့်မှန်းချက်များ၏ ရာခိုင်နှုန်းကို ပြသသည်။

ဤ curves များသည် ကျွန်ုပ်တို့၏ model က ထိရောက်စွာ သင်ယူနေခြင်း ရှိမရှိ နားလည်ရန် ကူညီပေးပြီး စွမ်းဆောင်ရည်ကို မြှင့်တင်ရန်အတွက် ချိန်ညှိမှုများ ပြုလုပ်ရာတွင် လမ်းညွှန်ပေးနိုင်သည်။ Transformers များတွင် ဤ metrics များကို batch တစ်ခုစီအတွက် သီးခြားစီ တွက်ချက်ပြီး disk ထဲသို့ log လုပ်သည်။ ထို့နောက် ကျွန်ုပ်တို့သည် [Weights & Biases](https://wandb.ai/) ကဲ့သို့သော library များကို အသုံးပြု၍ ဤ curves များကို မြင်သာအောင် ပြုလုပ်ပြီး ကျွန်ုပ်တို့၏ model ၏ စွမ်းဆောင်ရည်ကို အချိန်နှင့်အမျှ မှတ်တမ်းတင်နိုင်သည်။

### Loss Curves[[loss-curves]]

Loss curve သည် model ၏ error က အချိန်နှင့်အမျှ မည်သို့လျော့နည်းသွားသည်ကို ပြသသည်။ ပုံမှန် အောင်မြင်သော training run တစ်ခုတွင် အောက်ပါကဲ့သို့ curve ကို သင်တွေ့ရပါလိမ့်မည်။

![Loss Curve](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter3/1.png)

-   **မြင့်မားသော အစပိုင်း loss**: model သည် optimization မရှိဘဲ စတင်သောကြောင့် ခန့်မှန်းချက်များသည် အစပိုင်းတွင် ညံ့ဖျင်းသည်။
-   **လျော့နည်းလာသော loss**: training လုပ်ဆောင်လာသည်နှင့်အမျှ loss သည် ယေဘုယျအားဖြင့် လျော့နည်းသင့်သည်။
-   **Convergence**: နောက်ဆုံးတွင် loss သည် နည်းပါးသော တန်ဖိုးတစ်ခုတွင် တည်ငြိမ်လာပြီး model သည် ဒေတာရှိ ပုံစံများကို သင်ယူပြီးဖြစ်ကြောင်း ဖော်ပြသည်။

ယခင်အခန်းများတွင်ကဲ့သို့ပင်၊ ဤ metrics များကို မှတ်တမ်းတင်ရန်နှင့် dashboard တွင် မြင်သာအောင် ပြုလုပ်ရန် Trainer API ကို ကျွန်ုပ်တို့ အသုံးပြုနိုင်သည်။ အောက်ပါသည် Weights & Biases ဖြင့် ဤသို့ လုပ်ဆောင်ပုံ၏ ဥပမာတစ်ခုဖြစ်သည်။

```python
# Trainer ဖြင့် training လုပ်နေစဉ် loss ကို မှတ်တမ်းတင်ပုံ ဥပမာ
from transformers import Trainer, TrainingArguments
import wandb

# စမ်းသပ်မှု မှတ်တမ်းတင်ခြင်းအတွက် Weights & Biases ကို initialize လုပ်ပါ။
wandb.init(project="transformer-fine-tuning", name="bert-mrpc-analysis")

training_args = TrainingArguments(
    output_dir="./results",
    eval_strategy="steps",
    eval_steps=50,
    save_steps=100,
    logging_steps=10,  # metrics များကို steps 10 တိုင်း log လုပ်ပါ။
    num_train_epochs=3,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    report_to="wandb",  # logs များကို Weights & Biases သို့ ပို့ပါ။
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    processing_class=tokenizer,
    compute_metrics=compute_metrics,
)

# metrics များကို အလိုအလျောက် train လုပ်ပြီး log လုပ်ပါ။
trainer.train()
```

### Accuracy Curves[[accuracy-curves]]

Accuracy curve သည် အချိန်နှင့်အမျှ မှန်ကန်သော ခန့်မှန်းချက်များ၏ ရာခိုင်နှုန်းကို ပြသသည်။ loss curves များနှင့် မတူဘဲ accuracy curves များသည် model သင်ယူလာသည်နှင့်အမျှ ယေဘုယျအားဖြင့် တိုးလာသင့်ပြီး loss curve ထက် steps ပိုများနိုင်သည်။

![Accuracy Curve](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter3/2.png)

-   **အစပိုင်း နိမ့်ပါးခြင်း**: model သည် ဒေတာရှိ ပုံစံများကို မသင်ယူရသေးသောကြောင့် အစပိုင်း accuracy သည် နိမ့်ပါးသင့်သည်။
-   **Training နှင့်အတူ တိုးလာခြင်း**: model သည် ဒေတာရှိ ပုံစံများကို သင်ယူနိုင်ပါက accuracy သည် ယေဘုယျအားဖြင့် တိုးတက်သင့်သည်။
-   **Plateaus များ ပြသနိုင်ခြင်း**: model သည် true labels များနှင့် နီးစပ်သော ခန့်မှန်းချက်များ ပြုလုပ်သောကြောင့် accuracy သည် ချောမွေ့စွာ တိုးတက်ခြင်းထက် discrete jumps များဖြင့် တိုးတက်လေ့ရှိသည်။

> [!TIP]
> 💡 **Accuracy Curves များ "Steppy" ဖြစ်ရခြင်း အကြောင်းရင်း**: ဆက်တိုက်ဖြစ်သော loss နှင့်မတူဘဲ၊ accuracy ကို discrete predictions များကို true labels များနှင့် နှိုင်းယှဉ်ခြင်းဖြင့် တွက်ချက်သည်။ model ၏ confidence တွင် သေးငယ်သော တိုးတက်မှုများသည် နောက်ဆုံးခန့်မှန်းချက်ကို ပြောင်းလဲနိုင်ခြင်းမရှိဘဲ၊ threshold ကို ကျော်လွန်သည်အထိ accuracy ကို ပြောင်းလဲခြင်းမရှိဘဲ ပြားသွားစေသည်။

### Convergence[[convergence]]

Convergence ဆိုသည်မှာ model ၏ စွမ်းဆောင်ရည် တည်ငြိမ်လာပြီး loss နှင့် accuracy curves များ ညီညာသွားသည့်အခါ ဖြစ်ပေါ်သည်။ ဒါက model သည် ဒေတာရှိ ပုံစံများကို သင်ယူပြီးပြီဖြစ်ကာ အသုံးပြုရန် အသင့်ဖြစ်ပြီဆိုတဲ့ လက္ခဏာတစ်ခုဖြစ်သည်။ ရိုးရှင်းစွာပြောရလျှင် ကျွန်ုပ်တို့သည် model ကို train လုပ်တိုင်း တည်ငြိမ်သော စွမ်းဆောင်ရည်သို့ convergence ဖြစ်စေရန် ရည်ရွယ်သည်။

![Convergence](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter3/4.png)

models များ convergence ဖြစ်ပြီးသည်နှင့် ၎င်းတို့ကို data အသစ်များပေါ်တွင် ခန့်မှန်းချက်များ ပြုလုပ်ရန် အသုံးပြုနိုင်ပြီး model ၏ စွမ်းဆောင်ရည် မည်မျှ ကောင်းမွန်သည်ကို နားလည်ရန် evaluation metrics များကို ကိုးကားနိုင်သည်။

## Learning Curve ပုံစံများကို အဓိပ္ပာယ်ဖွင့်ဆိုခြင်း[[interpreting-learning-curve-patterns]]

မတူညီသော curve shapes များက သင့် model ၏ training ၏ ကွဲပြားသော ကဏ္ဍများကို ဖော်ပြသည်။ အဖြစ်အများဆုံး ပုံစံများနှင့် ၎င်းတို့၏ အဓိပ္ပာယ်များကို ဆန်းစစ်ကြည့်ကြပါစို့။

### ကောင်းမွန်သော Learning Curves[[healthy-learning-curves]]

ကောင်းမွန်စွာ လုပ်ဆောင်သော training run တစ်ခုသည် အောက်ပါကဲ့သို့ curve shapes များကို ပြသလေ့ရှိသည်။

![Healthy Loss Curve](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter3/5.png)

အထက်ပါ သရုပ်ဖော်ပုံကို ကြည့်ကြပါစို့။ ၎င်းသည် loss curve (ဘယ်ဘက်) နှင့် သက်ဆိုင်ရာ accuracy curve (ညာဘက်) နှစ်ခုလုံးကို ပြသထားသည်။ ဤ curves များသည် ထူးခြားသော ဝိသေသလက္ခဏာများ ရှိသည်။

Loss curve သည် အချိန်နှင့်အမျှ model ၏ loss တန်ဖိုးကို ပြသသည်။ အစပိုင်းတွင် loss သည် မြင့်မားပြီးနောက် တဖြည်းဖြည်း လျော့နည်းသွားသည်၊ ဒါက model က တိုးတက်နေကြောင်း ဖော်ပြသည်။ loss တန်ဖိုး လျော့နည်းခြင်းက model က ပိုမိုကောင်းမွန်သော ခန့်မှန်းချက်များ ပြုလုပ်နေကြောင်း ညွှန်ပြသည်၊ ဘာလို့လဲဆိုတော့ loss သည် ခန့်မှန်းထားသော output နှင့် true output အကြား error ကို ကိုယ်စားပြုလို့ပါပဲ။

ယခု ကျွန်ုပ်တို့၏ အာရုံကို accuracy curve သို့ ပြောင်းကြပါစို့။ ၎င်းသည် အချိန်နှင့်အမျှ model ၏ accuracy ကို ကိုယ်စားပြုသည်။ Accuracy curve သည် နည်းပါးသော တန်ဖိုးဖြင့် စတင်ပြီး training လုပ်ဆောင်လာသည်နှင့်အမျှ တိုးလာသည်။ Accuracy သည် မှန်ကန်စွာ classify လုပ်ထားသော instance များ၏ အချိုးကို တိုင်းတာသည်။ ထို့ကြောင့် accuracy curve တိုးလာသည်နှင့်အမျှ model က ပိုမိုမှန်ကန်သော ခန့်မှန်းချက်များ ပြုလုပ်နေကြောင်း ဖော်ပြသည်။

curves များကြား သိသာထင်ရှားသော ကွာခြားချက်တစ်ခုမှာ ချောမွေ့မှုနှင့် accuracy curve ပေါ်ရှိ "plateaus" များ ရှိနေခြင်းဖြစ်သည်။ loss သည် ချောမွေ့စွာ လျော့နည်းနေသော်လည်း၊ accuracy curve ပေါ်ရှိ plateaus များသည် ဆက်တိုက်တိုးတက်ခြင်းထက် accuracy တွင် discrete jumps များကို ဖော်ပြသည်။ ဤအပြုအမူသည် accuracy ကို တိုင်းတာပုံကြောင့် ဖြစ်သည်။ model ၏ output သည် target နှင့် ပိုမိုနီးစပ်လာပါက loss သည် တိုးတက်နိုင်သည်၊ နောက်ဆုံးခန့်မှန်းချက်သည် မှားယွင်းနေသေးလျှင်ပင်ပေါ့။ သို့သော် Accuracy သည် ခန့်မှန်းချက်က မှန်ကန်ရန် threshold ကို ကျော်လွန်မှသာ တိုးတက်သည်။

ဥပမာအားဖြင့်၊ ကြောင် (0) နှင့် ခွေး (1) ကို ခွဲခြားသော binary classifier တစ်ခုတွင်၊ model က ခွေးပုံ (true value 1) အတွက် 0.3 ဟု ခန့်မှန်းပါက၊ ၎င်းကို 0 အဖြစ် ပတ်လည်ကိန်းသတ်မှတ်ပြီး မှားယွင်းသော classification ဖြစ်သည်။ နောက်တစ်ဆင့်တွင် 0.4 ဟု ခန့်မှန်းပါက၊ ၎င်းသည် မှားယွင်းနေသေးသည်။ 0.4 သည် 0.3 ထက် 1 နှင့် ပိုမိုနီးစပ်သောကြောင့် loss သည် လျော့နည်းသွားမည်ဖြစ်သော်လည်း accuracy သည် ပြောင်းလဲခြင်းမရှိဘဲ plateau တစ်ခုကို ဖန်တီးသည်။ model က 0.5 ထက် ပိုကြီးသော တန်ဖိုးတစ်ခုကို ခန့်မှန်းပြီး 1 အဖြစ် ပတ်လည်ကိန်းသတ်မှတ်မှသာ accuracy သည် တိုးလာမည်။

> [!TIP]
> **ကောင်းမွန်သော curves ၏ ဝိသေသလက္ခဏာများ:**
> - **Loss တွင် ချောမွေ့စွာ လျော့နည်းခြင်း**: training နှင့် validation loss နှစ်ခုလုံး တဖြည်းဖြည်း လျော့နည်းသည်။
> - **နီးစပ်သော training/validation စွမ်းဆောင်ရည်**: training နှင့် validation metrics များကြား ကွာဟချက် နည်းပါးသည်။
> - **Convergence**: curves များ ညီညာသွားပြီး model သည် ပုံစံများကို သင်ယူပြီးဖြစ်ကြောင်း ဖော်ပြသည်။

### လက်တွေ့ဥပမာများ[[practical-examples]]

learning curves ၏ လက်တွေ့ဥပမာအချို့ကို လုပ်ဆောင်ကြပါစို့။ ပထမဦးစွာ training လုပ်နေစဉ် learning curves များကို စောင့်ကြည့်ရန် နည်းလမ်းအချို့ကို မီးမောင်းထိုးပြပါမည်။ အောက်တွင် learning curves တွင် တွေ့မြင်နိုင်သော မတူညီသော ပုံစံများကို ခွဲခြမ်းစိတ်ဖြာပါမည်။

#### Training လုပ်နေစဉ်[[during-training]]

training လုပ်ငန်းစဉ်အတွင်း (သင် `trainer.train()` ကို ခေါ်ဆိုပြီးနောက်) သင်သည် ဤအဓိက အညွှန်းကိန်းများကို စောင့်ကြည့်နိုင်သည်။

1.  **Loss convergence**: loss သည် ဆက်လက် လျော့နည်းနေသေးလား သို့မဟုတ် plateau ဖြစ်နေပြီလား။
2.  **Overfitting လက္ခဏာများ**: training loss လျော့နည်းနေစဉ် validation loss က တိုးလာခြင်း ရှိမရှိ။
3.  **Learning rate**: curves များသည် အလွန်မမှန် (LR (Learning Rate) အလွန်မြင့်မား) သို့မဟုတ် အလွန်ပြားနေသလား (LR အလွန်နည်းပါး)။
4.  **Stability**: ပြဿနာများကို ညွှန်ပြသော ရုတ်တရက် spikes သို့မဟုတ် drops များ ရှိမရှိ။

#### Training ပြီးနောက်[[after-training]]

training လုပ်ငန်းစဉ် ပြီးဆုံးပြီးနောက် သင်သည် model ၏ စွမ်းဆောင်ရည်ကို နားလည်ရန် ပြည့်စုံသော curves များကို ဆန်းစစ်နိုင်သည်။

1.  **နောက်ဆုံး စွမ်းဆောင်ရည်**: model က လက်ခံနိုင်သော စွမ်းဆောင်ရည်အဆင့်များသို့ ရောက်ရှိခဲ့သလား။
2.  **ထိရောက်မှု**: epochs နည်းပါးစွာဖြင့် တူညီသော စွမ်းဆောင်ရည်ကို ရရှိနိုင်ပါသလား။
3.  **Generalization**: training နှင့် validation စွမ်းဆောင်ရည် မည်မျှ နီးစပ်သလဲ။
4.  **Trends**: ထပ်မံ training လုပ်ခြင်းဖြင့် စွမ်းဆောင်ရည် တိုးတက်နိုင်ပါသလား။

> [!TIP]
> 🔍 **W&B Dashboard Features**: Weights & Biases သည် သင်၏ learning curves ၏ လှပသော၊ interactive plots များကို အလိုအလျောက် ဖန်တီးပေးသည်။ သင်သည်-
> - run များစွာကို ဘေးချင်းယှဉ်၍ နှိုင်းယှဉ်နိုင်သည်
> - custom metrics နှင့် visualizations များကို ထည့်သွင်းနိုင်သည်
> - ပုံမှန်မဟုတ်သော အပြုအမူများအတွက် alerts များကို သတ်မှတ်နိုင်သည်
> - ရလဒ်များကို သင်၏ team နှင့် မျှဝေနိုင်သည်
>
> [Weights & Biases documentation](https://docs.wandb.ai/) တွင် ပိုမိုလေ့လာပါ။

#### Overfitting[[overfitting]]

Overfitting ဆိုသည်မှာ model သည် training data မှ အလွန်အမင်း သင်ယူပြီး မတူညီသော data (validation set မှ ကိုယ်စားပြုသော) ကို အသုံးချနိုင်စွမ်းမရှိခြင်း ဖြစ်သည်။

![Overfitting](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter3/10.png)

**လက္ခဏာများ:**

- training loss ဆက်လက်လျော့နည်းနေစဉ် validation loss တိုးလာခြင်း သို့မဟုတ် plateau ဖြစ်ခြင်း။
- training နှင့် validation accuracy များကြား ကွာဟချက် ကြီးမားခြင်း။
- training accuracy သည် validation accuracy ထက် များစွာ မြင့်မားခြင်း။

**Overfitting အတွက် ဖြေရှင်းနည်းများ:**
- **Regularization**: dropout, weight decay သို့မဟုတ် အခြား regularization နည်းလမ်းများကို ထည့်သွင်းပါ။
- **Early stopping**: validation စွမ်းဆောင်ရည် မတိုးတက်တော့သည့်အခါ training ကို ရပ်တန့်ပါ။
- **Data augmentation**: training data အမျိုးအစားကို တိုးမြှင့်ပါ။
- **Model complexity ကို လျှော့ချပါ**: သေးငယ်သော model သို့မဟုတ် parameters နည်းပါးစွာ အသုံးပြုပါ။

အောက်ပါ ဥပမာတွင် ကျွန်ုပ်တို့သည် overfitting ကို ကာကွယ်ရန် early stopping ကို အသုံးပြုသည်။ ကျွန်ုပ်တို့သည် `early_stopping_patience` ကို 3 ဟု သတ်မှတ်ထားသည်၊ ဆိုလိုသည်မှာ validation loss သည် 3 consecutive epochs အတွက် မတိုးတက်ပါက training ကို ရပ်တန့်လိမ့်မည်။

```python
# early stopping ဖြင့် overfitting ကို detect လုပ်ပုံ ဥပမာ
from transformers import EarlyStoppingCallback

training_args = TrainingArguments(
    output_dir="./results",
    eval_strategy="steps",
    eval_steps=100,
    save_strategy="steps",
    save_steps=100,
    load_best_model_at_end=True,
    metric_for_best_model="eval_loss",
    greater_is_better=False,
    num_train_epochs=10,  # မြင့်မားစွာ သတ်မှတ်ထားသော်လည်း စောစီးစွာ ရပ်တန့်ပါမည်။
)

# overfitting ကို ကာကွယ်ရန် early stopping ကို ထည့်သွင်းပါ။
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    processing_class=tokenizer,
    compute_metrics=compute_metrics,
    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],
)
```

#### 2. Underfitting[[underfitting]]

Underfitting ဆိုသည်မှာ model သည် ဒေတာရှိ အခြေခံပုံစံများကို ဖမ်းယူရန် အလွန်ရိုးရှင်းလွန်းသောအခါ ဖြစ်ပေါ်သည်။ ၎င်းသည် အကြောင်းရင်းအများအပြားကြောင့် ဖြစ်နိုင်သည်။

- model သည် အလွန်သေးငယ်ခြင်း သို့မဟုတ် ပုံစံများကို သင်ယူရန် စွမ်းဆောင်ရည် မရှိခြင်း။
- learning rate သည် အလွန်နည်းပါးပြီး သင်ယူမှု နှေးကွေးခြင်း။
- dataset သည် အလွန်သေးငယ်ခြင်း သို့မဟုတ် ပြဿနာကို ကိုယ်စားပြုမှု မရှိခြင်း။
- model သည် မှန်ကန်စွာ regularization မလုပ်ထားခြင်း။

![Underfitting](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter3/7.png)

**လက္ခဏာများ:**
- training နှင့် validation loss နှစ်ခုလုံး မြင့်မားနေသေးသည်။
- training ၏ အစောပိုင်းတွင် model စွမ်းဆောင်ရည် plateau ဖြစ်သွားသည်။
- training accuracy သည် မျှော်လင့်ထားသည်ထက် နိမ့်သည်။

**Underfitting အတွက် ဖြေရှင်းနည်းများ:**
- **Model capacity တိုးမြှင့်ပါ**: ပိုကြီးမားသော model သို့မဟုတ် parameters ပိုများစွာ အသုံးပြုပါ။
- **ပိုမိုကြာကြာ train လုပ်ပါ**: epochs အရေအတွက်ကို တိုးမြှင့်ပါ။
- **Learning rate ချိန်ညှိပါ**: မတူညီသော learning rates များကို စမ်းသပ်ကြည့်ပါ။
- **ဒေတာအရည်အသွေးကို စစ်ဆေးပါ**: သင့်ဒေတာကို မှန်ကန်စွာ preprocessing လုပ်ထားကြောင်း သေချာပါစေ။

အောက်ပါ ဥပမာတွင် model က ဒေတာရှိ ပုံစံများကို သင်ယူနိုင်မလား သိရှိရန် epochs ပိုများစွာ train လုပ်သည်။

```python
from transformers import TrainingArguments

training_args = TrainingArguments(
    output_dir="./results",
    -num_train_epochs=5,
    +num_train_epochs=10,
)
```

#### 3. Erratic Learning Curves[[erratic-learning-curves]]

Erratic learning curves များသည် model က ထိရောက်စွာ သင်ယူခြင်းမရှိသောအခါ ဖြစ်ပေါ်သည်။ ၎င်းသည် အကြောင်းရင်းအများအပြားကြောင့် ဖြစ်နိုင်သည်။

- learning rate သည် အလွန်မြင့်မားပြီး model ကို optimal parameters များကို ကျော်လွန်သွားစေသည်။
- batch size သည် အလွန်သေးငယ်ပြီး model ကို နှေးကွေးစွာ သင်ယူစေသည်။
- model သည် မှန်ကန်စွာ regularization မလုပ်ထားသောကြောင့် training data ကို overfitting ဖြစ်စေသည်။
- dataset ကို မှန်ကန်စွာ preprocessing မလုပ်ထားသောကြောင့် model ကို noise မှ သင်ယူစေသည်။

![Erratic Learning Curves](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter3/3.png)

**လက္ခဏာများ:**
- loss သို့မဟုတ် accuracy တွင် မကြာခဏ အတက်အကျများ။
- curves များသည် မြင့်မားသော variance သို့မဟုတ် မတည်ငြိမ်မှုကို ပြသသည်။
- စွမ်းဆောင်ရည်သည် ရှင်းလင်းသော trend မရှိဘဲ လှုပ်ရှားနေသည်။

training နှင့် validation curves နှစ်ခုလုံးသည် erratic အပြုအမူကို ပြသသည်။

![Erratic Learning Curves](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter3/9.png)

**Erratic curves များအတွက် ဖြေရှင်းနည်းများ:**
- **Learning rate ကို လျှော့ချပါ**: ပိုမိုတည်ငြိမ်သော training အတွက် step size ကို လျှော့ချပါ။
- **Batch size တိုးမြှင့်ပါ**: ပိုကြီးမားသော batches များက ပိုမိုတည်ငြိမ်သော gradients များကို ပေးစွမ်းသည်။
- **Gradient clipping**: exploding gradients များကို ကာကွယ်ပါ။
- **ပိုမိုကောင်းမွန်သော ဒေတာ preprocessing**: တသမတ်တည်းသော ဒေတာအရည်အသွေးကို သေချာပါစေ။

အောက်ပါ ဥပမာတွင် ကျွန်ုပ်တို့သည် learning rate ကို လျှော့ချပြီး batch size ကို တိုးမြှင့်သည်။

```python
from transformers import TrainingArguments

training_args = TrainingArguments(
    output_dir="./results",
    -learning_rate=1e-5,
    +learning_rate=1e-4,
    -per_device_train_batch_size=16,
    +per_device_train_batch_size=32,
)
```

## အဓိက အချက်များ[[key-takeaways]]

learning curves များကို နားလည်ခြင်းသည် ထိရောက်သော machine learning practitioner တစ်ဦးဖြစ်လာရန် အရေးကြီးသည်။ ဤမြင်သာသော ကိရိယာများသည် သင်၏ model ၏ training လုပ်ဆောင်မှုတိုးတက်မှုအကြောင်း ချက်ချင်း တုံ့ပြန်ချက်ပေးပြီး training ကို ရပ်တန့်ရမည့်အချိန်၊ hyperparameters များကို ချိန်ညှိရမည့်အချိန် သို့မဟုတ် မတူညီသော နည်းလမ်းများကို စမ်းသပ်ရမည့်အချိန်တို့နှင့် ပတ်သက်၍ အသိဉာဏ်ရှိသော ဆုံးဖြတ်ချက်များ ချမှတ်ရာတွင် ကူညီပေးသည်။ လေ့ကျင့်မှုဖြင့် သင်သည် ကောင်းမွန်သော learning curves များ မည်သို့ရှိသည်ကို အလိုလို နားလည်လာပြီး ပြဿနာများ ပေါ်ပေါက်လာသောအခါ ၎င်းတို့ကို မည်သို့ဖြေရှင်းရမည်ကို သိရှိလာမည်။

> [!TIP]
> 💡 **အဓိက အချက်များ:**
> - Learning curves များသည် model training progress ကို နားလည်ရန် မရှိမဖြစ်လိုအပ်သော ကိရိယာများဖြစ်သည်။
> - loss နှင့် accuracy curves နှစ်ခုလုံးကို စောင့်ကြည့်ပါ၊ သို့သော် ၎င်းတို့တွင် မတူညီသော ဝိသေသလက္ခဏာများ ရှိသည်ကို သတိရပါ။
> - Overfitting သည် ကွဲပြားသော training/validation စွမ်းဆောင်ရည်အဖြစ် ပေါ်လာသည်။
> - Underfitting သည် training နှင့် validation data နှစ်ခုလုံးတွင် စွမ်းဆောင်ရည် ညံ့ဖျင်းခြင်းအဖြစ် ပေါ်လာသည်။
> - Weights & Biases ကဲ့သို့သော ကိရိယာများသည် learning curves များကို မှတ်တမ်းတင်ရန်နှင့် ဆန်းစစ်ရန် လွယ်ကူစေသည်။
> - Early stopping နှင့် မှန်ကန်သော regularization တို့သည် အဖြစ်များသော training ပြဿနာအများစုကို ဖြေရှင်းနိုင်သည်။
>
> 🔬 **နောက်တစ်ဆင့်များ**: သင်၏ကိုယ်ပိုင် fine-tuning စမ်းသပ်မှုများတွင် learning curves များကို ဆန်းစစ်ခြင်းကို လေ့ကျင့်ပါ။ မတူညီသော hyperparameters များကို စမ်းသပ်ပြီး ၎င်းတို့က curve shapes များကို မည်သို့သက်ရောက်သည်ကို လေ့လာပါ။ ဤလက်တွေ့အတွေ့အကြုံသည် training progress ကို ဖတ်ရှုရန်အတွက် အလိုလိုသိနိုင်စွမ်းကို မြှင့်တင်ပေးမည့် အကောင်းဆုံးနည်းလမ်းဖြစ်သည်။

## အခန်း၏ ဗဟုသုတစစ်ဆေးခြင်း[[section-quiz]]

learning curves နှင့် training analysis concepts များအကြောင်း သင့်နားလည်မှုကို စမ်းသပ်ပါ။

### 1. Training loss လျော့နည်းနေသော်လည်း validation loss တိုးလာပါက အများအားဖြင့် ဘာကို ဆိုလိုသလဲ။

<Question
	choices={[
		{
			text: "Model သည် အောင်မြင်စွာ သင်ယူနေပြီး ဆက်လက်တိုးတက်လိမ့်မည်။",
			explain: "validation loss တိုးလာနေပြီး training loss လျော့နည်းနေပါက၊ ၎င်းသည် ပြဿနာတစ်ခုကို ညွှန်ပြပြီး အောင်မြင်မှုကို မဟုတ်ပါ။"
		},
		{
			text: "Model သည် training data ကို overfitting ဖြစ်နေသည်။",
			explain: "မှန်ပါသည်။ ၎င်းသည် overfitting ၏ ပုံမှန်လက္ခဏာတစ်ခုဖြစ်သည် - model သည် training data ပေါ်တွင် ကောင်းစွာလုပ်ဆောင်သော်လည်း မမြင်ရသေးသော validation data ပေါ်တွင် ညံ့ဖျင်းသည်။",
            correct: true
		},
		{
			text: "Learning rate သည် အလွန်နည်းပါးသည်။",
			explain: "Learning rate နိမ့်ကျခြင်းက သင်ယူမှု နှေးကွေးစေမည်ဖြစ်ပြီး training နှင့် validation စွမ်းဆောင်ရည် ကွဲပြားခြင်းကို ဖြစ်စေမည်မဟုတ်ပါ။"
		},
        {
			text: "Dataset သည် အလွန်သေးငယ်သည်။",
			explain: "သေးငယ်သော datasets များသည် overfitting ကို အထောက်အကူပြုနိုင်သော်လည်း၊ ဤသီးခြားပုံစံသည် dataset size မည်သို့ပင်ဖြစ်စေ overfitting ၏ အဓိပ္ပာယ်ဖွင့်ဆိုချက်ဖြစ်သည်။"
		}
	]}
/>

### 2. Accuracy curves များသည် ချောမွေ့စွာ တိုးတက်ခြင်းထက် "steppy" သို့မဟုတ် plateau-like ပုံစံကို ဘာကြောင့် ပြလေ့ရှိသလဲ။

<Question
	choices={[
		{
			text: "accuracy တွက်ချက်မှုတွင် အမှားတစ်ခု ရှိနေသည်။",
			explain: "steppy ပုံစံသည် ပုံမှန်ဖြစ်ပြီး မျှော်လင့်ထားသည့်အတိုင်းဖြစ်ပြီး အမှားတစ်ခု မဟုတ်ပါ။"
		},
		{
			text: "Accuracy သည် discrete metric တစ်ခုဖြစ်ပြီး predictions များ decision boundaries ကို ကျော်လွန်မှသာ ပြောင်းလဲသည်။",
			explain: "မှန်ပါသည်။ Loss နှင့်မတူဘဲ၊ accuracy သည် discrete prediction decisions များပေါ်တွင် မူတည်သောကြောင့်၊ confidence တွင် သေးငယ်သော တိုးတက်မှုများသည် threshold ကို ကျော်လွန်သည်အထိ နောက်ဆုံး accuracy ကို ပြောင်းလဲနိုင်ခြင်းမရှိပါ။",
            correct: true
		},
		{
			text: "Model သည် ထိရောက်စွာ သင်ယူခြင်း မရှိပါ။",
			explain: "Model က ကောင်းစွာ သင်ယူနေသည့်အခါ၌ပင် steppy accuracy curves များသည် ပုံမှန်ဖြစ်သည်။"
		},
        {
			text: "Batch size သည် အလွန်သေးငယ်သည်။",
			explain: "Batch size သည် training stability ကို ထိခိုက်စေသော်လည်း accuracy metrics ၏ မူလ discrete သဘာဝကို မရှင်းပြပါ။"
		}
	]}
/>

### 3. Erratic, အလွန်အတက်အကျများသော learning curves များကို တွေ့ရှိသောအခါ အကောင်းဆုံးနည်းလမ်းက ဘာလဲ။

<Question
	choices={[
		{
			text: "Convergence ကို အရှိန်မြှင့်ရန် learning rate ကို တိုးမြှင့်ပါ။",
			explain: "Learning rate တိုးမြှင့်ခြင်းသည် အတက်အကျများကို ပိုမိုဆိုးရွားစေနိုင်သည်။"
		},
		{
			text: "Learning rate ကို လျှော့ချပြီး ဖြစ်နိုင်လျှင် batch size ကို တိုးမြှင့်ပါ။",
			explain: "မှန်ပါသည်။ Learning rates နည်းပါးခြင်းနှင့် batch sizes ကြီးမားခြင်းတို့သည် ပိုမိုတည်ငြိမ်သော training ကို ဖြစ်ပေါ်စေသည်။",
            correct: true
		},
		{
			text: "Model သည် တိုးတက်တော့မည်မဟုတ်သောကြောင့် training ကို ချက်ချင်းရပ်တန့်ပါ။",
			explain: "Erratic curves များကို hyperparameter ချိန်ညှိမှုများဖြင့် မကြာခဏ ပြုပြင်နိုင်သည်။"
		},
        {
			text: "လုံးဝ မတူညီသော model architecture သို့ ပြောင်းလဲပါ။",
			explain: "ဒါက စောသေးသည် - erratic curves များကို များသောအားဖြင့် hyperparameter tuning ဖြင့် ပြုပြင်နိုင်သည်။"
		}
	]}
/>

### 4. Early stopping ကို ဘယ်အချိန်မှာ အသုံးပြုရန် စဉ်းစားသင့်သလဲ။

<Question
	choices={[
		{
			text: "အမြဲတမ်း၊ ၎င်းသည် မည်သည့် overfitting ပုံစံကိုမဆို ကာကွယ်သောကြောင့်။",
			explain: "Early stopping သည် အသုံးဝင်သော်လည်း အမြဲတမ်း မလိုအပ်ပါ၊ အထူးသဖြင့် အခြား regularization နည်းလမ်းများ အလုပ်လုပ်နေပါက။"
		},
		{
			text: "Validation စွမ်းဆောင်ရည် မတိုးတက်တော့သည့်အခါ သို့မဟုတ် စတင်ကျဆင်းသည့်အခါ။",
			explain: "မှန်ပါသည်။ Early stopping သည် model သည် ပိုမိုကောင်းမွန်စွာ generalization မလုပ်နိုင်တော့သည့်အခါ training ကို ရပ်တန့်စေခြင်းဖြင့် overfitting ကို ကာကွယ်ရန် ကူညီပေးသည်။",
            correct: true
		},
		{
			text: "Training loss သည် အရှိန်အဟုန်ဖြင့် လျော့နည်းနေဆဲဖြစ်သည့်အခါမှသာ။",
			explain: "Training loss သည် အရှိန်အဟုန်ဖြင့် လျော့နည်းနေပြီး validation စွမ်းဆောင်ရည် ကောင်းမွန်ပါက၊ သင်သည် training ကို ဆက်လက်လုပ်ဆောင်လိုပေမည်။"
		},
        {
			text: "ဘယ်တော့မှ မသုံးပါနှင့်၊ ၎င်းသည် model ၏ အလားအလာ အပြည့်အဝကို မရောက်ရှိစေရန် တားဆီးသောကြောင့်။",
			explain: "Early stopping သည် overfitting ကို ကာကွယ်ခြင်းဖြင့် နောက်ဆုံး model စွမ်းဆောင်ရည်ကို မကြာခဏ တိုးတက်စေသည့် တန်ဖိုးရှိသော နည်းလမ်းတစ်ခုဖြစ်သည်။"
		}
	]}
/>

### 5. သင့် model သည် underfitting ဖြစ်နေကြောင်း ဘာက ညွှန်ပြသလဲ။

<Question
	choices={[
		{
			text: "Training accuracy သည် validation accuracy ထက် များစွာ မြင့်မားသည်။",
			explain: "ဒါက overfitting ကို ဖော်ပြတာဖြစ်ပြီး underfitting မဟုတ်ပါဘူး။"
		},
		{
			text: "Training နှင့် validation စွမ်းဆောင်ရည် နှစ်ခုလုံး ညံ့ဖျင်းပြီး စောစီးစွာ plateau ဖြစ်သည်။",
			explain: "မှန်ပါသည်။ Underfitting သည် model သည် ပုံစံများကို သင်ယူရန် စွမ်းဆောင်ရည် မရှိသောအခါ ဖြစ်ပေါ်ပြီး training နှင့် validation data နှစ်ခုလုံးတွင် စွမ်းဆောင်ရည် ညံ့ဖျင်းစေသည်။",
            correct: true
		},
		{
			text: "Learning curves များသည် အလွန်ချောမွေ့ပြီး အတက်အကျ မရှိပါ။",
			explain: "ချောမွေ့သော curves များသည် ယေဘုယျအားဖြင့် ကောင်းမွန်ပြီး underfitting ကို ညွှန်ပြခြင်း မရှိပါ။"
		},
        {
			text: "Validation loss သည် training loss ထက် ပိုမိုမြန်ဆန်စွာ လျော့နည်းနေသည်။",
			explain: "ဒါက တကယ်တမ်း ကောင်းမွန်တဲ့ လက္ခဏာတစ်ခုဖြစ်ပြီး ပြဿနာ မဟုတ်ပါဘူး။"
		}
	]}
/>

> [!TIP]
> 💡 **အဓိက အချက်များ:**
> - Learning curves များသည် model training progress ကို နားလည်ရန် မရှိမဖြစ်လိုအပ်သော ကိရိယာများဖြစ်သည်။
> - loss နှင့် accuracy curves နှစ်ခုလုံးကို စောင့်ကြည့်ပါ၊ သို့သော် ၎င်းတို့တွင် မတူညီသော ဝိသေသလက္ခဏာများ ရှိသည်ကို သတိရပါ။
> - Overfitting သည် ကွဲပြားသော training/validation စွမ်းဆောင်ရည်အဖြစ် ပေါ်လာသည်။
> - Underfitting သည် training နှင့် validation data နှစ်ခုလုံးတွင် စွမ်းဆောင်ရည် ညံ့ဖျင်းခြင်းအဖြစ် ပေါ်လာသည်။
> - Weights & Biases ကဲ့သို့သော ကိရိယာများသည် learning curves များကို မှတ်တမ်းတင်ရန်နှင့် ဆန်းစစ်ရန် လွယ်ကူစေသည်။
> - Early stopping နှင့် မှန်ကန်သော regularization တို့သည် အဖြစ်များသော training ပြဿနာအများစုကို ဖြေရှင်းနိုင်သည်။
>
> 🔬 **နောက်တစ်ဆင့်များ**: သင်၏ကိုယ်ပိုင် fine-tuning စမ်းသပ်မှုများတွင် learning curves များကို ဆန်းစစ်ခြင်းကို လေ့ကျင့်ပါ။ မတူညီသော hyperparameters များကို စမ်းသပ်ပြီး ၎င်းတို့က curve shapes များကို မည်သို့သက်ရောက်သည်ကို လေ့လာပါ။ ဤလက်တွေ့အတွေ့အကြုံသည် training progress ကို ဖတ်ရှုရန်အတွက် အလိုလိုသိနိုင်စွမ်းကို မြှင့်တင်ပေးမည့် အကောင်းဆုံးနည်းလမ်းဖြစ်သည်။

## ဝေါဟာရ ရှင်းလင်းချက် (Glossary)

*   **Fine-tuning**: ကြိုတင်လေ့ကျင့်ထားပြီးသား (pre-trained) မော်ဒယ်တစ်ခုကို သီးခြားလုပ်ငန်းတစ်ခု (specific task) အတွက် အနည်းငယ်သော ဒေတာနဲ့ ထပ်မံလေ့ကျင့်ပေးခြင်းကို ဆိုလိုပါတယ်။
*   **Trainer API (Application Programming Interface)**: Hugging Face Transformers library မှ model များကို ထိရောက်စွာ လေ့ကျင့်ရန်အတွက် ဒီဇိုင်းထုတ်ထားသော မြင့်မားသောအဆင့် (high-level) API။
*   **Custom Training Loops**: Trainer API ကဲ့သို့သော abstractions များကို အသုံးမပြုဘဲ PyTorch library ၏ အခြေခံလုပ်ဆောင်ချက်များဖြင့် model ကို လေ့ကျင့်ရန် code ကို ကိုယ်တိုင်ရေးသားခြင်း။
*   **Learning Curves**: Training လုပ်နေစဉ် model ၏ performance metrics (ဥပမာ- loss, accuracy) များကို အချိန်နှင့်အမျှ ပုံဖြင့်ပြသထားခြင်း။
*   **Performance Metrics**: Model ၏ စွမ်းဆောင်ရည်ကို တိုင်းတာရန် အသုံးပြုသော တန်ဖိုးများ (ဥပမာ- accuracy, F1 score)။
*   **Loss Curves**: Training steps သို့မဟုတ် epochs များတစ်လျှောက် model ၏ error (loss) မည်သို့ပြောင်းလဲသည်ကို ပြသသော learning curve။
*   **Accuracy Curves**: Training steps သို့မဟုတ် epochs များတစ်လျှောက် မှန်ကန်သော ခန့်မှန်းချက်များ၏ ရာခိုင်နှုန်းကို ပြသသော learning curve။
*   **Training Steps**: training batch တစ်ခုစီကို လုပ်ဆောင်ခြင်း။
*   **Epochs**: dataset တစ်ခုလုံးကို model တစ်ခုက အစအဆုံး တစ်ကြိမ် လေ့ကျင့်မှု ပြီးဆုံးခြင်း။
*   **Weights & Biases (wandb)**: Machine learning စမ်းသပ်မှုများကို မှတ်တမ်းတင်ရန်၊ မြင်သာအောင် ပြုလုပ်ရန်နှင့် မျှဝေရန်အတွက် ကိရိယာများကို ပံ့ပိုးပေးသော platform။
*   **Loss**: Model ၏ ခန့်မှန်းချက်များနှင့် အမှန်တကယ် labels များကြား ကွာခြားမှုကို တိုင်းတာသော တန်ဖိုး (error)။
*   **Optimization**: Model ၏ parameters များကို ချိန်ညှိခြင်းဖြင့် loss ကို လျှော့ချပြီး စွမ်းဆောင်ရည်ကို မြှင့်တင်ခြင်း။
*   **Convergence**: Training လုပ်နေစဉ် model ၏ performance metrics များ (loss, accuracy) တည်ငြိမ်လာပြီး ထပ်မံတိုးတက်ခြင်းမရှိတော့သည့် အခြေအနေ။
*   **Dashboard**: အချက်အလက်များကို မြင်သာသော ပုံစံဖြင့် စုစည်းပြသထားသည့် user interface။
*   **`wandb.init()` Function**: Weights & Biases ကို initialize လုပ်ပြီး စမ်းသပ်မှု မှတ်တမ်းတင်ခြင်းကို စတင်ရန် function။
*   **`project` (wandb argument)**: Weights & Biases တွင် စမ်းသပ်မှုများ စုစည်းထားသည့် project အမည်။
*   **`name` (wandb argument)**: Weights & Biases တွင် လက်ရှိ training run အတွက် ပေးသော အမည်။
*   **`TrainingArguments` Class**: Trainer ကို အသုံးပြု၍ မော်ဒယ်လေ့ကျင့်ရာတွင် လိုအပ်သော hyperparameters များနှင့် အခြားအခြေအနေများကို သတ်မှတ်ရန် အသုံးပြုသည့် class။
*   **`output_dir`**: လေ့ကျင့်ပြီးသား model နှင့် checkpoints များကို သိမ်းဆည်းမည့် directory။
*   **`eval_strategy="steps"`**: Training steps အရေအတွက်အလိုက် evaluation လုပ်ရန် သတ်မှတ်သော `eval_strategy` option။
*   **`eval_steps`**: evaluation လုပ်ငန်းကို ပြန်လုပ်မည့် training steps အရေအတွက်။
*   **`save_steps`**: Model checkpoints များကို သိမ်းဆည်းမည့် steps အရေအတွက်။
*   **`logging_steps`**: Metrics များကို log လုပ်မည့် steps အရေအတွက်။
*   **`num_train_epochs`**: Training လုပ်မည့် epochs အရေအတွက်။
*   **`per_device_train_batch_size`**: device တစ်ခုစီ (ဥပမာ- GPU တစ်ခုစီ) အတွက် training batch size။
*   **`per_device_eval_batch_size`**: device တစ်ခုစီ (ဥပမာ- GPU တစ်ခုစီ) အတွက် evaluation batch size။
*   **`report_to="wandb"`**: Logs များကို Weights & Biases သို့ ပို့ရန် သတ်မှတ်သော parameter။
*   **`model` (Trainer argument)**: Trainer ကို ပေးအပ်သော model object။
*   **`args` (Trainer argument)**: Trainer ကို ပေးအပ်သော `TrainingArguments` object။
*   **`train_dataset`**: Trainer ကို ပေးအပ်သော training set။
*   **`eval_dataset`**: Trainer ကို ပေးအပ်သော validation set။
*   **`data_collator`**: batch တစ်ခုအတွင်း samples များကို စုစည်းပေးသော function။
*   **`processing_class`**: Trainer ကို ဒေတာ processing အတွက် မည်သည့် tokenizer ကို အသုံးပြုရမည်ကို ပြောပြပေးသော parameter။
*   **`compute_metrics`**: evaluation လုပ်ငန်းစဉ်အတွင်း metrics (ဥပမာ- accuracy, F1 score) များကို တွက်ချက်ရန်အတွက် Trainer ကို ပေးအပ်သော function။
*   **Plateaus**: Learning curves များတွင် စွမ်းဆောင်ရည် တိုးတက်မှု ရပ်တန့်သွားသော ညီညာသည့် အပိုင်း။
*   **Discrete Predictions**: Model ၏ output များကို ပြတ်သားသော အမျိုးအစားများအဖြစ် ပြောင်းလဲခြင်း (ဥပမာ- 0 သို့မဟုတ် 1)။
*   **Threshold**: Discrete prediction ပြုလုပ်ရန်အတွက် ကျော်လွန်ရမည့် တန်ဖိုး။
*   **Binary Classifier**: ဒေတာများကို အမျိုးအစားနှစ်မျိုးအဖြစ် ခွဲခြားပေးသော model။
*   **Overfitting**: Model သည် training data မှ အလွန်အမင်း သင်ယူပြီး မမြင်ရသေးသော data (validation set) ပေါ်တွင် စွမ်းဆောင်ရည် ကျဆင်းခြင်း။
*   **Generalize (Generalization)**: Model သည် သင်ယူထားသော ပုံစံများကို မမြင်ရသေးသော ဒေတာအသစ်များပေါ်တွင် ကောင်းစွာ အသုံးချနိုင်စွမ်း။
*   **Regularization**: Model ၏ ရှုပ်ထွေးမှုကို လျှော့ချခြင်းဖြင့် overfitting ကို ကာကွယ်သော နည်းလမ်းများ (ဥပမာ- dropout, weight decay)။
    *   **Dropout**: Neural network layers များတွင် neurons အချို့ကို ကျပန်း (randomly) ပိတ်ထားခြင်းဖြင့် overfitting ကို လျှော့ချသော နည်းလမ်း။
    *   **Weight Decay**: Model ၏ weights များကို သေးငယ်အောင် ထိန်းညှိခြင်းဖြင့် overfitting ကို လျှော့ချသော နည်းလမ်း။
*   **Early Stopping**: Validation performance မတိုးတက်တော့သည့်အခါ training ကို ရပ်တန့်ခြင်း။
*   **Data Augmentation**: training data ကို ပြောင်းလဲခြင်း (ဥပမာ- ရုပ်ပုံများကို လှည့်ခြင်း၊ စာသားများကို ပြန်ရေးခြင်း) ဖြင့် ၎င်း၏ ကွဲပြားမှုကို တိုးမြှင့်ခြင်း။
*   **Model Complexity**: Model ၏ ရှုပ်ထွေးမှုပမာဏ (ဥပမာ- layers အရေအတွက်၊ parameters အရေအတွက်)။
*   **`EarlyStoppingCallback`**: `Trainer` တွင် early stopping feature ကို ထည့်သွင်းရန် အသုံးပြုသော callback။
*   **`early_stopping_patience`**: validation performance မတိုးတက်ဘဲ training ဆက်လုပ်မည့် epochs အရေအတွက်။
*   **`save_strategy`**: Model checkpoints များကို မည်သို့ သိမ်းဆည်းရမည်ကို သတ်မှတ်သော strategy (ဥပမာ- `"steps"`)။
*   **`load_best_model_at_end=True`**: Training ပြီးဆုံးသောအခါ အကောင်းဆုံး validation performance ရှိသော model ကို load လုပ်ရန် သတ်မှတ်သော parameter။
*   **`metric_for_best_model="eval_loss"`**: အကောင်းဆုံး model ကို ဆုံးဖြတ်ရန်အတွက် အသုံးပြုမည့် metric (ဤနေရာတွင် evaluation loss)။
*   **`greater_is_better=False`**: `metric_for_best_model` အတွက် ပိုကြီးသော တန်ဖိုးသည် ပိုကောင်းသည် (True) သို့မဟုတ် ပိုသေးငယ်သော တန်ဖိုးသည် ပိုကောင်းသည် (False) ကို သတ်မှတ်ခြင်း။
*   **Underfitting**: Model သည် training data ရှိ အခြေခံပုံစံများကို သင်ယူရန် အလွန်ရိုးရှင်းလွန်းသောကြောင့် training နှင့် validation data နှစ်ခုလုံးတွင် စွမ်းဆောင်ရည် ညံ့ဖျင်းခြင်း။
*   **Model Capacity**: Model ၏ သင်ယူနိုင်စွမ်း သို့မဟုတ် ရှုပ်ထွေးသော ပုံစံများကို ဖမ်းယူနိုင်စွမ်း။
*   **Learning Rate**: Training လုပ်နေစဉ် model ၏ weights များကို update လုပ်ရာတွင် အသုံးပြုသော step size။
*   **Erratic Learning Curves**: Model သည် ထိရောက်စွာ သင်ယူခြင်းမရှိဘဲ performance metrics များ မကြာခဏ အတက်အကျရှိနေသော learning curve ပုံစံ။
*   **Fluctuations**: တန်ဖိုးများ၏ အတက်အကျ သို့မဟုတ် မတည်ငြိမ်မှု။
*   **Variance**: ဒေတာအမှတ်များ၏ ပျံ့နှံ့မှုပမာဏ။
*   **Stability**: စွမ်းဆောင်ရည်၏ တည်ငြိမ်မှု သို့မဟုတ် ပြောင်းလဲမှု နည်းပါးခြင်း။
*   **Gradient Clipping**: Gradients များ၏ တန်ဖိုးကို ကန့်သတ်ခြင်းဖြင့် gradient exploding ပြဿနာကို ကာကွယ်သော နည်းလမ်း။
*   **Batch Size**: batch တစ်ခုစီတွင် ပါဝင်မည့် samples အရေအတွက်။
*   **Gradients**: Model ၏ loss function ကို လျှော့ချရန်အတွက် model ၏ weights များကို မည်သည့်လမ်းကြောင်းသို့ ချိန်ညှိရမည်ကို ညွှန်ပြသော တန်ဖိုးများ။