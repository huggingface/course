# အခြေခံ အသုံးပြုမှု ပြီးဆုံးပါပြီ![[basic-usage-completed]]

<CourseFloatingBanner
    chapter={2}
    classNames="absolute z-10 right-0 top-0"
/>

ဒီသင်တန်းကို ဒီအထိ လိုက်ပါခဲ့တဲ့အတွက် ဂုဏ်ယူပါတယ်။ အနှစ်ချုပ်အနေနဲ့၊ ဒီအခန်းမှာ သင်ဟာ အောက်ပါတို့ကို သင်ယူခဲ့ပါပြီ -

-   Transformer model တစ်ခု၏ အခြေခံတည်ဆောက်ပုံများကို သင်ယူခဲ့သည်။
-   tokenization pipeline ကို ဘာတွေနဲ့ ဖွဲ့စည်းထားတယ်ဆိုတာ သိရှိခဲ့သည်။
-   လက်တွေ့မှာ Transformer model တစ်ခုကို ဘယ်လိုအသုံးပြုရမယ်ဆိုတာကို တွေ့ခဲ့ရသည်။
-   tokenizer ကို အသုံးပြုပြီး text ကို model က နားလည်နိုင်တဲ့ tensors တွေအဖြစ် ဘယ်လိုပြောင်းလဲရမယ်ဆိုတာကို သင်ယူခဲ့သည်။
-   text ကနေ predictions တွေရဖို့ tokenizer နဲ့ model ကို အတူတကွ တည်ဆောက်ခဲ့သည်။
-   input IDs တွေရဲ့ ကန့်သတ်ချက်များကို သင်ယူခဲ့ပြီး attention masks တွေအကြောင်း သိရှိခဲ့သည်။
-   အသုံးဝင်ပြီး စိတ်ကြိုက်ပြင်ဆင်နိုင်သော tokenizer methods များနှင့် ကစားကြည့်ခဲ့သည်။

အခုကစပြီး သင်ဟာ 🤗 Transformers docs တွေထဲမှာ လွတ်လပ်စွာ သွားလာနိုင်ပါလိမ့်မယ်၊ Vocabulary တွေက ရင်းနှီးလာမှာဖြစ်ပြီး၊ သင် အချိန်အများစု အသုံးပြုရမယ့် methods တွေကိုလည်း သင် မြင်တွေ့ခဲ့ရပါပြီ။

## ဝေါဟာရ ရှင်းလင်းချက် (Glossary)

*   **Transformer Model**: Natural Language Processing (NLP) မှာ အောင်မြင်မှုများစွာရရှိခဲ့တဲ့ deep learning architecture တစ်မျိုးပါ။ ၎င်းတို့ဟာ စာသားတွေထဲက စကားလုံးတွေရဲ့ ဆက်နွယ်မှုတွေကို "attention mechanism" သုံးပြီး နားလည်အောင် သင်ကြားပေးပါတယ်။
*   **Tokenization Pipeline**: စာသားကို AI မော်ဒယ်များ လုပ်ဆောင်နိုင်သော ဂဏန်းဆိုင်ရာ ကိုယ်စားပြုမှုအဖြစ် ပြောင်းလဲရန် လိုအပ်သော အဆင့်များ (ဥပမာ- tokenization, input IDs conversion, padding, truncation)။
*   **Tokenizer**: စာသား (သို့မဟုတ် အခြားဒေတာ) ကို AI မော်ဒယ်များ စီမံဆောင်ရွက်နိုင်ရန် tokens တွေအဖြစ် ပိုင်းခြားပေးသည့် ကိရိယာ သို့မဟုတ် လုပ်ငန်းစဉ်။
*   **Text**: လူသားဘာသာစကားဖြင့် ရေးသားထားသော စာသားအချက်အလက်များ။
*   **Tensors**: Machine Learning frameworks (PyTorch, TensorFlow) များတွင် ဒေတာများကို ကိုယ်စားပြုသော multi-dimensional array များ။
*   **Predictions**: Machine Learning မော်ဒယ်တစ်ခုက input data ကို အခြေခံပြီး ခန့်မှန်းထုတ်ပေးသော ရလဒ်များ။
*   **Input IDs**: Tokenizer မှ ထုတ်ပေးသော tokens တစ်ခုစီ၏ ထူးခြားသော ဂဏန်းဆိုင်ရာ ID များ။
*   **Attention Masks**: မော်ဒယ်ကို အာရုံစိုက်သင့်သည့် tokens များနှင့် လျစ်လျူရှုသင့်သည့် (padding) tokens များကို ခွဲခြားပေးသည့် binary mask။
*   **Configurable Tokenizer Methods**: အသုံးပြုသူ၏ လိုအပ်ချက်များအတိုင်း ပြင်ဆင်သတ်မှတ်နိုင်သော tokenizer functions များ။
*   **🤗 Transformers Docs**: Hugging Face Transformers library ၏ တရားဝင် မှတ်တမ်းများ (documentation)။
*   **Vocabulary**: tokenizer သို့မဟုတ် model တစ်ခုက သိရှိနားလည်ပြီး ကိုင်တွယ်နိုင်သော ထူးခြားသည့် tokens များ စုစုပေါင်း။