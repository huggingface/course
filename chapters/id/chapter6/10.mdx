<!-- DISABLE-FRONTMATTER-SECTIONS -->

# Kuis akhir bab[[end-of-chapter-quiz]]

<CourseFloatingBanner
    chapter={6}
    classNames="absolute z-10 right-0 top-0"
/>

Ayo uji apa yang telah kamu pelajari di bab ini!

### 1. Kapan kamu sebaiknya melatih tokenizer baru?

<Question
	choices={[
		{
			text: "Ketika dataset-mu mirip dengan dataset yang digunakan oleh model pralatih yang ada, dan kamu ingin melakukan pretraining model baru",
			explain: "Dalam kasus ini, untuk menghemat waktu dan sumber daya komputasi, pilihan yang lebih baik adalah menggunakan tokenizer yang sama dengan model pralatih dan melakukan fine-tuning saja."
		},
		{
			text: "Ketika dataset-mu mirip dengan dataset yang digunakan oleh model pralatih yang ada, dan kamu ingin melakukan fine-tune model baru menggunakan model pralatih ini",
			explain: "Untuk fine-tune model dari model pralatih, kamu sebaiknya selalu menggunakan tokenizer yang sama."
		},
		{
			text: "Ketika dataset-mu berbeda dari dataset yang digunakan oleh model pralatih yang ada, dan kamu ingin melakukan pretraining model baru",
			explain: "Benar! Dalam kasus ini, tidak ada keuntungan menggunakan tokenizer yang sama.",
            correct: true
		},
        {
			text: "Ketika dataset-mu berbeda dari dataset yang digunakan oleh model pralatih yang ada, tetapi kamu ingin melakukan fine-tune model baru menggunakan model pralatih ini",
			explain: "Untuk fine-tune model dari model pralatih, kamu sebaiknya selalu menggunakan tokenizer yang sama."
		}
	]}
/>

### 2. Apa keuntungan menggunakan generator daftar teks dibandingkan dengan daftar daftar teks saat memakai `train_new_from_iterator()`?

<Question
	choices={[
		{
			text: "Itulah satu-satunya tipe yang diterima oleh metode <code>train_new_from_iterator()</code>.",
			explain: "Daftar dari daftar teks sebenarnya adalah bentuk khusus dari generator daftar teks, jadi metode ini tetap akan menerimanya. Coba lagi!"
		},
		{
			text: "Kamu akan menghindari memuat seluruh dataset ke dalam memori sekaligus.",
			explain: "Benar! Setiap batch teks akan dilepaskan dari memori setelah diproses, dan keuntungannya akan terlihat jelas jika kamu menggunakan ü§ó Datasets.",
			correct: true
		},
		{
			text: "Ini akan memungkinkan pustaka ü§ó Tokenizers untuk menggunakan multiprocessing.",
			explain: "Tidak, multiprocessing akan tetap digunakan tanpa tergantung pada itu."
		},
        {
			text: "Tokenizer yang kamu latih akan menghasilkan teks yang lebih baik.",
			explain: "Tokenizer tidak menghasilkan teks -- mungkin kamu sedang bingung dengan language model?"
		}
	]}
/>

### 3. Apa keuntungan menggunakan tokenizer ‚Äúfast‚Äù?

<Question
	choices={[
		{
			text: "Tokenizer ini dapat memproses input lebih cepat dibandingkan tokenizer lambat saat kamu memproses banyak input sekaligus.",
			explain: "Benar! Berkat paralelisme yang diimplementasikan dalam Rust, ini akan lebih cepat untuk batch input.",
			correct: true
		},
		{
			text: "Tokenizer cepat selalu lebih cepat daripada versi lambatnya.",
			explain: "Tokenizer cepat bisa jadi lebih lambat untuk teks tunggal karena tidak bisa memanfaatkan paralelisme."
		},
		{
			text: "Tokenizer ini dapat melakukan padding dan truncation.",
			explain: "Benar, tetapi tokenizer lambat juga bisa melakukan itu."
		},
        {
			text: "Tokenizer ini memiliki fitur tambahan yang memungkinkan kamu memetakan token ke bagian teks asalnya.",
			explain: "Ya -- ini disebut offset mapping. Tapi ini bukan satu-satunya keuntungannya.",
			correct: true
		}
	]}
/>

### 4. Bagaimana pipeline `token-classification` menangani entitas yang terdiri dari beberapa token?

<Question
	choices={[
		{
			text: "Entitas dengan label yang sama digabung menjadi satu entitas.",
			explain: "Itu terlalu menyederhanakan. Coba lagi!"
		},
		{
			text: "Ada label untuk awal entitas dan label untuk kelanjutan entitas.",
			explain: "Benar!",
			correct: true
		},
		{
			text: "Dalam satu kata, selama token pertama memiliki label entitas, seluruh kata dianggap memiliki entitas tersebut.",
			explain: "Itu salah satu strategi. Tapi ada jawaban lain juga yang benar.",
			correct: true
		},
        {
			text: "Ketika satu token memiliki label entitas, token-token setelahnya yang memiliki label sama dianggap bagian dari entitas tersebut, kecuali jika diberi label sebagai entitas baru.",
			explain: "Ini adalah cara paling umum mengelompokkan entitas -- ini juga jawaban yang benar.",
			correct: true
		}
	]}
/>

### 5. Bagaimana pipeline `question-answering` menangani konteks yang panjang?

<Question
	choices={[
		{
			text: "Pipeline ini tidak benar-benar menanganinya, hanya memotong konteks panjang hingga batas maksimum model.",
			explain: "Sebenarnya ada trik yang bisa dipakai untuk mengatasi konteks panjang. Ingat?"
		},
		{
			text: "Pipeline ini membagi konteks menjadi beberapa bagian dan mengambil rata-rata dari hasilnya.",
			explain: "Tidak masuk akal untuk merata-rata hasil, karena bisa jadi jawaban tidak ada di beberapa bagian konteks."
		},
		{
			text: "Pipeline ini membagi konteks menjadi beberapa bagian (dengan overlap) dan mengambil skor maksimum dari setiap bagian.",
			explain: "Itu jawaban yang benar!",
			correct: true
		},
        {
			text: "Pipeline ini membagi konteks menjadi beberapa bagian (tanpa overlap, demi efisiensi) dan mengambil skor maksimum dari setiap bagian.",
			explain: "Tidak, bagian-bagian tersebut diberi overlap untuk mencegah jawaban terpotong di antara dua bagian."
		}
	]}
/>

### 6. Apa itu normalisasi?

<Question
	choices={[
		{
			text: "Ini adalah proses pembersihan awal yang dilakukan tokenizer pada teks.",
			explain: "Benar -- misalnya, menghapus aksen, whitespace, atau mengubah huruf menjadi huruf kecil.",
			correct: true
		},
		{
			text: "Ini adalah teknik augmentasi data yang membuat teks lebih ‚Äònormal‚Äô dengan menghapus kata-kata langka.",
			explain: "Salah! Coba lagi."
		},
		{
			text: "Ini adalah langkah terakhir pasca-pemrosesan di mana tokenizer menambahkan token khusus.",
			explain: "Langkah itu disebut post-processing, bukan normalisasi."
		},
        {
			text: "Ini adalah saat embedding dibuat dengan rata-rata 0 dan deviasi standar 1.",
			explain: "Itu pengertian normalisasi dalam visi komputer, bukan NLP."
		}
	]}
/>

### 7. Apa itu pre-tokenization dalam subword tokenizer?

<Question
	choices={[
		{
			text: "Ini adalah tahap sebelum tokenisasi, di mana augmentasi data diterapkan.",
			explain: "Tidak, itu bagian dari preprocessing, bukan pre-tokenization."
		},
		{
			text: "Ini adalah tahap sebelum tokenisasi, di mana pembersihan dilakukan pada teks.",
			explain: "Itu adalah tahap normalisasi."
		},
		{
			text: "Ini adalah tahap sebelum model tokenizer digunakan, untuk memecah input menjadi kata-kata.",
			explain: "Benar!",
			correct: true
		},
        {
			text: "Ini adalah tahap sebelum model tokenizer digunakan, untuk memecah input menjadi token.",
			explain: "Tidak, memecah menjadi token adalah tugas model tokenizer."
		}
	]}
/>

### 8. Pilih pernyataan yang sesuai dengan model tokenisasi BPE.

<Question
	choices={[
		{
			text: "BPE adalah algoritma tokenisasi subword yang dimulai dengan kosakata kecil dan mempelajari aturan penggabungan.",
			explain: "Benar!",
			correct: true
		},
		{
			text: "BPE adalah algoritma tokenisasi subword yang dimulai dengan kosakata besar dan secara bertahap menghapus token.",
			explain: "Tidak, ini pendekatan algoritma lain."
		},
		{
			text: "Tokenizer BPE mempelajari aturan penggabungan dengan menggabungkan pasangan token yang paling sering muncul.",
			explain: "Benar!",
			correct: true
		},
		{
			text: "Tokenizer BPE mempelajari aturan penggabungan berdasarkan skor yang mengutamakan pasangan sering dengan bagian individual yang jarang.",
			explain: "Tidak, itu strategi algoritma lain."
		},
		{
			text: "BPE memecah kata menjadi karakter lalu menerapkan aturan penggabungan.",
			explain: "Benar!",
			correct: true
		},
		{
			text: "BPE memecah kata menjadi subword dengan mencari subword terpanjang dari awal yang ada di kosakata.",
			explain: "Tidak, itu strategi algoritma lain."
		},
	]}
/>

### 9. Pilih pernyataan yang sesuai dengan model tokenisasi WordPiece.

<Question
	choices={[
		{
			text: "WordPiece adalah algoritma tokenisasi subword yang dimulai dengan kosakata kecil dan mempelajari aturan penggabungan.",
			explain: "Benar!",
			correct: true
		},
		{
			text: "WordPiece adalah algoritma tokenisasi subword yang dimulai dengan kosakata besar dan menghapus token.",
			explain: "Tidak, itu strategi Unigram."
		},
		{
			text: "Tokenizer WordPiece menggabungkan pasangan token yang paling sering.",
			explain: "Tidak, itu strategi BPE."
		},
		{
			text: "Tokenizer WordPiece memilih pasangan token yang memaksimalkan skor berdasarkan frekuensi dan informasi tambahan.",
			explain: "Benar!",
			correct: true
		},
		{
			text: "WordPiece mencari segmentasi token yang paling mungkin menurut model.",
			explain: "Tidak, itu strategi Unigram.",
		},
		{
			text: "WordPiece memecah kata jadi subword dengan mencari subword terpanjang dari awal yang ada di kosakata, lalu mengulanginya untuk sisanya.",
			explain: "Benar!",
			correct: true
		},
	]}
/>

### 10. Pilih pernyataan yang sesuai dengan model tokenisasi Unigram.

<Question
	choices={[
		{
			text: "Unigram adalah algoritma tokenisasi subword yang dimulai dengan kosakata kecil dan mempelajari aturan penggabungan.",
			explain: "Tidak, itu pendekatan BPE dan WordPiece."
		},
		{
			text: "Unigram adalah algoritma tokenisasi subword yang dimulai dengan kosakata besar dan secara bertahap menghapus token.",
			explain: "Benar!",
			correct: true
		},
		{
			text: "Unigram menyesuaikan kosakatanya dengan meminimalkan loss yang dihitung dari seluruh korpus.",
			explain: "Benar!",
			correct: true
		},
		{
			text: "Unigram menyesuaikan kosakatanya dengan menyimpan subword yang paling sering.",
			explain: "Tidak, itu tidak sepenuhnya akurat."
		},
		{
			text: "Unigram memecah kata menjadi subword dengan mencari segmentasi paling mungkin menurut model.",
			explain: "Benar!",
			correct: true
		},
		{
			text: "Unigram memecah kata menjadi karakter lalu menerapkan aturan penggabungan.",
			explain: "Tidak, itu strategi BPE."
		},
	]}
/>
