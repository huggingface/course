<FrameworkSwitchCourse {fw} />

# Menggunakan Model yang Telah Dilatih[[using-pretrained-models]]

{#if fw === 'pt'}

<CourseFloatingBanner chapter={4}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter4/section2_pt.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter4/section2_pt.ipynb"},
]} />

{:else}

<CourseFloatingBanner chapter={4}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter4/section2_tf.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter4/section2_tf.ipynb"},
]} />

{/if}

Model Hub mempermudah pemilihan model yang sesuai, sehingga penggunaannya dalam pustaka mana pun dapat dilakukan hanya dengan beberapa baris kode. Mari kita lihat bagaimana cara menggunakan salah satu model ini, dan bagaimana cara berkontribusi kembali ke komunitas.

Misalnya kita sedang mencari model berbasis bahasa Prancis yang dapat melakukan pengisian topeng (mask filling).

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/camembert.gif" alt="Memilih model Camembert." width="80%"/>
</div>

Kita memilih checkpoint `camembert-base` untuk mencobanya. Identifier `camembert-base` adalah satu-satunya yang dibutuhkan untuk mulai menggunakannya! Seperti yang telah Anda lihat di bab sebelumnya, kita dapat menginstansiasinya menggunakan fungsi `pipeline()`:

```py
from transformers import pipeline

camembert_fill_mask = pipeline("fill-mask", model="camembert-base")
results = camembert_fill_mask("Le camembert est <mask> :)")
```

```python out
[
  {'sequence': 'Le camembert est délicieux :)', 'score': 0.49091005325317383, 'token': 7200, 'token_str': 'délicieux'}, 
  {'sequence': 'Le camembert est excellent :)', 'score': 0.1055697426199913, 'token': 2183, 'token_str': 'excellent'}, 
  {'sequence': 'Le camembert est succulent :)', 'score': 0.03453313186764717, 'token': 26202, 'token_str': 'succulent'}, 
  {'sequence': 'Le camembert est meilleur :)', 'score': 0.0330314114689827, 'token': 528, 'token_str': 'meilleur'}, 
  {'sequence': 'Le camembert est parfait :)', 'score': 0.03007650189101696, 'token': 1654, 'token_str': 'parfait'}
]
```

Seperti yang Anda lihat, memuat model ke dalam pipeline sangatlah mudah. Satu-satunya hal yang perlu diperhatikan adalah bahwa checkpoint yang dipilih cocok untuk tugas yang akan dijalankan. Misalnya, di sini kita memuat checkpoint `camembert-base` dalam pipeline `fill-mask`, yang sepenuhnya tepat. Namun jika kita memuat checkpoint ini dalam pipeline `text-classification`, hasilnya tidak akan masuk akal karena head dari `camembert-base` tidak cocok untuk tugas tersebut! Kami menyarankan untuk menggunakan pemilih tugas (task selector) pada antarmuka Hugging Face Hub untuk memilih checkpoint yang sesuai:

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/tasks.png" alt="Pemilih tugas pada antarmuka web." width="80%"/>
</div>

Anda juga dapat menginstansiasi checkpoint menggunakan arsitektur model secara langsung:

{#if fw === 'pt'}
```py
from transformers import CamembertTokenizer, CamembertForMaskedLM

tokenizer = CamembertTokenizer.from_pretrained("camembert-base")
model = CamembertForMaskedLM.from_pretrained("camembert-base")
```

Namun, kami menyarankan menggunakan [`Auto*` classes](https://huggingface.co/transformers/model_doc/auto?highlight=auto#auto-classes), karena kelas ini dirancang untuk tidak bergantung pada arsitektur tertentu. Sementara contoh kode sebelumnya membatasi pengguna pada checkpoint yang bisa dimuat dalam arsitektur CamemBERT, penggunaan `Auto*` classes membuat pergantian checkpoint menjadi lebih mudah:

```py
from transformers import AutoTokenizer, AutoModelForMaskedLM

tokenizer = AutoTokenizer.from_pretrained("camembert-base")
model = AutoModelForMaskedLM.from_pretrained("camembert-base")
```
{:else}
```py
from transformers import CamembertTokenizer, TFCamembertForMaskedLM

tokenizer = CamembertTokenizer.from_pretrained("camembert-base")
model = TFCamembertForMaskedLM.from_pretrained("camembert-base")
```

Namun, kami menyarankan menggunakan [`TFAuto*` classes](https://huggingface.co/transformers/model_doc/auto?highlight=auto#auto-classes), karena kelas ini dirancang untuk tidak bergantung pada arsitektur tertentu. Sementara contoh kode sebelumnya membatasi pengguna pada checkpoint yang bisa dimuat dalam arsitektur CamemBERT, penggunaan `TFAuto*` classes membuat pergantian checkpoint menjadi lebih mudah:

```py
from transformers import AutoTokenizer, TFAutoModelForMaskedLM

tokenizer = AutoTokenizer.from_pretrained("camembert-base")
model = TFAutoModelForMaskedLM.from_pretrained("camembert-base")
```
{/if}

<Tip>
Saat menggunakan model yang telah dilatih sebelumnya, pastikan untuk memeriksa bagaimana model tersebut dilatih, pada dataset apa, batasannya, dan biasnya. Semua informasi ini seharusnya tersedia di kartu model (model card)-nya.
</Tip>
