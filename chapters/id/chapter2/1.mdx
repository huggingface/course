# Pendahuluan[[introduction]]

<CourseFloatingBanner
    chapter={2}
    classNames="absolute z-10 right-0 top-0"
/>

Seperti yang telah Anda lihat di [Bab 1](/course/chapter1), model Transformer biasanya sangat besar. Dengan jutaan hingga *puluhan miliar* parameter, pelatihan dan penerapan model-model ini merupakan tugas yang rumit. Selain itu, dengan model-model baru yang dirilis hampir setiap hari dan masing-masing memiliki implementasi sendiri, mencoba semuanya bukanlah hal yang mudah.

Library ğŸ¤— Transformers dibuat untuk menyelesaikan masalah ini. Tujuannya adalah menyediakan satu API tunggal melalui mana model Transformer apa pun dapat dimuat, dilatih, dan disimpan. Fitur utama dari library ini adalah:

- **Mudah digunakan**: Mengunduh, memuat, dan menggunakan model NLP terkini untuk inferensi dapat dilakukan hanya dalam dua baris kode.
- **Fleksibel**: Pada dasarnya, semua model adalah kelas `nn.Module` PyTorch biasa dan dapat ditangani seperti model lain di framework machine learning (ML) masing-masing.
- **Sederhana**: Hampir tidak ada abstraksi yang dibuat di seluruh library. Konsep inti "Semua dalam satu file" diterapkan: proses forward dari suatu model sepenuhnya didefinisikan dalam satu file, sehingga kodenya dapat dipahami dan dimodifikasi.

Fitur terakhir ini membuat ğŸ¤— Transformers cukup berbeda dari library ML lainnya. Model-modelnya tidak dibangun berdasarkan modul yang dibagikan antar file; sebaliknya, setiap model memiliki layer-nya sendiri. Selain membuat model lebih mudah dipahami dan diakses, ini juga memungkinkan Anda untuk bereksperimen dengan satu model tanpa memengaruhi model lain.

Bab ini akan dimulai dengan contoh end-to-end di mana kita menggunakan model dan tokenizer bersama-sama untuk mereplikasi fungsi `pipeline()` yang diperkenalkan di [Bab 1](/course/chapter1). Selanjutnya, kita akan membahas API model: kita akan menyelami kelas model dan konfigurasi, serta menunjukkan cara memuat model dan bagaimana model memproses input numerik menjadi prediksi output.

Lalu kita akan melihat API tokenizer, yang merupakan komponen utama lain dari fungsi `pipeline()`. Tokenizer menangani langkah pemrosesan pertama dan terakhir, yaitu konversi dari teks ke input numerik untuk jaringan neural, dan konversi kembali ke teks saat dibutuhkan. Terakhir, kami akan menunjukkan cara mengirim beberapa kalimat melalui model dalam batch yang telah disiapkan, lalu menutupnya dengan melihat lebih dekat pada fungsi tingkat tinggi `tokenizer()`.

<Tip>
âš ï¸ Untuk mendapatkan semua fitur yang tersedia dengan Model Hub dan ğŸ¤— Transformers, kami menyarankan Anda <a href="https://huggingface.co/join">membuat akun</a>.
</Tip>
