<FrameworkSwitchCourse {fw} />

<!-- DISABLE-FRONTMATTER-SECTIONS -->

# Kuis Akhir Bab[[end-of-chapter-quiz]]

<CourseFloatingBanner
    chapter={2}
    classNames="absolute z-10 right-0 top-0"
/>

### 1. Apa urutan pipeline pemodelan bahasa?

<Question
	choices={[
		{
			text: "Pertama, model yang menangani teks dan mengembalikan prediksi mentah. Tokenizer kemudian mengartikan prediksi ini dan mengubahnya kembali menjadi teks saat dibutuhkan.",
			explain: "Model tidak bisa memahami teks! Tokenizer harus terlebih dahulu melakukan tokenisasi dan mengubah teks menjadi ID agar dapat dipahami oleh model."
		},
		{
			text: "Pertama, tokenizer yang menangani teks dan mengembalikan ID. Model menangani ID ini dan mengeluarkan prediksi yang bisa berupa teks.",
			explain: "Prediksi dari model tidak langsung berbentuk teks. Tokenizer diperlukan kembali untuk mengonversi prediksi menjadi teks!"
		},
		{
			text: "Tokenizer menangani teks dan mengembalikan ID. Model menangani ID ini dan mengeluarkan prediksi. Tokenizer kemudian dapat digunakan kembali untuk mengubah prediksi menjadi teks.",
			explain: "Tokenizer dapat digunakan untuk tokenisasi maupun de-tokenisasi.",
			correct: true
		}
	]}
/>

### 2. Berapa dimensi tensor yang dihasilkan oleh model Transformer dasar, dan apa saja?

<Question
	choices={[
		{
			text: "2: Panjang sekuens dan ukuran batch",
			explain: "Salah! Tensor dari model memiliki dimensi ketiga: ukuran hidden."
		},
		{
			text: "2: Panjang sekuens dan ukuran hidden",
			explain: "Salah! Semua model Transformer menangani batch, bahkan untuk satu sekuens (yang berarti batch size = 1)."
		},
		{
			text: "3: Panjang sekuens, ukuran batch, dan ukuran hidden",
			explain: "Bagus sekali!",
			correct: true
		}
	]}
/>

### 3. Mana dari berikut ini yang merupakan contoh tokenisasi sub-kata (*subword*)?

<Question
	choices={[
		{
			text: "WordPiece",
			explain: "Ya, ini adalah contoh tokenisasi subword!",
			correct: true
		},
		{
			text: "Tokenisasi berbasis karakter",
			explain: "Tokenisasi berbasis karakter bukanlah jenis tokenisasi subword."
		},
		{
			text: "Memisahkan berdasarkan spasi dan tanda baca",
			explain: "Ini adalah metode tokenisasi berbasis kata, bukan subword!"
		},
		{
			text: "BPE",
			explain: "Ya, ini juga merupakan metode tokenisasi subword!",
			correct: true
		},
		{
			text: "Unigram",
			explain: "Betul! Ini juga contoh tokenisasi subword.",
			correct: true
		},
		{
			text: "Tidak satu pun dari atas",
			explain: "Salah!"
		}
	]}
/>

### 4. Apa itu *model head*?

<Question
	choices={[
		{
			text: "Komponen dari jaringan Transformer dasar yang mengarahkan tensor ke layer yang tepat",
			explain: "Tidak ada komponen seperti itu."
		},
		{
			text: "Juga dikenal sebagai mekanisme self-attention, ia menyesuaikan representasi token berdasarkan token lain dalam sekuens",
			explain: "Layer self-attention memang memiliki 'head', tetapi itu bukan *model head* untuk adaptasi tugas."
		},
		{
			text: "Komponen tambahan, biasanya terdiri dari satu atau beberapa layer, untuk mengubah prediksi Transformer menjadi output yang spesifik untuk suatu tugas",
			explain: "Benar! *Model head* digunakan untuk tugas seperti klasifikasi sekuens, QA, dan lainnya.",
			correct: true
		}
	]}
/>

### 5. Apa itu `AutoModel`?

<Question
	choices={[
		{
			text: "Model yang otomatis melatih dirinya pada data Anda",
			explain: "Mungkin Anda sedang memikirkan produk <a href='https://huggingface.co/autotrain'>AutoTrain</a> kami?"
		},
		{
			text: "Objek yang mengembalikan arsitektur model yang tepat berdasarkan checkpoint",
			explain: "Tepat sekali: `AutoModel` hanya membutuhkan nama checkpoint untuk memuat arsitektur yang sesuai.",
			correct: true
		},
		{
			text: "Model yang secara otomatis mendeteksi bahasa input untuk memuat bobot yang tepat",
			explain: "Beberapa model mendukung banyak bahasa, tetapi tidak ada deteksi bahasa otomatis untuk memilih checkpoint. Gunakan <a href='https://huggingface.co/models'>Model Hub</a> untuk itu!"
		}
	]}
/>

### 6. Teknik apa yang perlu diperhatikan saat membuat batch dari sekuens dengan panjang berbeda?

<Question
	choices={[
		{
			text: "Truncating",
			explain: "Ya, truncation (pemotongan) dapat digunakan untuk menyamakan panjang sekuens.",
			correct: true
		},
		{
			text: "Mengembalikan tensor",
			explain: "Mengembalikan tensor sendiri tidak membantu membuat batch dari sekuens berbeda panjang."
		},
		{
			text: "Padding",
			explain: "Benar! Padding menambahkan token khusus agar semua sekuens memiliki panjang yang sama.",
			correct: true
		},
		{
			text: "Attention masking",
			explain: "Betul! Masking memastikan model mengabaikan token padding.",
			correct: true
		}
	]}
/>

### 7. Apa tujuan menerapkan fungsi SoftMax pada output *logits* dari model klasifikasi sekuens?

<Question
	choices={[
		{
			text: "Untuk melunakkan logits agar lebih dapat diandalkan.",
			explain: "Tidak, SoftMax tidak mempengaruhi keandalan hasil."
		},
		{
			text: "Untuk menerapkan batas atas dan bawah agar lebih mudah dipahami.",
			explain: "Nilai keluaran berada dalam rentang 0 hingga 1. Tapi bukan hanya itu tujuan SoftMax.",
			correct: true
		},
		{
			text: "Agar jumlah total output menjadi 1, sehingga bisa ditafsirkan secara probabilistik.",
			explain: "Benar! Ini adalah salah satu manfaat utama dari SoftMax.",
			correct: true
		}
	]}
/>

### 8. Metode apa yang menjadi inti dari API tokenizer?

<Question
	choices={[
		{
			text: "`encode`, karena bisa mengubah teks ke ID dan ID ke prediksi",
			explain: "Salah! Meskipun metode `encode` ada di tokenizer, metode ini tidak ada di model."
		},
		{
			text: "Memanggil objek tokenizer secara langsung.",
			explain: "Tepat! Metode `__call__` pada tokenizer sangat kuat dan fleksibel.",
			correct: true
		},
		{
			text: "`pad`",
			explain: "Salah! `pad` hanya salah satu fitur di API tokenizer."
		},
		{
			text: "`tokenize`",
			explain: "`tokenize` sangat berguna, tetapi bukan inti dari API tokenizer."
		}
	]}
/>

### 9. Apa isi dari variabel `result` dalam contoh kode berikut?

```py
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")
result = tokenizer.tokenize("Hello!")
```

<Question
	choices={[
		{
			text: "Daftar string, di mana tiap string adalah token",
			explain: "Benar! Anda dapat mengonversi ini ke ID dan mengirimkannya ke model!",
			correct: true
		},
		{
			text: "Daftar ID",
			explain: "Salah; itu adalah hasil dari __call__ atau convert_tokens_to_ids."
		},
		{
			text: "Satu string yang berisi semua token",
			explain: "Salah! Token seharusnya dipisah-pisah dalam daftar."
		}
	]}
/>

### 10. Apakah ada yang salah dengan kode berikut?

```py
from transformers import AutoTokenizer, AutoModel

tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")
model = AutoModel.from_pretrained("gpt2")

encoded = tokenizer("Hey!", return_tensors="pt")
result = model(**encoded)
```

<Question
	choices={[
		{
			text: "Tidak, ini tampaknya benar.",
			explain: "Sayangnya, menggunakan tokenizer dari checkpoint berbeda dengan model biasanya akan bermasalah. Model tidak dilatih dengan output dari tokenizer tersebut."
		},
		{
			text: "Tokenizer dan model sebaiknya selalu dari checkpoint yang sama.",
			explain: "Betul!",
			correct: true
		},
		{
			text: "Sebaiknya menggunakan padding dan truncation karena setiap input dianggap sebagai batch.",
			explain: "Memang input model harus berbentuk batch, tetapi untuk satu kalimat, padding/truncation mungkin tidak diperlukan."
		}
	]}
/>