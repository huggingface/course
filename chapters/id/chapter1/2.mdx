# Pemrosesan Bahasa Alami dan Model Bahasa Besar [[natural-language-processing-and-large-language-models]]

<CourseFloatingBanner
    chapter={1}
    classNames="absolute z-10 right-0 top-0"
/>

Sebelum masuk ke model Transformer, mari kita tinjau secara singkat apa itu pemrosesan bahasa alami (NLP), bagaimana model bahasa besar telah mengubah bidang ini, dan mengapa hal ini penting.

## Apa itu NLP? [[what-is-nlp]]

<Youtube id="iNzlxWUAjd4" />

NLP adalah bidang linguistik dan pembelajaran mesin yang berfokus pada pemahaman segala hal yang berkaitan dengan bahasa manusia. Tujuan dari tugas NLP bukan hanya memahami kata secara individu, tetapi juga memahami konteks dari kata-kata tersebut.

Berikut adalah daftar tugas NLP yang umum, beserta contohnya:

- **Klasifikasi seluruh kalimat**: Menentukan sentimen dari sebuah ulasan, mendeteksi apakah sebuah email adalah spam, menentukan apakah sebuah kalimat benar secara tata bahasa atau apakah dua kalimat saling berkaitan secara logika
- **Klasifikasi setiap kata dalam kalimat**: Mengidentifikasi komponen tata bahasa dari sebuah kalimat (kata benda, kata kerja, kata sifat), atau entitas bernama (nama orang, lokasi, organisasi)
- **Menghasilkan konten teks**: Melengkapi sebuah prompt dengan teks yang dihasilkan secara otomatis, mengisi bagian kosong dalam teks dengan kata-kata yang disamarkan
- **Menarik jawaban dari teks**: Diberikan sebuah pertanyaan dan konteks, menarik jawaban dari pertanyaan tersebut berdasarkan informasi yang tersedia di konteks
- **Menghasilkan kalimat baru dari teks input**: Menerjemahkan teks ke bahasa lain, membuat ringkasan teks

NLP tidak terbatas pada teks tertulis saja. Bidang ini juga menangani tantangan kompleks dalam pengenalan suara dan visi komputer, seperti membuat transkrip dari sampel audio atau deskripsi dari sebuah gambar.

## Munculnya Model Bahasa Besar (LLM) [[rise-of-llms]]

Dalam beberapa tahun terakhir, bidang NLP telah mengalami revolusi berkat Model Bahasa Besar (Large Language Models atau LLM). Model-model ini, termasuk arsitektur seperti GPT (Generative Pre-trained Transformer) dan [Llama](https://huggingface.co/meta-llama), telah mengubah apa yang mungkin dilakukan dalam pemrosesan bahasa.

<Tip>

Model bahasa besar (LLM) adalah model AI yang dilatih pada sejumlah besar data teks yang mampu memahami dan menghasilkan teks mirip manusia, mengenali pola dalam bahasa, dan melakukan berbagai tugas bahasa tanpa pelatihan khusus untuk setiap tugas. Model ini merupakan kemajuan besar dalam bidang pemrosesan bahasa alami (NLP).

</Tip>

Ciri khas LLM adalah:
- **Skala**: Memiliki jutaan, miliaran, atau bahkan ratusan miliar parameter
- **Kemampuan umum**: Dapat melakukan banyak tugas tanpa pelatihan khusus untuk setiap tugas
- **Pembelajaran dalam konteks (in-context learning)**: Dapat belajar dari contoh yang diberikan dalam prompt
- **Kemampuan emergen**: Saat model tumbuh lebih besar, ia menunjukkan kemampuan yang tidak secara eksplisit diprogramkan atau diprediksi

Kemunculan LLM telah mengubah paradigma dari membangun model khusus untuk tugas NLP tertentu menjadi menggunakan satu model besar yang bisa dipandu (prompt) atau disesuaikan (fine-tune) untuk menangani berbagai macam tugas bahasa. Hal ini membuat pemrosesan bahasa yang canggih menjadi lebih mudah diakses, meskipun juga menimbulkan tantangan baru dalam hal efisiensi, etika, dan penerapan.

Namun, LLM juga memiliki keterbatasan penting:
- **Halusinasi**: Dapat menghasilkan informasi yang salah dengan percaya diri
- **Kurangnya pemahaman sejati**: Tidak memiliki pemahaman nyata tentang dunia dan hanya beroperasi berdasarkan pola statistik
- **Bias**: Dapat mereproduksi bias yang ada di data pelatihan atau input
- **Jendela konteks**: Memiliki jendela konteks yang terbatas (meskipun hal ini terus berkembang)
- **Sumber daya komputasi**: Membutuhkan sumber daya komputasi yang besar

## Mengapa pemrosesan bahasa itu menantang? [[why-is-it-challenging]]

Komputer tidak memproses informasi dengan cara yang sama seperti manusia. Misalnya, saat kita membaca kalimat "Saya lapar", kita bisa langsung memahami maknanya. Begitu pula, saat diberikan dua kalimat seperti "Saya lapar" dan "Saya sedih", kita dapat dengan mudah menentukan seberapa mirip keduanya. Namun bagi model pembelajaran mesin (ML), tugas-tugas semacam ini jauh lebih sulit. Teks perlu diproses dengan cara yang memungkinkan model untuk belajar darinya. Dan karena bahasa itu kompleks, kita harus memikirkan dengan cermat bagaimana pemrosesan itu dilakukan. Sudah banyak penelitian dilakukan tentang cara merepresentasikan teks, dan kita akan membahas beberapa metode pada bab berikutnya.

Meskipun ada kemajuan dalam LLM, masih banyak tantangan mendasar yang tersisa. Ini termasuk memahami ambiguitas, konteks budaya, sarkasme, dan humor. LLM mengatasi tantangan ini melalui pelatihan masif pada berbagai dataset, namun tetap sering kali belum mencapai tingkat pemahaman manusia dalam banyak skenario kompleks.
