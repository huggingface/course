# Transformer: Apa Saja yang Bisa Mereka Lakukan?[[transformers-what-can-they-do]]

<CourseFloatingBanner chapter={1}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter1/section3.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter1/section3.ipynb"},
]} />

Di bagian ini, kita akan melihat apa saja yang bisa dilakukan oleh model Transformer dan menggunakan alat pertama dari modul ü§ó Transformers: fungsi `pipeline()`.

<Tip>
üëÄ Lihat tombol <em>Open in Colab</em> di kanan atas? Klik tombol tersebut untuk membuka notebook Google Colab berisi seluruh contoh kode di bagian ini. Tombol ini akan tersedia di setiap bagian yang menyertakan contoh kode.

Jika Anda ingin menjalankan contoh secara lokal, kami sarankan melihat bagian <a href="/course/chapter0">setup</a>.
</Tip>

## Transformer Ada di Mana-Mana![[transformers-are-everywhere]]

Model Transformer digunakan untuk menyelesaikan berbagai jenis tugas lintas *modality* ‚Äî termasuk NLP (pemrosesan bahasa alami), *computer vision*, pemrosesan audio, dan lainnya. Berikut adalah beberapa perusahaan dan organisasi yang menggunakan Hugging Face dan model Transformer, serta berkontribusi kembali ke komunitas dengan membagikan model mereka:

<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/companies.PNG" alt="Perusahaan yang menggunakan Hugging Face" width="100%">

modul [ü§ó Transformers](https://github.com/huggingface/transformers) memungkinkan Anda membuat dan menggunakan model yang dibagikan di [Model Hub](https://huggingface.co/models), yang berisi jutaan model pra-latih siap digunakan. Anda juga dapat mengunggah model Anda sendiri ke Hub!

<Tip>
‚ö†Ô∏è Hugging Face Hub tidak terbatas pada model Transformer saja. Siapa pun dapat membagikan model atau dataset apapun! <a href="https://huggingface.co/join">Buat akun huggingface.co</a> untuk mendapatkan semua fitur yang tersedia!
</Tip>

Sebelum membahas bagaimana model Transformer bekerja secara internal, mari kita lihat contoh penggunaan praktisnya dalam menyelesaikan berbagai masalah NLP.

## Bekerja dengan Pipeline[[working-with-pipelines]]

<Youtube id="tiZFewofSLM" />

Objek paling dasar di modul ü§ó Transformers adalah fungsi `pipeline()`. Fungsi ini menghubungkan model dengan langkah-langkah pra-pemrosesan dan pascapemrosesan yang dibutuhkan, sehingga Anda bisa langsung memasukkan teks dan mendapatkan hasil yang bermakna:

```python
from transformers import pipeline

classifier = pipeline("sentiment-analysis")
classifier("I've been waiting for a HuggingFace course my whole life.")
```

```python out
[{'label': 'POSITIVE', 'score': 0.9598047137260437}]
```

Anda bahkan bisa mengirim beberapa kalimat sekaligus:

```python
classifier(
    ["I've been waiting for a HuggingFace course my whole life.", "I hate this so much!"]
)
```

```python out
[{'label': 'POSITIVE', 'score': 0.9598047137260437},
 {'label': 'NEGATIVE', 'score': 0.9994558095932007}]
```

Secara default, pipeline ini menggunakan model pra-latih yang telah di-*fine-tune* untuk analisis sentimen dalam bahasa Inggris. Model akan diunduh dan disimpan saat Anda pertama kali menjalankan `classifier`. Saat dijalankan ulang, model dari cache akan digunakan.

Tiga langkah utama ketika teks dikirim ke `pipeline()`:

1. Teks dipra-proses menjadi format yang bisa dipahami model.
2. Input yang telah diproses dikirim ke model.
3. Prediksi dari model diproses ulang agar mudah dipahami.

## Pipeline Tersedia untuk Berbagai Modality

Fungsi `pipeline()` mendukung berbagai *modality*, seperti teks, gambar, audio, hingga tugas multimodal. Fokus utama dalam kursus ini adalah teks, tapi penting untuk mengenal potensi arsitektur Transformer secara luas.

Berikut adalah ringkasannya:

<Tip>
Untuk daftar lengkap dan terbaru, lihat [dokumentasi ü§ó Transformers](https://huggingface.co/docs/hub/en/models-tasks).
</Tip>

### Pipeline Teks

- `text-generation`: Menghasilkan teks dari sebuah prompt
- `text-classification`: Mengklasifikasikan teks ke dalam kategori tertentu
- `summarization`: Merangkum teks tanpa kehilangan informasi penting
- `translation`: Menerjemahkan teks antar bahasa
- `zero-shot-classification`: Mengklasifikasikan teks tanpa pelatihan spesifik pada label
- `feature-extraction`: Mengambil representasi vektor dari teks

### Pipeline Gambar

- `image-to-text`: Menghasilkan deskripsi teks dari gambar
- `image-classification`: Mengidentifikasi objek dalam gambar
- `object-detection`: Menemukan dan mengenali objek dalam gambar

### Pipeline Audio

- `automatic-speech-recognition`: Mengubah ucapan menjadi teks
- `audio-classification`: Mengklasifikasikan data audio
- `text-to-speech`: Mengubah teks menjadi suara

### Pipeline Multimodal

- `image-text-to-text`: Memberi respons terhadap gambar berdasarkan prompt teks

Mari kita eksplorasi beberapa pipeline ini secara lebih mendalam!

## Zero-shot classification[[zero-shot-classification]]

Kita akan mulai dengan tugas yang sedikit lebih menantang: mengklasifikasikan teks yang belum diberi label. Ini adalah kasus umum dalam proyek dunia nyata, karena proses anotasi teks memakan waktu dan membutuhkan keahlian khusus. Untuk kasus ini, pipeline `zero-shot-classification` sangat berguna: Anda dapat menentukan label apa pun yang ingin digunakan untuk klasifikasi ‚Äî tanpa bergantung pada label bawaan dari model pra-latih.

```python
from transformers import pipeline

classifier = pipeline("zero-shot-classification")
classifier(
    "This is a course about the Transformers library",
    candidate_labels=["education", "politics", "business"],
)
```

```python out
{'sequence': 'This is a course about the Transformers library',
 'labels': ['education', 'business', 'politics'],
 'scores': [0.8445963859558105, 0.111976258456707, 0.043427448719739914]}
```

Pipeline ini disebut *zero-shot* karena Anda tidak perlu melakukan *fine-tuning* model dengan data Anda. Model ini langsung mengembalikan skor probabilitas untuk daftar label apa pun yang Anda tentukan!

<Tip>
‚úèÔ∏è **Coba sendiri!** Bereksperimenlah dengan kalimat dan label buatan Anda untuk melihat bagaimana perilaku model berubah.
</Tip>

## Text generation[[text-generation]]

Sekarang mari kita lihat cara menggunakan pipeline untuk menghasilkan teks. Inti dari tugas ini adalah: Anda memberikan *prompt*, dan model akan melengkapinya dengan teks yang dihasilkan secara otomatis ‚Äî mirip dengan fitur prediksi teks di ponsel. Karena melibatkan elemen acak, hasil Anda mungkin berbeda dari contoh berikut.

```python
from transformers import pipeline

generator = pipeline("text-generation")
generator("In this course, we will teach you how to")
```

```python out
[{'generated_text': 'In this course, we will teach you how to understand and use '
                    'data flow and data interchange when handling user data. We '
                    'will be working with one or more of the most commonly used '
                    'data flows ‚Äî data flows of various types, as seen by the '
                    'HTTP'}]
```

Gunakan argumen `num_return_sequences` untuk menentukan berapa banyak variasi teks yang ingin dihasilkan, dan `max_length` untuk menentukan panjang maksimum teks keluaran.

<Tip>
‚úèÔ∏è **Coba sendiri!** Gunakan `num_return_sequences` dan `max_length` untuk menghasilkan dua kalimat dengan panjang masing-masing 15 kata.
</Tip>

## Menggunakan Model Apa Pun dari Hub[[using-any-model-from-the-hub-in-a-pipeline]]

Contoh sebelumnya menggunakan model default untuk setiap tugas. Namun, Anda juga dapat memilih model tertentu dari Model Hub untuk digunakan dalam pipeline. Misalnya, untuk tugas *text generation*, buka [Model Hub](https://huggingface.co/models), klik tag yang sesuai di panel kiri untuk memfilter model berdasarkan tugas. Contohnya: [text generation](https://huggingface.co/models?pipeline_tag=text-generation).

Mari kita coba model [`HuggingFaceTB/SmolLM2-360M`](https://huggingface.co/HuggingFaceTB/SmolLM2-360M)! Berikut cara menggunakannya:

```python
from transformers import pipeline

generator = pipeline("text-generation", model="HuggingFaceTB/SmolLM2-360M")
generator(
    "In this course, we will teach you how to",
    max_length=30,
    num_return_sequences=2,
)
```

```python out
[{'generated_text': 'In this course, we will teach you how to manipulate the world and '
                    'move your mental and physical capabilities to your advantage.'},
 {'generated_text': 'In this course, we will teach you how to become an expert and '
                    'practice realtime, and with a hands on experience on both real '
                    'time and real'}]
```

Anda bisa mempersempit pencarian dengan memilih tag bahasa tertentu untuk mencari model yang mendukung bahasa tersebut. Bahkan, terdapat model multibahasa di Hub!

Setelah memilih model, Anda juga bisa langsung mencoba kemampuannya melalui widget interaktif di halaman model.

<Tip>
‚úèÔ∏è **Coba sendiri!** Gunakan filter untuk menemukan model *text generation* dalam bahasa lain. Uji coba modelnya di widget sebelum digunakan dalam pipeline!
</Tip>

### Inference Providers[[inference-providers]]

Semua model dapat dicoba langsung melalui browser menggunakan layanan [Inference Providers](https://huggingface.co/docs/inference-providers/en/index). Cukup masukkan teks, dan lihat hasilnya secara langsung.

Layanan ini juga tersedia sebagai produk berbayar ‚Äî cocok untuk integrasi ke dalam alur kerja Anda. Lihat [halaman harga](https://huggingface.co/docs/inference-providers/en/pricing) untuk informasi lebih lanjut.

## Pengisian Mask[[mask-filling]]

Pipeline berikutnya adalah `fill-mask`. Tugas ini mengisi kata yang hilang dalam teks:

```python
from transformers import pipeline

unmasker = pipeline("fill-mask")
unmasker("This course will teach you all about <mask> models.", top_k=2)
```

```python out
[{'sequence': 'This course will teach you all about mathematical models.',
  'score': 0.19619831442832947,
  'token': 30412,
  'token_str': ' mathematical'},
 {'sequence': 'This course will teach you all about computational models.',
  'score': 0.04052725434303284,
  'token': 38163,
  'token_str': ' computational'}]
```

Argumen `top_k` menentukan berapa banyak kemungkinan yang ditampilkan. Perhatikan bahwa token `<mask>` adalah token khusus untuk mengindikasikan bagian yang perlu diisi. Token ini bisa berbeda di tiap model, jadi pastikan Anda mengetahui token yang tepat, misalnya dengan melihat widget di halaman model.

<Tip>
‚úèÔ∏è **Coba sendiri!** Cari model `bert-base-cased` di Hub dan identifikasi token mask-nya di widget API. Apa prediksinya untuk kalimat di atas?
</Tip>

## Named Entity Recognition[[named-entity-recognition]]

*Named Entity Recognition* (NER) adalah tugas untuk mengenali bagian-bagian dari teks yang merupakan entitas seperti nama orang, lokasi, atau organisasi. Contohnya:

```python
from transformers import pipeline

ner = pipeline("ner", grouped_entities=True)
ner("My name is Sylvain and I work at Hugging Face in Brooklyn.")
```

```python out
[{'entity_group': 'PER', 'score': 0.99816, 'word': 'Sylvain', 'start': 11, 'end': 18}, 
 {'entity_group': 'ORG', 'score': 0.97960, 'word': 'Hugging Face', 'start': 33, 'end': 45}, 
 {'entity_group': 'LOC', 'score': 0.99321, 'word': 'Brooklyn', 'start': 49, 'end': 57}]
```

Model ini berhasil mengenali *Sylvain* sebagai orang (PER), *Hugging Face* sebagai organisasi (ORG), dan *Brooklyn* sebagai lokasi (LOC).

Opsi `grouped_entities=True` menyatukan bagian-bagian yang tergolong entitas sama. Misalnya, ‚ÄúHugging‚Äù dan ‚ÄúFace‚Äù digabung sebagai satu organisasi.

<Tip>
‚úèÔ∏è **Coba sendiri!** Cari model yang mampu melakukan *part-of-speech tagging* (POS) dalam bahasa Inggris. Apa prediksinya untuk kalimat di atas?
</Tip>

## Question Answering[[question-answering]]

Pipeline `question-answering` memungkinkan Anda menjawab pertanyaan berdasarkan konteks yang diberikan:

```python
from transformers import pipeline

question_answerer = pipeline("question-answering")
question_answerer(
    question="Where do I work?",
    context="My name is Sylvain and I work at Hugging Face in Brooklyn",
)
```

```python out
{'score': 0.6385916471481323, 'start': 33, 'end': 45, 'answer': 'Hugging Face'}
```

Pipeline ini tidak menghasilkan jawaban baru, tapi mengekstraknya dari konteks yang diberikan.

## Ringkasan[[summarization]]

Tugas *summarization* bertujuan menyederhanakan teks panjang menjadi ringkasan yang tetap mempertahankan inti informasinya:

```python
from transformers import pipeline

summarizer = pipeline("summarization")
summarizer(
    """
    Amerika telah mengalami perubahan besar dalam beberapa tahun terakhir. 
    Tidak hanya jumlah lulusan di disiplin teknik tradisional seperti teknik 
    mesin, sipil, listrik, kimia, dan aeronautika yang menurun, tetapi di 
    sebagian besar universitas unggulan Amerika, kurikulum teknik kini lebih 
    menekankan dan mendorong studi rekayasa sains. Akibatnya, mata kuliah teknik 
    yang berkaitan dengan infrastruktur, lingkungan, dan isu terkait semakin sedikit 
    ditawarkan, dan ada konsentrasi yang lebih besar pada mata kuliah teknologi tinggi 
    yang mendukung perkembangan ilmiah yang semakin kompleks. Meskipun yang terakhir 
    itu penting, seharusnya tidak mengorbankan teknik tradisional.

    Negara dengan ekonomi yang berkembang pesat seperti Tiongkok dan India, serta negara 
    industri lain di Eropa dan Asia, terus mendorong dan mengembangkan pengajaran teknik. 
    Tiongkok dan India masing-masing meluluskan enam dan delapan kali lebih banyak insinyur 
    tradisional dibandingkan Amerika Serikat. Negara industri lainnya paling tidak 
    mempertahankan jumlah lulusan mereka, sementara Amerika mengalami penurunan serius 
    dalam jumlah lulusan teknik dan kekurangan insinyur yang berpendidikan baik.
    """
)
```

```python out
[{'summary_text': ' Amerika telah mengalami perubahan besar dalam beberapa tahun terakhir. '
                  'Jumlah lulusan teknik di AS menurun di bidang teknik tradisional seperti '
                  'teknik mesin, sipil, listrik, kimia, dan aeronautika. Negara dengan ekonomi '
                  'yang berkembang pesat seperti Tiongkok dan India, serta negara industri lain '
                  'di Eropa dan Asia, terus mendorong dan mengembangkan bidang teknik.'}]
```

Seperti pada *text generation*, Anda bisa menetapkan `max_length` dan `min_length` hasil ringkasan.

## Penerjemahan[[translation]]

Untuk tugas penerjemahan, Anda bisa menggunakan model default dengan menamai tugas seperti `"translation_en_to_fr"`, atau pilih langsung model dari [Model Hub](https://huggingface.co/models). Berikut contoh penerjemahan dari Prancis ke Inggris:

```python
from transformers import pipeline

translator = pipeline("translation", model="Helsinki-NLP/opus-mt-fr-en")
translator("Ce cours est produit par Hugging Face.")
```

```python out
[{'translation_text': 'This course is produced by Hugging Face.'}]
```

<Tip>
‚úèÔ∏è **Coba sendiri!** Cari model penerjemahan untuk bahasa lain dan coba terjemahkan kalimat di atas ke berbagai bahasa!
</Tip>

## Pipeline Gambar dan Audio

Selain teks, model Transformer juga bisa bekerja dengan gambar dan audio. Contoh:

### Klasifikasi Gambar

```python
from transformers import pipeline

image_classifier = pipeline(
    task="image-classification", model="google/vit-base-patch16-224"
)
result = image_classifier(
    "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg"
)
print(result)
```

### Automatic Speech Recognition

```python
from transformers import pipeline

transcriber = pipeline(
    task="automatic-speech-recognition", model="openai/whisper-large-v3"
)
result = transcriber(
    "https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac"
)
print(result)
```

```python out
{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}
```

## Menggabungkan Data dari Banyak Sumber

Kekuatan utama model Transformer adalah kemampuannya menggabungkan dan memproses data dari berbagai sumber. Ini sangat bermanfaat jika Anda:

1. Mencari informasi dari banyak basis data
2. Menggabungkan berbagai format (teks, gambar, audio)
3. Menyajikan informasi dari berbagai sumber secara terpadu

Contohnya, Anda bisa membangun sistem yang:

- Mencari data dari berbagai modalitas
- Menggabungkan hasil pencarian menjadi satu respons
- Menyajikan informasi relevan dari dokumen dan metadata

## Kesimpulan

Pipeline yang ditampilkan dalam bab ini digunakan sebagai demonstrasi. Mereka dirancang untuk tugas-tugas spesifik dan tidak dapat digunakan untuk variasi tugas lainnya secara langsung. Di bab selanjutnya, Anda akan belajar lebih dalam tentang apa yang ada di balik fungsi `pipeline()` dan bagaimana mengkustomisasinya.
