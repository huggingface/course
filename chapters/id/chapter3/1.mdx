<FrameworkSwitchCourse {fw} />

# Pendahuluan[[introduction]]

<CourseFloatingBanner
    chapter={3}
    classNames="absolute z-10 right-0 top-0"
/>

Pada [Bab 2](/course/chapter2) kita telah mempelajari cara menggunakan tokenizer dan model pralatih untuk membuat prediksi. Namun bagaimana jika Anda ingin melakukan fine-tuning pada model pralatih untuk menyelesaikan tugas tertentu? Itulah topik bab ini! Anda akan belajar:

* Cara menyiapkan dataset besar dari Hub menggunakan fitur terbaru dari 🤗 Datasets
* Cara menggunakan API tingkat tinggi `Trainer` untuk melakukan fine-tuning model dengan praktik terbaik modern
* Cara mengimplementasikan loop pelatihan kustom dengan teknik optimasi
* Cara memanfaatkan modul 🤗 Accelerate untuk menjalankan pelatihan terdistribusi dengan mudah di berbagai sistem
* Cara menerapkan praktik terbaik fine-tuning terkini untuk kinerja maksimal

<Tip>

📚 **Sumber Daya Penting**: Sebelum memulai, Anda mungkin ingin meninjau [dokumentasi 🤗 Datasets](https://huggingface.co/docs/datasets/) untuk pemrosesan data.

</Tip>

Bab ini juga akan menjadi pengantar beberapa modul Hugging Face di luar modul 🤗 Transformers! Kita akan melihat bagaimana modul seperti 🤗 Datasets, 🤗 Tokenizers, 🤗 Accelerate, dan 🤗 Evaluate dapat membantu Anda melatih model secara lebih efisien dan efektif.

Setiap bagian utama dalam bab ini akan mengajarkan hal yang berbeda:
- **Bagian 2**: Pelajari teknik pra-pemrosesan data modern dan penanganan dataset yang efisien
- **Bagian 3**: Kuasai API Trainer yang kuat dengan semua fitur terbarunya
- **Bagian 4**: Implementasikan loop pelatihan dari awal dan pahami pelatihan terdistribusi dengan Accelerate

Pada akhir bab ini, Anda akan dapat melakukan fine-tuning model pada dataset Anda sendiri menggunakan baik API tingkat tinggi maupun loop pelatihan kustom, dengan menerapkan praktik terbaik terkini di bidang ini.

<Tip>

🎯 **Yang Akan Anda Bangun**: Di akhir bab ini, Anda akan telah melakukan fine-tuning pada model BERT untuk klasifikasi teks dan memahami cara menyesuaikan teknik tersebut dengan dataset dan tugas Anda sendiri.

</Tip>

Bab ini secara eksklusif berfokus pada **PyTorch**, karena telah menjadi kerangka kerja standar untuk riset dan produksi deep learning modern. Kita akan menggunakan API dan praktik terbaik terbaru dari ekosistem Hugging Face.

Untuk mengunggah model yang telah Anda latih ke Hugging Face Hub, Anda akan memerlukan akun Hugging Face: [buat akun](https://huggingface.co/join)
