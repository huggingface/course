<FrameworkSwitchCourse {fw} />
# లెర్నింగ్ కర్వ్స్ అర్థం చేసుకోవడం[[understanding-learning-curves]]
<CourseFloatingBanner
  chapter={3}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/te/chapter3/section7.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/te/chapter3/section7.ipynb"},
  ]}
/>

`Trainer` API మరియు కస్టమ్ ట్రైనింగ్ లూప్స్ రెండిటితో ఫైన్-ట్యూనింగ్ ఎలా చేయాలో నేర్చుకున్న తర్వాత, ఫలితాలను ఎలా అర్థం చేసుకోవాలో తెలుసుకోవడం చాలా ముఖ్యం. లెర్నింగ్ కర్వ్స్ మోడల్ పనితీరును అంచనా వేయడానికి, సమస్యలను ముందుగానే గుర్తించడానికి అమూల్యమైన టూల్స్.

ఈ సెక్షన్‌లో ఆక్యురసీ మరియు లాస్ కర్వ్స్‌ను ఎలా చదవాలో, వివిధ కర్వ్ ఆకారాలు మోడల్ ప్రవర్తన గురించి ఏమి చెబుతాయో, సాధారణ శిక్షణ సమస్యలను ఎలా పరిష్కరించాలో తెలుసుకుంటాం.

## లెర్నింగ్ కర్వ్స్ అంటే ఏమిటి?[[what-are-learning-curves]]

లెర్నింగ్ కర్వ్స్ అంటే శిక్షణ సమయంలో మోడల్ పనితీరు మెట్రిక్స్ ఎలా మారుతాయో చూపే దృశ్య రూపాలు. పర్యవేక్షించాల్సిన ముఖ్యమైన రెండు కర్వ్స్:

- **లాస్ కర్వ్స్**: మోడల్ ఎర్రర్ (లాస్) శిక్షణ స్టెప్స్ లేదా ఎపాక్స్‌లో ఎలా మారుతుంది
- **ఆక్యురసీ కర్వ్స్**: సరైన ప్రిడిక్షన్స్ శాతం ఎలా మారుతుంది

### లాస్ కర్వ్స్[[loss-curves]]

లాస్ కర్వ్ మోడల్ ఎర్రర్ కాలక్రమంలో ఎలా తగ్గుతుందో చూపిస్తుంది. సాధారణ విజయవంతమైన శిక్షణలో కింది విధంగా కనిపిస్తుంది:

![Loss Curve](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter3/1.png)

- **మొదట ఎక్కువ లాస్**: మోడల్ ఆప్టిమైజ్ కాని స్థితిలో ఉంటుంది, ప్రిడిక్షన్స్ పేలవంగా ఉంటాయి
- **తగ్గుతున్న లాస్**: శిక్షణ పురోగమిస్తుండగా లాస్ సాధారణంగా తగ్గుతుంది
- **కన్వర్జెన్స్**: చివరికి లాస్ తక్కువ వాల్యూకి స్థిరపడుతుంది

```python
from transformers import Trainer, TrainingArguments
import wandb
wandb.init(project="transformer-fine-tuning", name="bert-mrpc-analysis")

training_args = TrainingArguments(
    output_dir="./results",
    eval_strategy="steps",
    eval_steps=50,
    save_steps=100,
    logging_steps=10,
    num_train_epochs=3,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    report_to="wandb",
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    processing_class=tokenizer,
    compute_metrics=compute_metrics,
)
trainer.train()
```

### ఆక్యురసీ కర్వ్స్[[accuracy-curves]]

![Accuracy Curve](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter3/2.png)

- **మొదట తక్కువ**: మోడల్ ఇంకా ప్యాటర్న్స్ నేర్చుకోలేదు
- **పెరుగుతుంది**: మోడల్ నేర్చుకుంటుంది కాబట్టి ఆక్యురసీ పెరుగుతుంది
- **ప్లాటోలు కనిపిస్తాయి**: ఆక్యురసీ సాధారణంగా డిస్క్రీట్ జంప్స్‌లో పెరుగుతుంది

> [!TIP]
> ఆక్యురసీ కర్వ్స్ "స్టెప్పీ"గా ఉండటానికి కారణం: లాస్ కంటిన్యూస్ అయితే, ఆక్యురసీ డిస్క్రీట్ ప్రిడిక్షన్స్‌పై ఆధారపడి ఉంటుంది. కాన్ఫిడెన్స్‌లో చిన్న మెరుగుదలలు ఫైనల్ ప్రిడిక్షన్ మార్చకపోవచ్చు, థ్రెషోల్డ్ దాటినప్పుడు మాత్రమే ఆక్యురసీ పెరుగుతుంది.

### కన్వర్జెన్స్[[convergence]]

![Convergence](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter3/4.png)

మోడల్ పనితీరు స్థిరపడినప్పుడు కన్వర్జెన్స్ జరుగుతుంది.

## లెర్నింగ్ కర్వ్ ప్యాటర్న్స్ అర్థం చేసుకోవడం[[interpreting-learning-curve-patterns]]

### ఆరోగ్యకరమైన లెర్నింగ్ కర్వ్స్[[healthy-learning-curves]]

![Healthy Loss Curve](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter3/5.png)

> [!TIP]
> ఆరోగ్యకరమైన కర్వ్స్ లక్షణాలు:
> - ట్రైన్ & వాలిడేషన్ లాస్ రెండూ స్థిరంగా తగ్గుతాయి
> - ట్రైన్/వాలిడేషన్ మధ్య చిన్న గ్యాప్ మాత్రమే ఉంటుంది
> - కర్వ్స్ స్థిరపడతాయి

### ఓవర్‌ఫిట్టింగ్[[overfitting]]

![Overfitting](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter3/10.png)

లక్షణాలు:
- ట్రైన్ లాస్ తగ్గుతూనే ఉంటుంది
- వాలిడేషన్ లాస్ పెరగడం మొదలవుతుంది లేదా స్థిరపడుతుంది

పరిష్కారాలు:
- రెగ్యులరైజేషన్ (డ్రాపౌట్, వెయిట్ డికే)
- ఎర్లీ స్టాప్పింగ్
- డేటా ఆగ్మెంటేషన్
- చిన్న మోడల్ వాడటం

```python
from transformers import EarlyStoppingCallback

trainer = Trainer(
    ...,
    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],
)
```

### అండర్‌ఫిట్టింగ్[[underfitting]]

![Underfitting](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter3/7.png)

లక్షణాలు:
- ట్రైన్ & వాలిడేషన్ లాస్ రెండూ ఎక్కువగా ఉంటాయి
- త్వరగా ప్లాటో అవుతాయి

పరిష్కారాలు:
- పెద్ద మోడల్ వాడటం
- ఎక్కువ ఎపాక్స్ శిక్షణ
- లెర్నింగ్ రేట్ సర్దడం

### ఎరాటిక్ లెర్నింగ్ కర్వ్స్[[erratic-learning-curves]]

![Erratic Learning Curves](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter3/3.png)
![Erratic Learning Curves](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter3/9.png)

లక్షణాలు:
- లాస్/ఆక్యురసీ తరచూ ఊగుతాయి
- స్పష్టమైన ట్రెండ్ ఉండదు

పరిష్కారాలు:
- లెర్నింగ్ రేట్ తగ్గించడం
- బ్యాచ్ సైజ్ పెంచడం
- గ్రేడియంట్ క్లిప్పింగ్

```python
training_args = TrainingArguments(
    ...,
    learning_rate=2e-5,           # ముందు ఎక్కువ ఉంటే తగ్గించండి
    per_device_train_batch_size=32,
)
```

## ముఖ్య పాయింట్లు[[key-takeaways]]

లెర్నింగ్ కర్వ్స్ అర్థం చేసుకోవడం ప్రభావవంతమైన మెషిన్ లెర్నింగ్ ప్రాక్టీషనర్ కావడానికి అవసరం.

> [!TIP]
> ముఖ్య పాయింట్లు:
> - లెర్నింగ్ కర్వ్స్ మోడల్ శిక్షణ పురోగతిని అర్థం చేసుకోవడానికి అవసరమైన టూల్స్
> - లాస్ మరియు ఆక్యురసీ కర్వ్స్ రెండూ పర్యవేక్షించండి, కానీ వాటి స్వభావాలు భిన్నంగా ఉంటాయి
> - ఓవర్‌ఫిట్టింగ్: ట్రైన్/వాలిడేషన్ పనితీరు వేరుపడటం
> - అండర్‌ఫిట్టింగ్: ట్రైన్ & వాలిడేషన్ రెండూ పేలవంగా ఉండటం
> - Weights & Biases వంటి టూల్స్ లెర్నింగ్ కర్వ్స్ ట్రాక్ చేయడం సులభం చేస్తాయి
> - ఎర్లీ స్టాప్పింగ్ మరియు రెగ్యులరైజేషన్ సాధారణ శిక్షణ సమస్యలను పరిష్కరిస్తాయి

## సెక్షన్ క్విజ్[[section-quiz]]

### 1. ట్రైన్ లాస్ తగ్గుతున్నా వాలిడేషన్ లాస్ పెరుగుతుంటే ఏమవుతుంది?
<Question
choices={[
{text: "మోడల్ విజయవంతంగా నేర్చుకుంటుంది.", explain: "కాదు, ఇది సమస్య సూచిక."},
{text: "మోడల్ ట్రైనింగ్ డేటాకు ఓవర్‌ఫిట్ అవుతుంది.", explain: "సరైనది! ఇది ఓవర్‌ఫిట్టింగ్ యొక్క క్లాసిక్ లక్షణం.", correct: true},
{text: "లెర్నింగ్ రేట్ చాలా తక్కువ.", explain: "కాదు."},
{text: "డేటాసెట్ చాలా చిన్నది.", explain: "కావచ్చు కానీ ఈ ప్యాటర్న్ ఓవర్‌ఫిట్టింగ్‌ని సూచిస్తుంది."}
]}/>

### 2. ఆక్యురసీ కర్వ్స్ ఎందుకు "స్టెప్పీ" ఆకారంలో ఉంటాయి?
<Question
choices={[
{text: "ఆక్యురసీ కాలిక్యులేషన్‌లో లోపం ఉంది.", explain: "కాదు, ఇది సహజం."},
{text: "ఆక్యురసీ డిస్క్రీట్ మెట్రిక్, ప్రిడిక్షన్స్ డిసిషన్ బౌండరీ దాటినప్పుడు మాత్రమే మారుతుంది.", explain: "సరైనది!", correct: true},
{text: "మోడల్ సరిగ్గా నేర్చుకోవడం లేదు.", explain: "కాదు, స్టెప్పీ కర్వ్స్ సహజం."},
{text: "బ్యాచ్ సైజ్ చాలా చిన్నది.", explain: "కాదు."}
]}/>

### 3. అస్థిర (ఎరాటిక్) లెర్నింగ్ కర్వ్స్ కనిపిస్తే ఏం చేయాలి?
<Question
choices={[
{text: "లెర్నింగ్ రేట్ పెంచాలి.", explain: "మరింత అస్థిరం అవుతుంది."},
{text: "లెర్నింగ్ రేట్ తగ్గించి, బ్యాచ్ సైజ్ పెంచాలి.", explain: "సరైనది!", correct: true},
{text: "వెంటనే శిక్షణ ఆపేయాలి.", explain: "అవసరం లేదు."},
{text: "మోడల్ ఆర్కిటెక్చర్ మార్చాలి.", explain: "అకాల నిర్ణయం."}
]}/>

### 4. ఎర్లీ స్టాప్పింగ్ ఎప్పుడు వాడాలి?
<Question
choices={[
{text: "ఎల్లప్పుడూ.", explain: "అవసరం లేని చోట కూడా అనవసరం."},
{text: "వాలిడేషన్ పనితీరు మెరుగుపడకపోతే లేదా క్షీణిస్తే.", explain: "సరైనది!", correct: true},
{text: "ట్రైన్ లాస్ ఇంకా త్వరగా తగ్గుతుంటే.", explain: "కొనసాగించవచ్చు."},
{text: "ఎప్పుడూ కాదు.", explain: "కాదు, మంచి టెక్నిక్."}
]}/>

### 5. మోడల్ అండర్‌ఫిట్ అవుతుందని ఏది సూచిస్తుంది?
<Question
choices={[
{text: "ట్రైన్ ఆక్యురసీ >> వాలిడేషన్ ఆక్యురసీ.", explain: "ఇది ఓవర్‌ఫిట్టింగ్."},
{text: "ట్రైన్ & వాలిడేషన్ పనితీరు రెండూ పేలవంగా, త్వరగా ప్లాటో.", explain: "సరైనది!", correct: true},
{text: "లెర్నింగ్ కర్వ్స్ చాలా స్మూత్.", explain: "కాదు."},
{text: "వాలిడేషన్ లాస్ ట్రైన్ కంటే త్వరగా తగ్గుతుంది.", explain: "ఇది మంచి సంకేతం."}
]}/>

**పూర్తయింది మామా! చాప్టర్ 3 మొత్తం రెడీ.**  
చాప్టర్ 4 (Sharing Models on the Hub) కావాలంటే చెప్పు – వెంటనే రాస్తా!