<FrameworkSwitchCourse {fw} />

# ‡∞™‡±à‡∞™‡±ç‚Äå‡∞≤‡±à‡∞®‡±ç ‡∞µ‡±Ü‡∞®‡±Å‡∞ï

<CourseFloatingBanner chapter={2}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter2/section2_pt.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter2/section2_pt.ipynb"},
]} />

<Youtube id="1pedAIvTWXk"/>

‡∞á‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å ‡∞í‡∞ï ‡∞™‡±Ç‡∞∞‡±ç‡∞§‡∞ø ‡∞â‡∞¶‡∞æ‡∞π‡∞∞‡∞£‡∞§‡±ã ‡∞™‡±ç‡∞∞‡∞æ‡∞∞‡∞Ç‡∞≠‡∞ø‡∞¶‡±ç‡∞¶‡∞æ‡∞Ç. [‡∞Ö‡∞ß‡±ç‡∞Ø‡∞æ‡∞Ø‡∞Ç 1](/course/chapter1)‡∞≤‡±ã ‡∞Æ‡∞®‡∞Ç ‡∞ï‡±ç‡∞∞‡∞ø‡∞Ç‡∞¶‡∞ø ‡∞ï‡±ã‡∞°‡±ç‚Äå‡∞®‡±Å ‡∞®‡∞°‡∞ø‡∞™‡∞ø‡∞®‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å ‡∞µ‡±Ü‡∞®‡±Å‡∞ï‡∞™‡∞ü‡±ç‡∞≤‡±ã ‡∞è‡∞Æ‡∞ø ‡∞ú‡∞∞‡∞ø‡∞ó‡∞ø‡∞Ç‡∞¶‡±ã ‡∞ö‡±Ç‡∞¶‡±ç‡∞¶‡∞æ‡∞Ç:

```python
from transformers import pipeline

classifier = pipeline("sentiment-analysis")
classifier(
    [
        "I've been waiting for a HuggingFace course my whole life.",
        "I hate this so much!",
    ]
)
```

‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞Æ‡∞®‡∞ï‡±Å ‡∞µ‡∞ö‡±ç‡∞ö‡∞ø‡∞® ‡∞´‡∞≤‡∞ø‡∞§‡∞æ‡∞≤‡±Å:

```python out
[{'label': 'POSITIVE', 'score': 0.9598047137260437},
 {'label': 'NEGATIVE', 'score': 0.9994558095932007}]
```

[‡∞Ö‡∞ß‡±ç‡∞Ø‡∞æ‡∞Ø‡∞Ç 1](/course/chapter1)‡∞≤‡±ã ‡∞ö‡±Ç‡∞∂‡∞ø‡∞®‡∞ü‡±ç‡∞≤‡±Å‡∞ó‡∞æ, ‡∞à ‡∞™‡±à‡∞™‡±ç‚Äå‡∞≤‡±à‡∞®‡±ç ‡∞Æ‡±Ç‡∞°‡±Å ‡∞¶‡∞∂‡∞≤‡∞®‡±Å ‡∞ï‡∞≤‡∞ø‡∞™‡∞ø ‡∞Ö‡∞Æ‡∞≤‡±Å ‡∞ö‡±á‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø: ‡∞™‡±ç‡∞∞‡±Ä‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡∞ø‡∞Ç‡∞ó‡±ç, ‡∞á‡∞®‡±ç‚Äå‡∞™‡±Å‡∞ü‡±ç‚Äå‡∞≤‡∞®‡±Å ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞¶‡±ç‡∞µ‡∞æ‡∞∞‡∞æ ‡∞™‡∞Ç‡∞™‡∞ø‡∞Ç‡∞ö‡∞°‡∞Ç, ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞™‡±ã‡∞∏‡±ç‡∞ü‡±ç‚Äå‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡∞ø‡∞Ç‡∞ó‡±ç:

<div class="flex justify-center"> 
<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/full_nlp_pipeline.svg" alt="‡∞™‡±Ç‡∞∞‡±ç‡∞§‡∞ø NLP ‡∞™‡±à‡∞™‡±ç‚Äå‡∞≤‡±à‡∞®‡±ç: ‡∞™‡∞æ‡∞†‡±ç‡∞Ø‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞ü‡±ã‡∞ï‡∞®‡±à‡∞ú‡±ç ‡∞ö‡±á‡∞Ø‡∞°‡∞Ç, IDs‚Äå‡∞ó‡∞æ ‡∞Æ‡∞æ‡∞∞‡±ç‡∞ö‡∞°‡∞Ç, ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞ü‡±ç‡∞∞‡∞æ‡∞®‡±ç‡∞∏‡±ç‚Äå‡∞´‡∞æ‡∞∞‡±ç‡∞Æ‡∞∞‡±ç ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞¶‡±ç‡∞µ‡∞æ‡∞∞‡∞æ ‡∞á‡∞®‡±ç‚Äå‡∞´‡∞∞‡±Ü‡∞®‡±ç‡∞∏‡±ç ‡∞ú‡∞∞‡∞™‡∞°‡∞Ç."/> 
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/full_nlp_pipeline-dark.svg" alt="‡∞™‡±Ç‡∞∞‡±ç‡∞§‡∞ø NLP ‡∞™‡±à‡∞™‡±ç‚Äå‡∞≤‡±à‡∞®‡±ç: ‡∞™‡∞æ‡∞†‡±ç‡∞Ø‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞ü‡±ã‡∞ï‡∞®‡±à‡∞ú‡±ç ‡∞ö‡±á‡∞Ø‡∞°‡∞Ç, IDs‚Äå‡∞ó‡∞æ ‡∞Æ‡∞æ‡∞∞‡±ç‡∞ö‡∞°‡∞Ç, ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞ü‡±ç‡∞∞‡∞æ‡∞®‡±ç‡∞∏‡±ç‚Äå‡∞´‡∞æ‡∞∞‡±ç‡∞Æ‡∞∞‡±ç ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞¶‡±ç‡∞µ‡∞æ‡∞∞‡∞æ ‡∞á‡∞®‡±ç‚Äå‡∞´‡∞∞‡±Ü‡∞®‡±ç‡∞∏‡±ç ‡∞ú‡∞∞‡∞™‡∞°‡∞Ç."/> 
</div>

‡∞á‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å ‡∞à ‡∞¶‡∞∂‡∞≤‡∞®‡±ç‡∞®‡∞ø‡∞Ç‡∞ü‡∞ø‡∞®‡±Ä ‡∞§‡±ç‡∞µ‡∞∞‡∞ó‡∞æ ‡∞™‡∞∞‡∞ø‡∞∂‡±Ä‡∞≤‡∞ø‡∞¶‡±ç‡∞¶‡∞æ‡∞Ç.

## ‡∞ü‡±ã‡∞ï‡∞®‡±à‡∞ú‡∞∞‡±ç‚Äå‡∞§‡±ã ‡∞™‡±ç‡∞∞‡±Ä‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡∞ø‡∞Ç‡∞ó‡±ç[[preprocessing-with-a-tokenizer]]

‡∞á‡∞§‡∞∞ ‡∞®‡±ç‡∞Ø‡±Ç‡∞∞‡∞≤‡±ç ‡∞®‡±Ü‡∞ü‡±ç‚Äå‡∞µ‡∞∞‡±ç‡∞ï‡±ç‚Äå‡∞≤ ‡∞Æ‡∞æ‡∞¶‡∞ø‡∞∞‡∞ø‡∞ó‡∞æ‡∞®‡±á, Transformer ‡∞Æ‡±ã‡∞°‡∞≥‡±ç‡∞≤‡±Å ‡∞∞‡∞æ ‡∞ü‡±Ü‡∞ï‡±ç‡∞∏‡±ç‡∞ü‡±ç‚Äå‡∞®‡±Å ‡∞®‡±á‡∞∞‡±Å‡∞ó‡∞æ ‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡±ç ‡∞ö‡±á‡∞Ø‡∞≤‡±á‡∞µ‡±Å. ‡∞ï‡∞æ‡∞¨‡∞ü‡±ç‡∞ü‡∞ø ‡∞™‡±à‡∞™‡±ç‚Äå‡∞≤‡±à‡∞®‡±ç‚Äå‡∞≤‡±ã ‡∞Æ‡±ä‡∞¶‡∞ü‡∞ø ‡∞¶‡∞∂ ‡∞™‡∞æ‡∞†‡±ç‡∞Ø‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞Ö‡∞∞‡±ç‡∞•‡∞Ç ‡∞ö‡±á‡∞∏‡±Å‡∞ï‡±Å‡∞®‡±á ‡∞∏‡∞Ç‡∞ñ‡±ç‡∞Ø‡∞≤‡±ç‡∞≤‡±ã‡∞ï‡∞ø ‡∞Æ‡∞æ‡∞∞‡±ç‡∞ö‡∞°‡∞Ç. ‡∞¶‡±Ä‡∞®‡∞ø ‡∞ï‡±ã‡∞∏‡∞Ç ‡∞Æ‡∞®‡∞Ç *‡∞ü‡±ã‡∞ï‡∞®‡±à‡∞ú‡∞∞‡±ç* ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞∏‡±ç‡∞§‡∞æ‡∞Æ‡±Å. ‡∞á‡∞¶‡∞ø ‡∞ï‡∞ø‡∞Ç‡∞¶‡∞ø ‡∞™‡∞®‡±Å‡∞≤‡∞ï‡±Å ‡∞¨‡∞æ‡∞ß‡±ç‡∞Ø‡∞§ ‡∞µ‡∞π‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø:

- ‡∞á‡∞®‡±ç‚Äå‡∞™‡±Å‡∞ü‡±ç‚Äå‡∞®‡±Å ‡∞™‡∞¶‡∞æ‡∞≤‡±Å, ‡∞â‡∞™‡∞™‡∞¶‡∞æ‡∞≤‡±Å ‡∞≤‡±á‡∞¶‡∞æ ‡∞ö‡∞ø‡∞π‡±ç‡∞®‡∞æ‡∞≤‡±Å (‡∞â‡∞¶‡∞æ‡∞π‡∞∞‡∞£‡∞ï‡±Å, punctuation)‡∞ó‡∞æ ‡∞µ‡∞ø‡∞≠‡∞ú‡∞ø‡∞Ç‡∞ö‡∞°‡∞Ç ‚Äî ‡∞µ‡±Ä‡∞ü‡∞ø‡∞®‡∞ø *tokens* ‡∞Ö‡∞®‡∞ø ‡∞™‡∞ø‡∞≤‡±Å‡∞∏‡±ç‡∞§‡∞æ‡∞∞‡±Å
- ‡∞™‡±ç‡∞∞‡∞§‡∞ø ‡∞ü‡±ã‡∞ï‡±Ü‡∞®‡±ç‚Äå‡∞®‡±Å ‡∞í‡∞ï integer ‡∞ï‡∞ø ‡∞Æ‡±ç‡∞Ø‡∞æ‡∞™‡±ç ‡∞ö‡±á‡∞Ø‡∞°‡∞Ç
- ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞ï‡±Å ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞™‡∞°‡±á ‡∞Ö‡∞¶‡∞®‡∞™‡±Å ‡∞á‡∞®‡±ç‚Äå‡∞™‡±Å‡∞ü‡±ç‚Äå‡∞≤‡∞®‡±Å ‡∞ú‡±ã‡∞°‡∞ø‡∞Ç‡∞ö‡∞°‡∞Ç

‡∞à ‡∞™‡±ç‡∞∞‡±Ä‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡∞ø‡∞Ç‡∞ó‡±ç ‡∞Æ‡±ä‡∞§‡±ç‡∞§‡∞Ç ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞®‡±Å ‡∞™‡±ç‡∞∞‡±Ä‡∞ü‡±ç‡∞∞‡±Ü‡∞Ø‡∞ø‡∞®‡±ç ‡∞ö‡±á‡∞∏‡∞ø‡∞®‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å ‡∞é‡∞≤‡∞æ ‡∞ú‡∞∞‡∞ø‡∞ó‡∞ø‡∞Ç‡∞¶‡±ã ‡∞Ö‡∞ö‡±ç‡∞ö‡±Å‡∞ó‡±Å‡∞¶‡±ç‡∞¶‡∞ø‡∞®‡∞ü‡±ç‡∞≤‡±Å‡∞ó‡∞æ ‡∞ú‡∞∞‡∞ó‡∞æ‡∞≤‡∞ø. ‡∞Ö‡∞Ç‡∞¶‡±Å‡∞ï‡±á ‡∞Æ‡±Å‡∞Ç‡∞¶‡±Å‡∞ó‡∞æ ‡∞Ü ‡∞∏‡∞Æ‡∞æ‡∞ö‡∞æ‡∞∞‡∞æ‡∞®‡±ç‡∞®‡∞ø [Model Hub](https://huggingface.co/models) ‡∞®‡±Å‡∞Ç‡∞°‡∞ø ‡∞°‡±å‡∞®‡±ç‚Äå‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞∏‡±Å‡∞ï‡±ã‡∞µ‡∞æ‡∞≤‡∞ø. ‡∞¶‡±Ä‡∞®‡∞ø ‡∞ï‡±ã‡∞∏‡∞Ç ‡∞Æ‡∞®‡∞Ç `AutoTokenizer` ‡∞ï‡±ç‡∞≤‡∞æ‡∞∏‡±ç ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞¶‡∞æ‡∞®‡∞ø `from_pretrained()` ‡∞™‡∞¶‡±ç‡∞ß‡∞§‡∞ø‡∞®‡∞ø ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞∏‡±ç‡∞§‡∞æ‡∞Æ‡±Å. ‡∞Æ‡∞® ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞Ø‡±ä‡∞ï‡±ç‡∞ï checkpoint ‡∞™‡±á‡∞∞‡±Å‡∞®‡±Å ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞ø, ‡∞á‡∞¶‡∞ø ‡∞Æ‡±ã‡∞°‡∞≤‡±ç tokenizer ‡∞ï‡±Å ‡∞∏‡∞Ç‡∞¨‡∞Ç‡∞ß‡∞ø‡∞Ç‡∞ö‡∞ø‡∞® ‡∞°‡±á‡∞ü‡∞æ‡∞®‡±Å ‡∞Ü‡∞ü‡±ã‡∞Æ‡±á‡∞ü‡∞ø‡∞ï‡±ç‚Äå‡∞ó‡∞æ ‡∞§‡±Ü‡∞ö‡±ç‡∞ö‡∞ø cache ‡∞≤‡±ã ‡∞≠‡∞¶‡±ç‡∞∞‡∞™‡∞∞‡±Å‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø (‡∞¶‡∞æ‡∞Ç‡∞§‡±ã ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞ï‡±ç‡∞∞‡∞ø‡∞Ç‡∞¶‡∞ø ‡∞ï‡±ã‡∞°‡±ç‚Äå‡∞®‡±Å ‡∞Æ‡±ä‡∞¶‡∞ü‡∞ø‡∞∏‡∞æ‡∞∞‡∞ø ‡∞®‡∞°‡∞ø‡∞™‡∞ø‡∞®‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å ‡∞Æ‡∞æ‡∞§‡±ç‡∞∞‡∞Æ‡±á ‡∞Ö‡∞¶‡∞ø ‡∞°‡±å‡∞®‡±ç‚Äå‡∞≤‡±ã‡∞°‡±ç ‡∞Ö‡∞µ‡±Å‡∞§‡±Å‡∞Ç‡∞¶‡∞ø).

`sentiment-analysis` ‡∞™‡±à‡∞™‡±ç‚Äå‡∞≤‡±à‡∞®‡±ç ‡∞Ø‡±ä‡∞ï‡±ç‡∞ï ‡∞°‡∞ø‡∞´‡∞æ‡∞≤‡±ç‡∞ü‡±ç checkpoint `distilbert-base-uncased-finetuned-sst-2-english` (‡∞¶‡∞æ‡∞®‡∞ø ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞ï‡∞æ‡∞∞‡±ç‡∞°‡±ç‚Äå‡∞®‡±Å [‡∞á‡∞ï‡±ç‡∞ï‡∞°](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english) ‡∞ö‡±Ç‡∞°‡∞µ‡∞ö‡±ç‡∞ö‡±Å). ‡∞ï‡∞æ‡∞¨‡∞ü‡±ç‡∞ü‡∞ø ‡∞Æ‡∞®‡∞Ç ‡∞à ‡∞ï‡±ç‡∞∞‡∞ø‡∞Ç‡∞¶‡∞ø ‡∞ï‡±ã‡∞°‡±ç‚Äå‡∞®‡±Å ‡∞®‡∞°‡±Å‡∞™‡±Å‡∞§‡∞æ‡∞Æ‡±Å:

```python
from transformers import AutoTokenizer

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
```

‡∞ü‡±ã‡∞ï‡∞®‡±à‡∞ú‡∞∞‡±ç ‡∞Æ‡∞®‡∞ï‡±Å ‡∞≤‡∞≠‡∞ø‡∞Ç‡∞ö‡∞ø‡∞® ‡∞§‡∞∞‡±ç‡∞µ‡∞æ‡∞§, ‡∞Æ‡∞®‡∞Ç ‡∞µ‡∞æ‡∞ï‡±ç‡∞Ø‡∞æ‡∞≤‡∞®‡±Å ‡∞®‡±á‡∞∞‡±Å‡∞ó‡∞æ ‡∞¶‡∞æ‡∞®‡∞ø‡∞≤‡±ã‡∞ï‡∞ø ‡∞™‡∞Ç‡∞™‡∞µ‡∞ö‡±ç‡∞ö‡±Å, ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞Ö‡∞¶‡∞ø ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞ï‡±Å ‡∞á‡∞µ‡±ç‡∞µ‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞∏‡∞ø‡∞¶‡±ç‡∞ß‡∞Æ‡±à‡∞® dictionary ‡∞®‡∞ø ‡∞§‡∞ø‡∞∞‡∞ø‡∞ó‡∞ø ‡∞á‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø! ‡∞á‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å ‡∞ö‡±á‡∞Ø‡∞µ‡∞≤‡∞∏‡∞ø‡∞Ç‡∞¶‡∞ø ‡∞í‡∞ï‡±ç‡∞ï‡∞ü‡±á ‡∞â‡∞Ç‡∞¶‡∞ø: input IDs ‡∞≤‡∞ø‡∞∏‡±ç‡∞ü‡±ç‚Äå‡∞®‡±Å tensors ‡∞ó‡∞æ ‡∞Æ‡∞æ‡∞∞‡±ç‡∞ö‡∞°‡∞Ç.

ü§ó Transformers ‡∞®‡±Å ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞ø‡∞®‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å ‡∞è ML framework backend ‡∞ó‡∞æ ‡∞µ‡∞æ‡∞°‡∞¨‡∞°‡±Å‡∞§‡±Å‡∞Ç‡∞¶‡±ã ‡∞ó‡±Å‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞Ü‡∞Ç‡∞¶‡±ã‡∞≥‡∞® ‡∞ö‡±Ü‡∞Ç‡∞¶‡∞æ‡∞≤‡±ç‡∞∏‡∞ø‡∞® ‡∞Ö‡∞µ‡∞∏‡∞∞‡∞Ç ‡∞≤‡±á‡∞¶‡±Å; ‡∞ï‡±ä‡∞®‡±ç‡∞®‡∞ø ‡∞Æ‡±ã‡∞°‡∞≥‡±ç‡∞≤‡∞ï‡±Å ‡∞Ö‡∞¶‡∞ø PyTorch ‡∞ï‡∞æ‡∞µ‡∞ö‡±ç‡∞ö‡±Å ‡∞≤‡±á‡∞¶‡∞æ Flax ‡∞ï‡∞æ‡∞µ‡∞ö‡±ç‡∞ö‡±Å. ‡∞Ö‡∞Ø‡∞ø‡∞§‡±á Transformer ‡∞Æ‡±ã‡∞°‡∞≥‡±ç‡∞≤‡±Å ‡∞ï‡±á‡∞µ‡∞≤‡∞Ç *tensors* ‡∞®‡±á ‡∞á‡∞®‡±ç‚Äå‡∞™‡±Å‡∞ü‡±ç‚Äå‡∞ó‡∞æ ‡∞∏‡±ç‡∞µ‡±Ä‡∞ï‡∞∞‡∞ø‡∞∏‡±ç‡∞§‡∞æ‡∞Ø‡∞ø. ‡∞Æ‡±Ä‡∞∞‡±Å tensors ‡∞ó‡±Å‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞§‡±ä‡∞≤‡∞ø‡∞∏‡∞æ‡∞∞‡∞ø ‡∞µ‡∞ø‡∞Ç‡∞ü‡±Å‡∞Ç‡∞ü‡±á, ‡∞µ‡∞æ‡∞ü‡∞ø‡∞®‡∞ø NumPy arrays ‡∞Æ‡∞æ‡∞¶‡∞ø‡∞∞‡∞ø‡∞ó‡∞æ ‡∞ä‡∞π‡∞ø‡∞Ç‡∞ö‡∞µ‡∞ö‡±ç‡∞ö‡±Å. NumPy array ‡∞í‡∞ï scalar (0D), ‡∞í‡∞ï vector (1D), ‡∞í‡∞ï matrix (2D), ‡∞≤‡±á‡∞¶‡∞æ ‡∞Æ‡∞∞‡∞ø‡∞Ç‡∞§ dimensions ‡∞ï‡∞≤‡∞ø‡∞ó‡∞ø ‡∞â‡∞Ç‡∞°‡∞µ‡∞ö‡±ç‡∞ö‡±Å. ‡∞á‡∞µ‡∞®‡±ç‡∞®‡±Ä tensors ‡∞≤‡∞æ‡∞ó‡∞æ‡∞®‡±á ‡∞™‡∞®‡∞ø‡∞ö‡±á‡∞∏‡±ç‡∞§‡∞æ‡∞Ø‡∞ø; ‡∞á‡∞§‡∞∞ ML frameworks ‡∞≤‡±ã‡∞®‡∞ø tensors ‡∞ï‡±Ç‡∞°‡∞æ ‡∞á‡∞≤‡∞æ‡∞ó‡±á ‡∞™‡±ç‡∞∞‡∞µ‡∞∞‡±ç‡∞§‡∞ø‡∞∏‡±ç‡∞§‡∞æ‡∞Ø‡∞ø, ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞∏‡∞æ‡∞ß‡∞æ‡∞∞‡∞£‡∞Ç‡∞ó‡∞æ NumPy arrays ‡∞®‡±Å ‡∞§‡∞Ø‡∞æ‡∞∞‡±Å ‡∞ö‡±á‡∞∏‡∞ø‡∞®‡∞Ç‡∞§ ‡∞∏‡±Å‡∞≤‡∞≠‡∞Ç‡∞ó‡∞æ‡∞®‡±á ‡∞µ‡∞æ‡∞ü‡∞ø‡∞®‡∞ø ‡∞∏‡±É‡∞∑‡±ç‡∞ü‡∞ø‡∞Ç‡∞ö‡∞µ‡∞ö‡±ç‡∞ö‡±Å.

‡∞Æ‡∞®‡∞ï‡±Å ‡∞§‡∞ø‡∞∞‡∞ø‡∞ó‡∞ø ‡∞∞‡∞æ‡∞µ‡∞≤‡∞∏‡∞ø‡∞® tensor ‡∞∞‡∞ï‡∞æ‡∞®‡±ç‡∞®‡∞ø (PyTorch ‡∞≤‡±á‡∞¶‡∞æ ‡∞∏‡∞æ‡∞ß‡∞æ‡∞∞‡∞£ NumPy) ‡∞®‡∞ø‡∞∞‡±ç‡∞£‡∞Ø‡∞ø‡∞Ç‡∞ö‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø `return_tensors` argument ‡∞®‡±Å ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞∏‡±ç‡∞§‡∞æ‡∞Æ‡±Å:


```python
raw_inputs = [
    "I've been waiting for a HuggingFace course my whole life.",
    "I hate this so much!",
]
inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors="pt")
print(inputs)
```

padding ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å truncation ‡∞ó‡±Å‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞á‡∞™‡±ç‡∞™‡±Å‡∞°‡±á ‡∞Ü‡∞Ç‡∞¶‡±ã‡∞≥‡∞® ‡∞ö‡±Ü‡∞Ç‡∞¶‡∞æ‡∞≤‡±ç‡∞∏‡∞ø‡∞® ‡∞Ö‡∞µ‡∞∏‡∞∞‡∞Ç ‡∞≤‡±á‡∞¶‡±Å; ‡∞µ‡∞æ‡∞ü‡∞ø‡∞®‡∞ø ‡∞§‡∞∞‡±Å‡∞µ‡∞æ‡∞§ ‡∞µ‡∞ø‡∞µ‡∞∞‡∞ø‡∞∏‡±ç‡∞§‡∞æ‡∞Æ‡±Å. ‡∞á‡∞ï‡±ç‡∞ï‡∞° ‡∞ó‡±Å‡∞∞‡±ç‡∞§‡±Å‡∞™‡±Ü‡∞ü‡±ç‡∞ü‡±Å‡∞ï‡±ã‡∞µ‡∞≤‡∞∏‡∞ø‡∞® ‡∞Æ‡±Å‡∞ñ‡±ç‡∞Ø‡∞Æ‡±à‡∞® ‡∞µ‡∞ø‡∞∑‡∞Ø‡∞Æ‡±á‡∞Æ‡∞ø‡∞ü‡∞Ç‡∞ü‡±á: ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞í‡∞ï ‡∞µ‡∞æ‡∞ï‡±ç‡∞Ø‡∞Ç ‡∞≤‡±á‡∞¶‡∞æ ‡∞µ‡∞æ‡∞ï‡±ç‡∞Ø‡∞æ‡∞≤ ‡∞ú‡∞æ‡∞¨‡∞ø‡∞§‡∞æ‡∞®‡±Å ‡∞™‡∞Ç‡∞™‡∞µ‡∞ö‡±ç‡∞ö‡±Å, ‡∞Ö‡∞≤‡∞æ‡∞ó‡±á ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞ï‡∞æ‡∞µ‡∞≤‡∞∏‡∞ø‡∞® tensor ‡∞∞‡∞ï‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞∏‡±Ç‡∞ö‡∞ø‡∞Ç‡∞ö‡∞µ‡∞ö‡±ç‡∞ö‡±Å (‡∞è ‡∞∞‡∞ï‡∞Ç ‡∞∏‡±Ç‡∞ö‡∞ø‡∞Ç‡∞ö‡∞ï‡∞™‡±ã‡∞§‡±á, ‡∞´‡∞≤‡∞ø‡∞§‡∞Ç‡∞ó‡∞æ lists of lists ‡∞µ‡∞∏‡±ç‡∞§‡∞æ‡∞Ø‡∞ø).

‡∞á‡∞ï‡±ç‡∞ï‡∞° PyTorch tensors ‡∞∞‡±Ç‡∞™‡∞Ç‡∞≤‡±ã ‡∞´‡∞≤‡∞ø‡∞§‡∞æ‡∞≤‡±Å ‡∞é‡∞≤‡∞æ ‡∞â‡∞Ç‡∞ü‡∞æ‡∞Ø‡±ã ‡∞ö‡±Ç‡∞°‡∞Ç‡∞°‡∞ø:

```python out
{
    'input_ids': tensor([
        [  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172, 2607,  2026,  2878,  2166,  1012,   102],
        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,     0,     0,     0,     0,     0,     0]
    ]), 
    'attention_mask': tensor([
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]
    ])
}
```

‡∞Ü ‡∞Ö‡∞µ‡±Å‡∞ü‡±ç‚Äå‡∞™‡±Å‡∞ü‡±ç dictionary ‡∞≤‡±ã ‡∞∞‡±Ü‡∞Ç‡∞°‡±Å keys ‡∞â‡∞Ç‡∞ü‡∞æ‡∞Ø‡∞ø: `input_ids` ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å `attention_mask`. `input_ids`‡∞≤‡±ã ‡∞∞‡±Ü‡∞Ç‡∞°‡±Å ‡∞™‡∞Ç‡∞ï‡±ç‡∞§‡±Å‡∞≤ integers ‡∞â‡∞Ç‡∞ü‡∞æ‡∞Ø‡∞ø (‡∞™‡±ç‡∞∞‡∞§‡∞ø ‡∞µ‡∞æ‡∞ï‡±ç‡∞Ø‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞í‡∞ï‡±ç‡∞ï‡∞ü‡∞ø), ‡∞á‡∞µ‡∞ø ‡∞™‡±ç‡∞∞‡∞§‡∞ø ‡∞µ‡∞æ‡∞ï‡±ç‡∞Ø‡∞Ç‡∞≤‡±ã ‡∞â‡∞®‡±ç‡∞® tokens ‡∞ï‡±Å ‡∞™‡±ç‡∞∞‡∞§‡±ç‡∞Ø‡±á‡∞ï‡∞Æ‡±à‡∞® ‡∞ó‡±Å‡∞∞‡±ç‡∞§‡∞ø‡∞Ç‡∞™‡±Å‡∞≤‡±Å. `attention_mask` ‡∞è‡∞Æ‡∞ø‡∞ü‡±ã ‡∞à ‡∞Ö‡∞ß‡±ç‡∞Ø‡∞æ‡∞Ø‡∞Ç‡∞≤‡±ã ‡∞§‡∞∞‡±Å‡∞µ‡∞æ‡∞§ ‡∞µ‡∞ø‡∞µ‡∞∞‡∞ø‡∞∏‡±ç‡∞§‡∞æ‡∞Æ‡±Å.

## ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞¶‡±ç‡∞µ‡∞æ‡∞∞‡∞æ ‡∞™‡∞Ç‡∞™‡∞°‡∞Ç[[going-through-the-model]]

‡∞™‡±ç‡∞∞‡±Ä‡∞ü‡±ç‡∞∞‡±Ü‡∞Ø‡∞ø‡∞®‡±ç ‡∞ö‡±á‡∞∏‡∞ø‡∞® ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞®‡±Å ‡∞ï‡±Ç‡∞°‡∞æ ‡∞Æ‡∞®‡∞Ç ‡∞ü‡±ã‡∞ï‡∞®‡±à‡∞ú‡∞∞‡±ç ‡∞Æ‡∞æ‡∞¶‡∞ø‡∞∞‡∞ø‡∞ó‡∞æ‡∞®‡±á ‡∞°‡±å‡∞®‡±ç‚Äå‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞∏‡±Å‡∞ï‡±ã‡∞µ‡∞ö‡±ç‡∞ö‡±Å. ü§ó Transformers ‡∞≤‡±ã `AutoModel` ‡∞ï‡±ç‡∞≤‡∞æ‡∞∏‡±ç ‡∞â‡∞Ç‡∞¶‡∞ø, ‡∞¶‡±Ä‡∞®‡∞ø‡∞ï‡∞ø ‡∞ï‡±Ç‡∞°‡∞æ `from_pretrained()` ‡∞™‡∞¶‡±ç‡∞ß‡∞§‡∞ø ‡∞â‡∞Ç‡∞¶‡∞ø:

```python
from transformers import AutoModel

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
model = AutoModel.from_pretrained(checkpoint)
```

‡∞à ‡∞ï‡±ã‡∞°‡±ç ‡∞∏‡±ç‡∞®‡∞ø‡∞™‡±Ü‡∞ü‡±ç‚Äå‡∞≤‡±ã, ‡∞Æ‡∞®‡∞Ç ‡∞™‡±à‡∞™‡±ç‚Äå‡∞≤‡±à‡∞®‡±ç‚Äå‡∞≤‡±ã ‡∞Æ‡±Å‡∞Ç‡∞¶‡±á ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞ø‡∞® ‡∞Ö‡∞¶‡±á checkpoint ‡∞®‡±Å ‡∞°‡±å‡∞®‡±ç‚Äå‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞∏‡±Å‡∞ï‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞Æ‡±Å (‡∞Ö‡∞¶‡∞ø ‡∞á‡∞™‡±ç‡∞™‡∞ü‡∞ø‡∞ï‡±á cache ‡∞≤‡±ã ‡∞â‡∞Ç‡∞°‡∞æ‡∞≤‡∞ø) ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞¶‡∞æ‡∞®‡∞ø‡∞§‡±ã ‡∞í‡∞ï model ‡∞®‡±Å ‡∞∏‡±É‡∞∑‡±ç‡∞ü‡∞ø‡∞Ç‡∞ö‡±Å‡∞ï‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞Æ‡±Å.

‡∞à architecture ‡∞ï‡±á‡∞µ‡∞≤‡∞Ç base Transformer ‡∞Æ‡∞æ‡∞°‡±ç‡∞Ø‡±Ç‡∞≤‡±ç‚Äå‡∞®‡±Å ‡∞Æ‡∞æ‡∞§‡±ç‡∞∞‡∞Æ‡±á ‡∞ï‡∞≤‡∞ø‡∞ó‡∞ø ‡∞â‡∞Ç‡∞ü‡±Å‡∞Ç‡∞¶‡∞ø: ‡∞ï‡±ä‡∞®‡±ç‡∞®‡∞ø ‡∞á‡∞®‡±ç‚Äå‡∞™‡±Å‡∞ü‡±ç‚Äå‡∞≤‡±Å ‡∞á‡∞ö‡±ç‡∞ö‡∞ø‡∞®‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å, ‡∞á‡∞¶‡∞ø *hidden states* (‡∞≤‡±á‡∞¶‡∞æ *features*) ‡∞Ö‡∞®‡∞ø ‡∞™‡∞ø‡∞≤‡∞ø‡∞ö‡±á ‡∞Ö‡∞µ‡±Å‡∞ü‡±ç‚Äå‡∞™‡±Å‡∞ü‡±ç‚Äå‡∞≤‡∞®‡±Å ‡∞á‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø. ‡∞™‡±ç‡∞∞‡∞§‡∞ø ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞á‡∞®‡±ç‚Äå‡∞™‡±Å‡∞ü‡±ç‚Äå‡∞ï‡±Å, Transformer ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞¶‡∞æ‡∞®‡∞ø ‡∞™‡±à ‡∞â‡∞®‡±ç‡∞® **contextual understanding** ‡∞®‡±Å ‡∞™‡±ç‡∞∞‡∞§‡∞ø‡∞¨‡∞ø‡∞Ç‡∞¨‡∞ø‡∞Ç‡∞ö‡±á ‡∞í‡∞ï high-dimensional ‡∞µ‡±Ü‡∞ï‡±ç‡∞ü‡∞∞‡±ç ‡∞≤‡∞≠‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø.

‡∞á‡∞¶‡∞ø ‡∞á‡∞™‡±ç‡∞™‡±Å‡∞°‡±á ‡∞™‡±Ç‡∞∞‡±ç‡∞§‡∞ø‡∞ó‡∞æ ‡∞Ö‡∞∞‡±ç‡∞•‡∞Ç ‡∞ï‡∞æ‡∞ï‡∞™‡±ã‡∞§‡±á ‡∞Ü‡∞Ç‡∞¶‡±ã‡∞≥‡∞® ‡∞ö‡±Ü‡∞Ç‡∞¶‡∞ï‡∞Ç‡∞°‡∞ø. ‡∞¶‡±Ä‡∞®‡±ç‡∞®‡∞ø ‡∞§‡∞∞‡±Å‡∞µ‡∞æ‡∞§ ‡∞µ‡∞ø‡∞™‡±Å‡∞≤‡∞Ç‡∞ó‡∞æ ‡∞µ‡∞ø‡∞µ‡∞∞‡∞ø‡∞∏‡±ç‡∞§‡∞æ‡∞Æ‡±Å.

‡∞à hidden states ‡∞ï‡±ä‡∞®‡±ç‡∞®‡∞ø ‡∞∏‡∞Ç‡∞¶‡∞∞‡±ç‡∞≠‡∞æ‡∞≤‡±ç‡∞≤‡±ã ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ï‡∞∞‡∞Ç‡∞ó‡∞æ ‡∞â‡∞Ç‡∞°‡∞µ‡∞ö‡±ç‡∞ö‡±Å, ‡∞ï‡∞æ‡∞®‡±Ä ‡∞Ö‡∞µ‡∞ø ‡∞∏‡∞æ‡∞ß‡∞æ‡∞∞‡∞£‡∞Ç‡∞ó‡∞æ ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞≤‡±ã‡∞®‡∞ø ‡∞Æ‡∞∞‡±ã ‡∞≠‡∞æ‡∞ó‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‚Äî *head* ‚Äî ‡∞ï‡±Å ‡∞á‡∞®‡±ç‚Äå‡∞™‡±Å‡∞ü‡±ç ‡∞Ö‡∞µ‡±Å‡∞§‡∞æ‡∞Ø‡∞ø. [‡∞Ö‡∞ß‡±ç‡∞Ø‡∞æ‡∞Ø‡∞Ç 1](/course/chapter1)‡∞≤‡±ã ‡∞ö‡±Ç‡∞∂‡∞ø‡∞®‡∞ü‡±ç‡∞≤‡±Å‡∞ó‡∞æ, ‡∞µ‡±á‡∞∞‡±ç‡∞µ‡±á‡∞∞‡±Å ‡∞™‡∞®‡±Å‡∞≤‡±Å ‡∞í‡∞ï‡±á architecture ‡∞§‡±ã ‡∞ö‡±á‡∞Ø‡∞µ‡∞ö‡±ç‡∞ö‡±Å, ‡∞ï‡∞æ‡∞®‡±Ä ‡∞™‡±ç‡∞∞‡∞§‡∞ø task ‡∞ï‡±Å ‡∞µ‡±á‡∞∞‡±ç‡∞µ‡±á‡∞∞‡±Å head ‡∞â‡∞Ç‡∞ü‡±Å‡∞Ç‡∞¶‡∞ø.

### ‡∞π‡±à-‡∞°‡±à‡∞Æ‡±Ü‡∞®‡±ç‡∞∑‡∞®‡∞≤‡±ç ‡∞µ‡±Ü‡∞ï‡±ç‡∞ü‡∞∞‡±ç?[[a-high-dimensional-vector]]

Transformer module ‡∞®‡±Å‡∞Ç‡∞ö‡∞ø ‡∞µ‡∞ö‡±ç‡∞ö‡±á ‡∞µ‡±Ü‡∞ï‡±ç‡∞ü‡∞∞‡±ç ‡∞∏‡∞æ‡∞ß‡∞æ‡∞∞‡∞£‡∞Ç‡∞ó‡∞æ ‡∞™‡±Ü‡∞¶‡±ç‡∞¶‡∞¶‡±á. ‡∞¶‡±Ä‡∞®‡∞ø‡∞ï‡∞ø ‡∞Æ‡±Ç‡∞°‡±Å ‡∞™‡∞∞‡∞ø‡∞Æ‡∞æ‡∞£‡∞æ‡∞≤‡±Å ‡∞â‡∞Ç‡∞ü‡∞æ‡∞Ø‡∞ø:

- **Batch size** (‡∞¨‡±ç‡∞Ø‡∞æ‡∞ö‡±ç ‡∞™‡∞∞‡∞ø‡∞Æ‡∞æ‡∞£‡∞Ç): ‡∞í‡∞ï‡±á‡∞∏‡∞æ‡∞∞‡∞ø ‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡±ç ‡∞ö‡±á‡∞∏‡±á ‡∞∏‡±Ä‡∞ï‡±ç‡∞µ‡±Ü‡∞®‡±ç‡∞∏‡±ç‚Äå‡∞≤ ‡∞∏‡∞Ç‡∞ñ‡±ç‡∞Ø (‡∞Æ‡∞® ‡∞â‡∞¶‡∞æ‡∞π‡∞∞‡∞£‡∞≤‡±ã 2).  
- **Sequence length** (‡∞∏‡±Ä‡∞ï‡±ç‡∞µ‡±Ü‡∞®‡±ç‡∞∏‡±ç ‡∞™‡±ä‡∞°‡∞µ‡±Å): ‡∞™‡±ç‡∞∞‡∞§‡∞ø ‡∞∏‡±Ä‡∞ï‡±ç‡∞µ‡±Ü‡∞®‡±ç‡∞∏‡±ç‚Äå‡∞ï‡±Å ‡∞∏‡∞Ç‡∞¨‡∞Ç‡∞ß‡∞ø‡∞Ç‡∞ö‡∞ø‡∞® ‡∞∏‡∞Ç‡∞ñ‡±ç‡∞Ø‡∞æ‡∞§‡±ç‡∞Æ‡∞ï ‡∞™‡±ç‡∞∞‡∞§‡∞ø‡∞®‡∞ø‡∞ß‡∞ø ‡∞Ø‡±ä‡∞ï‡±ç‡∞ï ‡∞™‡±ä‡∞°‡∞µ‡±Å (‡∞Æ‡∞® ‡∞â‡∞¶‡∞æ‡∞π‡∞∞‡∞£‡∞≤‡±ã 16).  
- **Hidden size** (‡∞π‡∞ø‡∞°‡±Ü‡∞®‡±ç ‡∞™‡∞∞‡∞ø‡∞Æ‡∞æ‡∞£‡∞Ç): ‡∞™‡±ç‡∞∞‡∞§‡∞ø ‡∞á‡∞®‡±ç‚Äå‡∞™‡±Å‡∞ü‡±ç ‡∞ü‡±ã‡∞ï‡±Ü‡∞®‡±ç‚Äå‡∞ï‡∞ø ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞â‡∞§‡±ç‡∞™‡∞§‡±ç‡∞§‡∞ø ‡∞ö‡±á‡∞∏‡±á ‡∞µ‡±Ü‡∞ï‡±ç‡∞ü‡∞∞‡±ç ‡∞Ø‡±ä‡∞ï‡±ç‡∞ï ‡∞°‡±à‡∞Æ‡±Ü‡∞®‡±ç‡∞∑‡∞®‡±ç.

‡∞à ‡∞ö‡∞ø‡∞µ‡∞∞‡∞ø ‡∞µ‡∞ø‡∞≤‡±Å‡∞µ ‡∞ï‡∞æ‡∞∞‡∞£‡∞Ç‡∞ó‡∞æ ‡∞¶‡±Ä‡∞®‡∞ø‡∞®‡∞ø "high dimensional" ‡∞Ö‡∞Ç‡∞ü‡∞æ‡∞∞‡±Å. ‡∞ö‡∞ø‡∞®‡±ç‡∞® ‡∞Æ‡±ã‡∞°‡∞≥‡±ç‡∞≤‡∞≤‡±ã hidden size 768‡∞ó‡∞æ ‡∞â‡∞Ç‡∞ü‡±Å‡∞Ç‡∞¶‡∞ø; ‡∞™‡±Ü‡∞¶‡±ç‡∞¶ ‡∞Æ‡±ã‡∞°‡∞≥‡±ç‡∞≤‡∞≤‡±ã ‡∞á‡∞¶‡∞ø 3072 ‡∞≤‡±á‡∞¶‡∞æ ‡∞Ö‡∞Ç‡∞§‡∞ï‡∞Ç‡∞ü‡±á ‡∞é‡∞ï‡±ç‡∞ï‡±Å‡∞µ ‡∞ï‡∞æ‡∞µ‡∞ö‡±ç‡∞ö‡±Å.


‡∞Æ‡∞®‡∞Æ‡±Å ‡∞™‡±ç‡∞∞‡±Ä‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡±ç ‡∞ö‡±á‡∞∏‡∞ø‡∞® ‡∞á‡∞®‡±ç‚Äå‡∞™‡±Å‡∞ü‡±ç‚Äå‡∞≤‡∞®‡±Å ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞≤‡±ã‡∞ï‡∞ø ‡∞™‡∞Ç‡∞™‡∞ø‡∞§‡±á ‡∞á‡∞¶‡∞ø ‡∞∏‡±ç‡∞™‡∞∑‡±ç‡∞ü‡∞Ç‡∞ó‡∞æ ‡∞ï‡∞®‡∞ø‡∞™‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø:

```python
outputs = model(**inputs)
print(outputs.last_hidden_state.shape)
```

```python out
torch.Size([2, 16, 768])
```

ü§ó Transformers ‡∞Æ‡±ã‡∞°‡∞≥‡±ç‡∞≤ ‡∞Ö‡∞µ‡±Å‡∞ü‡±ç‚Äå‡∞™‡±Å‡∞ü‡±ç‚Äå‡∞≤‡±Å `namedtuple`s ‡∞≤‡±á‡∞¶‡∞æ dictionaries ‡∞≤‡∞æ‡∞ó‡∞æ ‡∞™‡±ç‡∞∞‡∞µ‡∞∞‡±ç‡∞§‡∞ø‡∞∏‡±ç‡∞§‡∞æ‡∞Ø‡∞ø. ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞µ‡∞æ‡∞ü‡∞ø‡∞®‡∞ø attributes ‡∞¶‡±ç‡∞µ‡∞æ‡∞∞‡∞æ (‡∞Æ‡∞®‡∞Æ‡±Å ‡∞ö‡±á‡∞∏‡∞ø‡∞®‡∞ü‡±ç‡∞≤‡±Å‡∞ó‡∞æ), ‡∞≤‡±á‡∞¶‡∞æ key (`outputs["last_hidden_state"]`), ‡∞≤‡±á‡∞¶‡∞æ index ‡∞¶‡±ç‡∞µ‡∞æ‡∞∞‡∞æ (`outputs[0]`) ‡∞ï‡±Ç‡∞°‡∞æ ‡∞Ø‡∞æ‡∞ï‡±ç‡∞∏‡±Ü‡∞∏‡±ç ‡∞ö‡±á‡∞Ø‡∞µ‡∞ö‡±ç‡∞ö‡±Å.

### ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞π‡±Ü‡∞°‡±ç‚Äå‡∞≤‡±Å: ‡∞∏‡∞Ç‡∞ñ‡±ç‡∞Ø‡∞≤‡∞ï‡±Å ‡∞Ö‡∞∞‡±ç‡∞•‡∞Ç ‡∞ö‡±Ü‡∞™‡±ç‡∞™‡∞°‡∞Ç[[model-heads-making-sense-out-of-numbers]]

‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞π‡±Ü‡∞°‡±ç‚Äå‡∞≤‡±Å hidden states ‡∞Ö‡∞®‡±á ‡∞π‡±à-‡∞°‡±à‡∞Æ‡±Ü‡∞®‡±ç‡∞∑‡∞®‡∞≤‡±ç ‡∞µ‡±Ü‡∞ï‡±ç‡∞ü‡∞∞‡±ç‡∞≤‡∞®‡±Å ‡∞§‡±Ä‡∞∏‡±Å‡∞ï‡±Å‡∞®‡∞ø ‡∞µ‡∞æ‡∞ü‡∞ø‡∞®‡∞ø ‡∞µ‡±á‡∞∞‡±á ‡∞°‡±à‡∞Æ‡±Ü‡∞®‡±ç‡∞∑‡∞®‡±ç‚Äå‡∞ï‡∞ø ‡∞™‡±ç‡∞∞‡∞æ‡∞ú‡±Ü‡∞ï‡±ç‡∞ü‡±ç ‡∞ö‡±á‡∞∏‡±ç‡∞§‡∞æ‡∞Ø‡∞ø. ‡∞á‡∞µ‡∞ø ‡∞∏‡∞æ‡∞ß‡∞æ‡∞∞‡∞£‡∞Ç‡∞ó‡∞æ ‡∞í‡∞ï‡∞ü‡∞ø ‡∞≤‡±á‡∞¶‡∞æ ‡∞ï‡±ä‡∞®‡±ç‡∞®‡∞ø ‡∞≤‡±Ä‡∞®‡∞ø‡∞Ø‡∞∞‡±ç ‡∞≤‡±á‡∞Ø‡∞∞‡±ç‚Äå‡∞≤‡∞§‡±ã ‡∞∞‡±Ç‡∞™‡±ä‡∞Ç‡∞¶‡±Å‡∞§‡∞æ‡∞Ø‡∞ø:

<div class="flex justify-center">
<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/transformer_and_head.svg" alt="Transformer ‡∞®‡±Ü‡∞ü‡±ç‚Äå‡∞µ‡∞∞‡±ç‡∞ï‡±ç ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞¶‡∞æ‡∞®‡∞ø ‡∞π‡±Ü‡∞°‡±ç."/>
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/transformer_and_head-dark.svg" alt="Transformer ‡∞®‡±Ü‡∞ü‡±ç‚Äå‡∞µ‡∞∞‡±ç‡∞ï‡±ç ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞¶‡∞æ‡∞®‡∞ø ‡∞π‡±Ü‡∞°‡±ç."/>
</div>

Transformer ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞Ø‡±ä‡∞ï‡±ç‡∞ï ‡∞Ö‡∞µ‡±Å‡∞ü‡±ç‚Äå‡∞™‡±Å‡∞ü‡±ç ‡∞®‡±á‡∞∞‡±Å‡∞ó‡∞æ ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞π‡±Ü‡∞°‡±ç‚Äå‡∞ï‡±Å ‡∞™‡∞Ç‡∞™‡∞¨‡∞°‡±Å‡∞§‡±Å‡∞Ç‡∞¶‡∞ø, ‡∞Ö‡∞ï‡±ç‡∞ï‡∞° ‡∞Ö‡∞¶‡∞ø ‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡±ç ‡∞ö‡±á‡∞Ø‡∞¨‡∞°‡±Å‡∞§‡±Å‡∞Ç‡∞¶‡∞ø.

‡∞à ‡∞ö‡∞ø‡∞§‡±ç‡∞∞‡∞Ç‡∞≤‡±ã, ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞§‡∞® embeddings layer ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞¶‡∞æ‡∞®‡∞ø ‡∞§‡∞∞‡±ç‡∞µ‡∞æ‡∞§‡∞ø ‡∞≤‡±á‡∞Ø‡∞∞‡±ç‚Äå‡∞≤‡∞§‡±ã ‡∞ö‡±Ç‡∞™‡∞¨‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø. Embeddings layer ‡∞ü‡±ã‡∞ï‡∞®‡±à‡∞ú‡±ç ‡∞ö‡±á‡∞∏‡∞ø‡∞® ‡∞á‡∞®‡±ç‚Äå‡∞™‡±Å‡∞ü‡±ç‚Äå‡∞≤‡±ã‡∞®‡∞ø ‡∞™‡±ç‡∞∞‡∞§‡∞ø input ID ‡∞®‡±Å, ‡∞¶‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞∏‡∞∞‡∞ø‡∞™‡∞°‡±á token ‡∞®‡±Å ‡∞™‡±ç‡∞∞‡∞§‡∞ø‡∞®‡∞ø‡∞ß‡±ç‡∞Ø‡∞Ç ‡∞ö‡±á‡∞∏‡±á ‡∞í‡∞ï ‡∞µ‡±Ü‡∞ï‡±ç‡∞ü‡∞∞‡±ç‚Äå‡∞ó‡∞æ ‡∞Æ‡∞æ‡∞∞‡±Å‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø. ‡∞Ü ‡∞§‡∞∞‡±ç‡∞µ‡∞æ‡∞§‡∞ø ‡∞≤‡±á‡∞Ø‡∞∞‡±ç‚Äå‡∞≤‡±Å attention mechanism ‡∞®‡±Å ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞Ü ‡∞µ‡±Ü‡∞ï‡±ç‡∞ü‡∞∞‡±ç‚Äå‡∞≤‡∞®‡±Å ‡∞Æ‡∞æ‡∞∞‡±ç‡∞ö‡∞ø, ‡∞µ‡∞æ‡∞ï‡±ç‡∞Ø‡∞æ‡∞≤ ‡∞Ø‡±ä‡∞ï‡±ç‡∞ï ‡∞§‡±Å‡∞¶‡∞ø ‡∞™‡±ç‡∞∞‡∞§‡∞ø‡∞®‡∞ø‡∞ß‡∞ø‡∞®‡∞ø ‡∞§‡∞Ø‡∞æ‡∞∞‡±Å ‡∞ö‡±á‡∞∏‡±ç‡∞§‡∞æ‡∞Ø‡∞ø.

ü§ó Transformers ‡∞≤‡±ã ‡∞Ö‡∞®‡±á‡∞ï ‡∞µ‡∞ø‡∞≠‡∞ø‡∞®‡±ç‡∞® architectures ‡∞â‡∞®‡±ç‡∞®‡∞æ‡∞Ø‡∞ø, ‡∞™‡±ç‡∞∞‡∞§‡∞ø ‡∞í‡∞ï‡±ç‡∞ï‡∞ü‡∞ø ‡∞í‡∞ï ‡∞®‡∞ø‡∞∞‡±ç‡∞¶‡∞ø‡∞∑‡±ç‡∞ü ‡∞™‡∞®‡∞ø‡∞®‡∞ø ‡∞™‡∞∞‡∞ø‡∞∑‡±ç‡∞ï‡∞∞‡∞ø‡∞Ç‡∞ö‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞∞‡±Ç‡∞™‡±ä‡∞Ç‡∞¶‡∞ø ‡∞â‡∞Ç‡∞ü‡±Å‡∞Ç‡∞¶‡∞ø. ‡∞á‡∞µ‡∞ø ‡∞ï‡±ä‡∞®‡±ç‡∞®‡∞ø ‡∞â‡∞¶‡∞æ‡∞π‡∞∞‡∞£‡∞≤‡±Å:

- `*Model` (hidden states ‡∞®‡±Å ‡∞™‡±ä‡∞Ç‡∞¶‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø)
- `*ForCausalLM`
- `*ForMaskedLM`
- `*ForMultipleChoice`
- `*ForQuestionAnswering`
- `*ForSequenceClassification`
- `*ForTokenClassification`
- ‡∞á‡∞Ç‡∞ï‡∞æ ‡∞Æ‡∞∞‡±Ü‡∞®‡±ç‡∞®‡±ã ü§ó

‡∞Æ‡∞® ‡∞â‡∞¶‡∞æ‡∞π‡∞∞‡∞£‡∞≤‡±ã, ‡∞µ‡∞æ‡∞ï‡±ç‡∞Ø‡∞æ‡∞≤‡±Å positive ‡∞≤‡±á‡∞¶‡∞æ negative ‡∞Ö‡∞®‡∞ø ‡∞µ‡∞∞‡±ç‡∞ó‡±Ä‡∞ï‡∞∞‡∞ø‡∞Ç‡∞ö‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø sequence classification head ‡∞ï‡∞≤‡∞ø‡∞ó‡∞ø‡∞® ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞Ö‡∞µ‡∞∏‡∞∞‡∞Ç. ‡∞Ö‡∞Ç‡∞¶‡±Å‡∞µ‡∞≤‡±ç‡∞≤ ‡∞Æ‡∞®‡∞Ç `AutoModel` ‡∞®‡±Å ‡∞ï‡∞æ‡∞ï‡±Å‡∞Ç‡∞°‡∞æ `AutoModelForSequenceClassification` ‡∞®‡±Å ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞∏‡±ç‡∞§‡∞æ‡∞Æ‡±Å:

```python
from transformers import AutoModelForSequenceClassification

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
model = AutoModelForSequenceClassification.from_pretrained(checkpoint)
outputs = model(**inputs)
```

‡∞á‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å ‡∞Æ‡∞®‡∞Ç ‡∞Ö‡∞µ‡±Å‡∞ü‡±ç‚Äå‡∞™‡±Å‡∞ü‡±ç ‡∞Ø‡±ä‡∞ï‡±ç‡∞ï shape ‡∞®‡±Å ‡∞ö‡±Ç‡∞°‡∞ó‡∞æ, dimensionality ‡∞ö‡∞æ‡∞≤‡∞æ ‡∞§‡∞ï‡±ç‡∞ï‡±Å‡∞µ‡∞ó‡∞æ ‡∞â‡∞Ç‡∞ü‡±Å‡∞Ç‡∞¶‡∞ø: ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞π‡±Ü‡∞°‡±ç, ‡∞Æ‡±Å‡∞Ç‡∞¶‡±Å‡∞ó‡∞æ ‡∞ö‡±Ç‡∞∏‡∞ø‡∞® ‡∞π‡±à-‡∞°‡±à‡∞Æ‡±Ü‡∞®‡±ç‡∞∑‡∞®‡∞≤‡±ç ‡∞µ‡±Ü‡∞ï‡±ç‡∞ü‡∞∞‡±ç‡∞≤‡∞®‡±Å ‡∞§‡±Ä‡∞∏‡±Å‡∞ï‡±Å‡∞®‡∞ø, ‡∞™‡±ç‡∞∞‡∞§‡∞ø ‡∞≤‡±á‡∞¨‡±Å‡∞≤‡±ç‚Äå‡∞ï‡∞ø ‡∞í‡∞ï‡∞ü‡∞ø ‡∞ö‡±ä‡∞™‡±ç‡∞™‡±Å‡∞® ‡∞∞‡±Ü‡∞Ç‡∞°‡±Å ‡∞µ‡∞ø‡∞≤‡±Å‡∞µ‡∞≤‡∞®‡±Å ‡∞ï‡∞≤‡∞ø‡∞ó‡∞ø‡∞® ‡∞µ‡±Ü‡∞ï‡±ç‡∞ü‡∞∞‡±ç‡∞≤‡∞®‡±Å ‡∞â‡∞§‡±ç‡∞™‡∞§‡±ç‡∞§‡∞ø ‡∞ö‡±á‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø:

```python
print(outputs.logits.shape)
```

```python out
torch.Size([2, 2])
```

‡∞Æ‡∞®‡∞ï‡±Å ‡∞∞‡±Ü‡∞Ç‡∞°‡±Å ‡∞µ‡∞æ‡∞ï‡±ç‡∞Ø‡∞æ‡∞≤‡±Å ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞∞‡±Ü‡∞Ç‡∞°‡±Å ‡∞≤‡±á‡∞¨‡±Å‡∞≤‡±ç‡∞∏‡±ç ‡∞â‡∞®‡±ç‡∞®‡∞Ç‡∞¶‡±Å‡∞®, ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞á‡∞µ‡±ç‡∞µ‡∞¨‡∞°‡±á ‡∞´‡∞≤‡∞ø‡∞§‡∞Ç 2 x 2 ‡∞Ü‡∞ï‡∞æ‡∞∞‡∞Ç‡∞≤‡±ã ‡∞â‡∞Ç‡∞ü‡±Å‡∞Ç‡∞¶‡∞ø.

## ‡∞Ö‡∞µ‡±Å‡∞ü‡±ç‚Äå‡∞™‡±Å‡∞ü‡±ç‚Äå‡∞®‡±Å ‡∞™‡±ã‡∞∏‡±ç‡∞ü‡±ç‚Äå‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡∞ø‡∞Ç‡∞ó‡±ç ‡∞ö‡±á‡∞Ø‡∞°‡∞Ç[[postprocessing-the-output]]

‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞®‡±Å‡∞Ç‡∞°‡∞ø ‡∞µ‡∞ö‡±ç‡∞ö‡±á ‡∞Ö‡∞µ‡±Å‡∞ü‡±ç‚Äå‡∞™‡±Å‡∞ü‡±ç ‡∞µ‡∞ø‡∞≤‡±Å‡∞µ‡∞≤‡±Å ‡∞∏‡±ç‡∞µ‡∞§‡∞π‡∞æ‡∞ó‡∞æ ‡∞Ö‡∞∞‡±ç‡∞•‡∞Æ‡∞Ø‡±ç‡∞Ø‡±á ‡∞µ‡∞ø‡∞ß‡∞Ç‡∞ó‡∞æ ‡∞â‡∞Ç‡∞°‡∞ï‡∞™‡±ã‡∞µ‡∞ö‡±ç‡∞ö‡±Å. ‡∞í‡∞ï‡∞∏‡∞æ‡∞∞‡∞ø ‡∞ö‡±Ç‡∞¶‡±ç‡∞¶‡∞æ‡∞Ç:

```python
print(outputs.logits)
```

```python out
tensor([[-1.5607,  1.6123],
        [ 4.1692, -3.3464]], grad_fn=<AddmmBackward>)
```

‡∞Æ‡∞® ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞Æ‡±ä‡∞¶‡∞ü‡∞ø ‡∞µ‡∞æ‡∞ï‡±ç‡∞Ø‡∞æ‡∞®‡∞ø‡∞ï‡∞ø `[-1.5607, 1.6123]` ‡∞®‡±Å, ‡∞∞‡±Ü‡∞Ç‡∞°‡∞µ ‡∞µ‡∞æ‡∞ï‡±ç‡∞Ø‡∞æ‡∞®‡∞ø‡∞ï‡∞ø `[ 4.1692, -3.3464]` ‡∞®‡±Å ‡∞Ö‡∞Ç‡∞ö‡∞®‡∞æ ‡∞µ‡±á‡∞∏‡∞ø‡∞Ç‡∞¶‡∞ø. ‡∞á‡∞µ‡∞ø probabilities ‡∞ï‡∞æ‡∞µ‡±Å ‚Äî ‡∞á‡∞µ‡∞ø *logits*, ‡∞Ö‡∞Ç‡∞ü‡±á ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞ö‡∞ø‡∞µ‡∞∞‡∞ø ‡∞≤‡±á‡∞Ø‡∞∞‡±ç ‡∞â‡∞§‡±ç‡∞™‡∞§‡±ç‡∞§‡∞ø ‡∞ö‡±á‡∞∏‡±á raw, unnormalized ‡∞∏‡±ç‡∞ï‡±ã‡∞∞‡±ç‡∞≤‡±Å. ‡∞á‡∞µ‡∞ø probabilities‚Äå ‡∞ó‡∞æ ‡∞Æ‡∞æ‡∞∞‡∞æ‡∞≤‡∞Ç‡∞ü‡±á [SoftMax](https://en.wikipedia.org/wiki/Softmax_function) ‡∞≤‡±á‡∞Ø‡∞∞‡±ç ‡∞¶‡±ç‡∞µ‡∞æ‡∞∞‡∞æ ‡∞™‡∞Ç‡∞™‡∞æ‡∞≤‡∞ø.  
(‡∞Ö‡∞®‡±ç‡∞®‡∞ø ü§ó Transformers ‡∞Æ‡±ã‡∞°‡∞≥‡±ç‡∞≤‡±Å logits ‡∞®‡±Å Ï∂úÎ†• ‡∞ö‡±á‡∞∏‡±ç‡∞§‡∞æ‡∞Ø‡∞ø, ‡∞é‡∞Ç‡∞¶‡±Å‡∞ï‡∞Ç‡∞ü‡±á ‡∞ü‡±ç‡∞∞‡±à‡∞®‡∞ø‡∞Ç‡∞ó‡±ç‚Äå‡∞≤‡±ã loss function ‡∞∏‡∞æ‡∞ß‡∞æ‡∞∞‡∞£‡∞Ç‡∞ó‡∞æ SoftMax ‡∞µ‡∞Ç‡∞ü‡∞ø ‡∞ö‡∞ø‡∞µ‡∞∞‡∞ø activation ‡∞®‡±Å cross-entropy ‡∞µ‡∞Ç‡∞ü‡∞ø loss ‡∞§‡±ã ‡∞ï‡∞≤‡∞ø‡∞™‡∞ø ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø.)

```py
import torch

predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
print(predictions)
```

```python out
tensor([[4.0195e-02, 9.5980e-01],
        [9.9946e-01, 5.4418e-04]], grad_fn=<SoftmaxBackward>)
```

‡∞á‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å ‡∞Æ‡∞®‡∞ï‡±Å ‡∞∏‡±ç‡∞™‡∞∑‡±ç‡∞ü‡∞Ç‡∞ó‡∞æ ‡∞ï‡∞®‡∞ø‡∞™‡∞ø‡∞∏‡±ç‡∞§‡±ã‡∞Ç‡∞¶‡∞ø: ‡∞Æ‡±ä‡∞¶‡∞ü‡∞ø ‡∞µ‡∞æ‡∞ï‡±ç‡∞Ø‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞Æ‡±ã‡∞°‡∞≤‡±ç `[0.0402, 0.9598]`, ‡∞∞‡±Ü‡∞Ç‡∞°‡∞µ ‡∞µ‡∞æ‡∞ï‡±ç‡∞Ø‡∞æ‡∞®‡∞ø‡∞ï‡∞ø `[0.9995, 0.0005]` probabilities ‡∞®‡±Å ‡∞á‡∞ö‡±ç‡∞ö‡∞ø‡∞Ç‡∞¶‡∞ø. ‡∞á‡∞µ‡∞ø ‡∞Ö‡∞∞‡±ç‡∞•‡∞Æ‡∞Ø‡±ç‡∞Ø‡±á probability ‡∞∏‡±ç‡∞ï‡±ã‡∞∞‡±ç‡∞≤‡±Å.

‡∞™‡±ç‡∞∞‡∞§‡∞ø ‡∞∏‡±ç‡∞•‡∞æ‡∞®‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞∏‡∞Ç‡∞¨‡∞Ç‡∞ß‡∞ø‡∞Ç‡∞ö‡∞ø‡∞® ‡∞≤‡±á‡∞¨‡±Å‡∞≥‡±ç‡∞≤‡∞®‡±Å ‡∞§‡±Ü‡∞≤‡±Å‡∞∏‡±Å‡∞ï‡±ã‡∞µ‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø, ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞Ø‡±ä‡∞ï‡±ç‡∞ï config ‡∞≤‡±ã‡∞®‡∞ø `id2label` ‡∞≤‡∞ï‡±ç‡∞∑‡∞£‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞ö‡±Ç‡∞°‡∞µ‡∞ö‡±ç‡∞ö‡±Å (‡∞¶‡±Ä‡∞®‡∞ø ‡∞ó‡±Å‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞§‡∞∞‡±Å‡∞µ‡∞æ‡∞§‡∞ø ‡∞µ‡∞ø‡∞≠‡∞æ‡∞ó‡∞Ç‡∞≤‡±ã ‡∞Æ‡∞∞‡∞ø‡∞Ç‡∞§ ‡∞§‡±Ü‡∞≤‡±Å‡∞∏‡±Å‡∞ï‡±Å‡∞Ç‡∞ü‡∞æ‡∞Æ‡±Å):

```python
model.config.id2label
```

```python out
{0: 'NEGATIVE', 1: 'POSITIVE'}
```

‡∞á‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å ‡∞Æ‡∞®‡∞Ç ‡∞à ‡∞µ‡∞ø‡∞ß‡∞Ç‡∞ó‡∞æ ‡∞®‡∞ø‡∞∞‡±ç‡∞£‡∞Ø‡∞ø‡∞Ç‡∞ö‡∞µ‡∞ö‡±ç‡∞ö‡±Å:
 
- ‡∞Æ‡±ä‡∞¶‡∞ü‡∞ø ‡∞µ‡∞æ‡∞ï‡±ç‡∞Ø‡∞Ç: NEGATIVE: 0.0402, POSITIVE: 0.9598
- ‡∞∞‡±Ü‡∞Ç‡∞°‡∞µ ‡∞µ‡∞æ‡∞ï‡±ç‡∞Ø‡∞Ç: NEGATIVE: 0.9995, POSITIVE: 0.0005

‡∞á‡∞≤‡∞æ ‡∞Æ‡∞®‡∞Ç ‡∞™‡±à‡∞™‡±ç‚Äå‡∞≤‡±à‡∞®‡±ç‚Äå‡∞≤‡±ã‡∞®‡∞ø ‡∞Æ‡±Ç‡∞°‡±Å ‡∞¶‡∞∂‡∞≤‡∞®‡±Å ‡∞µ‡∞ø‡∞ú‡∞Ø‡∞µ‡∞Ç‡∞§‡∞Ç‡∞ó‡∞æ ‡∞™‡±Å‡∞®‡∞∞‡±Å‡∞¶‡±ç‡∞ß‡∞∞‡∞ø‡∞Ç‡∞ö‡∞æ‡∞Æ‡±Å: ‡∞ü‡±ã‡∞ï‡∞®‡±à‡∞ú‡∞∞‡±ç‚Äå‡∞§‡±ã ‡∞™‡±ç‡∞∞‡±Ä‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡∞ø‡∞Ç‡∞ó‡±ç, ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞¶‡±ç‡∞µ‡∞æ‡∞∞‡∞æ ‡∞™‡∞Ç‡∞™‡∞ø‡∞Ç‡∞ö‡∞°‡∞Ç, ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞™‡±ã‡∞∏‡±ç‡∞ü‡±ç‚Äå‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡∞ø‡∞Ç‡∞ó‡±ç!  
‡∞á‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å ‡∞à ‡∞™‡±ç‡∞∞‡∞§‡∞ø ‡∞¶‡∞∂‡∞®‡±Å ‡∞Æ‡∞∞‡∞ø‡∞Ç‡∞§ ‡∞≤‡±ã‡∞§‡±Å‡∞ó‡∞æ ‡∞™‡∞∞‡∞ø‡∞∂‡±Ä‡∞≤‡∞ø‡∞¶‡±ç‡∞¶‡∞æ‡∞Ç.

<Tip>

‚úèÔ∏è **‡∞™‡±ç‡∞∞‡∞Ø‡∞§‡±ç‡∞®‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø!** ‡∞Æ‡±Ä ‡∞∏‡±ç‡∞µ‡∞Ç‡∞§ ‡∞∞‡±Ü‡∞Ç‡∞°‡±Å (‡∞≤‡±á‡∞¶‡∞æ ‡∞Æ‡∞∞‡∞ø‡∞®‡±ç‡∞®‡∞ø) ‡∞µ‡∞æ‡∞ï‡±ç‡∞Ø‡∞æ‡∞≤‡∞®‡±Å ‡∞é‡∞Ç‡∞ö‡±Å‡∞ï‡±Å‡∞®‡∞ø ‡∞µ‡∞æ‡∞ü‡∞ø‡∞®‡∞ø `sentiment-analysis` ‡∞™‡±à‡∞™‡±ç‚Äå‡∞≤‡±à‡∞®‡±ç‚Äå‡∞≤‡±ã ‡∞®‡∞°‡∞™‡∞Ç‡∞°‡∞ø. ‡∞§‡∞∞‡±Å‡∞µ‡∞æ‡∞§ ‡∞á‡∞ï‡±ç‡∞ï‡∞° ‡∞ö‡±Ç‡∞™‡∞ø‡∞® ‡∞¶‡∞∂‡∞≤‡∞®‡±Å ‡∞í‡∞ï‡±ç‡∞ï‡±ä‡∞ï‡±ç‡∞ï‡∞ü‡∞ø‡∞ó‡∞æ ‡∞™‡±Å‡∞®‡∞∞‡∞æ‡∞µ‡±É‡∞§‡∞Ç ‡∞ö‡±á‡∞∏‡∞ø, ‡∞Ö‡∞¶‡±á ‡∞´‡∞≤‡∞ø‡∞§‡∞æ‡∞≤‡±Å ‡∞µ‡∞∏‡±ç‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞Ø‡∞æ ‡∞ö‡±Ç‡∞°‡∞Ç‡∞°‡∞ø!

</Tip>
