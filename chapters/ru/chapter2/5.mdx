<FrameworkSwitchCourse {fw} />

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π[[handling-multiple-sequences]]

{#if fw === 'pt'}

<CourseFloatingBanner chapter={2}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter2/section5_pt.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter2/section5_pt.ipynb"},
]} />

{:else}

<CourseFloatingBanner chapter={2}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter2/section5_tf.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter2/section5_tf.ipynb"},
]} />

{/if}

{#if fw === 'pt'}
<Youtube id="M6adb1j2jPI"/>
{:else}
<Youtube id="ROxrFOEbsQE"/>
{/if}

–í –ø—Ä–µ–¥—ã–¥—É—â–µ–º —Ä–∞–∑–¥–µ–ª–µ –º—ã —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–ª–∏ —Å–∞–º—ã–π –ø—Ä–æ—Å—Ç–æ–π –≤–∞—Ä–∏–∞–Ω—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è: –ø—Ä–æ–≤–µ–¥–µ–Ω–∏–µ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –Ω–∞ –æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –Ω–µ–±–æ–ª—å—à–æ–π –¥–ª–∏–Ω—ã. –û–¥–Ω–∞–∫–æ —É–∂–µ —Å–µ–π—á–∞—Å –≤–æ–∑–Ω–∏–∫–∞—é—Ç –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –≤–æ–ø—Ä–æ—Å—ã:

- –ö–∞–∫ –Ω–∞–º —Ä–∞–±–æ—Ç–∞—Ç—å —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è–º–∏?
- –ö–∞–∫ –Ω–∞–º —Ä–∞–±–æ—Ç–∞—Ç—å —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è–º–∏ *—Ä–∞–∑–Ω–æ–π –¥–ª–∏–Ω—ã*?
- –Ø–≤–ª—è—é—Ç—Å—è –ª–∏ –∏–Ω–¥–µ–∫—Å—ã —Å–ª–æ–≤–∞—Ä—è –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –≤—Ö–æ–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–∑–≤–æ–ª—è—é—Ç –º–æ–¥–µ–ª–∏ —Ä–∞–±–æ—Ç–∞—Ç—å —Ö–æ—Ä–æ—à–æ?
- –°—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ç–∞–∫–∞—è –≤–µ—â—å, –∫–∞–∫ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å?

–î–∞–≤–∞–π—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã –≤–æ–∑–Ω–∏–∫–∞—é—Ç –≤ —Å–≤—è–∑–∏ —Å —ç—Ç–∏–º–∏ –≤–æ–ø—Ä–æ—Å–∞–º–∏ –∏ –∫–∞–∫ –∏—Ö –º–æ–∂–Ω–æ —Ä–µ—à–∏—Ç—å —Å –ø–æ–º–æ—â—å—é ü§ó Transformers API.

## –ú–æ–¥–µ–ª–∏ –æ–∂–∏–¥–∞—é—Ç –±–∞—Ç—á –≤—Ö–æ–¥–æ–≤[[models-expect-a-batch-of-inputs]]

–í –ø—Ä–µ–¥—ã–¥—É—â–µ–º —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–∏ –≤—ã –≤–∏–¥–µ–ª–∏, –∫–∞–∫ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É—é—Ç—Å—è –≤ —Å–ø–∏—Å–∫–∏ —á–∏—Å–µ–ª. –î–∞–≤–∞–π—Ç–µ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —ç—Ç–æ—Ç —Å–ø–∏—Å–æ–∫ —á–∏—Å–µ–ª –≤ —Ç–µ–Ω–∑–æ—Ä –∏ –ø–µ—Ä–µ–¥–∞–¥–∏–º –µ–≥–æ –≤ –º–æ–¥–µ–ª—å:

{#if fw === 'pt'}
```py
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = AutoModelForSequenceClassification.from_pretrained(checkpoint)

sequence = "I've been waiting for a HuggingFace course my whole life."

tokens = tokenizer.tokenize(sequence)
ids = tokenizer.convert_tokens_to_ids(tokens)
input_ids = torch.tensor(ids)
# –≠—Ç–∞ —Å—Ç—Ä–æ–∫–∞ –≤—ã–¥–∞—Å—Ç –æ—à–∏–±–∫—É.
model(input_ids)
```

```python out
IndexError: Dimension out of range (expected to be in range of [-1, 0], but got 1)
```
{:else}
```py
import tensorflow as tf
from transformers import AutoTokenizer, TFAutoModelForSequenceClassification

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)

sequence = "I've been waiting for a HuggingFace course my whole life."

tokens = tokenizer.tokenize(sequence)
ids = tokenizer.convert_tokens_to_ids(tokens)
input_ids = tf.constant(ids)
# –≠—Ç–∞ —Å—Ç—Ä–æ–∫–∞ –≤—ã–¥–∞—Å—Ç –æ—à–∏–±–∫—É.
model(input_ids)
```

```py out
InvalidArgumentError: Input to reshape is a tensor with 14 values, but the requested shape has 196 [Op:Reshape]
```
{/if}

–û –Ω–µ—Ç! –ü–æ—á–µ–º—É —ç—Ç–æ –Ω–µ —É–¥–∞–ª–æ—Å—å? –ú—ã —Å–ª–µ–¥–æ–≤–∞–ª–∏ —à–∞–≥–∞–º –∏–∑ –∫–æ–Ω–≤–µ–π–µ—Ä–∞ –≤ —Ä–∞–∑–¥–µ–ª–µ 2.

–ü—Ä–æ–±–ª–µ–º–∞ –≤ —Ç–æ–º, —á—Ç–æ –º—ã –æ—Ç–ø—Ä–∞–≤–∏–ª–∏ –≤ –º–æ–¥–µ–ª—å –æ–¥–Ω—É –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å, –≤ —Ç–æ –≤—Ä–µ–º—è –∫–∞–∫ ü§ó –º–æ–¥–µ–ª–∏ Transformers –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –æ–∂–∏–¥–∞—é—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π. –ó–¥–µ—Å—å –º—ã –ø–æ–ø—ã—Ç–∞–ª–∏—Å—å —Å–¥–µ–ª–∞—Ç—å –≤—Å–µ —Ç–æ, —á—Ç–æ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –¥–µ–ª–∞–ª –∑–∞ –∫—É–ª–∏—Å–∞–º–∏, –∫–æ–≥–¥–∞ –º—ã –ø—Ä–∏–º–µ–Ω—è–ª–∏ –µ–≥–æ –∫ `–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏`. –ù–æ –µ—Å–ª–∏ –≤—ã –ø—Ä–∏–≥–ª—è–¥–∏—Ç–µ—Å—å, —Ç–æ —É–≤–∏–¥–∏—Ç–µ, —á—Ç–æ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –Ω–µ –ø—Ä–æ—Å—Ç–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–ª —Å–ø–∏—Å–æ–∫ –≤—Ö–æ–¥–Ω—ã—Ö –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ –≤ —Ç–µ–Ω–∑–æ—Ä, –∞ –¥–æ–±–∞–≤–∏–ª –∫ –Ω–µ–º—É –µ—â–µ –æ–¥–Ω–æ –∏–∑–º–µ—Ä–µ–Ω–∏–µ:

{#if fw === 'pt'}
```py
tokenized_inputs = tokenizer(sequence, return_tensors="pt")
print(tokenized_inputs["input_ids"])
```

```python out
tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,
          2607,  2026,  2878,  2166,  1012,   102]])
```
{:else}
```py
tokenized_inputs = tokenizer(sequence, return_tensors="tf")
print(tokenized_inputs["input_ids"])
```

```py out
<tf.Tensor: shape=(1, 16), dtype=int32, numpy=
array([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662,
        12172,  2607,  2026,  2878,  2166,  1012,   102]], dtype=int32)>
```
{/if}

–î–∞–≤–∞–π—Ç–µ –ø–æ–ø—Ä–æ–±—É–µ–º –µ—â–µ —Ä–∞–∑ –∏ –¥–æ–±–∞–≤–∏–º –Ω–æ–≤–æ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ:

{#if fw === 'pt'}
```py
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = AutoModelForSequenceClassification.from_pretrained(checkpoint)

sequence = "I've been waiting for a HuggingFace course my whole life."

tokens = tokenizer.tokenize(sequence)
ids = tokenizer.convert_tokens_to_ids(tokens)

input_ids = torch.tensor([ids])
print("Input IDs:", input_ids)

output = model(input_ids)
print("Logits:", output.logits)
```
{:else}
```py
import tensorflow as tf
from transformers import AutoTokenizer, TFAutoModelForSequenceClassification

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)

sequence = "I've been waiting for a HuggingFace course my whole life."

tokens = tokenizer.tokenize(sequence)
ids = tokenizer.convert_tokens_to_ids(tokens)

input_ids = tf.constant([ids])
print("Input IDs:", input_ids)

output = model(input_ids)
print("Logits:", output.logits)
```
{/if}

–ú—ã –≤—ã–≤–æ–¥–∏–º –≤—Ö–æ–¥–Ω—ã–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã, –∞ —Ç–∞–∫–∂–µ —Ä–µ–∑—É–ª—å—Ç–∏—Ä—É—é—â–∏–µ –ª–æ–≥–∏—Ç—ã - –≤–æ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç:

{#if fw === 'pt'}
```python out
Input IDs: [[ 1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,  2607, 2026,  2878,  2166,  1012]]
Logits: [[-2.7276,  2.8789]]
```
{:else}
```py out
Input IDs: tf.Tensor(
[[ 1045  1005  2310  2042  3403  2005  1037 17662 12172  2607  2026  2878
   2166  1012]], shape=(1, 14), dtype=int32)
Logits: tf.Tensor([[-2.7276208  2.8789377]], shape=(1, 2), dtype=float32)
```
{/if}

*–ë–∞—Ç—á–∏–Ω–≥* - —ç—Ç–æ –æ—Ç–ø—Ä–∞–≤–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ. –ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ, –≤—ã –º–æ–∂–µ—Ç–µ –ø—Ä–æ—Å—Ç–æ —Å–æ–∑–¥–∞—Ç—å –±–∞—Ç—á —Å –æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é:

```
batched_ids = [ids, ids]
```

–≠—Ç–æ –±–∞—Ç—á –∏–∑ –¥–≤—É—Ö –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π!

<Tip>

‚úèÔ∏è **–ü–æ–ø—Ä–æ–±—É–π—Ç–µ!** –ü—Ä–µ–æ–±—Ä–∞–∑—É–π—Ç–µ —ç—Ç–æ—Ç —Å–ø–∏—Å–æ–∫ `batched_ids` –≤ —Ç–µ–Ω–∑–æ—Ä –∏ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç–µ –µ–≥–æ —á–µ—Ä–µ–∑ –≤–∞—à—É –º–æ–¥–µ–ª—å. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –≤—ã –ø–æ–ª—É—á–∞–µ—Ç–µ —Ç–µ –∂–µ –ª–æ–≥–∏—Ç—ã, —á—Ç–æ –∏ —Ä–∞–Ω—å—à–µ (–Ω–æ –¥–≤–∞–∂–¥—ã)!

</Tip>

–ë–∞—Ç—á–∏–Ω–≥ –ø–æ–∑–≤–æ–ª—è–µ—Ç –º–æ–¥–µ–ª–∏ —Ä–∞–±–æ—Ç–∞—Ç—å, –∫–æ–≥–¥–∞ –≤—ã –ø–æ–¥–∞–µ—Ç–µ –µ–π –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π —Ç–∞–∫ –∂–µ –ø—Ä–æ—Å—Ç–æ, –∫–∞–∫ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –±–∞—Ç—á–∞ —Å –æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é. –û–¥–Ω–∞–∫–æ –µ—Å—Ç—å –∏ –≤—Ç–æ—Ä–∞—è –ø—Ä–æ–±–ª–µ–º–∞. –ö–æ–≥–¥–∞ –≤—ã –ø—ã—Ç–∞–µ—Ç–µ—Å—å —Å–æ–±—Ä–∞—Ç—å –≤ –±–∞—Ç—á –¥–≤–∞ (–∏–ª–∏ –±–æ–ª–µ–µ) –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –æ–Ω–∏ –º–æ–≥—É—Ç –±—ã—Ç—å —Ä–∞–∑–Ω–æ–π –¥–ª–∏–Ω—ã. –ï—Å–ª–∏ –≤—ã –∫–æ–≥–¥–∞-–Ω–∏–±—É–¥—å —Ä–∞–±–æ—Ç–∞–ª–∏ —Å —Ç–µ–Ω–∑–æ—Ä–∞–º–∏, —Ç–æ –∑–Ω–∞–µ—Ç–µ, —á—Ç–æ –æ–Ω–∏ –¥–æ–ª–∂–Ω—ã –∏–º–µ—Ç—å –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω—É—é —Ñ–æ—Ä–º—É, –ø–æ—ç—Ç–æ–º—É –≤—ã –Ω–µ —Å–º–æ–∂–µ—Ç–µ –Ω–∞–ø—Ä—è–º—É—é –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Ö–æ–¥–Ω—ã—Ö –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ –≤ —Ç–µ–Ω–∑–æ—Ä. –ß—Ç–æ–±—ã –æ–±–æ–π—Ç–∏ —ç—Ç—É –ø—Ä–æ–±–ª–µ–º—É, –º—ã –æ–±—ã—á–Ω–æ –ø—Ä–∏–±–µ–≥–∞–µ–º –∫ *–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—é (pad)* –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.

## –î–æ–ø–æ–ª–Ω–µ–Ω–∏–µ –≤—Ö–æ–¥–æ–≤[[padding-the-inputs]]

–°–ª–µ–¥—É—é—â–∏–π —Å–ø–∏—Å–æ–∫ —Å–ø–∏—Å–∫–æ–≤ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω –≤ —Ç–µ–Ω–∑–æ—Ä:

```py no-format
batched_ids = [
    [200, 200, 200],
    [200, 200]
]
```

–ß—Ç–æ–±—ã –æ–±–æ–π—Ç–∏ —ç—Ç—É –ø—Ä–æ–±–ª–µ–º—É, –º—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å *–¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ (padding)*, —á—Ç–æ–±—ã –ø—Ä–∏–¥–∞—Ç—å —Ç–µ–Ω–∑–æ—Ä–∞–º –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω—É—é —Ñ–æ—Ä–º—É. –î–æ–ø–æ–ª–Ω–µ–Ω–∏–µ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—É—é –¥–ª–∏–Ω—É –≤—Å–µ—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –¥–æ–±–∞–≤–ª—è—è —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–µ —Å–ª–æ–≤–æ *—Ç–æ–∫–µ–Ω –¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è* –∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º —Å –º–µ–Ω—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∑–Ω–∞—á–µ–Ω–∏–π. –ù–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å 10 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π —Å 10 —Å–ª–æ–≤–∞–º–∏ –∏ 1 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å 20 —Å–ª–æ–≤–∞–º–∏, —Ç–æ –ø—Ä–∏ –¥–æ–ø–æ–ª–Ω–µ–Ω–∏–∏ –≤—Å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –±—É–¥—É—Ç —Å–æ—Å—Ç–æ—è—Ç—å –∏–∑ 20 —Å–ª–æ–≤. –í –Ω–∞—à–µ–º –ø—Ä–∏–º–µ—Ä–µ —Ä–µ–∑—É–ª—å—Ç–∏—Ä—É—é—â–∏–π —Ç–µ–Ω–∑–æ—Ä –≤—ã–≥–ª—è–¥–∏—Ç —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º:

```py no-format
padding_id = 100

batched_ids = [
    [200, 200, 200],
    [200, 200, padding_id],
]
```

–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Ç–æ–∫–µ–Ω–∞ –¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è –º–æ–∂–Ω–æ –Ω–∞–π—Ç–∏ –≤ `tokenizer.pad_token_id`. –î–∞–≤–∞–π—Ç–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ –∏ –æ—Ç–ø—Ä–∞–≤–∏–º –Ω–∞—à–∏ –¥–≤–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –≤ –º–æ–¥–µ–ª—å –ø–æ –æ—Ç–¥–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ –±–∞—Ç—á–µ–º:

{#if fw === 'pt'}
```py no-format
model = AutoModelForSequenceClassification.from_pretrained(checkpoint)

sequence1_ids = [[200, 200, 200]]
sequence2_ids = [[200, 200]]
batched_ids = [
    [200, 200, 200],
    [200, 200, tokenizer.pad_token_id],
]

print(model(torch.tensor(sequence1_ids)).logits)
print(model(torch.tensor(sequence2_ids)).logits)
print(model(torch.tensor(batched_ids)).logits)
```

```python out
tensor([[ 1.5694, -1.3895]], grad_fn=<AddmmBackward>)
tensor([[ 0.5803, -0.4125]], grad_fn=<AddmmBackward>)
tensor([[ 1.5694, -1.3895],
        [ 1.3373, -1.2163]], grad_fn=<AddmmBackward>)
```
{:else}
```py no-format
model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)

sequence1_ids = [[200, 200, 200]]
sequence2_ids = [[200, 200]]
batched_ids = [
    [200, 200, 200],
    [200, 200, tokenizer.pad_token_id],
]

print(model(tf.constant(sequence1_ids)).logits)
print(model(tf.constant(sequence2_ids)).logits)
print(model(tf.constant(batched_ids)).logits)
```

```py out
tf.Tensor([[ 1.5693678 -1.3894581]], shape=(1, 2), dtype=float32)
tf.Tensor([[ 0.5803005  -0.41252428]], shape=(1, 2), dtype=float32)
tf.Tensor(
[[ 1.5693681 -1.3894582]
 [ 1.3373486 -1.2163193]], shape=(2, 2), dtype=float32)
```
{/if}

–ß—Ç–æ-—Ç–æ –Ω–µ —Ç–∞–∫ —Å –ª–æ–≥–∏—Ç–∞–º–∏ –≤ –Ω–∞—à–∏—Ö –±–∞—Ç—á–∞—Ö: –≤–æ –≤—Ç–æ—Ä–æ–º —Ä—è–¥—É –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Ç–µ –∂–µ –ª–æ–≥–∏—Ç—ã, —á—Ç–æ –∏ –¥–ª—è –≤—Ç–æ—Ä–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –Ω–æ –º—ã –ø–æ–ª—É—á–∏–ª–∏ —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ –¥—Ä—É–≥–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è!

–≠—Ç–æ —Å–≤—è–∑–∞–Ω–æ —Å —Ç–µ–º, —á—Ç–æ –∫–ª—é—á–µ–≤–æ–π –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å—é –º–æ–¥–µ–ª–µ–π Transformer —è–≤–ª—è—é—Ç—Å—è —Å–ª–æ–∏ –≤–Ω–∏–º–∞–Ω–∏—è (attention layers), –∫–æ—Ç–æ—Ä—ã–µ *–∫–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª–∏–∑–∏—Ä—É—é—Ç* –∫–∞–∂–¥—ã–π —Ç–æ–∫–µ–Ω. –û–Ω–∏ —É—á–∏—Ç—ã–≤–∞—é—Ç —Ç–æ–∫–µ–Ω—ã –¥–æ–ø–æ–ª–Ω–µ–Ω–∏–π, —Ç–∞–∫ –∫–∞–∫ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—é—Ç –≤—Å–µ —Ç–æ–∫–µ–Ω—ã –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏. –ß—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–∏ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–∏ —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π —Ä–∞–∑–Ω–æ–π –¥–ª–∏–Ω—ã –∏–ª–∏ –ø—Ä–∏ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–∏ –±–∞—Ç—á–∞ —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏ –∏ –¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è–º–∏, –Ω–∞–º –Ω—É–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å —Å–ª–æ—è–º –≤–Ω–∏–º–∞–Ω–∏—è –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å –¥–æ–ø–æ–ª–Ω—è—é—â–∏–µ —Ç–æ–∫–µ–Ω—ã. –î–ª—è —ç—Ç–æ–≥–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–∞—Å–∫–∞ –≤–Ω–∏–º–∞–Ω–∏—è (attention mask).

## –ú–∞—Å–∫–∏ –≤–Ω–∏–º–∞–Ω–∏—è[[attention-masks]]

*–ú–∞—Å–∫–∏ –≤–Ω–∏–º–∞–Ω–∏—è (Attention masks)* - —ç—Ç–æ —Ç–µ–Ω–∑–æ—Ä—ã —Ç–æ–π –∂–µ —Ñ–æ—Ä–º—ã, —á—Ç–æ –∏ —Ç–µ–Ω–∑–æ—Ä –≤—Ö–æ–¥–Ω—ã—Ö –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤, –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ 0 –∏ 1: 1 –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Ç–æ–∫–µ–Ω—ã –¥–æ–ª–∂–Ω—ã "–ø—Ä–∏–≤–ª–µ–∫–∞—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ", –∞ 0 –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Ç–æ–∫–µ–Ω—ã –Ω–µ –¥–æ–ª–∂–Ω—ã "–ø—Ä–∏–≤–ª–µ–∫–∞—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ" (—Ç.–µ. –¥–æ–ª–∂–Ω—ã –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å—Å—è —Å–ª–æ—è–º–∏ –≤–Ω–∏–º–∞–Ω–∏—è –º–æ–¥–µ–ª–∏).

–î–æ–ø–æ–ª–Ω–∏–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π –ø—Ä–∏–º–µ—Ä –º–∞—Å–∫–æ–π –≤–Ω–∏–º–∞–Ω–∏—è:

{#if fw === 'pt'}
```py no-format
batched_ids = [
    [200, 200, 200],
    [200, 200, tokenizer.pad_token_id],
]

attention_mask = [
    [1, 1, 1],
    [1, 1, 0],
]

outputs = model(torch.tensor(batched_ids), attention_mask=torch.tensor(attention_mask))
print(outputs.logits)
```

```python out
tensor([[ 1.5694, -1.3895],
        [ 0.5803, -0.4125]], grad_fn=<AddmmBackward>)
```
{:else}
```py no-format
batched_ids = [
    [200, 200, 200],
    [200, 200, tokenizer.pad_token_id],
]

attention_mask = [
    [1, 1, 1],
    [1, 1, 0],
]

outputs = model(tf.constant(batched_ids), attention_mask=tf.constant(attention_mask))
print(outputs.logits)
```

```py out
tf.Tensor(
[[ 1.5693681  -1.3894582 ]
 [ 0.5803021  -0.41252586]], shape=(2, 2), dtype=float32)
```
{/if}

–¢–µ–ø–µ—Ä—å –º—ã –ø–æ–ª—É—á–∏–º —Ç–∞–∫–∏–µ –∂–µ –ª–æ–≥–∏—Ç—ã –¥–ª—è –≤—Ç–æ—Ä–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –≤ –±–∞—Ç—á–µ.

–û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤—Ç–æ—Ä–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ - —ç—Ç–æ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è (padding ID), –∫–æ—Ç–æ—Ä—ã–π –≤ –º–∞—Å–∫–µ –≤–Ω–∏–º–∞–Ω–∏—è –∏–º–µ–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ 0.

<Tip>

‚úèÔ∏è **–ü–æ–ø—Ä–æ–±—É–π—Ç–µ! ** –ü—Ä–∏–º–µ–Ω–∏—Ç–µ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—é –≤—Ä—É—á–Ω—É—é –∫ –¥–≤—É–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–º –≤ —Ä–∞–∑–¥–µ–ª–µ 2 ("I've been waiting for a HuggingFace course my whole life." –∏ "I hate this so much!"). –ü—Ä–æ–ø—É—Å—Ç–∏—Ç–µ –∏—Ö —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å –∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –≤—ã –ø–æ–ª—É—á–∏—Ç–µ —Ç–µ –∂–µ –ª–æ–≥–∏—Ç—ã, —á—Ç–æ –∏ –≤ —Ä–∞–∑–¥–µ–ª–µ 2. –¢–µ–ø–µ—Ä—å –æ–±—ä–µ–¥–∏–Ω–∏—Ç–µ –∏—Ö –≤ –±–∞—Ç—á —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ç–æ–∫–µ–Ω–∞ –¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è, –∞ –∑–∞—Ç–µ–º —Å–æ–∑–¥–∞–π—Ç–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –º–∞—Å–∫—É –≤–Ω–∏–º–∞–Ω–∏—è. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –ø—Ä–∏ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–∏ —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å –≤—ã –ø–æ–ª—É—á–∞–µ—Ç–µ —Ç–µ –∂–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã!

</Tip>

## –ë–æ–ª–µ–µ –¥–ª–∏–Ω–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏[[longer-sequences]]

–í –º–æ–¥–µ–ª—è—Ö Transformer —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ –¥–ª–∏–Ω—É –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –º—ã –º–æ–∂–µ–º –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å –º–æ–¥–µ–ª—è–º. –ë–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π —Ä–∞–±–æ—Ç–∞—é—Ç —Å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è–º–∏ –¥–ª–∏–Ω–æ–π –¥–æ 512 –∏–ª–∏ 1024 —Ç–æ–∫–µ–Ω–æ–≤ –∏ —Ç–µ—Ä–ø—è—Ç –∫—Ä–∞—Ö –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –±–æ–ª–µ–µ –¥–ª–∏–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π. –ï—Å—Ç—å –¥–≤–∞ —Ä–µ—à–µ–Ω–∏—è —ç—Ç–æ–π –ø—Ä–æ–±–ª–µ–º—ã:

- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å —Å –±–æ–ª—å—à–µ–π –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–æ–π –¥–ª–∏–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.
- –£—Å–µ—á–µ–Ω–∏–µ (truncate) –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π.

–ú–æ–¥–µ–ª–∏ –∏–º–µ—é—Ç —Ä–∞–∑–Ω—É—é –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—É—é –¥–ª–∏–Ω—É –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, –∞ –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—Ç—Å—è –Ω–∞ —Ä–∞–±–æ—Ç–µ —Å –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–º–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è–º–∏. –û–¥–Ω–∏–º –∏–∑ –ø—Ä–∏–º–µ—Ä–æ–≤ —è–≤–ª—è–µ—Ç—Å—è [Longformer](https://huggingface.co/docs/transformers/model_doc/longformer), –∞ –¥—Ä—É–≥–∏–º - [LED](https://huggingface.co/docs/transformers/model_doc/led). –ï—Å–ª–∏ –≤—ã —Ä–∞–±–æ—Ç–∞–µ—Ç–µ –Ω–∞–¥ –∑–∞–¥–∞—á–µ–π, —Ç—Ä–µ–±—É—é—â–µ–π –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π, –º—ã —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º –≤–∞–º –æ–±—Ä–∞—Ç–∏—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —ç—Ç–∏ –º–æ–¥–µ–ª–∏.

–í –ø—Ä–æ—Ç–∏–≤–Ω–æ–º —Å–ª—É—á–∞–µ –º—ã —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —É—Å–µ—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π, —É–∫–∞–∑–∞–≤ –ø–∞—Ä–∞–º–µ—Ç—Ä `max_sequence_length`:

```py
sequence = sequence[:max_sequence_length]
```
