<FrameworkSwitchCourse {fw} />

# Fine-tuning –º–æ–¥–µ–ª–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Trainer API

<DocNotebookDropdown
  classNames="absolute z-10 right-0 top-0"
  options={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter3/section3.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter3/section3.ipynb"},
]} />

<Youtube id="nvBXf7s7vTI"/>

–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ ü§ó Transformers –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –∫–ª–∞—Å—Å `Trainer`, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–º–æ–≥–∞–µ—Ç –ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏ fine-tuning –ª—é–±–æ–π –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –≤–∞—à–µ–º –¥–∞—Ç–∞—Å–µ—Ç–µ. –ü–æ—Å–ª–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö, —Å–¥–µ–ª–∞–Ω–Ω—ã—Ö –≤ –ø—Ä–æ—à–ª–æ–º —Ä–∞–∑–¥–µ–ª–µ, –≤–∞–º –æ—Å—Ç–∞–Ω–µ—Ç—Å—è —Å–¥–µ–ª–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —à–∞–≥–æ–≤ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è `Trainer`. –°–∞–º–∞—è —Å–ª–æ–∂–Ω–∞—è —á–∞—Å—Ç—å ‚Äì –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –æ–∫—Ä—É–∂–µ–Ω–∏–µ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ `Trainer.train()`, —Ç.–∫. –æ–Ω–∞ –º–µ–¥–ª–µ–Ω–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–µ. –ï—Å–ª–∏ —É –≤–∞—Å –Ω–µ—Ç –≤–∏–¥–µ–æ–∫–∞—Ä—Ç—ã, –≤—ã –º–æ–∂–µ—Ç–µ –±–µ—Å–ø–ª–∞—Ç–Ω–æ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —Å–µ—Ä–≤–∏—Å–æ–º [Google Colab](https://colab.research.google.com/), –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –¥–æ—Å—Ç—É–ø –∫ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è–º —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º GPU –∏ TPU.

–§—Ä–∞–≥–º–µ–Ω—Ç—ã –∫–æ–¥–∞ –Ω–∏–∂–µ –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞—é—Ç, —á—Ç–æ –≤—ã –≤—ã–ø–æ–ª–Ω–∏–ª–∏ –∫–æ–¥ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Ä–∞–∑–¥–µ–ª–∞. –ù–∏–∂–µ –ø—Ä–∏–≤–µ–¥–µ–Ω–æ –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ —Ç–æ–≥–æ, —á—Ç–æ –≤–∞–º –Ω—É–∂–Ω–æ: 

```py
from datasets import load_dataset
from transformers import AutoTokenizer, DataCollatorWithPadding

raw_datasets = load_dataset("glue", "mrpc")
checkpoint = "bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)


def tokenize_function(example):
    return tokenizer(example["sentence1"], example["sentence2"], truncation=True)


tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)
data_collator = DataCollatorWithPadding(tokenizer=tokenizer)
```

### –û–±—É—á–µ–Ω–∏–µ

–ü–µ—Ä–≤—ã–π —à–∞–≥ –ø–µ—Ä–µ–¥ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º `Trainer`, –∑–∞–¥–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∞ `TrainingArguments`, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –≤—Å–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è `Trainer` (–¥–ª—è –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –æ–±—É—á–µ–Ω–∏—è –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏). –ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –∞—Ä–≥—É–º–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –≤—ã –¥–æ–ª–∂–Ω—ã –∑–∞–¥–∞—Ç—å ‚Äî —ç—Ç–æ –∫–∞—Ç–∞–ª–æ–≥, –≤ –∫–æ—Ç–æ—Ä–æ–º –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å, –∞ —Ç–∞–∫–∂–µ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ —Ç–æ—á–∫–∏. –î–ª—è –≤—Å–µ–≥–æ –æ—Å—Ç–∞–ª—å–Ω–æ–≥–æ –≤—ã –º–æ–∂–µ—Ç–µ –æ—Å—Ç–∞–≤–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, –∫–æ—Ç–æ—Ä—ã–µ –¥–æ–ª–∂–Ω—ã –ø–æ–¥–æ–π—Ç–∏ –¥–ª—è –±–∞–∑–æ–≤–æ–≥–æ fine-tuning.


```py
from transformers import TrainingArguments

training_args = TrainingArguments("test-trainer")
```

<Tip>

üí° –ï—Å–ª–∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∂–∞—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ Hub –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è, –ø–µ—Ä–µ–¥–∞–π—Ç–µ –∞—Ä–≥—É–º–µ–Ω—Ç `push_to_hub=True` –≤ `TrainingArguments`. –ú—ã –±–æ–ª—å—à–µ —É–∑–Ω–∞–µ–º –æ–± —ç—Ç–æ–º –≤ –≥–ª–∞–≤–µ [Chapter 4](/course/chapter4/3). 

</Tip>

–í—Ç–æ—Ä–æ–π —à–∞–≥ ‚Äì –∑–∞–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏. –¢–∞–∫ –∂–µ, –∫–∞–∫ –∏ –≤ [–ø—Ä–µ–¥—ã–¥—É—â–µ–π –≥–ª–∞–≤–µ](/course/chapter2), –º—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–ª–∞—Å—Å `AutoModelForSequenceClassification` —Å –¥–≤—É–º—è –ª–µ–π–±–ª–∞–º–∏: 

```py
from transformers import AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)
```

–ü–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –±—É–¥–µ—Ç —Ä–∞—Å–ø–µ—á–∞—Ç–∞–Ω–æ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ (–≤ [–≥–ª–∞–≤–µ 2](/course/chapter2) –º—ã —Å —Ç–∞–∫–∏–º –Ω–µ —Å—Ç–∞–ª–∫–∏–≤–∞–ª–∏—Å—å). –≠—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –ø–æ—Ç–æ–º—É, —á—Ç–æ BERT –Ω–µ –±—ã–ª –ø—Ä–µ–¥–æ–±—É—á–µ–Ω –¥–ª—è –∑–∞–¥–∞—á–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–∞—Ä –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –µ–≥–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π –Ω–µ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω, –≤–º–µ—Å—Ç–æ –Ω–µ–≥–æ –±—É–¥–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω —Å–ª–æ–π, –ø–æ–∑–≤–æ–ª—è—é—â–∏–π —Ä–∞–±–æ—Ç–∞—Ç—å —Å —Ç–∞–∫–æ–π –∑–∞–¥–∞—á–µ–π. –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è —Å–æ–æ–±—â–∞—é—Ç, —á—Ç–æ –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –≤–µ—Å–∞ –Ω–µ –±—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã (–∫–∞–∫ —Ä–∞–∑ —Ç–µ—Ö —Å–ª–æ–µ–≤, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –±—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è) –∏ –¥–ª—è –Ω–æ–≤—ã—Ö –±—É–¥—É—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã —Å–ª—É—á–∞–π–Ω—ã–µ –≤–µ—Å–∞. –í –∑–∞–∫–ª—é—á–µ–Ω–∏–∏ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å, —á—Ç–æ –º—ã –∏ —Å–¥–µ–ª–∞–µ–º –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å. 

–ü–æ—Å–ª–µ —Ç–æ–≥–æ, –∫–∞–∫ –º—ã –∑–∞–≥—Ä—É–∑–∏–ª–∏ –º–æ–¥–µ–ª—å, –º—ã –º–æ–∂–µ–º –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å `Trainer` –∏ –ø–µ—Ä–µ–¥–∞—Ç—å —Ç—É–¥–∞ –Ω—É–∂–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã: `model`, `training_args`, –æ–±—É—á–∞—é—â—É—é –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫–∏, `data_collator` –∏ `tokenizer`

```py
from transformers import Trainer

trainer = Trainer(
    model,
    training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    tokenizer=tokenizer,
)
```

–ó–∞–º–µ—Ç—å—Ç–µ, –∫–æ–≥–¥–∞ –≤—ã –ø–µ—Ä–µ–¥–∞–ª–∏ `tokenizer` –∫–∞–∫ –≤ –ø—Ä–∏–º–µ—Ä–µ –≤—ã—à–µ, –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è `data_collator` –≤ `Trainer` –±—É–¥–µ—Ç `DataCollatorWithPadding` —Ç–∞–∫–∏–º, –∫–∞–∫ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ –≤—ã—à–µ, —Ç–∞–∫ —á—Ç–æ —ç—Ç—É —Å—Ç—Ä–æ–∫—É (`data_collator=data_collator`) –º–æ–∂–Ω–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –≤ —ç—Ç–æ–º –≤—ã–∑–æ–≤–µ.  

<!-- Note that when you pass the `tokenizer` as we did here, the default `data_collator` used by the `Trainer` will be a `DataCollatorWithPadding` as defined previously, so you can skip the line `data_collator=data_collator` in this call. It was still important to show you this part of the processing in section 2! -->

–î–ª—è fine-tuning –º–æ–¥–µ–ª–∏ –Ω–∞ –Ω–∞—à–µ–º –¥–∞—Ç–∞—Å–µ—Ç–µ –º—ã –ø—Ä–æ—Å—Ç–æ –¥–æ–ª–∂–Ω—ã –≤—ã–∑–≤–∞—Ç—å –º–µ—Ç–æ–¥ `train()` —É `Trainer`: 

```py
trainer.train()
```

–≠—Ç–æ –∑–∞–ø—É—Å—Ç–∏—Ç –ø—Ä–æ—Ü–µ—Å—Å –¥–æ–æ–±—É—á–µ–Ω–∏—è (–∫–æ—Ç–æ—Ä—ã–π –¥–æ–ª–∂–µ–Ω –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç –Ω–∞ GPU) –∏ –±—É–¥–µ—Ç —Ä–∞—Å–ø–µ—á–∞—Ç—ã–≤–∞—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ –ª–æ—Å—Å–∞ –∫–∞–∂–¥—ã–µ 500 –∏—Ç–µ—Ä–∞—Ü–∏–π. –û–¥–Ω–∞–∫–æ —ç—Ç–∏ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–µ —Å–∫–∞–∂—É—Ç –Ω–∞–º, –Ω–∞—Å–∫–æ–ª—å–∫–æ —Ö–æ—Ä–æ—à–æ –∏–ª–∏ –ø–ª–æ—Ö–æ –º–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç. –ò –≤–æ—Ç –ø–æ—á–µ–º—É: 

1. –ú—ã –Ω–µ —Å–æ–æ–±—â–∏–ª–∏ `Trainer`, —á—Ç–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø—Ä–æ–≤–æ–¥–∏—Ç—å –≤–∞–ª–∏–¥–∞—Ü–∏—é: –¥–ª—è —ç—Ç–æ–≥–æ –Ω—É–∂–Ω–æ –ø—Ä–∏—Å–≤–æ–∏—Ç—å –∞—Ä–≥—É–º–µ–Ω—Ç—É `evaluation_strategy` –∑–Ω–∞—á–µ–Ω–∏–µ `"steps"` (–≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∂–¥—ã–µ `eval_steps`) –∏–ª–∏ `"epoch"` (–≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å –ø–æ –æ–∫–æ–Ω—á–∞–Ω–∏–∏ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–∏). 
2. –ú—ã –Ω–µ —É–∫–∞–∑–∞–ª–∏ `Trainer` –∞—Ä–≥—É–º–µ–Ω—Ç `compute_metrics()` ‚Äì —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π —á–∞—Å—Ç–∏ (–≤ —Ç–∞–∫–æ–º —Å–ª—É—á–∞–µ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –±—É–¥–µ—Ç —Ç–æ–ª—å–∫–æ —Ä–∞—Å–ø–µ—á–∞—Ç—ã–≤–∞—Ç—å—Å—è –∑–Ω–∞—á–µ–Ω–∏–µ –ª–æ—Å—Å–∞, —á—Ç–æ –Ω–µ –æ—á–µ–Ω—å –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ). 


### –í–∞–ª–∏–¥–∞—Ü–∏—è

–î–∞–≤–∞–π—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–∏–º –∫–∞–∫ –º—ã –º–æ–∂–µ–º —Å–æ–∑–¥–∞—Ç—å –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –æ–±—É—á–µ–Ω–∏—è –ø–æ–ª–µ–∑–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é `compute_metrics()`. –§—É–Ω–∫—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –ø—Ä–∏–Ω–∏–º–∞—Ç—å –Ω–∞ –≤—Ö–æ–¥ –æ–±—ä–µ–∫—Ç `EvalPrediction` (–∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã–π –∫–æ—Ä—Ç–µ–∂ —Å –ø–æ–ª—è–º–∏ `predictions` –∏  `label_ids`) –∏ –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å —Å–ª–æ–≤–∞—Ä—å, –≥–¥–µ –∫–ª—é—á–∏ - –Ω–∞–∑–≤–∞–Ω–∏—è –º–µ—Ç—Ä–∏–∫, –∞ –∑–Ω–∞—á–µ–Ω–∏—è - –æ—Ü–µ–Ω–∫–∏ —ç—Ç–∏—Ö –º–µ—Ç—Ä–∏–∫. –ß—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è, –º—ã –º–æ–∂–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é `Trainer.predict()`: 

```py
predictions = trainer.predict(tokenized_datasets["validation"])
print(predictions.predictions.shape, predictions.label_ids.shape)
```

```python out
(408, 2) (408,)
```

–†–µ–∑—É–ª—å—Ç–∞—Ç —Ñ—É–Ω–∫—Ü–∏–∏ `predict()` - –¥—Ä—É–≥–æ–π –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã–π –∫–æ—Ä—Ç–µ–∂ —Å –ø–æ–ª—è–º–∏ `predictions`, `label_ids` –∏ `metrics`. –ü–æ–ª–µ `metrics` –±—É–¥–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ –ª–æ—Å—Å–∞ –Ω–∞ –Ω–∞—à–µ–º –¥–∞—Ç–∞—Å–µ—Ç–µ –∏ –∑–Ω–∞—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫. –ü–æ—Å–ª–µ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ —Ñ—É–Ω–∫—Ü–∏–∏ `compute_metrics()` –∏ –ø–µ—Ä–µ–¥–∞—á–∏ –µ–µ –≤ `Trainer` –ø–æ–ª–µ `metrics` —Ç–∞–∫–∂–µ –±—É–¥–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ñ—É–Ω–∫—Ü–∏–∏ `compute_metrics()`. 

–ö–∞–∫ –º–æ–∂–Ω–æ –∑–∞–º–µ—Ç–∏—Ç—å, `predictions` - –º–∞—Å—Å–∏–≤ 408 —Ö 2 (408 - —á–∏—Å–ª–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ, –∫–æ—Ç–æ—Ä—ã–π –º—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏). –≠—Ç–æ –ª–æ–≥–∏—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –Ω–∞—à–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞, –ø–µ—Ä–µ–¥–∞–Ω–Ω–æ–≥–æ –≤ `predict()` (–∫–∞–∫ –≤—ã –≤–∏–¥–µ–ª–∏ –≤ [–ø—Ä–µ–¥—ã–¥—É—â–µ–π –≥–ª–∞–≤–µ](/course/chapter2) –≤—Å–µ –º–æ–¥–µ–ª–∏ –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤ –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç –ª–æ–≥–∏—Ç—ã). –ß—Ç–æ–±—ã –ø—Ä–µ–≤—Ä–∞—Ç–∏—Ç—å –∏—Ö –≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏ —Å—Ä–∞–≤–Ω–∏—Ç—å —Å –Ω–∞—à–∏–º–∏ –ª–µ–π–±–ª–∞–º–∏, –Ω–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∑–Ω–∞—Ç—å –∏–Ω–¥–µ–∫—Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –≤—Ç–æ—Ä–æ–π –æ—Å–∏: 

```py
import numpy as np

preds = np.argmax(predictions.predictions, axis=-1)
```

–¢–µ–ø–µ—Ä—å –º—ã –º–æ–∂–µ–º —Å—Ä–∞–≤–Ω–∏—Ç—å —ç—Ç–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å –ª–µ–π–±–ª–∞–º–∏. –î–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ `compute_metric()` –º—ã –≤–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ ü§ó [Evaluate](https://github.com/huggingface/evaluate/). –ú—ã –º–æ–∂–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç–∞ MRPC –º–µ—Ç—Ä–∏–∫–∏ —Ç–∞–∫ –∂–µ –ø—Ä–æ—Å—Ç–æ, –∫–∞–∫ –º—ã –∑–∞–≥—Ä—É–∑–∏–ª–∏ –¥–∞—Ç–∞—Å–µ—Ç, –Ω–æ –Ω–∞ —ç—Ç–æ—Ç —Ä–∞–∑ —Å –ø–æ–º–æ—â—å—é —Ñ—É–Ω–∫—Ü–∏–∏ `evaluate.load()`. –í–æ–∑–≤—Ä–∞—â–∞–µ–º—ã–π –æ–±—ä–µ–∫—Ç –∏–º–µ–µ—Ç –º–µ—Ç–æ–¥ `compute()`, –∫–æ—Ç–æ—Ä—ã–π –º—ã –º–æ–∂–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫–∏: 

```py
import evaluate

metric = evaluate.load("glue", "mrpc")
metric.compute(predictions=preds, references=predictions.label_ids)
```

```python out
{'accuracy': 0.8578431372549019, 'f1': 0.8996539792387542}
```

–£ –≤–∞—Å —ç—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–æ–≥—É—Ç –æ—Ç–ª–∏—á–∞—Ç—å—Å—è –≤–≤–∏–¥—É —Å–ª—É—á–∞–π–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏. –¢—É—Ç –º—ã –º–æ–∂–µ–º —É–≤–∏–¥–µ—Ç—å —Ç–æ—á–Ω–æ—Å—Ç—å 85.78% –∏ F1 89.97% –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π —á–∞—Å—Ç–∏ –≤—ã–±–æ—Ä–∫–∏. –≠—Ç–∏ –º–µ—Ç—Ä–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞ MRPC –¥–∞—Ç–∞—Å–µ—Ç–µ –Ω–∞ –±–µ–Ω—á–º–∞—Ä–∫–µ GLUE. –í —Ç–∞–±–ª–∏—Ü–µ –≤ —Å—Ç–∞—Ç—å–µ –æ [BERT](https://arxiv.org/pdf/1810.04805.pdf) —É–∫–∞–∑–∞–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ F1 –æ—Ü–µ–Ω–∫–∏ –≤ 88.9 –¥–ª—è –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏. –≠—Ç–æ –±—ã–ª–∞ –æ—Ü–µ–Ω–∫–∞ –¥–ª—è –≤–∞—Ä–∏–∞–Ω—Ç–∞ –º–æ–¥–µ–ª–∏ `uncased`, –∞ –º—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ `cased`, —ç—Ç–∏–º –∏ –æ–±—ä—è—Å–Ω—è–µ—Ç—Å—è –±–æ–ª–µ–µ —Ö–æ—Ä–æ—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç. 

–°–æ–±–∏—Ä–∞—è –≤–º–µ—Å—Ç–µ –≤—Å–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –≤—ã—à–µ, –º—ã –ø–æ–ª—É—á–∏–º –Ω–∞—à—É —Ñ—É–Ω–∫—Ü–∏—é `compute_metrics()`:

```py
def compute_metrics(eval_preds):
    metric = evaluate.load("glue", "mrpc")
    logits, labels = eval_preds
    predictions = np.argmax(logits, axis=-1)
    return metric.compute(predictions=predictions, references=labels)
```

–ß—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å —ç—Ç—É —Ñ—É–Ω–∫—Ü–∏—é –≤ –¥–µ–π—Å—Ç–≤–∏–∏ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–∏ –Ω–∏–∂–µ –º—ã –æ–ø—Ä–µ–¥–µ–ª–∏–º –µ—â–µ –æ–¥–∏–Ω `Trainer` —Å —Ñ—É–Ω–∫—Ü–∏–µ–π `compute_metrics()`: 

```py
training_args = TrainingArguments("test-trainer", evaluation_strategy="epoch")
model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)

trainer = Trainer(
    model,
    training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
)
```

–û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ –º—ã —Å–æ–∑–¥–∞–ª–∏ –Ω–æ–≤—ã–π –æ–±—ä–µ–∫—Ç `TrainingArguments` —Å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–º `evaluation_strategy` —Ä–∞–≤–Ω—ã–º `"epoch"` –∏ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª—å—é - –∏–Ω–∞—á–µ –º—ã –±—ã –ø—Ä–æ–¥–æ–ª–∂–∏–ª–∏ –æ–±—É—á–∞—Ç—å –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è —É–∂–µ —è–≤–ª—è–µ—Ç—Å—è –æ–±—É—á–µ–Ω–Ω–æ–π. –ß—Ç–æ–±—ã –∑–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ –∑–∞–Ω–æ–≤–æ, –Ω–∞–¥–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å: 

```
trainer.train()
```

–ù–∞ —ç—Ç–æ—Ç —Ä–∞–∑ –±—É–¥–µ—Ç —Ä–∞—Å–ø–µ—á–∞—Ç—ã–≤–∞—Ç—å—Å—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π –ª–æ—Å—Å –∏ –º–µ—Ç—Ä–∏–∫–∏ –ø–æ –æ–∫–æ–Ω—á–∞–Ω–∏—é –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–∏ –æ–±—É—á–µ–Ω–∏—è. –ù–∞–ø–æ–º–Ω–∏–º, —á—Ç–æ –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏ –∏ F1 –º–æ–≥—É—Ç –Ω–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å –ø—Ä–∏–≤–µ–¥–µ–Ω–Ω—ã–º–∏ –≤ –ø—Ä–∏–º–µ—Ä–µ –∏–∑-–∑–∞ —Å–ª—É—á–∞–π–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–ª–æ–µ–≤ –º–æ–¥–µ–ª–∏, –Ω–æ –ø–æ—Ä—è–¥–æ–∫ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø—Ä–∏–º–µ—Ä–Ω–æ —Ç–∞–∫–∏–º –∂–µ. 

`Trainer` –º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ GPU –∏–ª–∏ TPU –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–æ –æ–ø—Ü–∏–π, –Ω–∞–ø—Ä–∏–º–µ—Ä –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏–∫–∏ mixed-precision (—É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ `fp16 = True` –≤ –∞—Ä–≥—É–º–µ–Ω—Ç–∞—Ö). –ü–æ–¥—Ä–æ–±–Ω–æ –æ–± –æ–ø—Ü–∏—è—Ö –º—ã –ø–æ–≥–æ–≤–æ—Ä–∏–º —á—É—Ç—å –≤ –ì–ª–∞–≤–µ 10. 

–ù–∞ —ç—Ç–æ–º –≤–≤–µ–¥–µ–Ω–∏–µ –≤ fine-tuning —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º API `Trainer` –ø–æ–¥–æ—à–ª–æ –∫ –∫–æ–Ω—Ü—É. –ü—Ä–∏–º–µ—Ä —Ç–æ–≥–æ, –∫–∞–∫ —Å–¥–µ–ª–∞—Ç—å —ç—Ç–æ –∂–µ –¥–ª—è –Ω–∞–∏–±–æ–ª–µ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á  NLP –º—ã —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º –≤ –ì–ª–∞–≤–µ 7, –∞ —Å–µ–π—á–∞—Å –≤–∑–≥–ª—è–Ω–µ–º –Ω–∞ —Ç–æ, –∫–∞–∫ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Ç–æ –∂–µ —Å–∞–º–æ–µ –Ω–∞ —á–∏—Å—Ç–æ–º PyTorch. 

<Tip>

‚úèÔ∏è **–ü–æ–ø—Ä–æ–±—É–π—Ç–µ!** –ü—Ä–æ–∏–∑–≤–µ–¥–∏—Ç–µ fine-tuning –º–æ–¥–µ–ª–∏ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ GLUE SST-2 —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞ –∏–∑ —Ä–∞–∑–¥–µ–ª–∞ 2.

</Tip>

