<FrameworkSwitchCourse {fw} />

# Fine-tuning –º–æ–¥–µ–ª–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Keras

<DocNotebookDropdown
  classNames="absolute z-10 right-0 top-0"
  options={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter3/section3_tf.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter3/section3_tf.ipynb"},
]} />

–ü–æ—Å–ª–µ —Ç–æ–≥–æ, –∫–∞–∫ –≤—ã –≤—ã–ø–æ–ª–Ω–∏–ª–∏ –≤—Å—é —Ä–∞–±–æ—Ç—É –ø–æ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö –≤ –ø–æ—Å–ª–µ–¥–Ω–µ–º —Ä–∞–∑–¥–µ–ª–µ, —É –≤–∞—Å –æ—Å—Ç–∞–ª–æ—Å—å –≤—Å–µ–≥–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —à–∞–≥–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏. –û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, –æ–¥–Ω–∞–∫–æ, —á—Ç–æ –∫–æ–º–∞–Ω–¥–∞ `model.fit()` –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –æ—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω–æ –Ω–∞ CPU. –ï—Å–ª–∏ —É –≤–∞—Å –Ω–µ—Ç –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω–æ–≥–æ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞, –≤—ã –º–æ–∂–µ—Ç–µ –ø–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ –±–µ—Å–ø–ª–∞—Ç–Ω—ã–º –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞–º –∏–ª–∏ TPU –Ω–∞[Google Colab](https://colab.research.google.com/).

–í –ø—Ä–∏–≤–µ–¥–µ–Ω–Ω—ã—Ö –Ω–∏–∂–µ –ø—Ä–∏–º–µ—Ä–∞—Ö –∫–æ–¥–∞ –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ –≤—ã —É–∂–µ –≤—ã–ø–æ–ª–Ω–∏–ª–∏ –ø—Ä–∏–º–µ—Ä—ã –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Ä–∞–∑–¥–µ–ª–∞. –í–æ—Ç –∫—Ä–∞—Ç–∫–∏–π –æ–±–∑–æ—Ä —Ç–æ–≥–æ, —á—Ç–æ –≤–∞–º –Ω—É–∂–Ω–æ:

```py
from datasets import load_dataset
from transformers import AutoTokenizer, DataCollatorWithPadding
import numpy as np

raw_datasets = load_dataset("glue", "mrpc")
checkpoint = "bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)


def tokenize_function(example):
    return tokenizer(example["sentence1"], example["sentence2"], truncation=True)


tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)

data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors="tf")

tf_train_dataset = tokenized_datasets["train"].to_tf_dataset(
    columns=["attention_mask", "input_ids", "token_type_ids"],
    label_cols=["labels"],
    shuffle=True,
    collate_fn=data_collator,
    batch_size=8,
)

tf_validation_dataset = tokenized_datasets["validation"].to_tf_dataset(
    columns=["attention_mask", "input_ids", "token_type_ids"],
    label_cols=["labels"],
    shuffle=False,
    collate_fn=data_collator,
    batch_size=8,
)
```

### –û–±—É—á–µ–Ω–∏–µ

–ú–æ–¥–µ–ª–∏ TensorFlow, –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏–∑ ü§ó Transformers, —É–∂–µ —è–≤–ª—è—é—Ç—Å—è –º–æ–¥–µ–ª—è–º–∏ Keras. –í–æ—Ç –∫—Ä–∞—Ç–∫–æ–µ –≤–≤–µ–¥–µ–Ω–∏–µ –≤ Keras.

<Youtube id="rnTGBy2ax1c"/>

–≠—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –∫–æ–≥–¥–∞ —É –Ω–∞—Å –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ, –æ—Å—Ç–∞–µ—Ç—Å—è —Å–æ–≤—Å–µ–º –Ω–µ–º–Ω–æ–≥–æ –¥–æ –Ω–∞—á–∞–ª–∞ –æ–±—É—á–µ–Ω–∏—è.

<Youtube id="AUozVp78dhk"/>

–ö–∞–∫ –∏ –≤ [–ø—Ä–µ–¥—ã–¥—É—â–µ–π –≥–ª–∞–≤–µ](/course/ru/chapter2), –º—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–ª–∞—Å—Å `TFAutoModelForSequenceClassification` —Å –¥–≤—É–º—è –º–µ—Ç–∫–∞–º–∏:

```py
from transformers import TFAutoModelForSequenceClassification

model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)
```

–í—ã –∑–∞–º–µ—Ç–∏—Ç–µ, —á—Ç–æ –≤ –æ—Ç–ª–∏—á–∏–µ –æ—Ç [–ì–ª–∞–≤—ã 2](/course/ru/chapter2), –≤—ã –ø–æ–ª—É—á–∞–µ—Ç–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ —ç—Ç–æ–π –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏. –≠—Ç–æ —Å–≤—è–∑–∞–Ω–æ —Å —Ç–µ–º, —á—Ç–æ BERT –Ω–µ –±—ã–ª –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–∞—Ä –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –ø–æ—ç—Ç–æ–º—É –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –±—ã–ª –æ—Ç–±—Ä–æ—à–µ–Ω, –∞ –≤–º–µ—Å—Ç–æ –Ω–µ–≥–æ –±—ã–ª –≤—Å—Ç–∞–≤–ª–µ–Ω –Ω–æ–≤—ã–π —Å–ª–æ–π, –ø–æ–¥—Ö–æ–¥—è—â–∏–π –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π. –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è —É–∫–∞–∑—ã–≤–∞—é—Ç –Ω–∞ —Ç–æ, —á—Ç–æ –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –≤–µ—Å–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏—Å—å (—Ç–µ, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —É–¥–∞–ª–µ–Ω–Ω—ã–º —Å–ª–æ—è–º), –∞ –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –¥—Ä—É–≥–∏–µ –±—ã–ª–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã —Å–ª—É—á–∞–π–Ω—ã–º –æ–±—Ä–∞–∑–æ–º (—Ç–µ, —á—Ç–æ –¥–ª—è –Ω–æ–≤—ã—Ö —Å–ª–æ–µ–≤). –í –∑–∞–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å, —á—Ç–æ –º—ã –∏ —Å–æ–±–∏—Ä–∞–µ–º—Å—è —Å–¥–µ–ª–∞—Ç—å —Å–µ–π—á–∞—Å.

–ß—Ç–æ–±—ã —Ç–æ—á–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –º–æ–¥–µ–ª—å –≤ –Ω–∞—à–µ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö, –Ω–∞–º –ø—Ä–æ—Å—Ç–æ –Ω—É–∂–Ω–æ –≤—ã–∑–≤–∞—Ç—å `compile()` —É –Ω–∞—à–µ–π –º–æ–¥–µ–ª–∏, –∞ –∑–∞—Ç–µ–º –ø–µ—Ä–µ–¥–∞—Ç—å –Ω–∞—à–∏ –¥–∞–Ω–Ω—ã–µ –≤ –º–µ—Ç–æ–¥ `fit()`. –≠—Ç–æ –∑–∞–ø—É—Å—Ç–∏—Ç –ø—Ä–æ—Ü–µ—Å—Å fine tuning (–∫–æ—Ç–æ—Ä—ã–π –¥–æ–ª–∂–µ–Ω –∑–∞–Ω—è—Ç—å –ø–∞—Ä—É –º–∏–Ω—É—Ç –Ω–∞ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–µ) –∏ —Å–æ–æ–±—â–∏—Ç –æ –∑–Ω–∞—á–µ–Ω–∏—è—Ö —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏, –∞ —Ç–∞–∫–∂–µ –æ –∑–Ω–∞—á–µ–Ω–∏—è—Ö —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏.

<Tip>

–û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ —É –º–æ–¥–µ–ª–µ–π ü§ó Transformers –µ—Å—Ç—å –æ—Å–æ–±–∞—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å, –∫–æ—Ç–æ—Ä–æ–π –Ω–µ—Ç —É –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π Keras ‚Äî –æ–Ω–∏ –º–æ–≥—É—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å. –û–Ω–∏ –±—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —ç—Ç–∏ –ø–æ—Ç–µ—Ä—é –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, –µ—Å–ª–∏ –≤—ã –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∞—Ä–≥—É–º–µ–Ω—Ç `loss` –≤ `compile()`. –û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–π —Ñ—É–Ω–∫—Ü–∏–∏ –≤–∞–º –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç –ø–µ—Ä–µ–¥–∞—Ç—å —Å–≤–æ–∏ –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤ –∫–∞–∫ —á–∞—Å—Ç—å –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö, –∞ –Ω–µ –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—É—é –º–µ—Ç–∫—É, —á—Ç–æ —è–≤–ª—è–µ—Ç—Å—è –æ–±—ã—á–Ω—ã–º —Å–ø–æ—Å–æ–±–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–µ—Ç–æ–∫ —Å –º–æ–¥–µ–ª—è–º–∏ Keras. –í—ã —É–≤–∏–¥–∏—Ç–µ –ø—Ä–∏–º–µ—Ä—ã —ç—Ç–æ–≥–æ –≤–æ –≤—Ç–æ—Ä–æ–π —á–∞—Å—Ç–∏ –∫—É—Ä—Å–∞, –≥–¥–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–ª–æ–∂–Ω—ã–º. –û–¥–Ω–∞–∫–æ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å Keras –æ—Ç–ª–∏—á–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç, –ø–æ—ç—Ç–æ–º—É –º—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –µ–µ –∑–¥–µ—Å—å.

</Tip>

```py
from tensorflow.keras.losses import SparseCategoricalCrossentropy

model.compile(
    optimizer="adam",
    loss=SparseCategoricalCrossentropy(from_logits=True),
    metrics=["accuracy"],
)
model.fit(
    tf_train_dataset,
    validation_data=tf_validation_dataset,
)
```

<Tip warning={true}>

–û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –æ—á–µ–Ω—å —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—É—é –æ—à–∏–±–∫—É ‚Äî –≤ Keras —Ñ—É–Ω–∫—Ü–∏—é –ø–æ—Ç–µ—Ä—å –º–æ–∂–Ω–æ –∑–∞–¥–∞—Ç—å –ø—Ä–æ—Å—Ç–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º, –Ω–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é Keras –±—É–¥–µ—Ç —Å—á–∏—Ç–∞—Ç—å, —á—Ç–æ –≤—ã —É–∂–µ –ø—Ä–∏–º–µ–Ω–∏–ª–∏ softmax –∫ —Å–≤–æ–∏–º –≤—ã—Ö–æ–¥–∞–º. –û–¥–Ω–∞–∫–æ –º–Ω–æ–≥–∏–µ –º–æ–¥–µ–ª–∏ –≤—ã–≤–æ–¥—è—Ç –∑–Ω–∞—á–µ–Ω–∏—è –Ω–µ–ø–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ –ø–µ—Ä–µ–¥ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ–º softmax, —Ç–∞–∫ –Ω–∞–∑—ã–≤–∞–µ–º—ã–µ *–ª–æ–≥–∏—Ç—ã*. –ù–∞–º –Ω—É–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å —ç—Ç–æ –≤ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å, –∞ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π —Å–ø–æ—Å–æ–± —Å–¥–µ–ª–∞—Ç—å —ç—Ç–æ ‚Äî –≤—ã–∑–≤–∞—Ç—å –µ–µ –Ω–∞–ø—Ä—è–º—É—é, –∞ –Ω–µ –ø–æ –∏–º–µ–Ω–∏ –≤ –≤–∏–¥–µ —Å—Ç—Ä–æ–∫–∏.

</Tip>


### –ü–æ–≤—ã—à–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è

<Youtube id="cpzq6ESSM5c"/>

–ï—Å–ª–∏ –≤—ã –∑–∞–ø—É—Å—Ç–∏—Ç–µ –ø—Ä–∏–≤–µ–¥–µ–Ω–Ω—ã–π –≤—ã—à–µ –∫–æ–¥, –æ–Ω, –∫–æ–Ω–µ—á–Ω–æ, –∑–∞—Ä–∞–±–æ—Ç–∞–µ—Ç, –Ω–æ –≤—ã –æ–±–Ω–∞—Ä—É–∂–∏—Ç–µ, —á—Ç–æ –ø–æ—Ç–µ—Ä–∏ —Å–Ω–∏–∂–∞—é—Ç—Å—è –º–µ–¥–ª–µ–Ω–Ω–æ –∏–ª–∏ —Å–ø–æ—Ä–∞–¥–∏—á–µ—Å–∫–∏. –û—Å–Ω–æ–≤–Ω–∞—è –ø—Ä–∏—á–∏–Ω–∞ —ç—Ç–æ *—Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è* (*learning rate*). –ö–∞–∫ –∏ –≤ —Å–ª—É—á–∞–µ –ø–æ—Ç–µ—Ä–∏, –∫–æ–≥–¥–∞ –º—ã –ø–µ—Ä–µ–¥–∞–µ–º Keras –∏–º—è –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ –≤ –≤–∏–¥–µ —Å—Ç—Ä–æ–∫–∏, Keras –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç —ç—Ç–æ—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä —Å–æ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è –≤—Å–µ—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –≤–∫–ª—é—á–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è. –û–¥–Ω–∞–∫–æ –∏–∑ –º–Ω–æ–≥–æ–ª–µ—Ç–Ω–µ–≥–æ –æ–ø—ã—Ç–∞ –º—ã –∑–Ω–∞–µ–º, —á—Ç–æ –º–æ–¥–µ–ª–∏-—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã –≤—ã–∏–≥—Ä—ã–≤–∞—é—Ç –æ—Ç –≥–æ—Ä–∞–∑–¥–æ –±–æ–ª–µ–µ –Ω–∏–∑–∫–æ–π —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è, —á–µ–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è Adam - 1e-3 (1e-3 = 0.001). –ó–Ω–∞—á–µ–Ω–∏–µ 5e-5 (0.00005) –ø—Ä–∏–º–µ—Ä–Ω–æ –≤ –¥–≤–∞–¥—Ü–∞—Ç—å —Ä–∞–∑ –Ω–∏–∂–µ, –∏ —ç—Ç–æ –≥–æ—Ä–∞–∑–¥–æ –±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ.

–í –¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ –∫ —Å–Ω–∏–∂–µ–Ω–∏—é —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è —É –Ω–∞—Å –µ—Å—Ç—å –µ—â–µ –æ–¥–Ω–∞ —Ö–∏—Ç—Ä–æ—Å—Ç—å: –º—ã –º–æ–∂–µ–º –º–µ–¥–ª–µ–Ω–Ω–æ —Å–Ω–∏–∂–∞—Ç—å —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–µ –æ–±—É—á–µ–Ω–∏—è. –í –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–µ –≤—ã –∏–Ω–æ–≥–¥–∞ –º–æ–∂–µ—Ç–µ –≤—Å—Ç—Ä–µ—Ç–∏—Ç—å —Ç–µ—Ä–º–∏–Ω ¬´—É–±—ã–≤–∞–Ω–∏–µ¬ª –∏–ª–∏ ¬´–æ—Ç–∂–∏–≥¬ª —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è. –í Keras –ª—É—á—à–∏–π —Å–ø–æ—Å–æ–± —Å–¥–µ–ª–∞—Ç—å —ç—Ç–æ ‚Äî –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è. –•–æ—Ä–æ—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è `PolynomialDecay` ‚Äî –Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –Ω–∞–∑–≤–∞–Ω–∏–µ, —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –æ–Ω –ø—Ä–æ—Å—Ç–æ –ª–∏–Ω–µ–π–Ω–æ –∑–∞–Ω–∏–∂–∞–µ—Ç —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è –æ—Ç –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –¥–æ –∫–æ–Ω–µ—á–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è - —ç—Ç–æ –∏–º–µ–Ω–Ω–æ —Ç–æ, —á—Ç–æ –Ω–∞–º –Ω—É–∂–Ω–æ. –ß—Ç–æ–±—ã –ø—Ä–∞–≤–∏–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫,
—Ç–µ–º –Ω–µ –º–µ–Ω–µ–µ, –Ω–∞–º –Ω—É–∂–Ω–æ —Å–æ–æ–±—â–∏—Ç—å –µ–º—É, –∫–∞–∫ –¥–æ–ª–≥–æ –±—É–¥–µ—Ç –¥–ª–∏—Ç—å—Å—è –æ–±—É—á–µ–Ω–∏–µ. –ú—ã –≤—ã—á–∏—Å–ª—è–µ–º —ç—Ç–æ –∫–∞–∫ `num_train_steps` –Ω–∏–∂–µ.

```py
from tensorflow.keras.optimizers.schedules import PolynomialDecay

batch_size = 8
num_epochs = 3
# The number of training steps is the number of samples in the dataset, divided by the batch size then multiplied
# by the total number of epochs. Note that the tf_train_dataset here is a batched tf.data.Dataset,
# not the original Hugging Face Dataset, so its len() is already num_samples // batch_size.
num_train_steps = len(tf_train_dataset) * num_epochs
lr_scheduler = PolynomialDecay(
    initial_learning_rate=5e-5, end_learning_rate=0.0, decay_steps=num_train_steps
)
from tensorflow.keras.optimizers import Adam

opt = Adam(learning_rate=lr_scheduler)
```

<Tip>

–í –±–∏–±–ª–∏–æ—Ç–µ–∫–µ ü§ó Transformers —Ç–∞–∫–∂–µ –µ—Å—Ç—å —Ñ—É–Ω–∫—Ü–∏—è `create_optimizer()`, –∫–æ—Ç–æ—Ä–∞—è —Å–æ–∑–¥–∞—Å—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä `AdamW` —Å —É–º–µ–Ω—å—à–µ–Ω–∏–µ–º —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è. –≠—Ç–æ —É–¥–æ–±–Ω—ã–π —Å–ø–æ—Å–æ–±, —Å –∫–æ—Ç–æ—Ä—ã–º –≤—ã –ø–æ–¥—Ä–æ–±–Ω–æ –ø–æ–∑–Ω–∞–∫–æ–º–∏—Ç–µ—Å—å –≤ —Å–ª–µ–¥—É—é—â–∏—Ö —Ä–∞–∑–¥–µ–ª–∞—Ö –∫—É—Ä—Å–∞.

</Tip>

–¢–µ–ø–µ—Ä—å —É –Ω–∞—Å –µ—Å—Ç—å –Ω–æ–≤—ã–π –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä, –∏ –º—ã –º–æ–∂–µ–º –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å —Å –ø–æ–º–æ—â—å—é –Ω–µ–≥–æ. –í–æ-–ø–µ—Ä–≤—ã—Ö, –¥–∞–≤–∞–π—Ç–µ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏–º –º–æ–¥–µ–ª—å, —á—Ç–æ–±—ã —Å–±—Ä–æ—Å–∏—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤–µ—Å–æ–≤ –∏–∑ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–≥–æ –ø—Ä–æ–≥–æ–Ω–∞, –∫–æ—Ç–æ—Ä—ã–π –º—ã —Ç–æ–ª—å–∫–æ —á—Ç–æ —Å–¥–µ–ª–∞–ª–∏, –∞ –∑–∞—Ç–µ–º –º—ã –º–æ–∂–µ–º —Å–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞—Ç—å –µ–µ —Å –ø–æ–º–æ—â—å—é –Ω–æ–≤–æ–≥–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞:

```py
import tensorflow as tf

model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)
loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
model.compile(optimizer=opt, loss=loss, metrics=["accuracy"])
```

–ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –≤–Ω–æ–≤—å:

```py
model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=3)
```

<Tip>

üí° –ï—Å–ª–∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∂–∞—Ç—å —Å–≤–æ—é –º–æ–¥–µ–ª—å –Ω–∞ Hub –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è, –≤—ã –º–æ–∂–µ—Ç–µ –ø–µ—Ä–µ–¥–∞—Ç—å `PushToHubCallback` –≤ –º–µ—Ç–æ–¥ `model.fit()`. –ú—ã —É–∑–Ω–∞–µ–º –æ–± —ç—Ç–æ–º –±–æ–ª—å—à–µ –≤ [Chapter 4](/course/chapter4/3). 

</Tip>

### –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏

<Youtube id="nx10eh4CoOs"/>

–û–±—É—á–µ–Ω–∏–µ –∏ –Ω–∞–±–ª—é–¥–µ–Ω–∏–µ –∑–∞ —Å–Ω–∏–∂–µ–Ω–∏–µ–º –∑–Ω–∞—á–µ–Ω–∏–π —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å ‚Äî —ç—Ç–æ –æ—á–µ–Ω—å —Ö–æ—Ä–æ—à–æ, –Ω–æ —á—Ç–æ, –µ—Å–ª–∏ –º—ã –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Ö–æ—Ç–∏–º –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ç –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏, –ª–∏–±–æ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π, –ª–∏–±–æ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ –≤ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ? –î–ª—è —ç—Ç–æ–≥–æ –º—ã –º–æ–∂–µ–º –ø—Ä–æ—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–µ—Ç–æ–¥ `predict()`. –≠—Ç–æ –≤–µ—Ä–Ω–µ—Ç *–ª–æ–≥–∏—Ç—ã* –∏–∑ –º–æ–¥–µ–ª–∏, –ø–æ –æ–¥–Ω–æ–º—É –Ω–∞ –∫–ª–∞—Å—Å.

```py
preds = model.predict(tf_validation_dataset)["logits"]
```

–ú—ã –º–æ–∂–µ–º —Å–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ª–æ–≥–∏—Ç—ã –≤ –∑–Ω–∞—á–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∞ —Å –ø–æ–º–æ—â—å—é —Ñ—É–Ω–∫—Ü–∏–∏ `argmax` –¥–ª—è –ø–æ–∏—Å–∫–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –ª–æ–≥–∏—Ç–∞, –∫–æ—Ç–æ—Ä–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –Ω–∞–∏–±–æ–ª–µ–µ –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–Ω–æ–º—É –∫–ª–∞—Å—Å—É. 


```py
class_preds = np.argmax(preds, axis=1)
print(preds.shape, class_preds.shape)
```

```python out
(408, 2) (408,)
```

–¢–µ–ø–µ—Ä—å –¥–∞–≤–∞–π—Ç–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º —ç—Ç–∏ `preds` –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –º–µ—Ç—Ä–∏–∫! –ú—ã –º–æ–∂–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –¥–∞—Ç–∞—Å–µ—Ç–æ–º MRPC, —Ç–∞–∫ –∂–µ –ª–µ–≥–∫–æ, –∫–∞–∫ –º—ã –∑–∞–≥—Ä—É–∑–∏–ª–∏ —ç—Ç–æ—Ç –¥–∞—Ç–∞—Å–µ—Ç, –Ω–∞ —ç—Ç–æ—Ç —Ä–∞–∑ —Å –ø–æ–º–æ—â—å—é —Ñ—É–Ω–∫—Ü–∏–∏ `evaluate.load()`. –í–æ–∑–≤—Ä–∞—â–∞–µ–º—ã–π –æ–±—ä–µ–∫—Ç –∏–º–µ–µ—Ç –º–µ—Ç–æ–¥ `compute()`, –∫–æ—Ç–æ—Ä—ã–π –º—ã –º–æ–∂–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫–∏:

```py
import evaluate

metric = evaluate.load("glue", "mrpc")
metric.compute(predictions=class_preds, references=raw_datasets["validation"]["label"])
```

```python out
{'accuracy': 0.8578431372549019, 'f1': 0.8996539792387542}
```

–¢–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã –ø–æ–ª—É—á–∏—Ç–µ, –º–æ–≥—É—Ç –æ—Ç–ª–∏—á–∞—Ç—å—Å—è, —Ç–∞–∫ –∫–∞–∫ —Å–ª—É—á–∞–π–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤—ã—Ö–æ–¥–Ω—ã—Ö —Å–ª–æ–µ–≤ –º–æ–¥–µ–ª–∏ –º–æ–∂–µ—Ç –∏–∑–º–µ–Ω–∏—Ç—å –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏. –ó–¥–µ—Å—å –º—ã –≤–∏–¥–∏–º, —á—Ç–æ –Ω–∞—à–∞ –º–æ–¥–µ–ª—å –∏–º–µ–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å 85,78% –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–º –Ω–∞–±–æ—Ä–µ –∏ –æ—Ü–µ–Ω–∫—É F1 89,97. –≠—Ç–æ –¥–≤–µ –º–µ—Ç—Ä–∏–∫–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–∞—Ç–∞—Å–µ—Ç–∞ MRPC –¥–ª—è —Ç–µ—Å—Ç–∞ GLUE. –í —Ç–∞–±–ª–∏—Ü–µ –≤ [–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ BERT] (https://arxiv.org/pdf/1810.04805.pdf) —Å–æ–æ–±—â–∞–µ—Ç—Å—è –æ –±–∞–ª–ª–µ F1 88,97% –¥–ª—è –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏. –≠—Ç–æ –±—ã–ª–∞ –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –Ω–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–∞ –∫ —Ä–µ–≥–∏—Å—Ç—Ä—É —Ç–µ–∫—Å—Ç–∞, –≤ —Ç–æ –≤—Ä–µ–º—è –∫–∞–∫ —Å–µ–π—á–∞—Å –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å, —É—á–∏—Ç—ã–≤–∞—é—â—É—é —Ä–µ–≥–∏—Å—Ç—Ä, —á—Ç–æ –∏ –æ–±—ä—è—Å–Ω—è–µ—Ç –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç.

–ù–∞ —ç—Ç–æ–º –≤–≤–µ–¥–µ–Ω–∏–µ –≤ fine tuning —Å –ø–æ–º–æ—â—å—é Keras API –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –ü—Ä–∏–º–µ—Ä –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —ç—Ç–æ–≥–æ –¥–ª—è –Ω–∞–∏–±–æ–ª–µ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á NLP –±—É–¥–µ—Ç –¥–∞–Ω –≤ [–ì–ª–∞–≤–µ 7](/course/ru/chapter7). –ï—Å–ª–∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ –æ—Ç—Ç–æ—á–∏—Ç—å —Å–≤–æ–∏ –Ω–∞–≤—ã–∫–∏ —Ä–∞–±–æ—Ç—ã —Å Keras API, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Ç–æ—á–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –º–æ–¥–µ–ª—å –≤ –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö GLUE SST-2, –∏—Å–ø–æ–ª—å–∑—É—è –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—É—é –≤—ã –≤—ã–ø–æ–ª–Ω–∏–ª–∏ –≤ —Ä–∞–∑–¥–µ–ª–µ 2.
