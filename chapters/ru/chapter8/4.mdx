<FrameworkSwitchCourse {fw} />

# –û—Ç–ª–∞–¥–∫–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞ –æ–±—É—á–µ–Ω–∏—è

<CourseFloatingBanner chapter={8}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter8/section4_pt.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter8/section4_pt.ipynb"},
]} />

–í—ã –Ω–∞–ø–∏—Å–∞–ª–∏ –∫—Ä–∞—Å–∏–≤—ã–π —Å—Ü–µ–Ω–∞—Ä–∏–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏–ª–∏ —Ç–æ—á–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏ –Ω–∞ –∑–∞–¥–∞–Ω–Ω–æ–π –∑–∞–¥–∞—á–µ, –ø–æ—Å–ª—É—à–Ω–æ —Å–ª–µ–¥—É—è —Å–æ–≤–µ—Ç–∞–º –∏–∑ [–≥–ª–∞–≤—ã 7](/course/chapters/ru/chapter7). –ù–æ –∫–æ–≥–¥–∞ –≤—ã –∑–∞–ø—É—Å–∫–∞–µ—Ç–µ –∫–æ–º–∞–Ω–¥—É `trainer.train()`, –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –Ω–µ—á—Ç–æ —É–∂–∞—Å–Ω–æ–µ: –≤—ã –ø–æ–ª—É—á–∞–µ—Ç–µ –æ—à–∏–±–∫—É üò±! –ò–ª–∏, —á—Ç–æ –µ—â–µ —Ö—É–∂–µ, –≤—Å–µ –≤—Ä–æ–¥–µ –±—ã –≤ –ø–æ—Ä—è–¥–∫–µ, –æ–±—É—á–µ–Ω–∏–µ –ø—Ä–æ—Ö–æ–¥–∏—Ç –±–µ–∑ –æ—à–∏–±–æ–∫, –Ω–æ —Ä–µ–∑—É–ª—å—Ç–∏—Ä—É—é—â–∞—è –º–æ–¥–µ–ª—å –ø–æ–ª—É—á–∞–µ—Ç—Å—è –ø–ª–æ—Ö–æ–π. –í —ç—Ç–æ–º —Ä–∞–∑–¥–µ–ª–µ –º—ã –ø–æ–∫–∞–∂–µ–º –≤–∞–º, —á—Ç–æ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ –ø–æ–¥–æ–±–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º.

## –û—Ç–ª–∞–¥–∫–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞ –æ–±—É—á–µ–Ω–∏—è

<Youtube id="L-WSwUWde1U"/>

–ü—Ä–æ–±–ª–µ–º–∞, –∫–æ–≥–¥–∞ –≤—ã —Å—Ç–∞–ª–∫–∏–≤–∞–µ—Ç–µ—Å—å —Å –æ—à–∏–±–∫–æ–π –≤ `trainer.train()`, –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ —Ç–æ–º, —á—Ç–æ –æ–Ω–∞ –º–æ–∂–µ—Ç –≤–æ–∑–Ω–∏–∫–Ω—É—Ç—å –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤, –ø–æ—Å–∫–æ–ª—å–∫—É `Trainer` –æ–±—ã—á–Ω–æ —Å–æ–±–∏—Ä–∞–µ—Ç –≤–º–µ—Å—Ç–µ –º–Ω–æ–∂–µ—Å—Ç–≤–æ –≤–µ—â–µ–π. –û–Ω –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –Ω–∞–±–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö –≤ –∑–∞–≥—Ä—É–∑—á–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö, –ø–æ—ç—Ç–æ–º—É –ø—Ä–æ–±–ª–µ–º–∞ –º–æ–∂–µ—Ç –∑–∞–∫–ª—é—á–∞—Ç—å—Å—è –≤ —Ç–æ–º, —á—Ç–æ –≤ –≤–∞—à–µ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö —á—Ç–æ-—Ç–æ –Ω–µ —Ç–∞–∫, –∏–ª–∏ –≤ –∫–∞–∫–æ–π-—Ç–æ –ø—Ä–æ–±–ª–µ–º–µ –ø—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö. –ó–∞—Ç–µ–º –æ–Ω –±–µ—Ä–µ—Ç –ø–∞–∫–µ—Ç –¥–∞–Ω–Ω—ã—Ö –∏ –ø–æ–¥–∞–µ—Ç –µ–≥–æ –≤ –º–æ–¥–µ–ª—å, —Ç–∞–∫ —á—Ç–æ –ø—Ä–æ–±–ª–µ–º–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –≤ –∫–æ–¥–µ –º–æ–¥–µ–ª–∏. –ü–æ—Å–ª–µ —ç—Ç–æ–≥–æ –≤—ã—á–∏—Å–ª—è—é—Ç—Å—è –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —à–∞–≥ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏, –ø–æ—ç—Ç–æ–º—É –ø—Ä–æ–±–ª–µ–º–∞ —Ç–∞–∫–∂–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –≤ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–µ. –ò –¥–∞–∂–µ –µ—Å–ª–∏ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –æ–±—É—á–µ–Ω–∏—è –≤—Å–µ –∏–¥–µ—Ç —Ö–æ—Ä–æ—à–æ, –≤–æ –≤—Ä–µ–º—è –æ—Ü–µ–Ω–∫–∏ –≤—Å–µ —Ä–∞–≤–Ω–æ —á—Ç–æ-—Ç–æ –º–æ–∂–µ—Ç –ø–æ–π—Ç–∏ –Ω–µ —Ç–∞–∫, –µ—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–æ–±–ª–µ–º–∞ —Å –≤–∞—à–µ–π –º–µ—Ç—Ä–∏–∫–æ–π.

–õ—É—á—à–∏–π —Å–ø–æ—Å–æ–± –æ—Ç–ª–∞–¥–∏—Ç—å –æ—à–∏–±–∫—É, –≤–æ–∑–Ω–∏–∫–∞—é—â—É—é –≤ `trainer.train()`, - —ç—Ç–æ –≤—Ä—É—á–Ω—É—é –ø—Ä–æ–π—Ç–∏ –≤–µ—Å—å –ø–∞–π–ø–ª–∞–π–Ω, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å, –≥–¥–µ —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫. –í —ç—Ç–æ–º —Å–ª—É—á–∞–µ –æ—à–∏–±–∫—É —á–∞—Å—Ç–æ –æ—á–µ–Ω—å –ª–µ–≥–∫–æ —É—Å—Ç—Ä–∞–Ω–∏—Ç—å.

–ß—Ç–æ–±—ã –ø—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å —ç—Ç–æ, –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ª–µ–¥—É—é—â–∏–π —Å—Ü–µ–Ω–∞—Ä–∏–π, –∫–æ—Ç–æ—Ä—ã–π (–ø—ã—Ç–∞–µ—Ç—Å—è) —Ç–æ—á–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –º–æ–¥–µ–ª—å DistilBERT –Ω–∞ [MNLI –¥–∞—Ç–∞—Å–µ—Ç–µ](https://huggingface.co/datasets/glue):

```py
from datasets import load_dataset
import evaluate
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
    return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)

args = TrainingArguments(
    f"distilbert-finetuned-mnli",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
)

metric = evaluate.load("glue", "mnli")


def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    return metric.compute(predictions=predictions, references=labels)


trainer = Trainer(
    model,
    args,
    train_dataset=raw_datasets["train"],
    eval_dataset=raw_datasets["validation_matched"],
    compute_metrics=compute_metrics,
)
trainer.train()
```

–ï—Å–ª–∏ –≤—ã –ø–æ–ø—ã—Ç–∞–µ—Ç–µ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –µ–≥–æ, —Ç–æ —Å—Ç–æ–ª–∫–Ω–µ—Ç–µ—Å—å —Å –¥–æ–≤–æ–ª—å–Ω–æ –Ω–µ–ø–æ–Ω—è—Ç–Ω–æ–π –æ—à–∏–±–∫–æ–π:

```python out
'ValueError: You have to specify either input_ids or inputs_embeds'
```

### –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–≤–æ–∏ –¥–∞–Ω–Ω—ã–µ

–≠—Ç–æ —Å–∞–º–æ —Å–æ–±–æ–π —Ä–∞–∑—É–º–µ–µ—Ç—Å—è, –Ω–æ –µ—Å–ª–∏ –≤–∞—à–∏ –¥–∞–Ω–Ω—ã–µ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω—ã, `Trainer` –Ω–µ —Å–º–æ–∂–µ—Ç —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –Ω–∞–±–æ—Ä—ã, –Ω–µ –≥–æ–≤–æ—Ä—è —É–∂–µ –æ–± –æ–±—É—á–µ–Ω–∏–∏ –≤–∞—à–µ–π –º–æ–¥–µ–ª–∏. –ò—Ç–∞–∫, –ø—Ä–µ–∂–¥–µ –≤—Å–µ–≥–æ, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å, —á—Ç–æ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –≤–∞—à–µ–º –æ–±—É—á–∞—é—â–µ–º –Ω–∞–±–æ—Ä–µ.

–ß—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –±–µ—Å—á–∏—Å–ª–µ–Ω–Ω—ã—Ö —á–∞—Å–æ–≤, –ø–æ—Ç—Ä–∞—á–µ–Ω–Ω—ã—Ö –Ω–∞ –ø–æ–ø—ã—Ç–∫–∏ –∏—Å–ø—Ä–∞–≤–∏—Ç—å —Ç–æ, —á—Ç–æ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ø—Ä–∏—á–∏–Ω–æ–π –æ—à–∏–±–∫–∏, –º—ã —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º –≤–∞–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `trainer.train_dataset` –¥–ª—è –ø—Ä–æ–≤–µ—Ä–æ–∫ –∏ –Ω–∏—á–µ–≥–æ –±–æ–ª—å—à–µ. –¢–∞–∫ —á—Ç–æ –¥–∞–≤–∞–π—Ç–µ —Å–¥–µ–ª–∞–µ–º —ç—Ç–æ –∑–¥–µ—Å—å:

```py
trainer.train_dataset[0]
```

```python out
{'hypothesis': 'Product and geography are what make cream skimming work. ',
 'idx': 0,
 'label': 1,
 'premise': 'Conceptually cream skimming has two basic dimensions - product and geography.'}
```

–í—ã –∑–∞–º–µ—Ç–∏–ª–∏ —á—Ç–æ-—Ç–æ –Ω–µ —Ç–æ? –í —Å–æ—á–µ—Ç–∞–Ω–∏–∏ —Å —Å–æ–æ–±—â–µ–Ω–∏–µ–º –æ–± –æ—à–∏–±–∫–µ `input_ids`, –≤—ã –¥–æ–ª–∂–Ω—ã –ø–æ–Ω—è—Ç—å, —á—Ç–æ —ç—Ç–æ —Ç–µ–∫—Å—Ç—ã, –∞ –Ω–µ —á–∏—Å–ª–∞, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –ø–æ–Ω—è—Ç—å. –ó–¥–µ—Å—å –∏—Å—Ö–æ–¥–Ω–∞—è –æ—à–∏–±–∫–∞ –≤–≤–æ–¥–∏—Ç –≤ –∑–∞–±–ª—É–∂–¥–µ–Ω–∏–µ, –ø–æ—Ç–æ–º—É —á—Ç–æ `Trainer` –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–¥–∞–ª—è–µ—Ç —Å—Ç–æ–ª–±—Ü—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —Å–∏–≥–Ω–∞—Ç—É—Ä–µ –º–æ–¥–µ–ª–∏ (—Ç–æ –µ—Å—Ç—å –∞—Ä–≥—É–º–µ–Ω—Ç—ã, –æ–∂–∏–¥–∞–µ–º—ã–µ –º–æ–¥–µ–ª—å—é). –≠—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –∑–¥–µ—Å—å –≤—Å–µ, –∫—Ä–æ–º–µ –º–µ—Ç–æ–∫, –±—ã–ª–æ –æ—Ç–±—Ä–æ—à–µ–Ω–æ. –¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, –Ω–µ –±—ã–ª–æ –ø—Ä–æ–±–ª–µ–º—ã —Å —Å–æ–∑–¥–∞–Ω–∏–µ–º –Ω–∞–±–æ—Ä–æ–≤ –∏ –ø–æ—Å–ª–µ–¥—É—é—â–µ–π –æ—Ç–ø—Ä–∞–≤–∫–æ–π –∏—Ö –≤ –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è, –≤ —Å–≤–æ—é –æ—á–µ—Ä–µ–¥—å, —Å–æ–æ–±—â–∞–ª–∞, —á—Ç–æ –Ω–µ –ø–æ–ª—É—á–∏–ª–∞ –Ω—É–∂–Ω—ã—Ö –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.

–ü–æ—á–µ–º—É –¥–∞–Ω–Ω—ã–µ –Ω–µ –±—ã–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã? –ú—ã –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ –º–µ—Ç–æ–¥ `Dataset.map()` –¥–ª—è –Ω–∞–±–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö, —á—Ç–æ–±—ã –ø—Ä–∏–º–µ–Ω–∏—Ç—å —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –∫ –∫–∞–∂–¥–æ–º—É –æ–±—Ä–∞–∑—Ü—É. –ù–æ –µ—Å–ª–∏ –≤—ã –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –ø–æ—Å–º–æ—Ç—Ä–∏—Ç–µ –Ω–∞ –∫–æ–¥, —Ç–æ —É–≤–∏–¥–∏—Ç–µ, —á—Ç–æ –º—ã –¥–æ–ø—É—Å—Ç–∏–ª–∏ –æ—à–∏–±–∫—É –ø—Ä–∏ –ø–µ—Ä–µ–¥–∞—á–µ –æ–±—É—á–∞—é—â–µ–≥–æ –∏ –æ—Ü–µ–Ω–æ—á–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–æ–≤ –≤ `Trainer`. –í–º–µ—Å—Ç–æ `tokenized_datasets` –º—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ `raw_datasets` ü§¶. –¢–∞–∫ —á—Ç–æ –¥–∞–≤–∞–π—Ç–µ –∏—Å–ø—Ä–∞–≤–∏–º —ç—Ç–æ!

```py
from datasets import load_dataset
import evaluate
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
    return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)

args = TrainingArguments(
    f"distilbert-finetuned-mnli",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
)

metric = evaluate.load("glue", "mnli")


def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    return metric.compute(predictions=predictions, references=labels)


trainer = Trainer(
    model,
    args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation_matched"],
    compute_metrics=compute_metrics,
)
trainer.train()
```

–¢–µ–ø–µ—Ä—å —ç—Ç–æ—Ç –Ω–æ–≤—ã–π –∫–æ–¥ –±—É–¥–µ—Ç –≤—ã–¥–∞–≤–∞—Ç—å –¥—Ä—É–≥—É—é –æ—à–∏–±–∫—É (–ø—Ä–æ–≥—Ä–µ—Å—Å!):

```python out
'ValueError: expected sequence of length 43 at dim 1 (got 37)'
```

–ì–ª—è–¥—è –Ω–∞ —Ç—Ä–µ–π—Å–±–µ–∫, –º—ã –≤–∏–¥–∏–º, —á—Ç–æ –æ—à–∏–±–∫–∞ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –Ω–∞ —ç—Ç–∞–ø–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö:

```python out
~/git/transformers/src/transformers/data/data_collator.py in torch_default_data_collator(features)
    105                 batch[k] = torch.stack([f[k] for f in features])
    106             else:
--> 107                 batch[k] = torch.tensor([f[k] for f in features])
    108 
    109     return batch
```

–ò—Ç–∞–∫, –º—ã –¥–æ–ª–∂–Ω—ã –ø—Ä–∏—Å—Ç—É–ø–∏—Ç—å –∫ —ç—Ç–æ–º—É. –û–¥–Ω–∞–∫–æ –ø–µ—Ä–µ–¥ —ç—Ç–∏–º –¥–∞–≤–∞–π—Ç–µ –∑–∞–≤–µ—Ä—à–∏–º –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö, —á—Ç–æ–±—ã –±—ã—Ç—å –Ω–∞ 100% —É–≤–µ—Ä–µ–Ω–Ω—ã–º–∏ –≤ –∏—Ö –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç–∏.

–ü—Ä–∏ –æ—Ç–ª–∞–¥–∫–µ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–π —Å–µ—Å—Å–∏–∏ –≤—Å–µ–≥–¥–∞ –Ω—É–∂–Ω–æ —Å–º–æ—Ç—Ä–µ—Ç—å –Ω–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏. –ú—ã –Ω–µ –º–æ–∂–µ–º –ø–æ–Ω—è—Ç—å —Å–º—ã—Å–ª —á–∏—Å–µ–ª, –∫–æ—Ç–æ—Ä—ã–µ –º—ã –ø–µ—Ä–µ–¥–∞–µ–º –µ–π –Ω–∞–ø—Ä—è–º—É—é, –ø–æ—ç—Ç–æ–º—É –º—ã –¥–æ–ª–∂–Ω—ã –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å, —á—Ç–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç —Å–æ–±–æ–π —ç—Ç–∏ —á–∏—Å–ª–∞. –í –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–º –∑—Ä–µ–Ω–∏–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä, —ç—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –Ω–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–∏–∫—Å–µ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã –ø–µ—Ä–µ–¥–∞–µ—Ç–µ, –≤ —Ä–µ—á–∏ - –ø—Ä–æ—Å–ª—É—à–∞—Ç—å –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ–±—Ä–∞–∑—Ü—ã –∑–≤—É–∫–∞, –∞ –≤ –Ω–∞—à–µ–º –ø—Ä–∏–º–µ—Ä–µ —Å NLP - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–∞—à —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –¥–ª—è –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:

```py
tokenizer.decode(trainer.train_dataset[0]["input_ids"])
```

```python out
'[CLS] conceptually cream skimming has two basic dimensions - product and geography. [SEP] product and geography are what make cream skimming work. [SEP]'
```

–ò—Ç–∞–∫, —ç—Ç–æ –∫–∞–∂–µ—Ç—Å—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º. –í—ã –¥–æ–ª–∂–Ω—ã —Å–¥–µ–ª–∞—Ç—å —ç—Ç–æ –¥–ª—è –≤—Å–µ—Ö –∫–ª—é—á–µ–π –≤–æ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:

```py
trainer.train_dataset[0].keys()
```

```python out
dict_keys(['attention_mask', 'hypothesis', 'idx', 'input_ids', 'label', 'premise'])
```

–û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ –∫–ª—é—á–∏, –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –≤—Ö–æ–¥–∞–º, –ø—Ä–∏–Ω–∏–º–∞–µ–º—ã–º –º–æ–¥–µ–ª—å—é, –±—É–¥—É—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—Ç–±—Ä–æ—à–µ–Ω—ã, –ø–æ—ç—Ç–æ–º—É –∑–¥–µ—Å—å –º—ã —Å–æ—Ö—Ä–∞–Ω–∏–º —Ç–æ–ª—å–∫–æ `input_ids`, `attention_mask` –∏ `label` (–∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω –≤ `labels`). –ß—Ç–æ–±—ã –ø–µ—Ä–µ–ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–∏–≥–Ω–∞—Ç—É—Ä—É –º–æ–¥–µ–ª–∏, –≤—ã –º–æ–∂–µ—Ç–µ –≤—ã–≤–µ—Å—Ç–∏ –∫–ª–∞—Å—Å –≤–∞—à–µ–π –º–æ–¥–µ–ª–∏, –∞ –∑–∞—Ç–µ–º –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –∫ –Ω–µ–π:

```py
type(trainer.model)
```

```python out
transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification
```

–¢–∞–∫, –≤ –Ω–∞—à–µ–º —Å–ª—É—á–∞–µ –º—ã –º–æ–∂–µ–º –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –ø—Ä–∏–Ω—è—Ç—ã–µ –Ω–∞ [—ç—Ç–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ](https://huggingface.co/transformers/model_doc/distilbert.html#distilbertforsequenceclassification). `Trainer` —Ç–∞–∫–∂–µ –±—É–¥–µ—Ç —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–æ–ª–±—Ü—ã, –∫–æ—Ç–æ—Ä—ã–µ –æ–Ω –æ—Ç–±—Ä–∞—Å—ã–≤–∞–µ—Ç.

–ú—ã –ø—Ä–æ–≤–µ—Ä–∏–ª–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –≤–≤–æ–¥–∏–º—ã—Ö –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ –ø—É—Ç–µ–º –∏—Ö –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è. –î–∞–ª–µ–µ —Å–ª–µ–¥—É–µ—Ç `attention_mask`:

```py
trainer.train_dataset[0]["attention_mask"]
```

```python out
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
```

–ü–æ—Å–∫–æ–ª—å–∫—É –º—ã –Ω–µ –ø—Ä–∏–º–µ–Ω—è–ª–∏ –ø—Ä–æ–∫–ª–∞–¥–∫–∏ –≤ –Ω–∞—à–µ–π –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ, —ç—Ç–æ –∫–∞–∂–µ—Ç—Å—è —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–º. –ß—Ç–æ–±—ã —É–±–µ–¥–∏—Ç—å—Å—è –≤ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –ø—Ä–æ–±–ª–µ–º —Å —ç—Ç–æ–π "attention_mask", –¥–∞–≤–∞–π—Ç–µ –ø—Ä–æ–≤–µ—Ä–∏–º, —á—Ç–æ –æ–Ω–∞ –∏–º–µ–µ—Ç —Ç—É –∂–µ –¥–ª–∏–Ω—É, —á—Ç–æ –∏ –Ω–∞—à–∏ –≤—Ö–æ–¥–Ω—ã–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã:

```py
len(trainer.train_dataset[0]["attention_mask"]) == len(
    trainer.train_dataset[0]["input_ids"]
)
```

```python out
True
```

–≠—Ç–æ —Ö–æ—Ä–æ—à–æ! –ò –Ω–∞–∫–æ–Ω–µ—Ü, –¥–∞–≤–∞–π—Ç–µ –ø—Ä–æ–≤–µ—Ä–∏–º –Ω–∞—à—É –º–µ—Ç–∫—É:

```py
trainer.train_dataset[0]["label"]
```

```python out
1
```

–ö–∞–∫ –∏ –≤–≤–æ–¥–∏–º—ã–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã, —ç—Ç–æ —á–∏—Å–ª–æ, –∫–æ—Ç–æ—Ä–æ–µ —Å–∞–º–æ –ø–æ —Å–µ–±–µ –Ω–µ –∏–º–µ–µ—Ç —Å–º—ã—Å–ª–∞. –ö–∞–∫ –º—ã –≤–∏–¥–µ–ª–∏ —Ä–∞–Ω–µ–µ, —Å–≤—è–∑—å –º–µ–∂–¥—É —Ü–µ–ª—ã–º–∏ —á–∏—Å–ª–∞–º–∏ –∏ –∏–º–µ–Ω–∞–º–∏ –º–µ—Ç–æ–∫ —Ö—Ä–∞–Ω–∏—Ç—Å—è –≤ –∞—Ç—Ä–∏–±—É—Ç–µ `names` —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–π *—Ñ—É–Ω–∫—Ü–∏–∏* –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö:

```py
trainer.train_dataset.features["label"].names
```

```python out
['entailment', 'neutral', 'contradiction']
```

–ò—Ç–∞–∫, `1` –æ–∑–Ω–∞—á–∞–µ—Ç `–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ`, –∞ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç, —á—Ç–æ –¥–≤–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –º—ã –≤–∏–¥–µ–ª–∏ –≤—ã—à–µ, –Ω–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∞—Ç –¥—Ä—É–≥ –¥—Ä—É–≥—É, –∏ –∏–∑ –ø–µ—Ä–≤–æ–≥–æ –Ω–µ —Å–ª–µ–¥—É–µ—Ç –≤—Ç–æ—Ä–æ–µ. –≠—Ç–æ –∫–∞–∂–µ—Ç—Å—è –≤–µ—Ä–Ω—ã–º!

–ú—ã –Ω–µ —É–∫–∞–∑—ã–≤–∞–µ–º –∑–¥–µ—Å—å –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã —Ç–∏–ø–æ–≤ —Ç–æ–∫–µ–Ω–æ–≤, –ø–æ—Å–∫–æ–ª—å–∫—É DistilBERT –∏—Ö –Ω–µ –æ–∂–∏–¥–∞–µ—Ç; –µ—Å–ª–∏ –≤ –≤–∞—à–µ–π –º–æ–¥–µ–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å, –≤—ã –¥–æ–ª–∂–Ω—ã —É–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –æ–Ω–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏—é –ø–µ—Ä–≤–æ–≥–æ –∏ –≤—Ç–æ—Ä–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –Ω–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.

<Tip>

‚úèÔ∏è **–í–∞—à–∞ –æ—á–µ—Ä–µ–¥—å!** –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, –≤—Å–µ –ª–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Å–æ –≤—Ç–æ—Ä—ã–º —ç–ª–µ–º–µ–Ω—Ç–æ–º –æ–±—É—á–∞—é—â–µ–≥–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö.

</Tip>

–ó–¥–µ—Å—å –º—ã –ø—Ä–æ–≤–æ–¥–∏–º –ø—Ä–æ–≤–µ—Ä–∫—É —Ç–æ–ª—å–∫–æ –Ω–∞ –æ–±—É—á–∞—é—â–µ–º –Ω–∞–±–æ—Ä–µ, –Ω–æ, –∫–æ–Ω–µ—á–Ω–æ, –≤—ã –¥–æ–ª–∂–Ω—ã –¥–≤–∞–∂–¥—ã –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π –∏ —Ç–µ—Å—Ç–æ–≤—ã–π –Ω–∞–±–æ—Ä—ã —Ç–∞–∫–∏–º –∂–µ –æ–±—Ä–∞–∑–æ–º.

–¢–µ–ø–µ—Ä—å, –∫–æ–≥–¥–∞ –º—ã –∑–Ω–∞–µ–º, —á—Ç–æ –Ω–∞—à–∏ –Ω–∞–±–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö –≤—ã–≥–ª—è–¥—è—Ç —Ö–æ—Ä–æ—à–æ, –ø—Ä–∏—à–ª–æ –≤—Ä–µ–º—è –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–ª–µ–¥—É—é—â–∏–π —à–∞–≥ –ø–∞–π–ø–ª–∞–π–Ω–∞ –æ–±—É—á–µ–Ω–∏—è.

### –û—Ç –Ω–∞–±–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö –∫ –∑–∞–≥—Ä—É–∑—á–∏–∫–∞–º –¥–∞–Ω–Ω—ã—Ö

–°–ª–µ–¥—É—é—â–µ–µ, —á—Ç–æ –º–æ–∂–µ—Ç –ø–æ–π—Ç–∏ –Ω–µ —Ç–∞–∫ –≤ –ø–∞–π–ø–ª–∞–π–Ω–µ –æ–±—É—á–µ–Ω–∏—è, —ç—Ç–æ –∫–æ–≥–¥–∞ `Trainer` –ø—ã—Ç–∞–µ—Ç—Å—è —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –Ω–∞–±–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö –∏–∑ –æ–±—É—á–∞—é—â–µ–≥–æ –∏–ª–∏ –ø—Ä–æ–≤–µ—Ä–æ—á–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞. –ö–∞–∫ —Ç–æ–ª—å–∫–æ –≤—ã —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –Ω–∞–±–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö `Trainer` –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã, –≤—ã –º–æ–∂–µ—Ç–µ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –≤—Ä—É—á–Ω—É—é —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –Ω–∞–±–æ—Ä, –≤—ã–ø–æ–ª–Ω–∏–≤ —Å–ª–µ–¥—É—é—â–∏–µ –¥–µ–π—Å—Ç–≤–∏—è (–∑–∞–º–µ–Ω–∏—Ç–µ `train` –Ω–∞ `eval` –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–∞–≥—Ä—É–∑—á–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö):

```py
for batch in trainer.get_train_dataloader():
    break
```

–≠—Ç–æ—Ç –∫–æ–¥ —Å–æ–∑–¥–∞–µ—Ç –∑–∞–≥—Ä—É–∑—á–∏–∫ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è, –∑–∞—Ç–µ–º –≤—ã–ø–æ–ª–Ω—è–µ—Ç –∏—Ç–µ—Ä–∞—Ü–∏–∏ –ø–æ –Ω–µ–º—É, –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—è—Å—å –Ω–∞ –ø–µ—Ä–≤–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏. –ï—Å–ª–∏ –∫–æ–¥ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –±–µ–∑ –æ—à–∏–±–æ–∫, —É –≤–∞—Å –µ—Å—Ç—å –ø–µ—Ä–≤—ã–π –æ–±—É—á–∞—é—â–∏–π –Ω–∞–±–æ—Ä, –∫–æ—Ç–æ—Ä—ã–π –≤—ã –º–æ–∂–µ—Ç–µ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, –∞ –µ—Å–ª–∏ –∫–æ–¥ –≤—ã–¥–∞–µ—Ç –æ—à–∏–±–∫—É, –≤—ã —Ç–æ—á–Ω–æ –∑–Ω–∞–µ—Ç–µ, —á—Ç–æ –ø—Ä–æ–±–ª–µ–º–∞ –≤ –∑–∞–≥—Ä—É–∑—á–∏–∫–µ –¥–∞–Ω–Ω—ã—Ö, –∫–∞–∫ –≤ –¥–∞–Ω–Ω–æ–º —Å–ª—É—á–∞–µ:

```python out
~/git/transformers/src/transformers/data/data_collator.py in torch_default_data_collator(features)
    105                 batch[k] = torch.stack([f[k] for f in features])
    106             else:
--> 107                 batch[k] = torch.tensor([f[k] for f in features])
    108 
    109     return batch

ValueError: expected sequence of length 45 at dim 1 (got 76)
```

–û—Å–º–æ—Ç—Ä–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∫–∞–¥—Ä–∞ —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, —á—Ç–æ–±—ã –¥–∞—Ç—å –≤–∞–º –ø–æ–¥—Å–∫–∞–∑–∫—É, –Ω–æ –¥–∞–≤–∞–π—Ç–µ –∫–æ–ø–Ω–µ–º –µ—â–µ –Ω–µ–º–Ω–æ–≥–æ. –ë–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –ø—Ä–æ–±–ª–µ–º –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –ø–∞–∫–µ—Ç–∞ –≤–æ–∑–Ω–∏–∫–∞–µ—Ç –∏–∑-–∑–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ –æ–¥–∏–Ω –Ω–∞–±–æ—Ä, –ø–æ—ç—Ç–æ–º—É –ø–µ—Ä–≤–æ–µ, —á—Ç–æ –Ω—É–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ø—Ä–∏ –≤–æ–∑–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏–∏ —Å–æ–º–Ω–µ–Ω–∏–π, —ç—Ç–æ —Ç–æ, –∫–∞–∫–æ–π `collate_fn` –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≤–∞—à `DataLoader`:

```py
data_collator = trainer.get_train_dataloader().collate_fn
data_collator
```

```python out
<function transformers.data.data_collator.default_data_collator(features: List[InputDataClass], return_tensors='pt') -> Dict[str, Any]>
```

–ò—Ç–∞–∫, —ç—Ç–æ `default_data_collator`, –Ω–æ —ç—Ç–æ –Ω–µ —Ç–æ, —á—Ç–æ –Ω–∞–º –Ω—É–∂–Ω–æ –≤ –¥–∞–Ω–Ω–æ–º —Å–ª—É—á–∞–µ. –ú—ã —Ö–æ—Ç–∏–º –ø—Ä–∏–≤–µ—Å—Ç–∏ –Ω–∞—à–∏ –ø—Ä–∏–º–µ—Ä—ã –∫ —Å–∞–º–æ–º—É –¥–ª–∏–Ω–Ω–æ–º—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—é –≤ –Ω–∞–±–æ—Ä–µ, —á—Ç–æ –¥–µ–ª–∞–µ—Ç `DataCollatorWithPadding`. –ò —ç—Ç–æ—Ç –¥–∞—Ç–∞–∫–æ–ª–ª–∞—Ç–æ—Ä –¥–æ–ª–∂–µ–Ω –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤ `Trainer`, —Ç–∞–∫ –ø–æ—á–µ–º—É –∂–µ –æ–Ω –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–¥–µ—Å—å?

–û—Ç–≤–µ—Ç –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ —Ç–æ–º, —á—Ç–æ –º—ã –Ω–µ –ø–µ—Ä–µ–¥–∞–ª–∏ `tokenizer` –≤ `Trainer`, –ø–æ—ç—Ç–æ–º—É –æ–Ω –Ω–µ —Å–º–æ–≥ —Å–æ–∑–¥–∞—Ç—å –Ω—É–∂–Ω—ã–π –Ω–∞–º `DataCollatorWithPadding`. –ù–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø–æ–¥–æ–±–Ω—ã—Ö –æ—à–∏–±–æ–∫, –Ω–µ —Å–ª–µ–¥—É–µ—Ç —Å—Ç–µ—Å–Ω—è—Ç—å—Å—è —è–≤–Ω–æ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å –∫–æ–ª–ª–∞—Ç–æ—Ä –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–π –≤—ã —Ö–æ—Ç–∏—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å. –î–∞–≤–∞–π—Ç–µ –∞–¥–∞–ø—Ç–∏—Ä—É–µ–º –Ω–∞—à –∫–æ–¥, —á—Ç–æ–±—ã —Å–¥–µ–ª–∞—Ç—å –∏–º–µ–Ω–Ω–æ —ç—Ç–æ:

```py
from datasets import load_dataset
import evaluate
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    DataCollatorWithPadding,
    TrainingArguments,
    Trainer,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
    return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)

args = TrainingArguments(
    f"distilbert-finetuned-mnli",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
)

metric = evaluate.load("glue", "mnli")


def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    return metric.compute(predictions=predictions, references=labels)


data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

trainer = Trainer(
    model,
    args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation_matched"],
    compute_metrics=compute_metrics,
    data_collator=data_collator,
    tokenizer=tokenizer,
)
trainer.train()
```

–•–æ—Ä–æ—à–∏–µ –Ω–æ–≤–æ—Å—Ç–∏? –ú—ã –Ω–µ –ø–æ–ª—É—á–∞–µ–º —Ç—É –∂–µ –æ—à–∏–±–∫—É, —á—Ç–æ –∏ —Ä–∞–Ω—å—à–µ, —á—Ç–æ, –±–µ–∑—É—Å–ª–æ–≤–Ω–æ, —è–≤–ª—è–µ—Ç—Å—è –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º. –ü–ª–æ—Ö–∞—è –Ω–æ–≤–æ—Å—Ç—å? –í–º–µ—Å—Ç–æ –Ω–µ–µ –º—ã –ø–æ–ª—É—á–∞–µ–º –∏–∑–≤–µ—Å—Ç–Ω—É—é –æ—à–∏–±–∫—É CUDA:

```python out
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
```

–≠—Ç–æ –ø–ª–æ—Ö–æ, –ø–æ—Ç–æ–º—É —á—Ç–æ –æ—à–∏–±–∫–∏ CUDA –≤–æ–æ–±—â–µ –æ—á–µ–Ω—å —Ç—Ä—É–¥–Ω–æ –æ—Ç–ª–∞–∂–∏–≤–∞—Ç—å. –ß–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É –º—ã —É–≤–∏–¥–∏–º, –∫–∞–∫ —Ä–µ—à–∏—Ç—å —ç—Ç—É –ø—Ä–æ–±–ª–µ–º—É, –Ω–æ —Å–Ω–∞—á–∞–ª–∞ –¥–∞–≤–∞–π—Ç–µ –∑–∞–∫–æ–Ω—á–∏–º –∞–Ω–∞–ª–∏–∑ —Å–æ–∑–¥–∞–Ω–∏—è –Ω–∞–±–æ—Ä–æ–≤.

–ï—Å–ª–∏ –≤—ã —É–≤–µ—Ä–µ–Ω—ã, —á—Ç–æ –≤–∞—à –∫–æ–ª–ª–∞—Ç–æ—Ä –¥–∞–Ω–Ω—ã—Ö —è–≤–ª—è–µ—Ç—Å—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º, —Ç–æ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø—Ä–∏–º–µ–Ω–∏—Ç—å –µ–≥–æ –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –æ–±—Ä–∞–∑—Ü–∞—Ö –≤–∞—à–µ–≥–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö:

```py
data_collator = trainer.get_train_dataloader().collate_fn
batch = data_collator([trainer.train_dataset[i] for i in range(4)])
```

–≠—Ç–æ—Ç –∫–æ–¥ –Ω–µ –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω, –ø–æ—Ç–æ–º—É —á—Ç–æ `train_dataset` —Å–æ–¥–µ—Ä–∂–∏—Ç —Å—Ç—Ä–æ–∫–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ `Trainer` –æ–±—ã—á–Ω–æ —É–¥–∞–ª—è–µ—Ç. –í—ã –º–æ–∂–µ—Ç–µ —É–¥–∞–ª–∏—Ç—å –∏—Ö –≤—Ä—É—á–Ω—É—é, –∏–ª–∏, –µ—Å–ª–∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ —Ç–æ—á–Ω–æ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏ —Ç–æ, —á—Ç–æ –¥–µ–ª–∞–µ—Ç `Trainer` –∑–∞ –∫—É–ª–∏—Å–∞–º–∏, –≤—ã –º–æ–∂–µ—Ç–µ –≤—ã–∑–≤–∞—Ç—å –ø—Ä–∏–≤–∞—Ç–Ω—ã–π –º–µ—Ç–æ–¥ `Trainer._remove_unused_columns()`, –∫–æ—Ç–æ—Ä—ã–π –¥–µ–ª–∞–µ—Ç —ç—Ç–æ:

```py
data_collator = trainer.get_train_dataloader().collate_fn
actual_train_set = trainer._remove_unused_columns(trainer.train_dataset)
batch = data_collator([actual_train_set[i] for i in range(4)])
```

–í—ã –¥–æ–ª–∂–Ω—ã –∏–º–µ—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –≤—Ä—É—á–Ω—É—é –æ—Ç–ª–∞–¥–∏—Ç—å, —á—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –≤–Ω—É—Ç—Ä–∏ –∫–æ–ª–ª–∞—Ç–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö, –µ—Å–ª–∏ –æ—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è.

–¢–µ–ø–µ—Ä—å, –∫–æ–≥–¥–∞ –º—ã –æ—Ç–ª–∞–¥–∏–ª–∏ –ø—Ä–æ—Ü–µ—Å—Å —Å–æ–∑–¥–∞–Ω–∏—è –Ω–∞–±–æ—Ä–∞, –ø—Ä–∏—à–ª–æ –≤—Ä–µ–º—è –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –µ–≥–æ —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å!

### –ü—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å

–í—ã –¥–æ–ª–∂–Ω—ã –ø–æ–ª—É—á–∏—Ç—å –Ω–∞–±–æ—Ä, –≤—ã–ø–æ–ª–Ω–∏–≤ —Å–ª–µ–¥—É—é—â—É—é –∫–æ–º–∞–Ω–¥—É:

```py
for batch in trainer.get_train_dataloader():
    break
```

–ï—Å–ª–∏ –≤—ã –≤—ã–ø–æ–ª–Ω—è–µ—Ç–µ —ç—Ç–æ—Ç –∫–æ–¥ –≤ –±–ª–æ–∫–Ω–æ—Ç–µ, –≤—ã –º–æ–∂–µ—Ç–µ –ø–æ–ª—É—á–∏—Ç—å –æ—à–∏–±–∫—É CUDA, –ø–æ—Ö–æ–∂—É—é –Ω–∞ —Ç—É, —á—Ç–æ –º—ã –≤–∏–¥–µ–ª–∏ —Ä–∞–Ω–µ–µ, –≤ —ç—Ç–æ–º —Å–ª—É—á–∞–µ –≤–∞–º –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å –±–ª–æ–∫–Ω–æ—Ç –∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç –±–µ–∑ —Å—Ç—Ä–æ–∫–∏ `trainer.train()`. –≠—Ç–æ –≤—Ç–æ—Ä–∞—è —Å–∞–º–∞—è –Ω–µ–ø—Ä–∏—è—Ç–Ω–∞—è –≤–µ—â—å –≤ –æ—à–∏–±–∫–∞—Ö CUDA: –æ–Ω–∏ –±–µ–∑–≤–æ–∑–≤—Ä–∞—Ç–Ω–æ –ª–æ–º–∞—é—Ç –≤–∞—à–µ –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–µ —è–¥—Ä–æ. –°–∞–º–æ–µ –Ω–µ–ø—Ä–∏—è—Ç–Ω–æ–µ –≤ –Ω–∏—Ö —Ç–æ, —á—Ç–æ –∏—Ö —Ç—Ä—É–¥–Ω–æ –æ—Ç–ª–∞–∂–∏–≤–∞—Ç—å.

–ù–æ –ø–æ—á–µ–º—É? –≠—Ç–æ —Å–≤—è–∑–∞–Ω–æ —Å –ø—Ä–∏–Ω—Ü–∏–ø–æ–º —Ä–∞–±–æ—Ç—ã –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–≤. –û–Ω–∏ —á—Ä–µ–∑–≤—ã—á–∞–π–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã –ø—Ä–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –æ–ø–µ—Ä–∞—Ü–∏–π, –Ω–æ –∏—Ö –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ–∫ –≤ —Ç–æ–º, —á—Ç–æ –∫–æ–≥–¥–∞ –æ–¥–Ω–∞ –∏–∑ —ç—Ç–∏—Ö –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –æ—à–∏–±–∫–µ, –≤—ã –Ω–µ –º–æ–∂–µ—Ç–µ —É–∑–Ω–∞—Ç—å –æ–± —ç—Ç–æ–º –º–≥–Ω–æ–≤–µ–Ω–Ω–æ. –¢–æ–ª—å–∫–æ –∫–æ–≥–¥–∞ –ø—Ä–æ–≥—Ä–∞–º–º–∞ –≤—ã–∑–æ–≤–µ—Ç —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –Ω–∞ GPU, –æ–Ω–∞ –ø–æ–π–º–µ—Ç, —á—Ç–æ —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫, –ø–æ—ç—Ç–æ–º—É –æ—à–∏–±–∫–∞ –≤–æ–∑–Ω–∏–∫–∞–µ—Ç –≤ –º–µ—Å—Ç–µ, –∫–æ—Ç–æ—Ä–æ–µ –Ω–µ –∏–º–µ–µ—Ç –Ω–∏–∫–∞–∫–æ–≥–æ –æ—Ç–Ω–æ—à–µ–Ω–∏—è –∫ —Ç–æ–º—É, —á—Ç–æ –µ–µ —Å–æ–∑–¥–∞–ª–æ. –ù–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ –º—ã –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏–π —Ç—Ä–µ–π—Å–±–µ–∫, —Ç–æ –æ—à–∏–±–∫–∞ –≤–æ–∑–Ω–∏–∫–ª–∞ –≤–æ –≤—Ä–µ–º—è –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –ø—Ä–æ—Ö–æ–¥–∞, –Ω–æ —Å–∫–æ—Ä–æ –º—ã —É–≤–∏–¥–∏–º, —á—Ç–æ –Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ –æ–Ω–∞ –≤–æ–∑–Ω–∏–∫–ª–∞ –∏–∑-–∑–∞ —á–µ–≥–æ-—Ç–æ –≤ –ø—Ä—è–º–æ–º –ø—Ä–æ—Ö–æ–¥–µ.

–ö–∞–∫ –∂–µ –º—ã –æ—Ç–ª–∞–∂–∏–≤–∞–µ–º —ç—Ç–∏ –æ—à–∏–±–∫–∏? –û—Ç–≤–µ—Ç –ø—Ä–æ—Å—Ç: –Ω–∏–∫–∞–∫. –ï—Å–ª–∏ —Ç–æ–ª—å–∫–æ –æ—à–∏–±–∫–∞ CUDA –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –æ—à–∏–±–∫–æ–π –≤–Ω–µ –ø–∞–º—è—Ç–∏ (—á—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –≤ –≤–∞—à–µ–º GPU –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–∞–º—è—Ç–∏), –≤—ã –≤—Å–µ–≥–¥–∞ –¥–æ–ª–∂–Ω—ã –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å—Å—è –∫ CPU –¥–ª—è –µ–µ –æ—Ç–ª–∞–¥–∫–∏.

–ß—Ç–æ–±—ã —Å–¥–µ–ª–∞—Ç—å —ç—Ç–æ –≤ –Ω–∞—à–µ–º —Å–ª—É—á–∞–µ, –º—ã –ø—Ä–æ—Å—Ç–æ –¥–æ–ª–∂–Ω—ã –ø–æ–º–µ—Å—Ç–∏—Ç—å –º–æ–¥–µ–ª—å –æ–±—Ä–∞—Ç–Ω–æ –Ω–∞ CPU –∏ –≤—ã–∑–≤–∞—Ç—å –µ–µ –Ω–∞ –Ω–∞—à–µ–º –Ω–∞–±–æ—Ä–µ - –Ω–∞–±–æ—Ä, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—ã–π `DataLoader`, –µ—â–µ –Ω–µ –±—ã–ª –ø–µ—Ä–µ–º–µ—â–µ–Ω –Ω–∞ GPU:

```python
outputs = trainer.model.cpu()(**batch)
```

```python out
~/.pyenv/versions/3.7.9/envs/base/lib/python3.7/site-packages/torch/nn/functional.py in nll_loss(input, target, weight, size_average, ignore_index, reduce, reduction)
   2386         )
   2387     if dim == 2:
-> 2388         ret = torch._C._nn.nll_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index)
   2389     elif dim == 4:
   2390         ret = torch._C._nn.nll_loss2d(input, target, weight, _Reduction.get_enum(reduction), ignore_index)

IndexError: Target 2 is out of bounds.
```

–ò—Ç–∞–∫, –∫–∞—Ä—Ç–∏–Ω–∞ —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –±–æ–ª–µ–µ —è—Å–Ω–æ–π. –í–º–µ—Å—Ç–æ –æ—à–∏–±–∫–∏ CUDA –º—ã —Ç–µ–ø–µ—Ä—å –∏–º–µ–µ–º `IndexError` –ø—Ä–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–∏ –ø–æ—Ç–µ—Ä—å (–ø–æ—ç—Ç–æ–º—É –Ω–∏—á–µ–≥–æ –æ–±—â–µ–≥–æ —Å –æ–±—Ä–∞—Ç–Ω—ã–º –ø—Ä–æ—Ö–æ–¥–æ–º, –∫–∞–∫ –º—ã –≥–æ–≤–æ—Ä–∏–ª–∏ —Ä–∞–Ω–µ–µ). –¢–æ—á–Ω–µ–µ, –º—ã –≤–∏–¥–∏–º, —á—Ç–æ –æ—à–∏–±–∫–∞ –≤–æ–∑–Ω–∏–∫–∞–µ—Ç –∏–º–µ–Ω–Ω–æ –≤ —Ü–µ–ª–∏ 2, —Ç–∞–∫ —á—Ç–æ —ç—Ç–æ –æ—á–µ–Ω—å —Ö–æ—Ä–æ—à–∏–π –º–æ–º–µ–Ω—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –º–µ—Ç–æ–∫ –Ω–∞—à–µ–π –º–æ–¥–µ–ª–∏:

```python
trainer.model.config.num_labels
```

```python out
2
```

–ü—Ä–∏ –¥–≤—É—Ö –º–µ—Ç–∫–∞—Ö –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Ü–µ–ª–µ–π –¥–æ–ø—É—Å–∫–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ 0 –∏ 1, –Ω–æ, —Å–æ–≥–ª–∞—Å–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏—é –æ–± –æ—à–∏–±–∫–µ, –º—ã –ø–æ–ª—É—á–∏–ª–∏ 2. –ü–æ–ª—É—á–µ–Ω–∏–µ 2 –Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ: –µ—Å–ª–∏ –º—ã –ø–æ–º–Ω–∏–º –∏–º–µ–Ω–∞ –º–µ—Ç–æ–∫, –∫–æ—Ç–æ—Ä—ã–µ –º—ã –∏–∑–≤–ª–µ–∫–ª–∏ —Ä–∞–Ω–µ–µ, –∏—Ö –±—ã–ª–æ —Ç—Ä–∏, –ø–æ—ç—Ç–æ–º—É –≤ –Ω–∞—à–µ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö –µ—Å—Ç—å –∏–Ω–¥–µ–∫—Å—ã 0, 1 –∏ 2. –ü—Ä–æ–±–ª–µ–º–∞ –≤ —Ç–æ–º, —á—Ç–æ –º—ã –Ω–µ —Å–æ–æ–±—â–∏–ª–∏ —ç—Ç–æ –Ω–∞—à–µ–π –º–æ–¥–µ–ª–∏, –∫–æ—Ç–æ—Ä–∞—è –¥–æ–ª–∂–Ω–∞ –±—ã–ª–∞ –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω–∞ —Å —Ç—Ä–µ–º—è –º–µ—Ç–∫–∞–º–∏. –¢–∞–∫ —á—Ç–æ –¥–∞–≤–∞–π—Ç–µ —ç—Ç–æ –∏—Å–ø—Ä–∞–≤–∏–º!

```py
from datasets import load_dataset
import evaluate
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    DataCollatorWithPadding,
    TrainingArguments,
    Trainer,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
    return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=3)

args = TrainingArguments(
    f"distilbert-finetuned-mnli",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
)

metric = evaluate.load("glue", "mnli")


def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    return metric.compute(predictions=predictions, references=labels)


data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

trainer = Trainer(
    model,
    args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation_matched"],
    compute_metrics=compute_metrics,
    data_collator=data_collator,
    tokenizer=tokenizer,
)
```

–ú—ã –ø–æ–∫–∞ –Ω–µ –≤–∫–ª—é—á–∞–µ–º —Å—Ç—Ä–æ–∫—É `trainer.train()`, —á—Ç–æ–±—ã –ø–æ—Ç—Ä–∞—Ç–∏—Ç—å –≤—Ä–µ–º—è –Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫—É —Ç–æ–≥–æ, —á—Ç–æ –≤—Å–µ –≤—ã–≥–ª—è–¥–∏—Ç —Ö–æ—Ä–æ—à–æ. –ï—Å–ª–∏ –º—ã –∑–∞–ø—Ä–æ—Å–∏–º –Ω–∞–±–æ—Ä –∏ –ø–µ—Ä–µ–¥–∞–¥–∏–º –µ–≥–æ –Ω–∞—à–µ–π –º–æ–¥–µ–ª–∏, —Ç–æ —Ç–µ–ø–µ—Ä—å –º–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ –æ—à–∏–±–æ–∫!

```py
for batch in trainer.get_train_dataloader():
    break

outputs = trainer.model.cpu()(**batch)
```

–°–ª–µ–¥—É—é—â–∏–π —à–∞–≥ - –≤–µ—Ä–Ω—É—Ç—å—Å—è –∫ GPU –∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ –≤—Å–µ –ø–æ-–ø—Ä–µ–∂–Ω–µ–º—É —Ä–∞–±–æ—Ç–∞–µ—Ç:

```py
import torch

device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
batch = {k: v.to(device) for k, v in batch.items()}

outputs = trainer.model.to(device)(**batch)
```

–ï—Å–ª–∏ –≤—ã –ø–æ-–ø—Ä–µ–∂–Ω–µ–º—É –ø–æ–ª—É—á–∞–µ—Ç–µ –æ—à–∏–±–∫—É, —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—ã –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏–ª–∏ –±–ª–æ–∫–Ω–æ—Ç –∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç–µ —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω—é—é –≤–µ—Ä—Å–∏—é —Å–∫—Ä–∏–ø—Ç–∞.

### –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –æ–¥–Ω–æ–≥–æ —à–∞–≥–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏

–¢–µ–ø–µ—Ä—å, –∫–æ–≥–¥–∞ –º—ã –∑–Ω–∞–µ–º, —á—Ç–æ –º–æ–∂–µ–º —Å–æ–∑–¥–∞–≤–∞—Ç—å –Ω–∞–±–æ—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–æ—Ö–æ–¥—è—Ç —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å, –º—ã –≥–æ—Ç–æ–≤—ã –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —à–∞–≥—É –ø–∞–π–ø–ª–∞–π–Ω–∞ –æ–±—É—á–µ–Ω–∏—è: –≤—ã—á–∏—Å–ª–µ–Ω–∏—é –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—é —à–∞–≥–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏.

–ü–µ—Ä–≤–∞—è —á–∞—Å—Ç—å - —ç—Ç–æ –ø—Ä–æ—Å—Ç–æ –≤—ã–∑–æ–≤ –º–µ—Ç–æ–¥–∞ `backward()` –¥–ª—è loss:

```py
loss = outputs.loss
loss.backward()
```

–û—à–∏–±–∫–∞ –Ω–∞ —ç—Ç–æ–º —ç—Ç–∞–ø–µ –≤–æ–∑–Ω–∏–∫–∞–µ—Ç –¥–æ–≤–æ–ª—å–Ω–æ —Ä–µ–¥–∫–æ, –Ω–æ –µ—Å–ª–∏ –æ–Ω–∞ –≤—Å–µ –∂–µ –≤–æ–∑–Ω–∏–∫–ª–∞, –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –≤–µ—Ä–Ω–∏—Ç–µ—Å—å –∫ CPU, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –ø–æ–ª–µ–∑–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ.

–ß—Ç–æ–±—ã –≤—ã–ø–æ–ª–Ω–∏—Ç—å —à–∞–≥ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏, –Ω–∞–º –ø—Ä–æ—Å—Ç–æ –Ω—É–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å `optimizer` –∏ –≤—ã–∑–≤–∞—Ç—å –µ–≥–æ –º–µ—Ç–æ–¥ `step()`:

```py
trainer.create_optimizer()
trainer.optimizer.step()
```

–û–ø—è—Ç—å –∂–µ, –µ—Å–ª–∏ –≤—ã –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤ `Trainer`, –≤—ã –Ω–µ –¥–æ–ª–∂–Ω—ã –ø–æ–ª—É—á–∏—Ç—å –æ—à–∏–±–∫—É –Ω–∞ —ç—Ç–æ–º —ç—Ç–∞–ø–µ, –Ω–æ –µ—Å–ª–∏ –≤—ã –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä, –∑–¥–µ—Å—å –º–æ–≥—É—Ç –≤–æ–∑–Ω–∏–∫–Ω—É—Ç—å –ø—Ä–æ–±–ª–µ–º—ã –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏. –ù–µ –∑–∞–±—É–¥—å—Ç–µ –≤–µ—Ä–Ω—É—Ç—å—Å—è –∫ CPU, –µ—Å–ª–∏ –≤—ã –ø–æ–ª—É—á–∏—Ç–µ –æ—à–∏–±–∫—É CUDA. –ö—Å—Ç–∞—Ç–∏, –æ–± –æ—à–∏–±–∫–∞—Ö CUDA, —Ä–∞–Ω–µ–µ –º—ã —É–ø–æ–º–∏–Ω–∞–ª–∏ –æ—Å–æ–±—ã–π —Å–ª—É—á–∞–π. –î–∞–≤–∞–π—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –Ω–µ–≥–æ —Å–µ–π—á–∞—Å.

### –†–∞–±–æ—Ç–∞ —Å –æ—à–∏–±–∫–∞–º–∏ CUDA –≤–Ω–µ –ø–∞–º—è—Ç–∏

–ï—Å–ª–∏ –≤—ã –ø–æ–ª—É—á–∞–µ—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ, –Ω–∞—á–∏–Ω–∞—é—â–µ–µ—Å—è —Å `RuntimeError: CUDA out of memory`, —ç—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –≤–∞–º –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –ø–∞–º—è—Ç–∏ GPU. –≠—Ç–æ –Ω–µ —Å–≤—è–∑–∞–Ω–æ –Ω–∞–ø—Ä—è–º—É—é —Å –≤–∞—à–∏–º –∫–æ–¥–æ–º, –∏ –º–æ–∂–µ—Ç –ø—Ä–æ–∏–∑–æ–π—Ç–∏ —Å–æ —Å—Ü–µ–Ω–∞—Ä–∏–µ–º, –∫–æ—Ç–æ—Ä—ã–π —Ä–∞–±–æ—Ç–∞–µ—Ç —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ. –≠—Ç–∞ –æ—à–∏–±–∫–∞ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –≤—ã –ø—ã—Ç–∞–ª–∏—Å—å –ø–æ–º–µ—Å—Ç–∏—Ç—å —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –¥–∞–Ω–Ω—ã—Ö –≤–æ –≤–Ω—É—Ç—Ä–µ–Ω–Ω—é—é –ø–∞–º—è—Ç—å –≤–∞—à–µ–≥–æ GPU, –∏ —ç—Ç–æ –ø—Ä–∏–≤–µ–ª–æ –∫ –æ—à–∏–±–∫–µ. –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ –¥—Ä—É–≥–∏–º –æ—à–∏–±–∫–∞–º CUDA, –≤–∞–º –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–µ —è–¥—Ä–æ, —á—Ç–æ–±—ã —Å–Ω–æ–≤–∞ –∑–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ.

–ß—Ç–æ–±—ã —Ä–µ—à–∏—Ç—å —ç—Ç—É –ø—Ä–æ–±–ª–µ–º—É, –Ω—É–∂–Ω–æ –ø—Ä–æ—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–µ–Ω—å—à–µ –º–µ—Å—Ç–∞ –Ω–∞ GPU - —Ç–æ, —á—Ç–æ –∑–∞—á–∞—Å—Ç—É—é –ª–µ–≥—á–µ —Å–∫–∞–∑–∞—Ç—å, —á–µ–º —Å–¥–µ–ª–∞—Ç—å. –í–æ-–ø–µ—Ä–≤—ã—Ö, —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É –≤–∞—Å –Ω–µ—Ç –¥–≤—É—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ GPU –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ (–∫–æ–Ω–µ—á–Ω–æ, –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –≤–∞—à–µ–π –∑–∞–¥–∞—á–∏). –ó–∞—Ç–µ–º, –≤–µ—Ä–æ—è—Ç–Ω–æ, —Å–ª–µ–¥—É–µ—Ç —É–º–µ–Ω—å—à–∏—Ç—å —Ä–∞–∑–º–µ—Ä –Ω–∞–±–æ—Ä–∞, –ø–æ—Å–∫–æ–ª—å–∫—É –æ–Ω –Ω–∞–ø—Ä—è–º—É—é –≤–ª–∏—è–µ—Ç –Ω–∞ —Ä–∞–∑–º–µ—Ä—ã –≤—Å–µ—Ö –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö –≤—ã—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–∏ –∏ –∏—Ö –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤. –ï—Å–ª–∏ –ø—Ä–æ–±–ª–µ–º–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è, –ø–æ–¥—É–º–∞–π—Ç–µ –æ–± –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ –º–µ–Ω—å—à–µ–π –≤–µ—Ä—Å–∏–∏ –≤–∞—à–µ–π –º–æ–¥–µ–ª–∏.

<Tip>

–í —Å–ª–µ–¥—É—é—â–µ–π —á–∞—Å—Ç–∏ –∫—É—Ä—Å–∞ –º—ã —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º –±–æ–ª–µ–µ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –º–µ—Ç–æ–¥—ã, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–º–æ–≥—É—Ç –≤–∞–º —É–º–µ–Ω—å—à–∏—Ç—å –æ–±—ä–µ–º –ø–∞–º—è—Ç–∏ –∏ –ø–æ–∑–≤–æ–ª—è—Ç —Ç–æ—á–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å —Å–∞–º—ã–µ –±–æ–ª—å—à–∏–µ –º–æ–¥–µ–ª–∏.

</Tip>

### –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏

–¢–µ–ø–µ—Ä—å, –∫–æ–≥–¥–∞ –º—ã —Ä–µ—à–∏–ª–∏ –≤—Å–µ –ø—Ä–æ–±–ª–µ–º—ã —Å –Ω–∞—à–∏–º –∫–æ–¥–æ–º, –≤—Å–µ –∏–¥–µ–∞–ª—å–Ω–æ, –∏ –æ–±—É—á–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –ø—Ä–æ–π—Ç–∏ –≥–ª–∞–¥–∫–æ, –≤–µ—Ä–Ω–æ? –ù–µ —Ç–∞–∫ –±—ã—Å—Ç—Ä–æ! –ï—Å–ª–∏ –≤—ã –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –∫–æ–º–∞–Ω–¥—É `trainer.train()`, —Å–Ω–∞—á–∞–ª–∞ –≤—Å–µ –±—É–¥–µ—Ç –≤—ã–≥–ª—è–¥–µ—Ç—å —Ö–æ—Ä–æ—à–æ, –Ω–æ –ø–æ—Ç–æ–º –≤—ã –ø–æ–ª—É—á–∏—Ç–µ —Å–ª–µ–¥—É—é—â–µ–µ:

```py
# This will take a long time and error out, so you shouldn't run this cell
trainer.train()
```

```python out
TypeError: only size-1 arrays can be converted to Python scalars
```

–í—ã –ø–æ–π–º–µ—Ç–µ, —á—Ç–æ —ç—Ç–∞ –æ—à–∏–±–∫–∞ –ø–æ—è–≤–ª—è–µ—Ç—Å—è –Ω–∞ —ç—Ç–∞–ø–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è, –ø–æ—ç—Ç–æ–º—É —ç—Ç–æ –ø–æ—Å–ª–µ–¥–Ω–µ–µ, —á—Ç–æ –Ω–∞–º –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç –æ—Ç–ª–∞–∂–∏–≤–∞—Ç—å.

–í—ã –º–æ–∂–µ—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å —Ü–∏–∫–ª –≤—ã—á–∏—Å–ª–µ–Ω–∏—è `Trainer` –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –æ–±—É—á–µ–Ω–∏—è —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º:

```py
trainer.evaluate()
```

```python out
TypeError: only size-1 arrays can be converted to Python scalars
```

<Tip>

üí° –í—ã –≤—Å–µ–≥–¥–∞ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —É–≤–µ—Ä–µ–Ω—ã, —á—Ç–æ –º–æ–∂–µ—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å `trainer.evaluate()` –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º `trainer.train()`, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Ç—Ä–∞—Ç—ã –±–æ–ª—å—à–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤ –¥–æ –≤–æ–∑–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏—è –æ—à–∏–±–∫–∏.

</Tip>

–ü—Ä–µ–∂–¥–µ —á–µ–º –ø—ã—Ç–∞—Ç—å—Å—è –æ—Ç–ª–∞–¥–∏—Ç—å –ø—Ä–æ–±–ª–µ–º—É –≤ —Ü–∏–∫–ª–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Å–Ω–∞—á–∞–ª–∞ —É–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤—ã –ø–æ—Å–º–æ—Ç—Ä–µ–ª–∏ –Ω–∞ –¥–∞–Ω–Ω—ã–µ, —Å–º–æ–≥–ª–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –Ω–∞–±–æ—Ä –∏ –º–æ–∂–µ—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å –Ω–∞ –Ω–∏—Ö —Å–≤–æ—é –º–æ–¥–µ–ª—å. –ú—ã –≤—ã–ø–æ–ª–Ω–∏–ª–∏ –≤—Å–µ —ç—Ç–∏ —à–∞–≥–∏, –ø–æ—ç—Ç–æ–º—É —Å–ª–µ–¥—É—é—â–∏–π –∫–æ–¥ –º–æ–∂–µ—Ç –±—ã—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω –±–µ–∑ –æ—à–∏–±–æ–∫:

```py
for batch in trainer.get_eval_dataloader():
    break

batch = {k: v.to(device) for k, v in batch.items()}

with torch.no_grad():
    outputs = trainer.model(**batch)
```

–û—à–∏–±–∫–∞ –≤–æ–∑–Ω–∏–∫–∞–µ—Ç –≤ –∫–æ–Ω—Ü–µ —Ñ–∞–∑—ã –≤—ã—á–∏—Å–ª–µ–Ω–∏—è, –∏ –µ—Å–ª–∏ –º—ã –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Ç—Ä–µ–π—Å–±–µ–∫, —Ç–æ —É–≤–∏–¥–∏–º —Å–ª–µ–¥—É—é—â–µ–µ:

```python trace
~/git/datasets/src/datasets/metric.py in add_batch(self, predictions, references)
    431
    432         batch = {"predictions": predictions, "references": references}
--> 433         batch = self.info.features.encode_batch(batch)
    434         if self.writer is None:
    435             self._init_writer()
```

–≠—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç –Ω–∞–º, —á—Ç–æ –æ—à–∏–±–∫–∞ –≤–æ–∑–Ω–∏–∫–∞–µ—Ç –≤ –º–æ–¥—É–ª–µ `datasets/metric.py` - —Ç–∞–∫ —á—Ç–æ —ç—Ç–æ –ø—Ä–æ–±–ª–µ–º–∞ —Å –Ω–∞—à–µ–π —Ñ—É–Ω–∫—Ü–∏–µ–π `compute_metrics()`. –û–Ω–∞ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –∫–æ—Ä—Ç–µ–∂ —Å –ª–æ–≥–∏—Ç–∞–º–∏ –∏ –º–µ—Ç–∫–∞–º–∏ –≤ –≤–∏–¥–µ –º–∞—Å—Å–∏–≤–æ–≤ NumPy, —Ç–∞–∫ —á—Ç–æ –¥–∞–≤–∞–π—Ç–µ –ø–æ–ø—Ä–æ–±—É–µ–º –ø–µ—Ä–µ–¥–∞—Ç—å –µ–π —ç—Ç–æ:

```py
predictions = outputs.logits.cpu().numpy()
labels = batch["labels"].cpu().numpy()

compute_metrics((predictions, labels))
```

```python out
TypeError: only size-1 arrays can be converted to Python scalars
```

–ú—ã –ø–æ–ª—É—á–∞–µ–º —Ç—É –∂–µ –æ—à–∏–±–∫—É, —Ç–∞–∫ —á—Ç–æ –ø—Ä–æ–±–ª–µ–º–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ –∫—Ä–æ–µ—Ç—Å—è –≤ —ç—Ç–æ–π —Ñ—É–Ω–∫—Ü–∏–∏. –ï—Å–ª–∏ –º—ã –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –µ–µ –∫–æ–¥, —Ç–æ —É–≤–∏–¥–∏–º, —á—Ç–æ –æ–Ω–∞ –ø—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ–¥–∞–µ—Ç `predictions` –∏ `labels` –≤ `metric.compute()`. –¢–∞–∫ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –ø—Ä–æ–±–ª–µ–º–∞ —Å —ç—Ç–∏–º –º–µ—Ç–æ–¥–æ–º? –ù–µ —Å–æ–≤—Å–µ–º. –î–∞–≤–∞–π—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –Ω–∞—à–∏ –º–æ–¥–µ–ª–∏:

```py
predictions.shape, labels.shape
```

```python out
((8, 3), (8,))
```

–ù–∞—à–∏ –ø—Ä–æ–≥–Ω–æ–∑—ã –≤—Å–µ –µ—â–µ —è–≤–ª—è—é—Ç—Å—è –ª–æ–≥–∏—Ç–∞–º–∏, –∞ –Ω–µ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–º–∏ –ø—Ä–æ–≥–Ω–æ–∑–∞–º–∏, –ø–æ—ç—Ç–æ–º—É –º–µ—Ç—Ä–∏–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —ç—Ç—É (–Ω–µ—Å–∫–æ–ª—å–∫–æ –Ω–µ–ø–æ–Ω—è—Ç–Ω—É—é) –æ—à–∏–±–∫—É. –ò—Å–ø—Ä–∞–≤–∏—Ç—å —ç—Ç–æ –¥–æ–≤–æ–ª—å–Ω–æ –ø—Ä–æ—Å—Ç–æ: –Ω—É–∂–Ω–æ –ø—Ä–æ—Å—Ç–æ –¥–æ–±–∞–≤–∏—Ç—å argmax –≤ —Ñ—É–Ω–∫—Ü–∏—é `compute_metrics()`:

```py
import numpy as np


def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    predictions = np.argmax(predictions, axis=1)
    return metric.compute(predictions=predictions, references=labels)


compute_metrics((predictions, labels))
```

```python out
{'accuracy': 0.625}
```

–¢–µ–ø–µ—Ä—å –Ω–∞—à–∞ –æ—à–∏–±–∫–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∞! –û–Ω–∞ –±—ã–ª–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–π, –ø–æ—ç—Ç–æ–º—É —Ç–µ–ø–µ—Ä—å –Ω–∞—à —Å–∫—Ä–∏–ø—Ç –±—É–¥–µ—Ç –æ–±—É—á–∞—Ç—å –º–æ–¥–µ–ª—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ.

–î–ª—è –ø—Ä–∏–º–µ—Ä–∞, –≤–æ—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç:

```py
import numpy as np
from datasets import load_dataset
import evaluate
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    DataCollatorWithPadding,
    TrainingArguments,
    Trainer,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
    return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=3)

args = TrainingArguments(
    f"distilbert-finetuned-mnli",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
)

metric = evaluate.load("glue", "mnli")


def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    predictions = np.argmax(predictions, axis=1)
    return metric.compute(predictions=predictions, references=labels)


data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

trainer = Trainer(
    model,
    args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation_matched"],
    compute_metrics=compute_metrics,
    data_collator=data_collator,
    tokenizer=tokenizer,
)
trainer.train()
```

–í –Ω–∞—à–µ–º —Å–ª—É—á–∞–µ –ø—Ä–æ–±–ª–µ–º –±–æ–ª—å—à–µ –Ω–µ—Ç, –∏ –Ω–∞—à —Å–∫—Ä–∏–ø—Ç –Ω–∞—Å—Ç—Ä–æ–∏—Ç –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –¥–æ–ª–∂–Ω–∞ –¥–∞—Ç—å –ø—Ä–∏–µ–º–ª–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã. –ù–æ —á—Ç–æ –¥–µ–ª–∞—Ç—å, –µ—Å–ª–∏ –æ–±—É—á–µ–Ω–∏–µ –ø—Ä–æ—Ö–æ–¥–∏—Ç –±–µ–∑ –æ—à–∏–±–æ–∫, –∞ –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ–≤—Å–µ–º –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç? –≠—Ç–æ —Å–∞–º–∞—è —Å–ª–æ–∂–Ω–∞—è —á–∞—Å—Ç—å –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –∏ –º—ã –ø–æ–∫–∞–∂–µ–º –≤–∞–º –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏–µ–º—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –ø–æ–º–æ—á—å.

<Tip>

üí° –ï—Å–ª–∏ –≤—ã –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ –æ–±—É—á–∞—é—â–∏–π —Ü–∏–∫–ª –≤—Ä—É—á–Ω—É—é, –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ –≤–∞—à–µ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ –æ–±—É—á–µ–Ω–∏—è –ø—Ä–∏–º–µ–Ω–∏–º—ã —Ç–µ –∂–µ —à–∞–≥–∏, –Ω–æ –∏—Ö –ø—Ä–æ—â–µ —Ä–∞–∑–¥–µ–ª–∏—Ç—å. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—ã –Ω–µ –∑–∞–±—ã–ª–∏ `model.eval()` –∏–ª–∏ `model.train()` –≤ –Ω—É–∂–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö, –∏–ª–∏ `zero_grad()` –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ!

</Tip>

## –û—Ç–ª–∞–¥–∫–∞ —Ç–∏—Ö–∏—Ö –æ—à–∏–±–æ–∫ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è

–ß—Ç–æ –º—ã –º–æ–∂–µ–º —Å–¥–µ–ª–∞—Ç—å –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ –æ–±—É—á–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä–æ–µ –∑–∞–≤–µ—Ä—à–∞–µ—Ç—Å—è –±–µ–∑ –æ—à–∏–±–æ–∫, –Ω–æ –Ω–µ –¥–∞–µ—Ç —Ö–æ—Ä–æ—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤? –ú—ã –¥–∞–¥–∏–º –≤–∞–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–æ–≤–µ—Ç–æ–≤, –Ω–æ –∏–º–µ–π—Ç–µ –≤ –≤–∏–¥—É, —á—Ç–æ —Ç–∞–∫–∞—è –æ—Ç–ª–∞–¥–∫–∞ - —Å–∞–º–∞—è —Å–ª–æ–∂–Ω–∞—è —á–∞—Å—Ç—å –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –∏ –≤–æ–ª—à–µ–±–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.

### –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–≤–æ–∏ –¥–∞–Ω–Ω—ã–µ (–µ—â–µ —Ä–∞–∑!)

–í–∞—à–∞ –º–æ–¥–µ–ª—å —Å–º–æ–∂–µ—Ç —á–µ–º—É-—Ç–æ –Ω–∞—É—á–∏—Ç—å—Å—è, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∏–∑ –≤–∞—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –º–æ–∂–Ω–æ —á–µ–º—É-—Ç–æ –Ω–∞—É—á–∏—Ç—å—Å—è. –ï—Å–ª–∏ –µ—Å—Ç—å –æ—à–∏–±–∫–∞, –∫–æ—Ç–æ—Ä–∞—è –ø–æ—Ä—Ç–∏—Ç –¥–∞–Ω–Ω—ã–µ, –∏–ª–∏ –º–µ—Ç–∫–∏ –ø—Ä–∏–ø–∏—Å—ã–≤–∞—é—Ç—Å—è —Å–ª—É—á–∞–π–Ω—ã–º –æ–±—Ä–∞–∑–æ–º, –æ—á–µ–Ω—å –≤–µ—Ä–æ—è—Ç–Ω–æ, —á—Ç–æ –≤—ã –Ω–µ —Å–º–æ–∂–µ—Ç–µ –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ —Å–≤–æ–µ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö. –ü–æ—ç—Ç–æ–º—É –≤—Å–µ–≥–¥–∞ –Ω–∞—á–∏–Ω–∞–π—Ç–µ —Å –¥–≤–æ–π–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –º–µ—Ç–æ–∫, –∞ —Ç–∞–∫–∂–µ –∑–∞–¥–∞–≤–∞–π—Ç–µ —Å–µ–±–µ —Å–ª–µ–¥—É—é—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã:

- –ü–æ–Ω—è—Ç–Ω—ã –ª–∏ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ?
- –°–æ–≥–ª–∞—Å–Ω—ã –ª–∏ –≤—ã —Å —ç—Ç–∏–º–∏ –º–µ—Ç–∫–∞–º–∏?
- –ï—Å—Ç—å –ª–∏ –∫–∞–∫–∞—è-—Ç–æ –æ–¥–Ω–∞ –º–µ—Ç–∫–∞, –∫–æ—Ç–æ—Ä–∞—è –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è —á–∞—â–µ –¥—Ä—É–≥–∏—Ö?
- –ö–∞–∫–æ–π –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ø–æ—Ç–µ—Ä—è/–º–µ—Ç—Ä–∏–∫–∞, –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∞ —Å–ª—É—á–∞–π–Ω—ã–π –æ—Ç–≤–µ—Ç/–≤—Å–µ–≥–¥–∞ –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ –æ—Ç–≤–µ—Ç?

<Tip warning={true}>

‚ö†Ô∏è –ï—Å–ª–∏ –≤—ã –ø—Ä–æ–≤–æ–¥–∏—Ç–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ, —Ä–∞—Å–ø–µ—á–∞—Ç–∞–π—Ç–µ –æ–±—Ä–∞–∑—Ü—ã –≤–∞—à–µ–≥–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –≤ –∫–∞–∂–¥–æ–º –ø—Ä–æ—Ü–µ—Å—Å–µ –∏ —Ç—Ä–∏–∂–¥—ã –ø—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –≤—ã –ø–æ–ª—É—á–∞–µ—Ç–µ –æ–¥–Ω–æ –∏ —Ç–æ –∂–µ. –û–¥–Ω–æ–π –∏–∑ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –æ—à–∏–±–æ–∫ —è–≤–ª—è–µ—Ç—Å—è –Ω–∞–ª–∏—á–∏–µ —Å–ª—É—á–∞–π–Ω–æ—Å—Ç–∏ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö, –∏–∑-–∑–∞ –∫–æ—Ç–æ—Ä–æ–π –∫–∞–∂–¥—ã–π –ø—Ä–æ—Ü–µ—Å—Å –∏–º–µ–µ—Ç —Å–≤–æ—é –≤–µ—Ä—Å–∏—é –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö.

</Tip>

–ü–æ—Å–ª–µ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ—Å–º–æ—Ç—Ä–∏—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, —Å–ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª—å—é, –∏ —Ä–∞—Å—à–∏—Ñ—Ä—É–π—Ç–µ –∏—Ö. –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –ø–æ—Å—Ç–æ—è–Ω–Ω–æ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ—Ç –æ–¥–Ω–æ –∏ —Ç–æ –∂–µ, —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–≤—è–∑–∞–Ω–æ —Å —Ç–µ–º, —á—Ç–æ –≤–∞—à –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —Å–º–µ—â–µ–Ω –≤ —Å—Ç–æ—Ä–æ–Ω—É –æ–¥–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (–¥–ª—è –ø—Ä–æ–±–ª–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏); –∑–¥–µ—Å—å –º–æ–≥—É—Ç –ø–æ–º–æ—á—å —Ç–∞–∫–∏–µ –º–µ—Ç–æ–¥—ã, –∫–∞–∫ –∏–∑–±—ã—Ç–æ—á–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ —Ä–µ–¥–∫–∏—Ö –∫–ª–∞—Å—Å–æ–≤.

–ï—Å–ª–∏ –ø–æ—Ç–µ—Ä–∏/–º–µ—Ç—Ä–∏–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã –ø–æ–ª—É—á–∞–µ—Ç–µ –Ω–∞ –Ω–∞—á–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏, —Å–∏–ª—å–Ω–æ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è –æ—Ç –ø–æ—Ç–µ—Ä—å/–º–µ—Ç—Ä–∏–∫, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã –æ–∂–∏–¥–∞–µ—Ç–µ –¥–ª—è —Å–ª—É—á–∞–π–Ω—ã—Ö –ø—Ä–æ–≥–Ω–æ–∑–æ–≤, –ø–µ—Ä–µ–ø—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–ø–æ—Å–æ–± –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –ø–æ—Ç–µ—Ä—å –∏–ª–∏ –º–µ—Ç—Ä–∏–∫, —Ç–∞–∫ –∫–∞–∫, –≤–æ–∑–º–æ–∂–Ω–æ, —Ç–∞–º –µ—Å—Ç—å –æ—à–∏–±–∫–∞. –ï—Å–ª–∏ –≤—ã –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ—Ç–µ—Ä—å, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã –¥–æ–±–∞–≤–ª—è–µ—Ç–µ –≤ –∫–æ–Ω—Ü–µ, –ø—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ–±—ã –æ–Ω–∏ –±—ã–ª–∏ –æ–¥–∏–Ω–∞–∫–æ–≤–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞.

–ö–æ–≥–¥–∞ –≤—ã —É–≤–µ—Ä–µ–Ω—ã, —á—Ç–æ –≤–∞—à–∏ –¥–∞–Ω–Ω—ã–µ –∏–¥–µ–∞–ª—å–Ω—ã, –≤—ã –º–æ–∂–µ—Ç–µ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, —Å–ø–æ—Å–æ–±–Ω–∞ –ª–∏ –º–æ–¥–µ–ª—å –æ–±—É—á–∞—Ç—å—Å—è –Ω–∞ –Ω–∏—Ö, —Å –ø–æ–º–æ—â—å—é –æ–¥–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç–æ–≥–æ —Ç–µ—Å—Ç–∞.

### –ò–∑–±—ã—Ç–æ—á–Ω–∞—è –ø–æ–¥–≥–æ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ –æ–¥–Ω–æ–º –Ω–∞–±–æ—Ä–µ

–û–±—ã—á–Ω–æ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º—ã —Å—Ç–∞—Ä–∞–µ–º—Å—è –∏–∑–±–µ–≥–∞—Ç—å —á—Ä–µ–∑–º–µ—Ä–Ω–æ–π –ø–æ–¥–≥–æ–Ω–∫–∏, –ø–æ—Å–∫–æ–ª—å–∫—É —ç—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –º–æ–¥–µ–ª—å –Ω–µ —É—á–∏—Ç—Å—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç—å –æ–±—â–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏, –∞ –ø—Ä–æ—Å—Ç–æ –∑–∞–ø–æ–º–∏–Ω–∞–µ—Ç –æ–±—É—á–∞—é—â–∏–µ –Ω–∞–±–æ—Ä—ã. –û–¥–Ω–∞–∫–æ –ø–æ–ø—ã—Ç–∫–∞ –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ –æ–¥–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ —Å–Ω–æ–≤–∞ –∏ —Å–Ω–æ–≤–∞ - —ç—Ç–æ —Ö–æ—Ä–æ—à–∏–π —Ç–µ—Å—Ç, –ø–æ–∑–≤–æ–ª—è—é—â–∏–π –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, –º–æ–∂–µ—Ç –ª–∏ –ø—Ä–æ–±–ª–µ–º–∞, –≤ —Ç–æ–º –≤–∏–¥–µ, –≤ –∫–æ—Ç–æ—Ä–æ–º –≤—ã –µ–µ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–ª–∏, –±—ã—Ç—å —Ä–µ—à–µ–Ω–∞ —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–∏, –∫–æ—Ç–æ—Ä—É—é –≤—ã –ø—ã—Ç–∞–µ—Ç–µ—Å—å –æ–±—É—á–∏—Ç—å. –≠—Ç–æ —Ç–∞–∫–∂–µ –ø–æ–º–æ–∂–µ—Ç –≤–∞–º –ø–æ–Ω—è—Ç—å, –Ω–µ —Å–ª–∏—à–∫–æ–º –ª–∏ –≤—ã—Å–æ–∫–∞ –≤–∞—à–∞ –Ω–∞—á–∞–ª—å–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è.

–°–¥–µ–ª–∞—Ç—å —ç—Ç–æ –ø–æ—Å–ª–µ —Ç–æ–≥–æ, –∫–∞–∫ –≤—ã –æ–ø—Ä–µ–¥–µ–ª–∏–ª–∏ —Å–≤–æ–π `Trainer`, –æ—á–µ–Ω—å –ø—Ä–æ—Å—Ç–æ; –ø—Ä–æ—Å—Ç–æ –≤–æ–∑—å–º–∏—Ç–µ –Ω–∞–±–æ—Ä –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö, –∑–∞—Ç–µ–º –∑–∞–ø—É—Å—Ç–∏—Ç–µ –Ω–µ–±–æ–ª—å—à–æ–π —Ü–∏–∫–ª —Ä—É—á–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –∏—Å–ø–æ–ª—å–∑—É—è —Ç–æ–ª—å–∫–æ —ç—Ç–æ—Ç –Ω–∞–±–æ—Ä –≤ —Ç–µ—á–µ–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–Ω–æ 20 —à–∞–≥–æ–≤:

```py
for batch in trainer.get_train_dataloader():
    break

batch = {k: v.to(device) for k, v in batch.items()}
trainer.create_optimizer()

for _ in range(20):
    outputs = trainer.model(**batch)
    loss = outputs.loss
    loss.backward()
    trainer.optimizer.step()
    trainer.optimizer.zero_grad()
```

<Tip>

üí° –ï—Å–ª–∏ –≤–∞—à–∏ –æ–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω—ã, –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —Å–æ–∑–¥–∞–π—Ç–µ –Ω–∞–±–æ—Ä –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –≤—Å–µ –º–µ—Ç–∫–∏.

</Tip>

–ü–æ–ª—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –¥–æ–ª–∂–Ω–∞ –∏–º–µ—Ç—å –±–ª–∏–∑–∫–∏–µ –∫ –∏–¥–µ–∞–ª—å–Ω—ã–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ –æ–¥–Ω–æ–º –∏ —Ç–æ–º –∂–µ `batch`. –í—ã—á–∏—Å–ª–∏–º –º–µ—Ç—Ä–∏–∫—É –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∏—Ä—É—é—â–∏—Ö –ø—Ä–æ–≥–Ω–æ–∑–æ–≤:

```py
with torch.no_grad():
    outputs = trainer.model(**batch)
preds = outputs.logits
labels = batch["labels"]

compute_metrics((preds.cpu().numpy(), labels.cpu().numpy()))
```

```python out
{'accuracy': 1.0}
```

–¢–æ—á–Ω–æ—Å—Ç—å 100%, —ç—Ç–æ —Ö–æ—Ä–æ—à–∏–π –ø—Ä–∏–º–µ—Ä –∏–∑–±—ã—Ç–æ—á–Ω–æ–π –ø–æ–¥–≥–æ–Ω–∫–∏ (—ç—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –µ—Å–ª–∏ –≤—ã –ø–æ–ø—Ä–æ–±—É–µ—Ç–µ –≤–∞—à—É –º–æ–¥–µ–ª—å –Ω–∞ –ª—é–±–æ–º –¥—Ä—É–≥–æ–º –ø—Ä–∏–º–µ—Ä–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –æ–Ω–∞, —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ, –¥–∞—Å—Ç –≤–∞–º –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç)!

–ï—Å–ª–∏ –≤–∞–º –Ω–µ —É–¥–∞–µ—Ç—Å—è –¥–æ–±–∏—Ç—å—Å—è –æ—Ç –º–æ–¥–µ–ª–∏ –∏–¥–µ–∞–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, –∑–Ω–∞—á–∏—Ç, —á—Ç–æ-—Ç–æ –Ω–µ —Ç–∞–∫ —Å –ø–æ—Å—Ç–∞–Ω–æ–≤–∫–æ–π –∑–∞–¥–∞—á–∏ –∏–ª–∏ –¥–∞–Ω–Ω—ã–º–∏, –∏ –≤–∞–º —Å–ª–µ–¥—É–µ—Ç —ç—Ç–æ –∏—Å–ø—Ä–∞–≤–∏—Ç—å. –¢–æ–ª—å–∫–æ –∫–æ–≥–¥–∞ –≤–∞–º —É–¥–∞—Å—Ç—Å—è –ø—Ä–æ–π—Ç–∏ —Ç–µ—Å—Ç –Ω–∞ –∏–∑–±—ã—Ç–æ—á–Ω—É—é –ø–æ–¥–≥–æ–Ω–∫—É, –≤—ã –º–æ–∂–µ—Ç–µ –±—ã—Ç—å —É–≤–µ—Ä–µ–Ω—ã, —á—Ç–æ –≤–∞—à–∞ –º–æ–¥–µ–ª—å –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –º–æ–∂–µ—Ç —á–µ–º—É-—Ç–æ –Ω–∞—É—á–∏—Ç—å—Å—è.

<Tip warning={true}>

‚ö†Ô∏è –ü–æ—Å–ª–µ —ç—Ç–æ–≥–æ —Ç–µ—Å—Ç–∞ –≤–∞–º –ø—Ä–∏–¥–µ—Ç—Å—è –∑–∞–Ω–æ–≤–æ —Å–æ–∑–¥–∞—Ç—å —Å–≤–æ—é –º–æ–¥–µ–ª—å –∏ `Trainer`, –ø–æ—Å–∫–æ–ª—å–∫—É –ø–æ–ª—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å, –≤–µ—Ä–æ—è—Ç–Ω–æ, –Ω–µ —Å–º–æ–∂–µ—Ç –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å—Å—è –∏ –Ω–∞—É—á–∏—Ç—å—Å—è —á–µ–º—É-—Ç–æ –ø–æ–ª–µ–∑–Ω–æ–º—É –Ω–∞ –ø–æ–ª–Ω–æ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö.

</Tip>

### –ù–µ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–π—Ç–µ –Ω–∏—á–µ–≥–æ, –ø–æ–∫–∞ –Ω–µ –ø–æ–ª—É—á–∏—Ç–µ –ø–µ—Ä–≤—ã–π –±–∞–∑–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å.

–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤—Å–µ–≥–¥–∞ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–µ—Ç—Å—è –∫–∞–∫ —Å–∞–º–∞—è —Ç—Ä—É–¥–Ω–∞—è —á–∞—Å—Ç—å –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –Ω–æ —ç—Ç–æ –ª–∏—à—å –ø–æ—Å–ª–µ–¥–Ω–∏–π —à–∞–≥, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–º–æ–∂–µ—Ç –≤–∞–º –ø–æ–ª—É—á–∏—Ç—å –Ω–µ–±–æ–ª—å—à–æ–π –ø–ª—é—Å –≤ –º–µ—Ç—Ä–∏–∫–µ. –í –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ —Å–ª—É—á–∞–µ–≤ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤ `Trainer` –±—É–¥—É—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –ø—Ä–æ—Å—Ç–æ –æ—Ç–ª–∏—á–Ω–æ –∏ –¥–∞–¥—É—Ç –≤–∞–º —Ö–æ—Ä–æ—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, —Ç–∞–∫ —á—Ç–æ –Ω–µ –Ω–∞—á–∏–Ω–∞–π—Ç–µ —Ç—Ä—É–¥–æ–µ–º–∫–∏–π –∏ –¥–æ—Ä–æ–≥–æ—Å—Ç–æ—è—â–∏–π –ø–æ–∏—Å–∫ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –ø–æ–∫–∞ –Ω–µ –Ω–∞–π–¥–µ—Ç–µ —á—Ç–æ-—Ç–æ, —á—Ç–æ –ø–æ–±—å–µ—Ç –±–∞–∑–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å –Ω–∞ –≤–∞—à–µ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö.

–ö–æ–≥–¥–∞ —É –≤–∞—Å –µ—Å—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ö–æ—Ä–æ—à–∞—è –º–æ–¥–µ–ª—å, –≤—ã –º–æ–∂–µ—Ç–µ –Ω–∞—á–∞—Ç—å –µ–µ –Ω–µ–º–Ω–æ–≥–æ –ø–æ–¥—Å—Ç—Ä–∞–∏–≤–∞—Ç—å. –ù–µ –ø—ã—Ç–∞–π—Ç–µ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å —Ç—ã—Å—è—á—É –ø—Ä–æ–≥–æ–Ω–æ–≤ —Å —Ä–∞–∑–Ω—ã–º–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏, –Ω–æ —Å—Ä–∞–≤–Ω–∏—Ç–µ –ø–∞—Ä—É –ø—Ä–æ–≥–æ–Ω–æ–≤ —Å —Ä–∞–∑–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –æ–¥–Ω–æ–≥–æ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –æ —Ç–æ–º, –∫–∞–∫–æ–π –∏–∑ –Ω–∏—Ö –æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞–∏–±–æ–ª—å—à–µ–µ –≤–ª–∏—è–Ω–∏–µ.

–ï—Å–ª–∏ –≤—ã –≤–Ω–æ—Å–∏—Ç–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ —Å–∞–º—É –º–æ–¥–µ–ª—å, –±—É–¥—å—Ç–µ –ø—Ä–æ—â–µ –∏ –Ω–µ –ø—Ä–æ–±—É–π—Ç–µ —Ç–æ, —á—Ç–æ –Ω–µ –º–æ–∂–µ—Ç–µ –æ–±–æ—Å–Ω–æ–≤–∞—Ç—å. –í—Å–µ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–π—Ç–µ—Å—å –∫ —Ç–µ—Å—Ç—É –Ω–∞ –∏–∑–±—ã—Ç–æ—á–Ω—É—é –ø–æ–¥–≥–æ–Ω–∫—É, —á—Ç–æ–±—ã —É–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤–∞—à–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –Ω–µ –ø—Ä–∏–≤–µ–ª–æ –∫ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω—ã–º –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è–º.

### –ü–æ–ø—Ä–æ—Å–∏—Ç–µ –æ –ø–æ–º–æ—â–∏

–ù–∞–¥–µ—é—Å—å, –≤—ã –Ω–∞—à–ª–∏ –≤ —ç—Ç–æ–º —Ä–∞–∑–¥–µ–ª–µ —Å–æ–≤–µ—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–º–æ–≥–ª–∏ –≤–∞–º —Ä–µ—à–∏—Ç—å –≤–∞—à—É –ø—Ä–æ–±–ª–µ–º—É, –Ω–æ –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ —Ç–∞–∫, –ø–æ–º–Ω–∏—Ç–µ, —á—Ç–æ –≤—ã –≤—Å–µ–≥–¥–∞ –º–æ–∂–µ—Ç–µ —Å–ø—Ä–æ—Å–∏—Ç—å —É —Å–æ–æ–±—â–µ—Å—Ç–≤–∞ –Ω–∞ [—Ñ–æ—Ä—É–º–∞—Ö](https://discuss.huggingface.co/).

–í–æ—Ç –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –æ–∫–∞–∑–∞—Ç—å—Å—è –ø–æ–ª–µ–∑–Ω—ã–º–∏:

- ["Reproducibility as a vehicle for engineering best practices"](https://docs.google.com/presentation/d/1yHLPvPhUs2KGI5ZWo0sU-PKU3GimAk3iTsI38Z-B5Gw/edit#slide=id.p) by Joel Grus
- ["Checklist for debugging neural networks"](https://towardsdatascience.com/checklist-for-debugging-neural-networks-d8b2a9434f21) by Cecelia Shao
- ["How to unit test machine learning code"](https://medium.com/@keeper6928/how-to-unit-test-machine-learning-code-57cf6fd81765) by Chase Roberts
- ["A Recipe for Training Neural Networks"](http://karpathy.github.io/2019/04/25/recipe/) by Andrej Karpathy

–ö–æ–Ω–µ—á–Ω–æ, –Ω–µ –≤—Å–µ –ø—Ä–æ–±–ª–µ–º—ã, —Å –∫–æ—Ç–æ—Ä—ã–º–∏ –≤—ã —Å—Ç–∞–ª–∫–∏–≤–∞–µ—Ç–µ—Å—å –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π, –≤–æ–∑–Ω–∏–∫–∞—é—Ç –ø–æ –≤–∞—à–µ–π –≤–∏–Ω–µ! –ï—Å–ª–∏ –≤ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ ü§ó Transformers –∏–ª–∏ ü§ó Datasets –≤—ã —Å—Ç–æ–ª–∫–Ω—É–ª–∏—Å—å —Å —á–µ–º-—Ç–æ, —á—Ç–æ –∫–∞–∂–µ—Ç—Å—è –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–º, –≤–æ–∑–º–æ–∂–Ω–æ, –≤—ã —Å—Ç–æ–ª–∫–Ω—É–ª–∏—Å—å —Å –æ—à–∏–±–∫–æ–π. –í—ã –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–æ–ª–∂–Ω—ã —Ä–∞—Å—Å–∫–∞–∑–∞—Ç—å –Ω–∞–º –æ–± —ç—Ç–æ–º, –∏ –≤ —Å–ª–µ–¥—É—é—â–µ–º —Ä–∞–∑–¥–µ–ª–µ –º—ã –æ–±—ä—è—Å–Ω–∏–º, –∫–∞–∫ –∏–º–µ–Ω–Ω–æ —ç—Ç–æ —Å–¥–µ–ª–∞—Ç—å.
