<FrameworkSwitchCourse {fw} />

# –û—Ç–ª–∞–¥–∫–∞ –æ–±—É—á–µ–Ω–∏—è[[debugging-the-training-pipeline]]

<CourseFloatingBanner chapter={8}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter8/section4.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter8/section4.ipynb"},
]} />

–í—ã –Ω–∞–ø–∏—Å–∞–ª–∏ –ø—Ä–µ–∫—Ä–∞—Å–Ω—ã–π —Å—Ü–µ–Ω–∞—Ä–∏–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏–ª–∏ –¥–æ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –Ω–∞ –∑–∞–¥–∞–Ω–Ω–æ–π –∑–∞–¥–∞—á–µ, –ø–æ—Å–ª—É—à–Ω–æ —Å–ª–µ–¥—É—è —Å–æ–≤–µ—Ç–∞–º –∏–∑ [–ì–ª–∞–≤—ã 7](/course/chapter7/1). –ù–æ –∫–æ–≥–¥–∞ –≤—ã –∑–∞–ø—É—Å–∫–∞–µ—Ç–µ –∫–æ–º–∞–Ω–¥—É `model.fit()`, –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –Ω–µ—á—Ç–æ —É–∂–∞—Å–Ω–æ–µ: –≤—ã –ø–æ–ª—É—á–∞–µ—Ç–µ –æ—à–∏–±–∫—É üò±! –ò–ª–∏, —á—Ç–æ –µ—â–µ —Ö—É–∂–µ, –≤—Å–µ –≤—Ä–æ–¥–µ –±—ã —Ö–æ—Ä–æ—à–æ, –æ–±—É—á–µ–Ω–∏–µ –ø—Ä–æ—Ö–æ–¥–∏—Ç –±–µ–∑ –æ—à–∏–±–æ–∫, –Ω–æ —Ä–µ–∑—É–ª—å—Ç–∏—Ä—É—é—â–∞—è –º–æ–¥–µ–ª—å –ø–æ–ª—É—á–∞–µ—Ç—Å—è –ø–ª–æ—Ö–æ–π. –í —ç—Ç–æ–º —Ä–∞–∑–¥–µ–ª–µ –º—ã –ø–æ–∫–∞–∂–µ–º –≤–∞–º, —á—Ç–æ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ –ø–æ–¥–æ–±–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º.

## –û—Ç–ª–∞–¥–∫–∞ –æ–±—É—á–∞—é—â–µ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞[[debugging-the-training-pipeline]]

<Youtube id="L-WSwUWde1U"/>

–ü—Ä–æ–±–ª–µ–º–∞, –∫–æ–≥–¥–∞ –≤—ã —Å—Ç–∞–ª–∫–∏–≤–∞–µ—Ç–µ—Å—å —Å –æ—à–∏–±–∫–æ–π –≤ `trainer.train()`, –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ —Ç–æ–º, —á—Ç–æ –æ–Ω–∞ –º–æ–∂–µ—Ç –≤–æ–∑–Ω–∏–∫–Ω—É—Ç—å –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤, –ø–æ—Å–∫–æ–ª—å–∫—É `Trainer` –æ–±—ã—á–Ω–æ —Å–æ–±–∏—Ä–∞–µ—Ç –≤–º–µ—Å—Ç–µ –º–Ω–æ–∂–µ—Å—Ç–≤–æ –≤–µ—â–µ–π. –û–Ω –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –Ω–∞–±–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö –≤ –∑–∞–≥—Ä—É–∑—á–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö, –ø–æ—ç—Ç–æ–º—É –ø—Ä–æ–±–ª–µ–º–∞ –º–æ–∂–µ—Ç –∑–∞–∫–ª—é—á–∞—Ç—å—Å—è –≤ —Ç–æ–º, —á—Ç–æ –≤ –≤–∞—à–µ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö —á—Ç–æ-—Ç–æ –Ω–µ —Ç–∞–∫, –∏–ª–∏ –≤ —Ç–æ–º, —á—Ç–æ –≤—ã –ø—ã—Ç–∞–µ—Ç–µ—Å—å –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å —ç–ª–µ–º–µ–Ω—Ç—ã –Ω–∞–±–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö –≤ –±–∞—Ç—á. –ó–∞—Ç–µ–º –æ–Ω –±–µ—Ä–µ—Ç –±–∞—Ç—á –¥–∞–Ω–Ω—ã—Ö –∏ –ø–æ–¥–∞–µ—Ç –µ–≥–æ –≤ –º–æ–¥–µ–ª—å, —Ç–∞–∫ —á—Ç–æ –ø—Ä–æ–±–ª–µ–º–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –≤ –∫–æ–¥–µ –º–æ–¥–µ–ª–∏. –ü–æ—Å–ª–µ —ç—Ç–æ–≥–æ –≤—ã—á–∏—Å–ª—è—é—Ç—Å—è –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —ç—Ç–∞–ø –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏, —Ç–∞–∫ —á—Ç–æ –ø—Ä–æ–±–ª–µ–º–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –∏ –≤ –≤–∞—à–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–µ. –ò –¥–∞–∂–µ –µ—Å–ª–∏ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –≤—Å–µ –∏–¥–µ—Ç —Ö–æ—Ä–æ—à–æ, –≤–æ –≤—Ä–µ–º—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤—Å–µ —Ä–∞–≤–Ω–æ —á—Ç–æ-—Ç–æ –º–æ–∂–µ—Ç –ø–æ–π—Ç–∏ –Ω–µ —Ç–∞–∫, –µ—Å–ª–∏ –ø—Ä–æ–±–ª–µ–º–∞ –≤ –º–µ—Ç—Ä–∏–∫–µ.

–õ—É—á—à–∏–π —Å–ø–æ—Å–æ–± –æ—Ç–ª–∞–¥–∏—Ç—å –æ—à–∏–±–∫—É, –≤–æ–∑–Ω–∏–∫—à—É—é –≤ `trainer.train()`, - —ç—Ç–æ –≤—Ä—É—á–Ω—É—é –ø—Ä–æ–π—Ç–∏ –≤–µ—Å—å –ø–∞–π–ø–ª–∞–π–Ω –∏ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å, –≥–¥–µ –≤—Å–µ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫. –í —ç—Ç–æ–º —Å–ª—É—á–∞–µ –æ—à–∏–±–∫—É —á–∞—Å—Ç–æ –æ—á–µ–Ω—å –ª–µ–≥–∫–æ —É—Å—Ç—Ä–∞–Ω–∏—Ç—å.

–ß—Ç–æ–±—ã –ø—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å —ç—Ç–æ, –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ª–µ–¥—É—é—â–∏–π —Å–∫—Ä–∏–ø—Ç, –∫–æ—Ç–æ—Ä—ã–π (–ø—ã—Ç–∞–µ—Ç—Å—è) —Ç–æ—á–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –º–æ–¥–µ–ª—å DistilBERT –Ω–∞ –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö [MNLI dataset](https://huggingface.co/datasets/glue):

```py
from datasets import load_dataset
import evaluate
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
    return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)

args = TrainingArguments(
    f"distilbert-finetuned-mnli",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
)

metric = evaluate.load("glue", "mnli")


def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    return metric.compute(predictions=predictions, references=labels)


trainer = Trainer(
    model,
    args,
    train_dataset=raw_datasets["train"],
    eval_dataset=raw_datasets["validation_matched"],
    compute_metrics=compute_metrics,
)
trainer.train()
```

–ï—Å–ª–∏ –≤—ã –ø–æ–ø—ã—Ç–∞–µ—Ç–µ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –µ–≥–æ, —Ç–æ —Å—Ç–æ–ª–∫–Ω–µ—Ç–µ—Å—å —Å –¥–æ–≤–æ–ª—å–Ω–æ –∑–∞–≥–∞–¥–æ—á–Ω–æ–π –æ—à–∏–±–∫–æ–π:

```python out
'ValueError: You have to specify either input_ids or inputs_embeds'
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö[[check-your-data]]

–≠—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—á–µ–≤–∏–¥–Ω–æ, –Ω–æ –µ—Å–ª–∏ –≤–∞—à–∏ –¥–∞–Ω–Ω—ã–µ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω—ã, `Trainer` –Ω–µ —Å–º–æ–∂–µ—Ç —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –±–∞—Ç—á–∏, –Ω–µ –≥–æ–≤–æ—Ä—è —É–∂–µ –æ–± –æ–±—É—á–µ–Ω–∏–∏ –≤–∞—à–µ–π –º–æ–¥–µ–ª–∏. –ü–æ—ç—Ç–æ–º—É –ø—Ä–µ–∂–¥–µ –≤—Å–µ–≥–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å, —á—Ç–æ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –≤–∞—à–µ–º –æ–±—É—á–∞—é—â–µ–º –Ω–∞–±–æ—Ä–µ.

–ß—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –±–µ—Å—á–∏—Å–ª–µ–Ω–Ω—ã—Ö —á–∞—Å–æ–≤, –ø–æ—Ç—Ä–∞—á–µ–Ω–Ω—ã—Ö –Ω–∞ –ø–æ–ø—ã—Ç–∫–∏ –∏—Å–ø—Ä–∞–≤–∏—Ç—å —Ç–æ, —á—Ç–æ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –∏—Å—Ç–æ—á–Ω–∏–∫–æ–º –æ—à–∏–±–∫–∏, –º—ã —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `trainer.train_dataset` –¥–ª—è –ø—Ä–æ–≤–µ—Ä–æ–∫ –∏ –Ω–∏—á–µ–≥–æ –±–æ–ª—å—à–µ. –¢–∞–∫ —á—Ç–æ –¥–∞–≤–∞–π—Ç–µ —Å–¥–µ–ª–∞–µ–º —ç—Ç–æ –∑–¥–µ—Å—å:

```py
trainer.train_dataset[0]
```

```python out
{'hypothesis': 'Product and geography are what make cream skimming work. ',
 'idx': 0,
 'label': 1,
 'premise': 'Conceptually cream skimming has two basic dimensions - product and geography.'}
```

–í—ã –∑–∞–º–µ—Ç–∏–ª–∏ —á—Ç–æ-—Ç–æ –Ω–µ–ª–∞–¥–Ω–æ–µ? –í —Å–æ—á–µ—Ç–∞–Ω–∏–∏ —Å —Å–æ–æ–±—â–µ–Ω–∏–µ–º –æ–± –æ—à–∏–±–∫–µ `input_ids`, –≤—ã –¥–æ–ª–∂–Ω—ã –ø–æ–Ω—è—Ç—å, —á—Ç–æ —ç—Ç–æ —Ç–µ–∫—Å—Ç—ã, –∞ –Ω–µ —á–∏—Å–ª–∞, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –ø–æ–Ω—è—Ç—å. –ó–¥–µ—Å—å –∏—Å—Ö–æ–¥–Ω–∞—è –æ—à–∏–±–∫–∞ –≤–≤–æ–¥–∏—Ç –≤ –∑–∞–±–ª—É–∂–¥–µ–Ω–∏–µ, –ø–æ—Ç–æ–º—É —á—Ç–æ `Trainer` –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–¥–∞–ª—è–µ—Ç —Å—Ç–æ–ª–±—Ü—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —Å–∏–≥–Ω–∞—Ç—É—Ä–µ –º–æ–¥–µ–ª–∏ (—Ç–æ –µ—Å—Ç—å –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º, –æ–∂–∏–¥–∞–µ–º—ã–º –º–æ–¥–µ–ª—å—é). –≠—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –∑–¥–µ—Å—å –±—ã–ª–æ —É–¥–∞–ª–µ–Ω–æ –≤—Å–µ, –∫—Ä–æ–º–µ –º–µ—Ç–æ–∫. –¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, –Ω–µ –±—ã–ª–æ –Ω–∏–∫–∞–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º —Å —Å–æ–∑–¥–∞–Ω–∏–µ–º –±–∞—Ç—á–µ–π –∏ –æ—Ç–ø—Ä–∞–≤–∫–æ–π –∏—Ö –º–æ–¥–µ–ª–∏, –∫–æ—Ç–æ—Ä–∞—è, –≤ —Å–≤–æ—é –æ—á–µ—Ä–µ–¥—å, –∂–∞–ª–æ–≤–∞–ª–∞—Å—å, —á—Ç–æ –Ω–µ –ø–æ–ª—É—á–∏–ª–∞ –Ω—É–∂–Ω—ã—Ö –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.

–ü–æ—á–µ–º—É –¥–∞–Ω–Ω—ã–µ –Ω–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–ª–∏—Å—å? –ú—ã –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ –º–µ—Ç–æ–¥ `Dataset.map()` –¥–ª—è –Ω–∞–±–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö, —á—Ç–æ–±—ã –ø—Ä–∏–º–µ–Ω–∏—Ç—å —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –∫ –∫–∞–∂–¥–æ–π –≤—ã–±–æ—Ä–∫–µ. –ù–æ –µ—Å–ª–∏ –≤—ã –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –ø–æ—Å–º–æ—Ç—Ä–∏—Ç–µ –Ω–∞ –∫–æ–¥, —Ç–æ —É–≤–∏–¥–∏—Ç–µ, —á—Ç–æ –º—ã –¥–æ–ø—É—Å—Ç–∏–ª–∏ –æ—à–∏–±–∫—É –ø—Ä–∏ –ø–µ—Ä–µ–¥–∞—á–µ –æ–±—É—á–∞—é—â–µ–≥–æ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–æ–≤ –≤ `Trainer`. –í–º–µ—Å—Ç–æ —Ç–æ–≥–æ —á—Ç–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `tokenized_datasets`, –º—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ `raw_datasets` ü§¶. –¢–∞–∫ —á—Ç–æ –¥–∞–≤–∞–π—Ç–µ –∏—Å–ø—Ä–∞–≤–∏–º —ç—Ç–æ!

```py
from datasets import load_dataset
import evaluate
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
    return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)

args = TrainingArguments(
    f"distilbert-finetuned-mnli",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
)

metric = evaluate.load("glue", "mnli")


def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    return metric.compute(predictions=predictions, references=labels)


trainer = Trainer(
    model,
    args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation_matched"],
    compute_metrics=compute_metrics,
)
trainer.train()
```

–¢–µ–ø–µ—Ä—å —ç—Ç–æ—Ç –Ω–æ–≤—ã–π –∫–æ–¥ –±—É–¥–µ—Ç –≤—ã–¥–∞–≤–∞—Ç—å –¥—Ä—É–≥—É—é –æ—à–∏–±–∫—É (–ø—Ä–æ–≥—Ä–µ—Å—Å!):

```python out
'ValueError: expected sequence of length 43 at dim 1 (got 37)'
```

–ü–æ—Å–º–æ—Ç—Ä–µ–≤ –Ω–∞ —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫—É, –º—ã –≤–∏–¥–∏–º, —á—Ç–æ –æ—à–∏–±–∫–∞ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –Ω–∞ —ç—Ç–∞–ø–µ —Å–±–æ—Ä–∫–∏ –¥–∞–Ω–Ω—ã—Ö:

```python out
~/git/transformers/src/transformers/data/data_collator.py in torch_default_data_collator(features)
    105                 batch[k] = torch.stack([f[k] for f in features])
    106             else:
--> 107                 batch[k] = torch.tensor([f[k] for f in features])
    108 
    109     return batch
```

–ü–æ—ç—Ç–æ–º—É –Ω–∞–º —Å–ª–µ–¥—É–µ—Ç –ø–µ—Ä–µ–π—Ç–∏ –∫ —ç—Ç–æ–º—É. –û–¥–Ω–∞–∫–æ –ø–µ—Ä–µ–¥ —ç—Ç–∏–º –¥–∞–≤–∞–π—Ç–µ –∑–∞–∫–æ–Ω—á–∏–º –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö, —á—Ç–æ–±—ã –±—ã—Ç—å –Ω–∞ 100% —É–≤–µ—Ä–µ–Ω–Ω—ã–º–∏ –≤ –∏—Ö –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç–∏.

–ü—Ä–∏ –æ—Ç–ª–∞–¥–∫–µ –æ–±—É—á–µ–Ω–∏—è –≤—Å–µ–≥–¥–∞ –Ω—É–∂–Ω–æ —Å–º–æ—Ç—Ä–µ—Ç—å –Ω–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤—Ö–æ–¥—ã –º–æ–¥–µ–ª–∏. –ú—ã –Ω–µ –º–æ–∂–µ–º –ø–æ–Ω—è—Ç—å —Å–º—ã—Å–ª —á–∏—Å–µ–ª, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–¥–∞–µ–º –µ–π –Ω–∞–ø—Ä—è–º—É—é, –ø–æ—ç—Ç–æ–º—É –º—ã –¥–æ–ª–∂–Ω—ã –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å, —á—Ç–æ —ç—Ç–∏ —á–∏—Å–ª–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç. –í –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–º –∑—Ä–µ–Ω–∏–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä, —ç—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç –ø—Ä–æ—Å–º–æ—Ç—Ä –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø—Ä–æ–π–¥–µ–Ω–Ω—ã—Ö –ø–∏–∫—Å–µ–ª–µ–π, –≤ —Ä–µ—á–∏ - –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏–µ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ–±—Ä–∞–∑—Ü–æ–≤ –∑–≤—É–∫–∞, –∞ –≤ –Ω–∞—à–µ–º –ø—Ä–∏–º–µ—Ä–µ —Å NLP - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –Ω–∞—à–µ–≥–æ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ –¥–ª—è –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:

```py
tokenizer.decode(trainer.train_dataset[0]["input_ids"])
```

```python out
'[CLS] conceptually cream skimming has two basic dimensions - product and geography. [SEP] product and geography are what make cream skimming work. [SEP]'
```

–¢–∞–∫ —á—Ç–æ, –ø–æ—Ö–æ–∂–µ, –≤—Å–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ. –í—ã –¥–æ–ª–∂–Ω—ã —Å–¥–µ–ª–∞—Ç—å —ç—Ç–æ –¥–ª—è –≤—Å–µ—Ö –∫–ª—é—á–µ–π –≤–æ –≤—Ö–æ–¥–∞—Ö:

```py
trainer.train_dataset[0].keys()
```

```python out
dict_keys(['attention_mask', 'hypothesis', 'idx', 'input_ids', 'label', 'premise'])
```

–û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ –∫–ª—é—á–∏, –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –≤—Ö–æ–¥–∞–º, –ø—Ä–∏–Ω–∏–º–∞–µ–º—ã–º –º–æ–¥–µ–ª—å—é, –±—É–¥—É—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—Ç–±—Ä–æ—à–µ–Ω—ã, –ø–æ—ç—Ç–æ–º—É –∑–¥–µ—Å—å –º—ã –æ—Å—Ç–∞–≤–∏–º —Ç–æ–ª—å–∫–æ `input_ids`, `attention_mask` –∏ `label` (–∫–æ—Ç–æ—Ä–∞—è –±—É–¥–µ—Ç –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∞ –≤ `labels`). –ß—Ç–æ–±—ã –ø–µ—Ä–µ–ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–∏–≥–Ω–∞—Ç—É—Ä—É –º–æ–¥–µ–ª–∏, –≤—ã –º–æ–∂–µ—Ç–µ –≤—ã–≤–µ—Å—Ç–∏ –∫–ª–∞—Å—Å –≤–∞—à–µ–π –º–æ–¥–µ–ª–∏, –∞ –∑–∞—Ç–µ–º –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –µ–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é:

```py
type(trainer.model)
```

```python out
transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification
```

–ò—Ç–∞–∫, –≤ –Ω–∞—à–µ–º —Å–ª—É—á–∞–µ –º—ã –º–æ–∂–µ–º –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ø—Ä–∏–Ω—è—Ç—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞ [—ç—Ç–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ](https://huggingface.co/transformers/model_doc/distilbert.html#distilbertforsequenceclassification). "Trainer" —Ç–∞–∫–∂–µ –±—É–¥–µ—Ç —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–æ–ª–±—Ü—ã, –∫–æ—Ç–æ—Ä—ã–µ –æ–Ω –æ—Ç–±—Ä–∞—Å—ã–≤–∞–µ—Ç.

–ú—ã –ø—Ä–æ–≤–µ—Ä–∏–ª–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –≤—Ö–æ–¥–Ω—ã—Ö –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤, –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–≤ –∏—Ö. –î–∞–ª–µ–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è `attention_mask`:

```py
trainer.train_dataset[0]["attention_mask"]
```

```python out
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
```

–¢–∞–∫ –∫–∞–∫ –º—ã –Ω–µ –ø—Ä–∏–º–µ–Ω—è–ª–∏ –≤ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–µ –¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ –Ω—É–ª—è–º–∏, —ç—Ç–æ –∫–∞–∂–µ—Ç—Å—è —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–º. –ß—Ç–æ–±—ã —É–±–µ–¥–∏—Ç—å—Å—è –≤ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –ø—Ä–æ–±–ª–µ–º —Å —ç—Ç–æ–π –º–∞—Å–∫–æ–π –≤–Ω–∏–º–∞–Ω–∏—è, –¥–∞–≤–∞–π—Ç–µ –ø—Ä–æ–≤–µ—Ä–∏–º, —á—Ç–æ –æ–Ω–∞ –∏–º–µ–µ—Ç —Ç—É –∂–µ –¥–ª–∏–Ω—É, —á—Ç–æ –∏ –Ω–∞—à–∏ –≤—Ö–æ–¥–Ω—ã–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã:

```py
len(trainer.train_dataset[0]["attention_mask"]) == len(
    trainer.train_dataset[0]["input_ids"]
)
```

```python out
True
```

–≠—Ç–æ —Ö–æ—Ä–æ—à–æ! –ò –Ω–∞–∫–æ–Ω–µ—Ü, –¥–∞–≤–∞–π—Ç–µ –ø—Ä–æ–≤–µ—Ä–∏–º –Ω–∞—à—É –º–µ—Ç–∫—É –∫–ª–∞—Å—Å–∞:

```py
trainer.train_dataset[0]["label"]
```

```python out
1
```

–ö–∞–∫ –∏ –≤—Ö–æ–¥–Ω—ã–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã, —ç—Ç–æ —á–∏—Å–ª–æ, –∫–æ—Ç–æ—Ä–æ–µ —Å–∞–º–æ –ø–æ —Å–µ–±–µ –Ω–µ –∏–º–µ–µ—Ç —Å–º—ã—Å–ª–∞. –ö–∞–∫ –º—ã —É–∂–µ –≤–∏–¥–µ–ª–∏, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –º–µ–∂–¥—É —Ü–µ–ª—ã–º–∏ —á–∏—Å–ª–∞–º–∏ –∏ –∏–º–µ–Ω–∞–º–∏ –º–µ—Ç–æ–∫ —Ö—Ä–∞–Ω–∏—Ç—Å—è –≤ –∞—Ç—Ä–∏–±—É—Ç–µ `names` —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–π *—Ñ—É–Ω–∫—Ü–∏–∏* –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö:

```py
trainer.train_dataset.features["label"].names
```

```python out
['entailment', 'neutral', 'contradiction']
```

–ò—Ç–∞–∫, `1` –æ–∑–Ω–∞—á–∞–µ—Ç `–Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π`, –∞ –∑–Ω–∞—á–∏—Ç, –¥–≤–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –º—ã –≤–∏–¥–µ–ª–∏ –≤—ã—à–µ, –Ω–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∞—Ç –¥—Ä—É–≥ –¥—Ä—É–≥—É, –∏ –∏–∑ –ø–µ—Ä–≤–æ–≥–æ –Ω–µ —Å–ª–µ–¥—É–µ—Ç –≤—Ç–æ—Ä–æ–µ. –≠—Ç–æ –∫–∞–∂–µ—Ç—Å—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º!

–ó–¥–µ—Å—å —É –Ω–∞—Å –Ω–µ—Ç –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ —Ç–∏–ø–æ–≤ —Ç–æ–∫–µ–Ω–æ–≤, –ø–æ—Å–∫–æ–ª—å–∫—É DistilBERT –∏—Ö –Ω–µ –æ–∂–∏–¥–∞–µ—Ç; –µ—Å–ª–∏ –≤ –≤–∞—à–µ–π –º–æ–¥–µ–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å, –≤–∞–º —Ç–∞–∫–∂–µ —Å–ª–µ–¥—É–µ—Ç —É–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –æ–Ω–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –º–µ—Å—Ç—É –ø–µ—Ä–≤–æ–≥–æ –∏ –≤—Ç–æ—Ä–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤–æ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.

<Tip>

‚úèÔ∏è **–í–∞—à–∞ –æ—á–µ—Ä–µ–¥—å!** –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, –≤—Å–µ –ª–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Å–æ –≤—Ç–æ—Ä—ã–º —ç–ª–µ–º–µ–Ω—Ç–æ–º –æ–±—É—á–∞—é—â–µ–≥–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö.

</Tip>

–í –¥–∞–Ω–Ω–æ–º —Å–ª—É—á–∞–µ –º—ã –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ª—å–∫–æ –æ–±—É—á–∞—é—â–∏–π –Ω–∞–±–æ—Ä, –Ω–æ, –∫–æ–Ω–µ—á–Ω–æ, –≤—ã –¥–æ–ª–∂–Ω—ã –¥–≤–∞–∂–¥—ã –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π –∏ —Ç–µ—Å—Ç–æ–≤—ã–π –Ω–∞–±–æ—Ä—ã —Ç–∞–∫–∏–º –∂–µ –æ–±—Ä–∞–∑–æ–º.

–¢–µ–ø–µ—Ä—å, –∫–æ–≥–¥–∞ –º—ã –∑–Ω–∞–µ–º, —á—Ç–æ –Ω–∞—à–∏ –Ω–∞–±–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö –≤—ã–≥–ª—è–¥—è—Ç —Ö–æ—Ä–æ—à–æ, –ø—Ä–∏—à–ª–æ –≤—Ä–µ–º—è –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–ª–µ–¥—É—é—â–∏–π —ç—Ç–∞–ø –ø–∞–π–ø–ª–∞–π–Ω–∞ –æ–±—É—á–µ–Ω–∏—è.

### –û—Ç –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –∫ –∑–∞–≥—Ä—É–∑—á–∏–∫–∞–º –¥–∞–Ω–Ω—ã—Ö[[from-datasets-to-dataloaders]]

–°–ª–µ–¥—É—é—â–µ–µ, —á—Ç–æ –º–æ–∂–µ—Ç –ø–æ–π—Ç–∏ –Ω–µ —Ç–∞–∫ –≤ –ø–∞–π–ø–ª–∞–π–Ω–µ –æ–±—É—á–µ–Ω–∏—è, - —ç—Ç–æ –∫–æ–≥–¥–∞ `Trainer` –ø—ã—Ç–∞–µ—Ç—Å—è —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –±–∞—Ç—á–∏ –∏–∑ –æ–±—É—á–∞—é—â–µ–≥–æ –∏–ª–∏ –ø—Ä–æ–≤–µ—Ä–æ—á–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞. –£–±–µ–¥–∏–≤—à–∏—Å—å, —á—Ç–æ –Ω–∞–±–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö `Trainer` –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã, –º–æ–∂–Ω–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –≤—Ä—É—á–Ω—É—é —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –±–∞—Ç—á, –≤—ã–ø–æ–ª–Ω–∏–≤ —Å–ª–µ–¥—É—é—â–∏–µ –¥–µ–π—Å—Ç–≤–∏—è (–∑–∞–º–µ–Ω–∏—Ç–µ `train` –Ω–∞ `eval` –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –∑–∞–≥—Ä—É–∑—á–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö):

```py
for batch in trainer.get_train_dataloader():
    break
```

–≠—Ç–æ—Ç –∫–æ–¥ —Å–æ–∑–¥–∞–µ—Ç –∑–∞–≥—Ä—É–∑—á–∏–∫ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è, –∑–∞—Ç–µ–º –≤—ã–ø–æ–ª–Ω—è–µ—Ç –∏—Ç–µ—Ä–∞—Ü–∏–∏ –ø–æ –Ω–µ–º—É, –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—è—Å—å –Ω–∞ –ø–µ—Ä–≤–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏. –ï—Å–ª–∏ –∫–æ–¥ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –±–µ–∑ –æ—à–∏–±–æ–∫, —É –≤–∞—Å –µ—Å—Ç—å –ø–µ—Ä–≤—ã–π –æ–±—É—á–∞—é—â–∏–π –±–∞—Ç—á, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, –∞ –µ—Å–ª–∏ –∫–æ–¥ –≤—ã–¥–∞–µ—Ç –æ—à–∏–±–∫—É, –≤—ã —Ç–æ—á–Ω–æ –∑–Ω–∞–µ—Ç–µ, —á—Ç–æ –ø—Ä–æ–±–ª–µ–º–∞ –≤ –∑–∞–≥—Ä—É–∑—á–∏–∫–µ –¥–∞–Ω–Ω—ã—Ö, –∫–∞–∫ –≤ –¥–∞–Ω–Ω–æ–º —Å–ª—É—á–∞–µ:

```python out
~/git/transformers/src/transformers/data/data_collator.py in torch_default_data_collator(features)
    105                 batch[k] = torch.stack([f[k] for f in features])
    106             else:
--> 107                 batch[k] = torch.tensor([f[k] for f in features])
    108 
    109     return batch

ValueError: expected sequence of length 45 at dim 1 (got 76)
```

–û—Å–º–æ—Ç—Ä–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∫–∞–¥—Ä–∞ —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, —á—Ç–æ–±—ã –¥–∞—Ç—å –≤–∞–º –ø–æ–¥—Å–∫–∞–∑–∫—É, –Ω–æ –¥–∞–≤–∞–π—Ç–µ –ø–æ–∫–æ–ø–∞–µ–º—Å—è –µ—â–µ –Ω–µ–º–Ω–æ–≥–æ. –ë–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –ø—Ä–æ–±–ª–µ–º –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –±–∞—Ç—á–µ–π –≤–æ–∑–Ω–∏–∫–∞–µ—Ç –∏–∑-–∑–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ –æ–¥–∏–Ω –±–∞—Ç—á, –ø–æ—ç—Ç–æ–º—É –ø–µ—Ä–≤–æ–µ, —á—Ç–æ –Ω—É–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ø—Ä–∏ –≤–æ–∑–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏–∏ —Å–æ–º–Ω–µ–Ω–∏–π, —ç—Ç–æ —Ç–æ, –∫–∞–∫–æ–π `collate_fn` –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≤–∞—à `DataLoader`:

```py
data_collator = trainer.get_train_dataloader().collate_fn
data_collator
```

```python out
<function transformers.data.data_collator.default_data_collator(features: List[InputDataClass], return_tensors='pt') -> Dict[str, Any]>
```

–≠—Ç–æ—Ç `default_data_collator`  –Ω–µ —Ç–æ, —á—Ç–æ –Ω–∞–º –Ω—É–∂–Ω–æ –≤ –¥–∞–Ω–Ω–æ–º —Å–ª—É—á–∞–µ. –ú—ã —Ö–æ—Ç–∏–º —Ä–∞–∑–±–∏—Ç—å –Ω–∞—à–∏ –ø—Ä–∏–º–µ—Ä—ã –Ω–∞ —Å–∞–º—ã–µ –¥–ª–∏–Ω–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –≤ –ø–∞–∫–µ—Ç–µ, —á—Ç–æ –¥–µ–ª–∞–µ—Ç `DataCollatorWithPadding`. –ò —ç—Ç–æ—Ç –∫–ª–∞—Å—Å –¥–∞–Ω–Ω—ã—Ö –¥–æ–ª–∂–µ–Ω –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤ `Trainer`, —Ç–∞–∫ –ø–æ—á–µ–º—É –∂–µ –æ–Ω –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–¥–µ—Å—å?

–û—Ç–≤–µ—Ç –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ —Ç–æ–º, —á—Ç–æ –º—ã –Ω–µ –ø–µ—Ä–µ–¥–∞–ª–∏ `tokenizer` –≤ `Trainer`, –ø–æ—ç—Ç–æ–º—É –æ–Ω –Ω–µ —Å–º–æ–≥ —Å–æ–∑–¥–∞—Ç—å –Ω—É–∂–Ω—ã–π –Ω–∞–º `DataCollatorWithPadding`. –ù–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ –≤–∞–º –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ —Å–ª–µ–¥—É–µ—Ç —Å—Ç–µ—Å–Ω—è—Ç—å—Å—è —è–≤–Ω–æ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å data collator, –∫–æ—Ç–æ—Ä—ã–π –≤—ã —Ö–æ—Ç–∏—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø–æ–¥–æ–±–Ω—ã—Ö –æ—à–∏–±–æ–∫. –î–∞–≤–∞–π—Ç–µ –∞–¥–∞–ø—Ç–∏—Ä—É–µ–º –Ω–∞—à –∫–æ–¥, —á—Ç–æ–±—ã —Å–¥–µ–ª–∞—Ç—å –∏–º–µ–Ω–Ω–æ —ç—Ç–æ:

```py
from datasets import load_dataset
import evaluate
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    DataCollatorWithPadding,
    TrainingArguments,
    Trainer,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
    return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)

args = TrainingArguments(
    f"distilbert-finetuned-mnli",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
)

metric = evaluate.load("glue", "mnli")


def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    return metric.compute(predictions=predictions, references=labels)


data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

trainer = Trainer(
    model,
    args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation_matched"],
    compute_metrics=compute_metrics,
    data_collator=data_collator,
    tokenizer=tokenizer,
)
trainer.train()
```

–•–æ—Ä–æ—à–∏–µ –Ω–æ–≤–æ—Å—Ç–∏? –ú—ã –Ω–µ –ø–æ–ª—É—á–∞–µ–º —Ç—É –∂–µ –æ—à–∏–±–∫—É, —á—Ç–æ –∏ —Ä–∞–Ω—å—à–µ, —á—Ç–æ, –±–µ–∑—É—Å–ª–æ–≤–Ω–æ, —è–≤–ª—è–µ—Ç—Å—è –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º. –ü–ª–æ—Ö–∏–µ –Ω–æ–≤–æ—Å—Ç–∏? –í–º–µ—Å—Ç–æ –Ω–µ–µ –º—ã –ø–æ–ª—É—á–∞–µ–º –ø–µ—á–∞–ª—å–Ω–æ –∏–∑–≤–µ—Å—Ç–Ω—É—é –æ—à–∏–±–∫—É CUDA:

```python out
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
```

–≠—Ç–æ –ø–ª–æ—Ö–æ, –ø–æ—Ç–æ–º—É —á—Ç–æ –æ—à–∏–±–∫–∏ CUDA –≤–æ–æ–±—â–µ –æ—á–µ–Ω—å —Ç—Ä—É–¥–Ω–æ –æ—Ç–ª–∞–∂–∏–≤–∞—Ç—å. –ß–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É –º—ã —É–≤–∏–¥–∏–º, –∫–∞–∫ —Ä–µ—à–∏—Ç—å —ç—Ç—É –ø—Ä–æ–±–ª–µ–º—É, –Ω–æ —Å–Ω–∞—á–∞–ª–∞ –¥–∞–≤–∞–π—Ç–µ –∑–∞–∫–æ–Ω—á–∏–º –∞–Ω–∞–ª–∏–∑ —Å–æ–∑–¥–∞–Ω–∏—è –±–∞—Ç—á–µ–π.

–ï—Å–ª–∏ –≤—ã —É–≤–µ—Ä–µ–Ω—ã, —á—Ç–æ –≤–∞—à data collator –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø—Ä–∏–º–µ–Ω–∏—Ç—å –µ–≥–æ –Ω–∞ –ø–∞—Ä–µ –ø—Ä–∏–º–µ—Ä–æ–≤ –≤–∞—à–µ–≥–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö:

```py
data_collator = trainer.get_train_dataloader().collate_fn
batch = data_collator([trainer.train_dataset[i] for i in range(4)])
```

–≠—Ç–æ—Ç –∫–æ–¥ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–µ—Ç, –ø–æ—Ç–æ–º—É —á—Ç–æ `train_dataset` —Å–æ–¥–µ—Ä–∂–∏—Ç —Å—Ç—Ä–æ–∫–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ `Trainer` –æ–±—ã—á–Ω–æ —É–¥–∞–ª—è–µ—Ç. –í—ã –º–æ–∂–µ—Ç–µ —É–¥–∞–ª–∏—Ç—å –∏—Ö –≤—Ä—É—á–Ω—É—é, –∏–ª–∏, –µ—Å–ª–∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ –≤ —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å —Ç–æ, —á—Ç–æ `Trainer` –¥–µ–ª–∞–µ—Ç –∑–∞ –∫—É–ª–∏—Å–∞–º–∏: –Ω—É–∂–Ω–æ –≤—ã–∑–≤–∞—Ç—å –ø—Ä–∏–≤–∞—Ç–Ω—ã–π –º–µ—Ç–æ–¥ `Trainer._remove_unused_columns()`, –∫–æ—Ç–æ—Ä—ã–π –¥–µ–ª–∞–µ—Ç —ç—Ç–æ:

```py
data_collator = trainer.get_train_dataloader().collate_fn
actual_train_set = trainer._remove_unused_columns(trainer.train_dataset)
batch = data_collator([actual_train_set[i] for i in range(4)])
```

–ï—Å–ª–∏ –æ—à–∏–±–∫–∞ –Ω–µ –∏—Å—á–µ–∑–Ω–µ—Ç, –≤—ã —Å–º–æ–∂–µ—Ç–µ –≤—Ä—É—á–Ω—É—é –æ—Ç–ª–∞–¥–∏—Ç—å, —á—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –≤–Ω—É—Ç—Ä–∏ data collator.

–¢–µ–ø–µ—Ä—å, –∫–æ–≥–¥–∞ –º—ã –æ—Ç–ª–∞–¥–∏–ª–∏ –ø—Ä–æ—Ü–µ—Å—Å —Å–æ–∑–¥–∞–Ω–∏—è –±–∞—Ç—á–∞, –ø—Ä–∏—à–ª–æ –≤—Ä–µ–º—è –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –µ–≥–æ —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å!

### –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–∞–Ω–Ω—ã–µ[[going-through-the-model]]

–í—ã –¥–æ–ª–∂–Ω—ã –∏–º–µ—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø–æ–ª—É—á–∏—Ç—å –±–∞—Ç—á, –≤—ã–ø–æ–ª–Ω–∏–≤ —Å–ª–µ–¥—É—é—â—É—é –∫–æ–º–∞–Ω–¥—É:

```py
for batch in trainer.get_train_dataloader():
    break
```

–ï—Å–ª–∏ –≤—ã –≤—ã–ø–æ–ª–Ω—è–µ—Ç–µ —ç—Ç–æ—Ç –∫–æ–¥ –≤ –Ω–æ—É—Ç–±—É–∫–µ, –≤—ã –º–æ–∂–µ—Ç–µ –ø–æ–ª—É—á–∏—Ç—å –æ—à–∏–±–∫—É CUDA, –ø–æ—Ö–æ–∂—É—é –Ω–∞ —Ç—É, —á—Ç–æ –º—ã –≤–∏–¥–µ–ª–∏ —Ä–∞–Ω–µ–µ, –∏ –≤ —ç—Ç–æ–º —Å–ª—É—á–∞–µ –≤–∞–º –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å –Ω–æ—É—Ç–±—É–∫ –∏ –∑–∞–Ω–æ–≤–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç –±–µ–∑ —Å—Ç—Ä–æ–∫–∏ `trainer.train()`. –≠—Ç–æ –≤—Ç–æ—Ä–∞—è —Å–∞–º–∞—è –Ω–µ–ø—Ä–∏—è—Ç–Ω–∞—è –≤–µ—â—å –≤ –æ—à–∏–±–∫–∞—Ö CUDA: –æ–Ω–∏ –±–µ–∑–≤–æ–∑–≤—Ä–∞—Ç–Ω–æ –ª–æ–º–∞—é—Ç –≤–∞—à–µ —è–¥—Ä–æ. –°–∞–º–æ–µ –Ω–µ–ø—Ä–∏—è—Ç–Ω–æ–µ –≤ –Ω–∏—Ö —Ç–æ, —á—Ç–æ –∏—Ö —Ç—Ä—É–¥–Ω–æ –æ—Ç–ª–∞–∂–∏–≤–∞—Ç—å.

–ü–æ—á–µ–º—É? –≠—Ç–æ —Å–≤—è–∑–∞–Ω–æ —Å —Ç–µ–º, –∫–∞–∫ —Ä–∞–±–æ—Ç–∞—é—Ç –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä—ã. –û–Ω–∏ —á—Ä–µ–∑–≤—ã—á–∞–π–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã –ø—Ä–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –æ–ø–µ—Ä–∞—Ü–∏–π, –Ω–æ –∏—Ö –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ–∫ –≤ —Ç–æ–º, —á—Ç–æ –∫–æ–≥–¥–∞ –æ–¥–Ω–∞ –∏–∑ —ç—Ç–∏—Ö –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –æ—à–∏–±–∫–µ, –≤—ã –Ω–µ —Å—Ä–∞–∑—É –æ–± —ç—Ç–æ–º —É–∑–Ω–∞–µ—Ç–µ. –¢–æ–ª—å–∫–æ –∫–æ–≥–¥–∞ –ø—Ä–æ–≥—Ä–∞–º–º–∞ –≤—ã–∑–æ–≤–µ—Ç —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –Ω–∞ GPU, –æ–Ω–∞ –ø–æ–π–º–µ—Ç, —á—Ç–æ —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫, –ø–æ—ç—Ç–æ–º—É –æ—à–∏–±–∫–∞ –≤–æ–∑–Ω–∏–∫–∞–µ—Ç –≤ —Ç–æ–º –º–µ—Å—Ç–µ, –∫–æ—Ç–æ—Ä–æ–µ –Ω–µ –∏–º–µ–µ—Ç –Ω–∏–∫–∞–∫–æ–≥–æ –æ—Ç–Ω–æ—à–µ–Ω–∏—è –∫ —Ç–æ–º—É, —á—Ç–æ –µ–µ —Å–æ–∑–¥–∞–ª–æ. –ù–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ –º—ã –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –Ω–∞—à –ø—Ä–µ–¥—ã–¥—É—â–∏–π —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–æ—á–Ω—ã–π –æ—Ç–∫–∞—Ç, –æ—à–∏–±–∫–∞ –±—ã–ª–∞ –≤—ã–∑–≤–∞–Ω–∞ –≤–æ –≤—Ä–µ–º—è –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –ø—Ä–æ—Ö–æ–¥–∞, –Ω–æ —á–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É –º—ã —É–≤–∏–¥–∏–º, —á—Ç–æ –Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ –æ–Ω–∞ –≤–æ–∑–Ω–∏–∫–ª–∞ –∏–∑-–∑–∞ —á–µ–≥–æ-—Ç–æ –≤ –ø—Ä—è–º–æ–º –ø—Ä–æ—Ö–æ–¥–µ —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å.

–¢–∞–∫ –∫–∞–∫ –∂–µ –æ—Ç–ª–∞–¥–∏—Ç—å —ç—Ç–∏ –æ—à–∏–±–∫–∏? –û—Ç–≤–µ—Ç –ø—Ä–æ—Å—Ç: –Ω–∏–∫–∞–∫. –ï—Å–ª–∏ —Ç–æ–ª—å–∫–æ –æ—à–∏–±–∫–∞ CUDA –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –æ—à–∏–±–∫–æ–π –≤–Ω–µ –ø–∞–º—è—Ç–∏ (—á—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –≤ –≤–∞—à–µ–º GPU –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–∞–º—è—Ç–∏), –≤—ã –≤—Å–µ–≥–¥–∞ –¥–æ–ª–∂–Ω—ã –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å—Å—è –∫ CPU, —á—Ç–æ–±—ã –æ—Ç–ª–∞–¥–∏—Ç—å –µ–µ.

–ß—Ç–æ–±—ã —Å–¥–µ–ª–∞—Ç—å —ç—Ç–æ –≤ –Ω–∞—à–µ–º —Å–ª—É—á–∞–µ, –Ω–∞–º –ø—Ä–æ—Å—Ç–æ –Ω—É–∂–Ω–æ –≤–µ—Ä–Ω—É—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ CPU –∏ –≤—ã–∑–≤–∞—Ç—å –µ–µ –Ω–∞ –Ω–∞—à–µ–º –ø–∞–∫–µ—Ç–µ - –ø–∞–∫–µ—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—ã–π `DataLoader`, –µ—â–µ –Ω–µ –±—ã–ª –ø–µ—Ä–µ–º–µ—â–µ–Ω –Ω–∞ GPU:

```python
outputs = trainer.model.cpu()(**batch)
```

```python out
~/.pyenv/versions/3.7.9/envs/base/lib/python3.7/site-packages/torch/nn/functional.py in nll_loss(input, target, weight, size_average, ignore_index, reduce, reduction)
   2386         )
   2387     if dim == 2:
-> 2388         ret = torch._C._nn.nll_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index)
   2389     elif dim == 4:
   2390         ret = torch._C._nn.nll_loss2d(input, target, weight, _Reduction.get_enum(reduction), ignore_index)

IndexError: Target 2 is out of bounds.
```

–ò—Ç–∞–∫, –∫–∞—Ä—Ç–∏–Ω–∞ –ø—Ä–æ—è—Å–Ω—è–µ—Ç—Å—è. –í–º–µ—Å—Ç–æ –æ—à–∏–±–∫–∏ CUDA —É –Ω–∞—Å —Ç–µ–ø–µ—Ä—å `IndexError` –ø—Ä–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å (—Ç–∞–∫ —á—Ç–æ –æ–±—Ä–∞—Ç–Ω—ã–π –ø—Ä–æ—Ö–æ–¥, –∫–∞–∫ –º—ã —É–∂–µ –≥–æ–≤–æ—Ä–∏–ª–∏, –∑–¥–µ—Å—å –Ω–∏ –ø—Ä–∏ —á–µ–º). –¢–æ—á–Ω–µ–µ, –º—ã –≤–∏–¥–∏–º, —á—Ç–æ –æ—à–∏–±–∫–∞ –≤–æ–∑–Ω–∏–∫–∞–µ—Ç –∏–º–µ–Ω–Ω–æ –≤ –º–µ—Ç–∫–µ –∫–ª–∞—Å—Å–∞ 2, —Ç–∞–∫ —á—Ç–æ —ç—Ç–æ –æ—á–µ–Ω—å —Ö–æ—Ä–æ—à–∏–π –º–æ–º–µ–Ω—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –º–µ—Ç–æ–∫ –Ω–∞—à–µ–π –º–æ–¥–µ–ª–∏:

```python
trainer.model.config.num_labels
```

```python out
2
```

–ü—Ä–∏ –¥–≤—É—Ö –º–µ—Ç–∫–∞—Ö –≤ –∫–∞—á–µ—Å—Ç–≤–µ –∑–Ω–∞—á–µ–Ω–∏–π –¥–æ–ø—É—Å–∫–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ 0 –∏ 1, –Ω–æ, —Å–æ–≥–ª–∞—Å–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏—é –æ–± –æ—à–∏–±–∫–µ, –º—ã –ø–æ–ª—É—á–∏–ª–∏ 2. –ü–æ–ª—É—á–µ–Ω–∏–µ 2 –Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ: –µ—Å–ª–∏ –º—ã –ø–æ–º–Ω–∏–º –∏–º–µ–Ω–∞ –º–µ—Ç–æ–∫, –∫–æ—Ç–æ—Ä—ã–µ –º—ã –∏–∑–≤–ª–µ–∫–ª–∏ —Ä–∞–Ω–µ–µ, –∏—Ö –±—ã–ª–æ —Ç—Ä–∏, –ø–æ—ç—Ç–æ–º—É –≤ –Ω–∞—à–µ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö –µ—Å—Ç—å –∏–Ω–¥–µ–∫—Å—ã 0, 1 –∏ 2. –ü—Ä–æ–±–ª–µ–º–∞ –≤ —Ç–æ–º, —á—Ç–æ –º—ã –Ω–µ —Å–æ–æ–±—â–∏–ª–∏ –æ–± —ç—Ç–æ–º –Ω–∞—à–µ–π –º–æ–¥–µ–ª–∏, –∫–æ—Ç–æ—Ä–∞—è –¥–æ–ª–∂–Ω–∞ –±—ã–ª–∞ –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω–∞ —Å —Ç—Ä–µ–º—è –º–µ—Ç–∫–∞–º–∏. –¢–∞–∫ —á—Ç–æ –¥–∞–≤–∞–π—Ç–µ —ç—Ç–æ –∏—Å–ø—Ä–∞–≤–∏–º!

```py
from datasets import load_dataset
import evaluate
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    DataCollatorWithPadding,
    TrainingArguments,
    Trainer,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
    return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=3)

args = TrainingArguments(
    f"distilbert-finetuned-mnli",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
)

metric = evaluate.load("glue", "mnli")


def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    return metric.compute(predictions=predictions, references=labels)


data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

trainer = Trainer(
    model,
    args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation_matched"],
    compute_metrics=compute_metrics,
    data_collator=data_collator,
    tokenizer=tokenizer,
)
```

–ú—ã –ø–æ–∫–∞ –Ω–µ –≤–∫–ª—é—á–∞–µ–º —Å—Ç—Ä–æ–∫—É `trainer.train()`, —á—Ç–æ–±—ã –ø–æ—Ç—Ä–∞—Ç–∏—Ç—å –≤—Ä–µ–º—è –Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫—É —Ç–æ–≥–æ, —á—Ç–æ –≤—Å–µ –≤—ã–≥–ª—è–¥–∏—Ç —Ö–æ—Ä–æ—à–æ. –ï—Å–ª–∏ –º—ã –∑–∞–ø—Ä–æ—Å–∏–º –±–∞—Ç—á –∏ –ø–µ—Ä–µ–¥–∞–¥–∏–º –µ–µ –Ω–∞—à–µ–π –º–æ–¥–µ–ª–∏, —Ç–æ —Ç–µ–ø–µ—Ä—å –æ–Ω–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ –æ—à–∏–±–æ–∫!

```py
for batch in trainer.get_train_dataloader():
    break

outputs = trainer.model.cpu()(**batch)
```

–°–ª–µ–¥—É—é—â–∏–º —à–∞–≥–æ–º –±—É–¥–µ—Ç –≤–æ–∑–≤—Ä–∞—â–µ–Ω–∏–µ –∫ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–º—É –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä—É –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ–≥–æ, —á—Ç–æ –≤—Å–µ –ø–æ-–ø—Ä–µ–∂–Ω–µ–º—É —Ä–∞–±–æ—Ç–∞–µ—Ç:

```py
import torch

device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
batch = {k: v.to(device) for k, v in batch.items()}

outputs = trainer.model.to(device)(**batch)
```

–ï—Å–ª–∏ –≤—ã –≤—Å–µ –µ—â–µ –ø–æ–ª—É—á–∞–µ—Ç–µ –æ—à–∏–±–∫—É, —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏–ª–∏ –Ω–æ—É—Ç–±—É–∫ –∏ –≤—ã–ø–æ–ª–Ω–∏–ª–∏ —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω—é—é –≤–µ—Ä—Å–∏—é —Å–∫—Ä–∏–ø—Ç–∞.

### –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –æ–¥–Ω–æ–≥–æ —à–∞–≥–∞ –æ–ø—Ç–∏–∏–º–∑–∞—Ü–∏–∏[[performing-one-optimization-step]]

–¢–µ–ø–µ—Ä—å, –∫–æ–≥–¥–∞ –º—ã –∑–Ω–∞–µ–º, —á—Ç–æ –º–æ–∂–µ–º —Å–æ–∑–¥–∞–≤–∞—Ç—å –±–∞—Ç—á–∏, –∫–æ—Ç–æ—Ä—ã–µ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–æ—Ö–æ–¥—è—Ç —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å –±–µ–∑ –æ—à–∏–±–æ–∫, –º—ã –≥–æ—Ç–æ–≤—ã –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —à–∞–≥—É –ø–∞–π–ø–ª–∞–π–Ω–∞ –æ–±—É—á–µ–Ω–∏—è: –≤—ã—á–∏—Å–ª–µ–Ω–∏—é –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—é —à–∞–≥–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏.

–ü–µ—Ä–≤–∞—è —á–∞—Å—Ç—å –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ –≤—ã–∑–æ–≤–µ –º–µ—Ç–æ–¥–∞ `backward()` –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å:

```py
loss = outputs.loss
loss.backward()
```

–û—à–∏–±–∫–∏ –Ω–∞ —ç—Ç–æ–º —ç—Ç–∞–ø–µ –≤–æ–∑–Ω–∏–∫–∞—é—Ç –¥–æ–≤–æ–ª—å–Ω–æ —Ä–µ–¥–∫–æ, –Ω–æ –µ—Å–ª–∏ –æ–Ω–∏ –≤—Å–µ –∂–µ –≤–æ–∑–Ω–∏–∫–Ω—É—Ç, –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –≤–µ—Ä–Ω–∏—Ç–µ—Å—å –∫ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä—É, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –ø–æ–ª–µ–∑–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ.

–ß—Ç–æ–±—ã –≤—ã–ø–æ–ª–Ω–∏—Ç—å —à–∞–≥ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏, –Ω–∞–º –Ω—É–∂–Ω–æ –ø—Ä–æ—Å—Ç–æ —Å–æ–∑–¥–∞—Ç—å `optimizer` –∏ –≤—ã–∑–≤–∞—Ç—å –µ–≥–æ –º–µ—Ç–æ–¥ `step()`:

```py
trainer.create_optimizer()
trainer.optimizer.step()
```

–û–ø—è—Ç—å –∂–µ, –µ—Å–ª–∏ –≤—ã –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤ `Trainer`, –≤—ã –Ω–µ –¥–æ–ª–∂–Ω—ã –ø–æ–ª—É—á–∏—Ç—å –æ—à–∏–±–∫—É –Ω–∞ —ç—Ç–æ–º —ç—Ç–∞–ø–µ, –Ω–æ –µ—Å–ª–∏ –≤—ã –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä, –∑–¥–µ—Å—å –º–æ–≥—É—Ç –≤–æ–∑–Ω–∏–∫–Ω—É—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏. –ù–µ –∑–∞–±—É–¥—å—Ç–µ –≤–µ—Ä–Ω—É—Ç—å—Å—è –∫ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä—É, –µ—Å–ª–∏ –Ω–∞ —ç—Ç–æ–º —ç—Ç–∞–ø–µ –≤—ã –ø–æ–ª—É—á–∏—Ç–µ —Å—Ç—Ä–∞–Ω–Ω—É—é –æ—à–∏–±–∫—É CUDA. –ì–æ–≤–æ—Ä—è –æ–± –æ—à–∏–±–∫–∞—Ö CUDA, —Ä–∞–Ω–µ–µ –º—ã —É–ø–æ–º–∏–Ω–∞–ª–∏ –æ—Å–æ–±—ã–π —Å–ª—É—á–∞–π. –î–∞–≤–∞–π—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –Ω–µ–≥–æ —Å–µ–π—á–∞—Å.

### –ö–∞–∫ —Å–ø—Ä–∞–≤–∏—Ç—å—Å—è —Å –æ—à–∏–±–∫–∞–º–∏ –Ω–µ—Ö–≤–∞—Ç–∫–∏ –ø–∞–º—è—Ç–∏[[dealing-with-cuda-out-of-memory-errors]]

–ï—Å–ª–∏ –≤—ã –ø–æ–ª—É—á–∞–µ—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ, –Ω–∞—á–∏–Ω–∞—é—â–µ–µ—Å—è —Å `RuntimeError: CUDA out of memory`, —ç—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –≤–∞–º –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –ø–∞–º—è—Ç–∏ GPU. –≠—Ç–æ –Ω–µ —Å–≤—è–∑–∞–Ω–æ –Ω–∞–ø—Ä—è–º—É—é —Å –≤–∞—à–∏–º –∫–æ–¥–æ–º, –∏ –º–æ–∂–µ—Ç –ø—Ä–æ–∏–∑–æ–π—Ç–∏ —Å–æ —Å–∫—Ä–∏–ø—Ç–æ–º, –∫–æ—Ç–æ—Ä—ã–π —Ä–∞–±–æ—Ç–∞–µ—Ç —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ. –≠—Ç–∞ –æ—à–∏–±–∫–∞ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –≤—ã –ø—ã—Ç–∞–ª–∏—Å—å –ø–æ–º–µ—Å—Ç–∏—Ç—å —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –¥–∞–Ω–Ω—ã—Ö –≤–æ –≤–Ω—É—Ç—Ä–µ–Ω–Ω—é—é –ø–∞–º—è—Ç—å –≤–∞—à–µ–≥–æ GPU, –∏ —ç—Ç–æ –ø—Ä–∏–≤–µ–ª–æ –∫ –æ—à–∏–±–∫–µ. –ö–∞–∫ –∏ –≤ —Å–ª—É—á–∞–µ —Å –¥—Ä—É–≥–∏–º–∏ –æ—à–∏–±–∫–∞–º–∏ CUDA, –≤–∞–º –ø—Ä–∏–¥–µ—Ç—Å—è –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å —è–¥—Ä–æ, —á—Ç–æ–±—ã —Å–Ω–æ–≤–∞ –∑–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ.

–ß—Ç–æ–±—ã —Ä–µ—à–∏—Ç—å —ç—Ç—É –ø—Ä–æ–±–ª–µ–º—É, –Ω—É–∂–Ω–æ –ø—Ä–æ—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–µ–Ω—å—à–µ –ø–∞–º—è—Ç–∏ –Ω–∞ GPU - —á—Ç–æ –∑–∞—á–∞—Å—Ç—É—é –ª–µ–≥—á–µ —Å–∫–∞–∑–∞—Ç—å, —á–µ–º —Å–¥–µ–ª–∞—Ç—å. –í–æ-–ø–µ—Ä–≤—ã—Ö, —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É –≤–∞—Å –Ω–µ—Ç –¥–≤—É—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ GPU –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ (–µ—Å–ª–∏, –∫–æ–Ω–µ—á–Ω–æ, —ç—Ç–æ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –≤–∞—à–µ–π –∑–∞–¥–∞—á–∏). –ó–∞—Ç–µ–º, –≤–µ—Ä–æ—è—Ç–Ω–æ, —Å–ª–µ–¥—É–µ—Ç —É–º–µ–Ω—å—à–∏—Ç—å —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞, –ø–æ—Å–∫–æ–ª—å–∫—É –æ–Ω –Ω–∞–ø—Ä—è–º—É—é –≤–ª–∏—è–µ—Ç –Ω–∞ —Ä–∞–∑–º–µ—Ä—ã –≤—Å–µ—Ö –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö –≤—ã—Ö–æ–¥–æ–≤ –º–æ–¥–µ–ª–∏ –∏ –∏—Ö –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤. –ï—Å–ª–∏ –ø—Ä–æ–±–ª–µ–º–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è, –ø–æ–¥—É–º–∞–π—Ç–µ –æ —Ç–æ–º, —á—Ç–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–µ–Ω—å—à—É—é –≤–µ—Ä—Å–∏—é –º–æ–¥–µ–ª–∏.

<Tip>

–í —Å–ª–µ–¥—É—é—â–µ–π —á–∞—Å—Ç–∏ –∫—É—Ä—Å–∞ –º—ã —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º –±–æ–ª–µ–µ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–º–æ–≥—É—Ç –≤–∞–º —É–º–µ–Ω—å—à–∏—Ç—å –æ–±—ä–µ–º –∑–∞–Ω–∏–º–∞–µ–º–æ–π –ø–∞–º—è—Ç–∏ –∏ –ø–æ–∑–≤–æ–ª—è—Ç —Ç–æ—á–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å —Å–∞–º—ã–µ –±–æ–ª—å—à–∏–µ –º–æ–¥–µ–ª–∏.

</Tip>

### –í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏[[evaluating-the-model]]

–¢–µ–ø–µ—Ä—å, –∫–æ–≥–¥–∞ –º—ã —Ä–µ—à–∏–ª–∏ –≤—Å–µ –ø—Ä–æ–±–ª–µ–º—ã —Å –Ω–∞—à–∏–º –∫–æ–¥–æ–º, –≤—Å–µ –∏–¥–µ–∞–ª—å–Ω–æ, –∏ –æ–±—É—á–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –ø—Ä–æ–π—Ç–∏ –≥–ª–∞–¥–∫–æ, –≤–µ—Ä–Ω–æ? –ù–µ —Ç–∞–∫ –±—ã—Å—Ç—Ä–æ! –ï—Å–ª–∏ –≤—ã –∑–∞–ø—É—Å—Ç–∏—Ç–µ –∫–æ–º–∞–Ω–¥—É `trainer.train()`, —Å–Ω–∞—á–∞–ª–∞ –≤—Å–µ –±—É–¥–µ—Ç –≤—ã–≥–ª—è–¥–µ—Ç—å —Ö–æ—Ä–æ—à–æ, –Ω–æ —á–µ—Ä–µ–∑ –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è –≤—ã –ø–æ–ª—É—á–∏—Ç–µ —Å–ª–µ–¥—É—é—â–µ–µ:

```py
# –≠—Ç–æ –∑–∞–π–º–µ—Ç –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –∏ –ø—Ä–∏–≤–µ–¥–µ—Ç –∫ –æ—à–∏–±–∫–µ, –ø–æ—ç—Ç–æ–º—É –Ω–µ —Å—Ç–æ–∏—Ç –∑–∞–ø—É—Å–∫–∞—Ç—å —ç—Ç—É —è—á–µ–π–∫—É
trainer.train()
```

```python out
TypeError: only size-1 arrays can be converted to Python scalars
```

–í—ã –ø–æ–π–º–µ—Ç–µ, —á—Ç–æ —ç—Ç–∞ –æ—à–∏–±–∫–∞ –ø–æ—è–≤–ª—è–µ—Ç—Å—è –≤–æ –≤—Ä–µ–º—è —Ñ–∞–∑—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏, —Ç–∞–∫ —á—Ç–æ —ç—Ç–æ –ø–æ—Å–ª–µ–¥–Ω–µ–µ, —á—Ç–æ –Ω–∞–º –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç –æ—Ç–ª–∞–¥–∏—Ç—å.

–í—ã –º–æ–∂–µ—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å —Ü–∏–∫–ª –æ—Ü–µ–Ω–∫–∏ `Trainer` –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –æ–±—É—á–µ–Ω–∏—è —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º:

```py
trainer.evaluate()
```

```python out
TypeError: only size-1 arrays can be converted to Python scalars
```

<Tip>

üí° –ü–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º `trainer.train()` –≤—Å–µ–≥–¥–∞ —Å–ª–µ–¥—É–µ—Ç —É–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤—ã –º–æ–∂–µ—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å `trainer.evaluate()`, —á—Ç–æ–±—ã –Ω–µ —Ç—Ä–∞—Ç–∏—Ç—å –º–Ω–æ–≥–æ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤ –¥–æ —Ç–æ–≥–æ, –∫–∞–∫ —Å—Ç–æ–ª–∫–Ω–µ—Ç–µ—Å—å —Å –æ—à–∏–±–∫–æ–π.

</Tip>

–ü—Ä–µ–∂–¥–µ —á–µ–º –ø—ã—Ç–∞—Ç—å—Å—è –æ—Ç–ª–∞–¥–∏—Ç—å –ø—Ä–æ–±–ª–µ–º—É –≤ —Ü–∏–∫–ª–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏, –Ω—É–∂–Ω–æ —Å–Ω–∞—á–∞–ª–∞ —É–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤—ã –ø–æ—Å–º–æ—Ç—Ä–µ–ª–∏ –Ω–∞ –¥–∞–Ω–Ω—ã–µ, —Å–º–æ–≥–ª–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –±–∞—Ç—á –∏ –∑–∞–ø—É—Å—Ç–∏—Ç—å –Ω–∞ –Ω–µ–º —Å–≤–æ—é –º–æ–¥–µ–ª—å. –ú—ã –≤—ã–ø–æ–ª–Ω–∏–ª–∏ –≤—Å–µ —ç—Ç–∏ —à–∞–≥–∏, –ø–æ—ç—Ç–æ–º—É —Å–ª–µ–¥—É—é—â–∏–π –∫–æ–¥ –º–æ–∂–µ—Ç –±—ã—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω –±–µ–∑ –æ—à–∏–±–æ–∫:

```py
for batch in trainer.get_eval_dataloader():
    break

batch = {k: v.to(device) for k, v in batch.items()}

with torch.no_grad():
    outputs = trainer.model(**batch)
```

–û—à–∏–±–∫–∞ –≤–æ–∑–Ω–∏–∫–∞–µ—Ç –ø–æ–∑–∂–µ, –≤ –∫–æ–Ω—Ü–µ —Ñ–∞–∑—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏, –∏ –µ—Å–ª–∏ –º—ã –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫—É, —Ç–æ —É–≤–∏–¥–∏–º —Å–ª–µ–¥—É—é—â–µ–µ:

```python trace
~/git/datasets/src/datasets/metric.py in add_batch(self, predictions, references)
    431         """
    432         batch = {"predictions": predictions, "references": references}
--> 433         batch = self.info.features.encode_batch(batch)
    434         if self.writer is None:
    435             self._init_writer()
```

–≠—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç –Ω–∞–º –æ —Ç–æ–º, —á—Ç–æ –æ—à–∏–±–∫–∞ –≤–æ–∑–Ω–∏–∫–∞–µ—Ç –≤ –º–æ–¥—É–ª–µ `datasets/metric.py` - —Ç–∞–∫ —á—Ç–æ —ç—Ç–æ –ø—Ä–æ–±–ª–µ–º–∞ —Å –Ω–∞—à–µ–π —Ñ—É–Ω–∫—Ü–∏–µ–π `compute_metrics()`. –û–Ω–∞ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –∫–æ—Ä—Ç–µ–∂ —Å –ª–æ–≥–∏—Ç–∞–º–∏ –∏ –º–µ—Ç–∫–∞–º–∏ –≤ –≤–∏–¥–µ –º–∞—Å—Å–∏–≤–æ–≤ NumPy, —Ç–∞–∫ —á—Ç–æ –¥–∞–≤–∞–π—Ç–µ –ø–æ–ø—Ä–æ–±—É–µ–º —Å–∫–æ—Ä–º–∏—Ç—å –µ–π —ç—Ç–æ:

```py
predictions = outputs.logits.cpu().numpy()
labels = batch["labels"].cpu().numpy()

compute_metrics((predictions, labels))
```

```python out
TypeError: only size-1 arrays can be converted to Python scalars
```

–ú—ã –ø–æ–ª—É—á–∞–µ–º —Ç—É –∂–µ –æ—à–∏–±–∫—É, —Ç–∞–∫ —á—Ç–æ –ø—Ä–æ–±–ª–µ–º–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ –∫—Ä–æ–µ—Ç—Å—è –≤ —ç—Ç–æ–π —Ñ—É–Ω–∫—Ü–∏–∏. –ï—Å–ª–∏ –º—ã –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –µ–µ –∫–æ–¥, —Ç–æ —É–≤–∏–¥–∏–º, —á—Ç–æ –æ–Ω–∞ –ø—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ–¥–∞–µ—Ç `predictions` –∏ `labels` –≤ `metric.compute()`. –¢–∞–∫ –µ—Å—Ç—å –ª–∏ –ø—Ä–æ–±–ª–µ–º–∞ –≤ —ç—Ç–æ–º –º–µ—Ç–æ–¥–µ? –ù–∞ —Å–∞–º–æ–º –¥–µ–ª–µ –Ω–µ—Ç. –î–∞–≤–∞–π—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏:

```py
predictions.shape, labels.shape
```

```python out
((8, 3), (8,))
```

–ù–∞—à–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤—Å–µ –µ—â–µ —è–≤–ª—è—é—Ç—Å—è –ª–æ–≥–∏—Ç–∞–º–∏, –∞ –Ω–µ —Ä–µ–∞–ª—å–Ω—ã–º–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏, –ø–æ—ç—Ç–æ–º—É –º–µ—Ç—Ä–∏–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —ç—Ç—É (–Ω–µ—Å–∫–æ–ª—å–∫–æ –Ω–µ–ø–æ–Ω—è—Ç–Ω—É—é) –æ—à–∏–±–∫—É. –ò—Å–ø—Ä–∞–≤–∏—Ç—å —ç—Ç–æ –¥–æ–≤–æ–ª—å–Ω–æ –ø—Ä–æ—Å—Ç–æ: –Ω—É–∂–Ω–æ –ø—Ä–æ—Å—Ç–æ –¥–æ–±–∞–≤–∏—Ç—å argmax –≤ —Ñ—É–Ω–∫—Ü–∏—é `compute_metrics()`:

```py
import numpy as np


def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    predictions = np.argmax(predictions, axis=1)
    return metric.compute(predictions=predictions, references=labels)


compute_metrics((predictions, labels))
```

```python out
{'accuracy': 0.625}
```

–¢–µ–ø–µ—Ä—å –Ω–∞—à–∞ –æ—à–∏–±–∫–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∞! –û–Ω–∞ –±—ã–ª–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–π, –ø–æ—ç—Ç–æ–º—É —Ç–µ–ø–µ—Ä—å –Ω–∞—à —Å–∫—Ä–∏–ø—Ç –±—É–¥–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ–±—É—á–∞—Ç—å –º–æ–¥–µ–ª—å.

–î–ª—è —Å–ø—Ä–∞–≤–∫–∏, –≤–æ—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç:

```py
import numpy as np
from datasets import load_dataset
import evaluate
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    DataCollatorWithPadding,
    TrainingArguments,
    Trainer,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
    return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=3)

args = TrainingArguments(
    f"distilbert-finetuned-mnli",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
)

metric = evaluate.load("glue", "mnli")


def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    predictions = np.argmax(predictions, axis=1)
    return metric.compute(predictions=predictions, references=labels)


data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

trainer = Trainer(
    model,
    args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation_matched"],
    compute_metrics=compute_metrics,
    data_collator=data_collator,
    tokenizer=tokenizer,
)
trainer.train()
```

–í —ç—Ç–æ–º —Å–ª—É—á–∞–µ –ø—Ä–æ–±–ª–µ–º –±–æ–ª—å—à–µ –Ω–µ—Ç, –∏ –Ω–∞—à —Å–∫—Ä–∏–ø—Ç –æ–±—É—á–∏—Ç –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –¥–æ–ª–∂–Ω–∞ –¥–∞—Ç—å –ø—Ä–∏–µ–º–ª–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã. –ù–æ —á—Ç–æ –¥–µ–ª–∞—Ç—å, –µ—Å–ª–∏ –æ–±—É—á–µ–Ω–∏–µ –ø—Ä–æ—Ö–æ–¥–∏—Ç –±–µ–∑ –æ—à–∏–±–æ–∫, –∞ –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ–≤—Å–µ–º –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç? –≠—Ç–æ —Å–∞–º–∞—è —Å–ª–æ–∂–Ω–∞—è —á–∞—Å—Ç—å –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –∏ –º—ã –ø–æ–∫–∞–∂–µ–º –≤–∞–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–∏–µ–º–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –ø–æ–º–æ—á—å.

<Tip>

üí° –ï—Å–ª–∏ –≤—ã –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ —Ä—É—á–Ω–æ–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è, –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ –ø–∞–π–ø–ª–∞–π–Ω–∞ –æ–±—É—á–µ–Ω–∏—è –ø—Ä–∏–º–µ–Ω–∏–º—ã —Ç–µ –∂–µ —à–∞–≥–∏, –Ω–æ –∏—Ö –ø—Ä–æ—â–µ —Ä–∞–∑–¥–µ–ª–∏—Ç—å. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—ã –Ω–µ –∑–∞–±—ã–ª–∏ `model.eval()` –∏–ª–∏ `model.train()` –≤ –Ω—É–∂–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö, –∏–ª–∏ `zero_grad()` –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ!
</Tip>

## –û—Ç–ª–∞–¥–∫–∞ —Å–∫—Ä—ã—Ç—ã—Ö –æ—à–∏–±–æ–∫ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è[[debugging-silent-errors-during-training]]

–ß—Ç–æ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å, —á—Ç–æ–±—ã –æ—Ç–ª–∞–¥–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ –∑–∞–≤–µ—Ä—à–∞–µ—Ç—Å—è –±–µ–∑ –æ—à–∏–±–æ–∫, –Ω–æ –Ω–µ –¥–∞–µ—Ç —Ö–æ—Ä–æ—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤? –ú—ã –¥–∞–¥–∏–º –≤–∞–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–æ–≤–µ—Ç–æ–≤, –Ω–æ –∏–º–µ–π—Ç–µ –≤ –≤–∏–¥—É, —á—Ç–æ —Ç–∞–∫–∞—è –æ—Ç–ª–∞–¥–∫–∞ - —Å–∞–º–∞—è —Å–ª–æ–∂–Ω–∞—è —á–∞—Å—Ç—å –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –∏ –≤–æ–ª—à–µ–±–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ —ç—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.

### –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–≤–æ–∏ –¥–∞–Ω–Ω—ã–µ (–µ—â–µ —Ä–∞–∑!)[[check-your-data-again]]

–í–∞—à–∞ –º–æ–¥–µ–ª—å –Ω–∞—É—á–∏—Ç—Å—è —á–µ–º—É-—Ç–æ —Ç–æ–ª—å–∫–æ –≤ —Ç–æ–º —Å–ª—É—á–∞–µ, –µ—Å–ª–∏ –∏–∑ –≤–∞—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –º–æ–∂–Ω–æ —á–µ–º—É-—Ç–æ –Ω–∞—É—á–∏—Ç—å—Å—è. –ï—Å–ª–∏ –≤ –¥–∞–Ω–Ω—ã—Ö –µ—Å—Ç—å –æ—à–∏–±–∫–∞, –∫–æ—Ç–æ—Ä–∞—è –ø–æ—Ä—Ç–∏—Ç –∏—Ö, –∏–ª–∏ –º–µ—Ç–∫–∏ –ø—Ä–∏–ø–∏—Å–∞–Ω—ã —Å–ª—É—á–∞–π–Ω—ã–º –æ–±—Ä–∞–∑–æ–º, —Ç–æ, —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ, –≤—ã –Ω–µ —Å–º–æ–∂–µ—Ç–µ –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ —Å–≤–æ–µ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö. –ü–æ—ç—Ç–æ–º—É –≤—Å–µ–≥–¥–∞ –Ω–∞—á–∏–Ω–∞–π—Ç–µ —Å –ø–µ—Ä–µ–ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –º–µ—Ç–æ–∫ –∏ –∑–∞–¥–∞–≤–∞–π—Ç–µ —Å–µ–±–µ —Å–ª–µ–¥—É—é—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã:

- –ü–æ–Ω—è—Ç–Ω—ã –ª–∏ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ?
- –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ª–∏ –º–µ—Ç–∫–∏?
- –ï—Å—Ç—å –ª–∏ –æ–¥–Ω–∞ –º–µ—Ç–∫–∞, –∫–æ—Ç–æ—Ä–∞—è –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è —á–∞—â–µ –¥—Ä—É–≥–∏—Ö?
- –ö–∞–∫–∏–º –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å/–º–µ—Ç—Ä–∏–∫–∏ –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∞ —Å–ª—É—á–∞–π–Ω—ã–π –æ—Ç–≤–µ—Ç/–≤—Å–µ–≥–¥–∞ –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ –æ—Ç–≤–µ—Ç?

<Tip warning={true}>

‚ö†Ô∏è –ï—Å–ª–∏ –≤—ã –ø—Ä–æ–≤–æ–¥–∏—Ç–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ, —Ä–∞—Å–ø–µ—á–∞—Ç–∞–π—Ç–µ –æ–±—Ä–∞–∑—Ü—ã –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –≤ –∫–∞–∂–¥–æ–º –ø—Ä–æ—Ü–µ—Å—Å–µ –∏ —Ç—Ä–∏–∂–¥—ã –ø—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –≤—ã –ø–æ–ª—É—á–∞–µ—Ç–µ –æ–¥–Ω–æ –∏ —Ç–æ –∂–µ. –û–¥–Ω–∞ –∏–∑ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –æ—à–∏–±–æ–∫ - –Ω–∞–ª–∏—á–∏–µ –Ω–µ–∫–æ—Ç–æ—Ä–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ —Å–ª—É—á–∞–π–Ω–æ—Å—Ç–∏ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö, –∏–∑-–∑–∞ –∫–æ—Ç–æ—Ä–æ–≥–æ –∫–∞–∂–¥—ã–π –ø—Ä–æ—Ü–µ—Å—Å –∏–º–µ–µ—Ç —Å–≤–æ—é –≤–µ—Ä—Å–∏—é –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö.

</Tip>

–ü—Ä–æ—Å–º–æ—Ç—Ä–µ–≤ –¥–∞–Ω–Ω—ã–µ, –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –º–æ–¥–µ–ª–∏ –∏ –¥–µ–∫–æ–¥–∏—Ä—É–π—Ç–µ –∏—Ö. –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –ø–æ—Å—Ç–æ—è–Ω–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –æ–¥–Ω–æ –∏ —Ç–æ –∂–µ, —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–≤—è–∑–∞–Ω–æ —Å —Ç–µ–º, —á—Ç–æ –≤–∞—à –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —Å–º–µ—â–µ–Ω –≤ —Å—Ç–æ—Ä–æ–Ω—É –æ–¥–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (–¥–ª—è –ø—Ä–æ–±–ª–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏); –∑–¥–µ—Å—å –º–æ–≥—É—Ç –ø–æ–º–æ—á—å —Ç–∞–∫–∏–µ –º–µ—Ç–æ–¥—ã, –∫–∞–∫ oversampling —Ä–µ–¥–∫–∏—Ö –∫–ª–∞—Å—Å–æ–≤.

–ï—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å/–º–µ—Ç—Ä–∏–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã –ø–æ–ª—É—á–∞–µ—Ç–µ –Ω–∞ –Ω–∞—á–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏, —Å–∏–ª—å–Ω–æ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è –æ—Ç –∑–Ω–∞—á–µ–Ω–∏–π —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å/–º–µ—Ç—Ä–∏–∫, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–∂–Ω–æ –±—ã–ª–æ –±—ã –æ–∂–∏–¥–∞—Ç—å –¥–ª—è —Å–ª—É—á–∞–π–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π, –ø–µ—Ä–µ–ø—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–ø–æ—Å–æ–± –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –ø–æ—Ç–µ—Ä—å –∏–ª–∏ –º–µ—Ç—Ä–∏–∫, —Ç–∞–∫ –∫–∞–∫, –≤–æ–∑–º–æ–∂–Ω–æ, –≤ –Ω–∏—Ö –µ—Å—Ç—å –æ—à–∏–±–∫–∞. –ï—Å–ª–∏ –≤—ã –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ—É–Ω–∫—Ü–∏–π –ø–æ—Ç–µ—Ä—å, —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –æ–Ω–∏ –∏–º–µ—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π –º–∞—Å—à—Ç–∞–±.

–ö–æ–≥–¥–∞ –≤—ã —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤–∞—à–∏ –¥–∞–Ω–Ω—ã–µ –∏–¥–µ–∞–ª—å–Ω—ã, –≤—ã –º–æ–∂–µ—Ç–µ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, —Å–ø–æ—Å–æ–±–Ω–∞ –ª–∏ –º–æ–¥–µ–ª—å –æ–±—É—á–∞—Ç—å—Å—è –Ω–∞ –Ω–∏—Ö, —Å –ø–æ–º–æ—â—å—é –æ–¥–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç–æ–≥–æ —Ç–µ—Å—Ç–∞.

### –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –æ–¥–Ω–æ–º –±–∞—Ç—á–µ[[overfit-your-model-on-one-batch]]

–û–±—ã—á–Ω–æ –º—ã —Å—Ç–∞—Ä–∞–µ–º—Å—è –∏–∑–±–µ–≥–∞—Ç—å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –ø—Ä–∏ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–µ –º–æ–¥–µ–ª–∏, –ø–æ—Å–∫–æ–ª—å–∫—É —ç—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –º–æ–¥–µ–ª—å –Ω–µ —É—á–∏—Ç—Å—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç—å –æ–±—â–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏, –∞ –ø—Ä–æ—Å—Ç–æ –∑–∞–ø–æ–º–∏–Ω–∞–µ—Ç –æ–±—É—á–∞—é—â–∏–µ –≤—ã–±–æ—Ä–∫–∏. –û–¥–Ω–∞–∫–æ –ø–æ–ø—ã—Ç–∫–∞ –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ –æ–¥–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ —Å–Ω–æ–≤–∞ –∏ —Å–Ω–æ–≤–∞ - —ç—Ç–æ —Ö–æ—Ä–æ—à–∏–π —Ç–µ—Å—Ç, –ø–æ–∑–≤–æ–ª—è—é—â–∏–π –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, –º–æ–∂–µ—Ç –ª–∏ –ø—Ä–æ–±–ª–µ–º–∞ –≤ —Ç–æ–º –≤–∏–¥–µ, –≤ –∫–æ—Ç–æ—Ä–æ–º –≤—ã –µ–µ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–ª–∏, –±—ã—Ç—å —Ä–µ—à–µ–Ω–∞ —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–∏, –∫–æ—Ç–æ—Ä—É—é –≤—ã –ø—ã—Ç–∞–µ—Ç–µ—Å—å –æ–±—É—á–∏—Ç—å. –≠—Ç–æ —Ç–∞–∫–∂–µ –ø–æ–º–æ–∂–µ—Ç –≤–∞–º –ø–æ–Ω—è—Ç—å, –Ω–µ —Å–ª–∏—à–∫–æ–º –ª–∏ –≤—ã—Å–æ–∫–∞ –≤–∞—à–∞ –Ω–∞—á–∞–ª—å–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è.

–°–¥–µ–ª–∞—Ç—å —ç—Ç–æ –ø–æ—Å–ª–µ —Ç–æ–≥–æ, –∫–∞–∫ –≤—ã –æ–ø—Ä–µ–¥–µ–ª–∏–ª–∏ —Å–≤–æ–π `Trainer`, –æ—á–µ–Ω—å –ø—Ä–æ—Å—Ç–æ: –ø—Ä–æ—Å—Ç–æ –≤–æ–∑—å–º–∏—Ç–µ –±–∞—Ç—á –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö, –∞ –∑–∞—Ç–µ–º –∑–∞–ø—É—Å—Ç–∏—Ç–µ –Ω–µ–±–æ–ª—å—à–æ–π —Ü–∏–∫–ª —Ä—É—á–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –∏—Å–ø–æ–ª—å–∑—É—è —Ç–æ–ª—å–∫–æ —ç—Ç–æ—Ç –±–∞—Ç—á –≤ —Ç–µ—á–µ–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–Ω–æ 20 —à–∞–≥–æ–≤:

```py
for batch in trainer.get_train_dataloader():
    break

batch = {k: v.to(device) for k, v in batch.items()}
trainer.create_optimizer()

for _ in range(20):
    outputs = trainer.model(**batch)
    loss = outputs.loss
    loss.backward()
    trainer.optimizer.step()
    trainer.optimizer.zero_grad()
```

<Tip>

üí° –ï—Å–ª–∏ –≤–∞—à–∏ –æ–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω—ã, –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —Å–æ–∑–¥–∞–π—Ç–µ –±–∞—Ç—á –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –≤—Å–µ –º–µ—Ç–∫–∏.

</Tip>

–†–µ–∑—É–ª—å—Ç–∏—Ä—É—é—â–∞—è –º–æ–¥–µ–ª—å –¥–æ–ª–∂–Ω–∞ –∏–º–µ—Ç—å –±–ª–∏–∑–∫–∏–µ –∫ –∏–¥–µ–∞–ª—å–Ω—ã–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ –æ–¥–Ω–æ–º –∏ —Ç–æ–º –∂–µ –±–∞—Ç—á–µ. –í—ã—á–∏—Å–ª–∏–º –º–µ—Ç—Ä–∏–∫—É –ø–æ –ø–æ–ª—É—á–µ–Ω–Ω—ã–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º:

```py
with torch.no_grad():
    outputs = trainer.model(**batch)
preds = outputs.logits
labels = batch["labels"]

compute_metrics((preds.cpu().numpy(), labels.cpu().numpy()))
```

```python out
{'accuracy': 1.0}
```

–¢–æ—á–Ω–æ—Å—Ç—å 100 %, –≤–æ—Ç —ç—Ç–æ —Ö–æ—Ä–æ—à–∏–π –ø—Ä–∏–º–µ—Ä –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è (—ç—Ç–æ –∑–Ω–∞—á–∏—Ç, —á—Ç–æ –µ—Å–ª–∏ –≤—ã –ø–æ–ø—Ä–æ–±—É–µ—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ –ª—é–±–æ–º –¥—Ä—É–≥–æ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏, –æ–Ω–∞, —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ, –¥–∞—Å—Ç –≤–∞–º –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç)!

–ï—Å–ª–∏ –≤–∞–º –Ω–µ —É–¥–∞–µ—Ç—Å—è –¥–æ–±–∏—Ç—å—Å—è –æ—Ç –º–æ–¥–µ–ª–∏ —Ç–∞–∫–∏—Ö –∏–¥–µ–∞–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, –∑–Ω–∞—á–∏—Ç, —á—Ç–æ-—Ç–æ –Ω–µ —Ç–∞–∫ —Å –ø–æ—Å—Ç–∞–Ω–æ–≤–∫–æ–π –∑–∞–¥–∞—á–∏ –∏–ª–∏ –¥–∞–Ω–Ω—ã–º–∏, –∏ –≤–∞–º —Å–ª–µ–¥—É–µ—Ç —ç—Ç–æ –∏—Å–ø—Ä–∞–≤–∏—Ç—å. –¢–æ–ª—å–∫–æ –∫–æ–≥–¥–∞ –≤–∞–º —É–¥–∞—Å—Ç—Å—è –ø—Ä–æ–π—Ç–∏ —Ç–µ—Å—Ç –Ω–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ, –≤—ã —Å–º–æ–∂–µ—Ç–µ –±—ã—Ç—å —É–≤–µ—Ä–µ–Ω—ã, —á—Ç–æ –≤–∞—à–∞ –º–æ–¥–µ–ª—å –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Å–ø–æ—Å–æ–±–Ω–∞ —á–µ–º—É-—Ç–æ –Ω–∞—É—á–∏—Ç—å—Å—è.

<Tip warning={true}>

‚ö†Ô∏è –í–∞–º –ø—Ä–∏–¥–µ—Ç—Å—è –ø–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å –º–æ–¥–µ–ª—å –∏ `Trainer` –ø–æ—Å–ª–µ —ç—Ç–æ–≥–æ —Ç–µ—Å—Ç–∞ –Ω–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ, –ø–æ—Å–∫–æ–ª—å–∫—É –ø–æ–ª—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å, –≤–µ—Ä–æ—è—Ç–Ω–æ, –Ω–µ —Å–º–æ–∂–µ—Ç –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å—Å—è –∏ –Ω–∞—É—á–∏—Ç—å—Å—è —á–µ–º—É-—Ç–æ –ø–æ–ª–µ–∑–Ω–æ–º—É –Ω–∞ –ø–æ–ª–Ω–æ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö.

</Tip>

### –ù–µ –æ–±—É—á–∞–π—Ç–µ –Ω–∏—á–µ–≥–æ, –ø–æ–∫–∞ –Ω–µ –ø–æ–ª—É—á–∏—Ç–µ –ø–µ—Ä–≤—ã–π –±–µ–π–∑–ª–∞–π–Ω.[[dont-tune-anything-until-you-have-a-first-baseline]]

–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤—Å–µ–≥–¥–∞ —Å—á–∏—Ç–∞–µ—Ç—Å—è —Å–∞–º–æ–π —Å–ª–æ–∂–Ω–æ–π —á–∞—Å—Ç—å—é –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –Ω–æ —ç—Ç–æ –≤—Å–µ–≥–æ –ª–∏—à—å –ø–æ—Å–ª–µ–¥–Ω–∏–π —à–∞–≥, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–º–æ–∂–µ—Ç –≤–∞–º –Ω–µ–º–Ω–æ–≥–æ —É–ª—É—á—à–∏—Ç—å –º–µ—Ç—Ä–∏–∫—É. –í –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ —Å–ª—É—á–∞–µ–≤ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é `Trainer` –±—É–¥—É—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–æ—Ä–º–∞–ª—å–Ω–æ –∏ –¥–∞–≤–∞—Ç—å –≤–∞–º —Ö–æ—Ä–æ—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, –ø–æ—ç—Ç–æ–º—É –Ω–µ –ø—Ä–∏—Å—Ç—É–ø–∞–π—Ç–µ –∫ —Ç—Ä—É–¥–æ–µ–º–∫–æ–º—É –∏ –¥–æ—Ä–æ–≥–æ—Å—Ç–æ—è—â–µ–º—É –ø–æ–∏—Å–∫—É –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –ø–æ–∫–∞ —É –≤–∞—Å –Ω–µ –±—É–¥–µ—Ç —á–µ–≥–æ-—Ç–æ, —á—Ç–æ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç –±–∞–∑–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å, –∫–æ—Ç–æ—Ä—ã–π —É –≤–∞—Å –µ—Å—Ç—å –≤ –≤–∞—à–µ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö.

–ö–∞–∫ —Ç–æ–ª—å–∫–æ —É –≤–∞—Å –±—É–¥–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ö–æ—Ä–æ—à–∞—è –º–æ–¥–µ–ª—å, –≤—ã –º–æ–∂–µ—Ç–µ –Ω–∞—á–∞—Ç—å –µ–µ –Ω–µ–º–Ω–æ–≥–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å. –ù–µ –ø—ã—Ç–∞–π—Ç–µ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å —Ç—ã—Å—è—á—É —Ä–∞–∑ —Å —Ä–∞–∑–Ω—ã–º–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏, –Ω–æ —Å—Ä–∞–≤–Ω–∏—Ç–µ –ø–∞—Ä—É –∑–∞–ø—É—Å–∫–æ–≤ —Å —Ä–∞–∑–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –æ–¥–Ω–æ–≥–æ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –æ —Ç–æ–º, –∫–∞–∫–æ–π –∏–∑ –Ω–∏—Ö –æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞–∏–±–æ–ª—å—à–µ–µ –≤–ª–∏—è–Ω–∏–µ.

–ï—Å–ª–∏ –≤—ã –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç–µ —Å–∞–º—É –º–æ–¥–µ–ª—å, –±—É–¥—å—Ç–µ –ø—Ä–æ—â–µ –∏ –Ω–µ –ø—Ä–æ–±—É–π—Ç–µ —Ç–æ, —á—Ç–æ –Ω–µ –º–æ–∂–µ—Ç–µ –æ–±–æ—Å–Ω–æ–≤–∞—Ç—å. –í—Å–µ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–π—Ç–µ—Å—å –∫ —Ç–µ—Å—Ç—É –Ω–∞ –ø–µ—Ä–µ–±–æ—Ä, —á—Ç–æ–±—ã –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, –Ω–µ –ø—Ä–∏–≤–µ–ª–æ –ª–∏ –≤–∞—à–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –∫ –∫–∞–∫–∏–º-–ª–∏–±–æ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω—ã–º –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è–º.

### –ü–æ–ø—Ä–æ—Å–∏—Ç–µ –æ –ø–æ–º–æ—â–∏[[ask-for-help]]

–ù–∞–¥–µ–µ–º—Å—è, –≤—ã –Ω–∞—à–ª–∏ –≤ —ç—Ç–æ–º —Ä–∞–∑–¥–µ–ª–µ —Å–æ–≤–µ—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–º–æ–≥–ª–∏ –≤–∞–º —Ä–µ—à–∏—Ç—å –≤–∞—à—É –ø—Ä–æ–±–ª–µ–º—É, –Ω–æ –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ —Ç–∞–∫, –ø–æ–º–Ω–∏—Ç–µ, —á—Ç–æ –≤—ã –≤—Å–µ–≥–¥–∞ –º–æ–∂–µ—Ç–µ —Å–ø—Ä–æ—Å–∏—Ç—å —É —Å–æ–æ–±—â–µ—Å—Ç–≤–∞ –Ω–∞ [—Ñ–æ—Ä—É–º–∞—Ö](https://discuss.huggingface.co/).

–í–æ—Ç –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –æ–∫–∞–∑–∞—Ç—å—Å—è –ø–æ–ª–µ–∑–Ω—ã–º–∏:

- [" Reproducibility as a vehicle for engineering best practices"](https://docs.google.com/presentation/d/1yHLPvPhUs2KGI5ZWo0sU-PKU3GimAk3iTsI38Z-B5Gw/edit#slide=id.p) by Joel Grus
- ["Checklist for debugging neural networks"](https://towardsdatascience.com/checklist-for-debugging-neural-networks-d8b2a9434f21) by Cecelia Shao
- [" How to unit test machine learning code"](https://medium.com/@keeper6928/how-to-unit-test-machine-learning-code-57cf6fd81765) by Chase Roberts
- [""A Recipe for Training Neural Networks"](http://karpathy.github.io/2019/04/25/recipe/) by Andrej Karpathy

–ö–æ–Ω–µ—á–Ω–æ, –Ω–µ –≤—Å–µ –ø—Ä–æ–±–ª–µ–º—ã, —Å –∫–æ—Ç–æ—Ä—ã–º–∏ –≤—ã —Å—Ç–∞–ª–∫–∏–≤–∞–µ—Ç–µ—Å—å –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π, –≤–æ–∑–Ω–∏–∫–∞—é—Ç –ø–æ –≤–∞—à–µ–π –≤–∏–Ω–µ! –ï—Å–ª–∏ –≤ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ ü§ó Transformers –∏–ª–∏ ü§ó Datasets –≤—ã —Å—Ç–æ–ª–∫–Ω—É–ª–∏—Å—å —Å —á–µ–º-—Ç–æ, —á—Ç–æ –∫–∞–∂–µ—Ç—Å—è –≤–∞–º –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–º, –≤–æ–∑–º–æ–∂–Ω–æ, –≤—ã –æ–±–Ω–∞—Ä—É–∂–∏–ª–∏ –æ—à–∏–±–∫—É. –í–∞–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –Ω—É–∂–Ω–æ —Ä–∞—Å—Å–∫–∞–∑–∞—Ç—å –Ω–∞–º –æ–± —ç—Ç–æ–º, –∏ –≤ —Å–ª–µ–¥—É—é—â–µ–º —Ä–∞–∑–¥–µ–ª–µ –º—ã –æ–±—ä—è—Å–Ω–∏–º, –∫–∞–∫ –∏–º–µ–Ω–Ω–æ —ç—Ç–æ —Å–¥–µ–ª–∞—Ç—å.
