# Crea tu propio dataset

<CourseFloatingBanner chapter={5}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter5/section5.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter5/section5.ipynb"},
]} />

Algunas veces el dataset que necesitas para crear una aplicaci√≥n de procesamiento de lenguaje natural no existe, as√≠ que necesitas crearla. En esta secci√≥n vamos a mostrarte c√≥mo crear un corpus de [issues de GitHub](https://github.com/features/issues/), que se usan com√∫nmente para rastrear bugs o features en repositorios de GitHub. Este corpus podr√≠a ser usado para varios prop√≥sitos como:

* Explorar qu√© tanto se demora el cierre un issue abierto o un pull request
* Entrenar un _clasificador de etiquetas m√∫ltiples_ que pueda etiquetar issues con metadados basado en la descripci√≥n del issue (e.g., "bug", "mejora" o "pregunta")
* Crear un motor de b√∫squeda sem√°ntica para encontrar qu√© issues coinciden con la pregunta del usuario

En esta secci√≥n nos vamos a enfocar en la creaci√≥n del corpus y en la siguiente vamos a abordar la aplicaci√≥n de b√∫squeda sem√°ntica. Para que esto sea un meta-proyecto, vamos a usar los issues de Github asociados con un proyecto popular de c√≥digo abierto: ü§ó Datasets! Veamos c√≥mo obtener los datos y explorar la informaci√≥n contenida en estos issues.

## Obteniendo los datos

Puedes encontrar todos los issues de ü§ó Datasets yendo a la [pesta√±a de issues](https://github.com/huggingface/datasets/issues) del repositorio. Como se puede ver en la siguiente captura de pantalla, al momento de escribir esta secci√≥n hab√≠an 331 issues abiertos y 668 cerrados.

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter5/datasets-issues.png" alt="The GitHub issues associated with ü§ó Datasets." width="80%"/>
</div>

Si haces clic en alguno de estos issues te encontrar√°s con que incluyen un t√≠tulo, una descripci√≥n y un conjunto de etiquetas que lo caracterizan. Un ejemplo de esto se muestra en la siguiente captura de pantalla.

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter5/datasets-issues-single.png" alt="A typical GitHub issue in the ü§ó Datasets repository." width="80%"/>
</div>

Para descargar todos los issues del repositorio, usaremos el [API REST de GitHub](https://docs.github.com/en/rest) para obtener el [endpoint `Issues`](https://docs.github.com/en/rest/reference/issues#list-repository-issues). Este endpoint devuelve una lista de objetos JSON, en la que cada objeto contiene un gran n√∫mero de campos que incluyen el t√≠tulo y la descripci√≥n, as√≠ como metadatos sobre el estado del issue, entre otros.

Una forma conveniente de descargar los issues es a trav√©s de la librer√≠a `requests`, que es la manera est√°ndar para hacer pedidos HTTP en Python. Puedes instalar esta librer√≠a instalando:

```python
!pip install requests
```

Una vez la librer√≠a est√° instalada, puedes hacer pedidos GET al endpoint `Issues` ejecutando la funci√≥n `requests.get()`. Por ejemplo, puedes correr el siguiente comando para obtener el primer issue de la primera p√°gina:

```py
import requests

url = "https://api.github.com/repos/huggingface/datasets/issues?page=1&per_page=1"
response = requests.get(url)
```

El objeto `response` contiene una gran cantidad de informaci√≥n √∫til sobre el pedido, incluyendo el c√≥digo de status de HTTP:

```py
response.status_code
```

```python out
200
```

en el que un c√≥digo de `200` significa que el pedido fue exitoso (puedes ver una lista de posibles c√≥digos de status de HTTP [aqu√≠](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)). No obstante, en lo que estamos interesados realmente es el _payload_, que se puede acceder en varios formatos como bytes, strings o JSON. Como ya sabemos que los issues est√°n en formato JSON, inspeccionemos el _payload_ de la siguiente manera:

```py
response.json()
```

```python out
[{'url': 'https://api.github.com/repos/huggingface/datasets/issues/2792',
  'repository_url': 'https://api.github.com/repos/huggingface/datasets',
  'labels_url': 'https://api.github.com/repos/huggingface/datasets/issues/2792/labels{/name}',
  'comments_url': 'https://api.github.com/repos/huggingface/datasets/issues/2792/comments',
  'events_url': 'https://api.github.com/repos/huggingface/datasets/issues/2792/events',
  'html_url': 'https://github.com/huggingface/datasets/pull/2792',
  'id': 968650274,
  'node_id': 'MDExOlB1bGxSZXF1ZXN0NzEwNzUyMjc0',
  'number': 2792,
  'title': 'Update GooAQ',
  'user': {'login': 'bhavitvyamalik',
   'id': 19718818,
   'node_id': 'MDQ6VXNlcjE5NzE4ODE4',
   'avatar_url': 'https://avatars.githubusercontent.com/u/19718818?v=4',
   'gravatar_id': '',
   'url': 'https://api.github.com/users/bhavitvyamalik',
   'html_url': 'https://github.com/bhavitvyamalik',
   'followers_url': 'https://api.github.com/users/bhavitvyamalik/followers',
   'following_url': 'https://api.github.com/users/bhavitvyamalik/following{/other_user}',
   'gists_url': 'https://api.github.com/users/bhavitvyamalik/gists{/gist_id}',
   'starred_url': 'https://api.github.com/users/bhavitvyamalik/starred{/owner}{/repo}',
   'subscriptions_url': 'https://api.github.com/users/bhavitvyamalik/subscriptions',
   'organizations_url': 'https://api.github.com/users/bhavitvyamalik/orgs',
   'repos_url': 'https://api.github.com/users/bhavitvyamalik/repos',
   'events_url': 'https://api.github.com/users/bhavitvyamalik/events{/privacy}',
   'received_events_url': 'https://api.github.com/users/bhavitvyamalik/received_events',
   'type': 'User',
   'site_admin': False},
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2021-08-12T11:40:18Z',
  'updated_at': '2021-08-12T12:31:17Z',
  'closed_at': None,
  'author_association': 'CONTRIBUTOR',
  'active_lock_reason': None,
  'pull_request': {'url': 'https://api.github.com/repos/huggingface/datasets/pulls/2792',
   'html_url': 'https://github.com/huggingface/datasets/pull/2792',
   'diff_url': 'https://github.com/huggingface/datasets/pull/2792.diff',
   'patch_url': 'https://github.com/huggingface/datasets/pull/2792.patch'},
  'body': '[GooAQ](https://github.com/allenai/gooaq) dataset was recently updated after splits were added for the same. This PR contains new updated GooAQ with train/val/test splits and updated README as well.',
  'performed_via_github_app': None}]
```

Wow, ¬°es mucha informaci√≥n! Podemos ver campos √∫tiles como `title`, `body` y `number`, que describen el issue, as√≠ como informaci√≥n del usuario de GitHub que lo abri√≥.

<Tip>

‚úèÔ∏è **¬°Int√©ntalo!** Haz clic en algunas de las URL en el _payload_ JSON de arriba para explorar la informaci√≥n que est√° enlazada al issue de GitHub.

</Tip>

Tal como se describe en la [documentaci√≥n](https://docs.github.com/en/rest/overview/resources-in-the-rest-api#rate-limiting) de GitHub, los pedidos sin autenticaci√≥n est√°n limitados a 60 por hora. Si bien puedes incrementar el par√°metro de b√∫squeda `per_page` para reducir el n√∫mero de pedidos que haces, igual puedes alcanzar el l√≠mite de pedidos en cualquier repositorio que tenga m√°s que un par de miles de issues. En vez de hacer eso, puedes seguir las [instrucciones](https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token) de GitHub para crear un _token de acceso personal_ y que puedas incrementar el l√≠mite de pedidos a 5.000 por hora. Una vez tengas tu token, puedes incluirlo como parte del encabezado del pedido:

```py
GITHUB_TOKEN = xxx  # Copy your GitHub token here
headers = {"Authorization": f"token {GITHUB_TOKEN}"}
```

<Tip warning={true}>

‚ö†Ô∏è No compartas un cuaderno que contenga tu `GITHUB_TOKEN`. Te recomendamos eliminar la √∫ltima celda una vez la has ejecutado para evitar filtrar accidentalmente esta informaci√≥n. A√∫n mejor, guarda el token en un archivo *.env* y usa la librer√≠a [`python-dotenv`](https://github.com/theskumar/python-dotenv) para cargarla autom√°ticamente como una variable de ambiente.

</Tip>

Ahora que tenemos nuestro token de acceso, creemos una funci√≥n que descargue todos los issues de un repositorio de GitHub:

```py
import time
import math
from pathlib import Path
import pandas as pd
from tqdm.notebook import tqdm


def fetch_issues(
    owner="huggingface",
    repo="datasets",
    num_issues=10_000,
    rate_limit=5_000,
    issues_path=Path("."),
):
    if not issues_path.is_dir():
        issues_path.mkdir(exist_ok=True)

    batch = []
    all_issues = []
    per_page = 100  # N√∫mero de issues por p√°gina
    num_pages = math.ceil(num_issues / per_page)
    base_url = "https://api.github.com/repos"

    for page in tqdm(range(num_pages)):
        # Query con state=all para obtener tanto issues abiertos como cerrados
        query = f"issues?page={page}&per_page={per_page}&state=all"
        issues = requests.get(f"{base_url}/{owner}/{repo}/{query}", headers=headers)
        batch.extend(issues.json())

        if len(batch) > rate_limit and len(all_issues) < num_issues:
            all_issues.extend(batch)
            batch = []  # Vac√≠a el batch para el siguiente periodo de tiempo
            print(f"Reached GitHub rate limit. Sleeping for one hour ...")
            time.sleep(60 * 60 + 1)

    all_issues.extend(batch)
    df = pd.DataFrame.from_records(all_issues)
    df.to_json(f"{issues_path}/{repo}-issues.jsonl", orient="records", lines=True)
    print(
        f"Downloaded all the issues for {repo}! Dataset stored at {issues_path}/{repo}-issues.jsonl"
    )
```

Cuando ejecutemos `fetch_issues()`, se descargar√°n todos los issues en lotes para evitar exceder el l√≠mite de GitHub sobre el n√∫mero de pedidos por hora. El resultado se guardar√° en un archivo _repository_name-issues.jsonl_, donde cada l√≠nea es un objeto JSON que representa un issue. Usemos esta funci√≥n para cargar todos los issues de ü§ó Datasets:

```py
# Dependiendo de tu conexi√≥n a internet, esto puede tomar varios minutos para ejecutarse...
fetch_issues()
```

Una vez los issues est√©n descargados, los podemos cargar localmente usando las habilidades aprendidas en la [secci√≥n 2](/course/chaper5/2):

```py
issues_dataset = load_dataset("json", data_files="datasets-issues.jsonl", split="train")
issues_dataset
```

```python out
Dataset({
    features: ['url', 'repository_url', 'labels_url', 'comments_url', 'events_url', 'html_url', 'id', 'node_id', 'number', 'title', 'user', 'labels', 'state', 'locked', 'assignee', 'assignees', 'milestone', 'comments', 'created_at', 'updated_at', 'closed_at', 'author_association', 'active_lock_reason', 'pull_request', 'body', 'timeline_url', 'performed_via_github_app'],
    num_rows: 3019
})
```

¬°Genial! Hemos creado nuestro primer dataset desde cero. Pero, ¬øpor qu√© hay varios miles de issues cuando la [pesta√±a de Issues](https://github.com/huggingface/datasets/issues) del repositorio de ü§ó Datasets s√≥lo muestra alrededor de 1.000 en total? Como se describe en la [documentaci√≥n](https://docs.github.com/en/rest/reference/issues#list-issues-assigned-to-the-authenticated-user), esto sucede porque tambi√©n descargamos todos los pull requests:

> GitHub's REST API v3 considers every pull request an issue, but not every issue is a pull request. For this reason, "Issues" endpoints may return both issues and pull requests in the response. You can identify pull requests by the `pull_request` key. Be aware that the `id` of a pull request returned from "Issues" endpoints will be an issue id.

Como el contenido de los issues y pull requests son diferentes, hagamos un preprocesamiento simple para distinguirlos entre s√≠.

## Limpiando los datos

El fragmento anterior de la documentaci√≥n de GitHub nos dice que la columna `pull_request` puede usarse para diferenciar los issues de los pull requests. Veamos una muestra aleatoria para ver la diferencia. Como hicimos en la [secci√≥n 3](/course/chapter5/3), vamos a encadenar `Dataset.shuffle()` y `Dataset.select()` para crear una muestra aleatoria y luego unir las columnas de `html_url` y `pull_request` para comparar las distintas URL:

```py
sample = issues_dataset.shuffle(seed=666).select(range(3))

# Imprime la URL y las entradas de pull_request
for url, pr in zip(sample["html_url"], sample["pull_request"]):
    print(f">> URL: {url}")
    print(f">> Pull request: {pr}\n")
```

```python out
>> URL: https://github.com/huggingface/datasets/pull/850
>> Pull request: {'url': 'https://api.github.com/repos/huggingface/datasets/pulls/850', 'html_url': 'https://github.com/huggingface/datasets/pull/850', 'diff_url': 'https://github.com/huggingface/datasets/pull/850.diff', 'patch_url': 'https://github.com/huggingface/datasets/pull/850.patch'}

>> URL: https://github.com/huggingface/datasets/issues/2773
>> Pull request: None

>> URL: https://github.com/huggingface/datasets/pull/783
>> Pull request: {'url': 'https://api.github.com/repos/huggingface/datasets/pulls/783', 'html_url': 'https://github.com/huggingface/datasets/pull/783', 'diff_url': 'https://github.com/huggingface/datasets/pull/783.diff', 'patch_url': 'https://github.com/huggingface/datasets/pull/783.patch'}
```

Podemos ver que cada pull request est√° asociado con varias URL, mientras que los issues ordinarios tienen una entrada `None`. Podemos usar esta distinci√≥n para crear una nueva columna `is_pull_request` que revisa si el campo `pull_request` es `None` o no:

```py
issues_dataset = issues_dataset.map(
    lambda x: {"is_pull_request": False if x["pull_request"] is None else True}
)
```

<Tip>

‚úèÔ∏è **¬°Int√©ntalo!** Calcula el tiempo promedio que toma cerrar issues en ü§ó Datasets. La funci√≥n `Dataset.filter()` te ser√° √∫til para filtrar los pull requests y los issues abiertos, y puedes usar la funci√≥n `Dataset.set_format()` para convertir el dataset a un `DataFrame` para poder manipular f√°cilmente los timestamps de `created_at` y `closed_at`. Para puntos extra, calcula el tiempo promedio que toma cerrar pull requests.

</Tip>

Si bien podemos limpiar a√∫n m√°s el dataset eliminando o renombrando algunas columnas, es una buena pr√°ctica mantener un dataset lo m√°s parecido al original en esta etapa, para que se pueda usar f√°cilmente en varias aplicaciones.

Antes de subir el dataset el Hub de Hugging Face, nos hace falta a√±adirle algo m√°s: los comentarios asociados con cada issue y pull request. Los vamos a a√±adir con el API REST de GitHub.

## Ampliando el dataset

Como se muestra en la siguiente captura de pantalla, los comentarios asociados con un issue o un pull request son una fuente rica de informaci√≥n, especialmente si estamos interesados en construir un motor de b√∫squeda para responder preguntas de usuarios sobre la librer√≠a.

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter5/datasets-issues-comment.png" alt="Comments associated with an issue about ü§ó Datasets." width="80%"/>
</div>

El API REST de GitHub tiene un [endpoint `Comments`](https://docs.github.com/en/rest/reference/issues#list-issue-comments) que devuelve todos los comentarios asociados con un n√∫mero de issue. Prob√©mos este endpoint para ver qu√© devuelve:

```py
issue_number = 2792
url = f"https://api.github.com/repos/huggingface/datasets/issues/{issue_number}/comments"
response = requests.get(url, headers=headers)
response.json()
```

```python out
[{'url': 'https://api.github.com/repos/huggingface/datasets/issues/comments/897594128',
  'html_url': 'https://github.com/huggingface/datasets/pull/2792#issuecomment-897594128',
  'issue_url': 'https://api.github.com/repos/huggingface/datasets/issues/2792',
  'id': 897594128,
  'node_id': 'IC_kwDODunzps41gDMQ',
  'user': {'login': 'bhavitvyamalik',
   'id': 19718818,
   'node_id': 'MDQ6VXNlcjE5NzE4ODE4',
   'avatar_url': 'https://avatars.githubusercontent.com/u/19718818?v=4',
   'gravatar_id': '',
   'url': 'https://api.github.com/users/bhavitvyamalik',
   'html_url': 'https://github.com/bhavitvyamalik',
   'followers_url': 'https://api.github.com/users/bhavitvyamalik/followers',
   'following_url': 'https://api.github.com/users/bhavitvyamalik/following{/other_user}',
   'gists_url': 'https://api.github.com/users/bhavitvyamalik/gists{/gist_id}',
   'starred_url': 'https://api.github.com/users/bhavitvyamalik/starred{/owner}{/repo}',
   'subscriptions_url': 'https://api.github.com/users/bhavitvyamalik/subscriptions',
   'organizations_url': 'https://api.github.com/users/bhavitvyamalik/orgs',
   'repos_url': 'https://api.github.com/users/bhavitvyamalik/repos',
   'events_url': 'https://api.github.com/users/bhavitvyamalik/events{/privacy}',
   'received_events_url': 'https://api.github.com/users/bhavitvyamalik/received_events',
   'type': 'User',
   'site_admin': False},
  'created_at': '2021-08-12T12:21:52Z',
  'updated_at': '2021-08-12T12:31:17Z',
  'author_association': 'CONTRIBUTOR',
  'body': "@albertvillanova my tests are failing here:\r\n```\r\ndataset_name = 'gooaq'\r\n\r\n    def test_load_dataset(self, dataset_name):\r\n        configs = self.dataset_tester.load_all_configs(dataset_name, is_local=True)[:1]\r\n>       self.dataset_tester.check_load_dataset(dataset_name, configs, is_local=True, use_local_dummy_data=True)\r\n\r\ntests/test_dataset_common.py:234: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\ntests/test_dataset_common.py:187: in check_load_dataset\r\n    self.parent.assertTrue(len(dataset[split]) > 0)\r\nE   AssertionError: False is not true\r\n```\r\nWhen I try loading dataset on local machine it works fine. Any suggestions on how can I avoid this error?",
  'performed_via_github_app': None}]
```

Podemos ver que el comentario est√° almacenado en el campo `body`, as√≠ que escribamos una funci√≥n simple que devuelva todos los comentarios asociados con un issue al extraer el contenido de `body` para cada elemento en el `response.json()`:

```py
def get_comments(issue_number):
    url = f"https://api.github.com/repos/huggingface/datasets/issues/{issue_number}/comments"
    response = requests.get(url, headers=headers)
    return [r["body"] for r in response.json()]


# Revisar que el comportamiento de nuestra funci√≥n es el esperado
get_comments(2792)
```

```python out
["@albertvillanova my tests are failing here:\r\n```\r\ndataset_name = 'gooaq'\r\n\r\n    def test_load_dataset(self, dataset_name):\r\n        configs = self.dataset_tester.load_all_configs(dataset_name, is_local=True)[:1]\r\n>       self.dataset_tester.check_load_dataset(dataset_name, configs, is_local=True, use_local_dummy_data=True)\r\n\r\ntests/test_dataset_common.py:234: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\ntests/test_dataset_common.py:187: in check_load_dataset\r\n    self.parent.assertTrue(len(dataset[split]) > 0)\r\nE   AssertionError: False is not true\r\n```\r\nWhen I try loading dataset on local machine it works fine. Any suggestions on how can I avoid this error?"]
```

Esto luce bien, as√≠ que usemos `Dataset.map()` para a√±adir una nueva columna `comments` a cada issue en el dataset:

```py
# Dependiendo de tu conexi√≥n a internet, esto puede tomar varios minutos...
issues_with_comments_dataset = issues_dataset.map(
    lambda x: {"comments": get_comments(x["number"])}
)
```

El √∫ltimo paso es guardar el dataset ampliado en el mismo lugar que los datos originales para poderlos subir al Hub:

```py
issues_with_comments_dataset.to_json("issues-datasets-with-comments.jsonl")
```

## Subiendo un dataset al Hub de Hugging Face

<Youtube id="HaN6qCr_Afc"/>

Ahora que tenemos nuestro dataset ampliado, es momento de subirlo al Hub para poder compartirlo con la comunidad. Para subir el dataset tenemos que usar la [librer√≠a ü§ó Hub](https://github.com/huggingface/huggingface_hub), que nos permite interactuar con el Hub de Hugging Face usando una API de Python. ü§ó Hub viene instalada con ü§ó Transformers, as√≠ que podemos usarla directamente. Por ejemplo, podemos usar la funci√≥n `list_datasets()` para obtener informaci√≥n sobre todos los datasets p√∫blicos que est√°n almacenados en el Hub:

```py
from huggingface_hub import list_datasets

all_datasets = list_datasets()
print(f"Number of datasets on Hub: {len(all_datasets)}")
print(all_datasets[0])
```

```python out
Number of datasets on Hub: 1487
Dataset Name: acronym_identification, Tags: ['annotations_creators:expert-generated', 'language_creators:found', 'languages:en', 'licenses:mit', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:structure-prediction', 'task_ids:structure-prediction-other-acronym-identification']
```
Podemos ver que hay alrededor de 1.500 datasets en el Hub y que la funci√≥n `list_datasets()` tambi√©n provee algunos metadatos sobre el repositorio de cada uno.

Para lo que queremos hacer, lo primero que necesitamos es crear un nuevo repositorio de dataset en el Hub. Para ello, necesitamos un token de autenticaci√≥n, que se obtiene al acceder al Hub de Hugging Face con la funci√≥n `notebook_login()`:

```py
from huggingface_hub import notebook_login

notebook_login()
```

Esto crea un widget en el que ingresas tu nombre de usuario y contrase√±a, y guarda un token API en *~/.huggingface/token*. Si est√°s ejecutando el c√≥digo en la terminal, puedes acceder a trav√©s de la l√≠nea de comandos as√≠:

```bash
huggingface-cli login
```

Una vez hecho esto, podemos crear un nuevo repositorio para el dataset con la funci√≥n `create_repo()`:

```py
from huggingface_hub import create_repo

repo_url = create_repo(name="github-issues", repo_type="dataset")
repo_url
```

```python out
'https://huggingface.co/datasets/lewtun/github-issues'
```

En este ejemplo, hemos creado un repositorio vac√≠o para el dataset llamado `github-issues` bajo el nombre de usuario `lewtun` (¬°el nombre de usuario deber√≠a ser tu nombre de usuario del Hub cuando est√©s ejecutando este c√≥digo!).

<Tip>

‚úèÔ∏è **¬°Int√©ntalo!** Usa tu nombre de usuario de Hugging Face Hub para obtener un token y crear un repositorio vac√≠o llamado `girhub-issues`. Recuerda **nunca guardar tus credenciales** en Colab o cualquier otro repositorio, ya que esta informaci√≥n puede ser aprovechada por terceros.

</Tip>

Ahora clonemos el repositorio del Hub a nuestra m√°quina local y copiemos nuestro dataset ah√≠. ü§ó Hub incluye una clase `Repositorio` que envuelve muchos de los comandos comunes de Git, as√≠ que para clonar el repositorio remoto solamente necesitamos dar la URL y la ruta local en la que lo queremos clonar:

```py
from huggingface_hub import Repository

repo = Repository(local_dir="github-issues", clone_from=repo_url)
!cp issues-datasets-with-comments.jsonl github-issues/
```

Por defecto, varias extensiones de archivo (como *.bin*, *.gz*, and *.zip*) se siguen con Git LFS de tal manera que los archivos grandes se pueden versionar dentro del mismo flujo de trabajo de Git. Puedes encontrar una lista de extensiones que se van a seguir en el archivo *.gitattributes*. Para incluir el formato JSON Lines en la lista, puedes ejecutar el siguiente comando:

```py
repo.lfs_track("*.jsonl")
```

Luego, podemos usar `$$Repository.push_to_hub()` para subir el dataset al Hub:

```py
repo.push_to_hub()
```

Si navegamos a la URL que aparece en `repo_url`, deber√≠amos ver que el archivo del dataset se ha subido.

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter5/hub-repo.png" alt="Our dataset repository on the Hugging Face Hub." width="80%"/>
</div>

Desde aqui, cualquier persona podr√° descargar el dataset incluyendo el ID del repositorio en el argumento `path` de la funci√≥n `load_dataset()`:

```py
remote_dataset = load_dataset("lewtun/github-issues", split="train")
remote_dataset
```

```python out
Dataset({
    features: ['url', 'repository_url', 'labels_url', 'comments_url', 'events_url', 'html_url', 'id', 'node_id', 'number', 'title', 'user', 'labels', 'state', 'locked', 'assignee', 'assignees', 'milestone', 'comments', 'created_at', 'updated_at', 'closed_at', 'author_association', 'active_lock_reason', 'pull_request', 'body', 'performed_via_github_app', 'is_pull_request'],
    num_rows: 2855
})
```

¬°Genial, hemos subido el dataset al Hub y ya est√° disponible para que otras personas lo usen! S√≥lo hay una cosa restante por hacer: a√±adir una _tarjeta del dataset_ (_dataset card_) que explique c√≥mo se cre√≥ el corpus y provea informaci√≥n √∫til para la comunidad.

<Tip>

üí° Tambi√©n puedes subir un dataset al Hub de Hugging Face directamente desde la terminal usando `huggingface-cli` y un poco de Git. Revisa la [gu√≠a de ü§ó Datasets](https://huggingface.co/docs/datasets/share.html#add-a-community-dataset) para m√°s detalles sobre c√≥mo hacerlo.

</Tip>

## Creando una tarjeta del dataset

Los datasets bien documentados tienen m√°s probabilidades de ser √∫tiles para otros (incluy√©ndote a ti en el futuro), dado que brindan la informaci√≥n necesaria para que los usuarios decidan si el dataset es √∫til para su tarea, as√≠ como para evaluar cualquier sesgo o riesgo potencial asociado a su uso.

En el Hub de Hugging Face, esta informaci√≥n se almacena en el archivo *README.md* del repositorio del dataset. Hay dos pasos que deber√≠as hacer antes de crear este archivo:

1. Usa la [aplicaci√≥n `datasets-tagging`](https://huggingface.co/datasets/tagging/) para crear etiquetas de metadatos en el formato YAML. Estas etiquetas se usan para una variedad de funciones de b√∫squeda en el Hub de Hugging Face y aseguran que otros miembros de la comunidad puedan encontrar tu dataset. Dado que creamos un dataset personalizado en esta secci√≥n, tendremos que clonar el repositorio `datasets-tagging` y correr la aplicaci√≥n localmente. As√≠ se ve la interfaz de la aplicaci√≥n:

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter5/datasets-tagger.png" alt="The `datasets-tagging` interface." width="80%"/>
</div>

2. Lee la [gu√≠a de ü§ó Datasets](https://github.com/huggingface/datasets/blob/master/templates/README_guide.md) sobre c√≥mo crear tarjetas informativas y usarlas como plantilla.

Puedes crear el archivo *README.md* drectamente desde el Hub y puedes encontrar una plantilla de tarjeta en el repositorio `lewtun/github-issues`. As√≠ se ve una tarjeta de dataset diligenciada:

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter5/dataset-card.png" alt="A dataset card." width="80%"/>
</div>

<Tip>

‚úèÔ∏è **¬°Int√©ntalo!** Usa la aplicaci√≥n `dataset-tagging` y la [gu√≠a de ü§ó Datasets](https://github.com/huggingface/datasets/blob/master/templates/README_guide.md) para completar el archivo *README.md* para tu dataset de issues de GitHub.

</Tip>

¬°Eso es todo! Hemos visto que crear un buen dataset requiere de mucho esfuerzo de tu parte, pero afortunadamente subirlo y compartirlo con la comunidad no. En la siguiente secci√≥n usaremos nuestro nuevo dataset para crear un motor de b√∫squeda sem√°ntica con ü§ó Datasets que pueda emparejar pregunras con los issues y comentarios m√°s relevantes.

<Tip>

‚úèÔ∏è **¬°Int√©ntalo!** Sigue los pasos descritos en esta secci√≥n para crear un dataset de issues de GitHub de tu librer√≠a de c√≥digo abierto favorita (¬°por supuesto, escoge algo distinto a ü§ó Datasets!). Para puntos extra, ajusta un clasificador de etiquetas m√∫ltiples para predecir las etiquetas presentes en el campo `labels`.

</Tip>
