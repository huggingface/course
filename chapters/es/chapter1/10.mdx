<!-- DISABLE-FRONTMATTER-SECTIONS -->

# Quiz de final de capÃ­tulo

<CourseFloatingBanner
    chapter={1}
    classNames="absolute z-10 right-0 top-0"
/>

Â¡Este capÃ­tulo cubriÃ³ una gran variedad de temas! No te preocupes si no entendiste todos los detalles; los siguientes capÃ­tulos te ayudarÃ¡n a entender cÃ³mo funcionan las cosas detrÃ¡s de cÃ¡maras.

Por ahora, Â¡revisemos lo que aprendiste en este capÃ­tulo!

### 1. Explora el Hub y busca el punto de control `roberta-large-mnli`. Â¿QuÃ© tarea desarrolla?

<Question
	choices={[
		{
			text: "Resumen",
			explain: "Vuelve a mirar en la <a href=\"https://huggingface.co/roberta-large-mnli\">pÃ¡gina de roberta-large-mnli</a>."
		},
		{
			text: "ClasificaciÃ³n de texto",
			explain: " MÃ¡s precisamente, clasifica si dos oraciones estÃ¡n relacionadas lÃ³gicamente a travÃ©s de tres etiquetas (contradiction, neutral, entailment) - una tarea que tambiÃ©n se conoce como <em>inferencia de lenguaje natural</em>.", 
			correct: true
		},
		{
			text: "GeneraciÃ³n de texto",
			explain: "Vuelve a mirar en la <a href=\"https://huggingface.co/roberta-large-mnli\">pÃ¡gina de roberta-large-mnli</a>."
		}
	]}
/>

### 2. Â¿QuÃ© devuelve el siguiente cÃ³digo?

```py
from transformers import pipeline

ner = pipeline("ner", grouped_entities=True)
ner("My name is Sylvain and I work at Hugging Face in Brooklyn.")
```

<Question
	choices={[
		{
			text: "Devuelve los puntajes de clasificaciÃ³n de esta oraciÃ³n, con las etiquetas \"positive\" o \"negative\".",
			explain: "Incorrecto - esto serÃ­a un pipeline de <code>sentiment-analysis</code>."
		},
		{
			text: "Devuelve un texto generado que completa esta oraciÃ³n.",
			explain: "Incorrecto - esto serÃ­a un pipeline de <code>text-generation</code>."
		},
		{
			text: "Devuelve las palabras que representan personas, organizaciones o ubicaciones.",
			explain: "Adicionalmente, con <code>grouped_entities=True</code>, agruparÃ¡ las palabras que pertenecen a la misma entidad, como \"Hugging Face\".",
			correct: true
		}
	]}
/>

### 3. Â¿QuÃ© deberÃ­a reemplazar ... en este ejemplo de cÃ³digo?

```py
from transformers import pipeline

filler = pipeline("fill-mask", model="bert-base-cased")
result = filler("...")
```

<Question
	choices={[
		{
			text: "This &#60;mask> has been waiting for you.",
			explain: "Incorrecto. Revisa la ficha del modelo <code>bert-base-cased</code> e intenta identificar tu error."
		},
		{
			text: "This [MASK] has been waiting for you.",
			explain: "Â¡Correcto! El mask token de este modelo es [MASK].",
			correct: true
		},
		{
			text: "This man has been waiting for you.",
			explain: "Incorrecto. Esrte pipeline llena palabras ocultas, por lo que necesita un mask token en algÃºn lugar."
		}
	]}
/>

### 4. Â¿Por quÃ© fallarÃ¡ este cÃ³digo?

```py
from transformers import pipeline

classifier = pipeline("zero-shot-classification")
result = classifier("This is a course about the Transformers library")
```

<Question
	choices={[
		{
			text: "Este pipeline necesita que se le indiquen etiquetas para clasificar el texto.",
			explain: "Correcto â€” el cÃ³digo necesita incluir <code>candidate_labels=[...]</code>.",
			correct: true
		},
		{
			text: "Este pipeline requiere varias oraciones, no sÃ³lo una.",
			explain: "Incorrecto, aunque cuando se usa adecuadamente, este pipeline puede tomar una lista de oraciones para procesar (como todos los otros pipelines)."
		},
		{
			text: "La librerÃ­a ğŸ¤— Transformers estÃ¡ daÃ±ada, como siempre.",
			explain: "Â¡No vamos a dignificar esta respuesta con un comentario!"
		},
		{
			text: "Este pipeline necesita entradas mÃ¡s largas; esta oraciÃ³n es muy corta.",
			explain: "Incorrecto. Un texto muy largo se va a truncar cuando se procesa por este pipeline."
		}
	]}
/>

### 5. Â¿QuÃ© significa "transferencia de aprendizaje"?

<Question
	choices={[
		{
			text: "Transferir el conocimiento de un modelo preentrenado a un nuevo modelo, al entrenarlo en el mismo conjunto de datos.",
			explain: "No, eso serÃ­a dos versiones del mismo modelo."
		},
		{
			text: "Transferir el conocimiento de un modelo preentrenado a un nuevo modelo al inicializar un segundo modelo con los pesos del primero.",
			explain: "Correcto: cuando el segundo modelo se entrena para una tarea nueva, Ã©ste *transfiere* el conocimiento del primero.",
			correct: true
		},
		{
			text: "Transferir el conocimiento de un modelo preentrenado al construir el segundo modelo con la misma arquitectura del primero.",
			explain: "La arquitectura sÃ³lo es la forma en que el modelo se construye; en este caso no hay conocimiento compartido o transferido."
		}
	]}
/>

### 6. Â¿Verdadero o falso? Un modelo de lenguaje usualmente no necesita etiquetas para su preentrenamiento.

<Question
	choices={[
		{
			text: "Verdadero",
			explain: "El preentrenamiento suele ser <em>auto-supervisado</em>, lo que significa que las etiquetas se crean automÃ¡ticamente a partir de la entrada (como predecir la siguiente palabra o llenar palabras ocultas).",
			correct: true
		},
		{
			text: "Falso",
			explain: "Esta no es la respuesta correcta."
		}
	]}
/>

### 7. Selecciona la oraciÃ³n que describe mejor los tÃ©rminos "modelo", "arquitectura" y "pesos".

Select the sentence that best describes the terms "model," "architecture," and "weights."

<Question
	choices={[
		{
			text: "Si un modelo es un edificio, su arquitectura es el plano y los pesos son las personas que viven allÃ­.",
			explain: "Siguiendo esta metÃ¡fora, los pesos serÃ­an los ladrillos y otros materiales usados para construir el edificio."
		},
		{
			text: "Una arquitectura es un mapa para construir un modelo y sus pesos son las ciudades representadas en el mapa.",
			explain: "El problema de esta metÃ¡fora es que un mapa suele representar una realidad existente (sÃ³lo hay una ciudad en Francia llamada Paris). Para una arquitectura dada son posibles mÃºltiples pesos."
		},
		{
			text: "Una arquitectura es una sucesiÃ³n de funciones matemÃ¡ticas para construir un modelo y sus pesos son los parÃ¡metros de dichas funciones.",
			explain: "El mismo conjunto de funciones matemÃ¡ticas (arquitectura) pueden usarse para construir diferentes modelos, usando diferentes parÃ¡metros (pesos).",
			correct: true
		}
	]}
/>


### 8. Â¿CuÃ¡l de los siguientes tipos de modelos usarÃ­as para completar una indicaciÃ³n con texto generado?


<Question
	choices={[
		{
			text: "Un modelo de codificadores",
			explain: "Un modelo de codificadores genera una representaciÃ³n de la oraciÃ³n completa que es mÃ¡s adecuada para tareas como clasificaciÃ³n."
		},
		{
			text: "Un modelo de decodificadores",
			explain: "Los modelos de decodificadores son perfectamente adecuados para la generaciÃ³n de texto de una indicaciÃ³n.",
			correct: true
		},
		{
			text: "Un modelo secuencia a secuencia",
			explain: "Los modelos secuencia a secuencia son mÃ¡s adecuados para tareas en las que quieres generar oraciones en relaciÃ³n con las oraciones de entrada, no una indicaciÃ³n dada."
		}
	]}
/>

### 9. Â¿CuÃ¡l de los siguientes tipos de modelos usarÃ­as para resumir textos?

<Question
	choices={[
		{
			text: "Un modelo de codificadores",
			explain: "Un modelo de codificadores genera una representaciÃ³n de la oraciÃ³n completa que es mÃ¡s adecuada para tareas como clasificaciÃ³n."
		},
		{
			text: "Un modelo de decodificadores",
			explain: "Los modelos de decodificadores son buenos para generar salidas de texto (como resÃºmenes), pero no tienen la habilidad de explotar un contexto como el texto completo para resumir."
		},
		{
			text: "Un modelo secuencia a secuencia",
			explain: "Los modelos secuencia a secuencia son perfectamente adecuados para una tarea de resumen.",
			correct: true
		}
	]}
/>

### 10. Â¿CuÃ¡l de los siguientes tipos de modelos usarÃ­as para clasificar texto de acuerdo con ciertas etiquetas?

<Question
	choices={[
		{
			text: "Un modelo de codificadores",
			explain: "Un modelo de codificadores genera una representaciÃ³n de la oraciÃ³n completa que es perfectamente adecuado para una tarea como clasificaciÃ³n.",
			correct: true
		},
		{
			text: "Un modelo de decodificadores",
			explain: "Los modelos de decodificadores son buenos para generar textos de salida, no extraer una etiqueta de una oraciÃ³n."
		},
		{
			text: "Un modelo secuencia a secuencia",
			explain: "Los modelos secuencia a secuencia son mÃ¡s adecuados para tareas en las que quieres generar texro con base en una oraciÃ³n de entrada, no una etiqueta."
		}
	]}
/>

### 11. Â¿CuÃ¡l puede ser una posible fuente del sesgo observado en un modelo?

What possible source can the bias observed in a model have?

<Question
	choices={[
		{
			text: "El modelo es una versiÃ³n ajustada de un modelo preentrenado y tomÃ³ el sesgo a partir de allÃ­.",
			explain: "Cuando se aplica la Transferencia de Aprendizaje, el sesgo en el modelo preentrenado se manifiesta en el modelo ajustado.",
			correct: true
		},
		{
			text: "Los datos con los que se entrenÃ³ el modelo estÃ¡n sesgados.",
			explain: "Esta es la fuente mÃ¡s obvia de sesgo, pero no la Ãºnica.",
			correct: true
		},
		{
			text: "La mÃ©trica que el modelo estaba optimizando estÃ¡ sesgada.",
			explain: "Una fuente menos obvia de sesgo es la forma en que fue entrenado el modelo. El modelo va a optimizar ciegamente cualquier mÃ©trica que escojas, sin pensarlo dos veces.",
			correct: true
		}
	]}
/>
