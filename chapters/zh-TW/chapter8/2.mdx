# å‡ºç¾éŒ¯èª¤æ™‚è©²æ€éº¼è¾¦

<DocNotebookDropdown
  classNames="absolute z-10 right-0 top-0"
  options={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter8/section2.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter8/section2.ipynb"},
]} />

åœ¨æœ¬ç¯€ä¸­, æˆ‘å€‘å°‡ç ”ç©¶ç•¶ä½ å˜—è©¦å¾æ–°èª¿æ•´çš„ Transformer æ¨¡å‹ç”Ÿæˆé æ¸¬æ™‚å¯èƒ½ç™¼ç”Ÿçš„ä¸€äº›å¸¸è¦‹éŒ¯èª¤ã€‚é€™å°‡ç‚º [ç¬¬å››ç¯€](/course/chapter8/section4) åšæº–å‚™, æˆ‘å€‘å°‡æ¢ç´¢å¦‚ä½•èª¿è©¦è¨“ç·´éšæ®µæœ¬èº«ã€‚

<Youtube id="DQ-CpJn6Rc4"/>

æˆ‘å€‘ç‚ºé€™ä¸€ç¯€æº–å‚™äº†ä¸€å€‹ [æ¨¡æ¿æ¨¡å‹åº«](https://huggingface.co/lewtun/distilbert-base-uncased-finetuned-squad-d5716d28), å¦‚æœä½ æƒ³é‹è¡Œæœ¬ç« ä¸­çš„ä»£ç¢¼, ä½ é¦–å…ˆéœ€è¦å°‡æ¨¡å‹è¤‡è£½åˆ°ä½ çš„ [Hugging Face Hub](https://huggingface.co) è³¬è™Ÿã€‚ç‚ºæ­¤, é¦–å…ˆé€šéåœ¨ Jupyter ç­†è¨˜æœ¬ä¸­é‹è¡Œä»¥ä¸‹ä»»ä¸€å‘½ä»¤ä¾†ç™»éŒ„:

```python
from huggingface_hub import notebook_login

notebook_login()
```

æˆ–åœ¨ä½ æœ€å–œæ­¡çš„çµ‚ç«¯ä¸­åŸ·è¡Œä»¥ä¸‹æ“ä½œ:

```bash
huggingface-cli login
```

é€™å°‡æç¤ºä½ è¼¸å…¥ç”¨æˆ¶åå’Œå¯†ç¢¼, ä¸¦å°‡åœ¨ä¸‹é¢ä¿å­˜ä¸€å€‹ä»¤ç‰Œ *~/.cache/huggingface/*ã€‚ç™»éŒ„å¾Œ, ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹åŠŸèƒ½è¤‡è£½æ¨¡æ¿å­˜å„²åº«:

```python
from distutils.dir_util import copy_tree
from huggingface_hub import Repository, snapshot_download, create_repo, get_full_repo_name


def copy_repository_template():
    # Clone the repo and extract the local path
    template_repo_id = "lewtun/distilbert-base-uncased-finetuned-squad-d5716d28"
    commit_hash = "be3eaffc28669d7932492681cd5f3e8905e358b4"
    template_repo_dir = snapshot_download(template_repo_id, revision=commit_hash)
    # Create an empty repo on the Hub
    model_name = template_repo_id.split("/")[1]
    create_repo(model_name, exist_ok=True)
    # Clone the empty repo
    new_repo_id = get_full_repo_name(model_name)
    new_repo_dir = model_name
    repo = Repository(local_dir=new_repo_dir, clone_from=new_repo_id)
    # Copy files
    copy_tree(template_repo_dir, new_repo_dir)
    # Push to Hub
    repo.push_to_hub()
```

ç¾åœ¨, ç•¶ä½ èª¿ç”¨ `copy_repository_template()` æ™‚, å®ƒå°‡åœ¨ä½ çš„å¸³æˆ¶ä¸‹å‰µå»ºæ¨¡æ¿å­˜å„²åº«çš„å‰¯æœ¬ã€‚

## å¾ ğŸ¤— Transformers èª¿è©¦ç®¡é“

è¦é–‹å§‹æˆ‘å€‘èª¿è©¦ Transformer æ¨¡å‹çš„å¥‡å¦™ä¸–ç•Œä¹‹æ—…, è«‹è€ƒæ…®ä»¥ä¸‹å ´æ™¯: ä½ æ­£åœ¨èˆ‡ä¸€ä½åŒäº‹åˆä½œé€²è¡Œå•ç­”é …ç›®, ä»¥å¹«åŠ©é›»å­å•†å‹™ç¶²ç«™çš„å®¢æˆ¶æ‰¾åˆ°æœ‰é—œæ¶ˆè²»å“çš„ç­”æ¡ˆã€‚ä½ çš„åŒäº‹çµ¦ä½ ç™¼äº†ä¸€æ¢æ¶ˆæ¯, æ¯”å¦‚:

> å—¨! æˆ‘å‰›å‰›ä½¿ç”¨äº†æŠ±æŠ±è‡‰èª²ç¨‹çš„ [ç¬¬ä¸ƒç« ](/course/chapter7/7) ä¸­çš„æŠ€è¡“é€²è¡Œäº†ä¸€å€‹å¯¦é©—, ä¸¦åœ¨ SQuAD ä¸Šç²å¾—äº†ä¸€äº›å¾ˆæ£’çš„çµæœ! æˆ‘èªç‚ºæˆ‘å€‘å¯ä»¥ç”¨é€™å€‹æ¨¡å‹ä½œç‚ºæˆ‘å€‘é …ç›®çš„èµ·é»ã€‚Hubä¸Šçš„æ¨¡å‹IDæ˜¯ "lewtun/distillbert-base-uncased-finetuned-squad-d5716d28"ã€‚è«‹éš¨æ„æ¸¬è©¦ä¸€ä¸‹ :)

ä½ é¦–å…ˆæƒ³åˆ°çš„æ˜¯ä½¿ç”¨ ğŸ¤— Transformers ä¸­çš„ `ç®¡é“`:

```python
from transformers import pipeline

model_checkpoint = get_full_repo_name("distillbert-base-uncased-finetuned-squad-d5716d28")
reader = pipeline("question-answering", model=model_checkpoint)
```

```python out
"""
OSError: Can't load config for 'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28'. Make sure that:

- 'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28' is a correct model identifier listed on 'https://huggingface.co/models'

- or 'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28' is the correct path to a directory containing a config.json file
"""
```

å“¦ä¸å°, å¥½åƒå‡ºäº†ä»€éº¼å•é¡Œ! å¦‚æœä½ æ˜¯ç·¨ç¨‹æ–°æ‰‹, é€™äº›é¡å‹çš„éŒ¯èª¤ä¸€é–‹å§‹çœ‹èµ·ä¾†æœ‰é»ç¥ç§˜ (ç”šè‡³æ˜¯ä¸€å€‹ `OSError`?!)ã€‚é€™è£¡é¡¯ç¤ºçš„éŒ¯èª¤åªæ˜¯ä¸€å€‹æ›´å¤§çš„éŒ¯èª¤å ±å‘Šçš„æœ€å¾Œä¸€éƒ¨åˆ†, ç¨±ç‚º _Python traceback_ (åˆåå †æ£§è·Ÿè¹¤)ã€‚ä¾‹å¦‚, å¦‚æœä½ åœ¨ Google Colab ä¸Šé‹è¡Œæ­¤ä»£ç¢¼, ä½ æ‡‰è©²æœƒçœ‹åˆ°é¡ä¼¼æ–¼ä»¥ä¸‹å±å¹•æˆªåœ–çš„å…§å®¹:

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter8/traceback.png" alt="A Python traceback." width="100%"/>
</div>

é€™äº›å ±å‘Šä¸­åŒ…å«å¾ˆå¤šä¿¡æ¯, æ‰€ä»¥è®“æˆ‘å€‘ä¸€èµ·ä¾†çœ‹çœ‹é—œéµéƒ¨åˆ†ã€‚é¦–å…ˆè¦æ³¨æ„çš„æ˜¯, æ‡‰è©²å¾ _å¾åº•éƒ¨åˆ°é ‚éƒ¨_ è®€å–å›æº¯ã€‚å¦‚æœä½ ç¿’æ…£æ–¼å¾ä¸Šåˆ°ä¸‹é–±è®€è‹±æ–‡æ–‡æœ¬, é€™å¯èƒ½è½èµ·ä¾†å¾ˆå¥‡æ€ª,ä½†å®ƒåæ˜ äº†é€™æ¨£ä¸€å€‹äº‹å¯¦,å³å›æº¯é¡¯ç¤ºäº†åœ¨ä¸‹è¼‰æ¨¡å‹å’Œæ¨™è¨˜å™¨æ™‚ `ç®¡é“` é€²è¡Œçš„å‡½æ•¸èª¿ç”¨åºåˆ—ã€‚(æŸ¥çœ‹ [ç¬¬äºŒç« ](/course/chapter2) ç­è§£æœ‰é—œ `pipeline` å¦‚ä½•åœ¨å¾Œè‡ºå·¥ä½œçš„æ›´å¤šè©³ç´°ä¿¡æ¯ã€‚)

<Tip>

ğŸš¨ çœ‹åˆ°Google Colab å›æº¯ä¸­ "6 å¹€" å‘¨åœçš„è—è‰²æ¡†äº†å—? é€™æ˜¯ Colab çš„ä¸€å€‹ç‰¹æ®ŠåŠŸèƒ½, å®ƒå°‡å›æº¯å£“ç¸®ç‚º"å¹€"ã€‚å¦‚æœä½ ä¼¼ä¹ç„¡æ³•æ‰¾åˆ°éŒ¯èª¤çš„ä¾†æº, è«‹ç¢ºä¿é€šéå–®æ“Šé€™å…©å€‹å°ç®­é ­ä¾†å±•é–‹å®Œæ•´çš„å›æº¯ã€‚

</Tip>

é€™æ„å‘³è‘—å›æº¯çš„æœ€å¾Œä¸€è¡ŒæŒ‡ç¤ºæœ€å¾Œä¸€æ¢éŒ¯èª¤æ¶ˆæ¯ä¸¦çµ¦å‡ºå¼•ç™¼çš„ç•°å¸¸çš„åç¨±ã€‚åœ¨é€™ç¨®æƒ…æ³ä¸‹, ç•°å¸¸é¡å‹æ˜¯`OSError`, è¡¨ç¤ºèˆ‡ç³»çµ±ç›¸é—œçš„éŒ¯èª¤ã€‚å¦‚æœæˆ‘å€‘é–±è®€éš¨é™„çš„éŒ¯èª¤æ¶ˆæ¯, æˆ‘å€‘å¯ä»¥çœ‹åˆ°æ¨¡å‹çš„ *config.json* æ–‡ä»¶ä¼¼ä¹æœ‰å•é¡Œ, æˆ‘å€‘çµ¦å‡ºäº†å…©å€‹ä¿®å¾©å®ƒçš„å»ºè­°:

```python out
"""
Make sure that:

- 'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28' is a correct model identifier listed on 'https://huggingface.co/models'

- or 'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28' is the correct path to a directory containing a config.json file
"""
```

<Tip>

ğŸ’¡ å¦‚æœä½ é‡åˆ°é›£ä»¥ç†è§£çš„éŒ¯èª¤æ¶ˆæ¯, åªéœ€å°‡è©²æ¶ˆæ¯è¤‡è£½ä¸¦ç²˜è²¼åˆ° Google æˆ– [Stack Overflow](https://stackoverflow.com/) æœç´¢æ¬„ä¸­ (æ˜¯çš„, çœŸçš„!)ã€‚ä½ å¾ˆå¯èƒ½ä¸æ˜¯ç¬¬ä¸€å€‹é‡åˆ°éŒ¯èª¤çš„äºº, é€™æ˜¯æ‰¾åˆ°ç¤¾å€ä¸­å…¶ä»–äººç™¼ä½ˆçš„è§£æ±ºæ–¹æ¡ˆçš„å¥½æ–¹æ³•ã€‚ä¾‹å¦‚, åœ¨ Stack Overflow ä¸Šæœç´¢ `OSError: Can't load config for` çµ¦å‡ºäº†å¹¾å€‹[hits](https://stackoverflow.com/search?q=OSError%3A+Can%27t+load+config+for+), å¯èƒ½æ˜¯ç”¨ä½œè§£æ±ºå•é¡Œçš„èµ·é»ã€‚

</Tip>

ç¬¬ä¸€å€‹å»ºè­°æ˜¯è¦æ±‚æˆ‘å€‘æª¢æŸ¥æ¨¡å‹IDæ˜¯å¦çœŸçš„æ­£ç¢º, æ‰€ä»¥é¦–å…ˆè¦åšçš„å°±æ˜¯è¤‡è£½æ¨™è­˜ç¬¦ä¸¦å°‡å…¶ç²˜è²¼åˆ°Hubçš„æœç´¢æ¬„ä¸­:

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter8/wrong-model-id.png" alt="The wrong model name." width="100%"/>
</div>

å—¯, çœ‹èµ·ä¾†æˆ‘å€‘åŒäº‹çš„æ¨¡å‹ç¢ºå¯¦ä¸åœ¨ Hub ä¸Š... å•Šå“ˆ, ä½†æ˜¯æ¨¡å‹åç¨±ä¸­æœ‰ä¸€å€‹éŒ¯å­—! DistilBERT çš„åç¨±ä¸­åªæœ‰ä¸€å€‹ "l", æ‰€ä»¥è®“æˆ‘å€‘è§£æ±ºé€™å€‹å•é¡Œä¸¦å°‹æ‰¾ "lewtun/distilbert-base-uncased-finetuned-squad-d5716d28":

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter8/true-model-id.png" alt="The right model name." width="100%"/>
</div>

å¥½çš„, é€™å¾ˆå—æ­¡è¿ã€‚ç¾åœ¨è®“æˆ‘å€‘å˜—è©¦ä½¿ç”¨æ­£ç¢ºçš„æ¨¡å‹ ID å†æ¬¡ä¸‹è¼‰æ¨¡å‹:

```python
model_checkpoint = get_full_repo_name("distilbert-base-uncased-finetuned-squad-d5716d28")
reader = pipeline("question-answering", model=model_checkpoint)
```

```python out
"""
OSError: Can't load config for 'lewtun/distilbert-base-uncased-finetuned-squad-d5716d28'. Make sure that:

- 'lewtun/distilbert-base-uncased-finetuned-squad-d5716d28' is a correct model identifier listed on 'https://huggingface.co/models'

- or 'lewtun/distilbert-base-uncased-finetuned-squad-d5716d28' is the correct path to a directory containing a config.json file
"""
```

å•Š, å†æ¬¡æŒ«æ•— -- æ­¡è¿ä¾†åˆ°æ©Ÿå™¨å­¸ç¿’å·¥ç¨‹å¸«çš„æ—¥å¸¸ç”Ÿæ´»! å› ç‚ºæˆ‘å€‘å·²ç¶“ä¿®å¾©äº†æ¨¡å‹ ID, æ‰€ä»¥å•é¡Œä¸€å®šå‡ºåœ¨å­˜å„²åº«æœ¬èº«ã€‚è¨ªå• ğŸ¤— Hub ä¸Šå­˜å„²åº«å…§å®¹çš„ä¸€ç¨®å¿«é€Ÿæ–¹æ³•æ˜¯é€šé `huggingface_hub` åº«çš„ `list_repo_files()` æ–¹æ³•:

```python
from huggingface_hub import list_repo_files

list_repo_files(repo_id=model_checkpoint)
```

```python out
['.gitattributes', 'README.md', 'pytorch_model.bin', 'special_tokens_map.json', 'tokenizer_config.json', 'training_args.bin', 'vocab.txt']
```

æœ‰è¶£ -- ä¼¼ä¹æ²’æœ‰é…ç½®æ–‡ä»¶å­˜å„²åº«ä¸­çš„ *config.json* æ–‡ä»¶! é›£æ€ªæˆ‘å€‘çš„ `pipeline` ç„¡æ³•åŠ è¼‰æ¨¡å‹; æˆ‘å€‘çš„åŒäº‹ä¸€å®šæ˜¯åœ¨å¾®èª¿å¾Œå¿˜è¨˜å°‡é€™å€‹æ–‡ä»¶æ¨é€åˆ° Hubã€‚åœ¨é€™ç¨®æƒ…æ³ä¸‹, å•é¡Œä¼¼ä¹å¾ˆå®¹æ˜“è§£æ±º: æˆ‘å€‘å¯ä»¥è¦æ±‚ä»–å€‘æ·»åŠ æ–‡ä»¶, æˆ–è€…, å› ç‚ºæˆ‘å€‘å¯ä»¥å¾æ¨¡å‹ ID ä¸­çœ‹åˆ°ä½¿ç”¨çš„é è¨“ç·´æ¨¡å‹æ˜¯ [`distilbert-base-uncased`](https://huggingface.co/distilbert-base-uncased), æˆ‘å€‘å¯ä»¥ä¸‹è¼‰æ­¤æ¨¡å‹çš„é…ç½®ä¸¦å°‡å…¶æ¨é€åˆ°æˆ‘å€‘çš„å­˜å„²åº«ä»¥æŸ¥çœ‹æ˜¯å¦å¯ä»¥è§£æ±ºå•é¡Œã€‚è®“æˆ‘å€‘è©¦è©¦çœ‹ã€‚ä½¿ç”¨æˆ‘å€‘åœ¨ [ç¬¬äºŒç« ](/course/chapter2) ä¸­å­¸ç¿’çš„æŠ€è¡“, æˆ‘å€‘ä½¿ç”¨ `AutoConfig` é¡ä¸‹è¼‰æ¨¡å‹çš„é…ç½®:

```python
from transformers import AutoConfig

pretrained_checkpoint = "distilbert-base-uncased"
config = AutoConfig.from_pretrained(pretrained_checkpoint)
```

<Tip warning={true}>

ğŸš¨ æˆ‘å€‘åœ¨é€™è£¡æ¡ç”¨çš„æ–¹æ³•ä¸¦ä¸æ˜¯è¬ç„¡ä¸€å¤±çš„, å› ç‚ºæˆ‘å€‘çš„åŒäº‹å¯èƒ½åœ¨å¾®èª¿æ¨¡å‹ä¹‹å‰å·²ç¶“èª¿æ•´äº† `distilbert-base-uncased` é…ç½®ã€‚åœ¨ç¾å¯¦ç”Ÿæ´»ä¸­, æˆ‘å€‘æƒ³é¦–å…ˆæª¢æŸ¥å®ƒå€‘, ä½†å‡ºæ–¼æœ¬ç¯€çš„ç›®çš„, æˆ‘å€‘å‡è¨­å®ƒå€‘ä½¿ç”¨é»˜èªé…ç½®ã€‚

</Tip>

ç„¶å¾Œæˆ‘å€‘å¯ä»¥ä½¿ç”¨é…ç½®çš„ `push_to_hub()` æ–¹æ³•å°‡å…¶æ¨é€åˆ°æˆ‘å€‘çš„æ¨¡å‹å­˜å„²åº«:

```python
config.push_to_hub(model_checkpoint, commit_message="Add config.json")
```

ç¾åœ¨æˆ‘å€‘å¯ä»¥é€šéå¾æœ€æ–°æäº¤çš„ `main` åˆ†æ”¯ä¸­åŠ è¼‰æ¨¡å‹ä¾†æ¸¬è©¦é€™æ˜¯å¦æœ‰æ•ˆ:

```python
reader = pipeline("question-answering", model=model_checkpoint, revision="main")

context = r"""
Extractive Question Answering is the task of extracting an answer from a text
given a question. An example of a question answering dataset is the SQuAD
dataset, which is entirely based on that task. If you would like to fine-tune a
model on a SQuAD task, you may leverage the
examples/pytorch/question-answering/run_squad.py script.

ğŸ¤— Transformers is interoperable with the PyTorch, TensorFlow, and JAX
frameworks, so you can use your favourite tools for a wide variety of tasks!
"""

question = "What is extractive question answering?"
reader(question=question, context=context)
```

```python out
{'score': 0.38669535517692566,
 'start': 34,
 'end': 95,
 'answer': 'the task of extracting an answer from a text given a question'}
```

å“‡å“¦, æˆåŠŸäº†!è®“æˆ‘å€‘å›é¡§ä¸€ä¸‹ä½ å‰›å‰›å­¸åˆ°çš„æ±è¥¿:

- Python ä¸­çš„éŒ¯èª¤æ¶ˆæ¯ç¨±ç‚º _tracebacks_ , ä¸¦å¾ä¸‹åˆ°ä¸Šé–±è®€ã€‚éŒ¯èª¤æ¶ˆæ¯çš„æœ€å¾Œä¸€è¡Œé€šå¸¸åŒ…å«å®šä½å•é¡Œæ ¹æºæ‰€éœ€çš„ä¿¡æ¯ã€‚
- å¦‚æœæœ€å¾Œä¸€è¡Œæ²’æœ‰åŒ…å«è¶³å¤ çš„ä¿¡æ¯, è«‹æŒ‰ç…§æ‚¨çš„æ–¹å¼é€²è¡Œå›æº¯, çœ‹çœ‹æ‚¨æ˜¯å¦å¯ä»¥ç¢ºå®šæºä»£ç¢¼ä¸­ç™¼ç”ŸéŒ¯èª¤çš„ä½ç½®ã€‚
- å¦‚æœæ²’æœ‰ä»»ä½•éŒ¯èª¤æ¶ˆæ¯å¯ä»¥å¹«åŠ©æ‚¨èª¿è©¦å•é¡Œ, è«‹å˜—è©¦åœ¨ç·šæœç´¢é¡ä¼¼å•é¡Œçš„è§£æ±ºæ–¹æ¡ˆã€‚
- `huggingface_hub` 
// ğŸ¤— Hub?
åº«æä¾›äº†ä¸€å¥—å·¥å…·, ä½ å¯ä»¥ä½¿ç”¨é€™äº›å·¥å…·èˆ‡ Hub ä¸Šçš„å­˜å„²åº«é€²è¡Œäº¤äº’å’Œèª¿è©¦ã€‚

ç¾åœ¨ä½ çŸ¥é“å¦‚ä½•èª¿è©¦ç®¡é“, è®“æˆ‘å€‘çœ‹ä¸€ä¸‹æ¨¡å‹æœ¬èº«å‰å‘å‚³éä¸­çš„ä¸€å€‹æ›´æ£˜æ‰‹çš„ç¤ºä¾‹ã€‚

## èª¿è©¦æ¨¡å‹çš„å‰å‘å‚³é

å„˜ç®¡ `pipeline` å°æ–¼å¤§å¤šæ•¸éœ€è¦å¿«é€Ÿç”Ÿæˆé æ¸¬çš„æ‡‰ç”¨ç¨‹åºä¾†èªªéå¸¸æœ‰ç”¨, æœ‰æ™‚æ‚¨éœ€è¦è¨ªå•æ¨¡å‹çš„ logits (ä¾‹å¦‚, å¦‚æœæ‚¨æœ‰ä¸€äº›æƒ³è¦æ‡‰ç”¨çš„è‡ªå®šç¾©å¾Œè™•ç†)ã€‚ç‚ºäº†çœ‹çœ‹åœ¨é€™ç¨®æƒ…æ³ä¸‹æœƒå‡ºç¾ä»€éº¼å•é¡Œ, è®“æˆ‘å€‘é¦–å…ˆå¾ `pipeline` ä¸­ç²å–æ¨¡å‹å’Œæ¨™è¨˜å™¨:

```python
tokenizer = reader.tokenizer
model = reader.model
```

æ¥ä¸‹ä¾†æˆ‘å€‘éœ€è¦ä¸€å€‹å•é¡Œ, é‚£éº¼è®“æˆ‘å€‘çœ‹çœ‹æ˜¯å¦æ”¯æŒæˆ‘å€‘æœ€å–œæ­¡çš„æ¡†æ¶:

```python
question = "Which frameworks can I use?"
```

æ­£å¦‚æˆ‘å€‘åœ¨ [ç¬¬ä¸ƒç« ](/course/chapter7) ä¸­å­¸ç¿’çš„, æˆ‘å€‘éœ€è¦æ¡å–çš„é€šå¸¸æ­¥é©Ÿæ˜¯å°è¼¸å…¥é€²è¡Œæ¨™è¨˜åŒ–, æå–é–‹å§‹å’ŒçµæŸæ¨™è¨˜çš„å°æ•¸, ç„¶å¾Œè§£ç¢¼ç­”æ¡ˆç¯„åœ:

```python
import torch

inputs = tokenizer(question, context, add_special_tokens=True)
input_ids = inputs["input_ids"][0]
outputs = model(**inputs)
answer_start_scores = outputs.start_logits
answer_end_scores = outputs.end_logits
# Get the most likely beginning of answer with the argmax of the score
answer_start = torch.argmax(answer_start_scores)
# Get the most likely end of answer with the argmax of the score
answer_end = torch.argmax(answer_end_scores) + 1
answer = tokenizer.convert_tokens_to_string(
    tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end])
)
print(f"Question: {question}")
print(f"Answer: {answer}")
```

```python out
"""
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
/var/folders/28/k4cy5q7s2hs92xq7_h89_vgm0000gn/T/ipykernel_75743/2725838073.py in <module>
      1 inputs = tokenizer(question, text, add_special_tokens=True)
      2 input_ids = inputs["input_ids"]
----> 3 outputs = model(**inputs)
      4 answer_start_scores = outputs.start_logits
      5 answer_end_scores = outputs.end_logits

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)
   1049         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
   1050                 or _global_forward_hooks or _global_forward_pre_hooks):
-> 1051             return forward_call(*input, **kwargs)
   1052         # Do not call functions when jit is used
   1053         full_backward_hooks, non_full_backward_hooks = [], []

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py in forward(self, input_ids, attention_mask, head_mask, inputs_embeds, start_positions, end_positions, output_attentions, output_hidden_states, return_dict)
    723         return_dict = return_dict if return_dict is not None else self.config.use_return_dict
    724
--> 725         distilbert_output = self.distilbert(
    726             input_ids=input_ids,
    727             attention_mask=attention_mask,

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)
   1049         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
   1050                 or _global_forward_hooks or _global_forward_pre_hooks):
-> 1051             return forward_call(*input, **kwargs)
   1052         # Do not call functions when jit is used
   1053         full_backward_hooks, non_full_backward_hooks = [], []

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py in forward(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)
    471             raise ValueError("You cannot specify both input_ids and inputs_embeds at the same time")
    472         elif input_ids is not None:
--> 473             input_shape = input_ids.size()
    474         elif inputs_embeds is not None:
    475             input_shape = inputs_embeds.size()[:-1]

AttributeError: 'list' object has no attribute 'size'
"""
```

å™¢, çœ‹èµ·ä¾†æˆ‘å€‘çš„ä»£ç¢¼ä¸­æœ‰ä¸€å€‹éŒ¯èª¤!ä½†æˆ‘å€‘ä¸æ€•ä¸€é»èª¿è©¦ã€‚æ‚¨å¯ä»¥åœ¨ç­†è¨˜æœ¬ä¸­ä½¿ç”¨ Python èª¿è©¦å™¨:

<Youtube id="rSPyvPw0p9k"/>

æˆ–åœ¨çµ‚ç«¯ä¸­:

<Youtube id="5PkZ4rbHL6c"/>

åœ¨é€™è£¡, é–±è®€éŒ¯èª¤æ¶ˆæ¯å‘Šè¨´æˆ‘å€‘ `'list' object has no attribute 'size'`, æˆ‘å€‘å¯ä»¥çœ‹åˆ°ä¸€å€‹ `-->` ç®­é ­æŒ‡å‘ `model(**inputs)` ä¸­å‡ºç¾å•é¡Œçš„è¡Œã€‚ä½ å¯ä»¥ä½¿ç”¨ Python èª¿è©¦å™¨ä»¥äº¤äº’æ–¹å¼èª¿è©¦å®ƒ, ä½†ç¾åœ¨æˆ‘å€‘åªéœ€æ‰“å°å‡ºä¸€éƒ¨åˆ† `inputs`, çœ‹çœ‹æˆ‘å€‘æœ‰ä»€éº¼:

```python
inputs["input_ids"][:5]
```

```python out
[101, 2029, 7705, 2015, 2064]
```

é€™ç•¶ç„¶çœ‹èµ·ä¾†åƒä¸€å€‹æ™®é€šçš„ Python `list`, ä½†è®“æˆ‘å€‘ä»”ç´°æª¢æŸ¥ä¸€ä¸‹é¡å‹:

```python
type(inputs["input_ids"])
```

```python out
list
```

æ˜¯çš„, é€™è‚¯å®šæ˜¯ä¸€å€‹ Python `list`ã€‚é‚£éº¼å‡ºäº†ä»€éº¼å•é¡Œå‘¢? å›æ†¶ [ç¬¬äºŒç« ](/course/chapter2) ğŸ¤— Transformers ä¸­çš„ `AutoModelForXxx` é¡åœ¨ _tensors_ ä¸Šé‹è¡Œ(PyTorchæˆ–è€…or TensorFlow), ä¸€å€‹å¸¸è¦‹çš„æ“ä½œæ˜¯ä½¿ç”¨ `Tensor.size()` æ–¹æ³•æå–å¼µé‡çš„ç¶­åº¦, ä¾‹å¦‚, åœ¨ PyTorch ä¸­ã€‚è®“æˆ‘å€‘å†çœ‹çœ‹å›æº¯, çœ‹çœ‹å“ªä¸€è¡Œè§¸ç™¼äº†ç•°å¸¸:

```
~/miniconda3/envs/huggingface/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py in forward(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)
    471             raise ValueError("You cannot specify both input_ids and inputs_embeds at the same time")
    472         elif input_ids is not None:
--> 473             input_shape = input_ids.size()
    474         elif inputs_embeds is not None:
    475             input_shape = inputs_embeds.size()[:-1]

AttributeError: 'list' object has no attribute 'size'
```

çœ‹èµ·ä¾†æˆ‘å€‘çš„ä»£ç¢¼è©¦åœ–èª¿ç”¨ `input_ids.size()`, ä½†é€™é¡¯ç„¶ä¸é©ç”¨æ–¼ Python `list`, é€™åªæ˜¯ä¸€å€‹å®¹å™¨ã€‚æˆ‘å€‘å¦‚ä½•è§£æ±ºé€™å€‹å•é¡Œ? åœ¨ Stack Overflow ä¸Šæœç´¢éŒ¯èª¤æ¶ˆæ¯çµ¦å‡ºäº†å¾ˆå¤šç›¸é—œçš„ [hits](https://stackoverflow.com/search?q=AttributeError%3A+%27list%27+object+has+no+attribute+%27size%27&s=c15ec54c-63cb-481d-a749-408920073e8f)ã€‚å–®æ“Šç¬¬ä¸€å€‹æœƒé¡¯ç¤ºèˆ‡æˆ‘å€‘é¡ä¼¼çš„å•é¡Œ, ç­”æ¡ˆå¦‚ä¸‹é¢çš„å±å¹•æˆªåœ–æ‰€ç¤º:

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter8/stack-overflow.png" alt="An answer from Stack Overflow." width="100%"/>
</div>

ç­”æ¡ˆå»ºè­°æˆ‘å€‘æ·»åŠ  `return_tensors='pt'` åˆ°æ¨™è¨˜å™¨, æ‰€ä»¥è®“æˆ‘å€‘çœ‹çœ‹é€™æ˜¯å¦é©åˆæˆ‘å€‘:

```python out
inputs = tokenizer(question, context, add_special_tokens=True, return_tensors="pt")
input_ids = inputs["input_ids"][0]
outputs = model(**inputs)
answer_start_scores = outputs.start_logits
answer_end_scores = outputs.end_logits
# Get the most likely beginning of answer with the argmax of the score
answer_start = torch.argmax(answer_start_scores)
# Get the most likely end of answer with the argmax of the score
answer_end = torch.argmax(answer_end_scores) + 1
answer = tokenizer.convert_tokens_to_string(
    tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end])
)
print(f"Question: {question}")
print(f"Answer: {answer}")
```

```python out
"""
Question: Which frameworks can I use?
Answer: pytorch, tensorflow, and jax
"""
```

ä¸éŒ¯, æˆåŠŸäº†! é€™æ˜¯ Stack Overflow éå¸¸æœ‰ç”¨çš„ä¸€å€‹å¾ˆå¥½çš„ä¾‹å­: é€šéè­˜åˆ¥é¡ä¼¼çš„å•é¡Œ, æˆ‘å€‘èƒ½å¤ å¾ç¤¾å€ä¸­å…¶ä»–äººçš„ç¶“é©—ä¸­å—ç›Šã€‚ç„¶è€Œ, åƒé€™æ¨£çš„æœç´¢ä¸¦ä¸ç¸½æ˜¯æœƒç”¢ç”Ÿç›¸é—œçš„ç­”æ¡ˆ, é‚£éº¼åœ¨é€™ç¨®æƒ…æ³ä¸‹ä½ èƒ½åšä»€éº¼å‘¢? å¹¸é‹çš„æ˜¯, æœ‰ä¸€å€‹å—æ­¡è¿çš„é–‹ç™¼è€…ç¤¾å€ [Hugging Face forums](https://discuss.huggingface.co/) å¯ä»¥å¹«åŠ©ä½ ! åœ¨ä¸‹ä¸€ç¯€ä¸­, æˆ‘å€‘å°‡çœ‹çœ‹å¦‚ä½•è¨­è¨ˆå¯èƒ½å¾—åˆ°å›ç­”çš„å„ªç§€è«–å£‡å•é¡Œã€‚