# æ˜¯æ™‚å€™ä¾†å­¸ä¸€ä¸‹åˆ‡ç‰‡äº†

<CourseFloatingBanner chapter={5}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/zh-CN/chapter5/section3.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/zh-CN/chapter5/section3.ipynb"},
]} />

å¤§å¤šæ•¸æƒ…æ³ä¸‹ï¼Œæ‚¨ä½¿ç”¨çš„æ•¸æ“šéƒ½éœ€æ ¹æ“šæ¨¡å‹æ‰€è¦æ±‚çš„è¼¸å…¥é€²è¡Œæ¸…æ´—ã€‚åœ¨æœ¬ç¯€ä¸­ï¼Œæˆ‘å€‘å°‡æ¢ç´¢ ğŸ¤— Datasets æä¾›çš„ç”¨æ–¼æ•¸æ“šé›†æ¸…æ´—çš„å„ç¨®åŠŸèƒ½ã€‚

<Youtube id="tqfSFcPMgOI"/>

## åˆ‡ç‰‡èˆ‡åˆ‡åˆ†æˆ‘å€‘çš„æ•¸æ“š

èˆ‡ Pandas é¡ä¼¼ï¼ŒğŸ¤— Datasets æä¾›äº†å¹¾å€‹å‡½æ•¸ä¾†æ“ä½œ **Dataset** å’Œ **DatasetDict** å°è±¡ã€‚æˆ‘å€‘åœ¨[ç¬¬ä¸‰ç« ](/course/chapter3)å·²ç¶“é‡åˆ°äº† **Dataset.map()** æ–¹æ³•ï¼Œåœ¨æœ¬ç¯€ä¸­ï¼Œæˆ‘å€‘å°‡æ¢ç´¢æˆ‘å€‘å¯ä»¥ä½¿ç”¨çš„å…¶ä»–åŠŸèƒ½ã€‚

å°æ–¼é€™å€‹ä¾‹å­ï¼Œæˆ‘å€‘å°‡ä½¿ç”¨è¨—ç®¡åœ¨[åŠ å·å¤§å­¸æ­æ–‡åˆ†æ ¡æ©Ÿå™¨å­¸ç¿’å­˜å„²åº«](https://archive.ics.uci.edu/ml/index.php)çš„[è—¥ç‰©å¯©æŸ¥æ•¸æ“šé›†](https://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+%28Drugs.com%29)ï¼Œå…¶ä¸­åŒ…å«æ‚£è€…å°å„ç¨®è—¥ç‰©çš„è©•è«–ï¼Œä»¥åŠæ­£åœ¨æ²»ç™‚çš„ç—…æƒ…å’Œæ‚£è€…æ»¿æ„åº¦çš„ 10 æ˜Ÿè©•ç´šã€‚

é¦–å…ˆæˆ‘å€‘éœ€è¦ä¸‹è¼‰ä¸¦æå–æ•¸æ“šï¼Œé€™å¯ä»¥é€šé **wget** å’Œ **unzip** å‘½ä»¤ï¼š

```py
!wget "https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip"
!unzip drugsCom_raw.zip
```

ç”±æ–¼ TSV åªæ˜¯ä½¿ç”¨è£½è¡¨ç¬¦è€Œä¸æ˜¯é€—è™Ÿä½œç‚ºåˆ†éš”ç¬¦çš„ CSV è®Šé«”ï¼Œæˆ‘å€‘å¯ä»¥ä½¿ç”¨åŠ è¼‰**csv**æ–‡ä»¶çš„**load_dataset()**å‡½æ•¸ä¸¦æŒ‡å®šåˆ†éš”ç¬¦ ç¤ºä¾‹å¦‚ä¸‹ï¼š

```py
from datasets import load_dataset

data_files = {"train": "drugsComTrain_raw.tsv", "test": "drugsComTest_raw.tsv"}
# \t is the tab character in Python
drug_dataset = load_dataset("csv", data_files=data_files, delimiter="\t")
```

åœ¨é€²è¡Œä»»ä½•é¡å‹çš„æ•¸æ“šåˆ†ææ™‚ï¼Œä¸€å€‹å¥½çš„åšæ³•æ˜¯æŠ½å–ä¸€å€‹å°çš„éš¨æ©Ÿæ¨£æœ¬ï¼Œä»¥å¿«é€Ÿç­è§£æ‚¨æ­£åœ¨è™•ç†çš„æ•¸æ“šé¡å‹ã€‚åœ¨ğŸ¤—æ•¸æ“šé›†ä¸­ï¼Œæˆ‘å€‘å¯ä»¥é€šééˆæ¥ **Dataset.shuffle()** å’Œ **Dataset.select()** å…±åŒä¾†å®ŒæˆæŠ½å–ï¼š

```py
drug_sample = drug_dataset["train"].shuffle(seed=42).select(range(1000))
# Peek at the first few examples
drug_sample[:3]
```

```python out
{'Unnamed: 0': [87571, 178045, 80482],
 'drugName': ['Naproxen', 'Duloxetine', 'Mobic'],
 'condition': ['Gout, Acute', 'ibromyalgia', 'Inflammatory Conditions'],
 'review': ['"like the previous person mention, I&#039;m a strong believer of aleve, it works faster for my gout than the prescription meds I take. No more going to the doctor for refills.....Aleve works!"',
  '"I have taken Cymbalta for about a year and a half for fibromyalgia pain. It is great\r\nas a pain reducer and an anti-depressant, however, the side effects outweighed \r\nany benefit I got from it. I had trouble with restlessness, being tired constantly,\r\ndizziness, dry mouth, numbness and tingling in my feet, and horrible sweating. I am\r\nbeing weaned off of it now. Went from 60 mg to 30mg and now to 15 mg. I will be\r\noff completely in about a week. The fibro pain is coming back, but I would rather deal with it than the side effects."',
  '"I have been taking Mobic for over a year with no side effects other than an elevated blood pressure.  I had severe knee and ankle pain which completely went away after taking Mobic.  I attempted to stop the medication however pain returned after a few days."'],
 'rating': [9.0, 3.0, 10.0],
 'date': ['September 2, 2015', 'November 7, 2011', 'June 5, 2013'],
 'usefulCount': [36, 13, 128]}
```

è«‹æ³¨æ„ï¼Œå‡ºæ–¼å¯ä»¥å¾©ç¾çš„ç›®çš„ï¼Œæˆ‘å€‘å·²å°‡åœ¨**Dataset.shuffle()**é¸å–äº†å›ºå®šçš„éš¨æ©Ÿæ•¸ç¨®å­ã€‚ **Dataset.select()** éœ€è¦ä¸€å€‹å¯è¿­ä»£çš„ç´¢å¼•ï¼Œæ‰€ä»¥æˆ‘å€‘å·²ç¶“é€šéäº† **range(1000)** å¾éš¨æ©Ÿæ‰“äº‚çš„æ•¸æ“šé›†ä¸­é¸å–å‰ 1,000 å€‹ç¤ºä¾‹ã€‚å¾æŠ½å–çš„æ•¸æ“šä¸­ï¼Œæˆ‘å€‘å·²ç¶“å¯ä»¥çœ‹åˆ°æˆ‘å€‘æ•¸æ“šé›†çš„ä¸€äº›ç‰¹é»ï¼š

* **Unnamed: 0**é€™åˆ—çœ‹èµ·ä¾†å¾ˆåƒæ¯å€‹æ‚£è€…çš„åŒ¿å IDã€‚
* **condition** é€™åˆ—åŒ…å«æœ‰æè¿°å¥åº·ç‹€æ³çš„æ¨™ç±¤ã€‚
* è©•è«–é•·çŸ­ä¸ä¸€ï¼Œæ··åˆæœ‰ Python è¡Œåˆ†éš”ç¬¦ (**\r\n**) ä»¥åŠ HTML å­—ç¬¦ä»£ç¢¼ï¼Œå¦‚** &\#039;**ã€‚
  
è®“æˆ‘å€‘çœ‹çœ‹æˆ‘å€‘å¦‚ä½•ä½¿ç”¨ ğŸ¤— Datasets ä¾†è™•ç†é€™äº›å•é¡Œã€‚ç‚ºäº†é©—è­‰**Unnamed: 0** åˆ—å­˜å„²çš„æ˜¯æ‚£è€… IDçš„çŒœæƒ³ï¼Œæˆ‘å€‘å¯ä»¥ä½¿ç”¨ **Dataset.unique()** å‡½æ•¸ä¾†é©—è­‰åŒ¿åID çš„æ•¸é‡æ˜¯å¦èˆ‡æ‹†åˆ†å¾Œæ¯éƒ¨åˆ†ä¸­çš„è¡Œæ•¸åŒ¹é…ï¼š

```py
for split in drug_dataset.keys():
    assert len(drug_dataset[split]) == len(drug_dataset[split].unique("Unnamed: 0"))
```

é€™ä¼¼ä¹è­‰å¯¦äº†æˆ‘å€‘çš„å‡è¨­ï¼Œæ‰€ä»¥è®“æˆ‘å€‘æŠŠ **Unnamed: 0** åˆ—é‡å‘½åç‚ºæ‚£è€…çš„idã€‚æˆ‘å€‘å¯ä»¥ä½¿ç”¨ **DatasetDict.rename_column()**å‡½æ•¸ä¸€æ¬¡æ€§é‡å‘½åDatasetDictä¸­å…±æœ‰çš„åˆ—ï¼š

```py
drug_dataset = drug_dataset.rename_column(
    original_column_name="Unnamed: 0", new_column_name="patient_id"
)
drug_dataset
```

```python out
DatasetDict({
    train: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],
        num_rows: 161297
    })
    test: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],
        num_rows: 53766
    })
})
```

<Tip>

âœï¸ **è©¦è©¦çœ‹ï¼** ä½¿ç”¨ `Dataset.unique()` å‡½æ•¸æŸ¥æ‰¾è¨“ç·´å’Œæ¸¬è©¦é›†ä¸­æ»¿è¶³æŸå€‹æ¢ä»¶çš„è—¥ç‰©ç¶“éå»é‡ä¹‹å¾Œçš„æ•¸é‡ã€‚

</Tip>

æ¥ä¸‹ä¾†ï¼Œè®“æˆ‘å€‘ä½¿ç”¨ **Dataset.map()**æ¨™æº–åŒ–æ‰€æœ‰ **condition** æ¨™ç±¤ .æ­£å¦‚æˆ‘å€‘åœ¨[ç¬¬ä¸‰ç« ](/course/chapter3)ä¸­æ‰€åšçš„é‚£æ¨£ï¼Œæˆ‘å€‘å¯ä»¥å®šç¾©ä¸€å€‹ç°¡å–®çš„å‡½æ•¸ï¼Œå¯ä»¥å°‡è©²å‡½æ•¸æ‡‰ç”¨æ–¼**drug_dataset** æ‹†åˆ†å¾Œæ¯éƒ¨åˆ†çš„æ‰€æœ‰è¡Œï¼š

```py
def lowercase_condition(example):
    return {"condition": example["condition"].lower()}


drug_dataset.map(lowercase_condition)
```

```python out
AttributeError: 'NoneType' object has no attribute 'lower'
```

å“¦ä¸ï¼Œæˆ‘å€‘çš„mapåŠŸèƒ½é‡åˆ°äº†å•é¡Œï¼å¾éŒ¯èª¤ä¸­æˆ‘å€‘å¯ä»¥æ¨æ–·å‡º **condition** åˆ—å­˜åœ¨ **None** , ä¸èƒ½è½‰æ›ç‚ºå°å¯«ï¼Œå› ç‚ºå®ƒå€‘ä¸æ˜¯å­—ç¬¦ä¸²ã€‚è®“æˆ‘å€‘ä½¿ç”¨ **Dataset.filter()** åˆªé™¤é€™äº›è¡Œ ï¼Œå…¶å·¥ä½œæ–¹å¼é¡ä¼¼æ–¼ **Dataset.map()** ã€‚ä¾‹å¦‚ï¼š

```py
def filter_nones(x):
    return x["condition"] is not None
```

ç„¶å¾Œé‹è¡Œ **drug_dataset.filter(filter_nones)** ï¼Œæˆ‘å€‘å¯ä»¥åœ¨ä¸€è¡Œä¸­ä½¿ç”¨lambda å‡½æ•¸.åœ¨ Python ä¸­ï¼Œlambda å‡½æ•¸æ˜¯æ‚¨ç„¡éœ€æ˜ç¢ºå‘½åå³å¯ä½¿ç”¨çš„å¾®å‡½æ•¸ï¼ˆåŒ¿åå‡½æ•¸ï¼‰ã€‚å®ƒå€‘ä¸€èˆ¬æ¡ç”¨å¦‚ä¸‹å½¢å¼ï¼š

```
lambda <arguments> : <expression>
```

å…¶ä¸­**lambda** æ˜¯ Python çš„ç‰¹æ®Š[é—œéµå­—](https://docs.python.org/3/reference/lexical_analysis.html#keywords), **arguments** æ˜¯ä»¥é€—è™Ÿé€²è¡Œåˆ†éš”çš„å‡½æ•¸è¼¸å…¥çš„åˆ—è¡¨/é›†åˆï¼Œ **expression** ä»£è¡¨æ‚¨å¸Œæœ›åŸ·è¡Œçš„æ“ä½œã€‚ä¾‹å¦‚ï¼Œæˆ‘å€‘å¯ä»¥å®šç¾©ä¸€å€‹ç°¡å–®çš„ lambda å‡½æ•¸ä¾†å°ä¸€å€‹æ•¸å­—é€²è¡Œå¹³æ–¹ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```
lambda x : x * x
```

æˆ‘å€‘éœ€è¦å°‡è¦è¼¸å…¥çµ¦é€™å€‹å‡½æ•¸å€¼æ‹¬åœ¨æ‹¬è™Ÿä¸­ï¼š

```py
(lambda x: x * x)(3)
```

```python out
9
```

é¡ä¼¼åœ°ï¼Œæˆ‘å€‘å¯ä»¥é€šéç”¨é€—è™Ÿåˆ†éš”å¤šå€‹åƒæ•¸ä¾†å®šç¾© lambda å‡½æ•¸ã€‚ä¾‹å¦‚ï¼Œæˆ‘å€‘å¯ä»¥æŒ‰å¦‚ä¸‹æ–¹å¼è¨ˆç®—ä¸‰è§’å½¢çš„é¢ç©ï¼š

```py
(lambda base, height: 0.5 * base * height)(4, 8)
```

```python out
16.0
```

ç•¶æ‚¨æƒ³å®šç¾©å°å‹ã€ä¸€æ¬¡æ€§ä½¿ç”¨çš„å‡½æ•¸æ™‚ï¼ŒLambda å‡½æ•¸éå¸¸æ–¹ä¾¿ï¼ˆæœ‰é—œå®ƒå€‘çš„æ›´å¤šä¿¡æ¯ï¼Œæˆ‘å€‘å»ºè­°é–±è®€å®‰å¾·çƒˆÂ·å¸ƒçˆ¾é«˜å¯«çš„[çœŸæ­£çš„Pythonæ•™ç¨‹](https://realpython.com/python-lambda/)ï¼‰ã€‚åœ¨ğŸ¤— Datasets ä¸­ï¼Œæˆ‘å€‘å¯ä»¥ä½¿ç”¨ lambda å‡½æ•¸ä¾†å®šç¾©ç°¡å–®çš„æ˜ å°„å’Œéæ¿¾æ“ä½œï¼Œæ‰€ä»¥è®“æˆ‘å€‘ä½¿ç”¨é€™å€‹æŠ€å·§ä¾†æ¶ˆé™¤æˆ‘å€‘æ•¸æ“šé›†ä¸­çš„ **None** æ¢ç›®ï¼š

```py
drug_dataset = drug_dataset.filter(lambda x: x["condition"] is not None)
```

ç•¶ **None** æ¢ç›®å·²åˆªé™¤ï¼Œæˆ‘å€‘å¯ä»¥æ¨™æº–åŒ–æˆ‘å€‘çš„ **condition** åˆ—ï¼š

```py
drug_dataset = drug_dataset.map(lowercase_condition)
# Check that lowercasing worked
drug_dataset["train"]["condition"][:3]
```

```python out
['left ventricular dysfunction', 'adhd', 'birth control']
```

æœ‰ç”¨ï¼ç¾åœ¨æˆ‘å€‘å·²ç¶“æ¸…ç†äº†æ¨™ç±¤ï¼Œè®“æˆ‘å€‘ä¾†çœ‹çœ‹æ¸…æ´—å¾Œçš„è©•è«–æ–‡æœ¬ã€‚

## Creating new columns

æ¯ç•¶æ‚¨è™•ç†å®¢æˆ¶è©•è«–æ™‚ï¼Œä¸€å€‹å¥½çš„åšæ³•æ˜¯æª¢æŸ¥æ¯å€‹è©•è«–ä¸­çš„å­—æ•¸ã€‚è©•è«–å¯èƒ½åªæ˜¯ä¸€å€‹è©ï¼Œæ¯”å¦‚â€œå¤ªæ£’äº†ï¼â€æˆ–åŒ…å«æ•¸åƒå­—çš„å®Œæ•´æ–‡ç« ï¼Œæ ¹æ“šå¯¦éš›çš„æƒ…æ³ï¼Œæ‚¨éœ€è¦ä»¥ä¸åŒçš„æ–¹å¼è™•ç†é€™äº›æ¥µç«¯æƒ…æ³ã€‚ç‚ºäº†è¨ˆç®—æ¯æ¢è©•è«–ä¸­çš„å–®è©æ•¸ï¼Œæˆ‘å€‘å°‡ä½¿ç”¨åŸºæ–¼ç©ºæ ¼åˆ†å‰²æ¯å€‹æ–‡æœ¬çš„ç²—ç•¥æ–¹æ³•ã€‚

è®“æˆ‘å€‘å®šç¾©ä¸€å€‹ç°¡å–®çš„å‡½æ•¸ä¾†è¨ˆç®—æ¯æ¢è©•è«–ä¸­çš„å–®è©æ•¸ï¼š

```py
def compute_review_length(example):
    return {"review_length": len(example["review"].split())}
```

èˆ‡æˆ‘å€‘çš„ `lowercase_condition()` å‡½æ•¸ä¸åŒï¼Œ`compute_review_length()` è¿”å›ä¸€å€‹å­—å…¸ï¼Œå…¶éµèˆ‡æ•¸æ“šé›†ä¸­çš„åˆ—åä¹‹ä¸€ä¸å°æ‡‰ã€‚ åœ¨é€™ç¨®æƒ…æ³ä¸‹ï¼Œç•¶ `compute_review_length()` å‚³éçµ¦ `Dataset.map()` æ™‚ï¼Œå®ƒå°‡æ‡‰ç”¨æ–¼æ•¸æ“šé›†ä¸­çš„æ‰€æœ‰è¡Œä»¥å‰µå»ºæ–°çš„ `review_length` åˆ—ï¼š

```py
drug_dataset = drug_dataset.map(compute_review_length)
# Inspect the first training example
drug_dataset["train"][0]
```

```python out
{'patient_id': 206461,
 'drugName': 'Valsartan',
 'condition': 'left ventricular dysfunction',
 'review': '"It has no side effect, I take it in combination of Bystolic 5 Mg and Fish Oil"',
 'rating': 9.0,
 'date': 'May 20, 2012',
 'usefulCount': 27,
 'review_length': 17}
```

æ­£å¦‚é æœŸçš„é‚£æ¨£ï¼Œæˆ‘å€‘å¯ä»¥çœ‹åˆ°ä¸€å€‹ **review_length** åˆ—å·²æ·»åŠ åˆ°æˆ‘å€‘çš„è¨“ç·´é›†ä¸­ã€‚æˆ‘å€‘å¯ä»¥ä½¿ç”¨ **Dataset.sort()**å°é€™å€‹æ–°åˆ—é€²è¡Œæ’åºï¼Œç„¶å¾ŒæŸ¥çœ‹æ¥µç«¯é•·åº¦çš„è©•è«–çš„æ¨£å­ï¼š

```py
drug_dataset["train"].sort("review_length")[:3]
```

```python out
{'patient_id': [103488, 23627, 20558],
 'drugName': ['Loestrin 21 1 / 20', 'Chlorzoxazone', 'Nucynta'],
 'condition': ['birth control', 'muscle spasm', 'pain'],
 'review': ['"Excellent."', '"useless"', '"ok"'],
 'rating': [10.0, 1.0, 6.0],
 'date': ['November 4, 2008', 'March 24, 2017', 'August 20, 2016'],
 'usefulCount': [5, 2, 10],
 'review_length': [1, 1, 1]}
```

æ­£å¦‚æˆ‘å€‘æ‰€çŒœæƒ³çš„é‚£æ¨£ï¼Œä¸€äº›è©•è«–åªåŒ…å«ä¸€å€‹è©ï¼Œé›–ç„¶é€™å°æ–¼æƒ…æ„Ÿåˆ†æä¾†èªªå¯èƒ½æ²’å•é¡Œï¼Œä½†å¦‚æœæˆ‘å€‘æƒ³è¦é æ¸¬ç—…æƒ…ï¼Œé€™äº›è©•è«–å¯èƒ½ä¸¦ä¸é©åˆã€‚

<Tip>

ğŸ™‹å‘æ•¸æ“šé›†æ·»åŠ æ–°åˆ—çš„å¦ä¸€ç¨®æ–¹æ³•æ˜¯ä½¿ç”¨å‡½æ•¸Dataset.add_column() ã€‚é€™å…è¨±æ‚¨è¼¸å…¥Python åˆ—è¡¨æˆ– NumPyï¼Œåœ¨ä¸é©åˆä½¿ç”¨Dataset.map()æƒ…æ³ä¸‹å¯ä»¥å¾ˆæ–¹ä¾¿ã€‚

</Tip>

è®“æˆ‘å€‘ä½¿ç”¨ **Dataset.filter()** åŠŸèƒ½ä¾†åˆªé™¤åŒ…å«å°‘æ–¼ 30 å€‹å–®è©çš„è©•è«–ã€‚èˆ‡æˆ‘å€‘å° **condition** åˆ—çš„è™•ç†ç›¸ä¼¼ï¼Œæˆ‘å€‘å¯ä»¥é€šéé¸å–è©•è«–çš„é•·åº¦é«˜æ–¼æ­¤é–¾å€¼ä¾†éæ¿¾æ‰éå¸¸çŸ­çš„è©•è«–ï¼š

```py
drug_dataset = drug_dataset.filter(lambda x: x["review_length"] > 30)
print(drug_dataset.num_rows)
```

```python out
{'train': 138514, 'test': 46108}
```

å¦‚æ‚¨æ‰€è¦‹ï¼Œé€™å·²ç¶“å¾æˆ‘å€‘çš„åŸå§‹è¨“ç·´å’Œæ¸¬è©¦é›†ä¸­åˆªé™¤äº†å¤§ç´„ 15% çš„è©•è«–ã€‚

<Tip>

âœï¸ è©¦è©¦çœ‹ï¼ä½¿ç”¨ Dataset.sort() å‡½æ•¸æŸ¥çœ‹å–®è©æ•¸æœ€å¤šçš„è©•è«–ã€‚è«‹åƒé–±æ–‡æª”ä»¥ç­è§£æ‚¨éœ€è¦ä½¿ç”¨å“ªå€‹åƒæ•¸æŒ‰é•·åº¦é™åºå°è©•è«–é€²è¡Œæ’åºã€‚

</Tip>

æˆ‘å€‘éœ€è¦è™•ç†çš„æœ€å¾Œä¸€ä»¶äº‹æ˜¯è©•è«–ä¸­æ˜¯å¦å­˜åœ¨ HTML å­—ç¬¦ä»£ç¢¼ã€‚æˆ‘å€‘å¯ä»¥ä½¿ç”¨ Python çš„**html**æ¨¡å¡Šå–æ¶ˆé€™äº›å­—ç¬¦çš„è½‰ç¾©ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```py
import html

text = "I&#039;m a transformer called BERT"
html.unescape(text)
```

```python out
"I'm a transformer called BERT"
```

æˆ‘å€‘å°‡ä½¿ç”¨ **Dataset.map()** å°æˆ‘å€‘èªæ–™åº«ä¸­çš„æ‰€æœ‰ HTML å­—ç¬¦é€²è¡Œè½‰ç¾©ï¼š

```python
drug_dataset = drug_dataset.map(lambda x: {"review": html.unescape(x["review"])})
```

å¦‚æ‚¨æ‰€è¦‹ï¼Œ **Dataset.map()** æ–¹æ³•å°æ–¼è™•ç†æ•¸æ“šéå¸¸æœ‰ç”¨â€”â€”åœ¨ç¤ºä¾‹ä¸­åƒ…åƒ…æ˜¯æ·ºå˜—è¼’æ­¢å°±æœ‰å¾ˆå¤§çš„æ”¶ç©«ï¼

## map() æ–¹æ³•çš„è¶…ç´šåŠ é€Ÿ

**Dataset.map()** æ–¹æ³•æœ‰ä¸€å€‹ **batched** åƒæ•¸ï¼Œå¦‚æœè¨­ç½®ç‚º **True** , map å‡½æ•¸å°‡æœƒåˆ†æ‰¹åŸ·è¡Œæ‰€éœ€è¦é€²è¡Œçš„æ“ä½œï¼ˆæ‰¹é‡å¤§å°æ˜¯å¯é…ç½®çš„ï¼Œä½†é»˜èªç‚º 1,000ï¼‰ã€‚ä¾‹å¦‚ï¼Œä¹‹å‰å°æ‰€æœ‰ HTML é€²è¡Œè½‰ç¾©çš„ map å‡½æ•¸é‹è¡Œéœ€è¦ä¸€äº›æ™‚é–“ï¼ˆæ‚¨å¯ä»¥å¾é€²åº¦æ¢ä¸­è®€å–æ‰€ç”¨æ™‚é–“ï¼‰ã€‚æˆ‘å€‘å¯ä»¥é€šéä½¿ç”¨åˆ—è¡¨æ¨å°åŒæ™‚è™•ç†å¤šå€‹å…ƒç´ ä¾†åŠ å¿«é€Ÿåº¦ã€‚

ç•¶æ‚¨åœ¨ä½¿ç”¨ **Dataset.map()**å‡½æ•¸æ™‚æŒ‡å®š **batched=True**ã€‚è©²å‡½æ•¸æœƒæ¥æ”¶ä¸€å€‹åŒ…å«æ•¸æ“šé›†å­—æ®µçš„å­—å…¸ï¼Œæ¯å€‹å€¼éƒ½æ˜¯ä¸€å€‹åˆ—è¡¨ï¼Œè€Œä¸åƒ…åƒ…æ˜¯å–®å€‹å€¼ã€‚**Dataset.map()** çš„è¿”å›å€¼æ‡‰è©²æ˜¯ç›¸åŒçš„ï¼šä¸€å€‹åŒ…å«æˆ‘å€‘æƒ³è¦æ›´æ–°æˆ–æ·»åŠ åˆ°æ•¸æ“šé›†ä¸­çš„å­—æ®µçš„å­—å…¸ï¼Œå­—å…¸çš„éµæ˜¯è¦æ·»åŠ çš„å­—æ®µï¼Œå­—å…¸çš„å€¼æ˜¯çµæœçš„åˆ—è¡¨ã€‚ä¾‹å¦‚ï¼Œé€™æ˜¯ä½¿ç”¨ **batched=True**å°æ‰€æœ‰ HTML å­—ç¬¦é€²è¡Œè½‰ç¾©çš„æ–¹æ³• ï¼š

```python
new_drug_dataset = drug_dataset.map(
    lambda x: {"review": [html.unescape(o) for o in x["review"]]}, batched=True
)
```

å¦‚æœæ‚¨åœ¨ç­†è¨˜æœ¬ä¸­é‹è¡Œæ­¤ä»£ç¢¼ï¼Œæ‚¨æœƒçœ‹åˆ°æ­¤å‘½ä»¤çš„åŸ·è¡Œé€Ÿåº¦æ¯”å‰ä¸€å€‹å‘½ä»¤å¿«å¾—å¤šã€‚é€™ä¸æ˜¯å› ç‚ºæˆ‘å€‘çš„è©•è«–å·²ç¶“æ˜¯è™•ç†éçš„â€”â€”å¦‚æœä½ é‡æ–°åŸ·è¡Œä¸Šä¸€ç¯€çš„æŒ‡ä»¤ï¼ˆæ²’æœ‰ **batched=True** )ï¼Œå®ƒå°‡èŠ±è²»èˆ‡ä»¥å‰ç›¸åŒçš„æ™‚é–“ã€‚é€™æ˜¯å› ç‚ºåˆ—è¡¨æ¨å°å¼é€šå¸¸æ¯”åœ¨åŒä¸€ä»£ç¢¼ä¸­ç”¨ **for** å¾ªç’°åŸ·è¡Œç›¸åŒçš„ä»£ç¢¼æ›´å¿«ï¼Œä¸¦ä¸”æˆ‘å€‘é‚„é€šéåŒæ™‚è¨ªå•å¤šå€‹å…ƒç´ è€Œä¸æ˜¯ä¸€å€‹ä¸€å€‹ä¾†è™•ç†ä¾†æé«˜è™•ç†çš„é€Ÿåº¦ã€‚

åœ¨[ç¬¬å…­ç« ](/course/chapter6)æˆ‘å€‘å°‡é‡åˆ°çš„â€œå¿«é€Ÿâ€æ¨™è¨˜å™¨ï¼Œå®ƒå¯ä»¥å¿«é€Ÿæ¨™è¨˜å¤§æ–‡æœ¬åˆ—è¡¨ã€‚ä½¿ç”¨ **Dataset.map()** å’Œ **batched=True** æ˜¯åŠ é€Ÿçš„é—œéµã€‚ä¾‹å¦‚ï¼Œè¦ä½¿ç”¨å¿«é€Ÿæ¨™è¨˜å™¨æ¨™è¨˜æ‰€æœ‰è—¥ç‰©è©•è«–ï¼Œæˆ‘å€‘å¯ä»¥ä½¿ç”¨é€™æ¨£çš„å‡½æ•¸ï¼š

```python
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")


def tokenize_function(examples):
    return tokenizer(examples["review"], truncation=True)
```

æ­£å¦‚ä½ åœ¨[ç¬¬ä¸‰ç« ](/course/chapter3)æ‰€çœ‹åˆ°çš„ï¼Œæˆ‘å€‘åŸæœ¬å°±å¯ä»¥å°‡ä¸€å€‹æˆ–å¤šå€‹ç¤ºä¾‹å‚³éçµ¦åˆ†è©å™¨ï¼Œå› æ­¤åœ¨**batched=True**æ˜¯ä¸€å€‹éå¿…é ˆçš„é¸é ….è®“æˆ‘å€‘è—‰æ­¤æ©Ÿæœƒæ¯”è¼ƒä¸åŒé¸é …çš„æ€§èƒ½ã€‚åœ¨ç­†è¨˜æœ¬ä¸­ï¼Œæ‚¨å¯ä»¥åœ¨æ‚¨è¦æ¸¬é‡çš„ä»£ç¢¼è¡Œä¹‹å‰æ·»åŠ  **%time**ä¾†æ¸¬è©¦æ”¹è¡Œé‹è¡Œæ‰€æ¶ˆè€—çš„æ™‚é–“ï¼š

```python no-format
%time tokenized_dataset = drug_dataset.map(tokenize_function, batched=True)
```

æ‚¨é‚„å¯ä»¥é€šéå°‡æ•´å€‹å–®å…ƒæ ¼è¨ˆæ™‚ **%%time** åœ¨å–®å…ƒæ ¼çš„é–‹é ­ã€‚åœ¨æˆ‘å€‘åŸ·è¡Œæ­¤æ“ä½œçš„ç¡¬ä»¶ä¸Šï¼Œè©²æŒ‡ä»¤é¡¯ç¤º 10.8 ç§’ï¼ˆé€™æ˜¯å¯«åœ¨â€œWall timeâ€ä¹‹å¾Œçš„æ•¸å­—ï¼‰ã€‚

<Tip>

âœï¸ **è©¦è©¦çœ‹ï¼** ä½¿ç”¨å’Œä¸ä½¿ç”¨ `batched=True` åŸ·è¡Œç›¸åŒçš„æŒ‡ä»¤ï¼Œç„¶å¾Œä½¿ç”¨æ…¢é€Ÿæ¨™è¨˜å™¨å˜—è©¦ï¼ˆåœ¨ `AutoTokenizer.from_pretrained()` æ–¹æ³•ä¸­æ·»åŠ  `use_fast=False`ï¼‰ï¼Œé€™æ¨£ä½ å°±å¯ä»¥çœ‹çœ‹åœ¨ä½ çš„é›»è…¦ä¸Šå®ƒéœ€è¦å¤šé•·çš„æ™‚é–“ã€‚

</Tip>

ä»¥ä¸‹æ˜¯æˆ‘å€‘åœ¨ä½¿ç”¨å’Œä¸ä½¿ç”¨æ‰¹è™•ç†æ™‚ä½¿ç”¨å¿«é€Ÿå’Œæ…¢é€Ÿåˆ†è©å™¨ç²å¾—çš„çµæœï¼š

Options         | Fast tokenizer | Slow tokenizer
:--------------:|:--------------:|:-------------:
`batched=True`  | 10.8s          | 4min41s
`batched=False` | 59.2s          | 5min3s

é€™æ„å‘³è‘—ä½¿ç”¨å¸¶æœ‰ **batched=True** é¸é …æ¯”æ²’æœ‰æ‰¹è™•ç†çš„æ…¢é¸é …å¿« 30 å€â€”â€”é€™çœŸæ˜¯å¤ªæ£’äº†ï¼é€™å°±æ˜¯ç‚ºä»€éº¼**AutoTokenizer** çš„é»˜èªè¨­ç½®æ˜¯**use_fast=True**çš„ä¸»è¦åŸå›  ï¼ˆä»¥åŠç‚ºä»€éº¼å®ƒå€‘è¢«ç¨±ç‚ºâ€œå¿«é€Ÿâ€ï¼‰ã€‚ä»–å€‘èƒ½å¤ å¯¦ç¾é€™æ¨£çš„åŠ é€Ÿï¼Œå› ç‚ºåœ¨åº•å±¤çš„æ¨™è¨˜åŒ–ä»£ç¢¼æ˜¯åœ¨ Rust ä¸­åŸ·è¡Œçš„ï¼ŒRust æ˜¯ä¸€ç¨®å¯ä»¥è¼•é¬†ä¸¦è¡ŒåŒ–åŸ·è¡Œçš„èªè¨€ã€‚

ä¸¦è¡ŒåŒ–ä¹Ÿæ˜¯å¿«é€Ÿæ¨™è¨˜å™¨é€šéæ‰¹è™•ç†å¯¦ç¾è¿‘ 6 å€åŠ é€Ÿçš„åŸå› ï¼šå–®å€‹æ¨™è¨˜åŒ–æ“ä½œæ˜¯ä¸èƒ½ä¸¦è¡Œçš„ï¼Œä½†æ˜¯ç•¶æ‚¨æƒ³åŒæ™‚æ¨™è¨˜å¤§é‡æ–‡æœ¬æ™‚ï¼Œæ‚¨å¯ä»¥å°‡åŸ·è¡Œæ‹†åˆ†ç‚ºå¤šå€‹é€²ç¨‹ï¼Œæ¯å€‹é€²ç¨‹éƒ½å°è‡ªå·±çš„æ–‡æœ¬è² è²¬ã€‚

**Dataset.map()** ä¹Ÿæœ‰ä¸€äº›è‡ªå·±çš„ä¸¦è¡ŒåŒ–èƒ½åŠ›ã€‚ç”±æ–¼å®ƒå€‘ä¸å— Rust çš„æ”¯æŒï¼Œå› æ­¤æ…¢é€Ÿåˆ†è©å™¨çš„é€Ÿåº¦è¶•ä¸ä¸Šå¿«é€Ÿåˆ†è©å™¨ï¼Œä½†å®ƒå€‘ä»ç„¶æœƒæ›´å¿«ä¸€äº›ï¼ˆå°¤å…¶æ˜¯ç•¶æ‚¨ä½¿ç”¨æ²’æœ‰å¿«é€Ÿç‰ˆæœ¬çš„åˆ†è©å™¨æ™‚ï¼‰ã€‚è¦å•Ÿç”¨å¤šè™•ç†ï¼Œè«‹åœ¨**Dataset.map()**æ™‚ä½¿ç”¨ **num_proc** åƒæ•¸ä¸¦æŒ‡å®šè¦åœ¨èª¿ç”¨ä¸­ä½¿ç”¨çš„é€²ç¨‹æ•¸ ï¼š

```py
slow_tokenizer = AutoTokenizer.from_pretrained("bert-base-cased", use_fast=False)


def slow_tokenize_function(examples):
    return slow_tokenizer(examples["review"], truncation=True)


tokenized_dataset = drug_dataset.map(slow_tokenize_function, batched=True, num_proc=8)
```

æ‚¨å¯ä»¥å°è™•ç†çš„æ™‚é–“é€²è¡Œä¸€äº›è©¦é©—ï¼Œä»¥ç¢ºå®šè¦ä½¿ç”¨çš„æœ€ä½³é€²ç¨‹æ•¸ï¼›åœ¨æˆ‘å€‘çš„ä¾‹å­ä¸­ï¼Œ8 ä¼¼ä¹ç”¢ç”Ÿäº†æœ€å¥½çš„é€Ÿåº¦å¢ç›Šã€‚ä»¥ä¸‹æ˜¯æˆ‘å€‘åœ¨ä½¿ç”¨å’Œä¸ä½¿ç”¨å¤šè™•ç†æ™‚æ‰€éœ€è¦çš„æ™‚é–“ï¼š

Options         | Fast tokenizer | Slow tokenizer
:--------------:|:--------------:|:-------------:
`batched=True`  | 10.8s          | 4min41s
`batched=False` | 59.2s          | 5min3s
`batched=True`, `num_proc=8`  | 6.52s          | 41.3s
`batched=False`, `num_proc=8` | 9.49s          | 45.2s

å°æ–¼æ…¢é€Ÿåˆ†è©å™¨ä¾†èªªï¼Œé€™äº›çµæœè¦åˆç†å¾—å¤šï¼Œä½†å¿«é€Ÿåˆ†è©å™¨çš„æ€§èƒ½ä¹Ÿå¾—åˆ°äº†é¡¯è‘—æé«˜ã€‚ä½†æ˜¯è«‹æ³¨æ„ï¼Œæƒ…æ³ä¸¦éç¸½æ˜¯å¦‚æ­¤â€”â€”é™¤äº† **num_proc=8**ï¼Œæˆ‘å€‘çš„æ¸¬è©¦è¡¨æ˜ï¼Œä½¿ç”¨**batched=True**è€Œä¸å¸¶æœ‰**num_proc**åƒæ•¸çš„é¸é …è™•ç†èµ·ä¾†æ›´å¿«ã€‚é€šå¸¸ï¼Œæˆ‘å€‘ä¸å»ºè­°å°‡ Python å¤šç·šç¨‹è™•ç†ç”¨æ–¼å…·æœ‰**batched=True**åŠŸèƒ½çš„å¿«é€Ÿæ¨™è¨˜å™¨  .

<Tip>

ä½¿ç”¨num_procä»¥åŠ å¿«è™•ç†é€Ÿåº¦é€šå¸¸æ˜¯ä¸€å€‹å¥½ä¸»æ„ï¼Œåªè¦æ‚¨ä½¿ç”¨çš„å‡½æ•¸é‚„æ²’æœ‰è‡ªå·±å¸¶æœ‰çš„é€²è¡ŒæŸç¨®å¤šé€²ç¨‹è™•ç†çš„æ–¹æ³•ã€‚

</Tip>

å°‡æ‰€æœ‰é€™äº›åŠŸèƒ½æ¿ƒç¸®åˆ°ä¸€å€‹æ–¹æ³•ä¸­å·²ç¶“éå¸¸äº†ä¸èµ·ï¼Œä½†é‚„æœ‰æ›´å¤šï¼ä½¿ç”¨ **Dataset.map()** å’Œ **batched=True** æ‚¨å¯ä»¥æ›´æ”¹æ•¸æ“šé›†ä¸­çš„å…ƒç´ æ•¸é‡ã€‚ç•¶ä½ æƒ³å¾ä¸€å€‹ä¾‹å­ä¸­å‰µå»ºå¹¾å€‹è¨“ç·´ç‰¹å¾µæ™‚ï¼Œé€™æ˜¯éå¸¸æœ‰ç”¨çš„ã€‚æˆ‘å€‘å°‡åœ¨[ç¬¬ä¸ƒç« ](/course/chapter7).ä¸­é€²è¡Œçš„å¹¾å€‹NLPä»»å‹™çš„é è™•ç†ä¸­ä½¿ç”¨åˆ°é€™å€‹åŠŸèƒ½ï¼Œå®ƒéå¸¸ä¾¿åˆ©ã€‚

<Tip>

ğŸ’¡åœ¨æ©Ÿå™¨å­¸ç¿’ä¸­ï¼Œä¸€å€‹ä¾‹å­é€šå¸¸å¯ä»¥ç‚ºæˆ‘å€‘çš„æ¨¡å‹æä¾›ä¸€çµ„ç‰¹å¾µã€‚åœ¨æŸäº›æƒ…æ³ä¸‹ï¼Œé€™äº›ç‰¹å¾µæœƒå„²å­˜åœ¨æ•¸æ“šé›†çš„å¹¾å€‹åˆ—ï¼Œä½†åœ¨å…¶ä»–æƒ…æ³ä¸‹ï¼ˆä¾‹å¦‚æ­¤è™•çš„ä¾‹å­å’Œç”¨æ–¼å•ç­”çš„æ•¸æ“šï¼‰ï¼Œå¯ä»¥å¾å–®å€‹ç¤ºä¾‹çš„ä¸€åˆ—ä¸­æå–å¤šå€‹ç‰¹å¾µ

</Tip>

è®“æˆ‘å€‘ä¾†çœ‹çœ‹å®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼åœ¨é€™è£¡ï¼Œæˆ‘å€‘å°‡æ¨™è¨˜åŒ–æˆ‘å€‘çš„ç¤ºä¾‹ä¸¦å°‡æœ€å¤§æˆªæ–·é•·åº¦è¨­ç½®128ï¼Œä½†æˆ‘å€‘å°‡è¦æ±‚æ¨™è¨˜å™¨è¿”å›å…¨éƒ¨æ–‡æœ¬å¡Šï¼Œè€Œä¸åƒ…åƒ…æ˜¯ç¬¬ä¸€å€‹ã€‚é€™å¯ä»¥ç”¨ **return_overflowing_tokens=True** ï¼š

```py
def tokenize_and_split(examples):
    return tokenizer(
        examples["review"],
        truncation=True,
        max_length=128,
        return_overflowing_tokens=True,
    )
```

åœ¨ä½¿ç”¨**Dataset.map()** æ­£å¼åœ¨æ•´å€‹æ•¸æ“šé›†ä¸Šé–‹å§‹è™•ç†ä¹‹å‰è®“æˆ‘å€‘å…ˆåœ¨ä¸€å€‹ä¾‹å­ä¸Šæ¸¬è©¦ä¸€ä¸‹ï¼š

```py
result = tokenize_and_split(drug_dataset["train"][0])
[len(inp) for inp in result["input_ids"]]
```

```python out
[128, 49]
```

ç§ï¼æˆ‘å€‘åœ¨è¨“ç·´é›†ä¸­çš„ç¬¬ä¸€å€‹ç¤ºä¾‹è®Šæˆäº†å…©å€‹ç‰¹å¾µï¼Œå› ç‚ºå®ƒè¢«æ¨™è¨˜ç‚ºè¶…éæˆ‘å€‘æŒ‡å®šçš„æœ€å¤§æˆªæ–·é•·åº¦ï¼Œå› æ­¤çµæœè¢«æˆªæˆäº†å…©æ®µï¼šç¬¬ä¸€æ®µé•·åº¦ç‚º 128 ï¼Œç¬¬äºŒæ®µé•·åº¦ç‚º 49 ã€‚ç¾åœ¨è®“æˆ‘å€‘å°æ‰€æœ‰å…ƒç´ åŸ·è¡Œæ­¤æ“ä½œæ•¸æ“šé›†ï¼

```py
tokenized_dataset = drug_dataset.map(tokenize_and_split, batched=True)
```

```python out
ArrowInvalid: Column 1 named condition expected length 1463 but got length 1000
```

ä¸å¥½äº†ï¼å®ƒæ²’æœ‰èµ·ä½œç”¨ï¼ç‚ºä»€éº¼å‘¢ï¼ŸæŸ¥çœ‹éŒ¯èª¤æ¶ˆæ¯æœƒçµ¦æˆ‘å€‘ä¸€å€‹ç·šç´¢ï¼šåˆ—çš„é•·åº¦ä¸åŒ¹é…ï¼Œä¸€åˆ—é•·åº¦ç‚º 1,463ï¼Œå¦ä¸€åˆ—é•·åº¦ç‚º 1,000ã€‚1,000è¡Œçš„"review"çµ¦å‡ºäº† 1,463 è¡Œçš„æ–°ç‰¹å¾µï¼Œå°è‡´å’ŒåŸæœ¬çš„1000è¡Œæ•¸æ“šä¸åŒ¹é…ã€‚

å•é¡Œå‡ºåœ¨æˆ‘å€‘è©¦åœ–æ··åˆå…©å€‹ä¸åŒå¤§å°çš„ä¸åŒæ•¸æ“šé›†ï¼š **drug_dataset** åˆ—å°‡æœ‰ä¸€å®šæ•¸é‡çš„å…ƒç´ ï¼ˆæˆ‘å€‘éŒ¯èª¤ä¸­çš„ 1,000ï¼‰ï¼Œä½†æ˜¯æˆ‘å€‘æ­£åœ¨æ§‹å»º**tokenized_dataset** å°‡æœ‰æ›´å¤šçš„å…ƒç´ ï¼ˆéŒ¯èª¤æ¶ˆæ¯ä¸­çš„ 1,463ï¼‰ã€‚é€™ä¸é©ç”¨æ–¼ **Dataset** ï¼Œå› æ­¤æˆ‘å€‘éœ€è¦å¾èˆŠæ•¸æ“šé›†ä¸­åˆªé™¤åˆ—æˆ–ä½¿å®ƒå€‘çš„å¤§å°èˆ‡æ–°æ•¸æ“šé›†ä¸­çš„å¤§å°ç›¸åŒã€‚æˆ‘å€‘å¯ä»¥ç”¨ **remove_columns** åƒæ•¸ï¼š

```py
tokenized_dataset = drug_dataset.map(
    tokenize_and_split, batched=True, remove_columns=drug_dataset["train"].column_names
)
```

ç¾åœ¨é€™å€‹éç¨‹æ²’æœ‰éŒ¯èª¤ã€‚æˆ‘å€‘å¯ä»¥é€šéæ¯”è¼ƒé•·åº¦ä¾†æª¢æŸ¥æ–°æ•¸æ“šé›†çš„å…ƒç´ æ˜¯å¦æ¯”åŸå§‹æ•¸æ“šé›†å¤šå¾—å¤šï¼š

```py
len(tokenized_dataset["train"]), len(drug_dataset["train"])
```

```python out
(206772, 138514)
```

æˆ‘å€‘æåˆ°æˆ‘å€‘é‚„å¯ä»¥é€šéä½¿èˆŠåˆ—èˆ‡æ–°åˆ—çš„å¤§å°ç›¸åŒä¾†è™•ç†é•·åº¦ä¸åŒ¹é…çš„å•é¡Œã€‚ç‚ºæ­¤ï¼Œæˆ‘å€‘å¯ä»¥ä½¿ç”¨ **overflow_to_sample_mapping** å­—æ®µï¼Œç•¶æˆ‘å€‘è¨­ç½®**return_overflowing_tokens=True** .å®ƒç‚ºæˆ‘å€‘æä¾›äº†ç‰¹å¾µåˆ°å®ƒæ‰€ç”¢ç”Ÿçš„æ¨£æœ¬çš„æ˜ å°„ã€‚ä½¿ç”¨é€™å€‹ï¼Œæˆ‘å€‘å¯ä»¥å°‡åŸå§‹æ•¸æ“šé›†ä¸­çš„æ¯å€‹éµé—œè¯åˆ°ä¸€å€‹åˆé©å¤§å°çš„å€¼åˆ—è¡¨ä¸­ï¼Œé€šééæ­·æ‰€æœ‰çš„æ•¸æ“šä¾†ç”Ÿæˆæ–°ç‰¹æ€§:

```py
def tokenize_and_split(examples):
    result = tokenizer(
        examples["review"],
        truncation=True,
        max_length=128,
        return_overflowing_tokens=True,
    )
    # Extract mapping between new and old indices
    sample_map = result.pop("overflow_to_sample_mapping")
    for key, values in examples.items():
        result[key] = [values[i] for i in sample_map]
    return result
```

æˆ‘å€‘å¯ä»¥ä½¿ç”¨**Dataset.map()**ä¾†é€²è¡Œæ‰¹è™•ç†ï¼Œé€™æ¨£ç„¡éœ€æˆ‘å€‘åˆªé™¤èˆŠåˆ—ï¼š

```py
tokenized_dataset = drug_dataset.map(tokenize_and_split, batched=True)
tokenized_dataset
```

```python out
DatasetDict({
    train: Dataset({
        features: ['attention_mask', 'condition', 'date', 'drugName', 'input_ids', 'patient_id', 'rating', 'review', 'review_length', 'token_type_ids', 'usefulCount'],
        num_rows: 206772
    })
    test: Dataset({
        features: ['attention_mask', 'condition', 'date', 'drugName', 'input_ids', 'patient_id', 'rating', 'review', 'review_length', 'token_type_ids', 'usefulCount'],
        num_rows: 68876
    })
})
```

æˆ‘å€‘ç²å¾—äº†èˆ‡ä»¥å‰ç›¸åŒæ•¸é‡çš„è¨“ç·´ç‰¹å¾µï¼Œä½†åœ¨é€™è£¡æˆ‘å€‘ä¿ç•™äº†æ‰€æœ‰èˆŠå­—æ®µã€‚å¦‚æœæ‚¨åœ¨ä½¿ç”¨æ¨¡å‹è¨ˆç®—ä¹‹å¾Œéœ€è¦å®ƒå€‘é€²è¡Œä¸€äº›å¾Œè™•ç†ï¼Œæ‚¨å¯èƒ½éœ€è¦ä½¿ç”¨é€™ç¨®æ–¹æ³•ã€‚

æ‚¨ç¾åœ¨å·²ç¶“ç­è§£äº† ğŸ¤— Datasetså¦‚ä½•ä»¥å„ç¨®æ–¹å¼ç”¨æ–¼é è™•ç†æ•¸æ“šé›†ã€‚é›–ç„¶ğŸ¤— Datasets çš„è™•ç†åŠŸèƒ½æœƒè¦†è“‹ä½ å¤§éƒ¨åˆ†çš„æ¨¡å‹è¨“ç·´éœ€æ±‚ï¼Œæœ‰æ™‚æ‚¨å¯èƒ½éœ€è¦åˆ‡æ›åˆ° Pandas ä»¥ä½¿ç”¨æ›´å¼·å¤§çš„åŠŸèƒ½ï¼Œä¾‹å¦‚ **DataFrame.groupby()** æˆ–ç”¨æ–¼å¯è¦–åŒ–çš„é«˜ç´š APIã€‚å¹¸é‹çš„æ˜¯ï¼ŒğŸ¤— Datasetsæ—¨åœ¨èˆ‡ Pandasã€NumPyã€PyTorchã€TensorFlow å’Œ JAX ç­‰åº«å¯ä»¥ç›¸äº’è½‰æ›ã€‚è®“æˆ‘å€‘ä¾†çœ‹çœ‹é€™æ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚

## `ğŸ¤— Datasets å’Œ DataFrames çš„ç›¸äº’è½‰æ›

<Youtube id="tfcY1067A5Q"/>

ç‚ºäº†å¯¦ç¾å„ç¨®ç¬¬ä¸‰æ–¹åº«ä¹‹é–“çš„è½‰æ›ï¼ŒğŸ¤— Datasets æä¾›äº†ä¸€å€‹ **Dataset.set_format()** åŠŸèƒ½ã€‚æ­¤åŠŸèƒ½å¯ä»¥é€šéåƒ…æ›´æ”¹è¼¸å‡ºæ ¼å¼çš„ï¼Œè¼•é¬†åˆ‡æ›åˆ°å¦ä¸€ç¨®æ ¼å¼ï¼Œè€Œä¸æœƒå½±éŸ¿åº•å±¤æ•¸æ“šæ ¼å¼ï¼Œå³ Apache Arrowã€‚æ ¼å¼åŒ–æœƒåœ¨æ•¸æ“šæœ¬èº«ä¸Šé€²è¡Œã€‚ç‚ºäº†æ¼”ç¤ºï¼Œè®“æˆ‘å€‘å°‡æ•¸æ“šé›†è½‰æ›ç‚º Pandasï¼š

```py
drug_dataset.set_format("pandas")
```

ç¾åœ¨ï¼Œç•¶æˆ‘å€‘è¨ªå•æ•¸æ“šé›†çš„å…ƒç´ æ™‚ï¼Œæˆ‘å€‘æœƒå¾—åˆ°ä¸€å€‹ **pandas.DataFrame** è€Œä¸æ˜¯å­—å…¸ï¼š

```py
drug_dataset["train"][:3]
```

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>patient_id</th>
      <th>drugName</th>
      <th>condition</th>
      <th>review</th>
      <th>rating</th>
      <th>date</th>
      <th>usefulCount</th>
      <th>review_length</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>95260</td>
      <td>Guanfacine</td>
      <td>adhd</td>
      <td>"My son is halfway through his fourth week of Intuniv..."</td>
      <td>8.0</td>
      <td>April 27, 2010</td>
      <td>192</td>
      <td>141</td>
    </tr>
    <tr>
      <th>1</th>
      <td>92703</td>
      <td>Lybrel</td>
      <td>birth control</td>
      <td>"I used to take another oral contraceptive, which had 21 pill cycle, and was very happy- very light periods, max 5 days, no other side effects..."</td>
      <td>5.0</td>
      <td>December 14, 2009</td>
      <td>17</td>
      <td>134</td>
    </tr>
    <tr>
      <th>2</th>
      <td>138000</td>
      <td>Ortho Evra</td>
      <td>birth control</td>
      <td>"This is my first time using any form of birth control..."</td>
      <td>8.0</td>
      <td>November 3, 2015</td>
      <td>10</td>
      <td>89</td>
    </tr>
  </tbody>
</table>

è®“æˆ‘å€‘å‰µå»ºä¸€å€‹ **pandas.DataFrame** ä¾†é¸æ“‡ **drug_dataset[train]** çš„æ‰€æœ‰å…ƒç´ ï¼š

```py
train_df = drug_dataset["train"][:]
```

<Tip>

ğŸš¨ åœ¨åº•å±¤ï¼Œ`Dataset.set_format()` æ”¹è®Šäº†æ•¸æ“šé›†çš„ `__getitem__()` dunder æ–¹æ³•çš„è¿”å›æ ¼å¼ã€‚ é€™æ„å‘³è‘—ç•¶æˆ‘å€‘æƒ³å¾ `"pandas"` æ ¼å¼çš„ `Dataset` ä¸­å‰µå»ºåƒ `train_df` é€™æ¨£çš„æ–°å°è±¡æ™‚ï¼Œæˆ‘å€‘éœ€è¦å°æ•´å€‹æ•¸æ“šé›†é€²è¡Œåˆ‡ç‰‡ä»¥ç²å¾— `pandas.DataFrame`ã€‚ ç„¡è«–è¼¸å‡ºæ ¼å¼å¦‚ä½•ï¼Œæ‚¨éƒ½å¯ä»¥è‡ªå·±é©—è­‰ `drug_dataset["train"]` çš„é¡å‹ä¾ç„¶é‚„æ˜¯ `Dataset`ã€‚

</Tip>


å¾é€™è£¡æˆ‘å€‘å¯ä»¥ä½¿ç”¨æˆ‘å€‘æƒ³è¦çš„æ‰€æœ‰ Pandas åŠŸèƒ½ã€‚ä¾‹å¦‚ï¼Œæˆ‘å€‘å¯ä»¥é€šéèŠ±å¼éˆæ¥ä¾†è¨ˆç®— **condition**é¡ä¹‹é–“çš„åˆ†ä½ˆ ï¼š

```py
frequencies = (
    train_df["condition"]
    .value_counts()
    .to_frame()
    .reset_index()
    .rename(columns={"index": "condition", "condition": "frequency"})
)
frequencies.head()
```

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>condition</th>
      <th>frequency</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>birth control</td>
      <td>27655</td>
    </tr>
    <tr>
      <th>1</th>
      <td>depression</td>
      <td>8023</td>
    </tr>
    <tr>
      <th>2</th>
      <td>acne</td>
      <td>5209</td>
    </tr>
    <tr>
      <th>3</th>
      <td>anxiety</td>
      <td>4991</td>
    </tr>
    <tr>
      <th>4</th>
      <td>pain</td>
      <td>4744</td>
    </tr>
  </tbody>
</table>


ä¸€æ—¦æˆ‘å€‘å®Œæˆäº† Pandas åˆ†æï¼Œæˆ‘å€‘ç¸½æ˜¯é€šéä½¿ç”¨å°è±¡ **Dataset.from_pandas()**æ–¹æ³•å¯ä»¥å‰µå»ºä¸€å€‹æ–°çš„ **Dataset** å¦‚ä¸‹ï¼š


```py
from datasets import Dataset

freq_dataset = Dataset.from_pandas(frequencies)
freq_dataset
```

```python out
Dataset({
    features: ['condition', 'frequency'],
    num_rows: 819
})
```

<Tip>

âœï¸ **è©¦è©¦çœ‹ï¼** è¨ˆç®—æ¯ç¨®è—¥ç‰©çš„å¹³å‡è©•ç´šä¸¦å°‡çµæœå­˜å„²åœ¨ä¸€å€‹æ–°çš„Dataset.

</Tip>

æˆ‘å€‘å° ğŸ¤— Datasetsä¸­å¯ç”¨çš„å„ç¨®é è™•ç†æŠ€è¡“çš„ä»‹ç´¹åˆ°æ­¤çµæŸã€‚åœ¨æœ€å¾Œä¸€éƒ¨åˆ†ï¼Œè®“æˆ‘å€‘å‰µå»ºä¸€å€‹é©—è­‰é›†ä¾†æº–å‚™ç”¨æ–¼è¨“ç·´åˆ†é¡å™¨çš„æ•¸æ“šé›†ã€‚åœ¨æ­¤ä¹‹å‰ï¼Œæˆ‘å€‘å°‡è¼¸å‡ºæ ¼å¼ **drug_dataset** å¾ **pandas**é‡ç½®åˆ° **arrow** ï¼š

```python
drug_dataset.reset_format()
```

## å‰µå»ºé©—è­‰é›†

å„˜ç®¡æˆ‘å€‘æœ‰ä¸€å€‹å¯ä»¥ç”¨æ–¼è©•ä¼°çš„æ¸¬è©¦é›†ï¼Œä½†åœ¨é–‹ç™¼éç¨‹ä¸­ä¿æŒæ¸¬è©¦é›†ä¸è®Šä¸¦å‰µå»ºä¸€å€‹å–®ç¨çš„é©—è­‰é›†æ˜¯ä¸€å€‹å¾ˆå¥½çš„åšæ³•ã€‚ä¸€æ—¦æ‚¨å°æ¨¡å‹åœ¨æ¸¬è©¦é›†ä¸Šçš„è¡¨ç¾æ„Ÿåˆ°æ»¿æ„ï¼Œæ‚¨å°±å¯ä»¥å°é©—è­‰é›†é€²è¡Œæœ€çµ‚çš„æª¢æŸ¥ã€‚æ­¤éç¨‹æœ‰åŠ©æ–¼é™ä½æ‚¨éæ“¬åˆæ¸¬è©¦é›†ä¸¦éƒ¨ç½²åœ¨ç¾å¯¦ä¸–ç•Œæ•¸æ“šä¸Šå¤±æ•—çš„æ¨¡å‹çš„é¢¨éšªã€‚

ğŸ¤— Datasetsæä¾›äº†ä¸€å€‹åŸºæ–¼**scikit-learn**çš„ç¶“å…¸æ–¹æ³•**Dataset.train_test_split()** .è®“æˆ‘å€‘ç”¨å®ƒæŠŠæˆ‘å€‘çš„è¨“ç·´é›†åˆ†æˆ **train** å’Œ **validation** ï¼ˆç‚ºäº†å¯ä»¥å¾©ç¾ï¼Œæˆ‘å€‘å°‡è¨­ç½®**seed**çš„å€¼ç‚ºä¸€å€‹å¸¸é‡ï¼‰ï¼š

```py
drug_dataset_clean = drug_dataset["train"].train_test_split(train_size=0.8, seed=42)
# Rename the default "test" split to "validation"
drug_dataset_clean["validation"] = drug_dataset_clean.pop("test")
# Add the "test" set to our `DatasetDict`
drug_dataset_clean["test"] = drug_dataset["test"]
drug_dataset_clean
```

```python out
DatasetDict({
    train: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'review_clean'],
        num_rows: 110811
    })
    validation: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'review_clean'],
        num_rows: 27703
    })
    test: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'review_clean'],
        num_rows: 46108
    })
})
```

å¤ªå¥½äº†ï¼Œæˆ‘å€‘ç¾åœ¨å·²ç¶“æº–å‚™å¥½äº†ä¸€å€‹æ•¸æ“šé›†ï¼Œå¯ä»¥ç”¨ä¾†è¨“ç·´ä¸€äº›æ¨¡å‹äº†ï¼åœ¨[ç¬¬äº”ç¯€]](/course/chapter5/5)æˆ‘å€‘å°‡å‘æ‚¨å±•ç¤ºå¦‚ä½•å°‡æ•¸æ“šé›†ä¸Šå‚³åˆ° Hugging Face Hubï¼Œä½†ç¾åœ¨è®“æˆ‘å€‘æŸ¥çœ‹åœ¨æœ¬åœ°è¨ˆç®—æ©Ÿä¸Šä¿å­˜æ•¸æ“šé›†çš„å¹¾ç¨®æ–¹æ³•ã€‚

## ä¿å­˜æ•¸æ“šé›†

<Youtube id="blF9uxYcKHo"/>

é›–ç„¶ ğŸ¤— Datasets æœƒç·©å­˜æ¯å€‹ä¸‹è¼‰çš„æ•¸æ“šé›†å’Œå°å®ƒåŸ·è¡Œçš„æ“ä½œï¼Œä½†æœ‰æ™‚ä½ æœƒæƒ³è¦å°‡æ•¸æ“šé›†ä¿å­˜åˆ°ç£ç›¤ï¼ˆä¾‹å¦‚ï¼Œä»¥é˜²ç·©å­˜è¢«åˆªé™¤ï¼‰ã€‚å¦‚ä¸‹è¡¨æ‰€ç¤ºï¼ŒğŸ¤— Datasets æä¾›äº†ä¸‰å€‹ä¸»è¦åŠŸèƒ½ä¾†ä»¥ä¸åŒçš„æ ¼å¼ä¿å­˜æ‚¨çš„æ•¸æ“šé›†ï¼š

| æ•¸æ“šæ ¼å¼    |        å°æ‡‰çš„æ–¹æ³•        |
| :---------: | :--------------------: |
|    Arrow    | `Dataset.save_to_disk()` |
|     CSV     |    `Dataset.to_csv()`    |
|    JSON     |   `Dataset.to_json()`    |

ä¾‹å¦‚ï¼Œè®“æˆ‘å€‘ä»¥ Arrow æ ¼å¼ä¿å­˜æˆ‘å€‘æ¸…æ´—éçš„æ•¸æ“šé›†ï¼š

```py
drug_dataset_clean.save_to_disk("drug-reviews")
```

é€™å°‡å‰µå»ºä¸€å€‹å…·æœ‰ä»¥ä¸‹çµæ§‹çš„ç›®éŒ„ï¼š

```
drug-reviews/
â”œâ”€â”€ dataset_dict.json
â”œâ”€â”€ test
â”‚   â”œâ”€â”€ dataset.arrow
â”‚   â”œâ”€â”€ dataset_info.json
â”‚   â””â”€â”€ state.json
â”œâ”€â”€ train
â”‚   â”œâ”€â”€ dataset.arrow
â”‚   â”œâ”€â”€ dataset_info.json
â”‚   â”œâ”€â”€ indices.arrow
â”‚   â””â”€â”€ state.json
â””â”€â”€ validation
    â”œâ”€â”€ dataset.arrow
    â”œâ”€â”€ dataset_info.json
    â”œâ”€â”€ indices.arrow
    â””â”€â”€ state.json
```

åœ¨é‚£è£¡æˆ‘å€‘å¯ä»¥çœ‹åˆ°æ¯å€‹éƒ¨åˆ†.arrowè¡¨ï¼Œä»¥åŠä¸€äº›å…ƒæ•¸æ“šæ•¸æ“šé›†ä¿¡æ¯.jsonå’Œç‹€æ…‹æ–‡ä»¶ä¿å­˜åœ¨ä¸€èµ·.æ‚¨å¯ä»¥å°‡ Arrow æ ¼å¼è¦–ç‚ºä¸€å€‹ç²¾ç¾çš„åˆ—å’Œè¡Œçš„è¡¨æ ¼ï¼Œå®ƒé‡å°æ§‹å»ºè™•ç†å’Œå‚³è¼¸å¤§å‹æ•¸æ“šé›†çš„é«˜æ€§èƒ½æ‡‰ç”¨ç¨‹åºé€²è¡Œäº†å„ªåŒ–ã€‚

ä¿å­˜æ•¸æ“šé›†å¾Œï¼Œæˆ‘å€‘å¯ä»¥ä½¿ç”¨ **load_from_disk()** åŠŸèƒ½å¾ç£ç›¤è®€å–æ•¸æ“šå¦‚ä¸‹ï¼š

```py
from datasets import load_from_disk

drug_dataset_reloaded = load_from_disk("drug-reviews")
drug_dataset_reloaded
```

```python out
DatasetDict({
    train: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],
        num_rows: 110811
    })
    validation: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],
        num_rows: 27703
    })
    test: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],
        num_rows: 46108
    })
})
```

å°æ–¼ CSV å’Œ JSON æ ¼å¼ï¼Œæˆ‘å€‘å¿…é ˆå°‡æ¯å€‹éƒ¨åˆ†å­˜å„²ç‚ºå–®ç¨çš„æ–‡ä»¶ã€‚ä¸€ç¨®æ–¹æ³•æ˜¯è¿­ä»£**DatasetDict**ä¸­çš„éµå’Œå€¼ ï¼š

```py
for split, dataset in drug_dataset_clean.items():
    dataset.to_json(f"drug-reviews-{split}.jsonl")
```

é€™å°‡ä¿å­˜æ¯å€‹æ‹†åˆ†éƒ½æ˜¯[JSONçš„æ¨™æº–æ ¼å¼](https://jsonlines.org)ï¼Œå…¶ä¸­æ•¸æ“šé›†ä¸­çš„æ¯ä¸€è¡Œéƒ½å­˜å„²ç‚ºä¸€è¡Œ JSONã€‚é€™æ˜¯ç¬¬ä¸€å€‹ç¤ºä¾‹ï¼š

```py
!head -n 1 drug-reviews-train.jsonl
```

```python out
{"patient_id":141780,"drugName":"Escitalopram","condition":"depression","review":"\"I seemed to experience the regular side effects of LEXAPRO, insomnia, low sex drive, sleepiness during the day. I am taking it at night because my doctor said if it made me tired to take it at night. I assumed it would and started out taking it at night. Strange dreams, some pleasant. I was diagnosed with fibromyalgia. Seems to be helping with the pain. Have had anxiety and depression in my family, and have tried quite a few other medications that haven't worked. Only have been on it for two weeks but feel more positive in my mind, want to accomplish more in my life. Hopefully the side effects will dwindle away, worth it to stick with it from hearing others responses. Great medication.\"","rating":9.0,"date":"May 29, 2011","usefulCount":10,"review_length":125}
```

ç„¶å¾Œæˆ‘å€‘å¯ä»¥ä½¿ç”¨[ç¬¬äºŒç¯€](/course/chapter5/2)å­¸éçš„æŠ€è¡“åŠ è¼‰ JSON æ–‡ä»¶å¦‚ä¸‹ï¼š

```py
data_files = {
    "train": "drug-reviews-train.jsonl",
    "validation": "drug-reviews-validation.jsonl",
    "test": "drug-reviews-test.jsonl",
}
drug_dataset_reloaded = load_dataset("json", data_files=data_files)
```

é€™å°±æ˜¯æˆ‘å€‘æ¢ç´¢ ğŸ¤— Datasets çš„æ—…ç¨‹ï¼ç¾åœ¨æˆ‘å€‘æœ‰äº†ä¸€å€‹æ¸…æ´—éçš„æ•¸æ“šé›†ï¼Œä»¥ä¸‹æ˜¯æ‚¨å¯ä»¥å˜—è©¦çš„ä¸€äº›æƒ³æ³•ï¼š

1. ä½¿ç”¨[ç¬¬3ç« ](/course/chapter3)çš„æŠ€è¡“ä¾†è¨“ç·´ä¸€å€‹åˆ†é¡å™¨ï¼Œå®ƒå¯ä»¥æ ¹æ“šè—¥ç‰©è©•è«–é æ¸¬ç—…äººçš„æƒ…æ³ã€‚
2. ä½¿ç”¨ [Chapter 1](/course/chapter1) ä¸­çš„â€œsummarizationâ€ç®¡é“ç”Ÿæˆè©•è«–æ‘˜è¦ã€‚

æ¥ä¸‹ä¾†ï¼Œæˆ‘å€‘å°‡çœ‹çœ‹ ğŸ¤— Datasetså¦‚ä½•ä½¿æ‚¨èƒ½å¤ åœ¨ä¸æ’çˆ†ç­†è¨˜æœ¬é›»è…¦å…§å­˜çš„æƒ…æ³ä¸‹è™•ç†é¾å¤§çš„æ•¸æ“šé›†ï¼