# Transformer 是如何運作的？

<CourseFloatingBanner
    chapter={1}
    classNames="absolute z-10 right-0 top-0"
/>

在本節中，我們將探討 Transformer 模型的架構，並深入了解注意力機制、編碼器-解碼器架構等概念。

<Tip warning={true}>

🚀 我們在這裡要提升難度了。這個部分詳細且技術性很強，所以如果你不能立即理解所有內容，不用擔心。我們會在課程後面再回到這些概念。

</Tip>



## 一些 Transformers 的發展歷史

以下是 Transformer 模型（短暫）歷史中的一些參考點：

<div class="flex justify-center">
<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/transformers_chrono.svg" alt="A brief chronology of Transformers models.">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/transformers_chrono-dark.svg" alt="A brief chronology of Transformers models.">
</div>

[Transformer 架構](https://arxiv.org/abs/1706.03762) 於 2017 年 6 月推出。原始研究的重點是翻譯任務。隨後推出了幾個有影響力的模型，包括：

- **2018 年 6 月**: [GPT](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf), 第一個預訓練的 Transformer 模型，用於在各種 NLP 任務上進行微調並獲得了最先進的結果

- **2018 年 10 月**: [BERT](https://arxiv.org/abs/1810.04805), 另一個大型預訓練模型，這個模型旨在產生更好的句子摘要（下一章會有更多介紹！）

- **2019 年 2 月**: [GPT-2](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf), GPT 的改進（且更大）版本，由於倫理考量而未立即公開發布

- **2019 年 10 月**: [T5](https://huggingface.co/papers/1910.10683), 專注於多任務的序列到序列 Transformer 架構實現

- **2020 年 5 月**, [GPT-3](https://arxiv.org/abs/2005.14165), GPT-2 的更大版本，能夠在各種任務上表現良好而無需微調（稱為零樣本學習）

- **2022 年 1 月**, [InstructGPT](https://huggingface.co/papers/2203.02155), GPT-3 的一個版本，經過訓練能更好地遵循指令。這個列表遠非全面，只是為了突出幾種不同類型的 Transformer 模型。廣義上，它們可以分為三類：

- **2023 年 1 月**, [LLaMA](https://huggingface.co/papers/2302.13971), 一個能夠生成多種語言文本的大型語言模型

- **2023 年 3 月**, [Mistral](https://huggingface.co/papers/2310.06825), 一個 70 億參數的語言模型，在所有評估基準上都優於 Llama 2 13B，利用分組查詢注意力實現更快推理，並使用滑動窗口注意力處理任意長度的序列

- **2024 年 5 月**, [Gemma 2](https://huggingface.co/papers/2408.00118), 一系列輕量級、最先進的開源模型，參數範圍從 20 億到 270 億，結合了交錯的局部-全局注意力和分組查詢注意力，較小的模型使用知識蒸餾訓練，性能可與 2-3 倍大小的模型競爭

- **2024 年 11 月**, [SmolLM2](https://huggingface.co/papers/2502.02737), 一個最先進的小型語言模型（1.35 億到 17 億參數），儘管體積緊湊但實現了令人印象深刻的性能，為移動和邊緣設備開啟了新的可能性

- GPT 類型（也稱為自回歸 Transformer 模型）
- BERT 類型（也稱為自編碼 Transformer 模型）
- T5 類型（也稱為序列到序列 Transformer 模型）

我們稍後會更深入地探討這些系列

## Transformers 是語言模型

上述提到的所有 Transformer 模型（GPT、BERT、T5 等）都被訓練為語言模型。這意味著它們以自監督的方式在大量原始文本上進行訓練。

自監督學習是一種訓練類型，其中目標是從模型的輸入自動計算得出的。這意味著不需要人類來標記數據！

這種類型的模型對其訓練的語言產生統計理解，但對於特定的實際任務用處較小。因此，通用預訓練模型會經歷一個稱為遷移學習或微調的過程。在這個過程中，模型以監督的方式進行微調——也就是說，在給定任務上使用人工標註的標籤。

一個任務的例子是在讀取前 n 個詞後預測句子中的下一個詞。這被稱為因果語言建模，因為輸出依賴於過去和現在的輸入，但不依賴於未來的輸入。

<div class="flex justify-center">
<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/causal_modeling.svg" alt="Example of causal language modeling in which the next word from a sentence is predicted.">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/causal_modeling-dark.svg" alt="Example of causal language modeling in which the next word from a sentence is predicted.">
</div>

另一個例子是*遮蔽語言建模*，其中模型預測句子中被遮蔽的詞。

<div class="flex justify-center">
<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/masked_modeling.svg" alt="Example of masked language modeling in which a masked word from a sentence is predicted.">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/masked_modeling-dark.svg" alt="Example of masked language modeling in which a masked word from a sentence is predicted.">
</div>

## Transformer 是大型模型

除了少數例外（如 DistilBERT），實現更好性能的一般策略是增加模型的大小以及它們預訓練的數據量。

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/model_parameters.png" alt="Number of parameters of recent Transformers models" width="90%">
</div>

不幸的是，訓練一個模型，特別是大型模型，需要大量的數據。這在時間和計算資源方面變得非常昂貴。它甚至轉化為環境影響，如下圖所示。

<div class="flex justify-center">
<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/carbon_footprint.svg" alt="The carbon footprint of a large language model.">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/carbon_footprint-dark.svg" alt="The carbon footprint of a large language model.">
</div>

<Youtube id="ftWlj4FBHTg"/>

而這顯示的是一個由有意識地試圖減少預訓練環境影響的團隊領導的（非常大的）模型項目。運行大量試驗以獲得最佳超參數的足跡會更高。

想像一下，如果每次研究團隊、學生組織或公司想要訓練模型時，都從頭開始。這將導致巨大且不必要的全球成本！

這就是為什麼分享語言模型至關重要：分享訓練好的權重並在已訓練權重的基礎上構建，可以減少社群的整體計算成本和碳足跡。

順便說一下，你可以通過幾個工具來評估模型訓練的碳足跡。例如 [ML CO2 Impact](https://mlco2.github.io/impact/) 或集成在 🤗 Transformers 中的 [Code Carbon]( https://codecarbon.io/)。要了解更多相關信息，你可以閱讀這篇[博客文章](https://huggingface.co/blog/carbon-emissions-on-the-hub)，它將向你展示如何生成一個** emissions.csv **文件，其中包含訓練足跡的估算，以及 🤗 Transformers 關於這個主題的[文檔](https://huggingface.co/docs/hub/model-cards-co2)。

## 遷移學習

<Youtube id="BqqfQnyjmgg" />

*預訓練*是從頭開始訓練模型的行為：權重被隨機初始化，訓練在沒有任何先驗知識的情況下開始。

<div class="flex justify-center">
<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/pretraining.svg" alt="The pretraining of a language model is costly in both time and money.">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/pretraining-dark.svg" alt="The pretraining of a language model is costly in both time and money.">
</div>

語言模型的預訓練在時間和金錢方面都很昂貴。這種預訓練通常在非常大量的數據上進行。因此，它需要非常大的數據語料庫，訓練可能需要長達數週的時間。

另一方面，*微調*是在模型預訓練後進行的訓練。要執行微調，首先需要獲取一個經過預訓練的語言模型，然後使用特定於任務的數據集執行額外的訓練。等等——為什麼不從一開始就為你的最終用例從頭訓練模型呢？有幾個原因：

*  預訓練模型已經在與微調數據集有一些相似性的數據集上進行了訓練。因此，微調過程能夠利用初始模型在預訓練期間獲得的知識（例如，對於 NLP 問題，預訓練模型將對你用於任務的語言有某種統計理解）。
*  由於預訓練模型已經在大量數據上進行了訓練，微調需要的數據要少得多就能獲得不錯的結果。
*  出於同樣的原因，獲得良好結果所需的時間和資源要少得多。

例如，可以利用在英語上訓練的預訓練模型，然後在 arXiv 語料庫上對其進行微調，從而產生基於科學/研究的模型。微調只需要有限的數據量：預訓練模型獲得的知識被「轉移」，因此稱為*遷移學習*。

<div class="flex justify-center">
<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/finetuning.svg" alt="The fine-tuning of a language model is cheaper than pretraining in both time and money.">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/finetuning-dark.svg" alt="The fine-tuning of a language model is cheaper than pretraining in both time and money.">
</div>

因此，微調模型具有較低的時間、因此，微調模型具有較低的時間、數據、財務和環境成本。迭代不同的微調方案也更快更容易，因為訓練比完整的預訓練限制更少。數據、財務和環境成本。迭代不同的微調方案也更快、更容易，因爲與完整的預訓練相比，訓練的約束更少。

這個過程也會比從頭訓練獲得更好的結果（除非你有大量數據），這就是為什麼你應該總是嘗試利用預訓練模型——一個盡可能接近你手頭任務的模型——並對其進行微調。

## 通用 Transformer 架構

在本節中，我們將介紹 Transformer 模型的通用架構。如果你不理解某些概念，不用擔心；稍後會有詳細的章節涵蓋每個組件。

<Youtube id="H39Z_720T5s" />

該模型主要由兩塊組成：

* **Encoder (左側)**: 編碼器接收輸入並構建其表示（其特徵）。這意味著模型被優化以從輸入中獲得理解。
* **Decoder (右側)**: 解碼器使用編碼器的表示（特徵）以及其他輸入來生成目標序列。這意味著模型被優化用於生成輸出。

<div class="flex justify-center">
<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/transformers_blocks.svg" alt="Architecture of a Transformers models">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/transformers_blocks-dark.svg" alt="Architecture of a Transformers models">
</div>

這些部分中的每一個都可以獨立使用，取決於任務：

* **Encoder-only models**: 適用於需要理解輸入的任務，如句子分類和命名實體識別。
* **Decoder-only models**: 適用於生成任務，如文本生成。
* **Encoder-decoder models** 或者 **sequence-to-sequence models**: 適用於需要輸入的生成任務，如翻譯或摘要。

我們將在後面的章節中獨立深入探討這些架構。

## 注意力層

Transformer 模型的一個關鍵特徵是它們由稱為*注意力層*的特殊層構建而成。事實上，介紹 Transformer 架構的論文標題就是["Attention Is All You Need"](https://arxiv.org/abs/1706.03762)！我們將在課程後面探討注意力層的細節；現在，你只需要知道這一層會告訴模型在處理每個詞的表示時，對你傳遞給它的句子中的某些詞給予特定關注（或多或少忽略其他詞）。

為了將此置於上下文中，考慮將文本從英語翻譯成法語的任務。給定輸入「You like this course」，翻譯模型還需要關注相鄰的詞「You」以獲得詞「like」的正確翻譯，因為在法語中動詞「like」根據主語的不同而有不同的變位。然而，句子的其餘部分對該詞的翻譯並無用處。同樣地，在翻譯「this」時，模型還需要關注詞「course」，因為「this」的翻譯會根據相關名詞是陽性還是陰性而有所不同。同樣，句子中的其他詞對「course」的翻譯並不重要。對於更複雜的句子（和更複雜的語法規則），模型需要特別關注可能出現在句子中較遠位置的詞，以正確翻譯每個詞。

同樣的概念適用於與自然語言相關的任何任務：一個詞本身有意義，但該意義深受上下文影響，上下文可以是被研究詞之前或之後的任何其他詞（或詞語）。

現在你對注意力層的作用有了概念，讓我們更仔細地看看 Transformer 架構。

## 原始架構

Transformer Transformer 架構最初是為翻譯而設計的。在訓練期間，編碼器接收某種語言的輸入（句子），而解碼器接收所需目標語言的相同句子。在編碼器中，注意力層可以使用句子中的所有詞（因為正如我們剛才看到的，給定詞的翻譯可能依賴於句子中它之前和之後的內容）。然而，解碼器按順序工作，只能關注句子中已經翻譯的詞（因此，只能關注當前生成詞之前的詞）。例如，當我們預測了翻譯目標的前三個詞時，我們將它們提供給解碼器，然後解碼器使用編碼器的所有輸入來嘗試預測第四個詞。

為了在訓練期間加快速度（當模型可以訪問目標句子時），解碼器被餵入整個目標，但不允許使用未來的詞（如果在嘗試預測位置 2 的詞時可以訪問位置 2 的詞，問題就不會很困難！）。例如，在嘗試預測第四個詞時，注意力層只能訪問位置 1 到 3 的詞。

原始的 Transformer 架構看起來像這樣，編碼器在左側，解碼器在右側：

<div class="flex justify-center">
<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/transformers.svg" alt="Architecture of a Transformers models">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/transformers-dark.svg" alt="Architecture of a Transformers models">
</div>

請注意，解碼器塊中的第一個注意力層關注解碼器的所有（過去的）輸入，但第二個注意力層使用編碼器的輸出。因此它可以訪問整個輸入句子來最好地預測當前詞。這非常有用，因為不同語言可能有將詞語放在不同順序的語法規則，或者句子後面提供的一些上下文可能有助於確定給定詞的最佳翻譯。

注意力遮罩也可以在編碼器/解碼器中使用，以防止模型關注某些特殊詞——例如，在將句子批次處理時用於使所有輸入長度相同的特殊填充詞。

## 架構與檢查點

當我們在本課程中深入探討 Transformer 模型時，你會看到*架構*和*檢查點*以及*模型*的提及。這些術語都有略微不同的含義：

* **架構**：這是模型的骨架——模型內每一層和每個操作的定義。
* **檢查點**：這些是將在給定架構中載入的權重。
* **模型**：這是一個不如「架構」或「檢查點」精確的總稱：它可以指兩者。本課程會在重要時指定*架構*或*檢查點*以減少歧義。

例如，BERT 是一個架構，而 `bert-base-cased`（Google 團隊為 BERT 首次發布訓練的一組權重）是一個檢查點。然而，人們可以說「BERT 模型」和「`bert-base-cased` 模型」。