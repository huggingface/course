# 總結

<CourseFloatingBanner
    chapter={1}
    classNames="absolute z-10 right-0 top-0"
/>

在本章中，您瞭解瞭如何使用來自🤗Transformers 的函數 pipeline() 處理不同的 NLP 任務。您還了解了如何在模型中心（hub）中搜索和使用模型，以及如何使用推理API直接在瀏覽器中測試模型。

我們討論了Transformer模型如何在應用層上工作，並討論了遷移學習和微調的重要性。您可以使用完整的體系結構，也可以僅使用編碼器或解碼器，具體取決於您要解決的任務類型。下表總結了這一點：

|  模型   | 示例  | 任務|
|  ----  | ----  |----|
| 編碼器  | ALBERT, BERT, DistilBERT, ELECTRA, RoBERTa	|句子分類、命名實體識別、從文本中提取答案|
| 解碼器  | CTRL, GPT, GPT-2, Transformer XL	 |文本生成|
| 編碼器-解碼器  | BART, T5, Marian, mBART	 |文本摘要、翻譯、生成問題的回答|