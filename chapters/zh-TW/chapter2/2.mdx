<FrameworkSwitchCourse {fw} />

# ç®¡é“çš„å…§éƒ¨

{#if fw === 'pt'}

<CourseFloatingBanner chapter={2}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/zh-CN/chapter2/section2_pt.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/zh-CN/chapter2/section2_pt.ipynb"},
]} />

{:else}

<CourseFloatingBanner chapter={2}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/zh-CN/chapter2/section2_tf.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/zh-CN/chapter2/section2_tf.ipynb"},
]} />

{/if}

<Tip>
é€™æ˜¯ç¬¬ä¸€éƒ¨åˆ†ï¼Œæ ¹æ“šæ‚¨ä½¿ç”¨ PyTorch æˆ–è€… TensorFlowï¼Œå…§å®¹ç•¥æœ‰ä¸åŒã€‚é»æ“Šæ¨™é¡Œä¸Šæ–¹çš„å¹³è‡ºï¼Œé¸ä¸€å€‹æ‚¨å–œæ­¡çš„å§ï¼
</Tip>

{#if fw === 'pt'}
<Youtube id="1pedAIvTWXk"/>
{:else}
<Youtube id="wVN12smEvqg"/>
{/if}

è®“æˆ‘å€‘å¾ä¸€å€‹å®Œæ•´çš„ç¤ºä¾‹é–‹å§‹ï¼Œçœ‹çœ‹åœ¨[Chapter 1](/course/chapter1)ä¸­åŸ·è¡Œä»¥ä¸‹ä»£ç¢¼æ™‚åœ¨å¹•å¾Œç™¼ç”Ÿäº†ä»€éº¼

```python
from transformers import pipeline

classifier = pipeline("sentiment-analysis")
classifier(
    [
        "I've been waiting for a HuggingFace course my whole life.",
        "I hate this so much!",
    ]
)
```

ç²å¾—:

```python out
[{'label': 'POSITIVE', 'score': 0.9598047137260437},
 {'label': 'NEGATIVE', 'score': 0.9994558095932007}]
```

æ­£å¦‚æˆ‘å€‘åœ¨[Chapter 1](/course/chapter1)ä¸­çœ‹åˆ°çš„ï¼Œæ­¤ç®¡é“å°‡ä¸‰å€‹æ­¥é©Ÿçµ„åˆåœ¨ä¸€èµ·ï¼šé è™•ç†ã€é€šéæ¨¡å‹å‚³éè¼¸å…¥å’Œå¾Œè™•ç†ï¼š

<div class="flex justify-center">
<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/full_nlp_pipeline.svg" alt="The full NLP pipeline: tokenization of text, conversion to IDs, and inference through the Transformer model and the model head."/>
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/full_nlp_pipeline-dark.svg" alt="The full NLP pipeline: tokenization of text, conversion to IDs, and inference through the Transformer model and the model head."/>
</div>

è®“æˆ‘å€‘å¿«é€Ÿç€è¦½ä¸€ä¸‹é€™äº›å…§å®¹ã€‚

## ä½¿ç”¨åˆ†è©å™¨é€²è¡Œé è™•ç†

èˆ‡å…¶ä»–ç¥ç¶“ç¶²çµ¡ä¸€æ¨£ï¼ŒTransformer æ¨¡å‹ç„¡æ³•ç›´æ¥è™•ç†åŸå§‹æ–‡æœ¬ï¼Œ å› æ­¤æˆ‘å€‘ç®¡é“çš„ç¬¬ä¸€æ­¥æ˜¯å°‡æ–‡æœ¬è¼¸å…¥è½‰æ›ç‚ºæ¨¡å‹èƒ½å¤ ç†è§£çš„æ•¸å­—ã€‚ ç‚ºæ­¤ï¼Œæˆ‘å€‘ä½¿ç”¨*tokenizer*(æ¨™è¨˜å™¨)ï¼Œè² è²¬ï¼š

- å°‡è¼¸å…¥æ‹†åˆ†ç‚ºå–®è©ã€å­å–®è©æˆ–ç¬¦è™Ÿï¼ˆå¦‚æ¨™é»ç¬¦è™Ÿï¼‰ï¼Œç¨±ç‚ºæ¨™è¨˜(*token*)
- å°‡æ¯å€‹æ¨™è¨˜(token)æ˜ å°„åˆ°ä¸€å€‹æ•´æ•¸
- æ·»åŠ å¯èƒ½å°æ¨¡å‹æœ‰ç”¨çš„å…¶ä»–è¼¸å…¥

æ‰€æœ‰é€™äº›é è™•ç†éƒ½éœ€è¦ä»¥èˆ‡æ¨¡å‹é è¨“ç·´æ™‚å®Œå…¨ç›¸åŒçš„æ–¹å¼å®Œæˆï¼Œå› æ­¤æˆ‘å€‘é¦–å…ˆéœ€è¦å¾[Model Hub](https://huggingface.co/models)ä¸­ä¸‹è¼‰é€™äº›ä¿¡æ¯ã€‚ç‚ºæ­¤ï¼Œæˆ‘å€‘ä½¿ç”¨`AutoTokenizer`é¡åŠå…¶`from_pretrained()`æ–¹æ³•ã€‚ä½¿ç”¨æˆ‘å€‘æ¨¡å‹çš„æª¢æŸ¥é»åç¨±ï¼Œå®ƒå°‡è‡ªå‹•ç²å–èˆ‡æ¨¡å‹çš„æ¨™è¨˜å™¨ç›¸é—œè¯çš„æ•¸æ“šï¼Œä¸¦å°å…¶é€²è¡Œç·©å­˜ï¼ˆå› æ­¤åªæœ‰åœ¨æ‚¨ç¬¬ä¸€æ¬¡é‹è¡Œä¸‹é¢çš„ä»£ç¢¼æ™‚æ‰æœƒä¸‹è¼‰ï¼‰ã€‚

å› ç‚º`sentiment-analysis`ï¼ˆæƒ…ç·’åˆ†æï¼‰ç®¡é“çš„é»˜èªæª¢æŸ¥é»æ˜¯`distilbert-base-uncased-finetuned-sst-2-english`ï¼ˆä½ å¯ä»¥çœ‹åˆ°å®ƒçš„æ¨¡å‹å¡[here](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english))ï¼Œæˆ‘å€‘é‹è¡Œä»¥ä¸‹ç¨‹åºï¼š

```python
from transformers import AutoTokenizer

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
```

ä¸€æ—¦æˆ‘å€‘æœ‰äº†æ¨™è¨˜å™¨ï¼Œæˆ‘å€‘å°±å¯ä»¥ç›´æ¥å°‡æˆ‘å€‘çš„å¥å­å‚³éçµ¦å®ƒï¼Œç„¶å¾Œæˆ‘å€‘å°±æœƒå¾—åˆ°ä¸€æœ¬å­—å…¸ï¼Œå®ƒå¯ä»¥æä¾›çµ¦æˆ‘å€‘çš„æ¨¡å‹ï¼å‰©ä¸‹è¦åšçš„å”¯ä¸€ä¸€ä»¶äº‹å°±æ˜¯å°‡è¼¸å…¥IDåˆ—è¡¨è½‰æ›ç‚ºå¼µé‡ã€‚

æ‚¨å¯ä»¥ä½¿ç”¨ğŸ¤— Transformersï¼Œè€Œä¸å¿…æ“”å¿ƒå“ªå€‹ ML æ¡†æ¶è¢«ç”¨ä½œå¾Œç«¯ï¼›å®ƒå¯èƒ½æ˜¯ PyTorch æˆ– TensorFlowï¼Œæˆ– Flaxã€‚ä½†æ˜¯ï¼ŒTransformerså‹è™Ÿåªæ¥å—*å¼µé‡*ä½œç‚ºè¼¸å…¥ã€‚å¦‚æœé€™æ˜¯ä½ ç¬¬ä¸€æ¬¡è½èªªå¼µé‡ï¼Œä½ å¯ä»¥æŠŠå®ƒå€‘æƒ³è±¡æˆNumPyæ•¸çµ„ã€‚NumPyæ•¸çµ„å¯ä»¥æ˜¯æ¨™é‡ï¼ˆ0Dï¼‰ã€å‘é‡ï¼ˆ1Dï¼‰ã€çŸ©é™£ï¼ˆ2Dï¼‰æˆ–å…·æœ‰æ›´å¤šç¶­åº¦ã€‚å®ƒå¯¦éš›ä¸Šæ˜¯å¼µé‡ï¼›å…¶ä»– ML æ¡†æ¶çš„å¼µé‡è¡Œç‚ºé¡ä¼¼ï¼Œé€šå¸¸èˆ‡ NumPy æ•¸çµ„ä¸€æ¨£æ˜“æ–¼å¯¦ä¾‹åŒ–ã€‚

è¦æŒ‡å®šè¦è¿”å›çš„å¼µé‡é¡å‹ï¼ˆPyTorchã€TensorFlow æˆ– plain NumPyï¼‰ï¼Œæˆ‘å€‘ä½¿ç”¨`return_tensors`åƒæ•¸ï¼š

{#if fw === 'pt'}
```python
raw_inputs = [
    "I've been waiting for a HuggingFace course my whole life.",
    "I hate this so much!",
]
inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors="pt")
print(inputs)
```
{:else}
```python
raw_inputs = [
    "I've been waiting for a HuggingFace course my whole life.",
    "I hate this so much!",
]
inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors="tf")
print(inputs)
```
{/if}

ç¾åœ¨ä¸è¦æ“”å¿ƒå¡«å……å’Œæˆªæ–·ï¼›æˆ‘å€‘ç¨å¾Œæœƒè§£é‡‹é€™äº›ã€‚é€™è£¡è¦è¨˜ä½çš„ä¸»è¦äº‹æƒ…æ˜¯ï¼Œæ‚¨å¯ä»¥å‚³éä¸€å€‹å¥å­æˆ–ä¸€çµ„å¥å­ï¼Œé‚„å¯ä»¥æŒ‡å®šè¦è¿”å›çš„å¼µé‡é¡å‹ï¼ˆå¦‚æœæ²’æœ‰å‚³éé¡å‹ï¼Œæ‚¨å°‡å¾—åˆ°ä¸€çµ„åˆ—è¡¨ï¼‰ã€‚

{#if fw === 'pt'}

ä»¥ä¸‹æ˜¯PyTorchå¼µé‡çš„çµæœï¼š

```python out
{
    'input_ids': tensor([
        [  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172, 2607,  2026,  2878,  2166,  1012,   102],
        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,     0,     0,     0,     0,     0,     0]
    ]), 
    'attention_mask': tensor([
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]
    ])
}
```
{:else}

ä»¥ä¸‹æ˜¯ TensorFlow å¼µé‡çš„çµæœï¼š

```python out
{
    'input_ids': <tf.Tensor: shape=(2, 16), dtype=int32, numpy=
        array([
            [  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,  2607,  2026,  2878,  2166,  1012,   102],
            [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,     0,     0,     0,     0,     0,     0]
        ], dtype=int32)>, 
    'attention_mask': <tf.Tensor: shape=(2, 16), dtype=int32, numpy=
        array([
            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
            [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]
        ], dtype=int32)>
}
```
{/if}

è¼¸å‡ºæœ¬èº«æ˜¯ä¸€å€‹åŒ…å«å…©å€‹éµçš„å­—å…¸ï¼Œ`input_ids`å’Œ`attention_mask`ã€‚`input_ids`åŒ…å«å…©è¡Œæ•´æ•¸ï¼ˆæ¯å€‹å¥å­ä¸€è¡Œï¼‰ï¼Œå®ƒå€‘æ˜¯æ¯å€‹å¥å­ä¸­æ¨™è¨˜çš„å”¯ä¸€æ¨™è¨˜ï¼ˆtokenï¼‰ã€‚æˆ‘å€‘å°‡åœ¨æœ¬ç« å¾Œé¢è§£é‡‹ä»€éº¼æ˜¯`attention_mask`ã€‚

## ç€è¦½æ¨¡å‹

{#if fw === 'pt'}
æˆ‘å€‘å¯ä»¥åƒä½¿ç”¨æ¨™è¨˜å™¨ä¸€æ¨£ä¸‹è¼‰é è¨“ç·´æ¨¡å‹ã€‚ğŸ¤— Transformersæä¾›äº†ä¸€å€‹`AutoModel`é¡ï¼Œè©²é¡é‚„å…·æœ‰`from_pretrained()`æ–¹æ³•ï¼š

```python
from transformers import AutoModel

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
model = AutoModel.from_pretrained(checkpoint)
```
{:else}
æˆ‘å€‘å¯ä»¥åƒä½¿ç”¨æ¨™è¨˜å™¨ä¸€æ¨£ä¸‹è¼‰é è¨“ç·´æ¨¡å‹ã€‚ğŸ¤— Transformersæä¾›äº†ä¸€å€‹`TFAutoModel`é¡ï¼Œè©²é¡é‚„å…·æœ‰`from_pretrained()`æ–¹æ³•ï¼š

```python
from transformers import TFAutoModel

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
model = TFAutoModel.from_pretrained(checkpoint)
```
{/if}

åœ¨é€™å€‹ä»£ç¢¼ç‰‡æ®µä¸­ï¼Œæˆ‘å€‘ä¸‹è¼‰äº†ä¹‹å‰åœ¨ç®¡é“ä¸­ä½¿ç”¨çš„ç›¸åŒæª¢æŸ¥é»ï¼ˆå®ƒå¯¦éš›ä¸Šæ‡‰è©²å·²ç¶“è¢«ç·©å­˜ï¼‰ï¼Œä¸¦ç”¨å®ƒå¯¦ä¾‹åŒ–äº†ä¸€å€‹æ¨¡å‹ã€‚

é€™å€‹æ¶æ§‹åªåŒ…å«åŸºæœ¬è½‰æ›å™¨æ¨¡å¡Šï¼šçµ¦å®šä¸€äº›è¼¸å…¥ï¼Œå®ƒè¼¸å‡ºæˆ‘å€‘å°‡èª¿ç”¨çš„å…§å®¹*éš±è—ç‹€æ…‹ï¼ˆhidden statesï¼‰*ï¼Œäº¦ç¨±*ç‰¹å¾µï¼ˆfeaturesï¼‰*ã€‚å°æ–¼æ¯å€‹æ¨¡å‹è¼¸å…¥ï¼Œæˆ‘å€‘å°‡æª¢ç´¢ä¸€å€‹é«˜ç¶­å‘é‡ï¼Œè¡¨ç¤º**Transformeræ¨¡å‹å°è©²è¼¸å…¥çš„ä¸Šä¸‹æ–‡ç†è§£**ã€‚ 

å¦‚æœé€™ä¸åˆç†ï¼Œä¸è¦æ“”å¿ƒã€‚æˆ‘å€‘ä»¥å¾Œå†è§£é‡‹ã€‚

é›–ç„¶é€™äº›éš±è—ç‹€æ…‹æœ¬èº«å¯èƒ½å¾ˆæœ‰ç”¨ï¼Œä½†å®ƒå€‘é€šå¸¸æ˜¯æ¨¡å‹å¦ä¸€éƒ¨åˆ†ï¼ˆç¨±ç‚º*é ­éƒ¨(head)*ï¼‰çš„è¼¸å…¥ã€‚ åœ¨[Chapter 1](/course/chapter1)ä¸­ï¼Œå¯ä»¥ä½¿ç”¨ç›¸åŒçš„é«”ç³»çµæ§‹åŸ·è¡Œä¸åŒçš„ä»»å‹™ï¼Œä½†é€™äº›ä»»å‹™ä¸­çš„æ¯å€‹ä»»å‹™éƒ½æœ‰ä¸€å€‹èˆ‡ä¹‹é—œè¯çš„ä¸åŒé ­ã€‚

### é«˜ç¶­å‘é‡ï¼Ÿ

Transformers æ¨¡å¡Šçš„å‘é‡è¼¸å‡ºé€šå¸¸è¼ƒå¤§ã€‚å®ƒé€šå¸¸æœ‰ä¸‰å€‹ç¶­åº¦ï¼š

- **Batch size**: ä¸€æ¬¡è™•ç†çš„åºåˆ—æ•¸ï¼ˆåœ¨æˆ‘å€‘çš„ç¤ºä¾‹ä¸­ç‚º2ï¼‰ã€‚
- **Sequence length**: åºåˆ—çš„æ•¸å€¼è¡¨ç¤ºçš„é•·åº¦ï¼ˆåœ¨æˆ‘å€‘çš„ç¤ºä¾‹ä¸­ç‚º16ï¼‰ã€‚
- **Hidden size**: æ¯å€‹æ¨¡å‹è¼¸å…¥çš„å‘é‡ç¶­åº¦ã€‚

ç”±æ–¼æœ€å¾Œä¸€å€‹å€¼ï¼Œå®ƒè¢«ç¨±ç‚ºã€Œé«˜ç¶­ã€ã€‚éš±è—çš„å¤§å°å¯èƒ½éå¸¸å¤§ï¼ˆ768é€šå¸¸ç”¨æ–¼è¼ƒå°çš„å‹è™Ÿï¼Œè€Œåœ¨è¼ƒå¤§çš„å‹è™Ÿä¸­ï¼Œé€™å¯èƒ½é”åˆ°3072æˆ–æ›´å¤§ï¼‰ã€‚

å¦‚æœæˆ‘å€‘å°‡é è™•ç†çš„è¼¸å…¥è¼¸å…¥åˆ°æ¨¡å‹ä¸­ï¼Œæˆ‘å€‘å¯ä»¥çœ‹åˆ°é€™ä¸€é»ï¼š

{#if fw === 'pt'}
```python
outputs = model(**inputs)
print(outputs.last_hidden_state.shape)
```

```python out
torch.Size([2, 16, 768])
```
{:else}
```py
outputs = model(inputs)
print(outputs.last_hidden_state.shape)
```

```python out
(2, 16, 768)
```
{/if}

æ³¨æ„ğŸ¤— Transformers æ¨¡å‹çš„è¼¸å‡ºèˆ‡`namedtuple`æˆ–è©å…¸ç›¸ä¼¼ã€‚æ‚¨å¯ä»¥é€šéå±¬æ€§ï¼ˆå°±åƒæˆ‘å€‘æ‰€åšçš„é‚£æ¨£ï¼‰æˆ–éµï¼ˆ`è¼¸å‡º["last_hidden_state"]`ï¼‰è¨ªå•å…ƒç´ ï¼Œç”šè‡³å¯ä»¥é€šéç´¢å¼•è¨ªå•å…ƒç´ ï¼Œå‰ææ˜¯æ‚¨ç¢ºåˆ‡çŸ¥é“è¦æŸ¥æ‰¾çš„å…§å®¹åœ¨å“ªè£¡ï¼ˆ`outputs[0]`ï¼‰ã€‚

### æ¨¡å‹é ­ï¼šæ•¸å­—çš„æ„ç¾©

æ¨¡å‹é ­å°‡éš±è—ç‹€æ…‹çš„é«˜ç¶­å‘é‡ä½œç‚ºè¼¸å…¥ï¼Œä¸¦å°‡å…¶æŠ•å½±åˆ°ä¸åŒçš„ç¶­åº¦ã€‚å®ƒå€‘é€šå¸¸ç”±ä¸€å€‹æˆ–å¹¾å€‹ç·šæ€§å±¤çµ„æˆï¼š


<div class="flex justify-center">
<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/transformer_and_head.svg" alt="A Transformer network alongside its head."/>
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/transformer_and_head-dark.svg" alt="A Transformer network alongside its head."/>
</div>

Transformers æ¨¡å‹çš„è¼¸å‡ºç›´æ¥ç™¼é€åˆ°æ¨¡å‹é ­é€²è¡Œè™•ç†ã€‚

åœ¨æ­¤åœ–ä¸­ï¼Œæ¨¡å‹ç”±å…¶åµŒå…¥å±¤å’Œå¾ŒçºŒå±¤è¡¨ç¤ºã€‚åµŒå…¥å±¤å°‡æ¨™è¨˜åŒ–è¼¸å…¥ä¸­çš„æ¯å€‹è¼¸å…¥IDè½‰æ›ç‚ºè¡¨ç¤ºé—œè¯æ¨™è¨˜(token)çš„å‘é‡ã€‚å¾ŒçºŒå±¤ä½¿ç”¨æ³¨æ„æ©Ÿåˆ¶æ“ç¸±é€™äº›å‘é‡ï¼Œä»¥ç”Ÿæˆå¥å­çš„æœ€çµ‚è¡¨ç¤ºã€‚


ğŸ¤— Transformersä¸­æœ‰è¨±å¤šä¸åŒçš„é«”ç³»çµæ§‹ï¼Œæ¯ç¨®é«”ç³»çµæ§‹éƒ½æ˜¯åœç¹è™•ç†ç‰¹å®šä»»å‹™è€Œè¨­è¨ˆçš„ã€‚ä»¥ä¸‹æ˜¯ä¸€å€‹éè©³ç›¡çš„åˆ—è¡¨ï¼š

- `*Model` (retrieve the hidden states)
- `*ForCausalLM`
- `*ForMaskedLM`
- `*ForMultipleChoice`
- `*ForQuestionAnswering`
- `*ForSequenceClassification`
- `*ForTokenClassification`
- ä»¥åŠå…¶ä»– ğŸ¤—

{#if fw === 'pt'}
å°æ–¼æˆ‘å€‘çš„ç¤ºä¾‹ï¼Œæˆ‘å€‘éœ€è¦ä¸€å€‹å¸¶æœ‰åºåˆ—åˆ†é¡é ­çš„æ¨¡å‹ï¼ˆèƒ½å¤ å°‡å¥å­åˆ†é¡ç‚ºè‚¯å®šæˆ–å¦å®šï¼‰ã€‚å› æ­¤ï¼Œæˆ‘å€‘å¯¦éš›ä¸Šä¸æœƒä½¿ç”¨`AutoModel`é¡ï¼Œè€Œæ˜¯ä½¿ç”¨`AutoModelForSequenceClassification`ï¼š

```python
from transformers import AutoModelForSequenceClassification

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
model = AutoModelForSequenceClassification.from_pretrained(checkpoint)
outputs = model(**inputs)
```
{:else}
For our example, we will need a model with a sequence classification head (to be able to classify the sentences as positive or negative). So, we won't actually use the `TFAutoModel` class, but `TFAutoModelForSequenceClassification`:

```python
from transformers import TFAutoModelForSequenceClassification

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)
outputs = model(inputs)
```
{/if}

ç¾åœ¨ï¼Œå¦‚æœæˆ‘å€‘è§€å¯Ÿè¼¸å…¥çš„å½¢ç‹€ï¼Œç¶­åº¦å°‡ä½å¾—å¤šï¼šæ¨¡å‹é ­å°‡æˆ‘å€‘ä¹‹å‰çœ‹åˆ°çš„é«˜ç¶­å‘é‡ä½œç‚ºè¼¸å…¥ï¼Œä¸¦è¼¸å‡ºåŒ…å«å…©å€‹å€¼çš„å‘é‡ï¼ˆæ¯å€‹æ¨™ç±¤ä¸€å€‹ï¼‰ï¼š

```python
print(outputs.logits.shape)
```

{#if fw === 'pt'}

```python out
torch.Size([2, 2])
```

{:else}

```python out
(2, 2)
```

{/if}

å› ç‚ºæˆ‘å€‘åªæœ‰å…©å€‹å¥å­å’Œå…©å€‹æ¨™ç±¤ï¼Œæ‰€ä»¥æˆ‘å€‘å¾æ¨¡å‹ä¸­å¾—åˆ°çš„çµæœæ˜¯2 x 2çš„å½¢ç‹€ã€‚

## å°è¼¸å‡ºé€²è¡Œå¾Œè™•ç†

æˆ‘å€‘å¾æ¨¡å‹ä¸­å¾—åˆ°çš„è¼¸å‡ºå€¼æœ¬èº«ä¸¦ä¸ä¸€å®šæœ‰æ„ç¾©ã€‚æˆ‘å€‘ä¾†çœ‹çœ‹,

```python
print(outputs.logits)
```

{#if fw === 'pt'}
```python out
tensor([[-1.5607,  1.6123],
        [ 4.1692, -3.3464]], grad_fn=<AddmmBackward>)
```
{:else}
```python out
<tf.Tensor: shape=(2, 2), dtype=float32, numpy=
    array([[-1.5606991,  1.6122842],
           [ 4.169231 , -3.3464472]], dtype=float32)>
```
{/if}

æˆ‘å€‘çš„æ¨¡å‹é æ¸¬ç¬¬ä¸€å¥ç‚º`[-1.5607, 1.6123]`ï¼Œç¬¬äºŒå¥ç‚º`[ 4.1692, -3.3464]`ã€‚é€™äº›ä¸æ˜¯æ¦‚ç‡ï¼Œè€Œæ˜¯*logits*ï¼Œå³æ¨¡å‹æœ€å¾Œä¸€å±¤è¼¸å‡ºçš„åŸå§‹éæ¨™æº–åŒ–åˆ†æ•¸ã€‚è¦è½‰æ›ç‚ºæ¦‚ç‡ï¼Œå®ƒå€‘éœ€è¦ç¶“é[SoftMax](https://en.wikipedia.org/wiki/Softmax_function)å±¤ï¼ˆæ‰€æœ‰ğŸ¤—Transformersæ¨¡å‹è¼¸å‡ºlogitsï¼Œå› ç‚ºç”¨æ–¼è¨“ç·´çš„æè€—å‡½æ•¸é€šå¸¸æœƒå°‡æœ€å¾Œçš„æ¿€æ´»å‡½æ•¸ï¼ˆå¦‚SoftMaxï¼‰èˆ‡å¯¦éš›æè€—å‡½æ•¸ï¼ˆå¦‚äº¤å‰ç†µï¼‰èåˆï¼‰ï¼š

{#if fw === 'pt'}
```py
import torch

predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
print(predictions)
```
{:else}
```py
import tensorflow as tf

predictions = tf.math.softmax(outputs.logits, axis=-1)
print(predictions)
```
{/if}

{#if fw === 'pt'}
```python out
tensor([[4.0195e-02, 9.5980e-01],
        [9.9946e-01, 5.4418e-04]], grad_fn=<SoftmaxBackward>)
```
{:else}
```python out
tf.Tensor(
[[4.01951671e-02 9.59804833e-01]
 [9.9945587e-01 5.4418424e-04]], shape=(2, 2), dtype=float32)
```
{/if}

ç¾åœ¨æˆ‘å€‘å¯ä»¥çœ‹åˆ°ï¼Œæ¨¡å‹é æ¸¬ç¬¬ä¸€å¥ç‚º`[0.0402, 0.9598]`ï¼Œç¬¬äºŒå¥ç‚º`[0.9995,  0.0005]`ã€‚é€™äº›æ˜¯å¯è­˜åˆ¥çš„æ¦‚ç‡åˆ†æ•¸ã€‚

ç‚ºäº†ç²å¾—æ¯å€‹ä½ç½®å°æ‡‰çš„æ¨™ç±¤ï¼Œæˆ‘å€‘å¯ä»¥æª¢æŸ¥æ¨¡å‹é…ç½®çš„`id2label`å±¬æ€§ï¼ˆä¸‹ä¸€ç¯€å°‡å°æ­¤é€²è¡Œè©³ç´°ä»‹ç´¹ï¼‰ï¼š

```python
model.config.id2label
```

```python out
{0: 'NEGATIVE', 1: 'POSITIVE'}
```

ç¾åœ¨æˆ‘å€‘å¯ä»¥å¾—å‡ºçµè«–ï¼Œè©²æ¨¡å‹é æ¸¬äº†ä»¥ä¸‹å¹¾é»ï¼š
 
- ç¬¬ä¸€å¥ï¼šå¦å®šï¼š0.0402ï¼Œè‚¯å®šï¼š0.9598
- ç¬¬äºŒå¥ï¼šå¦å®šï¼š0.9995ï¼Œè‚¯å®šï¼š0.0005

æˆ‘å€‘å·²ç¶“æˆåŠŸåœ°è¤‡è£½äº†ç®¡é“çš„ä¸‰å€‹æ­¥é©Ÿï¼šä½¿ç”¨æ¨™è¨˜åŒ–å™¨é€²è¡Œé è™•ç†ã€é€šéæ¨¡å‹å‚³éè¼¸å…¥ä»¥åŠå¾Œè™•ç†ï¼ç¾åœ¨ï¼Œè®“æˆ‘å€‘èŠ±ä¸€äº›æ™‚é–“æ·±å…¥ç­è§£é€™äº›æ­¥é©Ÿä¸­çš„æ¯ä¸€æ­¥ã€‚

<Tip>

âœï¸ **è©¦è©¦çœ‹ï¼** é¸æ“‡å…©å€‹ï¼ˆæˆ–æ›´å¤šï¼‰ä½ è‡ªå·±çš„æ–‡æœ¬ä¸¦åœ¨ç®¡é“ä¸­é‹è¡Œå®ƒå€‘ã€‚ç„¶å¾Œè‡ªå·±è¤‡è£½åœ¨é€™è£¡çœ‹åˆ°çš„æ­¥é©Ÿï¼Œä¸¦æª¢æŸ¥æ˜¯å¦ç²å¾—ç›¸åŒçš„çµæœï¼

</Tip>
