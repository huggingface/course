<FrameworkSwitchCourse {fw} />

<!-- DISABLE-FRONTMATTER-SECTIONS -->

# End-of-chapter quiz

Let's test what you learned in this chapter!

### 1.下列哪個任務可以被框定為令牌分類問題？
<Question
	choices={[
		{
			text: "找出句子中的語法成分。",
			explain: "正確! 然後我們可以把每個單詞標記為名詞、動詞等。",
			correct: true
		},
		{
			text: "判斷一個句子的語法是否正確。",
			explain: "不，這是一個序列分類問題。"
		},
		{
			text: "找出句子中提到的人物。",
			explain: "不，除非你把你的問題回答定義為一個按順序排列的任務。",
            correct: true
		},
        {
			text: "找到一個句子中能夠回答問題的詞組。",
			explain: "不，那是一個回答問題。"
		}
	]}
/>

### 2.令牌分類預處理的哪一部分與其他預處理管道不同？
<Question
	choices={[
		{
			text: "當我們在數據集上運行一個模型，並獲得該數據集中每個樣本的預測時。",
			explain: "文本的確是作為單獨的單詞給出的，但我們仍然需要應用子詞標記模型。"
		},
		{
			text: "在應用截斷/填充時，我們需要確保將標籤截斷或填充到與輸入相同的大小。",
			explain: "正確！這不同於通常的預處理，我們需要應用完整的標記化管道。你能想到另一個不同點嗎？",
			correct: true
		},
		{
			text: "沒有必要做任何事情，課文已經被標記了。",
			explain: "這並不是特定於令牌分類的——我們總是使用 < code >-100 </code > 作為我們希望在丟失時忽略的令牌的標籤。"
		},
		{
			text: "因為互聯網上有大量的文本",
			explain: "的確如此! 但這並不是唯一的區別。",
			correct: true
		}
	]}
/>

### 3.當我們對標記分類問題中的單詞進行標記並希望標記時，會出現什麼問題？
<Question
	choices={[
		{
			text: "標記器添加了特殊的標記，我們沒有為他們的標籤。",
			explain: "我們將這些 < code >-100 </code > 標記為 < code > ，以便在丟失時忽略它們。"
		},
		{
			text: "每個單詞可以產生幾個標記，所以我們最終得到的標記比標籤多。",
			explain: "這是主要的問題，我們需要將原始標籤與標記對齊。",
			correct: true
		},
		{
			text: "因為目標是按順序排列的文本問題",
			explain: "這是不正確的; 我們需要儘可能多的標籤，否則我們的模型就會出錯。"
		}
	]}
/>

### 4.“領域適應”是什麼意思？
<Question
	choices={[
		{
			text: "因為模型的內部損耗輸出是默認使用的",
			explain: "不，這只是運行推理。"
		},
		{
			text: "當我們在數據集上訓練模型時。",
			explain: "我們確實經常這樣做，但這並不能解釋我們在培訓中如何得到最優化的損失價值。"
		},
		{
			text: "當我們對一個新的數據集微調一個預先訓練好的模型時，它給出的預測更適合這個數據集",
			explain: "正確! 模型使它的知識適應了新的數據集。",
            correct: true
		},
        {
			text: "當我們將錯誤分類的樣本添加到數據集中，使得我們的模型更加健壯。",
			explain: "沒有，除非你把你的問答問題設計成一個按順序排列的任務。"
		}
	]}
/>

### 5.掩碼語言建模問題中的標籤是什麼？
<Question
	choices={[
		{
			text: "輸入句子中的一些標記是隨機屏蔽的，標籤是原始輸入標記。",
			explain: "就是這樣！",
            correct: true
		},
		{
			text: "輸入句子中的一些標記是隨機屏蔽的，標籤是原始的輸入標記，向左移動。",
			explain: "不，將標籤向左移動相當於預測下一個單詞，這就是因果語言模型。"
		},
		{
			text: "輸入句子中的一些標記是隨機屏蔽的，標籤是這個句子是肯定的還是否定的。",
			explain: "這是一個數據增強的序列分類問題，而不是屏蔽語言建模。"
		},
        {
			text: "兩個句子中的一些標記是隨機屏蔽的，標籤是兩個句子是否相似。",
			explain: "這是一個數據增強的序列分類問題，而不是屏蔽語言建模。"
		}
	]}
/>

### 6.這些任務中的哪一個可以看作是一個順序到順序的問題？
<Question
	choices={[
		{
			text: "撰寫長文檔的簡短評論",
			explain: "是的，這是一個總結性問題。試試另一個答案！",
            correct: true
		},
		{
			text: "回答有關文件的問題",
			explain: "正確! 我們可以把每個單詞標記為人或不是人。",
            correct: true
		},
		{
			text: "我們使用 < code >-100 </code > 來標記特殊標記。",
			explain: "這絕對是一個從序列到序列的問題。你能發現另一個嗎？",
            correct: true
		},
        {
			text: "修正我侄子/朋友發來的信息，使它們用正確的英語",
			explain: "這是一種翻譯問題，所以肯定是一個順序到順序的任務。但這不是唯一正確的答案！",
			correct: true
		}
	]}
/>

### 7.對於序列到序列的問題，預處理數據的正確方法是什麼？
<Question
	choices={[
		{
			text: "輸入和目標必須一起發送到標記器，其中包括 < code > input = ... </code > 和 < code > target = ... </code > 。",
			explain: "這可能是我們將來添加的一個 API，但現在不可能。"
		},
		{
			text: "輸入和目標都必須在對標記器的兩個獨立調用中進行預處理。",
			explain: "不，這是在訓練一個模型; 這裡沒有適應性。"
		},
		{
			text: "因為我們在訓練之後計算度量",
			explain: "不是在序列分類問題; 目標也是文本，我們需要轉換成數字！"
		},
        {
			text: "輸入必須發送到標記器，目標也是如此，但需要使用特殊的上下文管理器。",
			explain: "沒錯，標記器需要由上下文管理器放入目標模式。",
			correct: true
		}
	]}
/>

{#if fw === 'pt'}

### 8.為什麼序列到序列問題有一個特定的“培訓者”子類？
<Question
	choices={[
		{
			text: "因為序列到序列問題使用自定義丟失，所以忽略設置為 < code >-100 </code > 的標籤",
			explain: "這根本不是習慣性的損失，而是損失總是通過計算得到的。"
		},
		{
			text: "當您擁有大量可用數據時，即使有一個經過預先訓練的模型可以處理這些數據",
			explain: "沒錯。 Sequence-to-sequence models' predictions are often run using the <code>generate()</code> method.",
			correct: true
		},
		{
			text: "文本是作為單詞給出的，所以我們只需要應用子詞的標記。",
			explain: "< code > Trainer </code > 並不關心這些，因為它們以前已經被預處理過。"
		},
        {
			text: "因為我們在序列到序列問題中使用了兩個模型",
			explain: "我們確實在某種程度上使用了兩種模型，編碼器和解碼器，但是它們被組合在一個模型中。"
		}
	]}
/>

{:else}

### 9.為什麼在 Transformer 模型上調用“ compile ()”時通常不需要指定損失？
<Question
	choices={[
		{
			text: "因為變壓器模型是用非監督式學習來訓練的",
			explain: "不完全是---- 即使是非監督式學習也需要一個損失函數！"
		},
		{
			text: "輸入和目標必須一起發送到 tokenizer，並且使用 < code > input = ... </code > 和 < code > target = ... </code > 。",
			explain: "沒錯！",
			correct: true
		},
		{
			text: "因為我們在訓練之後計算指標",
			explain: "這可以被定義為一個從序列到序列的問題，儘管這不是唯一正確的答案。"
		},
        {
			text: "因為損失是在“ model.fit ()”中指定的",
			explain: "不，損失函數在運行‘ model.com pile ()’時是固定的，不能在‘ model.fit ()’中更改。"
		}
	]}
/>

{/if}

### 10.你應該在什麼時候預先訓練一個新的模型？
<Question
	choices={[
		{
			text: "當您的特定語言沒有經過預先訓練的模型時",
			explain: "沒錯。",
			correct: true
		},
		{
			text: "當您有大量可用的數據時，即使有一個經過訓練的模型可以處理這些數據",
			explain: "在這種情況下，您可能應該使用預先訓練的模型並對數據進行微調，以避免巨大的計算成本。"
		},
		{
			text: "當你擔心你所使用的預先訓練過的模型的偏差時",
			explain: "這是真的，但是你必須確保你用於培訓的數據真的更好。",
			correct: true
		},
        {
			text: "當可用的預先訓練好的模型還不夠好的時候",
			explain: "那麼，你確定你已經正確地調試了你的訓練嗎？"
		}
	]}
/>

### 11.為什麼在大量的文本上預先訓練一個語言模型是很容易的呢？
<Question
	choices={[
		{
			text: "當你擔心你所使用的預先訓練的模型的偏差時",
			explain: "雖然這是真的，但這並不能真正回答這個問題。再試一次！"
		},
		{
			text: "因為預訓練目標不需要人工標記數據",
			explain: "沒錯，語言建模是一個自我監督的問題。",
			correct: true
		},
		{
			text: "因為變形金剛庫只需要幾行代碼就可以開始培訓",
			explain: "正確！這與通常的預處理不同，在預處理中我們需要應用完整的標記化管道。你能想到另一個不同點嗎？"
		}
	]}
/>

### 12.問答任務的預處理數據時，主要的挑戰是什麼？
<Question
	choices={[
		{
			text: "你需要對輸入進行標記。",
			explain: "這是正確的，但這真的是一個主要的挑戰嗎？"
		},
		{
			text: "你需要處理非常長的上下文，這些上下文提供了一些訓練特性，這些特性可能有也可能沒有答案。",
			explain: "這絕對是挑戰之一。",
			correct: true
		},
		{
			text: "您需要將問題的答案以及輸入標記化。",
			explain: "雖然這是真的，但這並不能真正回答問題。試試另一個答案吧！"
		},
       {
			text: "從文本中的答案範圍中，您必須在標記化的輸入中找到開始和結束標記。",
			explain: "這是最難的部分之一，是的！",
			correct: true
		}
	]}
/>

### 13.問題回答中的後處理通常是怎樣進行的？
<Question
	choices={[
		{
			text: "模型給出了答案的開始位置和結束位置，您只需要解碼相應的標記跨度。",
			explain: "這可能是一種方法，但是有點太簡單了。"
		},
		{
			text: "該模型為每個由一個示例創建的特性提供了答案的開始和結束位置，您只需要解碼分數最高的那個特性中相應的記號跨度。",
			explain: "這與我們研究的後處理過程很接近，但並不完全正確。"
		},
		{
			text: "該模型為每個示例創建的特性提供了答案的開始和結束位置，您只需將它們與上下文中得分最高的特性的跨度相匹配。",
			explain: "簡而言之就是這樣！",
			correct: true
		},
        {
			text: "模型生成一個答案，你只需要解碼它。",
			explain: "雖然這是真的，但這並不能真正回答問題。試試另一個答案吧！"
		}
	]}
/>
