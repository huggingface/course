# تعارف[[introduction]]

<CourseFloatingBanner
    chapter={2}
    classNames="absolute z-10 right-0 top-0"
/>

جیسا کہ آپ نے [باب 1](/course/chapter1) میں دیکھا، ٹرانسفارمر ماڈلز عام طور پر بہت بڑے ہوتے ہیں۔ ان میں لاکھوں سے لے کر *اربوں* تک پیرا میٹرز ہوتے ہیں، جس کی وجہ سے ان ماڈلز کو ٹرین اور ڈپلائے کرنا ایک پیچیدہ کام بن جاتا ہے۔ مزید یہ کہ، تقریباً روزانہ نئے ماڈلز جاری ہو رہے ہیں، اور ہر ایک کی الگ امپلیمینٹیشن ہوتی ہے، جس کی وجہ سے تمام ماڈلز کو آزمانا آسان نہیں ہوتا۔

🤗 Transformers لائبریری اسی مسئلے کو حل کرنے کے لیے بنائی گئی تھی۔ اس کا مقصد ایک واحد API فراہم کرنا ہے جس کے ذریعے کسی بھی ٹرانسفارمر ماڈل کو لوڈ، ٹرین اور سیو کیا جا سکے۔ اس لائبریری کی بنیادی خصوصیات درج ذیل ہیں:

- **آسانی**: کسی جدید NLP ماڈل کو ڈاؤن لوڈ کرنا، لوڈ کرنا اور انفیرینس کے لیے استعمال کرنا صرف دو لائنز کے کوڈ میں ممکن ہے۔
- **لچکداری**: بنیادی طور پر، تمام ماڈلز سادہ PyTorch `nn.Module` یا TensorFlow `tf.keras.Model` کلاسز ہیں اور انہیں ML فریم ورکس میں کسی بھی دوسرے ماڈل کی طرح استعمال کیا جا سکتا ہے۔
- **سادگی**: لائبریری میں زیادہ پیچیدہ تجریدات نہیں کی گئیں۔ "سب کچھ ایک فائل میں" کا اصول اپنایا گیا ہے: کسی ماڈل کا فارورڈ پاس مکمل طور پر ایک ہی فائل میں بیان کیا گیا ہے، تاکہ کوڈ کو سمجھنا اور اس میں ترمیم کرنا آسان ہو۔

یہ آخری خصوصیت 🤗 Transformers کو دیگر ML لائبریریوں سے کافی مختلف بناتی ہے۔ ماڈلز کو مختلف فائلز میں شیئر کیے جانے والے ماڈیولز پر مبنی نہیں بنایا گیا، بلکہ ہر ماڈل کی اپنی الگ تہیں (layers) ہوتی ہیں۔ اس سے نہ صرف ماڈلز کو سمجھنا اور ان پر کام کرنا آسان ہو جاتا ہے، بلکہ آپ کسی ایک ماڈل پر تجربہ کر سکتے ہیں بغیر دوسرے ماڈلز پر اثر ڈالے۔

اس باب میں ہم ایک مکمل مثال سے شروعات کریں گے، جہاں ہم ایک ماڈل اور ٹوکنائزر کو ایک ساتھ استعمال کریں گے تاکہ `pipeline()` فنکشن کو دوبارہ تخلیق کیا جا سکے، جس کا ذکر ہم نے [باب 1](/course/chapter1) میں کیا تھا۔ اس کے بعد، ہم ماڈل API پر گفتگو کریں گے: ہم ماڈل اور کنفیگریشن کلاسز کو گہرائی میں سمجھیں گے، اور دیکھیں گے کہ ماڈل کو لوڈ کیسے کیا جاتا ہے اور یہ عددی ان پٹس کو کیسے پراسیس کر کے پیش گوئیاں دیتا ہے۔

پھر ہم ٹوکنائزر API پر نظر ڈالیں گے، جو کہ `pipeline()` فنکشن کا دوسرا اہم جزو ہے۔ ٹوکنائزرز ٹیکسٹ کو عددی ان پٹس میں تبدیل کرنے اور نتیجہ واپس ٹیکسٹ میں تبدیل کرنے کے عمل کو سنبھالتے ہیں۔ آخر میں، ہم دیکھیں گے کہ ایک ماڈل میں ایک ساتھ کئی جملے کیسے بھیجے جا سکتے ہیں اور `tokenizer()` فنکشن کو مزید تفصیل سے سمجھیں گے۔

<Tip>
⚠️ ماڈل ہب اور 🤗 Transformers کی تمام خصوصیات سے فائدہ اٹھانے کے لیے، ہم تجویز کرتے ہیں کہ آپ <a href="https://huggingface.co/join">اکاؤنٹ بنائیں</a>۔
</Tip>
