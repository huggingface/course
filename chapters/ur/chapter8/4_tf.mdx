<FrameworkSwitchCourse {fw} />

# تربیتی پائپ لائن کی ڈیبگنگ[[debugging-the-training-pipeline]]

<CourseFloatingBanner chapter={8}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter8/section4_tf.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter8/section4_tf.ipynb"},
]} />

آپ نے ایک خوبصورت اسکرپٹ لکھا ہے تاکہ کسی مخصوص ٹاسک پر ماڈل کو تربیت یا فائن ٹیون کیا جا سکے، [Chapter 7](/course/chapter7) کی ہدایات پر عمل کرتے ہوئے۔ مگر جب آپ `model.fit()` کمانڈ چلاتے ہیں، تو کچھ نہایت خوفناک ہوتا ہے: آپ کو ایک ایرر ملتا ہے 😱! یا بدتر، ہر چیز ٹھیک چلتی نظر آتی ہے اور تربیت بغیر ایرر کے چلتی ہے، مگر نتیجے میں حاصل شدہ ماڈل ناقص نکلتا ہے۔ اس حصے میں، ہم آپ کو دکھائیں گے کہ ان مسائل کو ڈیبگ کرنے کے لیے آپ کیا کر سکتے ہیں۔

## تربیتی پائپ لائن کی ڈیبگنگ[[debugging-the-training-pipeline]]

<Youtube id="N9kO52itd0Q"/>

جب آپ `model.fit()` میں ایرر کا سامنا کرتے ہیں تو مسئلہ متعدد ذرائع سے پیدا ہو سکتا ہے، کیونکہ تربیت عموماً ان تمام چیزوں کو اکٹھا کر دیتی ہے جن پر آپ اب تک کام کر رہے ہوتے ہیں۔ مسئلہ آپ کے ڈیٹاسیٹ میں خرابی، یا ڈیٹاسیٹس کے عناصر کو بیچ (batch) کرنے میں کسی مسئلے کی وجہ سے ہو سکتا ہے۔ یا پھر ماڈل کے کوڈ، نقصان فنکشن (loss function) یا optimizer میں خرابی ہو سکتی ہے۔ اور اگرچہ تربیت ٹھیک چل جائے، تب بھی اگر آپ کے میٹرک (metric) میں مسئلہ ہو تو تشخیص (evaluation) کے دوران بھی کچھ غلط ہو سکتا ہے۔

`model.fit()` سے پیدا ہونے والی ایرر کو ڈیبگ کرنے کا بہترین طریقہ یہ ہے کہ آپ دستی طور پر پوری پائپ لائن سے گزریں تاکہ یہ معلوم ہو سکے کہ مسئلہ کہاں ہوا۔ اس کے بعد ایرر عموماً بہت آسانی سے حل ہو جاتا ہے۔

اس کی وضاحت کے لیے، ہم مندرجہ ذیل اسکرپٹ استعمال کریں گے جو [MNLI ڈیٹاسیٹ](https://huggingface.co/datasets/glue) پر DistilBERT ماڈل کو فائن ٹیون کرنے کی کوشش کرتا ہے:

```py
from datasets import load_dataset
import evaluate
from transformers import (
    AutoTokenizer,
    TFAutoModelForSequenceClassification,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
    return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)

train_dataset = tokenized_datasets["train"].to_tf_dataset(
    columns=["input_ids", "labels"], batch_size=16, shuffle=True
)

validation_dataset = tokenized_datasets["validation_matched"].to_tf_dataset(
    columns=["input_ids", "labels"], batch_size=16, shuffle=True
)

model = TFAutoModelForSequenceClassification.from_pretrained(model_checkpoint)

model.compile(loss="sparse_categorical_crossentropy", optimizer="adam")

model.fit(train_dataset)
```

اگر آپ اسے چلانے کی کوشش کرتے ہیں تو آپ کو ڈیٹاسیٹ کنورژن کے دوران کچھ `VisibleDeprecationWarning`s مل سکتے ہیں — یہ ایک معروف UX مسئلہ ہے، لہٰذا براہ کرم اسے نظر انداز کریں۔ اگر آپ یہ کورس مثلاً نومبر 2021 کے بعد پڑھ رہے ہیں اور مسئلہ اب بھی ہو رہا ہے، تو @carrigmat کو غصے بھری ٹویٹس بھیجیں جب تک کہ وہ اسے ٹھیک نہ کر دیں۔

لیکن ایک زیادہ سنگین مسئلہ یہ ہے کہ ہمیں ایک واضح ایرر مل جاتا ہے۔ اور یہ واقعی، بہت لمبا اور خوفناک ہے:

```python out
ValueError: No gradients provided for any variable: ['tf_distil_bert_for_sequence_classification/distilbert/embeddings/word_embeddings/weight:0', '...']
```

اس کا کیا مطلب ہے؟ ہم نے اپنے ڈیٹا پر تربیت کی کوشش کی، مگر ہمیں کوئی gradient نہیں ملا؟ یہ کافی پریشان کن ہے؛ ہم اس طرح کے مسئلے کو ڈیبگ کرنا کہاں سے شروع کریں؟ جب آپ کو ملنے والا ایرر فوری طور پر یہ نہ بتائے کہ مسئلہ کہاں ہے، تو بہترین حل یہ ہے کہ آپ ترتیب وار تمام مراحل کا جائزہ لیں، اور یہ دیکھیں کہ کہاں سب کچھ ٹھیک نظر آتا ہے۔ اور یقیناً، آغاز کا بہترین نقطہ یہ ہے کہ...

### اپنے ڈیٹا کو چیک کریں[[check-your-data]]

یہ کہے بغیر رہ ہی نہیں سکتا کہ اگر آپ کا ڈیٹا خراب ہو، تو Keras اسے ٹھیک نہیں کر پائے گا۔ لہٰذا سب سے پہلے، آپ کو اپنے تربیتی سیٹ کے اندر کیا ہے یہ دیکھنا ہوگا۔

اگرچہ `raw_datasets` اور `tokenized_datasets` کے اندر دیکھنا پرکشش ہو سکتا ہے، ہم آپ کو یہ تجویز کرتے ہیں کہ آپ ماڈل میں داخل ہونے سے عین پہلے ڈیٹا دیکھیں۔ اس کا مطلب ہے کہ `to_tf_dataset()` فنکشن سے تخلیق کیے گئے `tf.data.Dataset` کا آؤٹ پٹ پڑھیں! تو یہ کیسے کریں؟ `tf.data.Dataset` آبجیکٹس ایک وقت میں پورے بیچ دیتے ہیں اور انڈیکسنگ کی حمایت نہیں کرتے، لہٰذا ہم سیدھا `train_dataset[0]` نہیں کہہ سکتے۔ تاہم، ہم مہذب انداز میں ایک بیچ طلب کر سکتے ہیں:

```py
for batch in train_dataset:
    break
```

یہ `break` لوپ کو ایک تکرار کے بعد ختم کر دیتا ہے، لہٰذا یہ `train_dataset` کا پہلا بیچ حاصل کر کے اسے `batch` کے نام سے محفوظ کر لیتا ہے۔ اب، آئیں دیکھتے ہیں کہ اس کے اندر کیا موجود ہے:

```python out
{'attention_mask': <tf.Tensor: shape=(16, 76), dtype=int64, numpy=
 array([[1, 1, 1, ..., 0, 0, 0],
        [1, 1, 1, ..., 0, 0, 0],
        [1, 1, 1, ..., 0, 0, 0],
        ...,
        [1, 1, 1, ..., 1, 1, 1],
        [1, 1, 1, ..., 0, 0, 0],
        [1, 1, 1, ..., 0, 0, 0]])>,
 'label': <tf.Tensor: shape=(16,), dtype=int64, numpy=array([0, 2, 1, 2, 1, 1, 2, 0, 0, 0, 1, 0, 1, 2, 2, 1])>,
 'input_ids': <tf.Tensor: shape=(16, 76), dtype=int64, numpy=
 array([[ 101, 2174, 1010, ...,    0,    0,    0],
        [ 101, 3174, 2420, ...,    0,    0,    0],
        [ 101, 2044, 2048, ...,    0,    0,    0],
        ...,
        [ 101, 3398, 3398, ..., 2051, 2894,  102],
        [ 101, 1996, 4124, ...,    0,    0,    0],
        [ 101, 1999, 2070, ...,    0,    0,    0]])>}
```

یہ ٹھیک لگ رہا ہے، ہے نا؟ ہم `labels`, `attention_mask`, اور `input_ids` ماڈل کو دے رہے ہیں، جو کہ اسے آؤٹ پٹ کمپیوٹ کرنے اور نقصان (loss) کا حساب لگانے کے لیے درکار تمام چیزیں ہونی چاہئیں۔ تو پھر ہمیں gradient کیوں نہیں مل رہے؟ غور سے دیکھیں: ہم ایک واحد ڈکشنری بطور ان پٹ دے رہے ہیں، مگر ایک تربیتی بیچ عموماً ایک ان پٹ tensor یا ڈکشنری کے ساتھ ایک labels tensor بھی ہوتا ہے۔ ہمارے labels صرف ان پٹ ڈکشنری میں ایک کلید کے طور پر موجود ہیں۔

کیا یہ مسئلہ ہے؟ ہمیشہ نہیں، مگر یہ TensorFlow کے ساتھ Transformer ماڈلز کی تربیت کرتے وقت آپ کو درپیش ہونے والے سب سے عام مسائل میں سے ایک ہے۔ ہمارے ماڈلز اندرونی طور پر نقصان کمپیوٹ کر سکتے ہیں، مگر ایسا کرنے کے لیے labels کو ان پٹ ڈکشنری میں ہی پاس کیا جانا چاہیے۔ یہی نقصان ہے جو اس وقت استعمال ہوتا ہے جب ہم `compile()` میں کسی نقصان کی ویلیو کو مخصوص نہیں کرتے۔ دوسری جانب، Keras عموماً labels کو ان پٹ ڈکشنری سے الگ توقع کرتا ہے، اور اگر آپ ایسا نہ کریں تو نقصان کا حساب عموماً ناکام ہو جاتا ہے۔

اب مسئلہ واضح ہو گیا ہے: ہم نے `loss` آرگیومنٹ پاس کیا، جس کا مطلب ہے کہ ہم Keras سے نقصان کمپیوٹ کرنے کو کہہ رہے ہیں، مگر ہم نے اپنے labels ماڈل کو ان پٹ کے طور پر دے دیے، نہ کہ Keras کی توقع کے مطابق۔ ہمیں دونوں میں سے ایک کا انتخاب کرنا ہوگا: یا تو ہم ماڈل کا اندرونی نقصان استعمال کریں اور labels کو ویسے ہی چھوڑ دیں، یا پھر Keras نقصان استعمال کریں مگر labels کو Keras کے متعین مقام پر منتقل کریں۔ سادگی کے لیے، آئیے پہلا طریقہ اختیار کرتے ہیں۔ `compile()` کی کال کو اس طرح تبدیل کریں:

```py
model.compile(optimizer="adam")
```

اب ہم ماڈل کا اندرونی نقصان استعمال کریں گے، اور یہ مسئلہ حل ہو جانا چاہیے!

<Tip>

✏️ **آپ کی باری!** ایک اختیاری چیلنج کے طور پر، جب ہم باقی مسائل حل کر لیں، تو آپ اس مرحلے پر واپس آ کر کوشش کر سکتے ہیں کہ ماڈل کو اصلی Keras-کمپیوٹڈ نقصان کے ساتھ کام کروائیں بجائے اندرونی نقصان کے۔ آپ کو `to_tf_dataset()` کے `label_cols` آرگیومنٹ میں `"labels"` شامل کرنا ہوگا تاکہ labels صحیح طور پر آؤٹ پٹ کیے جائیں، جس سے آپ کو gradients مل جائیں گے — مگر اس نقصان کے ساتھ ایک اور مسئلہ ہے۔ تربیت اس مسئلے کے ساتھ بھی چلے گی، مگر سیکھنا بہت آہستہ ہوگا اور ایک بلند تربیتی نقصان پر پھسل جائے گا۔ کیا آپ اس کا پتہ لگا سکتے ہیں؟

A ROT13-encoded hint, if you're stuck: Vs lbh ybbx ng gur bhgchgf bs FrdhraprPynffvsvpngvba zbqryf va Genafsbezref, gurve svefg bhgchg vf `ybtvgf`. Jung ner ybtvgf?

And a second hint: Jura lbh fcrpvsl bcgvzvmref, npgvingvbaf be ybffrf jvgu fgevatf, Xrenf frgf nyy gur nethzrag inyhrf gb gurve qrsnhygf. Jung nethzragf qbrf FcnefrPngrtbevpnyPebffragebcl unir, naq jung ner gurve qrsnhygf?

</Tip>

اب، آئیں تربیت کی کوشش کریں۔ ہمیں اب gradients مل جانے چاہئیں، لہٰذا امید ہے کہ (اندھیری موسیقی بجتی ہے) ہم بس `model.fit()` کال کریں اور سب کچھ ٹھیک چل جائے گا!

```python out
  246/24543 [..............................] - ETA: 15:52 - loss: nan
```

افسوس۔

`nan` ایک حوصلہ افزا نقصان ویلیو نہیں ہے۔ پھر بھی، ہم نے اپنے ڈیٹا کو چیک کر لیا ہے، اور وہ کافی ٹھیک نظر آ رہا ہے۔ اگر یہ مسئلہ نہیں تو آگے کیا کریں؟ واضح اگلا قدم یہ ہے کہ...

### اپنے ماڈل کو چیک کریں[[check-your-model]]

`model.fit()` Keras کا ایک بہت ہی سہل فنکشن ہے، مگر یہ آپ کے لیے بہت سی چیزیں خود بخود کر دیتا ہے، جس سے یہ پتہ لگانا مشکل ہو جاتا ہے کہ مسئلہ اصل میں کہاں ہو رہا ہے۔ اگر آپ اپنے ماڈل کو ڈیبگ کر رہے ہیں، تو ایک حکمت عملی یہ ہے کہ آپ ماڈل کو صرف ایک بیچ پاس کریں اور اُس بیچ کے آؤٹ پٹ کو تفصیل سے دیکھیں۔ ایک اور مددگار ٹپ اگر ماڈل ایررز پھینک رہا ہو تو یہ ہے کہ ماڈل کو `compile()` کرتے وقت `run_eagerly=True` سیٹ کر دیں۔ اس سے ماڈل کافی سست چل جائے گا، مگر ایرر میسجز بہت زیادہ واضح ہو جائیں گے، کیونکہ وہ ٹھیک بتائیں گے کہ آپ کے ماڈل کے کوڈ کے کس حصے میں مسئلہ پیدا ہوا ہے۔

فی الحال، ہمیں ابھی `run_eagerly` کی ضرورت نہیں ہے۔ آئیں اُس `batch` کو جو پہلے حاصل کیا تھا ماڈل سے گزار کر دیکھتے ہیں کہ آؤٹ پٹ کیسی نکلتی ہے:

```py
model(batch)
```

```python out
TFSequenceClassifierOutput(loss=<tf.Tensor: shape=(16,), dtype=float32, numpy=
array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
       nan, nan, nan], dtype=float32)>, logits=<tf.Tensor: shape=(16, 2), dtype=float32, numpy=
array([[nan, nan],
       [nan, nan],
       [nan, nan],
       [nan, nan],
       [nan, nan],
       [nan, nan],
       [nan, nan],
       [nan, nan],
       [nan, nan],
       [nan, nan],
       [nan, nan],
       [nan, nan],
       [nan, nan],
       [nan, nan],
       [nan, nan],
       [nan, nan]], dtype=float32)>, hidden_states=None, attentions=None)
```

یہ تو کافی پیچیدہ ہے۔ سب کچھ `nan` آ رہا ہے! مگر یہ عجیب بھی ہے، ہے نا؟ ہمارے تمام logits `nan` کیسے ہو گئے؟ `nan` کا مطلب "not a number" ہوتا ہے۔ `nan` کی ویلیوز عموماً کسی ممنوع آپریشن جیسے کہ صفر سے تقسیم کرنے پر ظاہر ہوتی ہیں۔ مگر مشین لرننگ میں ایک اہم بات یہ جاننا ضروری ہے کہ `nan` ویلیو عام طور پر *پھیل جاتی ہے*۔ اگر آپ کسی عدد کو `nan` سے ضرب دیتے ہیں تو نتیجہ بھی `nan` ہوتا ہے۔ اور اگر کہیں بھی آپ کے آؤٹ پٹ، نقصان یا gradient میں `nan` آ جائے تو یہ جلد ہی پورے ماڈل میں پھیل جائے گا — کیونکہ جب وہ `nan` ویلیو آپ کے نیٹ ورک میں پیچھے منتقل ہوتی ہے، تو آپ کو `nan` gradients ملتے ہیں، اور جب وزن (weights) اپ ڈیٹ کیے جاتے ہیں تو وہ بھی `nan` ہو جاتے ہیں، اور پھر وہ وزن مزید `nan` آؤٹ پٹ کمپیوٹ کرتے ہیں! جلد ہی پورا نیٹ ورک صرف `nan` کی ایک بڑی دیوار بن جائے گا۔ ایک بار ایسا ہونے کے بعد، یہ دیکھنا مشکل ہو جاتا ہے کہ مسئلہ کہاں سے شروع ہوا۔ ہم کیسے الگ کر سکتے ہیں کہ `nan` پہلی بار کہاں آیا؟

اس کا جواب یہ ہے کہ ہم اپنے ماڈل کو *دوبارہ initialize* کرنے کی کوشش کریں۔ جب سے ہم نے تربیت شروع کی، کہیں پر ایک `nan` آ گیا اور یہ جلد ہی پورے ماڈل میں پھیل گیا۔ تو، آئیں ماڈل کو ایک checkpoint سے لوڈ کریں اور وزن اپ ڈیٹس نہ کریں، اور دیکھیں کہ کہاں `nan` آ رہا ہے:

```py
model = TFAutoModelForSequenceClassification.from_pretrained(model_checkpoint)
model(batch)
```

جب ہم یہ چلائیں تو ہمیں ملتا ہے:

```python out
TFSequenceClassifierOutput(loss=<tf.Tensor: shape=(16,), dtype=float32, numpy=
array([0.6844486 ,        nan,        nan, 0.67127866, 0.7068601 ,
              nan, 0.69309855,        nan, 0.65531296,        nan,
              nan,        nan, 0.675402  ,        nan,        nan,
       0.69831556], dtype=float32)>, logits=<tf.Tensor: shape=(16, 2), dtype=float32, numpy=
array([[-0.04761693, -0.06509043],
       [-0.0481936 , -0.04556257],
       [-0.0040929 , -0.05848458],
       [-0.02417453, -0.0684005 ],
       [-0.02517801, -0.05241832],
       [-0.04514256, -0.0757378 ],
       [-0.02656011, -0.02646275],
       [ 0.00766164, -0.04350497],
       [ 0.02060014, -0.05655622],
       [-0.02615328, -0.0447021 ],
       [-0.05119278, -0.06928903],
       [-0.02859691, -0.04879177],
       [-0.02210129, -0.05791225],
       [-0.02363213, -0.05962167],
       [-0.05352269, -0.0481673 ],
       [-0.08141848, -0.07110836]], dtype=float32)>, hidden_states=None, attentions=None)
```

اب ہم نے کچھ بہتری دیکھی! ہمارے logits میں کوئی `nan` ویلیوز نہیں ہیں، جو تسلی بخش ہے۔ مگر ہم اپنے نقصان میں چند `nan` ویلیوز دیکھ رہے ہیں! کیا ان نمونوں (samples) میں کوئی خاص بات ہے جو یہ مسئلہ پیدا کر رہی ہو؟ آئیں دیکھتے ہیں کہ یہ کس اندیکس پر ہیں (نوٹ کریں کہ اگر آپ یہ کوڈ خود چلائیں تو آپ کو مختلف اندیکس بھی مل سکتے ہیں کیونکہ ڈیٹاسیٹ کو shuffle کیا گیا ہے):

```python
import numpy as np

loss = model(batch).loss.numpy()
indices = np.flatnonzero(np.isnan(loss))
indices
```

```python out
array([ 1,  2,  5,  7,  9, 10, 11, 13, 14])
```

آئیں دیکھتے ہیں کہ ان اندیکس والے نمونے کس چیز سے آئے ہیں:

```python
input_ids = batch["input_ids"].numpy()
input_ids[indices]
```

```python out
array([[  101,  2007,  2032,  2001,  1037, 16480,  3917,  2594,  4135,
        23212,  3070,  2214, 10170,  1010,  2012,  4356,  1997,  3183,
         6838, 12953,  2039,  2000,  1996,  6147,  1997,  2010,  2606,
         1012,   102,  6838,  2001,  3294,  6625,  3773,  1996,  2214,
         2158,  1012,   102,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0],
       [  101,  1998,  6814,  2016,  2234,  2461,  2153,  1998, 13322,
         2009,  1012,   102,  2045,  1005,  1055,  2053,  3382,  2008,
         2016,  1005,  2222,  3046,  8103,  2075,  2009,  2153,  1012,
          102,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0],
       [  101,  1998,  2007,  1996,  3712,  4634,  1010,  2057,  8108,
         2025,  3404,  2028,  1012,  1996,  2616, 18449,  2125,  1999,
         1037,  9666,  1997,  4100,  8663, 11020,  6313,  2791,  1998,
         2431,  1011,  4301,  1012,   102,  2028,  1005,  1055,  5177,
         2110,  1998,  3977,  2000,  2832,  2106,  2025,  2689,  2104,
         2122,  6214,  1012,   102,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0],
       [  101,  1045,  2001,  1999,  1037, 13090,  5948,  2007,  2048,
         2308,  2006,  2026,  5001,  2043,  2026,  2171,  2001,  2170,
         1012,   102,  1045,  2001,  3564,  1999,  2277,  1012,   102,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0],
       [  101,  2195,  4279,  2191,  2039,  1996,  2181,  2124,  2004,
         1996,  2225,  7363,  1012,   102,  2045,  2003,  2069,  2028,
         2451,  1999,  1996,  2225,  7363,  1012,   102,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0],
       [  101,  2061,  2008,  1045,  2123,  1005,  1056,  2113,  2065,
         2009,  2428, 10654,  7347,  2030,  2009,  7126,  2256,  2495,
         2291,   102,  2009,  2003,  5094,  2256,  2495,  2291,  2035,
         2105,  1012,   102,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0],
       [  101,  2051,  1010,  2029,  3216,  2019,  2503,  3444,  1010,
         6732,  1996,  2265,  2038, 19840,  2098,  2125,  9906,  1998,
         2003,  2770,  2041,  1997,  4784,  1012,   102,  2051,  6732,
         1996,  2265,  2003,  9525,  1998,  4569,  1012,   102,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0],
       [  101,  1996, 10556,  2140, 11515,  2058,  1010,  2010,  2162,
         2252,  5689,  2013,  2010,  7223,  1012,   102,  2043,  1996,
        10556,  2140, 11515,  2058,  1010,  2010,  2252,  3062,  2000,
         1996,  2598,  1012,   102,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0],
       [  101, 13543,  1999,  2049,  6143,  2933,  2443,   102,  2025,
        13543,  1999,  6143,  2933,  2003,  2443,   102,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0]])
```



خیر، یہاں بہت کچھ ہے، لیکن کچھ بھی غیر معمولی نہیں لگ رہا۔ آئیے لیبلز پر نظر ڈالتے ہیں:

```python out
labels = batch['labels'].numpy()
labels[indices]
```

```python out
array([2, 2, 2, 2, 2, 2, 2, 2, 2])
```

آہ! `nan` والے تمام نمونے ایک ہی لیبل رکھتے ہیں، اور وہ لیبل 2 ہے۔ یہ ایک بہت مضبوط اشارہ ہے۔ یہ حقیقت کہ ہمیں صرف اس وقت `nan` نقصان ہو رہا ہے جب ہمارا لیبل 2 ہو، یہ بتاتی ہے کہ اب ہمارے ماڈل میں لیبلز کی تعداد کو چیک کرنے کا اچھا وقت ہے:

```python
model.config.num_labels
```

```python out
2
```

اب ہمیں مسئلہ نظر آ رہا ہے: ماڈل سمجھتا ہے کہ صرف دو کلاسز ہیں، لیکن لیبلز 2 تک جا رہے ہیں، جس کا مطلب ہے کہ حقیقت میں تین کلاسز ہیں (کیونکہ 0 بھی ایک کلاس ہے)۔ یہی وجہ ہے کہ ہمیں `nan` ملا—ہم نے ایک غیر موجود کلاس کے لیے نقصان کا حساب لگانے کی کوشش کی! آئیے اسے درست کریں اور ماڈل کو دوبارہ فٹ کریں:

```python
model = TFAutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=3)
model.compile(optimizer='adam')
model.fit(train_dataset)
```

```python out
  869/24543 [>.............................] - ETA: 15:29 - loss: 1.1032
```

ہم ٹریننگ کر رہے ہیں! اب مزید `nan` نہیں، اور ہمارا نقصان کم ہو رہا ہے... کسی حد تک۔ اگر آپ اسے کچھ دیر دیکھیں تو آپ تھوڑے بے صبر ہو سکتے ہیں، کیونکہ نقصان کی قیمت ضدی طور پر زیادہ رہتی ہے۔ آئیے یہاں رکیں اور سوچیں کہ یہ مسئلہ کیوں پیدا ہو رہا ہے۔ اس مقام پر، ہمیں یقین ہے کہ ڈیٹا اور ماڈل دونوں درست ہیں، لیکن ہمارا ماڈل اچھی طرح سیکھ نہیں رہا۔ اب کیا باقی بچا ہے؟ یہ وقت ہے...

### اپنے ہائپر پیرامیٹرز چیک کریں[[check-your-hyperparameters]]

اگر آپ اوپر دیے گئے کوڈ پر نظر ڈالیں تو آپ کو شاید کوئی ہائپر پیرامیٹر نظر نہ آئے، سوائے `batch_size` کے، اور وہ بھی ایک ممکنہ مسئلہ نہیں لگتا۔ لیکن دھوکہ نہ کھائیں؛ ہمیشہ ہائپر پیرامیٹرز ہوتے ہیں، اور اگر آپ انہیں نہیں دیکھ پا رہے تو اس کا مطلب ہے کہ آپ نہیں جانتے کہ وہ کیا سیٹ کیے گئے ہیں۔ خاص طور پر، Keras کے بارے میں ایک اہم چیز یاد رکھیں: اگر آپ کسی نقصان، آپٹیمائزر، یا ایکٹیویشن فنکشن کو ایک سٹرنگ کے طور پر سیٹ کرتے ہیں، _تو اس کے تمام دلائل ڈیفالٹ اقدار پر سیٹ ہو جائیں گے_۔

اس معاملے میں، ہم نے سٹرنگ کے ساتھ کہاں سیٹ کیا؟ ہم نے شروع میں نقصان کو سٹرنگ کے ساتھ سیٹ کیا تھا، لیکن اب ایسا نہیں کر رہے۔ تاہم، ہم ابھی بھی آپٹیمائزر کو ایک سٹرنگ کے ساتھ سیٹ کر رہے ہیں۔ کیا اس سے کچھ پوشیدہ ہو سکتا ہے؟ آئیے اس کے [دلائل](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) کو دیکھیں۔

یہاں کچھ خاص نظر آ رہا ہے؟ بالکل—لرننگ ریٹ! جب ہم سٹرنگ `'adam'` استعمال کرتے ہیں، تو ہمیں ڈیفالٹ لرننگ ریٹ 0.001 یا 1e-3 ملتا ہے۔ یہ ایک ٹرانسفارمر ماڈل کے لیے بہت زیادہ ہے! عام طور پر، ہم 1e-5 اور 1e-4 کے درمیان لرننگ ریٹ آزمانے کی سفارش کرتے ہیں؛ جو کہ موجودہ قدر سے 10X یا 100X کم ہے۔ آئیے اسے کم کرنے کی کوشش کریں۔ اس کے لیے، ہمیں اصل `optimizer` آبجیکٹ کو امپورٹ کرنا ہوگا۔ جبکہ ہم ایسا کر رہے ہیں، آئیے ماڈل کو بھی دوبارہ انیشیئلائز کریں:

```python
from tensorflow.keras.optimizers import Adam

model = TFAutoModelForSequenceClassification.from_pretrained(model_checkpoint)
model.compile(optimizer=Adam(5e-5))
```

<Tip>

💡 آپ 🤗 Transformers سے `create_optimizer()` فنکشن بھی امپورٹ کر سکتے ہیں، جو آپ کو ایک AdamW آپٹیمائزر دے گا جو صحیح ویٹ ڈیکے اور لرننگ ریٹ وارم اپ کے ساتھ بہتر نتائج دے سکتا ہے۔

</Tip>

اب، ہم نئے بہتر لرننگ ریٹ کے ساتھ ماڈل کو فٹ کرنے کی کوشش کر سکتے ہیں:

```python
model.fit(train_dataset)
```

```python out
319/24543 [..............................] - ETA: 16:07 - loss: 0.9718
```

اب ہمارا نقصان واقعی کم ہو رہا ہے! ٹریننگ آخرکار ٹھیک کام کر رہی ہے۔ یہاں سبق یہ ہے: جب آپ کا ماڈل چل رہا ہو لیکن نقصان کم نہ ہو رہا ہو، اور آپ کو اپنے ڈیٹا پر یقین ہو، تو لرننگ ریٹ اور ویٹ ڈیکے جیسے ہائپر پیرامیٹرز چیک کرنا اچھا خیال ہو سکتا ہے۔

## دیگر ممکنہ مسائل[[other-potential-issues]]

### آؤٹ آف میموری ایررز سے نمٹنا[[dealing-with-out-of-memory-errors]]

اگر آپ کو "OOM when allocating tensor" جیسا ایرر ملتا ہے، تو اس کا مطلب ہے کہ آپ کی میموری ختم ہو رہی ہے۔ بڑے لینگویج ماڈلز کے ساتھ یہ ایک عام مسئلہ ہے۔ اگر آپ کو یہ مسئلہ درپیش ہو، تو بیچ سائز کو آدھا کر کے دوبارہ کوشش کریں۔

<Tip>

اگلے حصے میں، ہم مزید جدید تکنیکوں پر بات کریں گے جو آپ کی میموری کے استعمال کو کم کر سکتی ہیں اور آپ کو بڑے ماڈلز کو فائن ٹیون کرنے میں مدد دے سکتی ہیں۔

</Tip>

### TensorFlow کی میموری بھوک 🦛[[hungry-hungry-tensorflow]]

TensorFlow جی پی یو کی تمام میموری کو پہلے ہی ایلوکیٹ کر لیتا ہے جب آپ کوئی ماڈل لوڈ کرتے ہیں، جو PyTorch سے مختلف رویہ ہے۔ اگر آپ دو TensorFlow پروسیسز ایک ساتھ چلاتے ہیں، تو مسائل پیدا ہو سکتے ہیں۔ خاص طور پر، Colab میں یہ مسئلہ نہیں ہوتا، لیکن اگر آپ لوکل مشین پر ہیں، تو یقینی بنائیں کہ کوئی اور نوٹ بک میموری کو ہولڈ نہیں کر رہی۔

### اپنے ڈیٹا کو دوبارہ چیک کریں[[check-your-data-again]]

اگر آپ کا ماڈل کچھ نہیں سیکھ رہا، تو ہو سکتا ہے کہ آپ کے ڈیٹا میں کوئی مسئلہ ہو۔ `tokenizer.decode()` کا استعمال کریں تاکہ آپ دیکھ سکیں کہ آپ کا ڈیٹا صحیح طور پر لیبل شدہ ہے یا نہیں۔

### ایک بیچ پر ماڈل کو اوور فٹ کریں[[overfit-your-model-on-one-batch]]

ایک بیچ پر ماڈل کو بار بار فٹ کرنا ایک اچھی آزمائش ہے کہ آیا ماڈل مسئلے کو حل کر سکتا ہے یا نہیں۔ یہ آپ کو یہ بھی دکھائے گا کہ آیا آپ کا لرننگ ریٹ بہت زیادہ ہے۔

```py
for batch in train_dataset:
    break

# Make sure you have run model.compile() and set your optimizer,
# and your loss/metrics if you're using them

model.fit(batch, epochs=20)
```
Here is your translated text in MDX format, keeping the code and links intact:

---

<Tip>

💡 اگر آپ کے تربیتی ڈیٹا میں عدم توازن ہے، تو اس بات کو یقینی بنائیں کہ تمام لیبلز پر مشتمل ایک بیچ بنائیں۔

</Tip>

حاصل شدہ ماڈل کو `batch` پر تقریباً مکمل نتائج فراہم کرنے چاہئیں، اور نقصان (loss) تیزی سے 0 کی طرف یا اس نقصان کی کم از کم قدر کی طرف جانا چاہیے جسے آپ استعمال کر رہے ہیں۔

اگر آپ کا ماڈل اس طرح کے کامل نتائج حاصل نہیں کر پاتا، تو اس کا مطلب ہے کہ مسئلہ کو فریم کرنے یا آپ کے ڈیٹا میں کچھ غلط ہے، اور آپ کو اسے درست کرنا ہوگا۔ جب تک آپ اپنے ماڈل کو اوورفٹنگ ٹیسٹ (overfitting test) پاس کرتے ہوئے نہ دیکھ لیں، آپ اس بات کا یقین نہیں کر سکتے کہ یہ درحقیقت کچھ سیکھ سکتا ہے۔

<Tip warning={true}>

⚠️ آپ کو اس اوورفٹنگ ٹیسٹ کے بعد اپنے ماڈل کو دوبارہ بنانا اور دوبارہ مرتب کرنا (recompile) ہوگا، کیونکہ یہ ماڈل ممکنہ طور پر مکمل ڈیٹا سیٹ پر کچھ مفید سیکھنے کے قابل نہیں ہوگا۔

</Tip>

### جب تک آپ کے پاس ایک ابتدائی بیس لائن نہ ہو، کچھ بھی ٹیون نہ کریں[[dont-tune-anything-until-you-have-a-first-baseline]]

مشین لرننگ میں ہائپر پیرامیٹر ٹیوننگ کو اکثر سب سے مشکل حصہ سمجھا جاتا ہے، لیکن یہ صرف آخری مرحلہ ہوتا ہے تاکہ میٹرک میں تھوڑا بہتری حاصل کی جا سکے۔ *بہت* خراب ہائپر پیرامیٹرز، جیسے ٹرانسفارمر ماڈل کے ساتھ ایڈم (Adam) کا ڈیفالٹ لرننگ ریٹ 1e-3 استعمال کرنا، سیکھنے کی رفتار کو بہت سست یا مکمل طور پر روک سکتا ہے، لیکن زیادہ تر وقت "مناسب" ہائپر پیرامیٹرز، جیسے 1e-5 سے 5e-5 کے درمیان لرننگ ریٹ، کافی اچھے نتائج دینے کے لیے کام کریں گے۔ لہذا، کسی وقت طلب اور مہنگی ہائپر پیرامیٹر سرچ شروع نہ کریں جب تک کہ آپ کے پاس اپنے ڈیٹا سیٹ پر کوئی معقول بیس لائن نہ ہو۔

جب ایک اچھا ماڈل دستیاب ہو جائے، تب آپ معمولی ایڈجسٹمنٹ شروع کر سکتے ہیں۔ ہزاروں تجربات مت چلائیں، بلکہ ایک ہائپر پیرامیٹر کے مختلف اقدار کے ساتھ کچھ تجربات کریں تاکہ معلوم ہو کہ کون سا زیادہ اثر انداز ہوتا ہے۔

اگر آپ خود ماڈل میں تبدیلی کر رہے ہیں، تو اسے سادہ رکھیں اور کوئی ایسا تجربہ نہ کریں جسے آپ معقول طریقے سے جواز نہ دے سکیں۔ ہمیشہ اوورفٹنگ ٹیسٹ پر واپس جائیں تاکہ تصدیق ہو سکے کہ آپ کی تبدیلی نے کوئی غیر متوقع اثر تو نہیں ڈالا۔

### مدد طلب کریں[[ask-for-help]]

امید ہے کہ آپ کو اس سیکشن میں ایسا مشورہ ملا ہوگا جو آپ کا مسئلہ حل کرنے میں مدد کرے، لیکن اگر ایسا نہیں ہوا، تو یاد رکھیں کہ آپ کمیونٹی سے [فورمز](https://discuss.huggingface.co/) پر مدد طلب کر سکتے ہیں۔

یہاں کچھ اضافی وسائل ہیں جو مددگار ثابت ہو سکتے ہیں:

- ["ریپروڈیوسیبلٹی بطور انجینئرنگ بہترین طریقوں کا ذریعہ"](https://docs.google.com/presentation/d/1yHLPvPhUs2KGI5ZWo0sU-PKU3GimAk3iTsI38Z-B5Gw/edit#slide=id.p) از جول گرس
- ["نیورل نیٹ ورکس کو ڈیبگ کرنے کے لیے چیک لسٹ"](https://towardsdatascience.com/checklist-for-debugging-neural-networks-d8b2a9434f21) از سسیلیا شاؤ
- ["مشین لرننگ کوڈ کی یونٹ ٹیسٹنگ کیسے کریں"](https://medium.com/@keeper6928/how-to-unit-test-machine-learning-code-57cf6fd81765) از چیس رابرٹس
- ["نیورل نیٹ ورکس کی تربیت کے لیے ایک نسخہ"](http://karpathy.github.io/2019/04/25/recipe/) از آندریج کارپتھی

ظاہر ہے، آپ کو مشین لرننگ ماڈلز کی تربیت کے دوران پیش آنے والے ہر مسئلے کی ذمہ داری خود پر نہیں ڈالنی چاہیے! اگر آپ کو 🤗 Transformers یا 🤗 Datasets لائبریری میں کوئی غلط چیز نظر آتی ہے، تو ممکن ہے کہ آپ نے کسی بگ (bug) کا سامنا کیا ہو۔ اس کے بارے میں ہمیں ضرور بتائیں، اور اگلے سیکشن میں ہم آپ کو بتائیں گے کہ یہ کیسے کیا جائے۔
