```mdx
# تعارف[[introduction]]

<CourseFloatingBanner
    chapter={1}
    classNames="absolute z-10 right-0 top-0"
/>

## 🤗 کورس میں خوش آمدید![[welcome-to-the-course]]

<Youtube id="00GKzGyWFEs" />

یہ کورس آپ کو قدرتی زبان کی پروسیسنگ (NLP) کے بارے میں سکھائے گا، [Hugging Face](https://huggingface.co/) ایکو سسٹم کی لائبریریوں — [🤗 Transformers](https://github.com/huggingface/transformers), [🤗 Datasets](https://github.com/huggingface/datasets), [🤗 Tokenizers](https://github.com/huggingface/tokenizers) اور [🤗 Accelerate](https://github.com/huggingface/accelerate) — کے استعمال سے، اور ساتھ ہی [Hugging Face Hub](https://huggingface.co/models) کا استعمال بھی۔ یہ کورس مکمل طور پر مفت ہے اور اس میں کوئی اشتہار نہیں ہیں۔

## آپ کیا توقع کر سکتے ہیں؟[[what-to-expect]]

یہاں کورس کا ایک مختصر جائزہ پیش کیا گیا ہے:

<div class="flex justify-center">
<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary.svg" alt="Brief overview of the chapters of the course.">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary-dark.svg" alt="Brief overview of the chapters of the course.">
</div>

- ابواب 1 سے 4 میں 🤗 Transformers لائبریری کے بنیادی تصورات کا تعارف پیش کیا گیا ہے۔ اس حصہ کے اختتام تک، آپ کو Transformer ماڈلز کے کام کرنے کا طریقہ سمجھ آ جائے گا اور آپ [Hugging Face Hub](https://huggingface.co/models) سے ماڈل استعمال کرنے، اسے کسی ڈیٹاسیٹ پر fine-tune کرنے اور اپنے نتائج Hub پر شیئر کرنے کا طریقہ جان لیں گے!
- ابواب 5 سے 8 میں 🤗 Datasets اور 🤗 Tokenizers کی بنیادی باتیں سکھائی جائیں گی، اس سے پہلے کہ کلاسیکی NLP ٹاسکس میں ڈوبی جائیں۔ اس حصہ کے اختتام تک، آپ خود بخود سب سے عام NLP مسائل کا حل نکال سکیں گے۔
- باب 9 NLP سے آگے بڑھ کر اس بات کا احاطہ کرتا ہے کہ اپنے ماڈلز کے ڈیموز کو 🤗 Hub پر کیسے بنایا اور شیئر کیا جائے۔ اس حصہ کے اختتام تک، آپ اپنی 🤗 Transformers ایپلیکیشن کو دنیا کے سامنے پیش کرنے کے لیے تیار ہوں گے!

یہ کورس:

* Python کی اچھی سمجھ بوجھ کا متقاضی ہے
* کسی introductory deep learning کورس کے بعد لینا بہتر ہے، جیسے [fast.ai's](https://www.fast.ai/) [Practical Deep Learning for Coders](https://course.fast.ai/) یا [DeepLearning.AI](https://www.deeplearning.ai/) کی جانب سے تیار کردہ کوئی پروگرام
* پہلے سے [PyTorch](https://pytorch.org/) یا [TensorFlow](https://www.tensorflow.org/) کا علم ضروری نہیں، اگرچہ ان میں سے کسی ایک سے واقفیت مددگار ثابت ہو گی

جب آپ یہ کورس مکمل کر لیں، تو ہم تجویز کرتے ہیں کہ DeepLearning.AI کا [Natural Language Processing Specialization](https://www.coursera.org/specializations/natural-language-processing?utm_source=deeplearning-ai&utm_medium=institutions&utm_campaign=20211011-nlp-2-hugging_face-page-nlp-refresh) دیکھیں، جو روایتی NLP ماڈلز جیسے naive Bayes اور LSTMs کا احاطہ کرتا ہے جو جاننا فائدہ مند ہے!

## ہم کون ہیں؟[[who-are-we]]

مصنفین کے بارے میں:

[**Abubakar Abid**](https://huggingface.co/abidlabs) نے اسٹینفورڈ سے applied machine learning میں اپنا PhD مکمل کیا۔ اپنے PhD کے دوران، انہوں نے [Gradio](https://github.com/gradio-app/gradio) کی بنیاد رکھی، ایک اوپن سورس Python لائبریری جس کا استعمال 600,000 سے زائد machine learning ڈیموز بنانے کے لیے کیا گیا ہے۔ Gradio کو Hugging Face نے acquire کیا، جہاں اب Abubakar ایک machine learning ٹیم لیڈ کے طور پر خدمات سرانجام دیتے ہیں۔

[**Matthew Carrigan**](https://huggingface.co/Rocketknight1) Hugging Face میں Machine Learning Engineer ہیں۔ وہ ڈبلن، آئرلینڈ میں رہتے ہیں اور پہلے Parse.ly میں ML انجینئر کے طور پر کام کر چکے ہیں اور اس سے پہلے Trinity College Dublin میں post-doctoral researcher رہے ہیں۔ وہ اس بات پر یقین نہیں رکھتے کہ موجودہ architectures کو scale کر کے ہم AGI تک پہنچ جائیں گے، لیکن روبوٹ کی ابدی حیات کے لیے ان کی امیدیں بلند ہیں۔

[**Lysandre Debut**](https://huggingface.co/lysandre) Hugging Face میں Machine Learning Engineer ہیں اور ابتدائی development stages سے ہی 🤗 Transformers لائبریری پر کام کر رہے ہیں۔ ان کا مقصد ایک سادہ API کے ذریعے NLP کو ہر کسی کے لیے قابل رسائی بنانا ہے۔

[**Sylvain Gugger**](https://huggingface.co/sgugger) Hugging Face میں Research Engineer ہیں اور 🤗 Transformers لائبریری کے بنیادی maintainers میں سے ایک ہیں۔ اس سے پہلے وہ fast.ai میں Research Scientist تھے، اور Jeremy Howard کے ساتھ مل کر _[Deep Learning for Coders with fastai and PyTorch](https://learning.oreilly.com/library/view/deep-learning-for/9781492045519/)_ کی تحریر میں شریک رہے۔ ان کی تحقیق کا بنیادی مقصد deep learning کو مزید قابل رسائی بنانا ہے، اس طرح تکنیکوں کو ڈیزائن اور بہتر بنانا جو محدود وسائل پر ماڈلز کو تیزی سے ٹرین کرنے کی اجازت دیں۔

[**Dawood Khan**](https://huggingface.co/dawoodkhan82) Hugging Face میں Machine Learning Engineer ہیں۔ وہ NYC سے ہیں اور New York University سے Computer Science کی تعلیم حاصل کی۔ چند سال iOS انجینئر کے طور پر کام کرنے کے بعد، Dawood نے اپنے ساتھی co-founders کے ساتھ Gradio شروع کرنے کا فیصلہ کیا۔ آخرکار Gradio کو Hugging Face نے acquire کر لیا۔

[**Merve Noyan**](https://huggingface.co/merve) Hugging Face میں developer advocate ہیں، جو ٹولز کی ترقی اور ان کے ارد گرد مواد تیار کرنے پر کام کرتے ہیں تاکہ machine learning کو ہر کسی کے لیے جمہوری بنایا جا سکے۔

[**Lucile Saulnier**](https://huggingface.co/SaulLu) Hugging Face میں machine learning engineer ہیں، جو اوپن سورس ٹولز کے استعمال کی ترقی اور حمایت کرتی ہیں۔ وہ Natural Language Processing کے میدان میں متعدد research projects میں بھی سرگرم عمل ہیں جیسے collaborative training اور BigScience۔

[**Lewis Tunstall**](https://huggingface.co/lewtun) Hugging Face میں machine learning engineer ہیں، جو اوپن سورس ٹولز کی ترقی اور انہیں وسیع تر کمیونٹی تک پہنچانے پر مرکوز ہیں۔ وہ O’Reilly کتاب [Natural Language Processing with Transformers](https://www.oreilly.com/library/view/natural-language-processing/9781098136789/) کے بھی co-author ہیں۔

[**Leandro von Werra**](https://huggingface.co/lvwerra) Hugging Face کی اوپن سورس ٹیم میں machine learning engineer ہیں اور O’Reilly کتاب [Natural Language Processing with Transformers](https://www.oreilly.com/library/view/natural-language-processing/9781098136789/) کے co-author بھی ہیں۔ انہیں NLP پروجیکٹس کو production میں لانے کا کئی سالہ صنعتی تجربہ ہے جو پورے machine learning stack میں کام کرتا ہے۔

## FAQ[[faq]]

یہاں اکثر پوچھے جانے والے سوالات کے جوابات دیے گئے ہیں:

- **کیا اس کورس کو کرنے سے کوئی سرٹیفکیٹ ملتا ہے؟**  
  اس وقت ہمارے پاس اس کورس کے لیے کوئی سرٹیفکیٹ موجود نہیں ہے۔ تاہم، ہم Hugging Face ایکو سسٹم کے لیے سرٹیفکیٹ پروگرام پر کام کر رہے ہیں – مزید معلومات کے لیے انتظار کریں!

- **مجھے اس کورس پر کتنا وقت صرف کرنا چاہیے؟**  
  اس کورس کا ہر باب تقریباً 1 ہفتے میں مکمل کرنے کے لیے ڈیزائن کیا گیا ہے، جس میں ہر ہفتے تقریباً 6-8 گھنٹے کام شامل ہے۔ تاہم، آپ کو کورس مکمل کرنے کے لیے جتنا وقت درکار ہو وہ لے سکتے ہیں۔

- **اگر مجھے کوئی سوال ہو تو میں اسے کہاں پوچھ سکتا ہوں؟**  
  اگر آپ کو کورس کے کسی بھی حصے کے بارے میں کوئی سوال ہو تو صفحے کے اوپر "*Ask a question*" بینر پر کلک کریں تاکہ آپ کو خود بخود [Hugging Face forums](https://discuss.huggingface.co/) کے متعلقہ حصے میں بھیج دیا جائے:

  <img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/forum-button.png" alt="Link to the Hugging Face forums" width="75%">

  نوٹ کریں کہ [project ideas](https://discuss.huggingface.co/c/course/course-event/25) کی فہرست بھی forums پر دستیاب ہے اگر آپ کورس مکمل کرنے کے بعد مزید مشق کرنا چاہتے ہیں۔

- **کورس کا کوڈ مجھے کہاں ملے گا؟**  
  ہر سیکشن کے لیے، صفحے کے اوپر موجود بینر پر کلک کریں تاکہ آپ Google Colab یا Amazon SageMaker Studio Lab میں کوڈ چلا سکیں:

  <img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/notebook-buttons.png" alt="Link to the Hugging Face course notebooks" width="75%">

  کورس کا تمام کوڈ مشتمل Jupyter notebooks [`huggingface/notebooks`](https://github.com/huggingface/notebooks) ریپو پر host کیے گئے ہیں۔ اگر آپ انہیں لوکل generate کرنا چاہتے ہیں تو [`course`](https://github.com/huggingface/course#-jupyter-notebooks) ریپو میں ہدایات ملاحظہ کریں۔

- **میں کورس میں کیسے تعاون کر سکتا ہوں؟**  
  کورس میں تعاون کرنے کے بہت سے طریقے ہیں! اگر آپ کو کوئی ٹائپو یا بگ نظر آئے تو [`course`](https://github.com/huggingface/course) ریپو پر issue کھولیں۔ اگر آپ اپنے مادری زبان میں کورس کے ترجمے میں مدد کرنا چاہتے ہیں تو [یہاں](https://github.com/huggingface/course#translating-the-course-into-your-language) ہدایات ملاحظہ کریں۔

- **ہر ترجمے کے لیے کیا انتخاب کیے گئے؟**  
  ہر ترجمے کے ساتھ ایک glossary اور `TRANSLATING.txt` فائل ہوتی ہے جو machine learning jargon وغیرہ کے لیے کیے گئے انتخاب کی تفصیل بیان کرتی ہے۔ آپ مثال کے طور پر German کے لیے [یہاں](https://github.com/huggingface/course/blob/main/chapters/de/TRANSLATING.txt) دیکھ سکتے ہیں۔

- **کیا میں اس کورس کو دوبارہ استعمال کر سکتا ہوں؟**  
  بالکل! یہ کورس permissive [Apache 2 license](https://www.apache.org/licenses/LICENSE-2.0.html) کے تحت جاری کیا گیا ہے۔ اس کا مطلب ہے کہ آپ کو مناسب کریڈٹ دینا ہوگا، لائسنس کا لنک فراہم کرنا ہوگا، اور اگر تبدیلیاں کی گئی ہوں تو ان کا ذکر کرنا ہوگا۔ آپ ایسا کسی بھی مناسب طریقے سے کر سکتے ہیں، مگر اس طرح کہ لائسنس دینے والے کا endorsement ظاہر نہ ہو۔ اگر آپ اس کورس کا حوالہ دینا چاہتے ہیں تو براہ کرم درج ذیل BibTeX استعمال کریں:

  ```
  @misc{huggingfacecourse,
    author = {Hugging Face},
    title = {The Hugging Face Course, 2022},
    howpublished = "\url{https://huggingface.co/course}",
    year = {2022},
    note = "[Online; accessed <today>]"
  }
  ```

## چلیں شروع کرتے ہیں
کیا آپ تیار ہیں؟ اس باب میں، آپ سیکھیں گے:

* `pipeline()` فنکشن کا استعمال کرتے ہوئے NLP ٹاسکس جیسے کہ text generation اور classification کا حل کیسے نکالا جائے
* Transformer architecture کے بارے میں
* encoder, decoder، اور encoder-decoder architectures اور ان کے استعمال کے معاملات میں تمیز کیسے کی جائے
```