<FrameworkSwitchCourse {fw} />

# ٹوکن کی درجہ بندی[[token-classification]]

{#if fw === 'pt'}

<CourseFloatingBanner chapter={7}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[ 
    {label: "گوگل کولیب", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter7/section2_pt.ipynb"},
    {label: "ایس ڈبلیو ایس اسٹوڈیو", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter7/section2_pt.ipynb"},
]} />

{:else}

<CourseFloatingBanner chapter={7}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[ 
    {label: "گوگل کولیب", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter7/section2_tf.ipynb"},
    {label: "ایس ڈبلیو ایس اسٹوڈیو", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter7/section2_tf.ipynb"},
]} />

{/if}

ہم جو پہلی ایپلی کیشن دیکھیں گے وہ ٹوکن کی درجہ بندی ہے۔ یہ عمومی کام ہر مسئلے کو "جملے میں ہر ٹوکن کو ایک لیبل دینے" کے طور پر ترتیب دیتا ہے، جیسے کہ:

- **نامیاتی ادارے کی شناخت (NER)**: جملے میں اداروں (جیسے افراد، مقامات، یا تنظیمیں) کو تلاش کریں۔ یہ ہر ٹوکن کو ایک لیبل دینے کے طور پر مرتب کیا جا سکتا ہے، جس میں ہر ادارے کے لئے ایک کلاس اور "کوئی ادارہ نہیں" کے لئے ایک کلاس شامل ہو۔
- **جزو کی نشاندہی (POS)**: جملے میں ہر لفظ کو ایک خاص جزوِ کلمہ (جیسے اسم، فعل، صفت وغیرہ) سے نشان زد کریں۔
- **چنکنگ**: ان ٹوکنز کو تلاش کریں جو ایک ہی ادارے میں شامل ہوں۔ یہ کام (جو POS یا NER کے ساتھ ملایا جا سکتا ہے) ہر چنک کے آغاز میں کسی ٹوکن کے لیے ایک لیبل (`B-`) لگانے، چنک میں موجود کسی دوسرے ٹوکن کے لیے دوسرا لیبل (`I-`) لگانے اور ان ٹوکنز کے لیے جو کسی چنک سے متعلق نہیں ہیں ایک تیسرا لیبل (`O`) لگانے کے طور پر ترتیب دیا جا سکتا ہے۔

<Youtube id="wVHdVlPScxA"/>

ظاہر ہے، ٹوکن کی درجہ بندی کے مسائل کی اور بھی کئی اقسام ہیں؛ یہ چند نمونہ جات ہیں۔ اس سیکشن میں، ہم ایک ماڈل (BERT) کو NER کام پر فائن ٹون کریں گے، جو اس طرح کی پیش گوئیاں کرنے کے قابل ہو گا:

<iframe src="https://course-demos-bert-finetuned-ner.hf.space" frameBorder="0" height="350" title="Gradio app" class="block dark:hidden container p-0 flex-grow space-iframe" allow="accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking" sandbox="allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"></iframe>

<a class="flex justify-center" href="/huggingface-course/bert-finetuned-ner">
<img class="block dark:hidden lg:w-3/5" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/model-eval-bert-finetuned-ner.png" alt="One-hot encoded labels for question answering."/>
<img class="hidden dark:block lg:w-3/5" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/model-eval-bert-finetuned-ner-dark.png" alt="One-hot encoded labels for question answering."/>
</a>

آپ اس ماڈل کو یہاں دیکھ سکتے ہیں جسے ہم ٹرین کریں گے اور ہب پر اپ لوڈ کریں گے، اور اس کی پیش گوئیاں دوبارہ چیک کریں [یہاں](https://huggingface.co/huggingface-course/bert-finetuned-ner?text=My+name+is+Sylvain+and+I+work+at+Hugging+Face+in+Brooklyn).

## ڈیٹا کی تیاری[[preparing-the-data]]

سب سے پہلے، ہمیں ٹوکن کی درجہ بندی کے لیے ایک مناسب ڈیٹا سیٹ کی ضرورت ہے۔ اس سیکشن میں ہم [CoNLL-2003 ڈیٹا سیٹ](https://huggingface.co/datasets/conll2003) استعمال کریں گے، جو ریٹرز کی خبریں پر مشتمل ہے۔

<Tip>

💡 جب تک آپ کا ڈیٹا سیٹ الفاظ میں تقسیم شدہ متن پر مشتمل ہو، جس کے ساتھ متعلقہ لیبلز ہوں، آپ یہاں بیان کردہ ڈیٹا پروسیسنگ طریقوں کو اپنے ڈیٹا سیٹ پر بھی لاگو کر سکتے ہیں۔ اگر آپ کو یاد دہانی کی ضرورت ہو تو آپ [باب 5](/course/chapter5) میں واپس جا سکتے ہیں تاکہ اپنے کسٹم ڈیٹا کو `Dataset` میں کیسے لوڈ کرنا ہے سیکھ سکیں۔

</Tip>

### CoNLL-2003 ڈیٹا سیٹ[[the-conll-2003-dataset]]

CoNLL-2003 ڈیٹا سیٹ کو لوڈ کرنے کے لیے، ہم 🤗 Datasets لائبریری سے `load_dataset()` میتھڈ استعمال کرتے ہیں:

```py
from datasets import load_dataset

raw_datasets = load_dataset("conll2003")
```

یہ ڈیٹاسیٹ کو ڈاؤن لوڈ اور کیش کرے گا، جیسے ہم نے [باب 3](/course/chapter3) میں GLUE MRPC ڈیٹاسیٹ کے لیے دیکھا تھا۔ اس آبجیکٹ کا معائنہ کرنے سے ہمیں دستیاب کالمز اور تربیتی، توثیقی، اور ٹیسٹ سیٹس کے درمیان تقسیم دکھائی دیتی ہے۔

```py
raw_datasets
```

```python out
DatasetDict({
    train: Dataset({
        features: ['chunk_tags', 'id', 'ner_tags', 'pos_tags', 'tokens'],
        num_rows: 14041
    })
    validation: Dataset({
        features: ['chunk_tags', 'id', 'ner_tags', 'pos_tags', 'tokens'],
        num_rows: 3250
    })
    test: Dataset({
        features: ['chunk_tags', 'id', 'ner_tags', 'pos_tags', 'tokens'],
        num_rows: 3453
    })
})
```

خاص طور پر، ہم دیکھ سکتے ہیں کہ یہ ڈیٹاسیٹ ان تین ٹاسکس کے لیے لیبلز پر مشتمل ہے جن کا ہم نے پہلے ذکر کیا: NER، POS، اور چنکنگ۔ دیگر ڈیٹاسیٹس کے مقابلے میں ایک بڑا فرق یہ ہے کہ ان پٹ ٹیکسٹ جملوں یا دستاویزات کی صورت میں نہیں دیے گئے، بلکہ الفاظ کی فہرستوں کی شکل میں موجود ہیں (آخری کالم کو `tokens` کہا گیا ہے، لیکن اس میں الفاظ شامل ہیں، کیونکہ یہ پہلے سے ٹوکنائز شدہ ان پٹ ہیں جنہیں ابھی سب ورڈ ٹوکنائزیشن کے لیے ٹوکنائزر سے گزرنا ہوگا)۔  

آئیے تربیتی سیٹ کے پہلے عنصر کو دیکھتے ہیں:

```py
raw_datasets["train"][0]["tokens"]
```

```python out
['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']
```

چونکہ ہم نامزد ادارے کی شناخت (Named Entity Recognition - NER) انجام دینا چاہتے ہیں، اس لیے ہم NER ٹیگز پر نظر ڈالیں گے۔

```py
raw_datasets["train"][0]["ner_tags"]
```

```python out
[3, 0, 7, 0, 0, 0, 7, 0, 0]
```

یہ لیبلز عددی شکل میں موجود ہیں اور ماڈل کی تربیت کے لیے تیار ہیں، لیکن ڈیٹا کا معائنہ کرنے کے لیے یہ زیادہ مفید نہیں ہیں۔ ٹیکسٹ کلاسیفیکیشن کی طرح، ہم اپنے ڈیٹاسیٹ کی `features` خصوصیت دیکھ کر ان نمبروں اور اصل لیبل ناموں کے درمیان مطابقت حاصل کر سکتے ہیں۔


```py
ner_feature = raw_datasets["train"].features["ner_tags"]
ner_feature
```

```python out
Sequence(feature=ClassLabel(num_classes=9, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], names_file=None, id=None), length=-1, id=None)
```

یہ کالم `ClassLabel` کے تسلسل (sequences) پر مشتمل ہوتا ہے۔ اس `ner_feature` کے عناصر کی قسم `feature` وصف (attribute) میں دی گئی ہوتی ہے، اور ان لیبلز کے اصل ناموں کی فہرست ہم `feature` کی `names` وصف کے ذریعے حاصل کر سکتے ہیں۔

```py
label_names = ner_feature.feature.names
label_names
```

```python out
['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']
```

جب ہم پہلے دیکھی گئی لیبلز کو ڈی کوڈ کرتے ہیں، تو ہمیں درج ذیل وضاحت ملتی ہے:  

- `O` کا مطلب ہے کہ یہ لفظ کسی بھی ہستی (entity) سے متعلق نہیں ہے۔  
- `B-PER` / `I-PER` کا مطلب ہے کہ یہ لفظ کسی *شخص* (person) کے نام کی شروعات یا اس کے اندر موجود ہے۔  
- `B-ORG` / `I-ORG` کا مطلب ہے کہ یہ لفظ کسی *تنظیم* (organization) کے نام کی شروعات یا اس کے اندر موجود ہے۔  
- `B-LOC` / `I-LOC` کا مطلب ہے کہ یہ لفظ کسی *مقام* (location) کے نام کی شروعات یا اس کے اندر موجود ہے۔  
- `B-MISC` / `I-MISC` کا مطلب ہے کہ یہ لفظ کسی *دیگر متفرق* (miscellaneous) ہستی کے نام کی شروعات یا اس کے اندر موجود ہے۔  

اب ہم پہلے دیکھی گئی لیبلز کو ڈی کوڈ کرکے ان کے معنی دیکھ سکتے ہیں۔

```python
words = raw_datasets["train"][0]["tokens"]
labels = raw_datasets["train"][0]["ner_tags"]
line1 = ""
line2 = ""
for word, label in zip(words, labels):
    full_label = label_names[label]
    max_length = max(len(word), len(full_label))
    line1 += word + " " * (max_length - len(word) + 1)
    line2 += full_label + " " * (max_length - len(full_label) + 1)

print(line1)
print(line2)
```

```python out
'EU    rejects German call to boycott British lamb .'
'B-ORG O       B-MISC O    O  O       B-MISC  O    O'
```

اور `B-` اور `I-` لیبلز کو ملا کر دیکھنے کی ایک مثال کے طور پر، یہی کوڈ ہمیں تربیتی سیٹ کے انڈیکس 4 پر درج ذیل نتائج دیتا ہے:


```python out
'Germany \'s representative to the European Union \'s veterinary committee Werner Zwingmann said on Wednesday consumers should buy sheepmeat from countries other than Britain until the scientific advice was clearer .'
'B-LOC   O  O              O  O   B-ORG    I-ORG O  O          O         B-PER  I-PER     O    O  O         O         O      O   O         O    O         O     O    B-LOC   O     O   O          O      O   O       O'
```

جیسا کہ ہم دیکھ سکتے ہیں، دو الفاظ پر مشتمل ادارے، جیسے "European Union" اور "Werner Zwingmann"، پہلے لفظ کے لیے `B-` لیبل اور دوسرے کے لیے `I-` لیبل حاصل کرتے ہیں۔  

<Tip>  

✏️ **اب آپ کی باری!** انہی دو جملوں کو ان کے POS یا chunking لیبلز کے ساتھ پرنٹ کریں۔  

</Tip>  

### ڈیٹا کی پروسیسنگ [[processing-the-data]]  

<Youtube id="iY2AZYdZAr0"/>  

حسب معمول، ہمارے متون کو ماڈل کے لیے قابلِ فہم بنانے کے لیے پہلے ٹوکن آئی ڈیز میں تبدیل کرنے کی ضرورت ہوتی ہے۔ جیسا کہ ہم نے [Chapter 6](/course/chapter6/) میں دیکھا، ٹوکن کلاسفکیشن ٹاسکس کے معاملے میں ایک بڑا فرق یہ ہے کہ ہمارے پاس پہلے سے ٹوکنائز شدہ ان پٹس موجود ہیں۔ خوش قسمتی سے، ٹوکنائزر API اسے کافی آسانی سے سنبھال سکتی ہے؛ ہمیں صرف `tokenizer` کو ایک خاص فلیگ کے ساتھ مطلع کرنا ہوگا۔  

شروع کرنے کے لیے، آئیے اپنا `tokenizer` آبجیکٹ بناتے ہیں۔ جیسا کہ ہم پہلے ذکر کر چکے ہیں، ہم BERT کا پری ٹرینڈ ماڈل استعمال کریں گے، اس لیے ہم متعلقہ ٹوکنائزر کو ڈاؤن لوڈ اور کیش کرنے سے آغاز کریں گے۔


```python
from transformers import AutoTokenizer

model_checkpoint = "bert-base-cased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)
```

آپ `model_checkpoint` کو [Hub](https://huggingface.co/models) سے کسی بھی دوسرے ماڈل کے ساتھ تبدیل کر سکتے ہیں، یا کسی مقامی فولڈر کے ساتھ جہاں آپ نے پہلے سے تربیت یافتہ ماڈل اور ٹوکنائزر کو محفوظ کیا ہو۔ واحد شرط یہ ہے کہ ٹوکنائزر کو 🤗 Tokenizers لائبریری کی مدد حاصل ہو، تاکہ اس کا "تیز" (`fast`) ورژن دستیاب ہو۔  

آپ تمام آرکیٹیکچرز کو دیکھ سکتے ہیں جن کے ساتھ ایک تیز (`fast`) ورژن آتا ہے [اس بڑے جدول](https://huggingface.co/transformers/#supported-frameworks) میں، اور یہ چیک کرنے کے لیے کہ جو `tokenizer` آبجیکٹ آپ استعمال کر رہے ہیں وہ واقعی 🤗 Tokenizers کی مدد سے چل رہا ہے، آپ اس کی `is_fast` خصوصیت کو دیکھ سکتے ہیں۔

```py
tokenizer.is_fast
```

```python out
True
```

پہلے سے ٹوکنائز کیے گئے ان پٹ کو ٹوکنائز کرنے کے لیے، ہم اپنے `tokenizer` کو معمول کے مطابق استعمال کر سکتے ہیں اور صرف `is_split_into_words=True` شامل کر سکتے ہیں:

```py
inputs = tokenizer(raw_datasets["train"][0]["tokens"], is_split_into_words=True)
inputs.tokens()
```

```python out
['[CLS]', 'EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'la', '##mb', '.', '[SEP]']
```

جیسا کہ ہم دیکھ سکتے ہیں، ٹوکنائزر نے ماڈل کے استعمال شدہ خاص ٹوکنز شامل کیے (`[CLS]` شروع میں اور `[SEP]` آخر میں) اور زیادہ تر الفاظ کو جوں کا توں رکھا۔ تاہم، لفظ `lamb` کو دو سب ورڈز میں تقسیم کیا گیا: `la` اور `##mb`۔ اس سے ہمارے ان پٹ اور لیبلز کے درمیان عدم مطابقت پیدا ہوتی ہے: لیبلز کی فہرست میں صرف 9 عناصر ہیں، جبکہ ہمارے ان پٹ میں اب 12 ٹوکنز ہیں۔ خاص ٹوکنز کا حساب لگانا آسان ہے (ہم جانتے ہیں کہ وہ شروع اور آخر میں ہیں)، لیکن ہمیں یہ بھی یقینی بنانا ہوگا کہ تمام لیبلز کو درست الفاظ کے ساتھ ہم آہنگ کیا جائے۔

خوش قسمتی سے، چونکہ ہم ایک فاسٹ ٹوکنائزر استعمال کر رہے ہیں، ہمیں 🤗 Tokenizers کی شاندار خصوصیات تک رسائی حاصل ہے، جس کا مطلب ہے کہ ہم آسانی سے ہر ٹوکن کو اس کے متعلقہ لفظ سے میپ کر سکتے ہیں (جیسا کہ [Chapter 6](/course/chapter6/3) میں دیکھا گیا):

```py
inputs.word_ids()
```

```python out
[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]
```

تھوڑے سے کام کے بعد، ہم اپنی لیبل لسٹ کو ٹوکنز کے مطابق وسعت دے سکتے ہیں۔ پہلا اصول جو ہم لاگو کریں گے وہ یہ ہے کہ خاص ٹوکنز کو `-100` کا لیبل دیا جائے گا۔ اس کی وجہ یہ ہے کہ ڈیفالٹ طور پر `-100` وہ انڈیکس ہے جسے ہم جس لاس فنکشن (کراس اینٹروپی) استعمال کریں گے، وہ نظر انداز کر دیتا ہے۔ پھر، ہر ٹوکن کو وہی لیبل دیا جائے گا جو اس لفظ کے پہلے ٹوکن کو دیا گیا تھا، کیونکہ وہ ایک ہی اینٹیٹی کا حصہ ہوتے ہیں۔ ان الفاظ کے اندر موجود ٹوکنز کے لیے جو ابتدا میں نہیں آتے، ہم `B-` کو `I-` سے بدل دیتے ہیں (کیونکہ یہ ٹوکن اینٹیٹی کی شروعات نہیں کرتا):

```python
def align_labels_with_tokens(labels, word_ids):
    new_labels = []
    current_word = None
    for word_id in word_ids:
        if word_id != current_word:
            # Start of a new word!
            current_word = word_id
            label = -100 if word_id is None else labels[word_id]
            new_labels.append(label)
        elif word_id is None:
            # Special token
            new_labels.append(-100)
        else:
            # Same word as previous token
            label = labels[word_id]
            # If the label is B-XXX we change it to I-XXX
            if label % 2 == 1:
                label += 1
            new_labels.append(label)

    return new_labels
```
آئیے اپنی پہلی جملے پر اسے آزما کر دیکھتے ہیں:

```py
labels = raw_datasets["train"][0]["ner_tags"]
word_ids = inputs.word_ids()
print(labels)
print(align_labels_with_tokens(labels, word_ids))
```

```python out
[3, 0, 7, 0, 0, 0, 7, 0, 0]
[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]
```

جیسا کہ ہم دیکھ سکتے ہیں، ہماری فنکشن نے ابتدائی اور اختتامی خصوصی ٹوکنز کے لیے `-100` شامل کیا، اور اس لفظ کے لیے ایک نیا `0` شامل کیا جو دو ٹوکنز میں تقسیم ہوا تھا۔

<Tip>

✏️ **آپ کی باری!** کچھ محققین ترجیح دیتے ہیں کہ ہر لفظ کے لیے صرف ایک لیبل مختص کیا جائے، اور کسی بھی اضافی سب ٹوکنز کو `-100` دیا جائے۔ اس کا مقصد یہ ہے کہ لمبے الفاظ جو کئی سب ٹوکنز میں تقسیم ہوتے ہیں، نقصان (loss) پر غیر ضروری طور پر زیادہ اثر نہ ڈالیں۔ پچھلی فنکشن میں ترمیم کریں تاکہ یہ لیبلز کو ان پٹ آئی ڈیز کے ساتھ اس اصول کے مطابق سیدھ میں کرے۔

</Tip>

ہمارے پورے ڈیٹاسیٹ کو پہلے سے پروسیس کرنے کے لیے، ہمیں تمام ان پٹس کو ٹوکنائز کرنا ہوگا اور `align_labels_with_tokens()` کو تمام لیبلز پر لاگو کرنا ہوگا۔ ہمارے فاسٹ ٹوکنائزر کی رفتار سے فائدہ اٹھانے کے لیے، بہتر ہے کہ ایک وقت میں کئی ٹیکسٹس کو ٹوکنائز کیا جائے، لہٰذا ہم ایک فنکشن لکھیں گے جو ایک مثالوں کی فہرست کو پروسیس کرے اور `Dataset.map()` طریقہ استعمال کرے جس میں `batched=True` کا آپشن ہو۔ جو چیز ہمارے پچھلے مثال سے مختلف ہے وہ یہ ہے کہ `word_ids()` فنکشن کو اس مثال کے انڈیکس کی ضرورت ہوتی ہے جس کے ہم لفظی آئی ڈیز لینا چاہتے ہیں، کیونکہ ہمارے ٹوکنائزر کے ان پٹ میں ٹیکسٹ کی فہرستیں (یا ہمارے کیس میں، الفاظ کی فہرستیں) شامل ہیں، اس لیے ہم یہ بھی شامل کریں گے:


```py
def tokenize_and_align_labels(examples):
    tokenized_inputs = tokenizer(
        examples["tokens"], truncation=True, is_split_into_words=True
    )
    all_labels = examples["ner_tags"]
    new_labels = []
    for i, labels in enumerate(all_labels):
        word_ids = tokenized_inputs.word_ids(i)
        new_labels.append(align_labels_with_tokens(labels, word_ids))

    tokenized_inputs["labels"] = new_labels
    return tokenized_inputs
```

نوٹ کریں کہ ہم نے ابھی تک اپنے ان پٹس کو پیڈ (pad) نہیں کیا ہے؛ ہم یہ بعد میں کریں گے، جب ہم ڈیٹا کولیٹر (data collator) کے ساتھ بیچز (batches) بنائیں گے۔  

اب ہم اپنے ڈیٹاسیٹ کے دیگر حصوں پر یہ تمام پری پروسیسنگ ایک ہی مرحلے میں لاگو کر سکتے ہیں:

```py
tokenized_datasets = raw_datasets.map(
    tokenize_and_align_labels,
    batched=True,
    remove_columns=raw_datasets["train"].column_names,
)
```

ہم نے سب سے مشکل حصہ مکمل کر لیا ہے! اب جب کہ ڈیٹا کی پہلے سے پروسیسنگ ہو چکی ہے، اصل تربیت (training) بالکل اسی طرح نظر آئے گی جیسے ہم نے [باب 3](/course/chapter3) میں کی تھی۔

{#if fw === 'pt'}


### Data collation[[data-collation]]

ہم صرف [Chapter 3](/course/chapter3) میں استعمال ہونے والے `DataCollatorWithPadding` کا استعمال نہیں کر سکتے کیونکہ وہ صرف inputs (input IDs, attention mask, اور token type IDs) کو pad کرتا ہے۔ یہاں ہمارے labels کو بھی inputs کی طرح ٹھیک ٹھاک pad کرنا ضروری ہے تاکہ ان کا سائز یکساں رہے، اور `-100` ویلیو استعمال کی جائے تاکہ متعلقہ predictions loss computation میں نظر انداز ہو جائیں۔

یہ سب کچھ ایک [`DataCollatorForTokenClassification`](https://huggingface.co/transformers/main_classes/data_collator.html#datacollatorfortokenclassification) کے ذریعے انجام دیا جاتا ہے۔ `DataCollatorWithPadding` کی طرح، یہ بھی وہی tokenizer لیتا ہے جو inputs کی preprocessing کے لیے استعمال کیا گیا ہو:

{#if fw === 'pt'}

```py
from transformers import DataCollatorForTokenClassification

data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)
```

{:else}

```py
from transformers import DataCollatorForTokenClassification

data_collator = DataCollatorForTokenClassification(
    tokenizer=tokenizer, return_tensors="tf"
)
```

{/if}

اسے چند نمونوں پر آزمانے کے لیے، ہم اسے اپنے ٹوکنائز کیے گئے تربیتی سیٹ کی مثالوں کی فہرست پر بلا سکتے ہیں:

```py
batch = data_collator([tokenized_datasets["train"][i] for i in range(2)])
batch["labels"]
```

```python out
tensor([[-100,    3,    0,    7,    0,    0,    0,    7,    0,    0,    0, -100],
        [-100,    1,    2, -100, -100, -100, -100, -100, -100, -100, -100, -100]])
```

آئیے اسے اپنے ڈیٹاسیٹ کے پہلے اور دوسرے عناصر کے لیبلز سے موازنہ کرتے ہیں:

```py
for i in range(2):
    print(tokenized_datasets["train"][i]["labels"])
```

```python out
[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]
[-100, 1, 2, -100]
```

{#if fw === 'pt'}

جیسا کہ ہم دیکھ سکتے ہیں، دوسرے سیٹ کے لیبلز کو پہلے والے کی لمبائی کے مطابق `-100` استعمال کرتے ہوئے پیڈ کیا گیا ہے۔

{:else}

ہمارا ڈیٹا کولیٹر استعمال کے لیے تیار ہے! اب آئیے اسے `to_tf_dataset()` میتھڈ کے ساتھ `tf.data.Dataset` بنانے کے لیے استعمال کریں۔ آپ `model.prepare_tf_dataset()` بھی استعمال کر سکتے ہیں تاکہ یہ کام کم کوڈ کے ساتھ کیا جا سکے – آپ اس چیپٹر کے دیگر سیکشنز میں اسے دیکھیں گے۔

```py
tf_train_dataset = tokenized_datasets["train"].to_tf_dataset(
    columns=["attention_mask", "input_ids", "labels", "token_type_ids"],
    collate_fn=data_collator,
    shuffle=True,
    batch_size=16,
)

tf_eval_dataset = tokenized_datasets["validation"].to_tf_dataset(
    columns=["attention_mask", "input_ids", "labels", "token_type_ids"],
    collate_fn=data_collator,
    shuffle=False,
    batch_size=16,
)
```

اگلا مرحلہ: خود ماڈل۔

{/if}

{#if fw === 'tf'}

### ماڈل کی وضاحت [[defining-the-model]]  

چونکہ ہم ایک ٹوکن کی درجہ بندی (token classification) کے مسئلے پر کام کر رہے ہیں، اس لیے ہم `TFAutoModelForTokenClassification` کلاس استعمال کریں گے۔ اس ماڈل کی وضاحت کرتے وقت سب سے اہم بات یہ ہے کہ ہم اپنے لیبلز کی تعداد کی معلومات فراہم کریں۔  

اس کا سب سے آسان طریقہ `num_labels` دلیل کے ساتھ اس تعداد کو پاس کرنا ہے، لیکن اگر ہم چاہتے ہیں کہ ہمارا ماڈل درست انداز میں انفرینس (inference) کرے، تو ہمیں لیبلز کی درست مطابقت بھی سیٹ کرنی ہوگی۔  

یہ دو ڈکشنریوں، `id2label` اور `label2id` کے ذریعے کی جاتی ہے، جو ID کو لیبل سے اور لیبل کو ID سے جوڑنے کا کام کرتی ہیں:

```py
id2label = {i: label for i, label in enumerate(label_names)}
label2id = {v: k for k, v in id2label.items()}
```

اب ہم انہیں `TFAutoModelForTokenClassification.from_pretrained()` میتھڈ میں پاس کر سکتے ہیں، اور یہ ماڈل کی کنفیگریشن میں سیٹ ہو جائیں گے، پھر درست طریقے سے محفوظ کیے جائیں گے اور ہب (Hub) پر اپ لوڈ ہو جائیں گے۔

```py
from transformers import TFAutoModelForTokenClassification

model = TFAutoModelForTokenClassification.from_pretrained(
    model_checkpoint,
    id2label=id2label,
    label2id=label2id,
)
```

جیسے ہم نے [Chapter 3](/course/chapter3) میں `TFAutoModelForSequenceClassification` ڈیفائن کیا تھا، اسی طرح ماڈل بنانے پر ایک وارننگ ظاہر ہوگی کہ کچھ ویٹس استعمال نہیں کیے گئے (یعنی وہ جو پری ٹریننگ ہیڈ سے متعلق ہیں) اور کچھ دیگر ویٹس رینڈم طریقے سے انیشلائز کیے گئے ہیں (یعنی وہ جو نئے ٹوکن کلاسیفکیشن ہیڈ سے متعلق ہیں)، اور اس ماڈل کو ٹرین کرنا ضروری ہے۔ ہم یہ کام ابھی تھوڑی دیر میں کریں گے، لیکن پہلے یہ ڈبل چیک کر لیتے ہیں کہ ہمارے ماڈل میں لیبلز کی درست تعداد موجود ہے۔

```python
model.config.num_labels
```

```python out
9
```

<Tip warning={true}>  

⚠️ اگر آپ کے ماڈل میں غلط تعداد میں لیبلز ہیں، تو `model.fit()` کال کرنے پر آپ کو ایک پیچیدہ ایرر مل سکتا ہے۔ یہ ڈیبگ کرنے میں مشکل ہو سکتا ہے، اس لیے یقینی بنائیں کہ آپ نے لیبلز کی متوقع تعداد کی تصدیق کر لی ہے۔  

</Tip>  

### ماڈل کو فائن ٹیون کرنا[[fine-tuning-the-model]]  

اب ہم اپنے ماڈل کو ٹرین کرنے کے لیے تیار ہیں! لیکن اس سے پہلے تھوڑی سی ترتیب مکمل کرنی ہوگی: ہمیں Hugging Face میں لاگ ان کرنا ہوگا اور اپنے ٹریننگ ہائپرپیرامیٹرز ڈیفائن کرنے ہوں گے۔ اگر آپ نوٹ بک میں کام کر رہے ہیں، تو اس کے لیے ایک کنوینینس فنکشن دستیاب ہے:

```python
from huggingface_hub import notebook_login

notebook_login()
```
یہ ایک ویجیٹ دکھائے گا جہاں آپ اپنی Hugging Face لاگ ان تفصیلات درج کر سکتے ہیں۔  

اگر آپ نوٹ بک میں کام نہیں کر رہے، تو بس اپنی ٹرمینل میں درج ذیل لائن ٹائپ کریں:


```bash
huggingface-cli login
```

لاگ ان کرنے کے بعد، ہم اپنے ماڈل کو مرتب کرنے کے لیے درکار ہر چیز تیار کر سکتے ہیں۔ 🤗 Transformers ایک آسان `create_optimizer()` فنکشن فراہم کرتا ہے جو آپ کو ایک `AdamW` آپٹیمائزر دے گا، جس میں ویٹ ڈیکے اور لرننگ ریٹ ڈیکے کے لیے مناسب سیٹنگز شامل ہوں گی۔ یہ دونوں بلٹ ان `Adam` آپٹیمائزر کے مقابلے میں آپ کے ماڈل کی کارکردگی کو بہتر بنائیں گے۔

```python
from transformers import create_optimizer
import tensorflow as tf

# Train in mixed-precision float16
# Comment this line out if you're using a GPU that will not benefit from this
tf.keras.mixed_precision.set_global_policy("mixed_float16")

# The number of training steps is the number of samples in the dataset, divided by the batch size then multiplied
# by the total number of epochs. Note that the tf_train_dataset here is a batched tf.data.Dataset,
# not the original Hugging Face Dataset, so its len() is already num_samples // batch_size.
num_epochs = 3
num_train_steps = len(tf_train_dataset) * num_epochs

optimizer, schedule = create_optimizer(
    init_lr=2e-5,
    num_warmup_steps=0,
    num_train_steps=num_train_steps,
    weight_decay_rate=0.01,
)
model.compile(optimizer=optimizer)
```

یہ بھی نوٹ کریں کہ ہم `compile()` میں `loss` دلیل فراہم نہیں کرتے۔ اس کی وجہ یہ ہے کہ ماڈلز اندرونی طور پر نقصان (loss) کا حساب لگا سکتے ہیں۔ اگر آپ کسی نقصان کی وضاحت کیے بغیر کمپائل کرتے ہیں اور اپنے لیبلز کو ان پٹ ڈکشنری میں فراہم کرتے ہیں (جیسا کہ ہم اپنے ڈیٹاسیٹس میں کرتے ہیں)، تو ماڈل اسی اندرونی نقصان کا استعمال کرتے ہوئے تربیت حاصل کرے گا، جو منتخب کردہ ٹاسک اور ماڈل کی قسم کے مطابق ہوگا۔  

اس کے بعد، ہم ایک `PushToHubCallback` کو متعین کرتے ہیں تاکہ تربیت کے دوران ہمارا ماڈل Hub پر اپ لوڈ ہو، اور پھر اس کال بیک کے ساتھ ماڈل کو فٹ کرتے ہیں۔


```python
from transformers.keras_callbacks import PushToHubCallback

callback = PushToHubCallback(output_dir="bert-finetuned-ner", tokenizer=tokenizer)

model.fit(
    tf_train_dataset,
    validation_data=tf_eval_dataset,
    callbacks=[callback],
    epochs=num_epochs,
)
```


آپ `hub_model_id` آرگومنٹ کے ساتھ اس ریپوزٹری کا مکمل نام مخصوص کر سکتے ہیں جس میں آپ پش کرنا چاہتے ہیں (خاص طور پر اگر آپ کسی آرگنائزیشن میں پش کرنا چاہتے ہیں)۔ مثال کے طور پر، جب ہم نے ماڈل کو [`huggingface-course` آرگنائزیشن](https://huggingface.co/huggingface-course) میں پش کیا، تو ہم نے `hub_model_id="huggingface-course/bert-finetuned-ner"` شامل کیا۔ ڈیفالٹ طور پر، استعمال ہونے والی ریپوزٹری آپ کے نام کے تحت ہوگی اور آپ کے آؤٹ پٹ ڈائریکٹری کے نام پر رکھی جائے گی، جیسے `"cool_huggingface_user/bert-finetuned-ner"`۔  

<Tip>  

💡 اگر آپ جو آؤٹ پٹ ڈائریکٹری استعمال کر رہے ہیں پہلے سے موجود ہے، تو اسے اس ریپوزٹری کی ایک مقامی کلون ہونی چاہیے جس میں آپ پش کرنا چاہتے ہیں۔ اگر ایسا نہیں ہے، تو `model.fit()` کو کال کرتے وقت آپ کو ایک ایرر ملے گا اور آپ کو ایک نیا نام سیٹ کرنا ہوگا۔  

</Tip>

نوٹ کریں کہ جب تربیت جاری ہوتی ہے، تو ہر بار جب ماڈل محفوظ ہوتا ہے (یہاں، ہر ایپوک پر)، تو یہ پس منظر میں Hub پر اپ لوڈ ہو جاتا ہے۔ اس طرح، اگر ضروری ہو تو، آپ کسی دوسری مشین پر اپنی تربیت دوبارہ شروع کر سکتے ہیں۔  

اس مرحلے پر، آپ Model Hub پر انفیرینس ویجیٹ استعمال کرکے اپنے ماڈل کو ٹیسٹ کر سکتے ہیں اور اسے اپنے دوستوں کے ساتھ شیئر کر سکتے ہیں۔ آپ نے کامیابی کے ساتھ ایک ماڈل کو ٹوکن کلاسیفیکیشن ٹاسک پر فائن ٹیون کر لیا ہے—مبارک ہو! لیکن ہمارا ماڈل حقیقت میں کتنا اچھا ہے؟ اس کا پتہ لگانے کے لیے ہمیں کچھ میٹرکس کا جائزہ لینا چاہیے۔

{/if}

### میٹرکس[[metrics]]

{#if fw === 'pt'}

`Trainer` کو ہر ایپوک میں میٹرک کا حساب لگانے کے لیے، ہمیں ایک `compute_metrics()` فنکشن کو ڈیفائن کرنا ہوگا جو پیش گوئیوں اور لیبلز کی arrays لیتا ہے اور میٹرک کے ناموں اور قدروں کے ساتھ ایک لغت واپس کرتا ہے۔  

ٹوکن درجہ بندی کی پیش گوئی کا اندازہ لگانے کے لیے روایتی فریم ورک [*seqeval*](https://github.com/chakki-works/seqeval) ہے۔ اس میٹرک کو استعمال کرنے کے لیے، ہمیں پہلے *seqeval* لائبریری انسٹال کرنی ہوگی:

```py
!pip install seqeval
```

پھر ہم اسے `evaluate.load()` فنکشن کے ذریعے لوڈ کر سکتے ہیں، جیسے ہم نے [باب 3](/course/chapter3) میں کیا تھا:  

{:else}  

ٹوکن درجہ بندی کی پیش گوئی کا اندازہ لگانے کے لیے روایتی فریم ورک [*seqeval*](https://github.com/chakki-works/seqeval) ہے۔ اس میٹرک کو استعمال کرنے کے لیے، ہمیں پہلے *seqeval* لائبریری انسٹال کرنی ہوگی:


```py
!pip install seqeval
```

پھر ہم اسے `evaluate.load()` فنکشن کے ذریعے لوڈ کر سکتے ہیں، جیسے ہم نے [باب 3](/course/chapter3) میں کیا تھا:

{/if}

```py
import evaluate

metric = evaluate.load("seqeval")
```

یہ میٹرک عام درستگی (accuracy) کی طرح کام نہیں کرتا: یہ درحقیقت لیبلز کی فہرستوں کو اسٹرنگز کی شکل میں لیتا ہے، نہ کہ انٹیجرز کی صورت میں، لہذا ہمیں پیشگوئیوں اور لیبلز کو مکمل طور پر ڈیکوڈ کرنا ہوگا اس سے پہلے کہ ہم انہیں میٹرک میں پاس کریں۔ آئیے دیکھتے ہیں کہ یہ کیسے کام کرتا ہے۔ سب سے پہلے، ہم اپنے پہلے ٹریننگ مثال کے لیے لیبلز حاصل کریں گے:

```py
labels = raw_datasets["train"][0]["ner_tags"]
labels = [label_names[i] for i in labels]
labels
```

```python out
['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']
```

پھر ہم محض انڈیکس 2 پر ویلیو تبدیل کرکے ان کے لیے جعلی پیشگوئیاں بنا سکتے ہیں:

```py
predictions = labels.copy()
predictions[2] = "O"
metric.compute(predictions=[predictions], references=[labels])
```

نوٹ کریں کہ میٹرک پیشگوئیوں کی فہرست (صرف ایک نہیں) اور لیبلز کی فہرست لیتا ہے۔ یہ ہے آؤٹ پٹ:

```python out
{'MISC': {'precision': 1.0, 'recall': 0.5, 'f1': 0.67, 'number': 2},
 'ORG': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},
 'overall_precision': 1.0,
 'overall_recall': 0.67,
 'overall_f1': 0.8,
 'overall_accuracy': 0.89}
```

{#if fw === 'pt'}

یہ کافی زیادہ معلومات واپس بھیج رہا ہے! ہمیں ہر الگ ادارے کے لیے precision، recall، اور F1 اسکور ملتا ہے، نیز مجموعی طور پر بھی۔ ہمارے میٹرک کے حساب میں ہم صرف مجموعی اسکور رکھیں گے، لیکن آپ `compute_metrics()` فنکشن میں ترمیم کر کے وہ تمام میٹرکس واپس حاصل کر سکتے ہیں جو آپ رپورٹ کرنا چاہتے ہیں۔  

یہ `compute_metrics()` فنکشن پہلے لاجٹس (logits) کا argmax لیتا ہے تاکہ انہیں پیشگوئیوں میں تبدیل کیا جا سکے (عام طور پر، لاجٹس اور احتمالات ایک ہی ترتیب میں ہوتے ہیں، لہٰذا ہمیں softmax لاگو کرنے کی ضرورت نہیں ہوتی)۔ پھر ہمیں لیبلز اور پیشگوئیوں دونوں کو integers سے strings میں تبدیل کرنا ہوتا ہے۔ ہم ان تمام اقدار کو ہٹا دیتے ہیں جہاں لیبل `-100` ہو، پھر نتائج کو `metric.compute()` میتھڈ میں پاس کرتے ہیں:

```py
import numpy as np


def compute_metrics(eval_preds):
    logits, labels = eval_preds
    predictions = np.argmax(logits, axis=-1)

    # Remove ignored index (special tokens) and convert to labels
    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]
    true_predictions = [
        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]
        for prediction, label in zip(predictions, labels)
    ]
    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)
    return {
        "precision": all_metrics["overall_precision"],
        "recall": all_metrics["overall_recall"],
        "f1": all_metrics["overall_f1"],
        "accuracy": all_metrics["overall_accuracy"],
    }
```

اب جب کہ یہ مکمل ہو گیا ہے، ہم اپنے `Trainer` کی تعریف کرنے کے قریب ہیں۔ ہمیں بس ایک `model` کی ضرورت ہے جسے ہم فائن ٹیون (fine-tune) کر سکیں!

{:else}

یہ ہمیں بہت زیادہ معلومات واپس بھیج رہا ہے! ہمیں ہر علیحدہ اینٹیٹی کے لیے پریسجن (precision)، ریکال (recall)، اور ایف 1 اسکور (F1 score) کے ساتھ ساتھ مجموعی اسکور بھی ملتا ہے۔ اب آئیے دیکھتے ہیں کہ اگر ہم اپنے اصل ماڈل کی پیشگوئیوں کو استعمال کر کے کچھ حقیقی اسکورز کا حساب لگانے کی کوشش کریں تو کیا ہوتا ہے۔  

TensorFlow کو ہماری پیشگوئیوں کو ایک ساتھ جوڑنا پسند نہیں، کیونکہ ان کی ترتیب کی لمبائی متغیر ہوتی ہے۔ اس کا مطلب ہے کہ ہم صرف `model.predict()` استعمال نہیں کر سکتے—لیکن یہ ہمیں روک نہیں سکتا۔ ہم بیچز میں کچھ پیشگوئیاں حاصل کریں گے اور انہیں ایک طویل فہرست میں جوڑتے جائیں گے، `-100` ٹوکنز کو ہٹا کر جو ماسکنگ/پیڈنگ کی نشاندہی کرتے ہیں، اور آخر میں اس فہرست پر میٹرکس کا حساب لگائیں گے:

```py
import numpy as np

all_predictions = []
all_labels = []
for batch in tf_eval_dataset:
    logits = model.predict_on_batch(batch)["logits"]
    labels = batch["labels"]
    predictions = np.argmax(logits, axis=-1)
    for prediction, label in zip(predictions, labels):
        for predicted_idx, label_idx in zip(prediction, label):
            if label_idx == -100:
                continue
            all_predictions.append(label_names[predicted_idx])
            all_labels.append(label_names[label_idx])
metric.compute(predictions=[all_predictions], references=[all_labels])
```


```python out
{'LOC': {'precision': 0.91, 'recall': 0.92, 'f1': 0.91, 'number': 1668},
 'MISC': {'precision': 0.70, 'recall': 0.79, 'f1': 0.74, 'number': 702},
 'ORG': {'precision': 0.85, 'recall': 0.90, 'f1': 0.88, 'number': 1661},
 'PER': {'precision': 0.95, 'recall': 0.95, 'f1': 0.95, 'number': 1617},
 'overall_precision': 0.87,
 'overall_recall': 0.91,
 'overall_f1': 0.89,
 'overall_accuracy': 0.97}
```

آپ کے ماڈل نے ہمارے مقابلے میں کیسا کارکردگی دکھائی؟ اگر آپ کو ملتے جلتے نمبرز ملے ہیں، تو آپ کی ٹریننگ کامیاب رہی!

{/if}

{#if fw === 'pt'}

### ماڈل کی تعریف[[defining-the-model]]  

چونکہ ہم ایک ٹوکن کلاسیفیکیشن کے مسئلے پر کام کر رہے ہیں، اس لیے ہم `AutoModelForTokenClassification` کلاس کا استعمال کریں گے۔ اس ماڈل کو ڈیفائن کرتے وقت سب سے اہم بات یہ ہے کہ ہم اپنے لیبلز کی تعداد کی معلومات فراہم کریں۔  

اس کا سب سے آسان طریقہ `num_labels` آرگومنٹ کے ذریعے یہ تعداد فراہم کرنا ہے، لیکن اگر ہم چاہتے ہیں کہ ہمارا انفرنس ویجیٹ بہتر کام کرے (جیسے ہم نے اس سیکشن کے شروع میں دیکھا تھا)، تو ہمیں درست لیبل کی مطابقتیں سیٹ کرنی ہوں گی۔  

یہ مطابقتیں دو ڈکشنریوں، `id2label` اور `label2id` کے ذریعے سیٹ کی جانی چاہئیں، جو ID کو لیبل سے اور لیبل کو ID سے جوڑتی ہیں:


```py
id2label = {i: label for i, label in enumerate(label_names)}
label2id = {v: k for k, v in id2label.items()}
```

اب ہم انہیں بس `AutoModelForTokenClassification.from_pretrained()` میتھڈ میں پاس کر سکتے ہیں، اور یہ ماڈل کی کنفیگریشن میں سیٹ ہو جائیں گے، پھر مناسب طریقے سے محفوظ کیے جائیں گے اور ہب پر اپلوڈ ہو جائیں گے:

```py
from transformers import AutoModelForTokenClassification

model = AutoModelForTokenClassification.from_pretrained(
    model_checkpoint,
    id2label=id2label,
    label2id=label2id,
)
```

جس طرح ہم نے [Chapter 3](/course/chapter3) میں اپنا `AutoModelForSequenceClassification` ڈیفائن کیا تھا، اسی طرح ماڈل بنانے پر ایک وارننگ ظاہر ہوتی ہے کہ کچھ ویٹس استعمال نہیں کیے گئے (جو پری ٹریننگ ہیڈ سے ہیں) اور کچھ دوسرے ویٹس رینڈم طریقے سے انیشلائز کیے گئے ہیں (جو نئے ٹوکن کلاسیفکیشن ہیڈ سے ہیں)، اور اس ماڈل کو ٹرین کرنا چاہیے۔ ہم یہ کام ابھی کریں گے، لیکن پہلے آئیے ڈبل چیک کر لیں کہ ہمارے ماڈل میں لیبلز کی صحیح تعداد موجود ہے:


```python
model.config.num_labels
```

```python out
9
```

<Tip warning={true}>

⚠️ اگر آپ کے ماڈل میں لیبلز کی غلط تعداد ہوگی، تو بعد میں `Trainer.train()` میتھڈ کو کال کرنے پر آپ کو ایک غیر واضح ایرر ملے گا (کچھ اس طرح: "CUDA error: device-side assert triggered")۔ یہ اس قسم کے ایررز کے بارے میں صارفین کی طرف سے رپورٹ کی جانے والی سب سے عام وجہ ہے، لہذا یقینی بنائیں کہ آپ یہ چیک کریں تاکہ تصدیق ہو سکے کہ آپ کے پاس متوقع تعداد میں لیبلز موجود ہیں۔

</Tip>


### ماڈل کو فائن ٹیون کرنا[[fine-tuning-the-model]]  

اب ہم اپنے ماڈل کو ٹرین کرنے کے لیے تیار ہیں! `Trainer` کو ڈیفائن کرنے سے پہلے ہمیں صرف دو آخری کام کرنے ہیں: Hugging Face میں لاگ ان کرنا اور اپنے ٹریننگ آرگیومنٹس کو ڈیفائن کرنا۔ اگر آپ کسی نوٹ بک میں کام کر رہے ہیں، تو اس کے لیے ایک آسان فنکشن موجود ہے جو آپ کی مدد کرے گا:

```python
from huggingface_hub import notebook_login

notebook_login()
```

یہ ایک ویجیٹ دکھائے گا جہاں آپ اپنی Hugging Face لاگ ان اسناد درج کر سکتے ہیں۔  

اگر آپ نوٹ بک میں کام نہیں کر رہے ہیں، تو بس اپنے ٹرمینل میں درج ذیل کمانڈ ٹائپ کریں:  

```bash
huggingface-cli login
```  

یہ مکمل ہونے کے بعد، ہم اپنے `TrainingArguments` کو ڈیفائن کر سکتے ہیں:


```python
from transformers import TrainingArguments

args = TrainingArguments(
    "bert-finetuned-ner",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
    push_to_hub=True,
)
```
آپ نے ان میں سے زیادہ تر چیزیں پہلے دیکھی ہیں: ہم کچھ ہائپرپیرامیٹرز سیٹ کرتے ہیں (جیسے لرننگ ریٹ، ایپوکس کی تعداد، اور ویٹ ڈیکے) اور `push_to_hub=True` کو اس بات کی نشاندہی کے لیے استعمال کرتے ہیں کہ ہم ہر ایپوک کے آخر میں ماڈل کو محفوظ کرنا اور اس کا تجزیہ کرنا چاہتے ہیں، اور ہم اپنے نتائج کو ماڈل ہب پر اپلوڈ کرنا چاہتے ہیں۔  

نوٹ کریں کہ آپ `hub_model_id` دلیل کے ذریعے اس ریپوزٹری کا نام مخصوص کر سکتے ہیں جس میں آپ اپنا ماڈل اپلوڈ کرنا چاہتے ہیں (خاص طور پر اگر آپ کسی تنظیم میں پش کرنا چاہتے ہیں تو یہ ضروری ہوگا)۔ مثال کے طور پر، جب ہم نے ماڈل [`huggingface-course` تنظیم](https://huggingface.co/huggingface-course) میں پش کیا، تو ہم نے `hub_model_id="huggingface-course/bert-finetuned-ner"` کو `TrainingArguments` میں شامل کیا۔ ڈیفالٹ طور پر، استعمال ہونے والی ریپوزٹری آپ کے نیم اسپیس میں ہوگی اور اس کا نام آپ کی آؤٹ پٹ ڈائریکٹری کے مطابق ہوگا، لہذا ہمارے معاملے میں یہ `"sgugger/bert-finetuned-ner"` ہوگا۔  

<Tip>  

💡 اگر آپ جو آؤٹ پٹ ڈائریکٹری استعمال کر رہے ہیں وہ پہلے سے موجود ہے، تو یہ اس ریپوزٹری کی ایک مقامی کلون ہونی چاہیے جس میں آپ پش کرنا چاہتے ہیں۔ اگر ایسا نہیں ہے، تو `Trainer` کو ڈیفائن کرتے وقت آپ کو ایک خرابی (error) ملے گی اور آپ کو نیا نام سیٹ کرنے کی ضرورت ہوگی۔  

</Tip>  

آخر میں، ہم بس سب کچھ `Trainer` کو پاس کرتے ہیں اور ٹریننگ کا آغاز کرتے ہیں:

```python
from transformers import Trainer

trainer = Trainer(
    model=model,
    args=args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    compute_metrics=compute_metrics,
    tokenizer=tokenizer,
)
trainer.train()
```

نوٹ کریں کہ جب ٹریننگ ہو رہی ہوتی ہے، تو ہر بار جب ماڈل محفوظ کیا جاتا ہے (یہاں، ہر ایپوک پر)، اسے پس منظر میں ہب پر اپلوڈ کر دیا جاتا ہے۔ اس طرح، اگر ضرورت ہو تو آپ کسی اور مشین پر اپنی ٹریننگ دوبارہ شروع کر سکتے ہیں۔  

جب ٹریننگ مکمل ہو جائے، تو ہم `push_to_hub()` میتھڈ استعمال کرتے ہیں تاکہ ماڈل کا تازہ ترین ورژن یقینی طور پر اپلوڈ ہو جائے:

```py
trainer.push_to_hub(commit_message="Training complete")
```

یہ کمانڈ اس کمیٹ کا URL واپس کرتی ہے جو ابھی مکمل ہوئی، اگر آپ اسے دیکھنا چاہیں:  

```python out
'https://huggingface.co/sgugger/bert-finetuned-ner/commit/26ab21e5b1568f9afeccdaed2d8715f571d786ed'
```  

`Trainer` ماڈل کارڈ کا ایک ڈرافٹ بھی تیار کرتا ہے جس میں تمام ایویلیوایشن کے نتائج ہوتے ہیں اور اسے اپلوڈ کر دیتا ہے۔ اس مرحلے پر، آپ Model Hub پر انفرنس ویجیٹ استعمال کر کے اپنے ماڈل کو آزما سکتے ہیں اور اسے اپنے دوستوں کے ساتھ شیئر کر سکتے ہیں۔ آپ نے کامیابی سے ایک ماڈل کو ٹوکن کلاسفکیشن ٹاسک پر فائن ٹیون کر لیا ہے—مبارک ہو!  

اگر آپ ٹریننگ لوپ کو مزید گہرائی سے سمجھنا چاہتے ہیں، تو اب ہم آپ کو 🤗 Accelerate کا استعمال کرتے ہوئے یہی کام کرنے کا طریقہ دکھائیں گے۔  

## ایک کسٹم ٹریننگ لوپ [[a-custom-training-loop]]  

اب ہم مکمل ٹریننگ لوپ پر نظر ڈالیں گے تاکہ آپ جس حصے کو چاہیں آسانی سے کسٹمائز کر سکیں۔ یہ بہت حد تک وہی ہوگا جو ہم نے [Chapter 3](/course/chapter3/4) میں کیا تھا، لیکن ایویلیوایشن کے لیے کچھ تبدیلیاں ہوں گی۔  

### ٹریننگ کے لیے تمام چیزیں تیار کرنا [[preparing-everything-for-training]]  

سب سے پہلے ہمیں اپنے ڈیٹاسیٹس سے `DataLoader`s بنانے کی ضرورت ہوگی۔ ہم اپنے `data_collator` کو `collate_fn` کے طور پر دوبارہ استعمال کریں گے اور ٹریننگ سیٹ کو شفل کریں گے، لیکن ویلیڈیشن سیٹ کو نہیں:


```py
from torch.utils.data import DataLoader

train_dataloader = DataLoader(
    tokenized_datasets["train"],
    shuffle=True,
    collate_fn=data_collator,
    batch_size=8,
)
eval_dataloader = DataLoader(
    tokenized_datasets["validation"], collate_fn=data_collator, batch_size=8
)
```

اگلے مرحلے میں ہم اپنا ماڈل دوبارہ ترتیب دیں گے، تاکہ یہ یقینی بنایا جا سکے کہ ہم پچھلے فائن ٹیوننگ کو جاری نہیں رکھ رہے بلکہ دوبارہ BERT پہلے سے تربیت یافتہ ماڈل سے شروع کر رہے ہیں:

```py
model = AutoModelForTokenClassification.from_pretrained(
    model_checkpoint,
    id2label=id2label,
    label2id=label2id,
)
```

پھر ہمیں ایک آپٹیمائزر کی ضرورت ہوگی۔ ہم کلاسک `AdamW` استعمال کریں گے، جو `Adam` کی طرح ہے، مگر وزن میں کمی کے اطلاق کے طریقہ کار میں بہتری کے ساتھ:

```py
from torch.optim import AdamW

optimizer = AdamW(model.parameters(), lr=2e-5)
```

جب ہمارے پاس یہ تمام آبجیکٹس موجود ہوں، تو ہم انہیں `accelerator.prepare()` میتھڈ کو بھیج سکتے ہیں:

```py
from accelerate import Accelerator

accelerator = Accelerator()
model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(
    model, optimizer, train_dataloader, eval_dataloader
)
```

<Tip>

🚨 اگر آپ TPU پر تربیت کر رہے ہیں، تو آپ کو اوپر والے سیل سے شروع ہونے والا تمام کوڈ ایک مخصوص تربیتی فنکشن میں منتقل کرنا ہوگا۔ مزید تفصیلات کے لیے [Chapter 3](/course/chapter3) ملاحظہ کریں۔

</Tip>

اب جبکہ ہم نے اپنے `train_dataloader` کو `accelerator.prepare()` میں بھیج دیا ہے، ہم اس کی لمبائی کا استعمال کرتے ہوئے تربیتی مراحل کی تعداد کا حساب لگا سکتے ہیں۔ یاد رکھیں کہ ہمیں ہمیشہ ڈیٹا لوڈر کو تیار کرنے کے بعد یہ عمل کرنا چاہیے، کیونکہ وہ میتھڈ اس کی لمبائی کو تبدیل کر دے گا۔ ہم سیکھنے کی شرح سے 0 تک کلاسک لکیری شیڈول استعمال کرتے ہیں:

```py
from transformers import get_scheduler

num_train_epochs = 3
num_update_steps_per_epoch = len(train_dataloader)
num_training_steps = num_train_epochs * num_update_steps_per_epoch

lr_scheduler = get_scheduler(
    "linear",
    optimizer=optimizer,
    num_warmup_steps=0,
    num_training_steps=num_training_steps,
)
```

آخری طور پر، اپنے ماڈل کو Hub پر دھکیلنے کے لیے، ہمیں ایک ورکنگ فولڈر میں ایک `Repository` آبجیکٹ تخلیق کرنے کی ضرورت ہوگی۔ اگر آپ پہلے سے لاگ ان نہیں ہیں تو پہلے Hugging Face میں لاگ ان کریں۔ ہم ماڈل کو جو ماڈل ID دینا چاہتے ہیں، اسی سے ریپوزیٹری کا نام متعین کریں گے (آپ چاہیں تو `repo_name` کو اپنی مرضی سے بدل سکتے ہیں؛ اسے صرف آپ کا یوزرنیم شامل ہونا چاہیے، جو کہ `get_full_repo_name()` فنکشن کرتا ہے):

```py
from huggingface_hub import Repository, get_full_repo_name

model_name = "bert-finetuned-ner-accelerate"
repo_name = get_full_repo_name(model_name)
repo_name
```

```python out
'sgugger/bert-finetuned-ner-accelerate'
```

پھر ہم اس ریپوزیٹری کو ایک مقامی فولڈر میں کلون کر سکتے ہیں۔ اگر یہ پہلے سے موجود ہے تو یہ مقامی فولڈر اسی ریپوزیٹری کا موجودہ کلون ہونا چاہیے جس پر ہم کام کر رہے ہیں:

```py
output_dir = "bert-finetuned-ner-accelerate"
repo = Repository(output_dir, clone_from=repo_name)
```

اب ہم `output_dir` میں محفوظ کی گئی کسی بھی چیز کو `repo.push_to_hub()` میتھڈ کال کرکے اپلوڈ کر سکتے ہیں۔ اس سے ہمیں ہر ایپوک کے اختتام پر درمیانی ماڈلز اپلوڈ کرنے میں مدد ملے گی۔

### تربیتی لوپ[[training-loop]]

اب ہم مکمل تربیتی لوپ لکھنے کے لیے تیار ہیں۔ اس کے جائزے کے حصے کو آسان بنانے کے لیے، ہم یہ `postprocess()` فنکشن تعریف کرتے ہیں جو پیش گوئیوں اور لیبلز کو لے کر انہیں اسٹرنگز کی فہرستوں میں تبدیل کرتا ہے، جیسا کہ ہمارے `metric` آبجیکٹ کی توقع ہے:

```py
def postprocess(predictions, labels):
    predictions = predictions.detach().cpu().clone().numpy()
    labels = labels.detach().cpu().clone().numpy()

    # غیر ضروری انڈیکس (خاص ٹوکنز) کو ہٹا کر لیبلز میں تبدیل کریں
    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]
    true_predictions = [
        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]
        for prediction, label in zip(predictions, labels)
    ]
    return true_labels, true_predictions
```

پھر ہم تربیتی لوپ لکھ سکتے ہیں۔ تربیت کے دوران پیش رفت دیکھنے کے لیے ایک پروگریس بار متعین کرنے کے بعد، اس لوپ کے تین حصے ہیں:

- خود تربیت، جو کہ `train_dataloader` پر کلاسیکی تکرار ہے، ماڈل کے ذریعے فارورڈ پاس، پھر بیک ورڈ پاس اور آپٹیمائزر کا مرحلہ۔
- جائزہ، جس میں ماڈل کے ایک بیچ پر آؤٹ پُٹ حاصل کرنے کے بعد ایک نیا عمل شامل ہوتا ہے: چونکہ دو عمل ممکن ہے کہ ان پٹ اور لیبلز کو مختلف اشکال میں پیڈ کر دیں، اس لیے ہمیں `accelerator.pad_across_processes()` استعمال کر کے پیش گوئیوں اور لیبلز کی شکلیں یکساں کرنی ہوں گی، اس سے پہلے کہ `gather()` میتھڈ کال کیا جائے۔ اگر ایسا نہ کیا گیا تو جائزہ یا تو ایرر دے گا یا ہمیشہ کے لیے پھنس جائے گا۔ پھر ہم نتائج کو `metric.add_batch()` میں بھیجتے ہیں اور جب جائزہ لوپ ختم ہو جائے تو `metric.compute()` کال کرتے ہیں۔
- محفوظ کرنا اور اپلوڈ کرنا، جہاں ہم پہلے ماڈل اور ٹوکنائزر کو محفوظ کرتے ہیں، پھر `repo.push_to_hub()` کال کرتے ہیں۔ نوٹ کریں کہ ہم دلیل `blocking=False` استعمال کرتے ہیں تاکہ 🤗 Hub لائبریری کو ایک غیر ہم وقت (asynchronous) عمل میں دھکیلنے کا کہا جائے۔ اس طرح تربیت معمول کے مطابق جاری رہتی ہے اور یہ (طویل) ہدایت بیک گراؤنڈ میں چلتی رہتی ہے۔

یہاں تربیتی لوپ کا مکمل کوڈ موجود ہے:

```py
from tqdm.auto import tqdm
import torch

progress_bar = tqdm(range(num_training_steps))

for epoch in range(num_train_epochs):
    # Training
    model.train()
    for batch in train_dataloader:
        outputs = model(**batch)
        loss = outputs.loss
        accelerator.backward(loss)

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(1)

    # Evaluation
    model.eval()
    for batch in eval_dataloader:
        with torch.no_grad():
            outputs = model(**batch)

        predictions = outputs.logits.argmax(dim=-1)
        labels = batch["labels"]

        # ضروری ہے کہ پیش گوئیوں اور لیبلز کو ایک جیسا شکل دینے کے لیے پیڈ کیا جائے تاکہ انہیں جمع کیا جا سکے
        predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)
        labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)

        predictions_gathered = accelerator.gather(predictions)
        labels_gathered = accelerator.gather(labels)

        true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)
        metric.add_batch(predictions=true_predictions, references=true_labels)

    results = metric.compute()
    print(
        f"epoch {epoch}:",
        {
            key: results[f"overall_{key}"]
            for key in ["precision", "recall", "f1", "accuracy"]
        },
    )

    # Save and upload
    accelerator.wait_for_everyone()
    unwrapped_model = accelerator.unwrap_model(model)
    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)
    if accelerator.is_main_process:
        tokenizer.save_pretrained(output_dir)
        repo.push_to_hub(
            commit_message=f"Training in progress epoch {epoch}", blocking=False
        )
```

اگر یہ پہلی بار ہے کہ آپ نے 🤗 Accelerate کے ساتھ محفوظ کیا گیا ماڈل دیکھا ہے، تو آئیں ان تین لائنوں کے کوڈ کا معائنہ کریں جو اس سے متعلق ہیں:

```py
accelerator.wait_for_everyone()
unwrapped_model = accelerator.unwrap_model(model)
unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)
```

پہلی لائن خود واضح ہے: یہ تمام عمل کو یہ بتاتی ہے کہ سب لوگ اسی مرحلے پر پہنچ جانے تک انتظار کریں۔ اس کا مقصد یہ ہے کہ محفوظ کرنے سے پہلے ہر عمل میں ایک ہی ماڈل موجود ہو۔ پھر ہم `unwrapped_model` حاصل کرتے ہیں، جو کہ ہمارا بنیادی ماڈل ہے جسے ہم نے تعریف کیا تھا۔ `accelerator.prepare()` میتھڈ ماڈل کو تقسیم شدہ تربیت کے لیے تبدیل کر دیتا ہے، لہٰذا اب اس میں `save_pretrained()` میتھڈ موجود نہیں ہوتا؛ `accelerator.unwrap_model()` میتھڈ یہ تبدیلی پلٹ دیتا ہے۔ آخر میں، ہم `save_pretrained()` کال کرتے ہیں مگر اس میتھڈ کو `torch.save()` کے بجائے `accelerator.save()` استعمال کرنے کے لیے کہتے ہیں۔

ایک بار جب یہ سب مکمل ہو جائے، تو آپ کے پاس ایسا ماڈل ہونا چاہیے جو `Trainer` کے ساتھ تربیت شدہ ماڈل کے مشابہ نتائج فراہم کرتا ہو۔ آپ اس کوڈ کا استعمال کرتے ہوئے تربیت شدہ ماڈل کو [*huggingface-course/bert-finetuned-ner-accelerate*](https://huggingface.co/huggingface-course/bert-finetuned-ner-accelerate) پر چیک کر سکتے ہیں۔ اور اگر آپ تربیتی لوپ میں کوئی تبدیلیاں آزمانا چاہتے ہیں، تو آپ اوپر دکھائے گئے کوڈ میں ترمیم کرکے براہ راست انہیں نافذ کر سکتے ہیں!

{/if}

## فائن ٹیون شدہ ماڈل کا استعمال[[using-the-fine-tuned-model]]

ہم پہلے ہی آپ کو دکھا چکے ہیں کہ آپ ماڈل ہب پر فائن ٹیون کیا گیا ماڈل انفرنس ویجیٹ کے ساتھ کیسے استعمال کر سکتے ہیں۔ اسے مقامی سطح پر `pipeline` میں استعمال کرنے کے لیے، آپ کو صرف مناسب ماڈل شناخت کنندہ بتانا ہے:

```py
from transformers import pipeline

# اپنی مرضی کا چیک پوائنٹ یہاں تبدیل کریں
model_checkpoint = "huggingface-course/bert-finetuned-ner"
token_classifier = pipeline(
    "token-classification", model=model_checkpoint, aggregation_strategy="simple"
)
token_classifier("My name is Sylvain and I work at Hugging Face in Brooklyn.")
```

```python out
[{'entity_group': 'PER', 'score': 0.9988506, 'word': 'Sylvain', 'start': 11, 'end': 18},
 {'entity_group': 'ORG', 'score': 0.9647625, 'word': 'Hugging Face', 'start': 33, 'end': 45},
 {'entity_group': 'LOC', 'score': 0.9986118, 'word': 'Brooklyn', 'start': 49, 'end': 57}]
```

زبردست! ہمارا ماڈل اس پائپ لائن کے لیے ڈیفالٹ ماڈل کی طرح ہی کام کر رہا ہے!







































 ## ماڈل کی تعریف

کیونکہ ہم ایک ٹوکن کلاسفیکیشن پر کام کر رہے ہیں، ہم `TFAutoModelForTokenClassification` کلاس استعمال کریں گے۔ اس ماڈل کی تعریف کرتے وقت سب سے اہم چیز یہ ہے کہ ہم اپنے لیبلز کی تعداد کے بارے میں معلومات فراہم کریں۔ اس کا آسان ترین طریقہ یہ ہے کہ `num_labels` ارگومنٹ کے ذریعے یہ تعداد پاس کریں، لیکن اگر ہم ایک خوبصورت انفیرنس وِڈگیٹ چاہتے ہیں جیسے کہ ہم نے اس سیکشن کے آغاز میں دیکھا تھا، تو بہتر ہے کہ صحیح لیبل کی ہم آہنگیاں مرتب کریں۔

یہ دو ڈکشنریوں `id2label` اور `label2id` کے ذریعے کی جانی چاہیے، جو ID سے لیبل اور اس کے برعکس کا میپنگ فراہم کرتی ہیں:

```python
id2label = {i: label for i, label in enumerate(label_names)}
label2id = {v: k for k, v in id2label.items()}

# Fine-tuned Model Training and Upload

ہم نے کچھ ہائپر پیرامیٹرز سیٹ کیے ہیں (جیسے سیکھنے کی شرح، کتنی ایپوک تک ٹریننگ کرنی ہے، اور وزن کی کمی) اور ہم نے `push_to_hub=True` سیٹ کیا ہے تاکہ یہ ظاہر ہو سکے کہ ہم ماڈل کو محفوظ کرنا چاہتے ہیں اور ہر ایپوک کے آخر میں اس کا جائزہ لینا چاہتے ہیں، اور ہمارے نتائج Model Hub پر اپ لوڈ کرنا چاہتے ہیں۔ نوٹ کریں کہ آپ `hub_model_id` کی مدد سے اس ریپوزیٹری کا نام سیٹ کر سکتے ہیں جس پر آپ ماڈل اپ لوڈ کرنا چاہتے ہیں (خاص طور پر اگر آپ کسی تنظیم میں اپ لوڈ کر رہے ہیں)۔

اگر آپ اس بات کو یقینی بنانا چاہتے ہیں کہ آپ کا ریپوزیٹری پہلے سے موجود ہے، تو اسے پہلے سے موجود کلون ہونا ضروری ہے، ورنہ آپ کو غلطی ملے گی۔

آخر میں، ہم سب کچھ `Trainer` میں دے دیتے ہیں اور ٹریننگ شروع کر دیتے ہیں:

```python
from transformers import Trainer

trainer = Trainer(
    model=model,
    args=args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    compute_metrics=compute_metrics,
    tokenizer=tokenizer,
)
trainer.train()

