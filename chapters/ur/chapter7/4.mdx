<FrameworkSwitchCourse {fw} />

# ุชุฑุฌู[[translation]]

{#if fw === 'pt'}

<CourseFloatingBanner chapter={7}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter7/section4_pt.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter7/section4_pt.ipynb"},
]} />

{:else}

<CourseFloatingBanner chapter={7}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter7/section4_tf.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter7/section4_tf.ipynb"},
]} />

{/if}

ุขุฆ ุงุจ ุชุฑุฌู ูฺบ ฺูุจุช ฺบ  ุงฺฉ ุงูุฑ [ุณquence-to-sequence ูนุงุณฺฉ](/course/chapter1/7) ุ ุฌุณ ฺฉุง ูุทูุจ  ฺฉ ูุณุฆู ฺฉู ุงฺฉ ุณquence ุณ ุฏูุณุฑ ุณquence ูฺบ ุชุจุฏู ฺฉุฑู ฺฉ ูุณุฆู ฺฉ ุตูุฑุช ูฺบ ูพุด ฺฉุง ุฌุง ุณฺฉุชุง  ุงุณ ูุญุงุธ ุณ  ูุณุฆู [ุฎูุงุต ูฺฏุงุฑ](/course/chapter7/6) ฺฉ ุจุช ูุฑุจ ุ ุงูุฑ ุขูพ ุงฺบ ุฏฺฉฺพ ุฌุงู ูุงู ุชฺฉูฺฉ ฺฉู ุฏฺฏุฑ sequence-to-sequence ูุณุงุฆู ูพุฑ ุจฺพ ุงูพู ุณฺฉุช ฺบ ุฌุณ ฺฉ:

- **ุงุณูนุงุฆู ูนุฑุงูุณูุฑ**: ุงุณุง ูุงฺู ุจูุงูุง ุฌู ุงฺฉ ูุฎุตูุต ุงูุฏุงุฒ ูฺบ ูฺฉฺพ ฺฏุฆ ุชุญุฑุฑูฺบ ฺฉู ุฏูุณุฑ ุงูุฏุงุฒ ูฺบ *ุชุฑุฌู* ฺฉุฑ ุฏ (ูุซูุงูุ ุฑุณู ุงูุฏุงุฒ ุณ ุบุฑ ุฑุณู ุง ุดฺฉุณูพุฆุฑู ุงูฺฏุฑุฒ ุณ ุฌุฏุฏ ุงูฺฏุฑุฒ)
- **ุฌูุฑูนู ุณูุงู ู ุฌูุงุจ**: ุงุณุง ูุงฺู ุชุงุฑ ฺฉุฑูุง ุฌู ฺฉุณ ุณุงู ู ุณุจุงู ฺฉู ุฏฺฉฺพุช ูุฆ ุณูุงูุงุช ฺฉ ุฌูุงุจุงุช ุชุงุฑ ฺฉุฑ

<Youtube id="1JvfrvZgi6c"/>

ุงฺฏุฑ ุขูพ ฺฉ ูพุงุณ ุฏู (ุง ุฒุงุฏ) ุฒุจุงููฺบ ูฺบ ฺฉุงู ุจฺ ููุฏุงุฑ ูฺบ ูุชูู ููุฌูุฏ ูฺบุ ุชู ุขูพ ุดุฑูุน ุณ ุงฺฉ ูุง ุชุฑุฌู ูุงฺู ุชุฑุจุช ุฏ ุณฺฉุช ฺบ ุฌุณุง ฺฉ ู [causal language modeling](/course/chapter7/6) ฺฉ ุญุต ูฺบ ุฏฺฉฺพฺบ ฺฏ ุชุงูุ ุงฺฉ ููุฌูุฏ ุชุฑุฌู ูุงฺู ฺฉู fine-tune ฺฉุฑูุง ุฒุงุฏ ุชุฒ ูฺฏุงุ ฺุง ู mT5 ุง mBART ุฌุณ ฺฉุซุฑ ูุณุงู ูุงฺู ูฺบ ุฌูฺบ ุขูพ ูุฎุตูุต ุฒุจุงู ุฌูฺ ฺฉ ู fine-tune ฺฉุฑูุง ฺุงุช ูฺบุ ุง ูพฺพุฑ ุงฺฉ ุงุณุง ูุงฺู ุฌู ุงฺฉ ุฒุจุงู ุณ ุฏูุณุฑ ุฒุจุงู ฺฉ ุชุฑุฌู ฺฉ ู ุฎุงุต ู ุงูุฑ ุขูพ ุงูพู ูุฎุตูุต ูุฌููุน ฺฉ ู fine-tune ฺฉุฑูุง ฺุงุช ูฺบ

ุงุณ ุณฺฉุดู ูฺบุ ู ุงฺฉ Marian ูุงฺู ฺฉู fine-tune ฺฉุฑฺบ ฺฏ ุฌู ูพู ุณ ุงูฺฏุฑุฒ ุณ ูุฑุงูุณุณ ูฺบ ุชุฑุฌู ฺฉุฑู ฺฉ ู ุชุฑุจุช ุงูุช  (ฺฉููฺฉ ุจุช ุณ Hugging Face ููุงุฒูู ุฏูููฺบ ุฒุจุงูฺบ ุจููุช ฺบ) [KDE4 dataset](https://huggingface.co/datasets/kde4) ูพุฑุ ุฌู [KDE ุงูพุณ](https://apps.kde.org/) ฺฉ ููุงู ูุงุฆููฺบ ฺฉุง ูุฌููุน  ุฌุณ ูุงฺู ฺฉู ู ุงุณุชุนูุงู ฺฉุฑฺบ ฺฏ ุงุณ ุงฺฉ ุจฺ ูุฑุงูุณุณ ุงูุฑ ุงูฺฏุฑุฒ ูุชูู ฺฉ ูุฌููุน ูพุฑ ูพู ุณ ุชุฑุจุช ุฏ ฺฏุฆ  ุฌู [Opus dataset](https://opus.nlpl.eu/) ุณ ูุง ฺฏุง ุ ุฌุณ ูฺบ ุฏุฑุงุตู KDE4 dataset ุจฺพ ุดุงูู  ูฺฉู ฺุง ูุงุฑุง ุงุณุชุนูุงู ฺฉุฑุฏ pretrained ูุงฺู ุงูพู ุชุฑุจุช ฺฉ ุฏูุฑุงู ุงุณ ฺูนุง ฺฉู ุฏฺฉฺพ ฺฺฉุง ูุ ู ุฏฺฉฺพฺบ ฺฏ ฺฉ fine-tuning ฺฉ ุจุนุฏ ุงุณ ฺฉ ฺฉุงุฑฺฉุฑุฏฺฏ ุจุชุฑ ู ุณฺฉุช 

ุงฺฉ ุฏูุน ู ฺฉุงู ูฺฉูู ฺฉุฑ ูฺบุ ูุงุฑ ูพุงุณ ุงุณุง ูุงฺู ูฺฏุง ุฌู ุงุณ ุทุฑุญ ฺฉ ูพุด ฺฏูุฆุงฺบ ฺฉุฑ ุณฺฉ ฺฏุง:

<iframe src="https://course-demos-marian-finetuned-kde4-en-to-fr.hf.space" frameBorder="0" height="350" title="Gradio app" class="block dark:hidden container p-0 flex-grow space-iframe" allow="accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking" sandbox="allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"></iframe>

<a class="flex justify-center" href="/huggingface-course/marian-finetuned-kde4-en-to-fr">
<img class="block dark:hidden lg:w-3/5" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/modeleval-marian-finetuned-kde4-en-to-fr.png" alt="One-hot encoded labels for question answering."/>
<img class="hidden dark:block lg:w-3/5" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/modeleval-marian-finetuned-kde4-en-to-fr-dark.png" alt="One-hot encoded labels for question answering."/>
</a>

ูพฺฺพู ุณฺฉุดูุฒ ฺฉ ุทุฑุญุ ุขูพ ุงุณ ุงุตู ูุงฺู ฺฉู ุฏฺฉฺพ ุณฺฉุช ฺบ ุฌุณ ู ุชุฑุจุช ุฏฺบ ฺฏ ุงูุฑ Hub ูพุฑ ุงูพููฺ ฺฉุฑฺบ ฺฏุ ูฺ ุฏุง ฺฏุง ฺฉูฺ ุงุณุชุนูุงู ฺฉุฑฺบ ุงูุฑ ุงุณ ฺฉ ูพุด ฺฏูุฆูฺบ ฺฉู [ุงฺบ](https://huggingface.co/huggingface-course/marian-finetuned-kde4-en-to-fr?text=This+plugin+allows+you+to+automatically+translate+web+pages+between+several+languages.) ฺุจู ฺฺฉ ฺฉุฑฺบ

## ฺูนุง ฺฉ ุชุงุฑ[[preparing-the-data]]

ุงฺฉ ุชุฑุฌู ูุงฺู ฺฉู ุดุฑูุน ุณ ุชุฑุจุช ุฏู ุง fine-tune ฺฉุฑู ฺฉ ูุ ูฺบ ุงฺฉ ุงุณุง ฺูนุงุณูน ฺุง ุฌู ุงุณ ฺฉุงู ฺฉ ู ููุฒูฺบ ู ุฌุณุง ฺฉ ูพู ุฐฺฉุฑ ฺฉุง ฺฏุง ุ ุงุณ ุณฺฉุดู ูฺบ ู [KDE4 dataset](https://huggingface.co/datasets/kde4) ุงุณุชุนูุงู ฺฉุฑฺบ ฺฏุ ูฺฉู ุขูพ ุขุณุงู ุณ ุงูพู ฺูนุง ฺฉ ุณุงุชฺพ ฺฉูฺ ฺฉู ุงฺุฌุณูน ฺฉุฑ ุณฺฉุช ฺบุ ุจุดุฑุทฺฉ ุขูพ ฺฉ ูพุงุณ ุงู ุฏู ุฒุจุงููฺบ ูฺบ ุฌูููฺบ ฺฉ ุฌูฺ ููุฌูุฏ ูฺบ ุฌู ุณ ุขูพ ุชุฑุฌู ฺฉุฑูุง ฺุงุช ฺบ ุงฺฏุฑ ุขูพ ฺฉู ุงูพู ฺฉุณูนู ฺูนุง ฺฉู `Dataset` ูฺบ ููฺ ฺฉุฑู ฺฉุง ุทุฑู ุงุฏ ูฺบ ุชู [Chapter 5](/course/chapter5) ููุงุญุธ ฺฉุฑฺบ

### KDE4 ฺูนุงุณูน[[the-kde4-dataset]]

ูุด ฺฉ ุทุฑุญุ ู `load_dataset()` ููฺฉุดู ุงุณุชุนูุงู ฺฉุฑฺฉ ุงูพูุง ฺูนุงุณูน ฺุงุคู ููฺ ฺฉุฑุช ฺบ:

```py
from datasets import load_dataset

raw_datasets = load_dataset("kde4", lang1="en", lang2="fr")
```

ุงฺฏุฑ ุขูพ ฺฉุณ ุงูุฑ ุฒุจุงู ฺฉ ุฌูฺ ฺฉ ุณุงุชฺพ ฺฉุงู ฺฉุฑูุง ฺุงุช ฺบุ ุชู ุขูพ ุงู ฺฉ ฺฉูฺุฒ ฺฉ ุฐุฑุน ูุถุงุญุช ฺฉุฑ ุณฺฉุช ฺบ ุงุณ ฺูนุงุณูน ูฺบ ฺฉู 92 ุฒุจุงูฺบ ุฏุณุชุงุจ ฺบุ ุขูพ ุงู ุณุจ ฺฉู ุงุณ ฺฉ [dataset card](https://huggingface.co/datasets/kde4) ูพุฑ ุฒุจุงู ูนฺฏุฒ ฺฉู ูุณุนุช ุฏ ฺฉุฑ ุฏฺฉฺพ ุณฺฉุช ฺบ

<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/language_tags.png" alt="Language available for the KDE4 dataset." width="100%">

ุขุฆ ฺูนุงุณูน ฺฉู ุฏฺฉฺพุช ฺบ:

```py
raw_datasets
```

```python out
DatasetDict({
    train: Dataset({
        features: ['id', 'translation'],
        num_rows: 210173
    })
})
```

ูุงุฑ ูพุงุณ 210,173 ุฌูููฺบ ฺฉ ุฌูฺ ฺบุ ูฺฉู  ุณุจ ุงฺฉ  ุณูพููน ูฺบ ฺบุ ููฐุฐุง ูฺบ ุงูพูุง validation ุณูน ุจูุงูุง ูฺฏุง ุฌุณุง ฺฉ ู ู [Chapter 5](/course/chapter5) ูฺบ ุฏฺฉฺพุง ฺฉ ุงฺฉ `Dataset` ูฺบ `train_test_split()` ูุชฺพฺ ูุชุง  ุฌู ุงุณ ูฺบ ูุฏุฏ ฺฉุฑ ุณฺฉุชุง  ู reproducibility ฺฉ ู ุงฺฉ seed ูุฑุงู ฺฉุฑฺบ ฺฏ:

```py
split_datasets = raw_datasets["train"].train_test_split(train_size=0.9, seed=20)
split_datasets
```

```python out
DatasetDict({
    train: Dataset({
        features: ['id', 'translation'],
        num_rows: 189155
    })
    test: Dataset({
        features: ['id', 'translation'],
        num_rows: 21018
    })
})
```

ู `"test"` ฺฉูุฏ ฺฉู ุงุณ ุทุฑุญ `"validation"` ูฺบ ุชุจุฏู ฺฉุฑ ุณฺฉุช ฺบ:

```py
split_datasets["validation"] = split_datasets.pop("test")
```

ุงุจ ุขุฆ ฺูนุงุณูน ฺฉ ุงฺฉ ุนูุตุฑ ฺฉู ุฏฺฉฺพุช ฺบ:

```py
split_datasets["train"][1]["translation"]
```

```python out
{'en': 'Default to expanded threads',
 'fr': 'Par dรฉfaut, dรฉvelopper les fils de discussion'}
```

ูฺบ ุงฺฉ ฺฺฉุดูุฑ ููุช  ุฌุณ ูฺบ ุฏู ุฌูู ูุช ฺบ ุฌูฺบ ู ู ูุทููุจ ุฒุจุงู ฺฉ ุฌูฺ ูฺบ ูุงูฺฏุง ุชฺพุง ุงุณ ฺูนุงุณูน ฺฉ ุงฺฉ ุฎุตูุตุช ุฌู ุชฺฉูฺฉ ฺฉููพููนุฑ ุณุงุฆูุณ ฺฉ ุงุตุทูุงุญุงุช ุณ ุจฺพุฑุง ูุง    ฺฉ  ูฺฉูู ุทูุฑ ูพุฑ ูุฑุงูุณุณ ูฺบ ุชุฑุฌู ฺฉุง ฺฏุง  ุชุงูุ ูุฑุงูุณุณ ุงูุฌูุฆุฑุฒ ฺฏูุชฺฏู ูฺบ ุฒุงุฏ ุชุฑ ฺฉููพููนุฑ ุณุงุฆูุณ ูุฎุตูุต ุงููุงุธ ฺฉู ุงูฺฏุฑุฒ ูฺบ  ฺฺพูฺ ุฏุช ฺบ ุงฺบุ ูุซุงู ฺฉ ุทูุฑ ูพุฑุ ููุธ "threads" ุงฺฉ ูุฑุงูุณุณ ุฌูู ูฺบ ุธุงุฑ ู ุณฺฉุชุง ุ ุฎุงุต ุทูุฑ ูพุฑ ุชฺฉูฺฉ ฺฏูุชฺฏู ูฺบุ ูฺฏุฑ ุงุณ ฺูนุงุณูน ูฺบ ุงุณ ุฒุงุฏ ุฏุฑุณุช "fils de discussion" ูฺบ ุชุฑุฌู ฺฉุง ฺฏุง  ูุงุฑุง pretrained ูุงฺูุ ุฌุณ ุฒุงุฏ ุจฺ ูุฑุงูุณุณ ุงูุฑ ุงูฺฏุฑุฒ ุฌูููฺบ ฺฉ ูุฌููุน ูพุฑ ุชุฑุจุช ุฏ ฺฏุฆ ุ ุขุณุงู ุณ ููุธ ฺฉู ุงุณ ุทุฑุญ ฺฺพูฺ ุฏุชุง :

```py
from transformers import pipeline

model_checkpoint = "Helsinki-NLP/opus-mt-en-fr"
translator = pipeline("translation", model=model_checkpoint)
translator("Default to expanded threads")
```

```python out
[{'translation_text': 'Par dรฉfaut pour les threads รฉlargis'}]
```

ุงุณ ุฑู ฺฉ ุงฺฉ ุงูุฑ ูุซุงู ููุธ "plugin" ฺฉ ุณุงุชฺพ ุฏฺฉฺพ ุฌุง ุณฺฉุช ุ ุฌู ุจุงุถุงุจุท ุทูุฑ ูพุฑ ูุฑุงูุณุณ ููุธ ูฺบ  ูฺฉู ุฒุงุฏ ุชุฑ ูุงุฏุฑ ุฒุจุงู ุจููู ูุงู ุงุณ ุณูุฌฺพ ูุช ฺบ ุงูุฑ ุชุฑุฌู ฺฉุฑู ฺฉ ุฒุญูุช ูฺบ ฺฉุฑุช
KDE4 ฺูนุงุณูน ูฺบ ุงุณ ููุธ ฺฉู ูุฑุงูุณุณ ูฺบ ุฒุงุฏ ุจุงูุงุนุฏ "module d'extension" ูฺบ ุชุฑุฌู ฺฉุง ฺฏุง :

```py
split_datasets["train"][172]["translation"]
```

```python
{'en': 'Unable to import %1 using the OFX importer plugin. This file is not the correct format.',
 'fr': "Impossible d'importer %1 en utilisant le module d'extension d'importation OFX. Ce fichier n'a pas un format correct."}
```

ูุงุฑุง pretrained ูุงฺูุ ุชุงูุ ูุฎุชุตุฑ ุงูุฑ ูุงููุณ ุงูฺฏุฑุฒ ููุธ ฺฉ ุณุงุชฺพ ฺูพฺฉุง ุฑุชุง :

```py
translator(
    "Unable to import %1 using the OFX importer plugin. This file is not the correct format."
)
```

```python
[{'translation_text': "Impossible d'importer %1 en utilisant le plugin d'importateur OFX. Ce fichier n'est pas le bon format."}]
```

 ุฏฺฉฺพูุง ุฏูฺุณูพ ูฺฏุง ฺฉ ฺฉุง ูุงุฑุง fine-tuned ูุงฺู ฺูนุงุณูน ฺฉ ุงู ุฎุตูุตุงุช ฺฉู ุงูพูุงุชุง  (ฺฺพููนุง ุณุง ุงุดุงุฑ:  ฺฉุฑ ฺฏุง)

<Youtube id="0Oxphw4Q9fo"/>

<Tip>

โ๏ธ **ุขูพ ฺฉ ุจุงุฑ!** ุงฺฉ ุงูุฑ ุงูฺฏุฑุฒ ููุธ ุฌู ูุฑุงูุณุณ ูฺบ ุงฺฉุซุฑ ุงุณุชุนูุงู ูุชุง  "email." ุชุฑุจุช ฺูนุงุณูน ูฺบ ุงุณ ููุธ ฺฉุง ูพูุง ูููู ุชูุงุด ฺฉุฑฺบ ุงุณ ฺฉุณ ุชุฑุฌู ฺฉุง ฺฏุง ุ ุงูุฑ ู ุงูฺฏุฑุฒ ุฌูู pretrained ูุงฺู ฺฉุณ ุชุฑุฌู ฺฉุฑุชุง ุ

</Tip>

### ฺูนุง ฺฉ ูพุฑูุณุณูฺฏ[[processing-the-data]]

<Youtube id="XAR8jnZZuUs"/>

ุงุจ ุชฺฉ ฺฉ ุชุฑุจุช ุขูพ ฺฉู ูุนููู ู ฺฏุฆ ูฺฏ: ุชูุงู ูุชูู ฺฉู token IDs ฺฉ ูุฌููุนูฺบ ูฺบ ุชุจุฏู ฺฉุฑูุง ุถุฑูุฑ  ุชุงฺฉ ูุงฺู ุงูฺบ ุณูุฌฺพ ุณฺฉ ุงุณ ฺฉุงู ฺฉ ูุ ูฺบ inputs ุงูุฑ targets ุฏูููฺบ ฺฉู tokenize ฺฉุฑูุง ูฺฏุง ูุงุฑุง ูพูุง ฺฉุงู `tokenizer` ุขุจุฌฺฉูน ุชุฎูู ฺฉุฑูุง  ุฌุณุง ฺฉ ูพู ุจุชุงุง ฺฏุง ุชฺพุงุ ู Marian ุงูฺฏุฑุฒ ุณ ูุฑุงูุณุณ pretrained ูุงฺู ุงุณุชุนูุงู ฺฉุฑ ุฑ ฺบ ุงฺฏุฑ ุขูพ  ฺฉูฺ ฺฉุณ ุงูุฑ ุฒุจุงู ฺฉ ุฌูฺ ฺฉ ู ุงุณุชุนูุงู ฺฉุฑ ุฑ ฺบ ุชู ูู ุจูุงุฆฺบ ฺฉ model checkpoint ฺฉู accordingly ุงฺุฌุณูน ฺฉุฑฺบ [Helsinki-NLP](https://huggingface.co/Helsinki-NLP) ุขุฑฺฏูุงุฆุฒุดู ูุชุนุฏุฏ ุฒุจุงููฺบ ูฺบ ุฒุงุฑูฺบ ูุงฺูุฒ ูุฑุงู ฺฉุฑุช 

```python
from transformers import AutoTokenizer

model_checkpoint = "Helsinki-NLP/opus-mt-en-fr"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, return_tensors="pt")
```

ุขูพ `model_checkpoint` ฺฉู [Hub](https://huggingface.co/models) ุณ ฺฉุณ ุงูุฑ ูุงฺู ุง ฺฉุณ ููุงู ูููฺุฑ ุณ ุฌุงฺบ ุขูพ ู pretrained ูุงฺู ุงูุฑ tokenizer ูุญููุธ ฺฉุง ูุ ุณ ุจฺพ ุชุจุฏู ฺฉุฑ ุณฺฉุช ฺบ

<Tip>

๐ก ุงฺฏุฑ ุขูพ mBARTุ mBART-50ุ ุง M2M100 ุฌุณ ฺฉุซุฑ ูุณุงู tokenizer ุงุณุชุนูุงู ฺฉุฑ ุฑ ฺบ ุชู ุขูพ ฺฉู ุงูพู inputs ุงูุฑ targets ฺฉ ุฒุจุงู ฺฉูฺุฒ ฺฉู `tokenizer.src_lang` ุงูุฑ `tokenizer.tgt_lang` ุณูน ฺฉุฑฺฉ ุฏุฑุณุช ุทุฑู ุณ ูุชุนู ฺฉุฑูุง ูฺฏุง

</Tip>

ูุงุฑ ฺูนุง ฺฉ ุชุงุฑ ฺฉุงู ุณุฏฺพ  ุจุณ ุงฺฉ ุจุงุช ุงุฏ ุฑฺฉฺพู ุ ุขูพ ฺฉู  ูู ุจูุงูุง  ฺฉ tokenizer targets ฺฉู ุขุคูน ูพูน ุฒุจุงู (ุงฺบุ ูุฑุงูุณุณ) ูฺบ process ฺฉุฑ ุขูพ  tokenizer ฺฉ `__call__` ูุชฺพฺ ฺฉ `text_target` ุขุฑฺฏููููน ูฺบ targets ุฏ ฺฉุฑ ฺฉุฑ ุณฺฉุช ฺบ

 ุฏฺฉฺพู ฺฉ ู ฺฉ  ฺฉุณ ฺฉุงู ฺฉุฑุชุง ุ ุขุฆ ุชุฑุจุช ุณูน ฺฉ ุฑ ุฒุจุงู ฺฉุง ุงฺฉ ูููู process ฺฉุฑุช ฺบ:

```python
en_sentence = split_datasets["train"][1]["translation"]["en"]
fr_sentence = split_datasets["train"][1]["translation"]["fr"]

inputs = tokenizer(en_sentence, text_target=fr_sentence)
inputs
```

```python out
{'input_ids': [47591, 12, 9842, 19634, 9, 0], 'attention_mask': [1, 1, 1, 1, 1, 1], 'labels': [577, 5891, 2, 3184, 16, 2542, 5, 1710, 0]}
```

ุฌุณุง ฺฉ ุฏฺฉฺพุง ุฌุง ุณฺฉุชุง ุ ุขุคูน ูพูน ูฺบ ุงูฺฏุฑุฒ ุฌูู ุณ ูุงุจุณุช input IDs ุดุงูู ฺบุ ุฌุจฺฉ ูุฑุงูุณุณ ุฌูู ฺฉ IDs `labels` ููฺ ูฺบ ูุญููุธ ฺบ ุงฺฏุฑ ุขูพ  ุจุชุงูุง ุจฺพูู ุฌุงุฆฺบ ฺฉ ุขูพ labels ฺฉู tokenize ฺฉุฑ ุฑ ฺบุ ุชู ู input tokenizer ฺฉ ุฐุฑุน tokenize ู ุฌุงุฆฺบ ฺฏุ ุฌู ฺฉ Marian ูุงฺู ฺฉ ุตูุฑุช ูฺบ ุจุงูฺฉู ุตุญุญ ูฺบ ูฺฏุง:

```python
wrong_targets = tokenizer(fr_sentence)
print(tokenizer.convert_ids_to_tokens(wrong_targets["input_ids"]))
print(tokenizer.convert_ids_to_tokens(inputs["labels"]))
```

```python out
['โPar', 'โdรฉ', 'f', 'aut', ',', 'โdรฉ', 've', 'lop', 'per', 'โles', 'โfil', 's', 'โde', 'โdiscussion', '</s>']
['โPar', 'โdรฉfaut', ',', 'โdรฉvelopper', 'โles', 'โfils', 'โde', 'โdiscussion', '</s>']
```

ุฌุณุง ฺฉ ุฏฺฉฺพุง ุฌุง ุณฺฉุชุง ุ ุงูฺฏุฑุฒ tokenizer ฺฉู ูุฑุงูุณุณ ุฌูู ฺฉู process ฺฉุฑู ุณ ฺฉฺบ ุฒุงุฏ tokens ุจู ุฌุงุช ฺบุ ฺฉููฺฉ tokenizer ฺฉู ูุฑุงูุณุณ ุงููุงุธ ฺฉุง ุนูู ูฺบ ูุชุง (ุณูุงุฆ ุงู ุงููุงุธ ฺฉ ุฌู ุงูฺฏุฑุฒ ูฺบ ุจฺพ ููุฌูุฏ ฺบุ ุฌุณ "discussion")

ฺููฺฉ `inputs` ุงฺฉ ฺฺฉุดูุฑ  ุฌุณ ูฺบ ูุงุฑ ูุนููู ฺฉ keys (input IDsุ attention maskุ ูุบุฑ) ููุฌูุฏ ฺบุ ุขุฎุฑ ูุฏู   ฺฉ ู ฺูนุงุณูนุณ ูพุฑ ูฺฏุงู ฺฉ ู preprocessing function ุชุนุฑู ฺฉุฑฺบ:

```python
max_length = 128


def preprocess_function(examples):
    inputs = [ex["en"] for ex in examples["translation"]]
    targets = [ex["fr"] for ex in examples["translation"]]
    model_inputs = tokenizer(
        inputs, text_target=targets, max_length=max_length, truncation=True
    )
    return model_inputs
```

ูููน ฺฉุฑฺบ ฺฉ ู ู inputs ุงูุฑ outputs ุฏูููฺบ ฺฉ ู ุงฺฉ  ุฒุงุฏ ุณ ุฒุงุฏ ููุจุงุฆ (max_length) ููุฑุฑ ฺฉ  ฺููฺฉ ูุงุฑ ูุชูู ฺฉุงู ฺฺพููน ูุธุฑ ุขุช ฺบุ ู 128 ุงุณุชุนูุงู ฺฉุฑุช ฺบ

<Tip>

๐ก ุงฺฏุฑ ุขูพ T5 ูุงฺู ุงุณุชุนูุงู ฺฉุฑ ุฑ ฺบ (ุฎุงุต ุทูุฑ ูพุฑ `t5-xxx` ฺฺฉ ูพูุงุฆููนุณ ูฺบ ุณ ฺฉูุฆ)ุ ุชู ูุงฺู ุชููุน ฺฉุฑ ฺฏุง ฺฉ text inputs ูฺบ ฺฉุงู ฺฉ ููุนุช ฺฉ ูุดุงูุฏ ฺฉุฑู ูุงูุง prefix ุดุงูู ูุ ุฌุณ ฺฉ `translate: English to French:`

</Tip>

<Tip warning={true}>

โ๏ธ ู targets ฺฉ attention mask ูพุฑ ุชูุฌ ูฺบ ุฏุชุ ฺฉููฺฉ ูุงฺู ฺฉู ุงุณ ฺฉ ุชููุน ูฺบ ูุช ุจูฺฉุ padding token ฺฉ ู labels ฺฉู `-100` ูพุฑ ุณูน ฺฉุฑูุง ฺุง ุชุงฺฉ loss computation ูฺบ ุงู ูพฺูฺฏ ุดุฏ ูุฏุฑูฺบ ฺฉู ูุธุฑุงูุฏุงุฒ ฺฉุง ุฌุง ุณฺฉ  ฺฉุงู ุจุนุฏ ูฺบ ูุงุฑ data collator ฺฉ ุฐุฑุน dynamic padding ูฺฏุงุช ููุช ฺฉุง ุฌุงุฆ ฺฏุงุ ูฺฉู ุงฺฏุฑ ุขูพ ุงฺบ padding ุงุณุชุนูุงู ฺฉุฑุช ฺบ ุชู preprocessing function ฺฉู ุงุณ ุทุฑุญ ุงฺุฌุณูน ฺฉุฑฺบ ฺฉ padding token ฺฉ ู ุชูุงู labels ฺฉู `-100` ูพุฑ ุณูน ฺฉุง ุฌุงุฆ

</Tip>

ุงุจ ู ุงุณ preprocessing ฺฉู ุงฺฉ ุณุงุชฺพ ุงูพู ฺูนุงุณูน ฺฉ ุชูุงู splits ูพุฑ ูุงฺฏู ฺฉุฑ ุณฺฉุช ฺบ:

```py
tokenized_datasets = split_datasets.map(
    preprocess_function,
    batched=True,
    remove_columns=split_datasets["train"].column_names,
)
```

ุงุจ ุฌุจฺฉ ฺูนุง ฺฉู preprocess ฺฉุฑ ูุง ฺฏุง ุ ู ุงูพู pretrained ูุงฺู ฺฉู fine-tune ฺฉุฑู ฺฉ ู ุชุงุฑ ฺบ!

{#if fw === 'pt'}

## `Trainer` API ฺฉ ุณุงุชฺพ ูุงฺู ฺฉ fine-tuning[[fine-tuning-the-model-with-the-trainer-api]]

ุงุตู ฺฉูฺ ุฌู `Trainer` ุงุณุชุนูุงู ฺฉุฑุชุง  ู ูพู ุฌุณุง  ุฑ ฺฏุงุ ุตุฑู ุงฺฉ ฺฺพููนุง ุณุง ูุฑู   ฺฉ ุงฺบ ู [`Seq2SeqTrainer`](https://huggingface.co/transformers/main_classes/trainer.html#seq2seqtrainer) ุงุณุชุนูุงู ฺฉุฑุช ฺบุ ุฌู `Trainer` ฺฉ ุงฺฉ ุฐู ฺฉูุงุณ  ุงูุฑ ูฺบ evaluation ฺฉ ุฏูุฑุงู inputs ุณ outputs ฺฉ ูพุด ฺฏูุฆ ฺฉ ู `generate()` ูุชฺพฺ ุงุณุชุนูุงู ฺฉุฑู ฺฉ ุณููุช ุฏุช  ู ุงุณ ูพุฑ ูุฒุฏ ุชูุตู ุณ ุชุจ ุจุงุช ฺฉุฑฺบ ฺฏ ุฌุจ ู metric computation ฺฉ ุจุงุช ฺฉุฑฺบ ฺฏ

ุณุจ ุณ ูพูุ ูฺบ fine-tune ฺฉุฑู ฺฉ ู ุงฺฉ ุงุตู ูุงฺู ฺฉ ุถุฑูุฑุช  ู ูุนููู ฺฉุง `AutoModel` API ุงุณุชุนูุงู ฺฉุฑฺบ ฺฏ:

```py
from transformers import AutoModelForSeq2SeqLM

model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)
```

{:else}

## Keras ฺฉ ุณุงุชฺพ ูุงฺู ฺฉ fine-tuning[[fine-tuning-the-model-with-keras]]

ุณุจ ุณ ูพูุ ูฺบ fine-tune ฺฉุฑู ฺฉ ู ุงฺฉ ุงุตู ูุงฺู ฺฉ ุถุฑูุฑุช  ู ูุนููู ฺฉุง `AutoModel` API ุงุณุชุนูุงู ฺฉุฑฺบ ฺฏ:

```py
from transformers import TFAutoModelForSeq2SeqLM

model = TFAutoModelForSeq2SeqLM.from_pretrained(model_checkpoint, from_pt=True)
```

<Tip warning={false}>

๐ก `Helsinki-NLP/opus-mt-en-fr` ฺฺฉ ูพูุงุฆููน ูฺบ ุตุฑู PyTorch weights ููุฌูุฏ ฺบุ ููฐุฐุง ุงฺฏุฑ ุขูพ `from_pretrained()` ูุชฺพฺ ูฺบ `from_pt=True` ุขุฑฺฏููููน ุงุณุชุนูุงู ฺฉ ุจุบุฑ ูุงฺู ููฺ ฺฉุฑู ฺฉ ฺฉูุดุด ฺฉุฑฺบ ฺฏ ุชู ุงุฑุฑ ุขุฆ ฺฏุง ุฌุจ ุขูพ `from_pt=True` ุงุณุชุนูุงู ฺฉุฑุช ฺบุ ุชู ูุงุฆุจุฑุฑ ุฎูุฏ ุจุฎูุฏ PyTorch weights ฺฉู ฺุงุคู ููฺ ุงูุฑ convert ฺฉุฑ ุฏ ฺฏ ุฌุณุง ฺฉ ุขูพ ุฏฺฉฺพ ุณฺฉุช ฺบุ ๐ค Transformers ูฺบ frameworks ฺฉ ุฏุฑูุงู ุณูุฆฺ ฺฉุฑูุง ุจุช ุขุณุงู !

</Tip>

{/if}

ูููน ฺฉุฑฺบ ฺฉ ุงุณ ุจุงุฑ ู ุงุณ ูุงฺู ฺฉู ุงุณุชุนูุงู ฺฉุฑ ุฑ ฺบ ุฌุณ ุชุฑุฌู ฺฉ ฺฉุงู ูพุฑ ุชุฑุจุช ุฏ ฺฏุฆ  ุงูุฑ ุงุณ ุฏุฑุงุตู ุงุณุชุนูุงู ฺฉุง ุฌุง ุณฺฉุชุง ุ ููฐุฐุง weights ฺฉ ฺฏู ูู ุง ูุฆ initialize ูู ฺฉ ุจุงุฑ ูฺบ ฺฉูุฆ ูุงุฑููฺฏ ูฺบ ุขุฆ ฺฏ

### ฺูนุง ฺฉููุฆุดู[[data-collation]]

ูฺบ dynamic batching ฺฉ ู padding ุณ ูููนู ฺฉ ู data collator ฺฉ ุถุฑูุฑุช ูฺฏ ู [Chapter 3](/course/chapter3) ฺฉ ุทุฑุญ ุตุฑู inputs (input IDsุ attention maskุ ุงูุฑ token type IDs) ฺฉู pad ฺฉุฑู ูุงูุง `DataCollatorWithPadding` ุงุณุชุนูุงู ูฺบ ฺฉุฑ ุณฺฉุช ูุงุฑ labels ฺฉู ุจฺพ ุงู ฺฉ ุฒุงุฏ ุณ ุฒุงุฏ ููุจุงุฆ ุชฺฉ pad ฺฉุง ุฌุงูุง ฺุง ุงูุฑุ ุฌุณุง ฺฉ ูพู ุฐฺฉุฑ ฺฉุง ฺฏุงุ labels ฺฉู pad ฺฉุฑู ฺฉ ู ุงุณุชุนูุงู ูู ูุงู padding value tokenizer ฺฉ padding token ฺฉ ุจุฌุงุฆ `-100` ูู ฺุงุ ุชุงฺฉ loss computation ูฺบ ุงู padded ูุฏุฑูฺบ ฺฉู ูุธุฑุงูุฏุงุฒ ฺฉุง ุฌุง ุณฺฉ

 ุณุจ ุงฺฉ [`DataCollatorForSeq2Seq`](https://huggingface.co/transformers/main_classes/data_collator.html#datacollatorforseq2seq) ฺฉ ุฐุฑุน ฺฉุง ุฌุงุชุง  `DataCollatorWithPadding` ฺฉ ุทุฑุญุ  ุจฺพ ุงู ูพูนุณ ฺฉู preprocess ฺฉุฑู ฺฉ ู ุงุณุชุนูุงู ูู ูุงู `tokenizer` ฺฉู ูุชุง ุ ูฺฉู  `model` ฺฉู ุจฺพ ูุชุง  ุงุณุง ุงุณ ู  ฺฉ  data collator decoder input IDs ุชุงุฑ ฺฉุฑู ฺฉุง ุจฺพ ุฐู ุฏุงุฑ ูฺฏุงุ ุฌู labels ฺฉ shifted ูุฑฺูุฒ ูุช ฺบ ุฌู ฺฉ ุดุฑูุน ูฺบ ุงฺฉ ุฎุงุต token ูุชุง  ฺููฺฉ  shift ูุฎุชูู architectures ฺฉ ู ุชฺพูฺุง ูุฎุชูู ูุชุง ุ ุงุณ ู `DataCollatorForSeq2Seq` ฺฉู `model` ุขุจุฌฺฉูน ฺฉุง ุนูู ููุง ุถุฑูุฑ :

{#if fw === 'pt'}

```py
from transformers import DataCollatorForSeq2Seq

data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)
```

{:else}

```py
from transformers import DataCollatorForSeq2Seq

data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors="tf")
```

{/if}

ฺฉฺฺพ ูููููฺบ ูพุฑ ุงุณ ุขุฒูุงู ฺฉ ูุ ู ุงุณ ุงูพู tokenized ุชุฑุจุช ุณูน ฺฉ ฺูุฏ examples ฺฉ ุงฺฉ ูุฑุณุช ูพุฑ ฺฉุงู ฺฉุฑุช ฺบ:

```py
batch = data_collator([tokenized_datasets["train"][i] for i in range(1, 3)])
batch.keys()
```

```python out
dict_keys(['attention_mask', 'input_ids', 'labels', 'decoder_input_ids'])
```

ู  ุฌุงูฺ ุณฺฉุช ฺบ ฺฉ ูุงุฑ labels ฺฉู ุจฺ ฺฉ ุฒุงุฏ ุณ ุฒุงุฏ ููุจุงุฆ ุชฺฉ pad ฺฉุง ฺฏุง ุ ุงูุฑ padding value `-100` ุงุณุชุนูุงู ฺฉ ฺฏุฆ :

```py
batch["labels"]
```

```python out
tensor([[  577,  5891,     2,  3184,    16,  2542,     5,  1710,     0,  -100,
          -100,  -100,  -100,  -100,  -100,  -100],
        [ 1211,     3,    49,  9409,  1211,     3, 29140,   817,  3124,   817,
           550,  7032,  5821,  7907, 12649,     0]])
```

ุงูุฑ ู decoder input IDs ฺฉู ุจฺพ ุฏฺฉฺพ ุณฺฉุช ฺบุ ุชุงฺฉ  ูุนููู ู ุณฺฉ ฺฉ ู labels ฺฉ shifted ูุฑฺู ฺบ:

```py
batch["decoder_input_ids"]
```

```python out
tensor([[59513,   577,  5891,     2,  3184,    16,  2542,     5,  1710,     0,
         59513, 59513, 59513, 59513, 59513, 59513],
        [59513,  1211,     3,    49,  9409,  1211,     3, 29140,   817,  3124,
           817,   550,  7032,  5821,  7907, 12649]])
```

ุงฺบ ูุงุฑ ฺูนุงุณูน ฺฉ ูพู ุงูุฑ ุฏูุณุฑ ุนูุงุตุฑ ฺฉ labels ฺบ:

```py
for i in range(1, 3):
    print(tokenized_datasets["train"][i]["labels"])
```

```python out
[577, 5891, 2, 3184, 16, 2542, 5, 1710, 0]
[1211, 3, 49, 9409, 1211, 3, 29140, 817, 3124, 817, 550, 7032, 5821, 7907, 12649, 0]
```

{#if fw === 'pt'}

ู ุงุณ `data_collator` ฺฉู `Seq2SeqTrainer` ฺฉู ูพุงุณ ฺฉุฑฺบ ฺฏ ุงุจุ ุขุฆฺบ metric ูพุฑ ูุธุฑ ฺุงูุช ฺบ

{:else}

ู ุงุจ ุงุณ `data_collator` ฺฉู ุงุณุชุนูุงู ฺฉุฑุช ูุฆ ุงูพู ุฑ ฺูนุงุณูน ฺฉู ุงฺฉ `tf.data.Dataset` ูฺบ ุชุจุฏู ฺฉุฑ ุณฺฉุช ฺบุ ุฌู ุชุฑุจุช ฺฉ ู ุชุงุฑ :

```python
tf_train_dataset = model.prepare_tf_dataset(
    tokenized_datasets["train"],
    collate_fn=data_collator,
    shuffle=True,
    batch_size=32,
)
tf_eval_dataset = model.prepare_tf_dataset(
    tokenized_datasets["validation"],
    collate_fn=data_collator,
    shuffle=False,
    batch_size=16,
)
```

{/if}


### ููนุฑฺฉุณ[[metrics]]

<Youtube id="M05L1DhFqcw"/>

{#if fw === 'pt'}

ู ุฎุตูุตุช ุฌู `Seq2SeqTrainer` ุงูพู ุณูพุฑ ฺฉูุงุณ `Trainer` ูฺบ ุดุงูู ฺฉุฑุชุง  ู   ฺฉ evaluation ุง prediction ฺฉ ุฏูุฑุงู `generate()` ูุชฺพฺ ุงุณุชุนูุงู ฺฉ ุฌุง ุณฺฉุช  ุชุฑุจุช ฺฉ ุฏูุฑุงูุ ูุงฺู `decoder_input_ids` ุงุณุชุนูุงู ฺฉุฑุชุง  ุงูุฑ ุงฺฉ attention mask ูฺฏุง ฺฉุฑ  ูู ุจูุงุชุง  ฺฉ ู ุงุณ token ฺฉ ุจุนุฏ ูุงู tokens ฺฉุง ุงุณุชุนูุงู ู ฺฉุฑ ุฌุณ ฺฉ ู ูพุด ฺฏูุฆ ฺฉุฑ ุฑุง ุ ุชุงฺฉ ุชุฑุจุช ุชุฒ ู ุณฺฉ inference ฺฉ ุฏูุฑุงู ฺููฺฉ ูุงุฑ ูพุงุณ labels ูฺบ ูฺบ ฺฏุ ุงุณ ู ุจุชุฑ  ฺฉ ู ุงูพู ูุงฺู ฺฉ evaluation ุงุณ ุชุฑุชุจ ฺฉ ุณุงุชฺพ ฺฉุฑฺบ

ุฌุณุง ฺฉ ู ู [Chapter 1](/course/chapter1/6) ูฺบ ุฏฺฉฺพุงุ decoder inference ุงุณ ุทุฑุญ ฺฉุฑุชุง  ฺฉ ุงฺฉ ุงฺฉ token ฺฉ ูพุด ฺฏูุฆ ฺฉุฑุชุง  โ ุฌู ฺฉ ๐ค Transformers ูฺบ `generate()` ูุชฺพฺ ฺฉ ุฐุฑุน ูพุณ ูพุฑุฏ ุนูู ูฺบ ูุงุง ุฌุงุชุง  ุงฺฏุฑ ู `predict_with_generate=True` ุณูน ฺฉุฑฺบ ุชู `Seq2SeqTrainer` ูฺบ evaluation ฺฉ ู ุงุณ ูุชฺพฺ ฺฉุง ุงุณุชุนูุงู ฺฉุฑู ุฏ ฺฏุง

{/if}

ุชุฑุฌู ฺฉ ู ุฑูุงุช metric [BLEU score](https://en.wikipedia.org/wiki/BLEU) ุ ุฌุณ Kishore Papineni ูุบุฑ ู [2002 ฺฉ ุงฺฉ ูุถููู](https://aclanthology.org/P02-1040.pdf) ูฺบ ูุชุนุงุฑู ฺฉุฑุงุง ุชฺพุง BLEU score ุงุณ ุจุงุช ฺฉุง ุงูุฏุงุฒ ูฺฏุงุชุง  ฺฉ ุชุฑุฌู labels ฺฉ ฺฉุชู ูุฑุจ ฺบ  ูุงฺู ฺฉ ุชุงุฑ ฺฉุฑุฏ outputs ฺฉ ุณูุฌฺพ ุจูุฌฺพ ุง ฺฏุฑุงูุฑ ฺฉ ุฏุฑุณุชฺฏ ฺฉู ูฺบ ุชููุชุงุ ุจูฺฉ ุดูุงุฑุงุช ุงุตูููฺบ ฺฉุง ุงุณุชุนูุงู ฺฉุฑุชุง  ุชุงฺฉ  ูู ุจูุงุง ุฌุง ุณฺฉ ฺฉ generated outputs ฺฉ ุชูุงู ุงููุงุธ targets ูฺบ ุจฺพ ุดุงูู ูฺบ ูุฒุฏ ุจุฑุขฺบุ ุงุณ ุงุตูู ุจฺพ ฺบ ุฌู ุงฺฉ  ููุธ ฺฉ ุจุงุฑ ุจุงุฑ ุฏุฑุงู ูพุฑ ุณุฒุง ุฏุช ฺบ ุงฺฏุฑ ู targets ูฺบ ุจฺพ ุฏุฑุงุง ู ฺฏุง ู (ุชุงฺฉ ูุงฺู "the the the the the" ุฌุณ ุฌูู ู ุจูุงุฆ) ุงูุฑ ุงุณ ุฌูู ุฌู ฺฉ ููุจุงุฆ targets ุณ ฺฉู ู (ุชุงฺฉ ูุงฺู "the" ุฌุณ ูุฎุชุตุฑ ุฌูู ู ุจูุงุฆ)

BLEU ฺฉุง ุงฺฉ ูุณุฆู   ฺฉ  ุชููุน ฺฉุฑุชุง  ฺฉ ูุชู ูพู ุณ tokenize ฺฉุง ุฌุง ฺฺฉุง ูุ ุฌุณ ุณ ูุฎุชูู tokenizers ุงุณุชุนูุงู ฺฉุฑู ูุงู ูุงฺูุฒ ฺฉ scores ฺฉุง ููุงุฒู ฺฉุฑูุง ูุดฺฉู ู ุฌุงุชุง  ููฐุฐุงุ ุขุฌ ฺฉู ุชุฑุฌู ูุงฺูุฒ ฺฉ benchmarking ฺฉ ู ุณุจ ุณ ุฒุงุฏ ุงุณุชุนูุงู ูู ูุงูุง metric [SacreBLEU](https://github.com/mjpost/sacrebleu) ุ ุฌู ุงุณ ุฎุงู (ุงูุฑ ุฏฺฏุฑ) ฺฉู ุฏูุฑ ฺฉุฑุชุง  ุงูุฑ tokenization ฺฉ ูุฑุญู ฺฉู standardize ฺฉุฑุชุง  ุงุณ metric ฺฉู ุงุณุชุนูุงู ฺฉุฑู ฺฉ ูุ ูฺบ ุณุจ ุณ ูพู SacreBLEU ูุงุฆุจุฑุฑ ุงูุณูนุงู ฺฉุฑู ูฺฏ:

```py
!pip install sacrebleu
```

ูพฺพุฑ ู ุงุณ [Chapter 3](/course/chapter3) ฺฉ ุทุฑุญ `evaluate.load()` ฺฉ ุฐุฑุน ููฺ ฺฉุฑุช ฺบ:

```py
import evaluate

metric = evaluate.load("sacrebleu")
```

 metric texts ฺฉู inputs ุงูุฑ targets ฺฉ ุทูุฑ ูพุฑ ูุชุง  ุงุณ ูุชุนุฏุฏ ูุงุจู ูุจูู targets ูุจูู ฺฉุฑู ฺฉ ู ฺุฒุงุฆู ฺฉุง ฺฏุง ุ ฺฉููฺฉ ุงฺฉ  ุฌูู ฺฉ ูุชุนุฏุฏ ูุงุจู ูุจูู ุชุฑุงุฌู ุงฺฉุซุฑ ููุช ฺบ โ ูุงุฑุง ฺูนุงุณูน ุตุฑู ุงฺฉ ูุฑุงู ฺฉุฑุชุง ุ ูฺฉู NLP ูฺบ ุงุณุง ุบุฑ ูุนููู ูฺบ ฺฉ ฺูนุงุณูนุณ ูุชุนุฏุฏ ุฌูู labels ฺฉ ุทูุฑ ูพุฑ ุฏฺบ ููฐุฐุงุ predictions ฺฉู ุฌูููฺบ ฺฉ ูุฑุณุช ูู ฺุงุ ุฌุจฺฉ references ฺฉู ุฌูููฺบ ฺฉ ูุฑุณุช ฺฉ ูุฑุณุช ูู ฺุง

ุขุฆฺบ ุงฺฉ ูุซุงู ุขุฒูุงุช ฺบ:

```py
predictions = [
    "This plugin lets you translate web pages between several languages automatically."
]
references = [
    [
        "This plugin allows you to automatically translate web pages between several languages."
    ]
]
metric.compute(predictions=predictions, references=references)
```

```python out
{'score': 46.750469682990165,
 'counts': [11, 6, 4, 3],
 'totals': [12, 11, 10, 9],
 'precisions': [91.67, 54.54, 40.0, 33.33],
 'bp': 0.9200444146293233,
 'sys_len': 12,
 'ref_len': 13}
```

ุงุณ ุณ BLEU score 46.75 ุญุงุตู ูุชุง ุ ุฌู ฺฉ ฺฉุงู ุงฺฺพุง  โ ุญูุงู ฺฉ ูุ "Attention Is All You Need" ูพูพุฑ ูฺบ ูพุด ฺฉุฑุฏ ุงุตู Transformer ูุงฺู ู ุงูฺฏุฑุฒ ุณ ูุฑุงูุณุณ ุชุฑุฌู ฺฉ ุงฺฉ ูุดุงุจ ูนุงุณฺฉ ูพุฑ 41.8 ฺฉุง BLEU score ุญุงุตู ฺฉุง ุชฺพุง! (ูุฒุฏ ูุนูููุงุช ฺฉ ู ุฌุณ ฺฉ `counts` ุงูุฑ `bp` ฺฉ ุจุงุฑ ูฺบุ [SacreBLEU repository](https://github.com/mjpost/sacrebleu/blob/078c440168c6adc89ba75fe6d63f0d922d42bcfe/sacrebleu/metrics/bleu.py#L74) ุฏฺฉฺพฺบ.) ุฏูุณุฑ ุทุฑูุ ุงฺฏุฑ ู ุชุฑุฌู ูุงฺูุฒ ฺฉ ุนูููุงู ูพุฏุง ูู ูุงู ุฏู ุฎุฑุงุจ prediction types (ุฒุงุฏ ุชฺฉุฑุงุฑ ุง ุจุช ูุฎุชุตุฑ) ุขุฒูุงุฆฺบ ุชู ูฺบ ฺฉุงู ุจุฑ BLEU scores ููฺบ ฺฏ:

```py
predictions = ["This This This This"]
references = [
    [
        "This plugin allows you to automatically translate web pages between several languages."
    ]
]
metric.compute(predictions=predictions, references=references)
```

```python out
{'score': 1.683602693167689,
 'counts': [1, 0, 0, 0],
 'totals': [4, 3, 2, 1],
 'precisions': [25.0, 16.67, 12.5, 12.5],
 'bp': 0.10539922456186433,
 'sys_len': 4,
 'ref_len': 13}
```

```py
predictions = ["This plugin"]
references = [
    [
        "This plugin allows you to automatically translate web pages between several languages."
    ]
]
metric.compute(predictions=predictions, references=references)
```

```python out
{'score': 0.0,
 'counts': [2, 1, 0, 0],
 'totals': [2, 1, 0, 0],
 'precisions': [100.0, 100.0, 0.0, 0.0],
 'bp': 0.004086771438464067,
 'sys_len': 2,
 'ref_len': 13}
```

ุงุณฺฉูุฑ 0 ุณ 100 ุชฺฉ ุฌุง ุณฺฉุชุง ุ ุงูุฑ ุฌุชูุง ุฒุงุฏ ูฺฏุงุ ุงุชูุง ุจุชุฑ

{#if fw === 'tf'}

ูุงฺู ฺฉ outputs ฺฉู ุงุณ ูุชูู ูฺบ ุชุจุฏู ฺฉุฑู ฺฉ ู ุฌูฺบ metric ุงุณุชุนูุงู ฺฉุฑ ุณฺฉุ ู `tokenizer.batch_decode()` ูุชฺพฺ ุงุณุชุนูุงู ฺฉุฑฺบ ฺฏ ูฺบ ุตุฑู labels ูฺบ ููุฌูุฏ ุชูุงู `-100` ฺฉู ุตุงู ฺฉุฑูุง ุ tokenizer padding token ฺฉ ู ุจฺพ ุฎูุฏฺฉุงุฑ ุทุฑู ุณ  ฺฉุฑ ฺฏุง ุขุฆ ุงฺฉ ุงุณุง ููฺฉุดู ุชุนุฑู ฺฉุฑุช ฺบ ุฌู ูุงุฑ ูุงฺู ุงูุฑ ฺูนุงุณูน ฺฉู ู ฺฉุฑ ุงู ูพุฑ ููนุฑฺฉุณ ฺฉุง ุญุณุงุจ ูฺฏุงุฆ ู ุงฺฉ ุงุณุง ุทุฑู ุจฺพ ุงุณุชุนูุงู ฺฉุฑู ุฌุง ุฑ ฺบ ุฌู ฺฉุงุฑฺฉุฑุฏฺฏ ูฺบ ููุงุงฺบ ุงุถุงู ฺฉุฑุชุง  - ุนู [XLA](https://www.tensorflow.org/xla) ฺฉ ุณุงุชฺพ ูุงุฑ generation ฺฉูฺ ฺฉู compile ฺฉุฑูุงุ ุฌู ฺฉ TensorFlow ฺฉุง accelerated linear algebra compiler  XLA ูุงฺู ฺฉ computation graph ูพุฑ ูุฎุชูู optimizations ูฺฏุงุชุง ุ ุฌุณ ุณ ุฑูุชุงุฑ ุงูุฑ memory ฺฉ ุงุณุชุนูุงู ูฺบ ุจุชุฑ ุขุช  ุฌุณุง ฺฉ Hugging Face ฺฉ [blog](https://huggingface.co/blog/tf-xla-generate) ูฺบ ุจุงู ฺฉุง ฺฏุง ุ XLA ุชุจ ุจุชุฑู ฺฉุงู ฺฉุฑุชุง  ุฌุจ ูุงุฑ input shapes ุจุช ุฒุงุฏ ูุฎุชูู ู ูฺบ ุงุณ ูุณุฆู ุณ ูููนู ฺฉ ูุ ู ุงูพู inputs ฺฉู 128 ฺฉ multiples ุชฺฉ pad ฺฉุฑฺบ ฺฏุ padding collator ฺฉ ุณุงุชฺพ ุงฺฉ ูุง ฺูนุงุณูน ุจูุงุฆฺบ ฺฏุ ุงูุฑ ูพฺพุฑ ุงูพู generation function ูพุฑ `@tf.function(jit_compile=True)` decorator ูฺฏุงุฆฺบ ฺฏุ ุฌุณ ุณ ูพูุฑ ููฺฉุดู ฺฉู XLA ฺฉ ุณุงุชฺพ compile ฺฉุฑู ฺฉ ู ูุดุงู ุฒุฏ ฺฉุง ุฌุงุฆ ฺฏุง

```py
import numpy as np
import tensorflow as tf
from tqdm import tqdm

generation_data_collator = DataCollatorForSeq2Seq(
    tokenizer, model=model, return_tensors="tf", pad_to_multiple_of=128
)

tf_generate_dataset = model.prepare_tf_dataset(
    tokenized_datasets["validation"],
    collate_fn=generation_data_collator,
    shuffle=False,
    batch_size=8,
)


@tf.function(jit_compile=True)
def generate_with_xla(batch):
    return model.generate(
        input_ids=batch["input_ids"],
        attention_mask=batch["attention_mask"],
        max_new_tokens=128,
    )


def compute_metrics():
    all_preds = []
    all_labels = []

    for batch, labels in tqdm(tf_generate_dataset):
        predictions = generate_with_xla(batch)
        decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)
        labels = labels.numpy()
        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)
        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)
        decoded_preds = [pred.strip() for pred in decoded_preds]
        decoded_labels = [[label.strip()] for label in decoded_labels]
        all_preds.extend(decoded_preds)
        all_labels.extend(decoded_labels)

    result = metric.compute(predictions=all_preds, references=all_labels)
    return {"bleu": result["score"]}
```

{:else}

ูุงฺู ฺฉ outputs ฺฉู ุงุณ ูุชูู ูฺบ ุชุจุฏู ฺฉุฑู ฺฉ ู ุฌูฺบ metric ุงุณุชุนูุงู ฺฉุฑ ุณฺฉุ ู `tokenizer.batch_decode()` ูุชฺพฺ ุงุณุชุนูุงู ฺฉุฑฺบ ฺฏ ูฺบ ุตุฑู labels ูฺบ ููุฌูุฏ ุชูุงู `-100` ฺฉู ุตุงู ฺฉุฑูุง  (tokenizer padding token ฺฉ ู ุจฺพ ุฎูุฏ ุจุฎูุฏ  ฺฉุฑ ฺฏุง):

```py
import numpy as np


def compute_metrics(eval_preds):
    preds, labels = eval_preds
    # ุงฺฏุฑ ูุงฺู prediction logits ุณ ุฒุงุฏ ฺฉฺฺพ ูููนุงุฆ ุชู
    if isinstance(preds, tuple):
        preds = preds[0]

    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)

    # -100 ฺฉู labels ูฺบ ุชุจุฏู ฺฉุฑฺบ ฺฉููฺฉ ู ุงูฺบ decode ูฺบ ฺฉุฑ ุณฺฉุช
    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)
    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)

    # ฺฉฺฺพ ุณุงุฏ post-processing
    decoded_preds = [pred.strip() for pred in decoded_preds]
    decoded_labels = [[label.strip()] for label in decoded_labels]

    result = metric.compute(predictions=decoded_preds, references=decoded_labels)
    return {"bleu": result["score"]}
```

{/if}

ุงุจ ุฌุจฺฉ  ุณุจ ูฺฉูู ู ฺฺฉุง ุ ู ุงูพู ูุงฺู ฺฉู fine-tune ฺฉุฑู ฺฉ ู ุชุงุฑ ฺบ!

### ูุงฺู ฺฉ fine-tuning[[fine-tuning-the-model]]

ูุงฺู fine-tune ฺฉุฑู ฺฉุง ูพูุง ูุฏู Hugging Face ูฺบ ูุงฺฏ ุงู ููุง ุ ุชุงฺฉ ุขูพ ุงูพู ูุชุงุฆุฌ Model Hub ูพุฑ ุงูพ ููฺ ฺฉุฑ ุณฺฉฺบ ูููน ุจฺฉ ูฺบ ุงฺฉ ุขุณุงู ููฺฉุดู ุฏุณุชุงุจ  ุฌู ุงุณ ฺฉุงู ูฺบ ุขูพ ฺฉ ูุฏุฏ ฺฉุฑุชุง :

```python
from huggingface_hub import notebook_login

notebook_login()
```

 ุงฺฉ widget ุธุงุฑ ฺฉุฑ ฺฏุง ุฌุงฺบ ุขูพ ุงูพู Hugging Face ูุงฺฏ ุงู ฺฉุฑฺูุดูุฒ ุฏุงุฎู ฺฉุฑ ุณฺฉุช ฺบ

ุงฺฏุฑ ุขูพ ูููน ุจฺฉ ูฺบ ฺฉุงู ูฺบ ฺฉุฑ ุฑุ ุชู ุงูพู ูนุฑููู ูฺบ ุตุฑู  ูุงุฆู ูนุงุฆูพ ฺฉุฑฺบ:

```bash
huggingface-cli login
```

{#if fw === 'tf'}

ุดุฑูุน ฺฉุฑู ุณ ูพูุ ุขุฆ ุฏฺฉฺพุช ฺบ ฺฉ ุจุบุฑ ฺฉุณ ุชุฑุจุช ฺฉ ูุงุฑ ูุงฺู ุณ ฺฉุณ ูุณู ฺฉ ูุชุงุฆุฌ ุญุงุตู ูุช ฺบ:

```py
print(compute_metrics())
```

```
{'bleu': 33.26983701454733}
```

ุฌุจ  ู ุฌุงุฆุ ุชู ู ู ุณุจ ฺฉฺฺพ ุชุงุฑ ฺฉุฑ ูุช ฺบ ุฌู ูุงฺู ฺฉู compile ุงูุฑ train ฺฉุฑู ฺฉ ู ุฏุฑฺฉุงุฑ  ูููน ฺฉุฑฺบ ฺฉ ุงฺบ `tf.keras.mixed_precision.set_global_policy("mixed_float16")` ุงุณุชุนูุงู ฺฉุง ฺฏุง  โ  Keras ฺฉู ุจุชุงุฆ ฺฏุง ฺฉ ู float16 ฺฉุง ุงุณุชุนูุงู ฺฉุฑุช ูุฆ ุชุฑุจุช ฺฉุฑุ ุฌู ุงุณ GPUs (Nvidia 20xx/V100 ุง ุงุณ ุณ ุฌุฏุฏ) ูพุฑ ููุงุงฺบ ุฑูุชุงุฑ ูฺบ ุงุถุงู ฺฉุฑ ุณฺฉุชุง 

```python
from transformers import create_optimizer
from transformers.keras_callbacks import PushToHubCallback
import tensorflow as tf

# ุชุฑุจุช ูุฑุงุญู ฺฉ ุชุนุฏุงุฏ ฺูนุงุณูน ูฺบ ููุฌูุฏ samples ฺฉ ุชุนุฏุงุฏุ batch size ุณ ุชูุณู ฺฉุฑ ฺฉุ ูพฺพุฑ epochs ฺฉ ุชุนุฏุงุฏ ุณ ุถุฑุจ ุฏ ุฌุงุช 
# ูููน ฺฉุฑฺบ ฺฉ tf_train_dataset ุงฺบ ุงฺฉ batched tf.data.Dataset ุ ู ฺฉ ุงุตู Hugging Face Datasetุ ููฐุฐุง ุงุณ ฺฉ len() ูพู  num_samples // batch_size ฺฉ ุจุฑุงุจุฑ 
num_epochs = 3
num_train_steps = len(tf_train_dataset) * num_epochs

optimizer, schedule = create_optimizer(
    init_lr=5e-5,
    num_warmup_steps=0,
    num_train_steps=num_train_steps,
    weight_decay_rate=0.01,
)
model.compile(optimizer=optimizer)

# mixed-precision float16 ูฺบ ุชุฑุจุช ฺฉุฑฺบ
tf.keras.mixed_precision.set_global_policy("mixed_float16")
```

ุงุณ ฺฉ ุจุนุฏุ ู `PushToHubCallback` ุชุนุฑู ฺฉุฑุช ฺบ ุชุงฺฉ ุชุฑุจุช ฺฉ ุฏูุฑุงู ูุงุฑุง ูุงฺู Hub ูพุฑ ุงูพ ููฺ ู ุฌุงุฆุ ุฌุณุง ฺฉ ู ู [section 2](/course/chapter7/2) ูฺบ ุฏฺฉฺพุง ุชฺพุงุ ุงูุฑ ูพฺพุฑ ุงุณ callback ฺฉ ุณุงุชฺพ ูุงฺู ฺฉู fit ฺฉุฑ ุฏุช ฺบ:

```python
from transformers.keras_callbacks import PushToHubCallback

callback = PushToHubCallback(
    output_dir="marian-finetuned-kde4-en-to-fr", tokenizer=tokenizer
)

model.fit(
    tf_train_dataset,
    validation_data=tf_eval_dataset,
    callbacks=[callback],
    epochs=num_epochs,
)
```

ูููน ฺฉุฑฺบ ฺฉ ุขูพ `hub_model_id` ุขุฑฺฏููููน ฺฉ ุฐุฑุน repository ฺฉุง ูุงู ูุฎุตูุต ฺฉุฑ ุณฺฉุช ฺบ (ุฎุงุต ุทูุฑ ูพุฑุ ุงฺฏุฑ ุขูพ ฺฉุณ organization ูฺบ push ฺฉุฑ ุฑ ฺบ ุชู ุขูพ ฺฉู  ุขุฑฺฏููููน ุงุณุชุนูุงู ฺฉุฑูุง ูฺฏุง) ูุซุงู ฺฉ ุทูุฑ ูพุฑุ ุฌุจ ู ู ูุงฺู ฺฉู [`huggingface-course` organization](https://huggingface.co/huggingface-course) ูพุฑ push ฺฉุงุ ุชู ู ู `hub_model_id="huggingface-course/marian-finetuned-kde4-en-to-fr"` `Seq2SeqTrainingArguments` ูฺบ ุดุงูู ฺฉุง ุจุฐุฑุน ฺูุงููนุ ุงุณุชุนูุงู ุดุฏ repository ุขูพ ฺฉ namespace ูฺบ ูฺฏ ุงูุฑ output directory ฺฉ ูุงู ูพุฑ ูุจู ูฺฏุ ููฐุฐุง ุงฺบ  `"sgugger/marian-finetuned-kde4-en-to-fr"` ูฺฏ (ุฌู ฺฉ ูุงฺู ู ู ุงุณ ุณฺฉุดู ฺฉ ุดุฑูุน ูฺบ ููฺฉ ฺฉุง ุชฺพุง)

<Tip>

๐ก ุงฺฏุฑ ุขูพ ฺฉ output directory ูพู ุณ ููุฌูุฏ ุ ุชู  ูุงุฒู  ฺฉ ู repository ฺฉุง ุงฺฉ ููุงู clone ู ุฌุณ ูพุฑ ุขูพ push ฺฉุฑูุง ฺุงุช ฺบ ุงฺฏุฑ ุงุณุง ูฺบ ุ ุชู `model.fit()` ฺฉุงู ฺฉุฑู ูพุฑ ุงุฑุฑ ุขุฆ ฺฏุง ุงูุฑ ุขูพ ฺฉู ูุง ูุงู ุณูน ฺฉุฑูุง ูฺฏุง

</Tip>

ุขุฎุฑ ูฺบุ ุขุฆ ุฏฺฉฺพุช ฺบ ฺฉ ุชุฑุจุช ูฺฉูู ูู ฺฉ ุจุนุฏ ูุงุฑ metrics ฺฉุณ ฺบ:

```py
print(compute_metrics())
```

```
{'bleu': 57.334066271545865}
```

ุงุณ ูุฑุญู ูพุฑุ ุขูพ Model Hub ูพุฑ ููุฌูุฏ inference widget ฺฉุง ุงุณุชุนูุงู ฺฉุฑุช ูุฆ ุงูพู ูุงฺู ฺฉุง ุชุฌุฑุจ ฺฉุฑ ุณฺฉุช ฺบ ุงูุฑ ุงุณ ุงูพู ุฏูุณุชูฺบ ฺฉ ุณุงุชฺพ ุดุฆุฑ ฺฉุฑ ุณฺฉุช ฺบ ุขูพ ู ฺฉุงูุงุจ ฺฉ ุณุงุชฺพ ุงฺฉ ุชุฑุฌู ูนุงุณฺฉ ูพุฑ ูุงฺู fine-tune ฺฉุฑ ูุง  โ ูุจุงุฑฺฉ ู!

{:else}

ุงฺฉ ุจุงุฑ ุฌุจ  ุณุจ ู ุฌุงุฆุ ุชู ู ุงูพู `Seq2SeqTrainingArguments` ุชุนุฑู ฺฉุฑ ุณฺฉุช ฺบ `Trainer` ฺฉ ุทุฑุญุ ู `TrainingArguments` ฺฉ ุงฺฉ ุฐู ฺฉูุงุณ ุงุณุชุนูุงู ฺฉุฑุช ฺบ ุฌุณ ูฺบ ฺูุฏ ุงุถุงู ููฺุฒ ุดุงูู ฺบ:

```python
from transformers import Seq2SeqTrainingArguments

args = Seq2SeqTrainingArguments(
    f"marian-finetuned-kde4-en-to-fr",
    evaluation_strategy="no",
    save_strategy="epoch",
    learning_rate=2e-5,
    per_device_train_batch_size=32,
    per_device_eval_batch_size=64,
    weight_decay=0.01,
    save_total_limit=3,
    num_train_epochs=3,
    predict_with_generate=True,
    fp16=True,
    push_to_hub=True,
)
```

ุนุงู hyperparameters (ุฌุณ learning rateุ epochs ฺฉ ุชุนุฏุงุฏุ batch sizeุ ุงูุฑ ฺฉฺฺพ weight decay) ฺฉ ุนูุงูุ ุงฺบ ฺูุฏ ุชุจุฏูุงฺบ ฺบ ุฌู ูพฺฺพู ุณฺฉุดูุฒ ฺฉ ููุงุจู ูฺบ ูุฎุชูู ฺบ:

- ู ุจุงูุงุนุฏ evaluation ุณูน ูฺบ ฺฉุฑุชุ ฺฉููฺฉ evaluation ูฺบ ฺฉุงู ููุช ูฺฏุชุง ุ ู ุตุฑู ุชุฑุจุช ุณ ูพู ุงูุฑ ุจุนุฏ ูฺบ evaluation ฺฉุฑฺบ ฺฏ
- ู `fp16=True` ุณูน ฺฉุฑุช ฺบุ ุฌู ุฌุฏุฏ GPUs ูพุฑ ุชุฑุจุช ฺฉ ุฑูุชุงุฑ ุจฺฺพุงุชุง 
- ู `predict_with_generate=True` ุณูน ฺฉุฑุช ฺบุ ุฌุณุง ฺฉ ุงููพุฑ ุจุงู ฺฉุง ฺฏุง 
- ู `push_to_hub=True` ุณูน ฺฉุฑุช ฺบ ุชุงฺฉ ุฑ epoch ฺฉ ุขุฎุฑ ูฺบ ูุงฺู Hub ูพุฑ ุงูพ ููฺ ู ุฌุงุฆ

ูููน ฺฉุฑฺบ ฺฉ ุขูพ `hub_model_id` ุขุฑฺฏููููน ฺฉ ุฐุฑุน repository ฺฉุง ูฺฉูู ูุงู ุจฺพ ูุฎุตูุต ฺฉุฑ ุณฺฉุช ฺบ (ุฎุงุต ุทูุฑ ูพุฑุ ุงฺฏุฑ ุขูพ ฺฉุณ organization ูฺบ push ฺฉุฑ ุฑ ฺบ ุชู ุขูพ ฺฉู  ุขุฑฺฏููููน ุงุณุชุนูุงู ฺฉุฑูุง ูฺฏุง) ูุซุงู ฺฉ ุทูุฑ ูพุฑุ ุฌุจ ู ู ูุงฺู ฺฉู [`huggingface-course` organization](https://huggingface.co/huggingface-course) ูพุฑ push ฺฉุงุ ุชู ู ู `hub_model_id="huggingface-course/marian-finetuned-kde4-en-to-fr"` `Seq2SeqTrainingArguments` ูฺบ ุดุงูู ฺฉุง ุจุฐุฑุน ฺูุงููนุ ุงุณุชุนูุงู ุดุฏ repository ุขูพ ฺฉ namespace ูฺบ ูฺฏ ุงูุฑ output directory ฺฉ ูุงู ูพุฑ ูุจู ูฺฏุ ููฐุฐุง ูุงุฑ ูุนุงูู ูฺบ  `"sgugger/marian-finetuned-kde4-en-to-fr"` ูฺฏ (ุฌู ฺฉ ู ูุงฺู  ุฌุณ ฺฉุง ู ู ุงุณ ุณฺฉุดู ฺฉ ุดุฑูุน ูฺบ ุฐฺฉุฑ ฺฉุง ุชฺพุง)

<Tip>

๐ก ุงฺฏุฑ ุขูพ ฺฉ output directory ูพู ุณ ููุฌูุฏ ุ ุชู  ูุงุฒู  ฺฉ ู repository ฺฉุง ุงฺฉ ููุงู clone ู ุฌุณ ูพุฑ ุขูพ push ฺฉุฑูุง ฺุงุช ฺบ ุงฺฏุฑ ุงุณุง ูฺบ ุ ุชู `Seq2SeqTrainer` ุชุนุฑู ฺฉุฑุช ููุช ุงุฑุฑ ุขุฆ ฺฏุง ุงูุฑ ุขูพ ฺฉู ูุง ูุงู ุณูน ฺฉุฑูุง ูฺฏุง

</Tip>

ุขุฎุฑ ูฺบุ ู ุณุจ ฺฉฺฺพ `Seq2SeqTrainer` ฺฉู ูพุงุณ ฺฉุฑ ุฏุช ฺบ:

```python
from transformers import Seq2SeqTrainer

trainer = Seq2SeqTrainer(
    model,
    args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
)
```

ุชุฑุจุช ุดุฑูุน ฺฉุฑู ุณ ูพูุ ู ูพู  ุฏฺฉฺพุช ฺบ ฺฉ ูุงุฑ ูุงฺู ฺฉู ฺฉุง ุงุณฺฉูุฑ ููุชุง ุ ุชุงฺฉ  ูู ุจูุงุง ุฌุง ุณฺฉ ฺฉ ู fine-tuning ฺฉ ุฏูุฑุงู ฺุฒูฺบ ฺฉู ุฎุฑุงุจ ูฺบ ฺฉุฑ ุฑ  ฺฉูุงูฺ ฺฉฺฺพ ููุช ู ฺฏุ ููฐุฐุง ุขูพ ฺฉุงู ฺฉุง ุงฺฉ ฺฉูพ ู ุณฺฉุช ฺบ ุฌุจ  execute ู ุฑ ู:

```python
trainer.evaluate(max_length=max_length)
```

```python out
{'eval_loss': 1.6964408159255981,
 'eval_bleu': 39.26865061007616,
 'eval_runtime': 965.8884,
 'eval_samples_per_second': 21.76,
 'eval_steps_per_second': 0.341}
```

BLEU score 39 ุจุฑุง ูฺบ ุ ุฌู ุงุณ ุจุงุช ฺฉ ุนฺฉุงุณ ฺฉุฑุชุง  ฺฉ ูุงุฑุง ูุงฺู ูพู  ุงูฺฏุฑุฒ ุฌูููฺบ ฺฉู ูุฑุงูุณุณ ูฺบ ุชุฑุฌู ฺฉุฑู ูฺบ ุงฺฺพุง 

ุงุจ ุชุฑุจุช ฺฉุง ูุฑุญู ุดุฑูุน ูุชุง ุ ุฌุณ ูฺบ ุจฺพ ฺฉฺฺพ ููุช ูฺฏ ฺฏุง:

```python
trainer.train()
```

ุชุฑุจุช ฺฉ ุฏูุฑุงูุ ุฑ ุจุงุฑ ุฌุจ ูุงฺู save ูุชุง  (ุงฺบุ ุฑ epoch ูฺบ)  ุจฺฉ ฺฏุฑุงุคูฺ ูฺบ Hub ูพุฑ ุงูพ ููฺ ู ุฌุงุชุง  ุงุณ ุทุฑุญุ ุงฺฏุฑ ุถุฑูุฑุช ู ุชู ุขูพ ฺฉุณ ุงูุฑ ูุดู ูพุฑ ุงูพู ุชุฑุจุช ุฏูุจุงุฑ ุดุฑูุน ฺฉุฑ ุณฺฉุช ฺบ

ุชุฑุจุช ูฺฉูู ูู ฺฉ ุจุนุฏุ ู ุฏูุจุงุฑ ุงูพู ูุงฺู ฺฉุง evaluation ฺฉุฑุช ฺบ โ ุงูุฏ  ฺฉ BLEU score ูฺบ ุจุชุฑ ูุธุฑ ุขุฆ ฺฏ!

```py
trainer.evaluate(max_length=max_length)
```

```python out
{'eval_loss': 0.8558505773544312,
 'eval_bleu': 52.94161337775576,
 'eval_runtime': 714.2576,
 'eval_samples_per_second': 29.426,
 'eval_steps_per_second': 0.461,
 'epoch': 3.0}
```

 ุชูุฑุจุงู 14 ูพูุงุฆููนุณ ฺฉ ุจุชุฑ ุ ุฌู ฺฉ ุจุช ุงฺฺพ ุจุงุช 

ุขุฎุฑ ูฺบุ ู `push_to_hub()` ูุชฺพฺ ฺฉุง ุงุณุชุนูุงู ฺฉุฑุช ฺบ ุชุงฺฉ  ูู ุจูุงุง ุฌุง ุณฺฉ ฺฉ ูุงฺู ฺฉุง ุชุงุฒ ุชุฑู ูุฑฺู ุงูพ ููฺ ู ฺฺฉุง  `Trainer` ุงฺฉ model card ุจฺพ ุชุงุฑ ฺฉุฑุชุง  ุฌุณ ูฺบ ุชูุงู evaluation ฺฉ ูุชุงุฆุฌ ุดุงูู ูุช ฺบ ุงูุฑ ุงุณ ุงูพ ููฺ ฺฉุฑ ุฏุชุง   model card metadata ุฑฺฉฺพุชุง  ุฌู Model Hub ฺฉู inference demo widget ููุชุฎุจ ฺฉุฑู ูฺบ ูุฏุฏ ุฏุชุง  ุนูููุงูุ ุงุณ ฺฉ ู ฺฉฺฺพ ฺฉู ฺฉ ุถุฑูุฑุช ูฺบ ูุช ฺฉููฺฉ  ูุงฺู ฺฉูุงุณ ุณ ุตุญุญ widget ฺฉุง ุงูุฏุงุฒ ูฺฏุง ูุชุง ุ ูฺฏุฑ ุงุณ ุตูุฑุช ูฺบ ฺููฺฉ ุงฺฉ  ูุงฺู ฺฉูุงุณ ูุฎุชูู ูุณู ฺฉ sequence-to-sequence ูุณุงุฆู ฺฉ ู ุงุณุชุนูุงู ู ุณฺฉุช ุ ู ูุงุถุญ ฺฉุฑุช ฺบ ฺฉ  ุงฺฉ ุชุฑุฌู ูุงฺู :

```python
trainer.push_to_hub(tags="translation", commit_message="Training complete")
```

 ฺฉูุงูฺ ุงุณ commit ฺฉุง URL ูููนุงุช  ุฌู ุงุจฺพ ฺฉุง ฺฏุงุ ุงฺฏุฑ ุขูพ ุงุณ ุฏฺฉฺพูุง ฺุงฺบ:

```python out
'https://huggingface.co/sgugger/marian-finetuned-kde4-en-to-fr/commit/3601d621e3baae2bc63d3311452535f8f58f6ef3'
```

ุงุณ ูุฑุญู ูพุฑุ ุขูพ Model Hub ูพุฑ ููุฌูุฏ inference widget ฺฉุง ุงุณุชุนูุงู ฺฉุฑุช ูุฆ ุงูพู ูุงฺู ฺฉุง ุชุฌุฑุจ ฺฉุฑ ุณฺฉุช ฺบ ุงูุฑ ุงุณ ุงูพู ุฏูุณุชูฺบ ฺฉ ุณุงุชฺพ ุดุฆุฑ ฺฉุฑ ุณฺฉุช ฺบ ุขูพ ู ฺฉุงูุงุจ ฺฉ ุณุงุชฺพ ุงฺฉ ุชุฑุฌู ูนุงุณฺฉ ูพุฑ ูุงฺู fine-tune ฺฉุฑ ูุง  โ ูุจุงุฑฺฉ ู!

ุงฺฏุฑ ุขูพ ุชุฑุจุช loop ูฺบ ูุฒุฏ ฺฏุฑุงุฆ ูฺบ ุฌุงูุง ฺุงุช ฺบุ ุชู ุงุจ ู ุขูพ ฺฉู  ุจฺพ ุฏฺฉฺพุงุฆฺบ ฺฏ ฺฉ ฺฉุณ ุทุฑุญ ุงุณ ฺฉุงู ฺฉู ๐ค Accelerate ฺฉุง ุงุณุชุนูุงู ฺฉุฑุช ูุฆ ฺฉุง ุฌุง ุณฺฉุชุง 

{/if}

{#if fw === 'pt'}

## ุงฺฉ ฺฉุณูนู ุชุฑุจุช loop[[a-custom-training-loop]]

ุขุฆ ุงุจ ูฺฉูู ุชุฑุจุช loop ฺฉู ุฏฺฉฺพุช ฺบุ ุชุงฺฉ ุขูพ ุขุณุงู ุณ ุงูพู ุถุฑูุฑุช ฺฉ ูุทุงุจู ุญุต customize ฺฉุฑ ุณฺฉฺบ  ุชูุฑุจุงู ูุณุง  ูุธุฑ ุขุฆ ฺฏุง ุฌุณุง ฺฉ ู ู [section 2](/course/chapter7/2) ุงูุฑ [Chapter 3](/course/chapter3/4) ูฺบ ฺฉุง ุชฺพุง

### ุชุฑุจุช ฺฉ ู ุฑ ฺุฒ ฺฉ ุชุงุฑ[[preparing-everything-for-training]]

ุขูพ ู  ุณุจ ฺฉฺฺพ ฺฉุฆ ุจุงุฑ ุฏฺฉฺพ ูุง ุ ููฐุฐุง ู ฺฉูฺ ฺฉู ุชุฒ ุณ ุฏฺฉฺพฺบ ฺฏ ุณุจ ุณ ูพู ู ุงูพู ฺูนุงุณูนุณ ุณ `DataLoader`s ุจูุงุช ฺบุ ุงูุฑ ฺูนุงุณูนุณ ฺฉู `"torch"` ูุงุฑููน ูฺบ ุณูน ฺฉุฑุช ฺบ ุชุงฺฉ ูฺบ PyTorch tensors ูู ุณฺฉฺบ:

```py
from torch.utils.data import DataLoader

tokenized_datasets.set_format("torch")
train_dataloader = DataLoader(
    tokenized_datasets["train"],
    shuffle=True,
    collate_fn=data_collator,
    batch_size=8,
)
eval_dataloader = DataLoader(
    tokenized_datasets["validation"], collate_fn=data_collator, batch_size=8
)
```

ูพฺพุฑ ู ุงูพู ูุงฺู ฺฉู ุฏูุจุงุฑ instantiate ฺฉุฑุช ฺบุ ุชุงฺฉ  ูู ู ุณฺฉ ฺฉ ู ูพฺฺพู fine-tuning ฺฉ ุญุงูุช ุณ ูฺบ ุจูฺฉ pretrained ูุงฺู ุณ ุดุฑูุน ฺฉุฑ ุฑ ฺบ:

```py
model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)
```

ุงุณ ฺฉ ุจุนุฏ ูฺบ ุงฺฉ optimizer ฺฉ ุถุฑูุฑุช ูฺฏ:

```py
from transformers import AdamW

optimizer = AdamW(model.parameters(), lr=2e-5)
```

ุงฺฉ ุจุงุฑ ุฌุจ ูุงุฑ ูพุงุณ  ุชูุงู ฺุฒฺบ ููุฌูุฏ ูฺบุ ุชู ู ุงูฺบ `accelerator.prepare()` ูุชฺพฺ ฺฉู ุจฺพุฌ ุฏุช ฺบ ุงุฏ ุฑ ฺฉ ุงฺฏุฑ ุขูพ Colab ูููน ุจฺฉ ูฺบ TPUs ูพุฑ ุชุฑุจุช ฺฉุฑูุง ฺุงุช ฺบ ุชู ุขูพ ฺฉู  ฺฉูฺ ุงฺฉ training function ูฺบ ฺุงููุง ูฺฏุงุ ุงูุฑ ุงุณุง ฺฉูุฆ ุจฺพ ุณู execute ูฺบ ฺฉุฑูุง ฺุง ุฌู `Accelerator` instantiate ฺฉุฑ

```py
from accelerate import Accelerator

accelerator = Accelerator()
model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(
    model, optimizer, train_dataloader, eval_dataloader
)
```

ุงุจ ฺููฺฉ ู ู ุงูพู `train_dataloader` ฺฉู `accelerator.prepare()` ฺฉู ุจฺพุฌ ุฏุง ุ ู ุงุณ ฺฉ ููุจุงุฆ ฺฉุง ุงุณุชุนูุงู ฺฉุฑุช ูุฆ ุชุฑุจุช ูุฑุงุญู ฺฉ ุชุนุฏุงุฏ ฺฉุง ุญุณุงุจ ูฺฏุง ุณฺฉุช ฺบ ุงุฏ ุฑ ฺฉ ูฺบ  ูุด dataloader ฺฉู prepare ฺฉุฑู ฺฉ ุจุนุฏ ฺฉุฑูุง ฺุงุ ฺฉููฺฉ  ูุชฺพฺ DataLoader ฺฉ ููุจุงุฆ ฺฉู ุชุจุฏู ฺฉุฑ ุฏุชุง  ู learning rate ฺฉู 0 ุชฺฉ linear schedule ุงุณุชุนูุงู ฺฉุฑุช ฺบ:

```py
from transformers import get_scheduler

num_train_epochs = 3
num_update_steps_per_epoch = len(train_dataloader)
num_training_steps = num_train_epochs * num_update_steps_per_epoch

lr_scheduler = get_scheduler(
    "linear",
    optimizer=optimizer,
    num_warmup_steps=0,
    num_training_steps=num_training_steps,
)
```

ุขุฎุฑ ูฺบุ ุงูพู ูุงฺู ฺฉู Hub ูพุฑ push ฺฉุฑู ฺฉ ูุ ูฺบ ุงฺฉ `Repository` ุขุจุฌฺฉูน ุจูุงูุง ูฺฏุง ุงฺฏุฑ ุขูพ ูพู ุณ ูุงฺฏ ุงู ูฺบ ฺบ ุชู Hugging Face Hub ูฺบ ูุงฺฏ ุงู ฺฉุฑฺบ ู ูุงฺู ฺฉ ID ุณ repository ฺฉุง ูุงู ูุชุนู ฺฉุฑฺบ ฺฏ (ุขูพ ุขุฒุงุฏุงู ุทูุฑ ูพุฑ `repo_name` ุชุจุฏู ฺฉุฑ ุณฺฉุช ฺบุ ุจุณ  ุขูพ ฺฉ username ฺฉู ุดุงูู ฺฉุฑุ ุฌุณุง ฺฉ `get_full_repo_name()` ููฺฉุดู ฺฉุฑุชุง ):

```py
from huggingface_hub import Repository, get_full_repo_name

model_name = "marian-finetuned-kde4-en-to-fr-accelerate"
repo_name = get_full_repo_name(model_name)
repo_name
```

```python out
'sgugger/marian-finetuned-kde4-en-to-fr-accelerate'
```

ูพฺพุฑ ู ุงุณ repository ฺฉู ุงฺฉ ููุงู ูููฺุฑ ูฺบ clone ฺฉุฑ ูุช ฺบ ุงฺฏุฑ  ูพู ุณ ููุฌูุฏ  ุชู ุงุณ ููุงู ูููฺุฑ ฺฉู ู repository ููุง ฺุง ุฌุณ ูพุฑ ุขูพ ฺฉุงู ฺฉุฑ ุฑ ฺบ:

```py
output_dir = "marian-finetuned-kde4-en-to-fr-accelerate"
repo = Repository(output_dir, clone_from=repo_name)
```

ุงุจ ู `output_dir` ูฺบ ูุญููุธ ฺฉ ุฌุงู ูุงู ฺฉุณ ุจฺพ ฺุฒ ฺฉู `repo.push_to_hub()` ูุชฺพฺ ฺฉุงู ฺฉุฑ ฺฉ ุงูพ ููฺ ฺฉุฑ ุณฺฉุช ฺบ  ูฺบ ุฑ epoch ฺฉ ุขุฎุฑ ูฺบ intermediate ูุงฺูุฒ ุงูพ ููฺ ฺฉุฑู ูฺบ ูุฏุฏ ฺฉุฑ ฺฏุง

### ุชุฑุจุช loop[[training-loop]]

ุงุจ ู ูฺฉูู ุชุฑุจุช loop ูฺฉฺพู ฺฉ ู ุชุงุฑ ฺบ evaluation ฺฉู ุขุณุงู ุจูุงู ฺฉ ูุ ู ุงฺฉ `postprocess()` ููฺฉุดู ุชุนุฑู ฺฉุฑุช ฺบ ุฌู predictions ุงูุฑ labels ฺฉู ุงุณ string ฺฉ ูุฑุณุช ูฺบ ุชุจุฏู ฺฉุฑุชุง  ุฌุณุง ฺฉ ูุงุฑุง `metric` ุขุจุฌฺฉูน ุชููุน ุฑฺฉฺพุชุง :

```py
def postprocess(predictions, labels):
    predictions = predictions.cpu().numpy()
    labels = labels.cpu().numpy()

    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)

    # -100 ฺฉู labels ูฺบ ุชุจุฏู ฺฉุฑฺบ ฺฉููฺฉ ู ุงูฺบ decode ูฺบ ฺฉุฑ ุณฺฉุช
    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)
    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)

    # ฺฉฺฺพ ุณุงุฏ post-processing
    decoded_preds = [pred.strip() for pred in decoded_preds]
    decoded_labels = [[label.strip()] for label in decoded_labels]
    return decoded_preds, decoded_labels
```

ุชุฑุจุช loop ุชูุฑุจุงู [section 2](/course/chapter7/2) ุงูุฑ [Chapter 3](/course/chapter3) ุฌุณ loops ฺฉ ุทุฑุญ ุ ูฺฏุฑ evaluation ุญุต ูฺบ ฺูุฏ ุงุฎุชูุงูุงุช ฺบ โ ุชู ุขุฆ ุงุณ ูพุฑ ุชูุฌ ุฏฺบ!

ุณุจ ุณ ูพู ุจุงุช   ฺฉ ู predictions ุญุงุตู ฺฉุฑู ฺฉ ู `generate()` ูุชฺพฺ ุงุณุชุนูุงู ฺฉุฑุช ฺบุ ูฺฏุฑ  ูุงุฑ base model ูพุฑ ููุฌูุฏ ุ ู ฺฉ ู wrapped model ุฌุณ ๐ค Accelerate ู `prepare()` ูุชฺพฺ ูฺบ ุจูุงุง  ุงุณ ู ู ูพู model ฺฉู unwrap ฺฉุฑุช ฺบุ ูพฺพุฑ  ูุชฺพฺ ฺฉุงู ฺฉุฑุช ฺบ

ุฏูุณุฑ ุจุงุช   ฺฉุ ุฌุณ ฺฉ [token classification](/course/chapter7/2) ูฺบ ูุงุ ุฏู processes ู inputs ุงูุฑ labels ฺฉู ูุฎุชูู shapes ูฺบ pad ฺฉุง ู ุณฺฉุชุง ุ ุงุณ ู ู `accelerator.pad_across_processes()` ุงุณุชุนูุงู ฺฉุฑุช ฺบ ุชุงฺฉ predictions ุงูุฑ labels ฺฉู ุงฺฉ  shape ูฺบ ูุงุง ุฌุง ุณฺฉ ุงุณ ุณ ูพู ฺฉ ู `gather()` ูุชฺพฺ ฺฉุงู ฺฉุฑฺบ ุงฺฏุฑ ู ุงุณุง ู ฺฉุฑฺบ ุชู evaluation ุง ุชู error ุฏ ฺฏุง ุง ูุด ฺฉ ู ุฑฺฉุง ุฑ ฺฏุง

```py
from tqdm.auto import tqdm
import torch

progress_bar = tqdm(range(num_training_steps))

for epoch in range(num_train_epochs):
    # ุชุฑุจุช
    model.train()
    for batch in train_dataloader:
        outputs = model(**batch)
        loss = outputs.loss
        accelerator.backward(loss)

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(1)

    # Evaluation
    model.eval()
    for batch in tqdm(eval_dataloader):
        with torch.no_grad():
            generated_tokens = accelerator.unwrap_model(model).generate(
                batch["input_ids"],
                attention_mask=batch["attention_mask"],
                max_length=128,
            )
        labels = batch["labels"]

        # ุถุฑูุฑ  ฺฉ predictions ุงูุฑ labels ฺฉู gather ฺฉุฑู ุณ ูพู pad ฺฉุง ุฌุงุฆ
        generated_tokens = accelerator.pad_across_processes(
            generated_tokens, dim=1, pad_index=tokenizer.pad_token_id
        )
        labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)

        predictions_gathered = accelerator.gather(generated_tokens)
        labels_gathered = accelerator.gather(labels)

        decoded_preds, decoded_labels = postprocess(predictions_gathered, labels_gathered)
        metric.add_batch(predictions=decoded_preds, references=decoded_labels)

    results = metric.compute()
    print(f"epoch {epoch}, BLEU score: {results['score']:.2f}")

    # ูุญููุธ ฺฉุฑฺบ ุงูุฑ ุงูพ ููฺ ฺฉุฑฺบ
    accelerator.wait_for_everyone()
    unwrapped_model = accelerator.unwrap_model(model)
    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)
    if accelerator.is_main_process:
        tokenizer.save_pretrained(output_dir)
        repo.push_to_hub(
            commit_message=f"Training in progress epoch {epoch}", blocking=False
        )
```

```python out
epoch 0, BLEU score: 53.47
epoch 1, BLEU score: 54.24
epoch 2, BLEU score: 54.44
```

ุงฺฉ ุจุงุฑ ุฌุจ  ุณุจ ู ุฌุงุฆุ ุชู ุขูพ ฺฉ ูพุงุณ ุงฺฉ ุงุณุง ูุงฺู ูฺฏุง ุฌุณ ฺฉ ูุชุงุฆุฌ ุชูุฑุจุงู ุงุณ ุทุฑุญ ฺฉ ูฺบ ฺฏ ุฌุณ ู ู `Seq2SeqTrainer` ฺฉ ุณุงุชฺพ ุชุฑุจุช ฺฉุง ุชฺพุง ุขูพ ุงุณ ูุงฺู ฺฉู [*huggingface-course/marian-finetuned-kde4-en-to-fr-accelerate*](https://huggingface.co/huggingface-course/marian-finetuned-kde4-en-to-fr-accelerate) ูพุฑ ฺฺฉ ฺฉุฑ ุณฺฉุช ฺบ ุงูุฑ ุงฺฏุฑ ุขูพ ุชุฑุจุช loop ูฺบ ฺฉูุฆ ุชุจุฏูุงฺบ ุขุฒูุงูุง ฺุงุช ฺบุ ุชู ุขูพ ุงููพุฑ ุฏฺฉฺพุงุฆ ฺฏุฆ ฺฉูฺ ูฺบ ุจุฑุง ุฑุงุณุช ุชุจุฏู ฺฉุฑ ุณฺฉุช ฺบ!

{/if}

## fine-tuned ูุงฺู ฺฉุง ุงุณุชุนูุงู[[using-the-fine-tuned-model]]

ู ูพู  ุขูพ ฺฉู ุฏฺฉฺพุง ฺฺฉ ฺบ ฺฉ ุขูพ Model Hub ูพุฑ ููุฌูุฏ inference widget ฺฉุง ุงุณุชุนูุงู ฺฉุฑุช ูุฆ ูุงุฑ fine-tuned ูุงฺู ฺฉู ฺฉุณ ุงุณุชุนูุงู ฺฉุฑ ุณฺฉุช ฺบ ููฺฉู ุทูุฑ ูพุฑ `pipeline` ูฺบ ุงุณุชุนูุงู ฺฉุฑู ฺฉ ูุ ูฺบ ุตุฑู ุตุญุญ ูุงฺู identifier ูุฎุตูุต ฺฉุฑูุง ูฺฏุง:

```py
from transformers import pipeline

# ุงุณ ุงูพู checkpoint ุณ ุชุจุฏู ฺฉุฑฺบ
model_checkpoint = "huggingface-course/marian-finetuned-kde4-en-to-fr"
translator = pipeline("translation", model=model_checkpoint)
translator("Default to expanded threads")
```

```python out
[{'translation_text': 'Par dรฉfaut, dรฉvelopper les fils de discussion'}]
```

ุฌุณุง ฺฉ ุชููุน ฺฉ ุฌุงุช ุ ูุงุฑุง pretrained ูุงฺู ุฌุณ corpus ูพุฑ fine-tune ฺฉุง ฺฏุง ุงุณ ฺฉ ูุนูููุงุช ฺฉู ุงูพูุงู ูฺฏุง ุ ุงูุฑ ุงุจ ู ุงูฺฏุฑุฒ ููุธ "threads" ฺฉู ูุณ  ฺฺพูฺู ฺฉ ุจุฌุงุฆุ ูุฑุงูุณุณ ฺฉ ุจุงูุงุนุฏ ุงูุฏุงุฒ ูฺบ ุชุฑุฌู ฺฉุฑุชุง  "plugin" ฺฉ ูุนุงูู ูฺบ ุจฺพ  ุตูุฑุชุญุงู :

```py
translator(
    "Unable to import %1 using the OFX importer plugin. This file is not the correct format."
)
```

```python out
[{'translation_text': "Impossible d'importer %1 en utilisant le module externe d'importation OFX. Ce fichier n'est pas le bon format."}]
```

 domain adaptation ฺฉ ุงฺฉ ุงูุฑ ุจุชุฑู ูุซุงู !

<Tip>

โ๏ธ **ุขูพ ฺฉ ุจุงุฑ!** ุงุณ ูููู ูพุฑ ุฌุณ ูฺบ "email" ููุธ ุงุณุชุนูุงู ูุง ุชฺพุงุ ูุงฺู ฺฉุง ูุงูพุณ ฺฉุฑุชุง ุ

</Tip>