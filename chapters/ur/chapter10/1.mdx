# Argilla کا تعارف[[introduction-to-argilla]]

<CourseFloatingBanner
    chapter={10}
    classNames="absolute z-10 right-0 top-0"
/>

باب 5 میں آپ نے 🤗 Datasets لائبریری کا استعمال کرتے ہوئے ایک dataset بنانے کا طریقہ سیکھا اور باب 6 میں آپ نے کچھ عام NLP ٹاسکس کے لیے ماڈلز کو fine-tune کرنے کا طریقہ دریافت کیا۔ اس باب میں، آپ سیکھیں گے کہ [Argilla](https://argilla.io) کا استعمال کرتے ہوئے **datasets کو annotate اور curate** کیسے کریں جنہیں آپ اپنے ماڈلز کی تربیت اور جانچ کے لیے استعمال کر سکتے ہیں۔

ماڈلز کی اچھی کارکردگی کی تربیت کی کلید اعلی معیار کے ڈیٹا کا ہونا ہے۔ اگرچہ Hub میں کچھ اچھے datasets موجود ہیں جنہیں آپ اپنے ماڈلز کی تربیت اور جانچ کے لیے استعمال کر سکتے ہیں، یہ آپ کی مخصوص درخواست یا استعمال کے معاملے کے لیے متعلقہ نہیں ہو سکتے۔ اس صورتِ حال میں، آپ اپنا dataset خود بنانے اور curate کرنے کا سوچ سکتے ہیں۔ Argilla اس کام کو مؤثر طریقے سے انجام دینے میں آپ کی مدد کرے گا۔

<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter10/signin-hf-page.png" alt="Argilla sign in page."/>

Argilla کے ساتھ آپ یہ کر سکتے ہیں:

- غیر منظم ڈیٹا کو **منظم ڈیٹا** میں تبدیل کریں تاکہ اسے NLP ٹاسکس میں استعمال کیا جا سکے۔
- ایک dataset کو curate کریں تاکہ ایک کم معیار والے dataset سے ایک **اعلی معیار والے dataset** تک پہنچا جا سکے۔
- LLMs اور ملٹی-موڈل ماڈلز کے لیے **انسانی فیڈ بیک** جمع کریں۔
- Argilla میں ماہرین کو مدعو کریں کہ وہ آپ کے ساتھ تعاون کریں، یا annotations کو crowdsource کریں!

یہاں کچھ چیزیں ہیں جو آپ اس باب میں سیکھیں گے:

- اپنا Argilla instance سیٹ اپ کرنا۔
- ایک dataset کو لوڈ کرنا اور اسے کچھ مشہور NLP ٹاسکس کی بنیاد پر کنفیگر کرنا۔
- اپنے dataset کو annotate کرنے کے لیے Argilla UI کا استعمال کرنا۔
- اپنے curate کردہ dataset کو استعمال کرنا اور اسے Hub پر export کرنا۔
