# اپنے dataset کو Argilla پر لوڈ کریں[[load-your-dataset-to-argilla]]

<CourseFloatingBanner chapter={10}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter10/section3.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter10/section3.ipynb"},
]} />

آپ جس NLP ٹاسک پر کام کر رہے ہیں اور جس مخصوص استعمال یا ایپلیکیشن کے لحاظ سے، آپ کا ڈیٹا اور annotation کا کام مختلف نظر آئے گا۔ اس کورس کے اس حصے میں، ہم [خبروں کا ایک dataset](https://huggingface.co/datasets/SetFit/ag_news) استعمال کریں گے تاکہ دو کام مکمل کیے جا سکیں: ایک ٹیکسٹ classification ہر ٹیکسٹ کے موضوع پر اور ایک token classification تاکہ نامزد entities کی شناخت کی جا سکے۔

<iframe
  src="https://huggingface.co/datasets/SetFit/ag_news/embed/viewer/default/train"
  frameborder="0"
  width="100%"
  height="560px"
></iframe>

Argilla UI کا استعمال کرتے ہوئے Hub سے ڈیٹاسیٹس import کرنا ممکن ہے، لیکن ہم SDK کا استعمال کریں گے تاکہ اگر ضرورت ہو تو ہم ڈیٹا میں مزید ترامیم کر سکیں۔

## اپنے dataset کو کنفیگر کریں

سب سے پہلے، ہم اپنے Argilla instance سے پچھلے حصے کی طرح کنیکٹ کریں گے:

```python
import argilla as rg

HF_TOKEN = "..."  # صرف نجی Spaces کے لیے

client = rg.Argilla(
    api_url="...",
    api_key="...",
    headers={"Authorization": f"Bearer {HF_TOKEN}"},  # صرف نجی Spaces کے لیے
)
```

اب ہم Argilla میں اپنے dataset کی settings پر غور کر سکتے ہیں۔ یہ settings ان annotation tasks کی نمائندگی کرتی ہیں جو ہم اپنے ڈیٹا پر انجام دینا چاہتے ہیں۔ سب سے پہلے، ہم Hub سے dataset لوڈ کر کے اس کی خصوصیات کو دیکھتے ہیں تاکہ ہم یہ یقینی بنا سکیں کہ ہم dataset کو درست طریقے سے کنفیگر کر رہے ہیں:

```python
from datasets import load_dataset

data = load_dataset("SetFit/ag_news", split="train")
data.features
```

یہ ہمارے dataset کی خصوصیات ہیں:

```python out
{'text': Value(dtype='string', id=None),
 'label': Value(dtype='int64', id=None),
 'label_text': Value(dtype='string', id=None)}
```

اس میں `text` شامل ہے اور ساتھ ہی text classification کے لیے ابتدائی labels بھی موجود ہیں۔ ہم ان labels کو اپنے dataset settings میں شامل کریں گے اور ساتھ ہی named entities کے لیے ایک `spans` سوال بھی شامل کریں گے:

```python
settings = rg.Settings(
    fields=[rg.TextField(name="text")],
    questions=[
        rg.LabelQuestion(
            name="label", title="Classify the text:", labels=data.unique("label_text")
        ),
        rg.SpanQuestion(
            name="entities",
            title="Highlight all the entities in the text:",
            labels=["PERSON", "ORG", "LOC", "EVENT"],
            field="text",
        ),
    ],
)
```

آئیں تھوڑا سا گہرائی میں جا کر دیکھتے ہیں کہ یہ settings کیا معنی رکھتی ہیں۔ سب سے پہلے، ہم نے **fields** کی تعریف کی ہے، جن میں وہ معلومات شامل ہیں جنہیں ہم annotate کریں گے۔ اس صورت میں، ہمارے پاس صرف ایک field ہے اور وہ ٹیکسٹ کی شکل میں ہے، لہٰذا ہم نے `TextField` کا انتخاب کیا ہے۔

پھر، ہم **questions** کی تعریف کرتے ہیں جو ان tasks کی نمائندگی کرتی ہیں جو ہم اپنے ڈیٹا پر انجام دینا چاہتے ہیں:

- text classification کے کام کے لیے، ہم نے ایک `LabelQuestion` منتخب کیا ہے اور ہم نے `label_text` کالم کی منفرد ویلیوز کو اپنے labels کے طور پر استعمال کیا ہے تاکہ یہ یقینی بنایا جا سکے کہ سوال dataset میں پہلے سے موجود labels کے مطابق ہو۔
- token classification کے کام کے لیے، ہمیں ایک `SpanQuestion` کی ضرورت ہوگی۔ ہم نے ان labels کا ایک مجموعہ متعین کیا ہے جنہیں ہم اس کام کے لیے استعمال کریں گے، اور ساتھ ہی وہ field بھی جس پر ہم spans draw کریں گے۔

مزید advanced settings جیسے metadata اور vectors کے بارے میں مزید جاننے کے لیے، [Argilla docs](https://docs.argilla.io/latest/how_to_guides/dataset/#define-dataset-settings) دیکھیں۔

## اپنے dataset کو اپ لوڈ کریں

اب جبکہ ہم نے کچھ settings متعین کر لی ہیں، ہم dataset بنا سکتے ہیں:

```python
dataset = rg.Dataset(name="ag_news", settings=settings)

dataset.create()
```

اب dataset ہمارے Argilla instance میں ظاہر ہو گیا ہے، لیکن آپ دیکھیں گے کہ یہ خالی ہے:

<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter10/empty_dataset.png" alt="Screenshot of the empty dataset."/>

اب ہمیں ان records (rows) کو شامل کرنے کی ضرورت ہے جنہیں ہم annotate کریں گے۔ ایسا کرنے کے لیے، ہمیں صرف ڈیٹا کو records کے طور پر log کرنا ہوگا اور ان عناصر کے لیے mapping فراہم کرنی ہوگی جن کا نام Hub اور Argilla datasets میں ایک جیسا نہیں ہے:

```python
dataset.records.log(data, mapping={"label_text": "label"})
```

ہماری mapping میں، ہم نے یہ وضاحت کی ہے کہ dataset کے `label_text` کالم کو سوال جس کا نام `label` ہے سے map کیا جانا چاہیے۔ اس طرح، ہم dataset میں موجود labels کو پہلے سے annotations کے طور پر استعمال کریں گے تاکہ annotation کا عمل تیز ہو سکے۔

جبکہ records log ہوتے رہیں، آپ Argilla UI میں اپنے dataset پر کام شروع کر سکتے ہیں۔ اس مقام پر، یہ کچھ اس طرح نظر آنا چاہیے:

<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter10/argilla_initial_dataset.png" alt="Screenshot of the dataset in Argilla."/>

اب ہمارا dataset annotate کرنے کے لیے تیار ہے!
