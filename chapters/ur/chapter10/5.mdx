# اپنے annotate کردہ dataset کا استعمال کریں[[use-your-annotated-dataset]]

<CourseFloatingBanner chapter={10}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter10/section5.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter10/section5.ipynb"},
]} />

اب ہم یہ سیکھیں گے کہ Argilla میں موجود annotate کردہ ڈیٹا کو کیسے export اور استعمال کیا جائے۔

## dataset لوڈ کریں

سب سے پہلے، ہمیں یہ یقینی بنانا ہوگا کہ ہم پچھلے مراحل کی طرح اپنے Argilla instance سے کنیکٹ ہیں:

```python
import argilla as rg

HF_TOKEN = "..."  # صرف نجی Spaces کے لیے

client = rg.Argilla(
    api_url="...",
    api_key="...",
    headers={"Authorization": f"Bearer {HF_TOKEN}"},  # صرف نجی Spaces کے لیے
)
```

اور اب، ہم وہ dataset لوڈ کریں گے جس پر ہم کام کریں گے:

```python
dataset = client.datasets(name="ag_news")
```

dataset کو لوڈ کرنا اور `dataset.records` کا استعمال کرتے ہوئے اس کے records کو کال کرنا آپ کے اپنے مقاصد اور pipelines کے لیے dataset اور records کا استعمال شروع کرنے کے لیے کافی ہے۔ تاہم، ہم کچھ اضافی آپریشنز بھی سیکھیں گے، جیسے کہ records کو filter کرنا اور اپنے dataset کو Hugging Face Hub پر export کرنا۔

## dataset کو filter کریں

بعض اوقات، آپ صرف اُن records کا استعمال کرنا چاہتے ہیں جو مکمل ہو چکے ہیں، لہٰذا ہم پہلے اپنے dataset میں موجود records کو ان کی status کی بنیاد پر filter کریں گے:

```python
status_filter = rg.Query(filter=rg.Filter([("status", "==", "completed")]))

filtered_records = dataset.records(status_filter)
```

>[!TIP]
>⚠️ نوٹ کریں کہ `completed` status والے records (یعنی وہ records جو task distribution settings میں مقرر کردہ کم از کم جمع شدہ جوابات کو پورا کرتے ہیں) میں ایک سے زیادہ response ہو سکتے ہیں اور ہر response کا status `submitted`, `draft` یا `discarded` ہو سکتا ہے۔

Argilla docs میں querying اور filtering records کے بارے میں مزید جاننے کے لیے [یہاں](https://docs.argilla.io/latest/how_to_guides/query/) دیکھیں۔

## Hub پر export کریں

اب ہم اپنی annotations کو Hugging Face Hub پر export کر سکتے ہیں تاکہ ہم انہیں دوسروں کے ساتھ شیئر کر سکیں۔ ایسا کرنے کے لیے، ہمیں records کو ایک 🤗 Dataset میں تبدیل کرنا ہوگا اور پھر اسے Hub پر push کرنا ہوگا:

```python
filtered_records.to_datasets().push_to_hub("argilla/ag_news_annotated")
```

متبادل طور پر، ہم مکمل Argilla dataset (بشمول pending records) کو براہ راست اس طرح export کر سکتے ہیں:

```python
dataset.to_hub(repo_id="argilla/ag_news_annotated")
```

یہ ایک دلچسپ انتخاب ہے اگر دوسرے افراد اپنے Argilla instances میں dataset کھولنا چاہتے ہوں، کیونکہ settings خود بخود محفوظ ہو جاتی ہیں اور وہ صرف ایک لائن کوڈ کے ذریعے مکمل dataset import کر سکتے ہیں:

```python
dataset = rg.Dataset.from_hub(repo_id="argilla/ag_news_annotated")
```