<CourseFloatingBanner chapter={2}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/main/course/en/chapter11/section2.ipynb"},
]} />

# چیٹ ٹیمپلیٹس

## تعارف

چیٹ ٹیمپلیٹس زبان کے ماڈلز اور صارفین کے درمیان بات چیت کی ساخت بنانے کے لیے نہایت ضروری ہیں۔ چاہے آپ ایک سادہ چیٹ بوٹ تیار کر رہے ہوں یا ایک پیچیدہ AI ایجنٹ، اپنی گفتگو کو درست طریقے سے فارمیٹ کرنا آپ کے ماڈل سے بہترین نتائج حاصل کرنے کے لیے اہم ہے۔ اس رہنما میں، ہم یہ جانیں گے کہ چیٹ ٹیمپلیٹس کیا ہیں، یہ کیوں اہم ہیں، اور انہیں مؤثر طریقے سے کیسے استعمال کیا جائے۔

<Tip>
چیٹ ٹیمپلیٹس درج ذیل وجوہات کی بنا پر نہایت اہم ہیں:
- مسلسل گفتگو کے ڈھانچے کو برقرار رکھنا
- مناسب کردار کی شناخت کو یقینی بنانا
- متعدد باریوں میں سیاق و سباق کا انتظام کرنا
- ٹول کے استعمال جیسے جدید خصوصیات کی حمایت کرنا
</Tip>

## ماڈل کی اقسام اور ٹیمپلیٹس

### بنیادی ماڈلز بمقابلہ ہدایت شدہ ماڈلز

ایک بنیادی ماڈل کو کچے متن کے ڈیٹا پر تربیت دی جاتی ہے تاکہ اگلا ٹوکن پیش گوئی کیا جا سکے، جبکہ ہدایت شدہ ماڈل کو خاص طور پر ہدایات پر عمل کرنے اور گفتگو میں شامل ہونے کے لیے فائن-ٹیون کیا جاتا ہے۔ مثال کے طور پر، [`SmolLM2-135M`](https://huggingface.co/HuggingFaceTB/SmolLM2-135M) ایک بنیادی ماڈل ہے، جبکہ [`SmolLM2-135M-Instruct`](https://huggingface.co/HuggingFaceTB/SmolLM2-135M-Instruct) اس کا ہدایت شدہ ورژن ہے۔

ہدایت شدہ ماڈلز کو ایک مخصوص گفتگو کے ڈھانچے کی پیروی کے لیے تربیت دی جاتی ہے، جس کی وجہ سے وہ چیٹ بوٹ ایپلیکیشنز کے لیے زیادہ موزوں ہوتے ہیں۔ مزید برآں، ہدایت شدہ ماڈلز پیچیدہ تعاملات کو سنبھال سکتے ہیں، جن میں ٹول کا استعمال، ملٹی ماڈل ان پٹس، اور فنکشن کالنگ شامل ہیں۔

ایک بنیادی ماڈل کو ہدایت شدہ ماڈل کی طرح برتاؤ کرنے کے لیے، ہمیں اپنے پرامپٹس کو ایک مستقل اور قابل فہم فارمیٹ میں ترتیب دینے کی ضرورت ہے۔ یہی وہ مقام ہے جہاں چیٹ ٹیمپلیٹس مددگار ثابت ہوتے ہیں۔ ChatML ایک ایسا ٹیمپلیٹ فارمیٹ ہے جو گفتگو کو واضح کردار کے اشاروں (system, user, assistant) کے ساتھ ترتیب دیتا ہے۔ یہاں [ChatML](https://huggingface.co/HuggingFaceTB/SmolLM2-135M-Instruct/blob/e2c3f7557efbdec707ae3a336371d169783f1da1/tokenizer_config.json#L146) پر ایک رہنما دستیاب ہے۔

<Tip warning={true}>
ہدایت شدہ ماڈل استعمال کرتے وقت، ہمیشہ اس بات کی تصدیق کریں کہ آپ صحیح چیٹ ٹیمپلیٹ فارمیٹ استعمال کر رہے ہیں۔ غلط ٹیمپلیٹ کے استعمال سے ماڈل کی کارکردگی متاثر ہو سکتی ہے یا غیر متوقع برتاؤ دیکھنے کو مل سکتا ہے۔ اس بات کو یقینی بنانے کا سب سے آسان طریقہ ہب پر ماڈل کے ٹوکنائزر کی کنفیگریشن چیک کرنا ہے۔ مثال کے طور پر، `SmolLM2-135M-Instruct` ماڈل <a href="https://huggingface.co/HuggingFaceTB/SmolLM2-135M-Instruct/blob/e2c3f7557efbdec707ae3a336371d169783f1da1/tokenizer_config.json#L146">اس کنفیگریشن</a> کا استعمال کرتا ہے۔
</Tip>

### عام ٹیمپلیٹ فارمیٹس

مخصوص امپلیمنٹیشنز میں جانے سے پہلے، یہ سمجھنا ضروری ہے کہ مختلف ماڈلز اپنی گفتگو کو کس طرح فارمیٹ کرنے کی توقع رکھتے ہیں۔ آئیں ایک سادہ مثال گفتگو کا استعمال کرتے ہوئے کچھ عام ٹیمپلیٹ فارمیٹس کو دیکھتے ہیں:

ہم تمام مثالوں کے لیے درج ذیل گفتگو کا ڈھانچہ استعمال کریں گے:

```python
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Hello!"},
    {"role": "assistant", "content": "Hi! How can I help you today?"},
    {"role": "user", "content": "What's the weather?"},
]
```

یہ وہ ChatML ٹیمپلیٹ ہے جو SmolLM2 اور Qwen 2 جیسے ماڈلز میں استعمال ہوتا ہے:

```sh
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
Hello!<|im_end|>
<|im_start|>assistant
Hi! How can I help you today?<|im_end|>
<|im_start|>user
What's the weather?<|im_start|>assistant
```

یہ `mistral` ٹیمپلیٹ فارمیٹ استعمال کر رہا ہے:

```sh
<s>[INST] You are a helpful assistant. [/INST]
Hi! How can I help you today?</s>
[INST] Hello! [/INST]
```

ان فارمیٹس کے درمیان اہم فرق درج ذیل ہیں:

1. **سسٹم پیغام کی ہینڈلنگ**: 
   - Llama 2 سسٹم پیغامات کو `<<SYS>>` ٹیگز میں لپیٹتا ہے
   - Llama 3 `<|system|>` ٹیگز استعمال کرتا ہے جن کے اختتام پر `</s>` آتا ہے
   - Mistral پہلے انسٹرکشن میں سسٹم پیغام شامل کرتا ہے
   - Qwen واضح `system` کردار کے ساتھ `<|im_start|>` ٹیگز استعمال کرتا ہے
   - ChatGPT `SYSTEM:` پری فکس استعمال کرتا ہے

2. **پیغام کی سرحدیں**:
   - Llama 2 `[INST]` اور `[/INST]` ٹیگز استعمال کرتا ہے
   - Llama 3 کردار مخصوص ٹیگز (`<|system|>`, `<|user|>`, `<|assistant|>`) استعمال کرتا ہے جن کے اختتام پر `</s>` آتا ہے
   - Mistral `[INST]` اور `[/INST]` کو `<s>` اور `</s>` کے ساتھ استعمال کرتا ہے
   - Qwen کردار مخصوص شروع/اختتام ٹوکن استعمال کرتا ہے

3. **خصوصی ٹوکنز**:
   - Llama 2 گفتگو کی سرحدوں کے لیے `<s>` اور `</s>` استعمال کرتا ہے
   - Llama 3 ہر پیغام کے اختتام کے لیے `</s>` استعمال کرتا ہے
   - Mistral باری کی سرحدوں کے لیے `<s>` اور `</s>` استعمال کرتا ہے
   - Qwen کردار مخصوص شروع/اختتام ٹوکن استعمال کرتا ہے

ان فرق کو سمجھنا مختلف ماڈلز کے ساتھ کام کرنے کے لیے کلیدی حیثیت رکھتا ہے۔ آئیں دیکھتے ہیں کہ کس طرح transformers لائبریری ان مختلفیوں کو خود بخود سنبھالنے میں ہماری مدد کرتی ہے:

```python
from transformers import AutoTokenizer

# These will use different templates automatically
mistral_tokenizer = AutoTokenizer.from_pretrained("mistralai/Mistral-7B-Instruct-v0.1")
qwen_tokenizer = AutoTokenizer.from_pretrained("Qwen/Qwen-7B-Chat")
smol_tokenizer = AutoTokenizer.from_pretrained("HuggingFaceTB/SmolLM2-135M-Instruct")

messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Hello!"},
]

# Each will format according to its model's template
mistral_chat = mistral_tokenizer.apply_chat_template(messages, tokenize=False)
qwen_chat = qwen_tokenizer.apply_chat_template(messages, tokenize=False)
smol_chat = smol_tokenizer.apply_chat_template(messages, tokenize=False)
```

<details>
<summary>مثال کے ٹیمپلیٹس دیکھنے کے لیے کلک کریں</summary>

Qwen 2 اور SmolLM2 ChatML ٹیمپلیٹ:

```sh
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
Hello!<|im_end|>
<|im_start|>assistant
Hi! How can I help you today?<|im_end|>
<|im_start|>user
What's the weather?<|im_start|>assistant
```

Mistral ٹیمپلیٹ:

```sh
<s>[INST] You are a helpful assistant. [/INST]
Hi! How can I help you today?</s>
[INST] Hello! [/INST]
```

</details>

### جدید خصوصیات

چیٹ ٹیمپلیٹس صرف گفتگو کی بات چیت سے ہٹ کر مزید پیچیدہ منظرناموں کو بھی سنبھال سکتے ہیں، جن میں شامل ہیں:

1. **ٹول کا استعمال**: جب ماڈلز کو بیرونی ٹولز یا APIs کے ساتھ بات چیت کرنے کی ضرورت ہو
2. **ملٹی ماڈل ان پٹس**: تصاویر، آڈیو، یا دیگر میڈیا اقسام کو سنبھالنے کے لیے
3. **فنکشن کالنگ**: منظم فنکشن کے عمل درآمد کے لیے
4. **ملٹی ٹرن سیاق و سباق**: گفتگو کی تاریخ کو برقرار رکھنے کے لیے

<Tip>
جدید خصوصیات کو نافذ کرتے وقت:
- اپنے مخصوص ماڈل کے ساتھ مکمل جانچ کریں۔ ویژن اور ٹول کے استعمال کے ٹیمپلیٹس خاص طور پر متنوع ہوتے ہیں۔
- ہر خصوصیت اور ماڈل کے درمیان ٹوکن کے استعمال کی احتیاط سے نگرانی کریں۔
- ہر خصوصیت کے لیے متوقع فارمیٹ کا دستاویزی ریکارڈ رکھیں
</Tip>

ملٹی ماڈل گفتگو کے لیے، چیٹ ٹیمپلیٹس میں تصویر کے حوالہ جات یا base64-encoded تصاویر شامل کی جا سکتی ہیں:

```python
messages = [
    {
        "role": "system",
        "content": "You are a helpful vision assistant that can analyze images.",
    },
    {
        "role": "user",
        "content": [
            {"type": "text", "text": "What's in this image?"},
            {"type": "image", "image_url": "https://example.com/image.jpg"},
        ],
    },
]
```

یہاں ٹول کے استعمال کے ساتھ ایک چیٹ ٹیمپلیٹ کی مثال ہے:

```python
messages = [
    {
        "role": "system",
        "content": "You are an AI assistant that can use tools. Available tools: calculator, weather_api",
    },
    {"role": "user", "content": "What's 123 * 456 and is it raining in Paris?"},
    {
        "role": "assistant",
        "content": "Let me help you with that.",
        "tool_calls": [
            {
                "tool": "calculator",
                "parameters": {"operation": "multiply", "x": 123, "y": 456},
            },
            {"tool": "weather_api", "parameters": {"city": "Paris", "country": "France"}},
        ],
    },
    {"role": "tool", "tool_name": "calculator", "content": "56088"},
    {
        "role": "tool",
        "tool_name": "weather_api",
        "content": "{'condition': 'rain', 'temperature': 15}",
    },
]
```

## بہترین طریقے

### عمومی رہنما اصول

چیٹ ٹیمپلیٹس کے ساتھ کام کرتے وقت، درج ذیل اہم اصولوں کی پیروی کریں:

1. **مستقل فارمیٹنگ**: اپنی ایپلیکیشن میں ہمیشہ ایک ہی ٹیمپلیٹ فارمیٹ استعمال کریں
2. **واضح کردار کی تعریف**: ہر پیغام کے لیے واضح طور پر کردار (system, user, assistant, tool) بیان کریں
3. **سیاق و سباق کا انتظام**: گفتگو کی تاریخ برقرار رکھتے وقت ٹوکن کی حد کا خیال رکھیں
4. **غلطی کا انتظام**: ٹول کالز اور ملٹی ماڈل ان پٹس کے لیے مناسب غلطی ہینڈلنگ شامل کریں
5. **تصدیق**: ماڈل کو بھیجنے سے پہلے پیغام کے ڈھانچے کی تصدیق کریں

<Tip warning={true}>
عام غلطیاں جن سے بچنا چاہیے:
- ایک ہی ایپلیکیشن میں مختلف ٹیمپلیٹ فارمیٹس کا مکس ہونا
- طویل گفتگو کی تاریخ کے ساتھ ٹوکن کی حدود سے تجاوز کرنا
- پیغامات میں خصوصی حروف کو صحیح طریقے سے escape نہ کرنا
- ان پٹ پیغام کے ڈھانچے کی تصدیق کرنا بھول جانا
- ماڈل مخصوص ٹیمپلیٹ کی ضروریات کو نظرانداز کرنا
</Tip>

## عملی مشق

آئیں حقیقی دنیا کی مثال کے ساتھ چیٹ ٹیمپلیٹس کو نافذ کرنے کی مشق کریں۔

<Tip>
`HuggingFaceTB/smoltalk` ڈیٹاسیٹ کو ChatML فارمیٹ میں تبدیل کرنے کے لیے درج ذیل مراحل پر عمل کریں:

1. **ڈیٹاسیٹ کو لوڈ کریں:**
```python
from datasets import load_dataset

dataset = load_dataset("HuggingFaceTB/smoltalk")
```

2. **ایک پراسیسنگ فنکشن بنائیں:**
```python
def convert_to_chatml(example):
    return {
        "messages": [
            {"role": "user", "content": example["input"]},
            {"role": "assistant", "content": example["output"]},
        ]
    }
```

3. **اپنے منتخب کردہ ماڈل کے ٹوکنائزر کا استعمال کرتے ہوئے چیٹ ٹیمپلیٹ کو لاگو کریں**

یاد رکھیں کہ آپ کے آؤٹ پٹ فارمیٹ کی تصدیق کر لیں کہ یہ آپ کے ہدف ماڈل کی ضروریات سے میل کھاتا ہے!
</Tip>

## اضافی وسائل

- [Hugging Face چیٹ ٹیمپلیٹنگ گائیڈ](https://huggingface.co/docs/transformers/main/en/chat_templating)
- [Transformers دستاویزات](https://huggingface.co/docs/transformers)
- [چیٹ ٹیمپلیٹس کی مثالیں ریپوزٹری](https://github.com/chujiezheng/chat_templates)