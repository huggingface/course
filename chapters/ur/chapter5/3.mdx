# ÙˆÙ‚Øª Ø¢ Ú¯ÛŒØ§ ÛÛ’ "Ø³Ù„Ø§Ø¦Ø³ Ø§ÛŒÙ†Úˆ ÚˆØ§Ø¦Ø³" Ú©Ø±Ù†Û’ Ú©Ø§[[time-to-slice-and-dice]]

<CourseFloatingBanner chapter={5}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter5/section3.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter5/section3.ipynb"},
]} />

Ø§Ú©Ø«Ø± Ø§ÙˆÙ‚Ø§ØªØŒ Ø¬Ùˆ ÚˆÛŒÙ¹Ø§ Ø¢Ù¾ Ú©Û’ Ù¾Ø§Ø³ ÛÙˆØªØ§ ÛÛ’ ÙˆÛ Ù…Ø§ÚˆÙ„Ø² Ú©ÛŒ ØªØ±Ø¨ÛŒØª Ú©Û’ Ù„ÛŒÛ’ Ù¾ÙˆØ±ÛŒ Ø·Ø±Ø­ ØªÛŒØ§Ø± Ù†ÛÛŒÚº ÛÙˆØªØ§Û” Ø§Ø³ Ø³ÛŒÚ©Ø´Ù† Ù…ÛŒÚº ÛÙ… Ø§Ù† Ù…Ø®ØªÙ„Ù Ø®ØµÙˆØµÛŒØ§Øª Ú©Ø§ Ø¬Ø§Ø¦Ø²Û Ù„ÛŒÚº Ú¯Û’ Ø¬Ùˆ ğŸ¤— Datasets Ø¢Ù¾ Ú©Û’ ÚˆÛŒÙ¹Ø§Ø³ÛŒÙ¹Ø³ Ú©Ùˆ ØµØ§Ù Ú©Ø±Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ ÙØ±Ø§ÛÙ… Ú©Ø±ØªØ§ ÛÛ’Û”

<Youtube id="tqfSFcPMgOI"/>

## Ø§Ù¾Ù†Û’ ÚˆÛŒÙ¹Ø§ Ú©Ùˆ Ø³Ù„Ø§Ø¦Ø³ Ø§ÙˆØ± ÚˆØ§Ø¦Ø³ Ú©Ø±Ù†Ø§[[slicing-and-dicing-our-data]]

Pandas Ú©ÛŒ Ø·Ø±Ø­ØŒ ğŸ¤— Datasets Ù…ØªØ¹Ø¯Ø¯ Ø§ÛŒØ³Û’ ÙÙ†Ú©Ø´Ù†Ø² ÙØ±Ø§ÛÙ… Ú©Ø±ØªØ§ ÛÛ’ Ø¬Ù† Ú©ÛŒ Ù…Ø¯Ø¯ Ø³Û’ Ø¢Ù¾ `Dataset` Ø§ÙˆØ± `DatasetDict` Ø¢Ø¨Ø¬ÛŒÚ©Ù¹Ø³ Ú©Û’ Ù…Ù†Ø¯Ø±Ø¬Ø§Øª Ú©Ùˆ Ù…Ù†ÛŒÙ¾ÙˆÙ„ÛŒÙ¹ Ú©Ø± Ø³Ú©ØªÛ’ ÛÛŒÚºÛ” ÛÙ… Ù¾ÛÙ„Û’ ÛÛŒ [Ø¨Ø§Ø¨ 3](/course/chapter3) Ù…ÛŒÚº `Dataset.map()` Ù…ÛŒØªÚ¾Úˆ Ú©Ø§ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ø¯ÛŒÚ©Ú¾ Ú†Ú©Û’ ÛÛŒÚºØŒ Ø§ÙˆØ± Ø§Ø³ Ø³ÛŒÚ©Ø´Ù† Ù…ÛŒÚº ÛÙ… Ø§Ù¾Ù†ÛŒ Ø¯Ø³ØªØ±Ø³ Ù…ÛŒÚº Ù…ÙˆØ¬ÙˆØ¯ Ø¯ÛŒÚ¯Ø± ÙÙ†Ú©Ø´Ù†Ø² Ú©Ùˆ Ø¯Ø±ÛŒØ§ÙØª Ú©Ø±ÛŒÚº Ú¯Û’Û”

Ø§Ø³ Ù…Ø«Ø§Ù„ Ú©Û’ Ù„ÛŒÛ’ ÛÙ… [Drug Review Dataset](https://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+%28Drugs.com%29) Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±ÛŒÚº Ú¯Û’ØŒ Ø¬Ùˆ [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php) Ù¾Ø± ÛÙˆØ³Ù¹ ÛÛ’Û” Ø§Ø³ Ù…ÛŒÚº Ù…Ø®ØªÙ„Ù Ø¯ÙˆØ§Ø¦ÛŒÚºØŒ Ø¹Ù„Ø§Ø¬ Ú©ÛŒ Ø¬Ø§Ù†Û’ ÙˆØ§Ù„ÛŒ Ø­Ø§Ù„Øª Ø§ÙˆØ± Ù…Ø±ÛŒØ¶ Ú©ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ú©Û’ 10 Ø³ØªØ§Ø±Û’ Ú©Û’ Ø±ÛŒÙ¹Ù†Ú¯ Ú©Û’ Ø³Ø§ØªÚ¾ Ù…Ø±ÛŒØ¶ÙˆÚº Ú©Û’ Ø±ÛŒÙˆÛŒÙˆØ² Ø´Ø§Ù…Ù„ ÛÛŒÚºÛ”

Ø³Ø¨ Ø³Û’ Ù¾ÛÙ„Û’ ÛÙ…ÛŒÚº ÚˆÛŒÙ¹Ø§ ÚˆØ§Ø¤Ù† Ù„ÙˆÚˆ Ø§ÙˆØ± Ø§ÛŒÚ©Ø³Ù¹Ø±ÛŒÚ©Ù¹ Ú©Ø±Ù†Ø§ ÛÙˆÚ¯Ø§ØŒ Ø¬Ùˆ Ú©Û `wget` Ø§ÙˆØ± `unzip` Ú©Ù…Ø§Ù†ÚˆØ² Ú©Û’ Ø°Ø±ÛŒØ¹Û’ Ú©ÛŒØ§ Ø¬Ø§ Ø³Ú©ØªØ§ ÛÛ’:

```py
!wget "https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip"
!unzip drugsCom_raw.zip
```

Ú†ÙˆÙ†Ú©Û TSV ØµØ±Ù CSV Ú©Ø§ Ø§ÛŒÚ© Ù…Ø®ØªÙ„Ù ÙˆØ±Ú˜Ù† ÛÛ’ Ø¬Ø³ Ù…ÛŒÚº Ø¹Ù„ÛŒØ­Ø¯Ú¯ÛŒ Ú©Û’ Ù„ÛŒÛ’ Ú©Ø§Ù…Ø§Ø² Ú©ÛŒ Ø¨Ø¬Ø§Ø¦Û’ tabs Ø§Ø³ØªØ¹Ù…Ø§Ù„ ÛÙˆØªÛ’ ÛÛŒÚºØŒ Ø§Ø³ Ù„ÛŒÛ’ ÛÙ… Ø§Ù† ÙØ§Ø¦Ù„ÙˆÚº Ú©Ùˆ `csv` Ù„ÙˆÚˆÙ†Ú¯ Ø§Ø³Ú©Ø±Ù¾Ù¹ Ø§ÙˆØ± `load_dataset()` ÙÙ†Ú©Ø´Ù† Ù…ÛŒÚº `delimiter` Ø¢Ø±Ú¯ÙˆÙ…Ù†Ù¹ ÙØ±Ø§ÛÙ… Ú©Ø± Ú©Û’ Ù„ÙˆÚˆ Ú©Ø± Ø³Ú©ØªÛ’ ÛÛŒÚº:

```py
from datasets import load_dataset

data_files = {"train": "drugsComTrain_raw.tsv", "test": "drugsComTest_raw.tsv"}
# \t Python Ù…ÛŒÚº tab Ú©Ø±Ø¯Ø§Ø± ÛÛ’
drug_dataset = load_dataset("csv", data_files=data_files, delimiter="\t")
```

ÚˆÛŒÙ¹Ø§ Ø§ÛŒÙ†Ø§Ù„ÛŒØ³Ø³ Ú©Ø±ØªÛ’ ÙˆÙ‚Øª Ø§ÛŒÚ© Ø§Ú†Ú¾ÛŒ Ù…Ø´Ù‚ ÛŒÛ ÛÛ’ Ú©Û Ø¢Ù¾ Ø§ÛŒÚ© Ú†Ú¾ÙˆÙ¹Ø§ Ø±ÛŒÙ†ÚˆÙ… Ù†Ù…ÙˆÙ†Û Ø­Ø§ØµÙ„ Ú©Ø±ÛŒÚº ØªØ§Ú©Û Ø¢Ù¾ Ú©Ùˆ ÙÙˆØ±ÛŒ Ø·ÙˆØ± Ù¾Ø± ÛŒÛ Ø§Ù†Ø¯Ø§Ø²Û ÛÙˆ Ø³Ú©Û’ Ú©Û Ø¢Ù¾ Ú©Ø³ Ù‚Ø³Ù… Ú©Û’ ÚˆÛŒÙ¹Ø§ Ú©Û’ Ø³Ø§ØªÚ¾ Ú©Ø§Ù… Ú©Ø± Ø±ÛÛ’ ÛÛŒÚºÛ” ğŸ¤— Datasets Ù…ÛŒÚº ÛÙ… `Dataset.shuffle()` Ø§ÙˆØ± `Dataset.select()` ÙÙ†Ú©Ø´Ù†Ø² Ú©Ùˆ Ú†ÛŒÙ† Ú©Ø± Ú©Û’ Ø§ÛŒÚ© Ø±ÛŒÙ†ÚˆÙ… Ù†Ù…ÙˆÙ†Û Ø¨Ù†Ø§ Ø³Ú©ØªÛ’ ÛÛŒÚº:

```py
drug_sample = drug_dataset["train"].shuffle(seed=42).select(range(1000))
# Ù¾ÛÙ„Û’ Ú†Ù†Ø¯ Ù…Ø«Ø§Ù„ÛŒÚº Ø¯ÛŒÚ©Ú¾ÛŒÚº
drug_sample[:3]
```

```python
{'Unnamed: 0': [87571, 178045, 80482],
 'drugName': ['Naproxen', 'Duloxetine', 'Mobic'],
 'condition': ['Gout, Acute', 'ibromyalgia', 'Inflammatory Conditions'],
 'review': ['"like the previous person mention, I&#039;m a strong believer of aleve, it works faster for my gout than the prescription meds I take. No more going to the doctor for refills.....Aleve works!"',
  '"I have taken Cymbalta for about a year and a half for fibromyalgia pain. It is great\r\nas a pain reducer and an anti-depressant, however, the side effects outweighed \r\nany benefit I got from it. I had trouble with restlessness, being tired constantly,\r\ndizziness, dry mouth, numbness and tingling in my feet, and horrible sweating. I am\r\nbeing weaned off of it now. Went from 60 mg to 30mg and now to 15 mg. I will be\r\noff completely in about a week. The fibro pain is coming back, but I would rather deal with it than the side effects."',
  '"I have been taking Mobic for over a year with no side effects other than an elevated blood pressure.  I had severe knee and ankle pain which completely went away after taking Mobic.  I attempted to stop the medication however pain returned after a few days."'],
 'rating': [9.0, 3.0, 10.0],
 'date': ['September 2, 2015', 'November 7, 2011', 'June 5, 2013'],
 'usefulCount': [36, 13, 128]}
```

Ù†ÙˆÙ¹ Ú©Ø±ÛŒÚº Ú©Û ÛÙ… Ù†Û’ reproducibility Ú©Û’ Ù„ÛŒÛ’ `Dataset.shuffle()` Ù…ÛŒÚº seed Ù…Ù‚Ø±Ø± Ú©ÛŒØ§ ÛÛ’Û” `Dataset.select()` Ø§ÛŒÚ© iterable (Ù…Ø«Ù„Ø§Ù‹ `range(1000)`) Ú©ÛŒ ØªÙˆÙ‚Ø¹ Ú©Ø±ØªØ§ ÛÛ’ ØªØ§Ú©Û Ø´ÙÙ„ Ø´Ø¯Û ÚˆÛŒÙ¹Ø§Ø³ÛŒÙ¹ Ø³Û’ Ù¾ÛÙ„ÛŒ 1,000 Ù…Ø«Ø§Ù„ÛŒÚº Ø­Ø§ØµÙ„ Ú©ÛŒ Ø¬Ø§ Ø³Ú©ÛŒÚºÛ” Ø§Ø³ Ù†Ù…ÙˆÙ†Û’ Ø³Û’ ÛÙ…ÛŒÚº Ù¾ÛÙ„Û’ ÛÛŒ Ø§Ù¾Ù†Û’ ÚˆÛŒÙ¹Ø§Ø³ÛŒÙ¹ Ú©ÛŒ Ú†Ù†Ø¯ Ø®Ø§Ù…ÛŒØ§Úº Ù†Ø¸Ø± Ø¢ Ø±ÛÛŒ ÛÛŒÚº:

* `Unnamed: 0` Ú©Ø§Ù„Ù… ÛØ± Ù…Ø±ÛŒØ¶ Ú©Û’ Ù„ÛŒÛ’ Ø§ÛŒÚ© Ø§Ù†Ø§Ù†ÙˆÙ…Ø§Ø¦Ø²Úˆ ID Ú©ÛŒ Ø·Ø±Ø­ Ù„Ú¯ØªØ§ ÛÛ’Û”
* `condition` Ú©Ø§Ù„Ù… Ù…ÛŒÚº uppercase Ø§ÙˆØ± lowercase Ø¯ÙˆÙ†ÙˆÚº Ù„ÛŒØ¨Ù„Ø² Ø´Ø§Ù…Ù„ ÛÛŒÚºÛ”
* Ø±ÛŒÙˆÛŒÙˆØ² Ù…Ø®ØªÙ„Ù Ù„Ù…Ø¨Ø§Ø¦ÛŒ Ú©Û’ ÛÛŒÚº Ø§ÙˆØ± Ø§Ù† Ù…ÛŒÚº Python Ú©Û’ Ù„Ø§Ø¦Ù† Ø³ÛŒÙ¾Ø±Ù¹Ø± (`\r\n`) Ú©Û’ Ø³Ø§ØªÚ¾ Ø³Ø§ØªÚ¾ HTML character codes Ø¬ÛŒØ³Û’ `&\#039;` Ø¨Ú¾ÛŒ Ù…ÙˆØ¬ÙˆØ¯ ÛÛŒÚºÛ”

Ø¢Ø¦ÛŒÚº Ø¯ÛŒÚ©Ú¾ØªÛ’ ÛÛŒÚº Ú©Û ÛÙ… ğŸ¤— Datasets Ú©Ø§ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø± Ú©Û’ Ø§Ù† Ù…Ø³Ø§Ø¦Ù„ Ú©Ùˆ Ú©ÛŒØ³Û’ Ø­Ù„ Ú©Ø± Ø³Ú©ØªÛ’ ÛÛŒÚºÛ” `Unnamed: 0` Ú©Ø§Ù„Ù… Ú©Û’ Ù„ÛŒÛ’ Ù…Ø±ÛŒØ¶ ID Ú©ÛŒ Ù…ÙØ±ÙˆØ¶Û Ú©ÛŒ ØªØµØ¯ÛŒÙ‚ Ú©Ø±Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ ÛÙ… `Dataset.unique()` ÙÙ†Ú©Ø´Ù† Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø± Ú©Û’ Ø¯ÛŒÚ©Ú¾ Ø³Ú©ØªÛ’ ÛÛŒÚº Ú©Û ID Ú©ÛŒ ØªØ¹Ø¯Ø§Ø¯ ÛØ± Ø³Ù¾Ù„Ù¹ Ù…ÛŒÚº Ù…ÙˆØ¬ÙˆØ¯ Ù‚Ø·Ø§Ø±ÙˆÚº Ú©ÛŒ ØªØ¹Ø¯Ø§Ø¯ Ø³Û’ Ù…Ù„ØªÛŒ ÛÛ’ ÛŒØ§ Ù†ÛÛŒÚº:

```py
for split in drug_dataset.keys():
    assert len(drug_dataset[split]) == len(drug_dataset[split].unique("Unnamed: 0"))
```

ÛŒÛ ÛÙ…Ø§Ø±ÛŒ Ù…ÙØ±ÙˆØ¶Û Ú©ÛŒ ØªØµØ¯ÛŒÙ‚ Ú©Ø±ØªØ§ ÛÛ’ØŒ Ù„ÛÙ°Ø°Ø§ Ø¢Ø¦ÛŒÚº ÚˆÛŒÙ¹Ø§Ø³ÛŒÙ¹ Ú©Ùˆ ØµØ§Ù Ú©Ø±ØªÛ’ ÛÙˆØ¦Û’ `Unnamed: 0` Ú©Ø§Ù„Ù… Ú©Ø§ Ù†Ø§Ù… ØªØ¨Ø¯ÛŒÙ„ Ú©Ø± Ú©Û’ Ø§Ø³Û’ Ø²ÛŒØ§Ø¯Û Ø³Ù…Ø¬Ú¾ Ø¢Ù†Û’ ÙˆØ§Ù„Ø§ Ø¨Ù†Ø§ Ø¯ÛŒØªÛ’ ÛÛŒÚºÛ” ÛÙ… `DatasetDict.rename_column()` ÙÙ†Ú©Ø´Ù† Ú©Ø§ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø± Ú©Û’ Ø¯ÙˆÙ†ÙˆÚº Ø³Ù¾Ù„Ù¹Ø³ Ù…ÛŒÚº Ø§ÛŒÚ© Ø³Ø§ØªÚ¾ Ú©Ø§Ù„Ù… Ú©Ø§ Ù†Ø§Ù… ØªØ¨Ø¯ÛŒÙ„ Ú©Ø± Ø³Ú©ØªÛ’ ÛÛŒÚº:

```py
drug_dataset = drug_dataset.rename_column(
    original_column_name="Unnamed: 0", new_column_name="patient_id"
)
drug_dataset
```

```python
DatasetDict({
    train: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],
        num_rows: 161297
    })
    test: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],
        num_rows: 53766
    })
})
```

<Tip>

âœï¸ **Ø¢Ø²Ù…Ø§Ø¦ÛŒÚº!** `Dataset.unique()` ÙÙ†Ú©Ø´Ù† Ú©Ø§ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±ØªÛ’ ÛÙˆØ¦Û’ Ù¹Ø±ÛŒÙ†Ù†Ú¯ Ø§ÙˆØ± Ù¹ÛŒØ³Ù¹ Ø³ÛŒÙ¹Ø³ Ù…ÛŒÚº Ù…Ù†ÙØ±Ø¯ Ø¯ÙˆØ§Ø¤Úº Ø§ÙˆØ± Ø­Ø§Ù„Ø§Øª Ú©ÛŒ ØªØ¹Ø¯Ø§Ø¯ Ù…Ø¹Ù„ÙˆÙ… Ú©Ø±ÛŒÚºÛ”

</Tip>

Ø§Ú¯Ù„Ø§ Ù…Ø±Ø­Ù„Û `condition` Ù„ÛŒØ¨Ù„Ø² Ú©Ùˆ normalize Ú©Ø±Ù†Ø§ ÛÛ’ØŒ Ø¬Ø³ Ú©Û’ Ù„ÛŒÛ’ ÛÙ… `Dataset.map()` Ú©Ø§ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±ÛŒÚº Ú¯Û’Û” Ø¬ÛŒØ³Û’ Ú©Û ÛÙ… Ù†Û’ [Ø¨Ø§Ø¨ 3](/course/chapter3) Ù…ÛŒÚº tokenization Ú©Û’ Ù„ÛŒÛ’ Ú©ÛŒØ§ ØªÚ¾Ø§ØŒ ÛÙ… Ø§ÛŒÚ© Ø³Ø§Ø¯Û ÙÙ†Ú©Ø´Ù† ÚˆÛŒÙØ§Ø¦Ù† Ú©Ø± Ø³Ú©ØªÛ’ ÛÛŒÚº Ø¬Ùˆ ÛØ± Ù…Ø«Ø§Ù„ Ù¾Ø± Ù„Ø§Ú¯Ùˆ ÛÙˆ:

```py
def lowercase_condition(example):
    return {"condition": example["condition"].lower()}
```

```py
drug_dataset.map(lowercase_condition)
```

```python
AttributeError: 'NoneType' object has no attribute 'lower'
```

Ø§ÙˆÛ Ù†ÛÛŒÚº! ÛÙ…Ø§Ø±Ø§ map ÙÙ†Ú©Ø´Ù† Ø§ÛŒÚ© Ù…Ø³Ø¦Ù„Û’ Ø³Û’ Ú¯Ø²Ø± Ú¯ÛŒØ§ ÛÛ’! Ø§Ø³ ØºÙ„Ø·ÛŒ Ø³Û’ ÛÙ…ÛŒÚº Ù¾ØªÛ Ú†Ù„ØªØ§ ÛÛ’ Ú©Û `condition` Ú©Ø§Ù„Ù… Ú©ÛŒ Ú©Ú†Ú¾ entries `None` ÛÛŒÚºØŒ Ø¬Ù†ÛÛŒÚº lowercasing Ù†ÛÛŒÚº Ú©ÛŒØ§ Ø¬Ø§ Ø³Ú©ØªØ§ Ú©ÛŒÙˆÙ†Ú©Û ÙˆÛ strings Ù†ÛÛŒÚº ÛÛŒÚºÛ” Ø§Ù† rows Ú©Ùˆ ÛÙ¹Ø§Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ ÛÙ… `Dataset.filter()` Ú©Ø§ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±ÛŒÚº Ú¯Û’ØŒ Ø¬Ùˆ `Dataset.map()` Ú©ÛŒ Ø·Ø±Ø­ Ú©Ø§Ù… Ú©Ø±ØªØ§ ÛÛ’ Ø§ÙˆØ± Ø§ÛŒÚ© ÙÙ†Ú©Ø´Ù† Ú©ÛŒ ØªÙˆÙ‚Ø¹ Ø±Ú©Ú¾ØªØ§ ÛÛ’ Ø¬Ùˆ Ø§ÛŒÚ© Ù…Ø«Ø§Ù„ ÙˆØµÙˆÙ„ Ú©Ø±Û’Û” Ø¨Ø¬Ø§Ø¦Û’ Ø§Ø³ Ú©Û’ Ú©Û ÛÙ… Ø§ÛŒÚ© ÙˆØ§Ø¶Ø­ ÙÙ†Ú©Ø´Ù† Ù„Ú©Ú¾ÛŒÚº Ø¬ÛŒØ³Û’:

```py
def filter_nones(x):
    return x["condition"] is not None
```

Ø§ÙˆØ± Ù¾Ú¾Ø± `drug_dataset.filter(filter_nones)` Ú†Ù„Ø§Ø¦ÛŒÚºØŒ ÛÙ… Ø§ÛŒÚ© Ù„Ø§Ø¦Ù† Ù…ÛŒÚº lambda ÙÙ†Ú©Ø´Ù† Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø± Ø³Ú©ØªÛ’ ÛÛŒÚº:

```
lambda <arguments> : <expression>
```

Ø¬ÛØ§Úº `lambda` Ù¾Ø§Ø¦ØªÚ¾ÙˆÙ† Ú©Û’ Ø®Ø§Øµ [Ú©ÛŒ ÙˆØ±ÚˆØ²](https://docs.python.org/3/reference/lexical_analysis.html#keywords) Ù…ÛŒÚº Ø³Û’ Ø§ÛŒÚ© ÛÛ’ØŒ `<arguments>` Ø§ÛŒÚ© ÙÛØ±Ø³Øª ÛŒØ§ Ø³ÛŒÙ¹ ÛÙˆØªÛŒ ÛÛ’ Ø¬Ùˆ Ú©Ø§Ù…Ø§ Ø³Û’ Ø¬Ø¯Ø§ Ú©ÛŒÛ’ Ú¯Ø¦Û’ Ø§Ù‚Ø¯Ø§Ø± Ù¾Ø± Ù…Ø´ØªÙ…Ù„ ÛÙˆØªÛŒ ÛÛ’ Ø§ÙˆØ± ÙÙ†Ú©Ø´Ù† Ú©Û’ Ø§Ù† Ù¾Ù¹ Ú©Ùˆ Ø¨ÛŒØ§Ù† Ú©Ø±ØªÛŒ ÛÛ’ØŒ Ø§ÙˆØ± `<expression>` ÙˆÛ Ø¢Ù¾Ø±ÛŒØ´Ù†Ø² ÛÙˆØªÛ’ ÛÛŒÚº Ø¬Ùˆ Ø¢Ù¾ Ø§Ù†Ø¬Ø§Ù… Ø¯ÛŒÙ†Ø§ Ú†Ø§ÛØªÛ’ ÛÛŒÚºÛ” Ù…Ø«Ø§Ù„ Ú©Û’ Ø·ÙˆØ± Ù¾Ø±ØŒ ÛÙ… Ø§ÛŒÚ© Ø³Ø§Ø¯Û `lambda` ÙÙ†Ú©Ø´Ù† ØªØ¹Ø±ÛŒÙ Ú©Ø± Ø³Ú©ØªÛ’ ÛÛŒÚº Ø¬Ùˆ Ú©Ø³ÛŒ Ù†Ù…Ø¨Ø± Ú©Ø§ Ø§Ø³Ú©ÙˆØ§Ø¦Ø± Ú©Ø±ØªØ§ ÛÛ’:

```
lambda x : x * x
```

Ø§Ø³ ÙÙ†Ú©Ø´Ù† Ú©Ùˆ Ú©Ø³ÛŒ Ø§Ù† Ù¾Ù¹ Ù¾Ø± Ù„Ø§Ú¯Ùˆ Ú©Ø±Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ØŒ ÛÙ…ÛŒÚº Ø§Ø³Û’ Ø§ÙˆØ± Ø§Ù† Ù¾Ù¹ Ú©Ùˆ Ù‚ÙˆØ³ÛŒÙ† `()` Ù…ÛŒÚº Ù„Ù¾ÛŒÙ¹Ù†Ø§ ÛÙˆÚ¯Ø§:

```py
(lambda x: x * x)(3)
```

```python out
9
```

Ø§Ø³ÛŒ Ø·Ø±Ø­ØŒ ÛÙ… Ù…ØªØ¹Ø¯Ø¯ Ø¯Ù„Ø§Ø¦Ù„ (arguments) Ú©Û’ Ø³Ø§ØªÚ¾ `lambda` ÙÙ†Ú©Ø´Ù†Ø² Ú©ÛŒ ØªØ¹Ø±ÛŒÙ Ú©Ø± Ø³Ú©ØªÛ’ ÛÛŒÚºØŒ Ø¬ÛØ§Úº ÛØ± Ø¯Ù„ÛŒÙ„ Ú©Ùˆ Ú©Ø§Ù…Ø§ Ø³Û’ Ø§Ù„Ú¯ Ú©ÛŒØ§ Ø¬Ø§ØªØ§ ÛÛ’Û” Ù…Ø«Ø§Ù„ Ú©Û’ Ø·ÙˆØ± Ù¾Ø±ØŒ ÛÙ… Ù…Ø«Ù„Ø« Ú©Ø§ Ø±Ù‚Ø¨Û Ø§Ø³ Ø·Ø±Ø­ Ø­Ø§ØµÙ„ Ú©Ø± Ø³Ú©ØªÛ’ ÛÛŒÚº:


```py
(lambda base, height: 0.5 * base * height)(4, 8)
```

```python out
16.0
```

`lambda` ÙÙ†Ú©Ø´Ù†Ø² Ù…ÙÛŒØ¯ ÛÙˆØªÛ’ ÛÛŒÚº Ø¬Ø¨ Ø¢Ù¾ Ú†Ú¾ÙˆÙ¹Û’ Ø§ÙˆØ± Ø§ÛŒÚ© Ø¨Ø§Ø± Ø§Ø³ØªØ¹Ù…Ø§Ù„ ÛÙˆÙ†Û’ ÙˆØ§Ù„Û’ ÙÙ†Ú©Ø´Ù†Ø² Ø¨Ù†Ø§Ù†Ø§ Ú†Ø§ÛØªÛ’ ÛÛŒÚºÛ” (Ù…Ø²ÛŒØ¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ú©Û’ Ù„ÛŒÛ’ØŒ ÛÙ… Ø§ÛŒÙ†ÚˆØ±ÛŒ Ø¨Ø±Ú¯Ø§Úˆ Ú©Ø§ Ø´Ø§Ù†Ø¯Ø§Ø± [Real Python tutorial](https://realpython.com/python-lambda/) Ù¾Ú‘Ú¾Ù†Û’ Ú©ÛŒ Ø³ÙØ§Ø±Ø´ Ú©Ø±ØªÛ’ ÛÛŒÚº)Û”  

ğŸ¤— Datasets Ú©Û’ ØªÙ†Ø§Ø¸Ø± Ù…ÛŒÚºØŒ ÛÙ… `lambda` ÙÙ†Ú©Ø´Ù†Ø² Ú©Ùˆ Ø³Ø§Ø¯Û `map` Ø§ÙˆØ± `filter` Ø¢Ù¾Ø±ÛŒØ´Ù†Ø² Ú©Û’ Ù„ÛŒÛ’ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø± Ø³Ú©ØªÛ’ ÛÛŒÚºÛ” ØªÙˆ Ø¢Ø¦ÛŒÛ’ Ø§Ø³ ØªÚ©Ù†ÛŒÚ© Ú©Ø§ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±Ú©Û’ Ø§Ù¾Ù†Û’ ÚˆÛŒÙ¹Ø§ Ø³ÛŒÙ¹ Ù…ÛŒÚº Ø³Û’ `None` Ø§Ù†Ø¯Ø±Ø§Ø¬Ø§Øª Ú©Ùˆ Ø®ØªÙ… Ú©Ø±ØªÛ’ ÛÛŒÚº:


```py
drug_dataset = drug_dataset.filter(lambda x: x["condition"] is not None)
```





Ø§Ø¨ `None` entries ÛÙ¹ Ú†Ú©ÛŒ ÛÛŒÚºØŒ ÛÙ… `condition` Ú©Ø§Ù„Ù… Ú©Ùˆ normalize Ú©Ø± Ø³Ú©ØªÛ’ ÛÛŒÚº:

```py
drug_dataset = drug_dataset.map(lowercase_condition)
# Ú†ÛŒÚ© Ú©Ø±ÛŒÚº Ú©Û lowercasing ÛÙˆ Ú¯ÛŒØ§
drug_dataset["train"]["condition"][:3]
```

```python
['left ventricular dysfunction', 'adhd', 'birth control']
```




ÛŒÛ Ú©Ø§Ù… Ú©Ø± Ú¯ÛŒØ§! Ø§Ø¨ Ø¬Ø¨ Ú©Û ÛÙ… Ù†Û’ Ù„ÛŒØ¨Ù„Ø² ØµØ§Ù Ú©Ø± Ù„ÛŒÛ’ ÛÛŒÚºØŒ Ø¢Ø¦ÛŒÚº Ø±ÛŒÙˆÛŒÙˆØ² Ú©Ùˆ ØµØ§Ù Ú©Ø±Ù†Û’ Ù¾Ø± ØªÙˆØ¬Û Ø¯ÛŒÚºÛ”

## Ù†Ø¦ÛŒ Ú©Ø§Ù„Ù…Ø² ØªØ®Ù„ÛŒÙ‚ Ú©Ø±Ù†Ø§[[creating-new-columns]]

Ø¬Ø¨ Ø¢Ù¾ Ú©Ø³Ù¹Ù…Ø± Ø±ÛŒÙˆÛŒÙˆØ² Ú©Û’ Ø³Ø§ØªÚ¾ Ú©Ø§Ù… Ú©Ø± Ø±ÛÛ’ ÛÙˆÚºØŒ Ø§ÛŒÚ© Ø§Ú†Ú¾ÛŒ Ù…Ø´Ù‚ ÛŒÛ ÛÛ’ Ú©Û Ø¢Ù¾ ÛØ± Ø±ÛŒÙˆÛŒÙˆ Ù…ÛŒÚº Ø§Ù„ÙØ§Ø¸ Ú©ÛŒ ØªØ¹Ø¯Ø§Ø¯ Ú†ÛŒÚ© Ú©Ø±ÛŒÚºÛ” Ø§ÛŒÚ© Ø±ÛŒÙˆÛŒÙˆ ØµØ±Ù "Great!" Ø¬ÛŒØ³Û’ Ø§ÛŒÚ© Ù„ÙØ¸ Ù¾Ø± Ù…Ø´ØªÙ…Ù„ ÛÙˆ Ø³Ú©ØªØ§ ÛÛ’ ÛŒØ§ ÛØ²Ø§Ø±ÙˆÚº Ø§Ù„ÙØ§Ø¸ Ù¾Ø± Ù…Ø´ØªÙ…Ù„ Ø§ÛŒÚ© Ù…Ú©Ù…Ù„ Ù…Ø¶Ù…ÙˆÙ† ÛÙˆ Ø³Ú©ØªØ§ ÛÛ’ØŒ Ø§ÙˆØ± Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Û’ Ù…Ø¹Ø§Ù…Ù„Û’ Ú©Û’ Ù…Ø·Ø§Ø¨Ù‚ Ø¢Ù¾ Ú©Ùˆ Ø§Ù† Ø§Ù†ØªÛØ§Ø¤Úº Ú©Ùˆ Ù…Ø®ØªÙ„Ù Ø·Ø±ÛŒÙ‚Û’ Ø³Û’ Ø³Ù†Ø¨Ú¾Ø§Ù„Ù†Û’ Ú©ÛŒ Ø¶Ø±ÙˆØ±Øª ÛÙˆÚ¯ÛŒÛ” ÛØ± Ø±ÛŒÙˆÛŒÙˆ Ù…ÛŒÚº Ø§Ù„ÙØ§Ø¸ Ú©ÛŒ ØªØ¹Ø¯Ø§Ø¯ Ù…Ø¹Ù„ÙˆÙ… Ú©Ø±Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ ÛÙ… whitespace Ù¾Ø± Ù…Ø¨Ù†ÛŒ ØªÙ‚Ø³ÛŒÙ… Ú©Û’ Ø§ÛŒÚ© Ø§Ù†Ø¯Ø§Ø²Û’ Ú©Ø§ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±ÛŒÚº Ú¯Û’Û”

Ø¢Ø¦ÛŒÚº Ø§ÛŒÚ© Ø³Ø§Ø¯Û ÙÙ†Ú©Ø´Ù† ÚˆÛŒÙØ§Ø¦Ù† Ú©Ø±ÛŒÚº Ø¬Ùˆ ÛØ± Ø±ÛŒÙˆÛŒÙˆ Ù…ÛŒÚº Ù…ÙˆØ¬ÙˆØ¯ Ø§Ù„ÙØ§Ø¸ Ú©ÛŒ ØªØ¹Ø¯Ø§Ø¯ Ú¯Ù†ØªØ§ ÛÛ’:

```py
def compute_review_length(example):
    return {"review_length": len(example["review"].split())}
```

ÛÙ…Ø§Ø±Û’ `lowercase_condition()` ÙÙ†Ú©Ø´Ù† Ú©Û’ Ø¨Ø±Ø¹Ú©Ø³ØŒ `compute_review_length()` Ø§ÛŒÚ© Ø§ÛŒØ³ÛŒ ÚˆÚ©Ø´Ù†Ø±ÛŒ ÙˆØ§Ù¾Ø³ Ú©Ø±ØªØ§ ÛÛ’ Ø¬Ø³ Ú©ÛŒ key ÚˆÛŒÙ¹Ø§Ø³ÛŒÙ¹ Ú©Û’ Ú©Ø³ÛŒ Ù…ÙˆØ¬ÙˆØ¯Û Ú©Ø§Ù„Ù… Ú©Û’ Ù…Ø·Ø§Ø¨Ù‚ Ù†ÛÛŒÚº ÛÙˆØªÛŒÛ” Ø§Ø³ ØµÙˆØ±Øª Ù…ÛŒÚºØŒ Ø¬Ø¨ `compute_review_length()` Ú©Ùˆ `Dataset.map()` Ù…ÛŒÚº Ù¾Ø§Ø³ Ú©ÛŒØ§ Ø¬Ø§ØªØ§ ÛÛ’ØŒ ØªÙˆ ÛŒÛ ÚˆÛŒÙ¹Ø§Ø³ÛŒÙ¹ Ú©ÛŒ ØªÙ…Ø§Ù… rows Ù¾Ø± Ù„Ø§Ú¯Ùˆ ÛÙˆ Ú©Ø± Ø§ÛŒÚ© Ù†ÛŒØ§ `review_length` Ú©Ø§Ù„Ù… ØªØ®Ù„ÛŒÙ‚ Ú©Ø± Ø¯ÛŒØªØ§ ÛÛ’:

```py
drug_dataset = drug_dataset.map(compute_review_length)
# Ù¾ÛÙ„Û’ Ù¹Ø±ÛŒÙ†Ù†Ú¯ Ù…Ø«Ø§Ù„ Ú©Ùˆ Ø¯ÛŒÚ©Ú¾ÛŒÚº
drug_dataset["train"][0]
```

```python
{'patient_id': 206461,
 'drugName': 'Valsartan',
 'condition': 'left ventricular dysfunction',
 'review': '"It has no side effect, I take it in combination of Bystolic 5 Mg and Fish Oil"',
 'rating': 9.0,
 'date': 'May 20, 2012',
 'usefulCount': 27,
 'review_length': 17}
```

Ø¬ÛŒØ³Ø§ Ú©Û ØªÙˆÙ‚Ø¹ Ú©ÛŒ Ú¯Ø¦ÛŒØŒ ÛÙ…Ø§Ø±Û’ Ù¹Ø±ÛŒÙ†Ù†Ú¯ Ø³ÛŒÙ¹ Ù…ÛŒÚº `review_length` Ú©Ø§Ù„Ù… Ø´Ø§Ù…Ù„ ÛÙˆ Ú¯ÛŒØ§ ÛÛ’Û” ÛÙ… `Dataset.sort()` Ú©Ø§ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø± Ú©Û’ Ø§Ø³ Ù†Ø¦Û’ Ú©Ø§Ù„Ù… Ú©Ùˆ sort Ú©Ø± Ú©Û’ Ø¯ÛŒÚ©Ú¾ Ø³Ú©ØªÛ’ ÛÛŒÚº Ú©Û Ø§Ù†ØªÛØ§Ø¤Úº Ù…ÛŒÚº Ú©ÛŒØ§ Ø­Ø§Ù„Ø§Øª ÛÛŒÚº:

```py
drug_dataset["train"].sort("review_length")[:3]
```

```python
{'patient_id': [103488, 23627, 20558],
 'drugName': ['Loestrin 21 1 / 20', 'Chlorzoxazone', 'Nucynta'],
 'condition': ['birth control', 'muscle spasm', 'pain'],
 'review': ['"Excellent."', '"useless"', '"ok"'],
 'rating': [10.0, 1.0, 6.0],
 'date': ['November 4, 2008', 'March 24, 2017', 'August 20, 2016'],
 'usefulCount': [5, 2, 10],
 'review_length': [1, 1, 1]}
```

Ø¬ÛŒØ³Ø§ Ú©Û ÛÙ… Ù†Û’ Ù…Ø´Ø§ÛØ¯Û Ú©ÛŒØ§ØŒ Ú©Ú†Ú¾ Ø±ÛŒÙˆÛŒÙˆØ² ØµØ±Ù Ø§ÛŒÚ© Ù„ÙØ¸ Ú©Û’ ÛÛŒÚºØŒ Ø¬Ùˆ Ú©Û sentiment analysis Ú©Û’ Ù„ÛŒÛ’ Ù¹Ú¾ÛŒÚ© ÛÙˆ Ø³Ú©ØªØ§ ÛÛ’ Ù„ÛŒÚ©Ù† Ø§Ú¯Ø± ÛÙ… condition Ú©ÛŒ Ù¾ÛŒØ´ Ú¯ÙˆØ¦ÛŒ Ú©Ø±Ù†Ø§ Ú†Ø§ÛØªÛ’ ÛÛŒÚº ØªÙˆ Ù…Ø¹Ù„ÙˆÙ…Ø§ØªÛŒ Ù†ÛÛŒÚº ÛÙˆÚº Ú¯Û’Û”

<Tip>

ğŸ™‹ ÚˆÛŒÙ¹Ø§Ø³ÛŒÙ¹ Ù…ÛŒÚº Ù†Ø¦ÛŒ Ú©Ø§Ù„Ù…Ø² Ø´Ø§Ù…Ù„ Ú©Ø±Ù†Û’ Ú©Ø§ Ø§ÛŒÚ© Ù…ØªØ¨Ø§Ø¯Ù„ Ø·Ø±ÛŒÙ‚Û `Dataset.add_column()` ÛÛ’Û” Ø§Ø³ Ø³Û’ Ø¢Ù¾ Python list ÛŒØ§ NumPy array ÙØ±Ø§ÛÙ… Ú©Ø± Ú©Û’ Ú©Ø§Ù„Ù… Ø´Ø§Ù…Ù„ Ú©Ø± Ø³Ú©ØªÛ’ ÛÛŒÚºØŒ Ø¬Ùˆ Ø§Ù† ØµÙˆØ±ØªÙˆÚº Ù…ÛŒÚº Ù…ÙÛŒØ¯ ÛÙˆØªØ§ ÛÛ’ Ø¬Ø¨ `Dataset.map()` Ø¢Ù¾ Ú©ÛŒ ØªØ¬Ø²ÛŒÛ’ Ú©Û’ Ù„ÛŒÛ’ Ù…Ù†Ø§Ø³Ø¨ Ù†Û ÛÙˆÛ”

</Tip>

Ø¢Ø¦ÛŒÚº `Dataset.filter()` ÙÙ†Ú©Ø´Ù† Ú©Ø§ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±ØªÛ’ ÛÙˆØ¦Û’ Ø§ÛŒØ³Û’ Ø±ÛŒÙˆÛŒÙˆØ² Ú©Ùˆ ÛÙ¹Ø§ Ø¯ÛŒÚº Ø¬Ù† Ù…ÛŒÚº 30 Ø³Û’ Ú©Ù… Ø§Ù„ÙØ§Ø¸ ÛÛŒÚºÛ” ÙˆÛŒØ³Û’ ÛÛŒ Ø¬ÛŒØ³Û’ ÛÙ… Ù†Û’ `condition` Ú©Ø§Ù„Ù… Ú©Û’ Ø³Ø§ØªÚ¾ Ú©ÛŒØ§ØŒ ÛÙ… Ø§Ù†ØªÛØ§Ø¦ÛŒ Ú†Ú¾ÙˆÙ¹Û’ Ø±ÛŒÙˆÛŒÙˆØ² Ú©Ùˆ ÙÙ„Ù¹Ø± Ú©Ø± Ø³Ú©ØªÛ’ ÛÛŒÚº:

```py
drug_dataset = drug_dataset.filter(lambda x: x["review_length"] > 30)
print(drug_dataset.num_rows)
```

```python
{'train': 138514, 'test': 46108}
```

Ø¬ÛŒØ³Ø§ Ú©Û Ø¢Ù¾ Ø¯ÛŒÚ©Ú¾ Ø³Ú©ØªÛ’ ÛÛŒÚºØŒ Ø§Ø³ Ø³Û’ ÛÙ…Ø§Ø±Û’ Ø§ØµÙ„ Ù¹Ø±ÛŒÙ†Ù†Ú¯ Ø§ÙˆØ± Ù¹ÛŒØ³Ù¹ Ø³ÛŒÙ¹Ø³ Ø³Û’ ØªÙ‚Ø±ÛŒØ¨Ø§Ù‹ 15% Ø±ÛŒÙˆÛŒÙˆØ² ÛÙ¹ Ú¯Ø¦Û’ ÛÛŒÚºÛ”

<Tip>

âœï¸ **Ø¢Ø²Ù…Ø§Ø¦ÛŒÚº!** `Dataset.sort()` ÙÙ†Ú©Ø´Ù† Ú©Ø§ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±ØªÛ’ ÛÙˆØ¦Û’ Ø§Ù† Ø±ÛŒÙˆÛŒÙˆØ² Ú©Ùˆ Ø¯ÛŒÚ©Ú¾ÛŒÚº Ø¬Ù† Ù…ÛŒÚº Ø³Ø¨ Ø³Û’ Ø²ÛŒØ§Ø¯Û Ø§Ù„ÙØ§Ø¸ ÛÛŒÚºÛ” Ø¯ÛŒÚ©Ú¾Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ [Ø¯Ø³ØªØ§ÙˆÛŒØ²Ø§Øª](https://huggingface.co/docs/datasets/package_reference/main_classes#datasets.Dataset.sort) Ù…ÛŒÚº Ø¨ÛŒØ§Ù† Ú©Ø±Ø¯Û Ø¢Ø±Ú¯ÙˆÙ…Ù†Ù¹ Ú©Ø§ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±ÛŒÚº ØªØ§Ú©Û Ø±ÛŒÙˆÛŒÙˆØ² Ú©Ùˆ descending order Ù…ÛŒÚº sort Ú©ÛŒØ§ Ø¬Ø§ Ø³Ú©Û’Û”

</Tip>

Ø¢Ø®Ø±ÛŒ Ú†ÛŒØ² Ø¬Ø³Û’ ÛÙ…ÛŒÚº Ø³Ù†Ø¨Ú¾Ø§Ù„Ù†Û’ Ú©ÛŒ Ø¶Ø±ÙˆØ±Øª ÛÛ’ ÙˆÛ ÛÛ’ HTML character codes Ú©Ø§ Ø±ÛŒÙˆÛŒÙˆØ² Ù…ÛŒÚº Ù…ÙˆØ¬ÙˆØ¯ ÛÙˆÙ†Ø§Û” ÛÙ… Python Ú©Û’ `html` module Ú©Ø§ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±ØªÛ’ ÛÙˆØ¦Û’ Ø§Ù† Ø­Ø±ÙˆÙ Ú©Ùˆ unescape Ú©Ø± Ø³Ú©ØªÛ’ ÛÛŒÚº:

```py
import html

text = "I&#039;m a transformer called BERT"
html.unescape(text)
```

```python
"I'm a transformer called BERT"
```

ÛÙ… `Dataset.map()` Ú©Ø§ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±ØªÛ’ ÛÙˆØ¦Û’ Ø§Ù¾Ù†Û’ corpus Ù…ÛŒÚº Ù…ÙˆØ¬ÙˆØ¯ ØªÙ…Ø§Ù… HTML characters Ú©Ùˆ unescape Ú©Ø± Ø¯ÛŒÚº Ú¯Û’:

```py
drug_dataset = drug_dataset.map(lambda x: {"review": html.unescape(x["review"])})
```

Ø¬ÛŒØ³Ø§ Ú©Û Ø¢Ù¾ Ø¯ÛŒÚ©Ú¾ Ø³Ú©ØªÛ’ ÛÛŒÚºØŒ `Dataset.map()` Ù…ÛŒØªÚ¾Úˆ ÚˆÛŒÙ¹Ø§ Ù¾Ø±Ø§Ø³ÛŒØ³Ù†Ú¯ Ú©Û’ Ù„ÛŒÛ’ Ú©Ø§ÙÛŒ Ú©Ø§Ø±Ø¢Ù…Ø¯ ÛÛ’ â€” Ø§ÙˆØ± ÛŒÛ Ø§Ø¨Ú¾ÛŒ ØªÚ© Ø§Ø³ Ú©ÛŒ ØªÙ…Ø§Ù… ØµÙ„Ø§Ø­ÛŒØªÙˆÚº Ú©Ø§ Ø§Ø­Ø§Ø·Û Ù†ÛÛŒÚº Ú©Ø±ØªØ§!

## `map()` Ù…ÛŒØªÚ¾Úˆ Ú©ÛŒ Ø³Ù¾Ø± Ù¾Ø§ÙˆØ±Ø²[[the-map-methods-superpowers]]

`Dataset.map()` Ù…ÛŒØªÚ¾Úˆ Ø§ÛŒÚ© `batched` Ø¢Ø±Ú¯ÙˆÙ…Ù†Ù¹ Ù„ÛŒØªØ§ ÛÛ’ Ø¬Ùˆ Ø§Ú¯Ø± `True` Ù¾Ø± Ø³ÛŒÙ¹ ÛÙˆ ØªÙˆ Ø§ÛŒÚ© Ø³Ø§ØªÚ¾ Ù…ØªØ¹Ø¯Ø¯ Ù…Ø«Ø§Ù„ÛŒÚº map ÙÙ†Ú©Ø´Ù† Ú©Ùˆ Ø¨Ú¾ÛŒØ¬ØªØ§ ÛÛ’ (Ø¨ÛŒÚ† Ø³Ø§Ø¦Ø² Ú©Ù†ÙÛŒÚ¯Ø±ÛŒØ¨Ù„ ÛÛ’ Ù…Ú¯Ø± ÚˆÛŒÙØ§Ù„Ù¹ 1,000 ÛÛ’)Û” Ù…Ø«Ø§Ù„ Ú©Û’ Ø·ÙˆØ± Ù¾Ø±ØŒ ÙˆÛ map ÙÙ†Ú©Ø´Ù† Ø¬Ùˆ ØªÙ…Ø§Ù… HTML characters Ú©Ùˆ unescape Ú©Ø±ØªØ§ ØªÚ¾Ø§ØŒ Ø§Ø³Û’ Ú†Ù„Ø§Ù†Û’ Ù…ÛŒÚº ØªÚ¾ÙˆÚ‘Ø§ ÙˆÙ‚Øª Ù„Ú¯ Ø±ÛØ§ ØªÚ¾Ø§ (Ø¢Ù¾ progress bars Ø³Û’ ÙˆÙ‚Øª Ø¯ÛŒÚ©Ú¾ Ø³Ú©ØªÛ’ ÛÛŒÚº)Û” ÛÙ… Ø§Ø³ Ú©ÛŒ Ú©Ø§Ø±Ú©Ø±Ø¯Ú¯ÛŒ Ú©Ùˆ Ø¨ÛØªØ± Ø¨Ù†Ø§Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ Ø§ÛŒÚ© Ø³Ø§ØªÚ¾ Ú©Ø¦ÛŒ Ø¹Ù†Ø§ØµØ± Ú©Ùˆ list comprehension Ú©Û’ Ø°Ø±ÛŒØ¹Û’ Ù¾Ø±Ø§Ø³ÛŒØ³ Ú©Ø± Ø³Ú©ØªÛ’ ÛÛŒÚºÛ”

Ø¬Ø¨ Ø¢Ù¾ `batched=True` Ø³ÛŒÙ¹ Ú©Ø±ØªÛ’ ÛÛŒÚº ØªÙˆ ÙÙ†Ú©Ø´Ù† Ú©Ùˆ ÚˆÛŒÙ¹Ø§Ø³ÛŒÙ¹ Ú©Û’ ÙÛŒÙ„ÚˆØ² Ú©Û’ Ø³Ø§ØªÚ¾ Ø§ÛŒÚ© ÚˆÚ©Ø´Ù†Ø±ÛŒ Ù…ÙˆØµÙˆÙ„ ÛÙˆØªÛŒ ÛÛ’ØŒ Ù„ÛŒÚ©Ù† Ø§Ø¨ ÛØ± ÙˆÛŒÙ„ÛŒÙˆ Ø§ÛŒÚ© _list of values_ ÛÙˆØªÛŒ ÛÛ’ØŒ Ù†Û Ú©Û Ø§ÛŒÚ© ÙˆØ§Ø­Ø¯ ÙˆÛŒÙ„ÛŒÙˆÛ” `Dataset.map()` Ú©Ø§ Ø±ÛŒÙ¹Ø±Ù† ÙˆÛŒÙ„ÛŒÙˆ Ø¨Ú¾ÛŒ Ø§ÛŒØ³ÛŒ ÛÛŒ ÛÙˆÙ†ÛŒ Ú†Ø§ÛÛŒÛ’: Ø§ÛŒÚ© ÚˆÚ©Ø´Ù†Ø±ÛŒ Ø¬Ø³ Ù…ÛŒÚº ÙˆÛ ÙÛŒÙ„ÚˆØ² Ø´Ø§Ù…Ù„ ÛÙˆÚº Ø¬Ù†ÛÛŒÚº ÛÙ… Ø§Ù¾ÚˆÛŒÙ¹ ÛŒØ§ Ù†ÛŒØ§ Ø´Ø§Ù…Ù„ Ú©Ø±Ù†Ø§ Ú†Ø§ÛØªÛ’ ÛÛŒÚºØŒ Ø§ÙˆØ± Ø§Ù† Ú©ÛŒ ÙˆÛŒÙ„ÛŒÙˆØ² Ú©ÛŒ Ù„Ø³Ù¹Û” Ù…Ø«Ø§Ù„ Ú©Û’ Ø·ÙˆØ± Ù¾Ø±ØŒ ÛŒÛØ§Úº Ø§ÛŒÚ© Ø§ÙˆØ± Ø·Ø±ÛŒÙ‚Û ÛÛ’ Ø¬Ø³ Ø³Û’ ØªÙ…Ø§Ù… HTML characters Ú©Ùˆ unescape Ú©ÛŒØ§ Ø¬Ø§ Ø³Ú©ØªØ§ ÛÛ’ØŒ Ù…Ú¯Ø± `batched=True` Ú©Û’ Ø³Ø§ØªÚ¾:

```python
new_drug_dataset = drug_dataset.map(
    lambda x: {"review": [html.unescape(o) for o in x["review"]]}, batched=True
)
```

Ø§Ú¯Ø± Ø¢Ù¾ ÛŒÛ Ú©ÙˆÚˆ Ù†ÙˆÙ¹ Ø¨ÙÚ© Ù…ÛŒÚº Ú†Ù„Ø§ Ø±ÛÛ’ ÛÛŒÚº ØªÙˆ Ø¢Ù¾ Ø¯ÛŒÚ©Ú¾ÛŒÚº Ú¯Û’ Ú©Û ÛŒÛ Ú©Ù…Ø§Ù†Úˆ Ù¾Ú†Ú¾Ù„ÛŒ Ú©Ù…Ø§Ù†Úˆ Ú©Û’ Ù…Ù‚Ø§Ø¨Ù„Û’ Ù…ÛŒÚº Ø¨ÛØª ØªÛŒØ²ÛŒ Ø³Û’ Ú†Ù„ØªÛŒ ÛÛ’Û” Ø§ÙˆØ± ÛŒÛ Ø§Ø³ Ù„ÛŒÛ’ Ù†ÛÛŒÚº Ú©Û ÛÙ…Ø§Ø±Û’ Ø±ÛŒÙˆÛŒÙˆØ² Ù¾ÛÙ„Û’ ÛÛŒ unescape ÛÙˆ Ú†Ú©Û’ ÛÛŒÚº â€” Ø§Ú¯Ø± Ø¢Ù¾ Ù¾Ú†Ú¾Ù„Û’ Ø³ÛŒÚ©Ø´Ù† Ú©ÛŒ ÛØ¯Ø§ÛŒØ§Øª Ú©Ùˆ Ø¯ÙˆØ¨Ø§Ø±Û (Ø¨ØºÛŒØ± `batched=True` Ú©Û’) Ú†Ù„Ø§Ø¦ÛŒÚº ØªÙˆ Ø§Ø³Û’ Ù¾ÛÙ„Û’ Ø¬ÛŒØ³Ø§ ÛÛŒ ÙˆÙ‚Øª Ù„Ú¯Û’ Ú¯Ø§Û” Ø§Ø³ Ú©ÛŒ ÙˆØ¬Û ÛŒÛ ÛÛ’ Ú©Û list comprehensions Ø¹Ù…ÙˆÙ…Ø§Ù‹ for loop Ú©Û’ Ù…Ù‚Ø§Ø¨Ù„Û’ Ù…ÛŒÚº ØªÛŒØ² ÛÙˆØªÛŒ ÛÛŒÚºØŒ Ø§ÙˆØ± Ø§Ø³ Ú©Û’ Ø¹Ù„Ø§ÙˆÛ Ø§ÛŒÚ© Ø³Ø§ØªÚ¾ Ø¨ÛØª Ø³Û’ Ø¹Ù†Ø§ØµØ± ØªÚ© Ø±Ø³Ø§Ø¦ÛŒ Ø³Û’ Ø¨Ú¾ÛŒ Ú©Ø§Ø±Ú©Ø±Ø¯Ú¯ÛŒ Ù…ÛŒÚº Ø¨ÛØªØ±ÛŒ Ø¢ØªÛŒ ÛÛ’Û”

`Dataset.map()` Ú©Û’ Ø³Ø§ØªÚ¾ `batched=True` Ú©Ø§ Ø§Ø³ØªØ¹Ù…Ø§Ù„ "ÙØ§Ø³Ù¹" Ù¹ÙˆÚ©Ù†Ø§Ø¦Ø²Ø±Ø² Ú©ÛŒ Ø±ÙØªØ§Ø± Ú©Ùˆ Ø§Ù† Ù„Ø§Ú© Ú©Ø±Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ Ø¶Ø±ÙˆØ±ÛŒ ÛÙˆÚ¯Ø§ Ø¬Ù† Ú©Ø§ ÛÙ… [Ø¨Ø§Ø¨ 6](/course/chapter6) Ù…ÛŒÚº Ø³Ø§Ù…Ù†Ø§ Ú©Ø±ÛŒÚº Ú¯Û’ØŒ Ø¬Ùˆ Ø¨Ú‘ÛŒ Ù„Ø³Ù¹ÙˆÚº Ú©Û’ texts Ú©Ùˆ ØªÛŒØ²ÛŒ Ø³Û’ tokenize Ú©Ø± Ø³Ú©ØªÛ’ ÛÛŒÚºÛ” Ù…Ø«Ø§Ù„ Ú©Û’ Ø·ÙˆØ± Ù¾Ø±ØŒ Ø§Ú¯Ø± ÛÙ… ØªÙ…Ø§Ù… drug Ø±ÛŒÙˆÛŒÙˆØ² Ú©Ùˆ Ø§ÛŒÚ© fast tokenizer Ú©Û’ Ø³Ø§ØªÚ¾ tokenize Ú©Ø±Ù†Ø§ Ú†Ø§ÛÛŒÚº ØªÙˆ ÛÙ… Ø§ÛŒØ³Ø§ ÙÙ†Ú©Ø´Ù† Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø± Ø³Ú©ØªÛ’ ÛÛŒÚº:

```python
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")


def tokenize_function(examples):
    return tokenizer(examples["review"], truncation=True)
```

Ø¬ÛŒØ³Ø§ Ú©Û Ø¢Ù¾ Ù†Û’ [Ø¨Ø§Ø¨ 3](/course/chapter3) Ù…ÛŒÚº Ø¯ÛŒÚ©Ú¾Ø§ØŒ ÛÙ… Ù¹ÙˆÚ©Ù†Ø§Ø¦Ø²Ø± Ú©Ùˆ Ø§ÛŒÚ© ÛŒØ§ Ú©Ø¦ÛŒ Ù…Ø«Ø§Ù„ÛŒÚº Ù¾Ø§Ø³ Ú©Ø± Ø³Ú©ØªÛ’ ÛÛŒÚºØŒ Ù„ÛÙ°Ø°Ø§ ÛÙ… Ø§Ø³ ÙÙ†Ú©Ø´Ù† Ú©Ùˆ `batched=True` Ú©Û’ Ø³Ø§ØªÚ¾ ÛŒØ§ Ø¨ØºÛŒØ± Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø± Ø³Ú©ØªÛ’ ÛÛŒÚºÛ” Ø¢Ø¦ÛŒÚº Ø§Ø³ Ù…ÙˆÙ‚Ø¹ Ú©Ø§ ÙØ§Ø¦Ø¯Û Ø§Ù¹Ú¾Ø§ØªÛ’ ÛÙˆØ¦Û’ Ù…Ø®ØªÙ„Ù Ø§Ø®ØªÛŒØ§Ø±Ø§Øª Ú©ÛŒ Ú©Ø§Ø±Ú©Ø±Ø¯Ú¯ÛŒ Ú©Ø§ Ù…ÙˆØ§Ø²Ù†Û Ú©Ø±ØªÛ’ ÛÛŒÚºÛ” Ù†ÙˆÙ¹ Ø¨ÙÚ© Ù…ÛŒÚºØŒ Ø¢Ù¾ `%time` Ø´Ø§Ù…Ù„ Ú©Ø± Ú©Û’ Ø§ÛŒÚ© Ù„Ø§Ø¦Ù† Ú©Û’ Ú©ÙˆÚˆ Ú©ÛŒ Ú©Ø§Ø±Ú©Ø±Ø¯Ú¯ÛŒ Ø¬Ø§Ù†Ú† Ø³Ú©ØªÛ’ ÛÛŒÚº:

```python no-format
%time tokenized_dataset = drug_dataset.map(tokenize_function, batched=True)
```

Ø¢Ù¾ Ù¾ÙˆØ±Û’ Ø³ÛŒÙ„ Ú©Ùˆ Ø¨Ú¾ÛŒ `%%time` Ú©Û’ Ø³Ø§ØªÚ¾ Ù¹Ø§Ø¦Ù… Ú©Ø± Ø³Ú©ØªÛ’ ÛÛŒÚºÛ” Ø¬Ø³ ÛØ§Ø±ÚˆÙˆÛŒØ¦Ø± Ù¾Ø± ÛÙ… Ù†Û’ ÛŒÛ Ø¢Ø²Ù…Ø§ÛŒØ§ØŒ Ø§Ø³ Ù†Û’ "Wall time" Ú©Û’ Ø¨Ø¹Ø¯ 10.8s Ø¯Ú©Ú¾Ø§ÛŒØ§Û”

<Tip>

âœï¸ **Ø¢Ø²Ù…Ø§Ø¦ÛŒÚº!** ÙˆÛÛŒ ÛØ¯Ø§ÛŒØª `batched=True` Ú©Û’ Ø³Ø§ØªÚ¾ Ø§ÙˆØ± Ø¨ØºÛŒØ± Ú†Ù„Ø§Ø¦ÛŒÚºØŒ Ù¾Ú¾Ø± Ø§ÛŒÚ© slow tokenizer (AutoTokenizer.from_pretrained() Ù…ÛŒÚº `use_fast=False` Ø´Ø§Ù…Ù„ Ú©Ø±ÛŒÚº) Ú©Û’ Ø³Ø§ØªÚ¾ Ø¢Ø²Ù…Ø§Ø¦ÛŒÚº ØªØ§Ú©Û Ø¢Ù¾ Ø¯ÛŒÚ©Ú¾ Ø³Ú©ÛŒÚº Ú©Û Ø¢Ù¾ Ú©Û’ ÛØ§Ø±ÚˆÙˆÛŒØ¦Ø± Ù¾Ø± Ú©ÛŒØ§ Ù†ØªØ§Ø¦Ø¬ Ù…Ù„ØªÛ’ ÛÛŒÚºÛ”

</Tip>

ÛŒÛØ§Úº ÙˆÛ Ù†ØªØ§Ø¦Ø¬ ÛÛŒÚº Ø¬Ùˆ ÛÙ… Ù†Û’ batching Ú©Û’ Ø³Ø§ØªÚ¾ Ø§ÙˆØ± Ø¨ØºÛŒØ±ØŒ fast Ø§ÙˆØ± slow tokenizer Ú©Û’ Ø³Ø§ØªÚ¾ Ø­Ø§ØµÙ„ Ú©ÛŒÛ’:

Options         | Fast tokenizer | Slow tokenizer
:--------------:|:--------------:|:-------------:
`batched=True`  | 10.8s          | 4min41s
`batched=False` | 59.2s          | 5min3s

Ø§Ø³ Ú©Ø§ Ù…Ø·Ù„Ø¨ ÛÛ’ Ú©Û fast tokenizer Ú©Ùˆ `batched=True` Ú©Û’ Ø¢Ù¾Ø´Ù† Ú©Û’ Ø³Ø§ØªÚ¾ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±Ù†Ø§ slow tokenizer Ú©Û’ Ø¨ØºÛŒØ± batching Ú©Û’ Ù…Ù‚Ø§Ø¨Ù„Û’ Ù…ÛŒÚº 30 Ú¯Ù†Ø§ ØªÛŒØ² ÛÛ’ â€” ÛŒÛ ÙˆØ§Ù‚Ø¹ÛŒ Ø­ÛŒØ±Ø§Ù† Ú©Ù† ÛÛ’! ÛŒÛÛŒ ÙˆØ¬Û ÛÛ’ Ú©Û fast tokenizers `AutoTokenizer` Ú©Û’ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ù…ÛŒÚº ÚˆÛŒÙØ§Ù„Ù¹ ÛÙˆØªÛ’ ÛÛŒÚº (Ø§ÙˆØ± Ø§Ù†ÛÛŒÚº "fast" Ú©ÛØ§ Ø¬Ø§ØªØ§ ÛÛ’)Û” ÙˆÛ ÛŒÛ Ø±ÙØªØ§Ø± Ø§Ø³ Ù„ÛŒÛ’ Ø­Ø§ØµÙ„ Ú©Ø± Ù¾Ø§ØªÛ’ ÛÛŒÚº Ú©ÛŒÙˆÙ†Ú©Û Ø§Ù† Ú©Û’ Ø§Ù†Ø¯Ø±ÙˆÙ†ÛŒ Ú©ÙˆÚˆ Rust Ù…ÛŒÚº Ú†Ù„Ø§ÛŒØ§ Ø¬Ø§ØªØ§ ÛÛ’ØŒ Ø¬Ùˆ Ú©Û Ú©ÙˆÚˆ Ú©ÛŒ parallelization Ú©Ùˆ Ø¢Ø³Ø§Ù† Ø¨Ù†Ø§ØªØ§ ÛÛ’Û”

parallelization Ú©ÛŒ Ø¨Ø¯ÙˆÙ„Øª fast tokenizer batching Ú©Û’ Ø³Ø§ØªÚ¾ ØªÙ‚Ø±ÛŒØ¨Ø§Ù‹ 6x ØªÛŒØ²ÛŒ Ø­Ø§ØµÙ„ Ú©Ø±ØªØ§ ÛÛ’: Ø¢Ù¾ Ø§ÛŒÚ© ÙˆØ§Ø­Ø¯ tokenization Ø¢Ù¾Ø±ÛŒØ´Ù† Ú©Ùˆ parallelize Ù†ÛÛŒÚº Ú©Ø± Ø³Ú©ØªÛ’ØŒ Ù„ÛŒÚ©Ù† Ø¬Ø¨ Ø¢Ù¾ Ø¨ÛŒÚ© ÙˆÙ‚Øª Ø¨ÛØª Ø³Û’ texts Ú©Ùˆ tokenize Ú©Ø±Ù†Ø§ Ú†Ø§ÛØªÛ’ ÛÛŒÚº ØªÙˆ Ø¢Ù¾ execution Ú©Ùˆ Ù…Ø®ØªÙ„Ù processes Ù…ÛŒÚº ØªÙ‚Ø³ÛŒÙ… Ú©Ø± Ø³Ú©ØªÛ’ ÛÛŒÚºØŒ Ø¬Ù† Ù…ÛŒÚº Ø³Û’ ÛØ± Ø§ÛŒÚ© Ø§Ù¾Ù†ÛŒ texts Ú©Û’ Ù„ÛŒÛ’ Ø°Ù…Û Ø¯Ø§Ø± ÛÙˆØªØ§ ÛÛ’Û”

`Dataset.map()` Ù…ÛŒÚº Ø¨Ú¾ÛŒ parallelization Ú©ÛŒ Ú©Ú†Ú¾ ØµÙ„Ø§Ø­ÛŒØªÛŒÚº Ù…ÙˆØ¬ÙˆØ¯ ÛÛŒÚºÛ” Ú†ÙˆÙ†Ú©Û ÛŒÛ Rust Ø³Û’ backed Ù†ÛÛŒÚº ÛÛ’ØŒ Ø§Ø³ Ù„ÛŒÛ’ ÛŒÛ slow tokenizer Ú©Ùˆ fast tokenizer Ú©Û’ Ø¨Ø±Ø§Ø¨Ø± Ù†ÛÛŒÚº Ù„Ø§ Ø³Ú©ØªØ§ØŒ Ù…Ú¯Ø± ÛŒÛ Ø§Ø¨ Ø¨Ú¾ÛŒ Ù…ÙÛŒØ¯ Ø«Ø§Ø¨Øª ÛÙˆ Ø³Ú©ØªØ§ ÛÛ’ (Ø®Ø§Øµ Ø·ÙˆØ± Ù¾Ø± Ø§Ú¯Ø± Ø¢Ù¾ Ø§ÛŒØ³Û’ tokenizer Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø± Ø±ÛÛ’ ÛÛŒÚº Ø¬Ø³ Ú©Ø§ fast ÙˆØ±Ú˜Ù† Ù…ÙˆØ¬ÙˆØ¯ Ù†Û ÛÙˆ)Û” multiprocessing ÙØ¹Ø§Ù„ Ú©Ø±Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ `num_proc` Ø¢Ø±Ú¯ÙˆÙ…Ù†Ù¹ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±ÛŒÚº Ø§ÙˆØ± Ø§Ù¾Ù†ÛŒ `Dataset.map()` Ú©Ø§Ù„ Ù…ÛŒÚº Ø§Ø³ØªØ¹Ù…Ø§Ù„ ÛÙˆÙ†Û’ ÙˆØ§Ù„Û’ processes Ú©ÛŒ ØªØ¹Ø¯Ø§Ø¯ Ø¨ØªØ§Ø¦ÛŒÚº:

```python
slow_tokenizer = AutoTokenizer.from_pretrained("bert-base-cased", use_fast=False)


def slow_tokenize_function(examples):
    return slow_tokenizer(examples["review"], truncation=True)


tokenized_dataset = drug_dataset.map(slow_tokenize_function, batched=True, num_proc=8)
```

Ø¢Ù¾ ØªÚ¾ÙˆÚ‘Ø§ ØªØ¬Ø±Ø¨Û Ú©Ø± Ú©Û’ timing Ø³Û’ Ù…Ø¹Ù„ÙˆÙ… Ú©Ø± Ø³Ú©ØªÛ’ ÛÛŒÚº Ú©Û processes Ú©ÛŒ ØªØ¹Ø¯Ø§Ø¯ Ú©ÛŒØ§ ÛÙˆÙ†ÛŒ Ú†Ø§ÛÛŒÛ’Ø› ÛÙ…Ø§Ø±Û’ Ú©ÛŒØ³ Ù…ÛŒÚº 8 Ø³Ø¨ Ø³Û’ Ø¨ÛØªØ± Ù†ØªÛŒØ¬Û Ø¯Û’ Ø±ÛØ§ ØªÚ¾Ø§Û” ÛŒÛØ§Úº ÙˆÛ Ø§Ø¹Ø¯Ø§Ø¯ Ùˆ Ø´Ù…Ø§Ø± ÛÛŒÚº Ø¬Ùˆ ÛÙ…ÛŒÚº multiprocessing Ú©Û’ Ø³Ø§ØªÚ¾ Ø§ÙˆØ± Ø¨ØºÛŒØ± Ù…Ù„Û’:

Options         | Fast tokenizer | Slow tokenizer
:--------------:|:--------------:|:-------------:
`batched=True`  | 10.8s          | 4min41s
`batched=False` | 59.2s          | 5min3s
`batched=True`, `num_proc=8`  | 6.52s          | 41.3s
`batched=False`, `num_proc=8` | 9.49s          | 45.2s

ÛŒÛ slow tokenizer Ú©Û’ Ù„ÛŒÛ’ Ú©Ø§ÙÛŒ Ù…Ø¹Ù‚ÙˆÙ„ Ù†ØªØ§Ø¦Ø¬ ÛÛŒÚºØŒ Ù„ÛŒÚ©Ù† fast tokenizer Ú©ÛŒ Ú©Ø§Ø±Ú©Ø±Ø¯Ú¯ÛŒ Ø¨Ú¾ÛŒ Ù†Ù…Ø§ÛŒØ§Úº Ø·ÙˆØ± Ù¾Ø± Ø¨ÛØªØ± ÛÙˆØ¦ÛŒÛ” Ø§Ù„Ø¨ØªÛØŒ ÛŒÛ ÛÙ…ÛŒØ´Û Ø§ÛŒØ³Ø§ Ù†ÛÛŒÚº ÛÙˆÚ¯Ø§ â€” 8 Ú©Û’ Ø¹Ù„Ø§ÙˆÛ Ø¯ÛŒÚ¯Ø± `num_proc` Ù‚Ø¯Ø±ÙˆÚº Ú©Û’ Ù„ÛŒÛ’ ÛÙ…Ø§Ø±Û’ Ù¹ÛŒØ³Ù¹ Ù†Û’ ÛŒÛ Ø¯Ú©Ú¾Ø§ÛŒØ§ Ú©Û `batched=True` Ú©Ùˆ Ø¨ØºÛŒØ± multiprocessing Ú©Û’ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±Ù†Ø§ Ø²ÛŒØ§Ø¯Û ØªÛŒØ² ØªÚ¾Ø§Û” Ø¹Ù…ÙˆÙ…ÛŒ Ø·ÙˆØ± Ù¾Ø±ØŒ ÛÙ… fast tokenizers Ú©Û’ Ù„ÛŒÛ’ `batched=True` Ú©Û’ Ø³Ø§ØªÚ¾ Python multiprocessing Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±Ù†Û’ Ú©ÛŒ Ø³ÙØ§Ø±Ø´ Ù†ÛÛŒÚº Ú©Ø±ØªÛ’Û”

<Tip>

Ø§Ù¾Ù†ÛŒ processing Ú©ÛŒ Ø±ÙØªØ§Ø± Ø¨Ú‘Ú¾Ø§Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ `num_proc` Ú©Ø§ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ø¹Ø§Ù… Ø·ÙˆØ± Ù¾Ø± Ø§Ú†Ú¾Ø§ Ø®ÛŒØ§Ù„ ÛÛ’ØŒ Ø¨Ø´Ø±Ø·ÛŒÚ©Û Ø¢Ù¾ Ø¬Ùˆ ÙÙ†Ú©Ø´Ù† Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø± Ø±ÛÛ’ ÛÛŒÚº ÙˆÛ Ù¾ÛÙ„Û’ Ø³Û’ ÛÛŒ Ú©Ø³ÛŒ Ù‚Ø³Ù… Ú©ÛŒ multiprocessing Ù†Û Ú©Ø± Ø±ÛØ§ ÛÙˆÛ”

</Tip>

ÛŒÛ ØªÙ…Ø§Ù… Ø®ØµÙˆØµÛŒØ§Øª Ø§ÛŒÚ© ÛÛŒ Ù…ÛŒØªÚ¾Úˆ Ù…ÛŒÚº Ø³Ù…Ù¹ Ú©Ø± Ú©Ø§ÙÛŒ Ø­ÛŒØ±Ø§Ù† Ú©Ù† ÛÛŒÚºØŒ Ù…Ú¯Ø± Ø§Ø¨Ú¾ÛŒ Ø§ÙˆØ± Ø¨Ú¾ÛŒ Ø¨ÛØª Ú©Ú†Ú¾ ÛÛ’! `Dataset.map()` Ø§ÙˆØ± `batched=True` Ú©Û’ Ø³Ø§ØªÚ¾ Ø¢Ù¾ Ø§Ù¾Ù†Û’ ÚˆÛŒÙ¹Ø§Ø³ÛŒÙ¹ Ù…ÛŒÚº Ù…ÙˆØ¬ÙˆØ¯ Ø¹Ù†Ø§ØµØ± Ú©ÛŒ ØªØ¹Ø¯Ø§Ø¯ Ú©Ùˆ Ø¨Ú¾ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ú©Ø± Ø³Ú©ØªÛ’ ÛÛŒÚºÛ” ÛŒÛ Ø¨ÛØª Ø³ÛŒ ØµÙˆØ±ØªÙˆÚº Ù…ÛŒÚº Ù…ÙÛŒØ¯ ÛÛ’ Ø¬ÛØ§Úº Ø¢Ù¾ Ø§ÛŒÚ© Ù…Ø«Ø§Ù„ Ø³Û’ Ù…ØªØ¹Ø¯Ø¯ ØªØ±Ø¨ÛŒØªÛŒ ÙÛŒÚ†Ø±Ø² ØªØ®Ù„ÛŒÙ‚ Ú©Ø±Ù†Ø§ Ú†Ø§ÛØªÛ’ ÛÛŒÚºØŒ Ø§ÙˆØ± ÛÙ…ÛŒÚº ÛŒÛ Ú©Ø¦ÛŒ NLP Ú©Ø§Ù…ÙˆÚº Ú©ÛŒ preprocessing Ù…ÛŒÚº Ú©Ø±Ù†Û’ Ú©ÛŒ Ø¶Ø±ÙˆØ±Øª ÛÙˆÚ¯ÛŒ Ø¬Ùˆ ÛÙ… [Ø¨Ø§Ø¨ 7](/course/chapter7) Ù…ÛŒÚº Ú©Ø±ÛŒÚº Ú¯Û’Û”

<Tip>

ğŸ’¡ Ù…Ø´ÛŒÙ† Ù„Ø±Ù†Ù†Ú¯ Ù…ÛŒÚºØŒ Ø§ÛŒÚ© _example_ Ø¹Ø§Ù… Ø·ÙˆØ± Ù¾Ø± ÙˆÛ ÙÛŒÚ†Ø±Ø² Ú©Ø§ Ù…Ø¬Ù…ÙˆØ¹Û ÛÙˆØªØ§ ÛÛ’ Ø¬Ùˆ ÛÙ… Ù…Ø§ÚˆÙ„ Ú©Ùˆ Ø¯ÛŒØªÛ’ ÛÛŒÚºÛ” Ú©Ú†Ú¾ Ù…ÙˆØ§Ù‚Ø¹ Ù¾Ø± ÛŒÛ ÙÛŒÚ†Ø±Ø² `Dataset` Ú©Û’ Ú©Ø§Ù„Ù…Ø² Ú©Ø§ Ù…Ø¬Ù…ÙˆØ¹Û ÛÙˆØªÛ’ ÛÛŒÚºØŒ Ù…Ú¯Ø± Ø¨Ø¹Ø¶ Ù…ÙˆØ§Ù‚Ø¹ (Ø¬ÛŒØ³Û’ ÛŒÛØ§Úº Ø§ÙˆØ± Ø³ÙˆØ§Ù„ Ø¬ÙˆØ§Ø¨ Ú©Û’ Ù„ÛŒÛ’) Ø§ÛŒÚ© ÛÛŒ Ù…Ø«Ø§Ù„ Ø³Û’ Ù…ØªØ¹Ø¯Ø¯ ÙÛŒÚ†Ø±Ø² Ù†Ú©Ø§Ù„Û’ Ø¬Ø§ Ø³Ú©ØªÛ’ ÛÛŒÚº Ø¬Ùˆ Ø§ÛŒÚ© ÛÛŒ Ú©Ø§Ù„Ù… Ù…ÛŒÚº Ø´Ø§Ù…Ù„ ÛÙˆ Ø³Ú©ØªÛ’ ÛÛŒÚºÛ”

</Tip>

Ø¢Ø¦ÛŒÚº Ø¯ÛŒÚ©Ú¾ØªÛ’ ÛÛŒÚº Ú©Û ÛŒÛ Ú©ÛŒØ³Û’ Ú©Ø§Ù… Ú©Ø±ØªØ§ ÛÛ’! ÛŒÛØ§Úº ÛÙ… Ø§Ù¾Ù†ÛŒ Ù…Ø«Ø§Ù„ÙˆÚº Ú©Ùˆ tokenize Ú©Ø±ÛŒÚº Ú¯Û’ Ø§ÙˆØ± Ø§Ù†ÛÛŒÚº Ø²ÛŒØ§Ø¯Û Ø³Û’ Ø²ÛŒØ§Ø¯Û 128 tokens ØªÚ© truncate Ú©Ø±ÛŒÚº Ú¯Û’ØŒ Ù…Ú¯Ø± ÛÙ… Ù¹ÙˆÚ©Ù†Ø§Ø¦Ø²Ø± Ø³Û’ ÛŒÛ Ú†Ø§ÛÛŒÚº Ú¯Û’ Ú©Û ÙˆÛ texts Ú©Û’ *ØªÙ…Ø§Ù…* Ø­ØµÛ’ ÙˆØ§Ù¾Ø³ Ú©Ø±Û’ Ù†Û Ú©Û ØµØ±Ù Ù¾ÛÙ„Ø§Û” ÛŒÛ `return_overflowing_tokens=True` Ú©Û’ Ø°Ø±ÛŒØ¹Û’ Ú©ÛŒØ§ Ø¬Ø§ Ø³Ú©ØªØ§ ÛÛ’:

```py
def tokenize_and_split(examples):
    return tokenizer(
        examples["review"],
        truncation=True,
        max_length=128,
        return_overflowing_tokens=True,
    )
```

Ø¢Ø¦ÛŒÚº Ø§Ø³Û’ Ù¾ÙˆØ±Û’ ÚˆÛŒÙ¹Ø§Ø³ÛŒÙ¹ Ù¾Ø± `Dataset.map()` Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±Ù†Û’ Ø³Û’ Ù¾ÛÙ„Û’ Ø§ÛŒÚ© Ù…Ø«Ø§Ù„ Ù¾Ø± Ù¹ÛŒØ³Ù¹ Ú©Ø±ØªÛ’ ÛÛŒÚº:

```py
result = tokenize_and_split(drug_dataset["train"][0])
[len(inp) for inp in result["input_ids"]]
```

```python
[128, 49]
```

ØªÙˆØŒ ÛÙ…Ø§Ø±ÛŒ Ù¾ÛÙ„ÛŒ Ù…Ø«Ø§Ù„ Ø¬Ùˆ Ù¹Ø±ÛŒÙ†Ù†Ú¯ Ø³ÛŒÙ¹ Ù…ÛŒÚº ØªÚ¾ÛŒØŒ Ø¯Ùˆ ÙÛŒÚ†Ø±Ø² Ù…ÛŒÚº ØªÙ‚Ø³ÛŒÙ… ÛÙˆ Ú¯Ø¦ÛŒ Ú©ÛŒÙˆÙ†Ú©Û Ø§Ø³Û’ tokenize Ú©Ø±ØªÛ’ ÙˆÙ‚Øª 128 tokens Ø³Û’ Ø²ÛŒØ§Ø¯Û tokens Ø¨Ù† Ú¯Ø¦Û’: Ù¾ÛÙ„Ø§ 128 tokens Ú©Ø§ Ø§ÙˆØ± Ø¯ÙˆØ³Ø±Ø§ 49 tokens Ú©Ø§Û” Ø§Ø¨ Ø¢Ø¦ÛŒÚº Ø§Ø³Û’ Ù¾ÙˆØ±Û’ ÚˆÛŒÙ¹Ø§Ø³ÛŒÙ¹ Ù¾Ø± Ú©Ø±ÛŒÚº!

```py
tokenized_dataset = drug_dataset.map(tokenize_and_split, batched=True)
```

```python
ArrowInvalid: Column 1 named condition expected length 1463 but got length 1000
```

Ø§ÙˆÛ Ù†ÛÛŒÚº! ÛŒÛ Ú©Ø§Ù… Ù†ÛÛŒÚº Ú©Ø± Ø±ÛØ§! Ú©ÛŒÙˆÚºØŸ ØºÙ„Ø·ÛŒ Ú©Û’ Ù¾ÛŒØºØ§Ù… Ú©Ùˆ Ø¯ÛŒÚ©Ú¾ Ú©Ø± ÛÙ…ÛŒÚº Ø³Ø±Ø§Øº Ù…Ù„ØªØ§ ÛÛ’ Ú©Û Ø§ÛŒÚ© Ú©Ø§Ù„Ù… Ú©ÛŒ Ù„Ù…Ø¨Ø§Ø¦ÛŒ Ù…ÛŒÚº Ù…ÛŒÙ„ Ù†ÛÛŒÚº Ú©Ú¾Ø§ Ø±ÛÛŒ: Ø§ÛŒÚ© Ú©Ø§Ù„Ù… Ú©ÛŒ Ù„Ù…Ø¨Ø§Ø¦ÛŒ 1,463 ÛÛ’ Ø¬Ø¨Ú©Û Ø¯ÙˆØ³Ø±Û’ Ú©ÛŒ 1,000 ÛÛ’Û” Ø§Ú¯Ø± Ø¢Ù¾ Ù†Û’ `Dataset.map()` Ú©ÛŒ [Ø¯Ø³ØªØ§ÙˆÛŒØ²Ø§Øª](https://huggingface.co/docs/datasets/package_reference/main_classes#datasets.Dataset.map) Ø¯ÛŒÚ©Ú¾ÛŒ ÛÙˆ ØªÙˆ Ø¢Ù¾ Ú©Ùˆ ÛŒØ§Ø¯ ÛÙˆÚ¯Ø§ Ú©Û Ø¬Ø³ ØªØ¹Ø¯Ø§Ø¯ Ú©ÛŒ Ù…Ø«Ø§Ù„ÛŒÚº ÙÙ†Ú©Ø´Ù† Ú©Ùˆ Ø¯ÛŒ Ø¬Ø§ØªÛŒ ÛÛŒÚºØŒ ÙˆÛÛŒ ØªØ¹Ø¯Ø§Ø¯ Ù†Ø¦Û’ ÚˆÛŒÙ¹Ø§ Ú©ÛŒ ÛÙˆÙ†ÛŒ Ú†Ø§ÛÛŒÛ’Ø› ÛŒÛØ§Úº 1,000 Ù…Ø«Ø§Ù„ÛŒÚº 1,463 Ù†Ø¦Û’ ÙÛŒÚ†Ø±Ø² Ù…ÛŒÚº ØªØ¨Ø¯ÛŒÙ„ ÛÙˆ Ú¯Ø¦ÛŒ ÛÛŒÚºØŒ Ø¬Ø³ Ø³Û’ shape error Ø¢ Ú¯ÛŒØ§Û”

Ù…Ø³Ø¦Ù„Û ÛŒÛ ÛÛ’ Ú©Û ÛÙ… Ø¯Ùˆ Ù…Ø®ØªÙ„Ù Ø³Ø§Ø¦Ø² Ú©Û’ ÚˆÛŒÙ¹Ø§Ø³ÛŒÙ¹Ø³ Ú©Ùˆ Ù…Ù„Ø§ Ø±ÛÛ’ ÛÛŒÚº: `drug_dataset` Ú©Û’ Ú©Ø§Ù„Ù…Ø² Ù…ÛŒÚº Ø§ÛŒÚ© Ù…Ø®ØµÙˆØµ ØªØ¹Ø¯Ø§Ø¯ Ú©ÛŒ Ù…Ø«Ø§Ù„ÛŒÚº (ÛÙ…Ø§Ø±Û’ error Ù…ÛŒÚº 1,000) ÛÙˆÚº Ú¯ÛŒØŒ Ù…Ú¯Ø± `tokenized_dataset` Ù…ÛŒÚº Ø²ÛŒØ§Ø¯Û (error Ù¾ÛŒØºØ§Ù… Ù…ÛŒÚº 1,463) Ú©ÛŒÙˆÙ†Ú©Û ÛÙ… Ù„Ù…Ø¨Û’ Ø±ÛŒÙˆÛŒÙˆØ² Ú©Ùˆ `return_overflowing_tokens=True` Ú©Û’ Ø°Ø±ÛŒØ¹Û’ Ø§ÛŒÚ© Ø³Û’ Ø²ÛŒØ§Ø¯Û Ù…Ø«Ø§Ù„ÙˆÚº Ù…ÛŒÚº ØªÙ‚Ø³ÛŒÙ… Ú©Ø± Ø±ÛÛ’ ÛÛŒÚºÛ” ÛŒÛ Ø§ÛŒÚ© `Dataset` Ú©Û’ Ù„ÛŒÛ’ Ú©Ø§Ù… Ù†ÛÛŒÚº Ú©Ø±ØªØ§ØŒ Ù„ÛÙ°Ø°Ø§ ÛÙ…ÛŒÚº ÛŒØ§ ØªÙˆ Ù¾Ø±Ø§Ù†Û’ ÚˆÛŒÙ¹Ø§Ø³ÛŒÙ¹ Ú©Û’ Ú©Ø§Ù„Ù…Ø² Ú©Ùˆ ÛÙ¹Ø§ Ø¯ÛŒÙ†Ø§ ÛÙˆÚ¯Ø§ ÛŒØ§ Ø§Ù†ÛÛŒÚº Ù†Ø¦Û’ ÚˆÛŒÙ¹Ø§Ø³ÛŒÙ¹ Ú©Û’ Ø³Ø§Ø¦Ø² Ú©Û’ Ø¨Ø±Ø§Ø¨Ø± Ú©Ø±Ù†Ø§ ÛÙˆÚ¯Ø§Û” ÛÙ… Ù¾ÛÙ„Û’ Ø·Ø±ÛŒÙ‚Û’ Ú©Ùˆ `remove_columns` Ø¢Ø±Ú¯ÙˆÙ…Ù†Ù¹ Ú©Û’ Ø°Ø±ÛŒØ¹Û’ Ú©Ø± Ø³Ú©ØªÛ’ ÛÛŒÚº:

```py
tokenized_dataset = drug_dataset.map(
    tokenize_and_split, batched=True, remove_columns=drug_dataset["train"].column_names
)
```

Ø§Ø¨ ÛŒÛ Ø¨ØºÛŒØ± Ú©Ø³ÛŒ ØºÙ„Ø·ÛŒ Ú©Û’ Ú©Ø§Ù… Ú©Ø±ØªØ§ ÛÛ’Û” ÛÙ… ÚˆÛŒÙ¹Ø§ Ø³ÛŒÙ¹ Ú©ÛŒ Ù„Ù…Ø¨Ø§Ø¦ÛŒÙˆÚº Ú©Ø§ Ù…ÙˆØ§Ø²Ù†Û Ú©Ø±Ú©Û’ ØªØµØ¯ÛŒÙ‚ Ú©Ø± Ø³Ú©ØªÛ’ ÛÛŒÚº Ú©Û ÛÙ…Ø§Ø±Û’ Ù†Ø¦Û’ ÚˆÛŒÙ¹Ø§ Ø³ÛŒÙ¹ Ù…ÛŒÚº Ø§ØµÙ„ ÚˆÛŒÙ¹Ø§ Ø³ÛŒÙ¹ Ú©Û’ Ù…Ù‚Ø§Ø¨Ù„Û’ Ù…ÛŒÚº Ø²ÛŒØ§Ø¯Û Ø¹Ù†Ø§ØµØ± Ù…ÙˆØ¬ÙˆØ¯ ÛÛŒÚº:

```py
len(tokenized_dataset["train"]), len(drug_dataset["train"])
```

```python out
(206772, 138514)
```

ÛÙ… Ù†Û’ Ø°Ú©Ø± Ú©ÛŒØ§ ØªÚ¾Ø§ Ú©Û ÛÙ… ØºÛŒØ± Ù…Ù…Ø§Ø«Ù„ Ù„Ù…Ø¨Ø§Ø¦ÛŒ Ú©Û’ Ù…Ø³Ø¦Ù„Û’ Ø³Û’ Ø§Ø³ Ø·Ø±Ø­ Ø¨Ú¾ÛŒ Ù†Ù…Ù¹ Ø³Ú©ØªÛ’ ÛÛŒÚº Ú©Û Ù¾Ø±Ø§Ù†Û’ Ú©Ø§Ù„Ù…Ø² Ú©Ùˆ Ù†Ø¦Û’ Ú©Ø§Ù„Ù…Ø² Ú©Û’ Ø¨Ø±Ø§Ø¨Ø± Ø¨Ù†Ø§ Ø¯ÛŒÚºÛ” Ø§Ø³ Ú©Û’ Ù„ÛŒÛ’ ÛÙ…ÛŒÚº `overflow_to_sample_mapping` ÙÛŒÙ„Úˆ Ú©ÛŒ Ø¶Ø±ÙˆØ±Øª ÛÙˆÚ¯ÛŒØŒ Ø¬Ùˆ Ú©Û `tokenizer` Ø§Ø³ ÙˆÙ‚Øª ÙˆØ§Ù¾Ø³ Ú©Ø±ØªØ§ ÛÛ’ Ø¬Ø¨ ÛÙ… `return_overflowing_tokens=True` Ø³ÛŒÙ¹ Ú©Ø±ØªÛ’ ÛÛŒÚºÛ”  

ÛŒÛ ÛÙ…ÛŒÚº Ø§ÛŒÚ© Ù†ÛŒØ§ ÙÛŒÚ†Ø± Ø§Ù†ÚˆÛŒÚ©Ø³ Ø§Ø³ Ù†Ù…ÙˆÙ†Û’ (sample) Ú©Û’ Ø§Ù†ÚˆÛŒÚ©Ø³ Ø³Û’ Ù…Ù†Ø³Ù„Ú© Ú©Ø±Ù†Û’ Ú©ÛŒ Ø§Ø¬Ø§Ø²Øª Ø¯ÛŒØªØ§ ÛÛ’ Ø¬ÛØ§Úº Ø³Û’ ÛŒÛ Ù†Ú©Ù„Ø§ ØªÚ¾Ø§Û” Ø§Ø³ Ú©ÛŒ Ù…Ø¯Ø¯ Ø³Û’ØŒ ÛÙ… Ø§Ù¾Ù†Û’ Ø§ØµÙ„ ÚˆÛŒÙ¹Ø§ Ø³ÛŒÙ¹ Ù…ÛŒÚº Ù…ÙˆØ¬ÙˆØ¯ ÛØ± Ú©Ù„ÛŒØ¯ (key) Ú©Ùˆ Ø¯Ø±Ø³Øª Ø³Ø§Ø¦Ø² Ú©ÛŒ ÙˆÛŒÙ„ÛŒÙˆØ² Ú©ÛŒ ÙÛØ±Ø³Øª Ø³Û’ Ø¬ÙˆÚ‘ Ø³Ú©ØªÛ’ ÛÛŒÚºØŒ ÛŒØ¹Ù†ÛŒ ÛØ± Ù…Ø«Ø§Ù„ Ú©ÛŒ Ù‚Ø¯Ø±ÛŒÚº Ø§ØªÙ†ÛŒ Ø¨Ø§Ø± Ø¯ÛØ±Ø§Ø¦ÛŒ Ø¬Ø§ØªÛŒ ÛÛŒÚº Ø¬ØªÙ†ÛŒ Ø¨Ø§Ø± ÛŒÛ Ù†Ø¦Û’ ÙÛŒÚ†Ø±Ø² ØªØ®Ù„ÛŒÙ‚ Ú©Ø±ØªÛŒ ÛÛ’:


```py
def tokenize_and_split(examples):
    result = tokenizer(
        examples["review"],
        truncation=True,
        max_length=128,
        return_overflowing_tokens=True,
    )
    # Extract mapping between new and old indices
    sample_map = result.pop("overflow_to_sample_mapping")
    for key, values in examples.items():
        result[key] = [values[i] for i in sample_map]
    return result
```

ÛÙ… Ø¯ÛŒÚ©Ú¾ Ø³Ú©ØªÛ’ ÛÛŒÚº Ú©Û ÛŒÛ `Dataset.map()` Ú©Û’ Ø³Ø§ØªÚ¾ Ø¨ØºÛŒØ± Ù¾Ø±Ø§Ù†Û’ Ú©Ø§Ù„Ù…Ø² Ú©Ùˆ ÛÙ¹Ø§Ø¦Û’ Ú©Ø§Ù… Ú©Ø±ØªØ§ ÛÛ’:


```py
tokenized_dataset = drug_dataset.map(tokenize_and_split, batched=True)
tokenized_dataset
```

```python out
DatasetDict({
    train: Dataset({
        features: ['attention_mask', 'condition', 'date', 'drugName', 'input_ids', 'patient_id', 'rating', 'review', 'review_length', 'token_type_ids', 'usefulCount'],
        num_rows: 206772
    })
    test: Dataset({
        features: ['attention_mask', 'condition', 'date', 'drugName', 'input_ids', 'patient_id', 'rating', 'review', 'review_length', 'token_type_ids', 'usefulCount'],
        num_rows: 68876
    })
})
```

ÛÙ…ÛŒÚº ÙˆÛÛŒ ØªØ¹Ø¯Ø§Ø¯ Ù…ÛŒÚº Ù¹Ø±ÛŒÙ†Ù†Ú¯ ÙÛŒÚ†Ø±Ø² Ù…Ù„ØªÛŒ ÛÛŒÚº Ø¬ÛŒØ³Ø§ Ú©Û Ù¾ÛÙ„Û’ØŒ Ù„ÛŒÚ©Ù† ÛŒÛØ§Úº ÛÙ… Ù†Û’ ØªÙ…Ø§Ù… Ù¾Ø±Ø§Ù†Û’ ÙÛŒÙ„ÚˆØ² Ú©Ùˆ Ø¨Ø±Ù‚Ø±Ø§Ø± Ø±Ú©Ú¾Ø§ ÛÛ’Û” Ø§Ú¯Ø± Ø¢Ù¾ Ú©Ùˆ Ø§Ù¾Ù†Û’ Ù…Ø§ÚˆÙ„ Ú©Ùˆ Ù„Ø§Ú¯Ùˆ Ú©Ø±Ù†Û’ Ú©Û’ Ø¨Ø¹Ø¯ Ú©Ø³ÛŒ Ù¾ÙˆØ³Ù¹ Ù¾Ø±ÙˆØ³ÛŒØ³Ù†Ú¯ Ú©Û’ Ù„ÛŒÛ’ Ø§Ù† ÙÛŒÙ„ÚˆØ² Ú©ÛŒ Ø¶Ø±ÙˆØ±Øª ÛÙˆØŒ ØªÙˆ Ø¢Ù¾ Ø§Ø³ Ø·Ø±ÛŒÙ‚Û’ Ú©Ùˆ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±Ù†Ø§ Ú†Ø§ÛÛŒÚº Ú¯Û’Û”  

Ø§Ø¨ Ø¢Ù¾ Ù†Û’ Ø¯ÛŒÚ©Ú¾ Ù„ÛŒØ§ Ú©Û ğŸ¤— Datasets Ú©Ùˆ Ù…Ø®ØªÙ„Ù Ø·Ø±ÛŒÙ‚ÙˆÚº Ø³Û’ ÚˆÛŒÙ¹Ø§ Ø³ÛŒÙ¹ Ú©ÛŒ Ù¾Ø±ÛŒ Ù¾Ø±ÙˆØ³ÛŒØ³Ù†Ú¯ Ú©Û’ Ù„ÛŒÛ’ Ú©ÛŒØ³Û’ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©ÛŒØ§ Ø¬Ø§ Ø³Ú©ØªØ§ ÛÛ’Û” Ø§Ú¯Ø±Ú†Û ğŸ¤— Datasets Ú©ÛŒ Ù¾Ø±ÙˆØ³ÛŒØ³Ù†Ú¯ ÙÙ†Ú©Ø´Ù†Ø² Ø²ÛŒØ§Ø¯Û ØªØ± Ù…Ø§ÚˆÙ„ Ù¹Ø±ÛŒÙ†Ù†Ú¯ Ú©ÛŒ Ø¶Ø±ÙˆØ±ÛŒØ§Øª Ú©Ùˆ Ù¾ÙˆØ±Ø§ Ú©Ø± Ù„ÛŒØªÛŒ ÛÛŒÚºØŒ Ù„ÛŒÚ©Ù† Ú©Ú†Ú¾ Ù…ÙˆØ§Ù‚Ø¹ Ù¾Ø± Ø¢Ù¾ Ú©Ùˆ Ù…Ø²ÛŒØ¯ Ø·Ø§Ù‚ØªÙˆØ± ÙÛŒÚ†Ø±Ø² ØªÚ© Ø±Ø³Ø§Ø¦ÛŒ Ú©Û’ Ù„ÛŒÛ’ Pandas Ú©ÛŒ Ø·Ø±Ù Ø¬Ø§Ù†Ø§ Ù¾Ú‘ Ø³Ú©ØªØ§ ÛÛ’ØŒ Ø¬ÛŒØ³Û’ `DataFrame.groupby()` ÛŒØ§ ÚˆÛŒÙ¹Ø§ Ú©ÛŒ Ø¨ØµØ±ÛŒ Ù†Ù…Ø§Ø¦Ù†Ø¯Ú¯ÛŒ Ú©Û’ Ù„ÛŒÛ’ ÛØ§Ø¦ÛŒ Ù„ÛŒÙˆÙ„ APIsÛ”  

Ø®ÙˆØ´ Ù‚Ø³Ù…ØªÛŒ Ø³Û’ØŒ ğŸ¤— Datasets Ú©Ùˆ PandasØŒ NumPyØŒ PyTorchØŒ TensorFlowØŒ Ø§ÙˆØ± JAX Ø¬ÛŒØ³ÛŒ Ù„Ø§Ø¦Ø¨Ø±ÛŒØ±ÛŒÙˆÚº Ú©Û’ Ø³Ø§ØªÚ¾ Ú©Ø§Ù… Ú©Ø±Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ ÚˆÛŒØ²Ø§Ø¦Ù† Ú©ÛŒØ§ Ú¯ÛŒØ§ ÛÛ’Û” Ø¢Ø¦ÛŒÛ’ Ø¯ÛŒÚ©Ú¾ØªÛ’ ÛÛŒÚº Ú©Û ÛŒÛ Ú©ÛŒØ³Û’ Ú©Ø§Ù… Ú©Ø±ØªØ§ ÛÛ’Û”  

## `Dataset` Ø³Û’ `DataFrame` Ø§ÙˆØ± ÙˆØ§Ù¾Ø³

<Youtube id="tfcY1067A5Q"/>

Ù…Ø®ØªÙ„Ù ØªÚ¾Ø±Úˆ Ù¾Ø§Ø±Ù¹ÛŒ Ù„Ø§Ø¦Ø¨Ø±ÛŒØ±ÛŒÙˆÚº Ú©Û’ Ø¯Ø±Ù…ÛŒØ§Ù† Ú©Ù†ÙˆØ±Ú˜Ù† Ú©Ùˆ Ù…Ù…Ú©Ù† Ø¨Ù†Ø§Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ØŒ ğŸ¤— Datasets Ø§ÛŒÚ© `Dataset.set_format()` ÙÙ†Ú©Ø´Ù† ÙØ±Ø§ÛÙ… Ú©Ø±ØªØ§ ÛÛ’Û” ÛŒÛ ÙÙ†Ú©Ø´Ù† ØµØ±Ù ÚˆÛŒÙ¹Ø§ Ø³ÛŒÙ¹ Ú©Ø§ **Ø¢Ø¤Ù¹ Ù¾Ù¹ ÙØ§Ø±Ù…ÛŒÙ¹** ØªØ¨Ø¯ÛŒÙ„ Ú©Ø±ØªØ§ ÛÛ’ØŒ Ù„ÛØ°Ø§ Ø¢Ù¾ Ø¢Ø³Ø§Ù†ÛŒ Ø³Û’ Ú©Ø³ÛŒ Ø¯ÙˆØ³Ø±Û’ ÙØ§Ø±Ù…ÛŒÙ¹ Ù¾Ø± Ø³ÙˆØ¦Ú† Ú©Ø± Ø³Ú©ØªÛ’ ÛÛŒÚº Ø¨ØºÛŒØ± Ø¨Ù†ÛŒØ§Ø¯ÛŒ **ÚˆÛŒÙ¹Ø§ ÙØ§Ø±Ù…ÛŒÙ¹** (Ø¬Ùˆ Ú©Û Apache Arrow ÛÛ’) Ú©Ùˆ Ù…ØªØ§Ø«Ø± Ú©ÛŒÛ’Û”  

ÛŒÛ ÙØ§Ø±Ù…ÛŒÙ¹Ù†Ú¯ **Ø§ØµÙ„ ÚˆÛŒÙ¹Ø§ Ø³ÛŒÙ¹ Ù¾Ø± Ø¨Ø±Ø§Û Ø±Ø§Ø³Øª** Ù„Ø§Ú¯Ùˆ ÛÙˆØªÛŒ ÛÛ’Û” Ø¢Ø¦ÛŒÛ’ Ø§ÛŒÚ© Ù…Ø«Ø§Ù„ Ú©Û’ Ø°Ø±ÛŒØ¹Û’ Ø¯ÛŒÚ©Ú¾ØªÛ’ ÛÛŒÚº Ú©Û ÛÙ… Ø§Ù¾Ù†Û’ ÚˆÛŒÙ¹Ø§ Ø³ÛŒÙ¹ Ú©Ùˆ Pandas Ù…ÛŒÚº Ú©ÛŒØ³Û’ ØªØ¨Ø¯ÛŒÙ„ Ú©Ø± Ø³Ú©ØªÛ’ ÛÛŒÚº:


```py
drug_dataset.set_format("pandas")
```

Ø§Ø¨ Ø¬Ø¨ ÛÙ… ÚˆÛŒÙ¹Ø§ Ø³ÛŒÙ¹ Ú©Û’ Ø¹Ù†Ø§ØµØ± ØªÚ© Ø±Ø³Ø§Ø¦ÛŒ Ø­Ø§ØµÙ„ Ú©Ø±ØªÛ’ ÛÛŒÚºØŒ ØªÙˆ ÛÙ…ÛŒÚº Ù„ØºØª (dictionary) Ú©ÛŒ Ø¨Ø¬Ø§Ø¦Û’ Ø§ÛŒÚ© `pandas.DataFrame` Ù…Ù„ØªØ§ ÛÛ’:

```py
drug_dataset["train"][:3]
```

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>patient_id</th>
      <th>drugName</th>
      <th>condition</th>
      <th>review</th>
      <th>rating</th>
      <th>date</th>
      <th>usefulCount</th>
      <th>review_length</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>95260</td>
      <td>Guanfacine</td>
      <td>adhd</td>
      <td>"My son is halfway through his fourth week of Intuniv..."</td>
      <td>8.0</td>
      <td>April 27, 2010</td>
      <td>192</td>
      <td>141</td>
    </tr>
    <tr>
      <th>1</th>
      <td>92703</td>
      <td>Lybrel</td>
      <td>birth control</td>
      <td>"I used to take another oral contraceptive, which had 21 pill cycle, and was very happy- very light periods, no other side effects..."</td>
      <td>5.0</td>
      <td>December 14, 2009</td>
      <td>17</td>
      <td>134</td>
    </tr>
    <tr>
      <th>2</th>
      <td>138000</td>
      <td>Ortho Evra</td>
      <td>birth control</td>
      <td>"This is my first time using any form of birth control..."</td>
      <td>8.0</td>
      <td>November 3, 2015</td>
      <td>10</td>
      <td>89</td>
    </tr>
  </tbody>
</table>

Ø¢Ø¦ÛŒÚº Ù¾ÙˆØ±Û’ Ù¹Ø±ÛŒÙ†Ù†Ú¯ Ø³ÛŒÙ¹ Ú©Ø§ `pandas.DataFrame` Ø¨Ù†Ø§ØªÛ’ ÛÛŒÚº:

```py
train_df = drug_dataset["train"][:]
```

<Tip>

ğŸš¨ Ø¯Ø±Ø§ØµÙ„ØŒ `Dataset.set_format()` ÚˆÛŒÙ¹Ø§Ø³ÛŒÙ¹ Ú©Û’ `__getitem__()` dunder method Ú©Û’ output format Ú©Ùˆ ØªØ¨Ø¯ÛŒÙ„ Ú©Ø±ØªØ§ ÛÛ’Û” Ø§Ø³ Ú©Ø§ Ù…Ø·Ù„Ø¨ ÛÛ’ Ú©Û Ø¬Ø¨ ÛÙ… `drug_dataset["train"]` Ú©Ùˆ `"pandas"` ÙØ§Ø±Ù…ÛŒÙ¹ Ù…ÛŒÚº Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±ØªÛ’ ÛÛŒÚºØŒ ØªØ¨ Ø¨Ú¾ÛŒ Ø§Ø³ Ú©Ø§ Ø§ØµÙ„ Ù¹Ø§Ø¦Ù¾ `Dataset` ÛÛŒ Ø±ÛØªØ§ ÛÛ’Û” Ù„ÛŒÚ©Ù† slicing Ú©Ø±Ù†Û’ Ù¾Ø± Ø§ÛŒÚ© `pandas.DataFrame` Ø­Ø§ØµÙ„ ÛÙˆØªØ§ ÛÛ’Û”

</Tip>

Ø§Ø¨ ÛÙ… Pandas Ú©ÛŒ ØªÙ…Ø§Ù… Ø®ØµÙˆØµÛŒØ§Øª Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø± Ø³Ú©ØªÛ’ ÛÛŒÚºÛ” Ù…Ø«Ø§Ù„ Ú©Û’ Ø·ÙˆØ± Ù¾Ø±ØŒ ÛÙ… chaining Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø± Ú©Û’ `condition` entries Ù…ÛŒÚº class distribution Ù…Ø¹Ù„ÙˆÙ… Ú©Ø± Ø³Ú©ØªÛ’ ÛÛŒÚº:

```py
frequencies = (
    train_df["condition"]
    .value_counts()
    .to_frame()
    .reset_index()
    .rename(columns={"index": "condition", "condition": "frequency"})
)
frequencies.head()
```

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>condition</th>
      <th>frequency</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>birth control</td>
      <td>27655</td>
    </tr>
    <tr>
      <th>1</th>
      <td>depression</td>
      <td>8023</td>
    </tr>
    <tr>
      <th>2</th>
      <td>acne</td>
      <td>5209</td>
    </tr>
    <tr>
      <th>3</th>
      <td>anxiety</td>
      <td>4991</td>
    </tr>
    <tr>
      <th>4</th>
      <td>pain</td>
      <td>4744</td>
    </tr>
  </tbody>
</table>

Ø§ÙˆØ± Ø¬Ø¨ Ø¢Ù¾ Ø§Ù¾Ù†ÛŒ Pandas ØªØ¬Ø²ÛŒÛ Ú©Ø§Ø±ÛŒ Ù…Ú©Ù…Ù„ Ú©Ø± Ù„ÛŒÚºØŒ Ø¢Ù¾ `Dataset.from_pandas()` ÙÙ†Ú©Ø´Ù† Ú©Ø§ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø± Ú©Û’ Ø§ÛŒÚ© Ù†ÛŒØ§ `Dataset` Ø¢Ø¨Ø¬ÛŒÚ©Ù¹ Ø¨Ú¾ÛŒ Ø¨Ù†Ø§ Ø³Ú©ØªÛ’ ÛÛŒÚº:

```py
from datasets import Dataset

freq_dataset = Dataset.from_pandas(frequencies)
freq_dataset
```

```python
Dataset({
    features: ['condition', 'frequency'],
    num_rows: 819
})
```

<Tip>

âœï¸ **Ø¢Ø²Ù…Ø§Ø¦ÛŒÚº!** ÛØ± Ø¯ÙˆØ§ Ú©ÛŒ Ø§ÙˆØ³Ø· Ø±ÛŒÙ¹Ù†Ú¯ Ù…Ø¹Ù„ÙˆÙ… Ú©Ø±ÛŒÚº Ø§ÙˆØ± Ù†ØªÛŒØ¬Û Ú©Ùˆ Ø§ÛŒÚ© Ù†Ø¦Û’ `Dataset` Ù…ÛŒÚº Ø§Ø³Ù¹ÙˆØ± Ú©Ø±ÛŒÚºÛ”

</Tip>

ÛŒÛ ÛÙ…Ø§Ø±ÛŒ ğŸ¤— Datasets Ú©Û’ Ø°Ø±ÛŒØ¹Û’ ÚˆÛŒÙ¹Ø§ Ù¾Ø±ÛŒ Ù¾Ø±Ø§Ø³ÛŒØ³Ù†Ú¯ Ú©ÛŒ Ù…Ø®ØªÙ„Ù ØªÚ©Ù†ÛŒÚ©ÙˆÚº Ú©Ø§ Ø¬Ø§Ø¦Ø²Û Ø®ØªÙ… Ú©Ø±ØªØ§ ÛÛ’Û” Ø§Ø³ Ø³ÛŒÚ©Ø´Ù† Ú©Ùˆ Ø®ØªÙ… Ú©Ø±Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ØŒ Ø¢Ø¦ÛŒÚº Ø§ÛŒÚ© validation set ØªØ®Ù„ÛŒÙ‚ Ú©Ø±ØªÛ’ ÛÛŒÚº ØªØ§Ú©Û classifier Ú©ÛŒ ØªØ±Ø¨ÛŒØª Ú©Û’ Ù„ÛŒÛ’ ÚˆÛŒÙ¹Ø§Ø³ÛŒÙ¹ ØªÛŒØ§Ø± ÛÙˆ Ø¬Ø§Ø¦Û’Û” Ø§Ø³ Ø³Û’ Ù¾ÛÙ„Û’ Ú©Û ÛÙ… Ø§ÛŒØ³Ø§ Ú©Ø±ÛŒÚºØŒ ÛÙ… Ø§Ù¾Ù†Û’ `drug_dataset` Ú©Ø§ output format `"pandas"` Ø³Û’ `"arrow"` Ù…ÛŒÚº ÙˆØ§Ù¾Ø³ ØªØ¨Ø¯ÛŒÙ„ Ú©Ø± Ø¯ÛŒØªÛ’ ÛÛŒÚº:

```py
drug_dataset.reset_format()
```

## Ø§ÛŒÚ© validation set ØªØ®Ù„ÛŒÙ‚ Ú©Ø±Ù†Ø§[[creating-a-validation-set]]

Ø§Ú¯Ø±Ú†Û ÛÙ…Ø§Ø±Û’ Ù¾Ø§Ø³ Ø¬Ø§Ù†Ú† (test) set Ù…ÙˆØ¬ÙˆØ¯ ÛÛ’ØŒ Ø¨ÛØªØ± ÛŒÛ ÛÛ’ Ú©Û Ø§Ø³Û’ Ø¨ØºÛŒØ± Ú†Ú¾ÙˆØ¦Û’ Ø§ÛŒÚ© Ø¹Ù„ÛŒØ­Ø¯Û validation set Ø¨Ù†Ø§ÛŒØ§ Ø¬Ø§Ø¦Û’ ØªØ§Ú©Û ØªØ±Ù‚ÛŒ Ú©Û’ Ø¯ÙˆØ±Ø§Ù† Ù…Ø§ÚˆÙ„ Ú©Ùˆ Ø¬Ø§Ù†Ú†Ø§ Ø¬Ø§ Ø³Ú©Û’Û” Ø¬Ø¨ Ø¢Ù¾ validation set Ù¾Ø± Ù…Ø§ÚˆÙ„ Ú©ÛŒ Ú©Ø§Ø±Ú©Ø±Ø¯Ú¯ÛŒ Ø³Û’ Ù…Ø·Ù…Ø¦Ù† ÛÙˆ Ø¬Ø§Ø¦ÛŒÚºØŒ ØªØ¨ Ø¢Ù¾ test set Ù¾Ø± Ø­ØªÙ…ÛŒ Ø¬Ø§Ù†Ú† Ú©Ø± Ø³Ú©ØªÛ’ ÛÛŒÚºÛ” Ø§Ø³ Ø¹Ù…Ù„ Ø³Û’ ÛŒÛ ÛŒÙ‚ÛŒÙ†ÛŒ Ø¨Ù†ØªØ§ ÛÛ’ Ú©Û Ø¢Ù¾ test set Ù¾Ø± overfit Ù†Û ÛÙˆ Ø¬Ø§Ø¦ÛŒÚº Ø§ÙˆØ± Ø­Ù‚ÛŒÙ‚ÛŒ Ø¯Ù†ÛŒØ§ Ú©Û’ ÚˆÛŒÙ¹Ø§ Ù¾Ø± Ù…Ø§ÚˆÙ„ Ø§Ú†Ú¾ÛŒ Ú©Ø§Ø±Ú©Ø±Ø¯Ú¯ÛŒ Ø¯Ú©Ú¾Ø§Ø¦Û’Û”

ğŸ¤— Datasets `Dataset.train_test_split()` ÙÙ†Ú©Ø´Ù† ÙØ±Ø§ÛÙ… Ú©Ø±ØªØ§ ÛÛ’ Ø¬Ùˆ scikit-learn Ú©ÛŒ Ù…Ø´ÛÙˆØ± ÙØ¹Ø§Ù„ÛŒØª Ù¾Ø± Ù…Ø¨Ù†ÛŒ ÛÛ’Û” Ø¢Ø¦ÛŒÚº Ø§Ø³Û’ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø± Ú©Û’ Ø§Ù¾Ù†Û’ training set Ú©Ùˆ `train` Ø§ÙˆØ± `validation` Ø³Ù¾Ù„Ù¹Ø³ Ù…ÛŒÚº ØªÙ‚Ø³ÛŒÙ… Ú©Ø±ØªÛ’ ÛÛŒÚº (reproducibility Ú©Û’ Ù„ÛŒÛ’ seed Ø³ÛŒÙ¹ Ú©Ø±ÛŒÚº):

```py
drug_dataset_clean = drug_dataset["train"].train_test_split(train_size=0.8, seed=42)
# ÚˆÛŒÙØ§Ù„Ù¹ "test" Ø³Ù¾Ù„Ù¹ Ú©Ø§ Ù†Ø§Ù… ØªØ¨Ø¯ÛŒÙ„ Ú©Ø± Ú©Û’ "validation" Ú©Ø± Ø¯ÛŒÚº
drug_dataset_clean["validation"] = drug_dataset_clean.pop("test")
# "test" Ø³ÛŒÙ¹ Ú©Ùˆ ÛÙ…Ø§Ø±Û’ DatasetDict Ù…ÛŒÚº Ø´Ø§Ù…Ù„ Ú©Ø±ÛŒÚº
drug_dataset_clean["test"] = drug_dataset["test"]
drug_dataset_clean
```

```python
DatasetDict({
    train: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'review_clean'],
        num_rows: 110811
    })
    validation: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'review_clean'],
        num_rows: 27703
    })
    test: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'review_clean'],
        num_rows: 46108
    })
})
```

Ø²Ø¨Ø±Ø¯Ø³ØªØŒ Ø§Ø¨ ÛÙ…Ø§Ø±Û’ Ù¾Ø§Ø³ Ø§ÛŒÚ© Ø§ÛŒØ³Ø§ ÚˆÛŒÙ¹Ø§Ø³ÛŒÙ¹ ØªÛŒØ§Ø± ÛÛ’ Ø¬Ùˆ Ù…Ø§ÚˆÙ„Ø² Ú©ÛŒ ØªØ±Ø¨ÛŒØª Ú©Û’ Ù„ÛŒÛ’ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©ÛŒØ§ Ø¬Ø§ Ø³Ú©ØªØ§ ÛÛ’! [Ø¨Ø§Ø¨ 5](/course/chapter5/5) Ù…ÛŒÚº ÛÙ… Ø¯Ú©Ú¾Ø§Ø¦ÛŒÚº Ú¯Û’ Ú©Û Ú©Ø³ Ø·Ø±Ø­ ÚˆÛŒÙ¹Ø§Ø³ÛŒÙ¹Ø³ Ú©Ùˆ Hugging Face Hub Ù¾Ø± Ø§Ù¾Ù„ÙˆÚˆ Ú©ÛŒØ§ Ø¬Ø§ Ø³Ú©ØªØ§ ÛÛ’ØŒ Ù…Ú¯Ø± Ø§Ø¨Ú¾ÛŒ ÛÙ… Ø§Ù¾Ù†Û’ ØªØ¬Ø²ÛŒÛ’ Ú©Ùˆ Ø®ØªÙ… Ú©Ø±ØªÛ’ ÛÙˆØ¦Û’ ÛŒÛ Ø¯ÛŒÚ©Ú¾ÛŒÚº Ú¯Û’ Ú©Û Ø¢Ù¾ Ø§Ù¾Ù†Û’ Ù…Ù‚Ø§Ù…ÛŒ Ù…Ø´ÛŒÙ† Ù¾Ø± ÚˆÛŒÙ¹Ø§Ø³ÛŒÙ¹Ø³ Ú©Ùˆ Ú©Ø³ Ø·Ø±Ø­ Ù…Ø­ÙÙˆØ¸ Ú©Ø± Ø³Ú©ØªÛ’ ÛÛŒÚºÛ”

## Ø§ÛŒÚ© ÚˆÛŒÙ¹Ø§Ø³ÛŒÙ¹ Ù…Ø­ÙÙˆØ¸ Ú©Ø±Ù†Ø§[[saving-a-dataset]]

<Youtube id="blF9uxYcKHo"/>

Ø§Ú¯Ø±Ú†Û ğŸ¤— Datasets ÛØ± ÚˆØ§Ø¤Ù† Ù„ÙˆÚˆ Ø´Ø¯Û ÚˆÛŒÙ¹Ø§Ø³ÛŒÙ¹ Ø§ÙˆØ± Ø§Ø³ Ù¾Ø± Ú©ÛŒ Ø¬Ø§Ù†Û’ ÙˆØ§Ù„ÛŒ ØªÙ…Ø§Ù… operations Ú©Ùˆ cache Ú©Ø± Ø¯ÛŒØªØ§ ÛÛ’ØŒ Ø¨Ø¹Ø¶ Ø§ÙˆÙ‚Ø§Øª Ø¢Ù¾ Ú©Ùˆ ÚˆÛŒÙ¹Ø§Ø³ÛŒÙ¹ Ú©Ùˆ ÚˆØ³Ú© Ù¾Ø± Ù…Ø­ÙÙˆØ¸ Ú©Ø±Ù†Û’ Ú©ÛŒ Ø¶Ø±ÙˆØ±Øª Ù¾ÛŒØ´ Ø¢ Ø³Ú©ØªÛŒ ÛÛ’ (Ù…Ø«Ù„Ø§Ù‹ØŒ Ø§Ú¯Ø± cache ÚˆÛŒÙ„ÛŒÙ¹ ÛÙˆ Ø¬Ø§Ø¦Û’)Û” Ø¬ÛŒØ³Ø§ Ú©Û Ù†ÛŒÚ†Û’ Ø¯ÛŒ Ú¯Ø¦ÛŒ Ù¹ÛŒØ¨Ù„ Ù…ÛŒÚº Ø¯Ú©Ú¾Ø§ÛŒØ§ Ú¯ÛŒØ§ ÛÛ’ØŒ ğŸ¤— Datasets ØªÛŒÙ† Ø§ÛÙ… ÙÙ†Ú©Ø´Ù†Ø² ÙØ±Ø§ÛÙ… Ú©Ø±ØªØ§ ÛÛ’ ØªØ§Ú©Û Ø¢Ù¾ Ø§Ù¾Ù†Û’ ÚˆÛŒÙ¹Ø§Ø³ÛŒÙ¹ Ú©Ùˆ Ù…Ø®ØªÙ„Ù ÙØ§Ø±Ù…ÛŒÙ¹Ø³ Ù…ÛŒÚº Ù…Ø­ÙÙˆØ¸ Ú©Ø± Ø³Ú©ÛŒÚº:

|  ÚˆÛŒÙ¹Ø§ ÙØ§Ø±Ù…ÛŒÙ¹  |        ÙÙ†Ú©Ø´Ù†         |
| :------------: | :-------------------: |
|    Arrow     | `Dataset.save_to_disk()` |
|     CSV      |    `Dataset.to_csv()`    |
|    JSON      |   `Dataset.to_json()`    |

Ù…Ø«Ø§Ù„ Ú©Û’ Ø·ÙˆØ± Ù¾Ø±ØŒ Ø¢Ø¦ÛŒÚº Ø§Ù¾Ù†Û’ ØµØ§Ù Ø´Ø¯Û ÚˆÛŒÙ¹Ø§Ø³ÛŒÙ¹ Ú©Ùˆ Arrow ÙØ§Ø±Ù…ÛŒÙ¹ Ù…ÛŒÚº Ù…Ø­ÙÙˆØ¸ Ú©Ø±ØªÛ’ ÛÛŒÚº:

```py
drug_dataset_clean.save_to_disk("drug-reviews")
```

ÛŒÛ Ø§ÛŒÚ© directory ØªØ®Ù„ÛŒÙ‚ Ú©Ø±Û’ Ú¯Ø§ Ø¬Ø³ Ú©ÛŒ Ø³Ø§Ø®Øª Ú©Ú†Ú¾ Ø§Ø³ Ø·Ø±Ø­ ÛÙˆÚ¯ÛŒ:

```
drug-reviews/
â”œâ”€â”€ dataset_dict.json
â”œâ”€â”€ test
â”‚   â”œâ”€â”€ dataset.arrow
â”‚   â”œâ”€â”€ dataset_info.json
â”‚   â””â”€â”€ state.json
â”œâ”€â”€ train
â”‚   â”œâ”€â”€ dataset.arrow
â”‚   â”œâ”€â”€ dataset_info.json
â”‚   â”œâ”€â”€ indices.arrow
â”‚   â””â”€â”€ state.json
â””â”€â”€ validation
    â”œâ”€â”€ dataset.arrow
    â”œâ”€â”€ dataset_info.json
    â”œâ”€â”€ indices.arrow
    â””â”€â”€ state.json
```

Ø¬ÛØ§Úº ÛØ± Ø³Ù¾Ù„Ù¹ Ø§Ù¾Ù†Û’ Ù…ØªØ¹Ù„Ù‚Û *dataset.arrow* Ù¹ÛŒØ¨Ù„ Ø§ÙˆØ± Ú©Ú†Ú¾ metadata (*dataset_info.json* Ø§ÙˆØ± *state.json*) Ú©Û’ Ø³Ø§ØªÚ¾ Ù…Ø­ÙÙˆØ¸ ÛÛ’Û” Ø¢Ù¾ Arrow ÙØ§Ø±Ù…ÛŒÙ¹ Ú©Ùˆ Ø§ÛŒÚ© Ø¬Ø¯ÛŒØ¯ Ù¹ÛŒØ¨Ù„ Ø³Ù…Ø¬Ú¾ Ø³Ú©ØªÛ’ ÛÛŒÚº Ø¬Ùˆ Ø¨Ú‘ÛŒ ÚˆÛŒÙ¹Ø§Ø³ÛŒÙ¹Ø³ Ú©ÛŒ ØªÛŒØ² Ù¾Ø±Ø§Ø³ÛŒØ³Ù†Ú¯ Ø§ÙˆØ± Ù¹Ø±Ø§Ù†Ø³Ù¾ÙˆØ±Ù¹ Ú©Û’ Ù„ÛŒÛ’ Ù…ÙˆØ²ÙˆÚº ÛÛ’Û”

Ø§ÛŒÚ© Ø¨Ø§Ø± ÚˆÛŒÙ¹Ø§Ø³ÛŒÙ¹ Ù…Ø­ÙÙˆØ¸ ÛÙˆØ¬Ø§Ø¦Û’ØŒ Ø¢Ù¾ `load_from_disk()` ÙÙ†Ú©Ø´Ù† Ú©Ø§ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø± Ú©Û’ Ø§Ø³Û’ Ø¯ÙˆØ¨Ø§Ø±Û Ù„ÙˆÚˆ Ú©Ø± Ø³Ú©ØªÛ’ ÛÛŒÚº:

```py
from datasets import load_from_disk

drug_dataset_reloaded = load_from_disk("drug-reviews")
drug_dataset_reloaded
```

```python
DatasetDict({
    train: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],
        num_rows: 110811
    })
    validation: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],
        num_rows: 27703
    })
    test: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],
        num_rows: 46108
    })
})
```

CSV Ø§ÙˆØ± JSON ÙØ§Ø±Ù…ÛŒÙ¹Ø³ Ú©Û’ Ù„ÛŒÛ’ØŒ ÛØ± Ø³Ù¾Ù„Ù¹ Ú©Ùˆ Ø§ÛŒÚ© Ø¹Ù„ÛŒØ­Ø¯Û ÙØ§Ø¦Ù„ Ú©Û’ Ø·ÙˆØ± Ù¾Ø± Ù…Ø­ÙÙˆØ¸ Ú©Ø±Ù†Ø§ Ù¾Ú‘ØªØ§ ÛÛ’Û” Ø§ÛŒØ³Ø§ Ú©Ø±Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ Ø¢Ù¾ `DatasetDict` Ù¾Ø± iterate Ú©Ø± Ø³Ú©ØªÛ’ ÛÛŒÚº:

```py
for split, dataset in drug_dataset_clean.items():
    dataset.to_json(f"drug-reviews-{split}.jsonl")
```

ÛŒÛ ÛØ± Ø³Ù¾Ù„Ù¹ Ú©Ùˆ [JSON Lines format](https://jsonlines.org) Ù…ÛŒÚº Ù…Ø­ÙÙˆØ¸ Ú©Ø±ØªØ§ ÛÛ’ØŒ Ø¬ÛØ§Úº ÛØ± row Ø§ÛŒÚ© JSON Ù„Ø§Ø¦Ù† Ù…ÛŒÚº Ø§Ø³Ù¹ÙˆØ± ÛÙˆØªØ§ ÛÛ’Û” Ù…Ø«Ø§Ù„ Ú©Û’ Ø·ÙˆØ± Ù¾Ø±ØŒ Ù¾ÛÙ„ÛŒ Ù„Ø§Ø¦Ù† ÛŒÙˆÚº Ø¯Ú©Ú¾ Ø³Ú©ØªÛŒ ÛÛ’:

```py
!head -n 1 drug-reviews-train.jsonl
```

```python
{"patient_id":141780,"drugName":"Escitalopram","condition":"depression","review":"\"I seemed to experience the regular side effects of LEXAPRO, insomnia, low sex drive, sleepiness during the day. I am taking it at night because my doctor said if it made me tired to take it at night. I assumed it would and started out taking it at night. Strange dreams, some pleasant. I was diagnosed with fibromyalgia. Seems to be helping with the pain. Have had anxiety and depression in my family, and have tried quite a few other medications that haven't worked. Only have been on it for two weeks but feel more positive in my mind, want to accomplish more in my life. Hopefully the side effects will dwindle away, worth it to stick with it from hearing others responses. Great medication.\"","rating":9.0,"date":"May 29, 2011","usefulCount":10,"review_length":125}
```

Ø¢Ù¾ Ù¾Ú¾Ø± [Ø¨Ø§Ø¨ 2](/course/chapter5/2) Ú©ÛŒ ØªÚ©Ù†ÛŒÚ©ÙˆÚº Ú©Ø§ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø± Ú©Û’ JSON ÙØ§Ø¦Ù„ÙˆÚº Ú©Ùˆ Ù„ÙˆÚˆ Ú©Ø± Ø³Ú©ØªÛ’ ÛÛŒÚº:

```py
data_files = {
    "train": "drug-reviews-train.jsonl",
    "validation": "drug-reviews-validation.jsonl",
    "test": "drug-reviews-test.jsonl",
}
drug_dataset_reloaded = load_dataset("json", data_files=data_files)
```

ÛŒÛ ÛÙ…Ø§Ø±ÛŒ ÚˆÛŒÙ¹Ø§ ÙˆØ§Ø±Ù†Ú¯ Ú©Ø§ Ø³ÙØ± Ø®ØªÙ… Ú©Ø±ØªØ§ ÛÛ’Û” Ø§Ø¨ Ø¬Ø¨ Ú©Û ÛÙ…Ø§Ø±Û’ Ù¾Ø§Ø³ Ø§ÛŒÚ© ØµØ§Ù ÚˆÛŒÙ¹Ø§Ø³ÛŒÙ¹ ÛÛ’ Ø¬Ø³ Ù¾Ø± Ù…Ø§ÚˆÙ„ Ú©ÛŒ ØªØ±Ø¨ÛŒØª Ú©ÛŒ Ø¬Ø§ Ø³Ú©ØªÛŒ ÛÛ’ØŒ ÛŒÛØ§Úº Ú†Ù†Ø¯ ØªØ¬Ø§ÙˆÛŒØ² ÛÛŒÚº Ø¬Ù†ÛÛŒÚº Ø¢Ù¾ Ø¢Ø²Ù…Ø§ Ø³Ú©ØªÛ’ ÛÛŒÚº:

1. [Ø¨Ø§Ø¨ 3](/course/chapter3) Ú©ÛŒ ØªÚ©Ù†ÛŒÚ©ÙˆÚº Ú©Ø§ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±ØªÛ’ ÛÙˆØ¦Û’ Ø§ÛŒÚ© classifier ØªØ±Ø¨ÛŒØª Ú©Ø±ÛŒÚº Ø¬Ùˆ drug review Ú©ÛŒ Ø¨Ù†ÛŒØ§Ø¯ Ù¾Ø± Ù…Ø±ÛŒØ¶ Ú©ÛŒ Ø­Ø§Ù„Øª Ú©ÛŒ Ù¾ÛŒØ´ Ú¯ÙˆØ¦ÛŒ Ú©Ø± Ø³Ú©Û’Û”
2. [Ø¨Ø§Ø¨ 1](/course/chapter1) Ø³Û’ summarization pipeline Ú©Ø§ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±ØªÛ’ ÛÙˆØ¦Û’ Ø±ÛŒÙˆÛŒÙˆØ² Ú©Ø§ Ø®Ù„Ø§ØµÛ ØªÛŒØ§Ø± Ú©Ø±ÛŒÚºÛ”

Ø¢Ø®Ø± Ù…ÛŒÚºØŒ ÛÙ… Ø¯ÛŒÚ©Ú¾ÛŒÚº Ú¯Û’ Ú©Û Ú©Ø³ Ø·Ø±Ø­ ğŸ¤— Datasets Ø¢Ù¾ Ú©Ùˆ Ø¨ÛØª Ø¨Ú‘Û’ ÚˆÛŒÙ¹Ø§Ø³ÛŒÙ¹Ø³ Ú©Û’ Ø³Ø§ØªÚ¾ Ú©Ø§Ù… Ú©Ø±Ù†Û’ Ú©ÛŒ Ø§Ø¬Ø§Ø²Øª Ø¯ÛŒØªØ§ ÛÛ’ Ø¨ØºÛŒØ± Ø¢Ù¾ Ú©Û’ Ù„ÛŒÙ¾ Ù¹Ø§Ù¾ Ú©ÛŒ Ù…ÛŒÙ…ÙˆØ±ÛŒ Ø¨Ú¾Ø±Ù†Û’ Ú©Û’Û”

