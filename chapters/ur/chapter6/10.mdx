# End-of-chapter quiz[[end-of-chapter-quiz]]

<CourseFloatingBanner
    chapter={6}
    classNames="absolute z-10 right-0 top-0"
/>

Let's test what you learned in this chapter!

### 1. ูุง tokenizer ฺฉุจ ุชุฑุจุช ุฏูุง ฺุงุ

<Question
	choices={[
		{
			text: "ุฌุจ ุขูพ ฺฉุง dataset ุงฺฉ ููุฌูุฏ pretrained model ฺฉ ุงุณุชุนูุงู ฺฉ ฺฏุฆ dataset ุณ ููุงุซู ูุ ุงูุฑ ุขูพ ุงฺฉ ูุง model pretrain ฺฉุฑูุง ฺุงุช ูฺบ",
			explain: "ุงุณ ุตูุฑุช ูฺบุ ููุช ุงูุฑ compute ูุณุงุฆู ุจฺุงู ฺฉ ู ุจุชุฑ  ูฺฏุง ฺฉ ุขูพ ุงุณ tokenizer ฺฉุง ุงุณุชุนูุงู ฺฉุฑฺบ ุฌู pretrained model ู ุงุณุชุนูุงู ฺฉุง ู ุงูุฑ ุงุณ model ฺฉู fine-tune ฺฉุฑฺบ"
		},
		{
			text: "ุฌุจ ุขูพ ฺฉุง dataset ุงฺฉ ููุฌูุฏ pretrained model ฺฉ ุงุณุชุนูุงู ฺฉ ฺฏุฆ dataset ุณ ููุงุซู ูุ ุงูุฑ ุขูพ ุงุณ pretrained model ฺฉุง ุงุณุชุนูุงู ฺฉุฑุช ูุฆ ุงฺฉ ูุง model fine-tune ฺฉุฑูุง ฺุงุช ูฺบ",
			explain: "Pretrained model ุณ fine-tuning ฺฉ ู ูุด ู tokenizer ุงุณุชุนูุงู ฺฉุฑฺบ"
		},
		{
			text: "ุฌุจ ุขูพ ฺฉุง dataset ุงฺฉ ููุฌูุฏ pretrained model ฺฉ ุงุณุชุนูุงู ฺฉ ฺฏุฆ dataset ุณ ูุฎุชูู ูุ ุงูุฑ ุขูพ ุงฺฉ ูุง model pretrain ฺฉุฑูุง ฺุงุช ูฺบ",
			explain: "ุตุญุญ! ุงุณ ุตูุฑุช ูฺบ ุงฺฉ  tokenizer ุงุณุชุนูุงู ฺฉุฑู ฺฉุง ฺฉูุฆ ูุงุฆุฏ ูฺบ ูุชุง",
            correct: true
		},
        {
			text: "ุฌุจ ุขูพ ฺฉุง dataset ุงฺฉ ููุฌูุฏ pretrained model ฺฉ ุงุณุชุนูุงู ฺฉ ฺฏุฆ dataset ุณ ูุฎุชูู ูุ ูฺฉู ุขูพ ุงุณ pretrained model ฺฉุง ุงุณุชุนูุงู ฺฉุฑุช ูุฆ ุงฺฉ ูุง model fine-tune ฺฉุฑูุง ฺุงุช ูฺบ",
			explain: "Pretrained model ุณ fine-tuning ฺฉ ู ูุด ู tokenizer ุงุณุชุนูุงู ฺฉุฑฺบ"
		}
	]}
/>

### 2. `train_new_from_iterator()` ุงุณุชุนูุงู ฺฉุฑุช ููุชุ texts ฺฉ lists ฺฉุง generator ุงุณุชุนูุงู ฺฉุฑู ฺฉุง ฺฉุง ูุงุฆุฏ ุ ุจุฌุงุฆ texts ฺฉ lists ฺฉ ูุณูน ฺฉุ

<Question
	choices={[
		{
			text: " ูุงุญุฏ ูุณู  ุฌู method `train_new_from_iterator()` ูุจูู ฺฉุฑุชุง ",
			explain: "texts ฺฉ lists ฺฉ ูุณูนุ texts ฺฉ lists ฺฉุง ุงฺฉ ุฎุงุต ูุณู ฺฉุง generator ุ ููฐุฐุง method ุงุณ ุจฺพ ูุจูู ฺฉุฑ ฺฏุง ุฏูุจุงุฑ ฺฉูุดุด ฺฉุฑฺบ!"
		},
		{
			text: "ุขูพ ูพูุฑุง dataset ุงฺฉ ุณุงุชฺพ memory ูฺบ load ูู ุณ ุจฺ ุฌุงุช ฺบ",
			explain: "ุตุญุญ! ุฑ batch ฺฉ texts ฺฉู iterate ฺฉุฑู ฺฉ ุจุนุฏ memory ุณ ุขุฒุงุฏ ฺฉุฑ ุฏุง ุฌุงุชุง ุ ุงูุฑ  ูุงุฆุฏ ุฎุงุต ุทูุฑ ูพุฑ ุงุณ ุตูุฑุช ูฺบ ูุงุถุญ ูุชุง  ุฌุจ ุขูพ ๐ค Datasets ฺฉู texts ุฐุฎุฑ ฺฉุฑู ฺฉ ู ุงุณุชุนูุงู ฺฉุฑฺบ",
            correct: true
		},
		{
			text: "ุงุณ ุณ ๐ค Tokenizers ูุงุฆุจุฑุฑ multiprocessing ุงุณุชุนูุงู ฺฉุฑ ุณฺฉุช ",
			explain: "ูฺบุ ุฏูููฺบ ุตูุฑุชูฺบ ูฺบ multiprocessing ุงุณุชุนูุงู ูุช "
		},
        {
			text: "ุชุฑุจุช ุฏุง ฺฏุง tokenizer ุจุชุฑ texts generate ฺฉุฑ ฺฏุง",
			explain: "Tokenizer text generate ูฺบ ฺฉุฑุชุง โ ฺฉุง ุขูพ ุงุณ language model ุณ ุบูุท ุณูุฌฺพ ุฑ ฺบุ"
		}
	]}
/>

### 3. "ูุงุณูน" tokenizer ุงุณุชุนูุงู ฺฉุฑู ฺฉ ฺฉุง ูุงุฆุฏ ฺบุ

<Question
	choices={[
		{
			text: " ุจฺฉ ููุช ุจุช ุณ inputs ฺฉู batch ฺฉุฑู ูพุฑ ุณูู tokenizer ฺฉ ููุงุจู ูฺบ ุฒุงุฏ ุชุฒ ุณ process ฺฉุฑ ุณฺฉุชุง ",
			explain: "ุตุญุญ! Rust ูฺบ parallelism ฺฉ ุจุฏููุชุ  batches ูพุฑ ุชุฒ ุณ ฺฉุงู ฺฉุฑุชุง  ุขูพ ุงูุฑ ฺฉุง ูุงุฆุฏ ุณูฺ ุณฺฉุช ฺบุ",
            correct: true
		},
		{
			text: "ูุงุณูน tokenizers ูุด ุงูพู ุณูู counterparts ุณ ุชุฒ ุณ tokenize ฺฉุฑุช ฺบ",
			explain: "ุงฺฉ ูุงุณูน tokenizer ุงฺฉ ุง ุจุช ฺฉู texts ูพุฑ ฺฉุงู ฺฉุฑุช ููุช ุณูู tokenizer ุณ ุขุณุช ู ุณฺฉุชุง  ฺฉููฺฉ ู parallelism ุงุณุชุนูุงู ูฺบ ฺฉุฑ ูพุงุชุง"
		},
		{
			text: " padding ุงูุฑ truncation ูุงฺฏู ฺฉุฑ ุณฺฉุชุง ",
			explain: "ุณฺ ุ ูฺฏุฑ ุณูู tokenizers ุจฺพ  ฺฉุงู ฺฉุฑุช ฺบ"
		},
        {
			text: "ุงุณ ูฺบ ุงุถุงู ุฎุตูุตุงุช ุดุงูู ฺบ ุฌู ุขูพ ฺฉู tokens ฺฉู ุงู ฺฉ original text ฺฉ span ุณ map ฺฉุฑู ฺฉ ุงุฌุงุฒุช ุฏุช ฺบ",
			explain: "ูุงูุน โ  ุฎุตูุตุงุช offset mappings ฺฉูุงุช ฺบ",
            correct: true
		}
	]}
/>

### 4. `token-classification` ูพุงุฆูพ ูุงุฆู ุงุณ entities ฺฉู ฺฉุณ ูฺู ฺฉุฑุช  ุฌู ฺฉุฆ tokens ูพุฑ ูุญุท ูฺบุ

<Question
	choices={[
		{
			text: "ุงฺฉ  label ูุงู entities ฺฉู ููุง ฺฉุฑ ุงฺฉ entity ูฺบ ุชุจุฏู ฺฉุฑ ุฏุง ุฌุงุชุง ",
			explain: " ุชฺพูฺุง oversimplify ฺฉุฑ ุฑุง  ุฏูุจุงุฑ ฺฉูุดุด ฺฉุฑฺบ!"
		},
		{
			text: "ุงฺฉ entity ฺฉ ุขุบุงุฒ ุงูุฑ ุงุณ ฺฉ ุฌุงุฑ ุฑู ฺฉ ู ูุฎุชูู labels ูุช ฺบ",
			explain: "ุตุญุญ!",
            correct: true
		},
		{
			text: "ฺฉุณ word ูฺบุ ุฌุจ ุชฺฉ ฺฉ ูพูุง token entity ฺฉุง label ุฑฺฉฺพุชุง ุ ูพูุฑุง word ุงุณ entity ฺฉ ุชุญุช ุดูุงุฑ ฺฉุง ุฌุงุชุง ",
			explain: " entities ฺฉู ูฺู ฺฉุฑู ฺฉ ุงฺฉ ุญฺฉูุช ุนูู ",
            correct: true
		},
        {
			text: "ุฌุจ ฺฉุณ token ฺฉู ฺฉุณ entity ฺฉุง label ุฏุง ุฌุงุฆุ ุชู ูุณูุณู ุขู ูุงู ุฏูุณุฑ tokens ฺฉู ุงุณ entity ฺฉุง ุญุต ุณูุฌฺพุง ุฌุงุชุง ุ ุฌุจ ุชฺฉ ฺฉ ู ูุฆ entity ฺฉ ุขุบุงุฒ ฺฉุง ูุดุงู ู ุฏฺบ",
			explain: " entities ฺฉู ฺฏุฑููพ ฺฉุฑู ฺฉุง ุณุจ ุณ ุนุงู ุทุฑู  โ ูฺฏุฑ  ูุงุญุฏ ุตุญุญ ุฌูุงุจ ูฺบ ",
            correct: true
		}
	]}
/>

### 5. `question-answering` ูพุงุฆูพ ูุงุฆู ุทูู contexts ฺฉู ฺฉุณ ูฺู ฺฉุฑุช ุ

<Question
	choices={[
		{
			text: " ุฏุฑุงุตู ุทูู context ฺฉู model ฺฉ ุฒุงุฏ ุณ ุฒุงุฏ ููุจุงุฆ ูพุฑ truncate ฺฉุฑ ุฏุช ",
			explain: "ุงฺฉ ฺุงูุงฺฉ ุทุฑู ููุฌูุฏ  ุฌุณ ุณ ุทูู contexts ฺฉู ูฺู ฺฉุง ุฌุง ุณฺฉุชุง  ฺฉุง ุขูพ ฺฉู ุงุฏ  ู ฺฉุง ุ"
		},
		{
			text: " context ฺฉู ฺฉุฆ ุญุตูฺบ ูฺบ ุชูุณู ฺฉุฑ ฺฉ ูุชุงุฆุฌ ฺฉุง average ูุช ",
			explain: "ูฺบุ results ฺฉุง average ููุง ูุนููู ูฺบ ฺฉููฺฉ context ฺฉ ฺฉฺฺพ ุญุตูฺบ ูฺบ ุฌูุงุจ ููุฌูุฏ ูฺบ ูฺฏุง"
		},
		{
			text: " context ฺฉู overlap ฺฉ ุณุงุชฺพ ฺฉุฆ ุญุตูฺบ ูฺบ ุชูุณู ฺฉุฑุช  ุงูุฑ ุฑ ุญุต ูฺบ ุฌูุงุจ ฺฉ ู maximum score ุชูุงุด ฺฉุฑุช ",
			explain: " ุตุญุญ ุฌูุงุจ !",
            correct: true
		},
        {
			text: " context ฺฉู ุจุบุฑ overlap ฺฉ ฺฉุฆ ุญุตูฺบ ูฺบ ุชูุณู ฺฉุฑุช  ุงูุฑ ุฑ ุญุต ูฺบ ุฌูุงุจ ฺฉ ู maximum score ุชูุงุด ฺฉุฑุช ",
			explain: "ูฺบุ ุฌูุงุจ ฺฉู ุฏู ุญุตูฺบ ูฺบ ุชูุณู ูู ุณ ุจฺุงู ฺฉ ู  overlap ุดุงูู ฺฉุฑุช "
		}
	]}
/>

### 6. Normalization ฺฉุง ุ

<Question
	choices={[
		{
			text: " ู ุตูุงุฆ  ุฌู tokenizer ุงุจุชุฏุงุฆ ูุฑุงุญู ูฺบ texts ูพุฑ ฺฉุฑุชุง ",
			explain: " ุฏุฑุณุช  โ ูุซุงู ฺฉ ุทูุฑ ูพุฑุ  accents ุง whitespace ฺฉู ูนุง ุณฺฉุชุง  ุง inputs ฺฉู lower case ูฺบ ุชุจุฏู ฺฉุฑ ุณฺฉุชุง ",
            correct: true
		},
		{
			text: " ุงฺฉ data augmentation ุชฺฉูฺฉ  ุฌุณ ูฺบ text ฺฉู ุฒุงุฏ 'normal' ุจูุงู ฺฉ ู rare ุงููุงุธ ฺฉู ูนุงุง ุฌุงุชุง ",
			explain: " ุบูุท ! ุฏูุจุงุฑ ฺฉูุดุด ฺฉุฑฺบ"
		},
		{
			text: " ุขุฎุฑ post-processing ูุฑุญู  ุฌุงฺบ tokenizer special tokens ุดุงูู ฺฉุฑุชุง ",
			explain: " ูุฑุญู post-processing ฺฉูุงุชุง "
		},
        {
			text: " ู ุนูู  ุฌุจ embeddings ฺฉู mean 0 ุงูุฑ standard deviation 1 ฺฉ ุณุงุชฺพ normalize ฺฉุง ุฌุงุชุง ุ ุนู mean ฺฉู subtract ฺฉุฑ ฺฉ ุงูุฑ std ุณ ุชูุณู ฺฉุฑ ฺฉ",
			explain: " ุนูู ุนูููุงู computer vision ูฺบ pixel values ฺฉู normalize ฺฉุฑู ฺฉ ู ุงุณุชุนูุงู ูุชุง ุ ูฺฏุฑ NLP ูฺบ normalization ฺฉุง  ูุทูุจ ูฺบ ูุชุง"
		}
	]}
/>

### 7. ุณุจ ูุฑฺ ูนูฺฉูุงุฆุฒุฑ ฺฉ ู pre-tokenization ฺฉุง ุ

<Question
	choices={[
		{
			text: " ู ูุฑุญู  ุฌู tokenization ุณ ูพู ุขุชุง ุ ุฌุงฺบ data augmentation (ุฌุณ random masking) ูุงฺฏู ฺฉ ุฌุงุช ",
			explain: "ูฺบุ  ูุฑุญู preprocessing ฺฉุง ุญุต "
		},
		{
			text: " ู ูุฑุญู  ุฌู tokenization ุณ ูพู ุขุชุง ุ ุฌุงฺบ text ูพุฑ ูุทููุจ ุตูุงุฆ (cleanup) ฺฉ ุฌุงุช ",
			explain: "ูฺบุ  normalization ฺฉุง ูุฑุญู "
		},
		{
			text: " ู ูุฑุญู  ุฌู tokenizer model ฺฉู ูุงฺฏู ฺฉุฑู ุณ ูพู ุขุชุง ุ ุชุงฺฉ input ฺฉู ุงููุงุธ ูฺบ ุชูุณู ฺฉุง ุฌุง ุณฺฉ",
			explain: " ุฏุฑุณุช ุฌูุงุจ !",
            correct: true
		},
        {
			text: " ู ูุฑุญู  ุฌู tokenizer model ฺฉู ูุงฺฏู ฺฉุฑู ุณ ูพู ุขุชุง ุ ุชุงฺฉ input ฺฉู tokens ูฺบ ุชูุณู ฺฉุง ุฌุง ุณฺฉ",
			explain: "ูฺบุ tokens ูฺบ ุชูุณู ฺฉุฑูุง tokenizer model ฺฉุง ฺฉุงู "
		}
	]}
/>

### 8. ุงู ุฌูููฺบ ฺฉู ููุชุฎุจ ฺฉุฑฺบ ุฌู BPE ูุงฺู ฺฉ ู ุฏุฑุณุช ฺบ:

<Question
	choices={[
		{
			text: "BPE ุงฺฉ ุณุจ ูุฑฺ ูนูฺฉูุงุฆุฒุดู ุงูฺฏูุฑุชฺพู  ุฌู ุงฺฉ ฺฺพููน vocabulary ุณ ุดุฑูุน ูุชุง  ุงูุฑ merge rules ุณฺฉฺพุชุง ",
			explain: " ุจุงูฺฉู ุฏุฑุณุช !",
            correct: true
		},
		{
			text: "BPE ุงฺฉ ุณุจ ูุฑฺ ูนูฺฉูุงุฆุฒุดู ุงูฺฏูุฑุชฺพู  ุฌู ุงฺฉ ุจฺ vocabulary ุณ ุดุฑูุน ูุชุง  ุงูุฑ ุจุชุฏุฑุฌ tokens ฺฉู ุญุฐู ฺฉุฑุชุง ",
			explain: "ูฺบุ  ุทุฑู ฺฉุงุฑ ุงฺฉ ูุฎุชูู ูนูฺฉูุงุฆุฒุดู ุงูฺฏูุฑุชฺพู ฺฉุง "
		},
		{
			text: "BPE tokenizers merge rules ุณุจ ุณ ุฒุงุฏ frequent pair ฺฉู merge ฺฉุฑ ฺฉ ุณฺฉฺพุช ฺบ",
			explain: " ุฏุฑุณุช !",
            correct: true
		},
        {
			text: "ุงฺฉ BPE tokenizer ู pair merge ฺฉุฑุชุง  ุฌู ุงฺฉ ุงุณ score ฺฉู maximize ฺฉุฑุชุง  ุฌู ฺฉู frequent individual ุญุตูฺบ ฺฉู ุชุฑุฌุญ ุฏุชุง ",
			explain: "ูฺบุ  ุญฺฉูุช ุนูู ฺฉุณ ุงูุฑ ูนูฺฉูุงุฆุฒุดู ุงูฺฏูุฑุชฺพู ฺฉ "
		},
		{
			text: "BPE ุงููุงุธ ฺฉู subwords ูฺบ tokenize ฺฉุฑุชุง ุ ูพู ุงูฺบ characters ูฺบ ุชูุณู ฺฉุฑุชุง  ุงูุฑ ูพฺพุฑ merge rules apply ฺฉุฑุชุง ",
			explain: " ุฏุฑุณุช !",
            correct: true
		},
        {
			text: "BPE ุงููุงุธ ฺฉู subwords ูฺบ tokenize ฺฉุฑุชุง ุ ุณุจ ุณ ุทูู subword ุชูุงุด ฺฉุฑ ฺฉ ุฌู vocabulary ูฺบ ููุฌูุฏ ูุ ูพฺพุฑ ุจุงู ูุชู ฺฉ ู  ุนูู ุฏุฑุงุง ุฌุงุชุง ",
			explain: "ูฺบุ  ุงฺฉ ูุฎุชูู ูนูฺฉูุงุฆุฒุดู ุงูฺฏูุฑุชฺพู ฺฉุง ุทุฑู "
		}
	]}
/>

### 9. ุงู ุฌูููฺบ ฺฉู ููุชุฎุจ ฺฉุฑฺบ ุฌู WordPiece ูุงฺู ฺฉ ู ุฏุฑุณุช ฺบ:

<Question
	choices={[
		{
			text: "WordPiece ุงฺฉ ุณุจ ูุฑฺ ูนูฺฉูุงุฆุฒุดู ุงูฺฏูุฑุชฺพู  ุฌู ุงฺฉ ฺฺพููน vocabulary ุณ ุดุฑูุน ูุชุง  ุงูุฑ merge rules ุณฺฉฺพุชุง ",
			explain: " ุจุงูฺฉู ุฏุฑุณุช !",
            correct: true
		},
		{
			text: "WordPiece ุงฺฉ ุณุจ ูุฑฺ ูนูฺฉูุงุฆุฒุดู ุงูฺฏูุฑุชฺพู  ุฌู ุงฺฉ ุจฺ vocabulary ุณ ุดุฑูุน ูุชุง  ุงูุฑ ุจุชุฏุฑุฌ tokens ฺฉู ุญุฐู ฺฉุฑุชุง ",
			explain: "ูฺบุ  ุทุฑู ฺฉุงุฑ ุงฺฉ ูุฎุชูู ูนูฺฉูุงุฆุฒุดู ุงูฺฏูุฑุชฺพู ฺฉุง "
		},
		{
			text: "WordPiece tokenizers ุณุจ ุณ ุฒุงุฏ frequent pair ฺฉู merge ฺฉุฑ ฺฉ merge rules ุณฺฉฺพุช ฺบ",
			explain: "ูฺบุ  ุญฺฉูุช ุนูู ุฏูุณุฑ ูนูฺฉูุงุฆุฒุดู ุงูฺฏูุฑุชฺพู ฺฉ "
		},
        {
			text: "ุงฺฉ WordPiece tokenizer ู merge rule ุณฺฉฺพุชุง  ุฌู ุงุณ pair ฺฉู merge ฺฉุฑุชุง  ุฌู ุงฺฉ ุงุณ score ฺฉู maximize ฺฉุฑุชุง  ุฌู ฺฉู frequent individual ุญุตูฺบ ฺฉ ุณุงุชฺพ frequent pairs ฺฉู ุชุฑุฌุญ ุฏุชุง ",
			explain: " ุฏุฑุณุช !",
            correct: true
		},
		{
			text: "WordPiece ุงููุงุธ ฺฉู subwords ูฺบ tokenize ฺฉุฑุชุง ุ ูุงฺู ฺฉ ูุทุงุจู ุณุจ ุณ ุฒุงุฏ ููฺฉู segmentation ุชูุงุด ฺฉุฑ ฺฉ",
			explain: "ูฺบุ  ุงฺฉ ุงูุฑ ูนูฺฉูุงุฆุฒุดู ุงูฺฏูุฑุชฺพู ฺฉุง ุทุฑู "
		},
        {
			text: "WordPiece ุงููุงุธ ฺฉู subwords ูฺบ tokenize ฺฉุฑุชุง ุ ุณุจ ุณ ุทูู subword ุชูุงุด ฺฉุฑ ฺฉ ุฌู vocabulary ูฺบ ููุฌูุฏ ูุ ูพฺพุฑ ุจุงู ูุชู ฺฉ ู  ุนูู ุฏุฑุงุง ุฌุงุชุง ",
			explain: "ุงฺบุ  WordPiece encoding ฺฉุง ุทุฑู ",
            correct: true
		}
	]}
/>

### 10. ุงู ุฌูููฺบ ฺฉู ููุชุฎุจ ฺฉุฑฺบ ุฌู Unigram ูุงฺู ฺฉ ู ุฏุฑุณุช ฺบ:

<Question
	choices={[
		{
			text: "Unigram ุงฺฉ ุณุจ ูุฑฺ ูนูฺฉูุงุฆุฒุดู ุงูฺฏูุฑุชฺพู  ุฌู ุงฺฉ ฺฺพููน vocabulary ุณ ุดุฑูุน ูุชุง  ุงูุฑ merge rules ุณฺฉฺพุชุง ",
			explain: "ูฺบุ  ุทุฑู ฺฉุงุฑ ุงฺฉ ูุฎุชูู ูนูฺฉูุงุฆุฒุดู ุงูฺฏูุฑุชฺพู ฺฉุง "
		},
		{
			text: "Unigram ุงฺฉ ุณุจ ูุฑฺ ูนูฺฉูุงุฆุฒุดู ุงูฺฏูุฑุชฺพู  ุฌู ุงฺฉ ุจฺ vocabulary ุณ ุดุฑูุน ูุชุง  ุงูุฑ ุจุชุฏุฑุฌ tokens ฺฉู ุญุฐู ฺฉุฑุชุง ",
			explain: " ุฏุฑุณุช !",
            correct: true
		},
		{
			text: "Unigram ุงูพู vocabulary ฺฉู minimize ูู ูุงู loss ฺฉ ุฐุฑุน ุงูพฺูน ฺฉุฑุชุง  ุฌู ูพูุฑ corpus ูพุฑ compute ูุชุง ",
			explain: " ุฏุฑุณุช !",
            correct: true
		},
		{
			text: "Unigram ุงูพู vocabulary ฺฉู ุณุจ ุณ ุฒุงุฏ frequent subwords ฺฉู ุฑฺฉฺพ ฺฉุฑ ุงูพฺูน ฺฉุฑุชุง ",
			explain: "ูฺบุ  ุฏุฑุณุช ูฺบ "
		},
        {
			text: "Unigram ุงููุงุธ ฺฉู subwords ูฺบ tokenize ฺฉุฑุชุง  ฺฉ ู ูุงฺู ฺฉ ูุทุงุจู ุณุจ ุณ ุฒุงุฏ ููฺฉู segmentation ุชูุงุด ฺฉุฑ",
			explain: " ุฏุฑุณุช !",
            correct: true
		},
		{
			text: "Unigram ุงููุงุธ ฺฉู subwords ูฺบ tokenize ฺฉุฑุชุง ุ ูพู ุงูฺบ characters ูฺบ ุชูุณู ฺฉุฑ ฺฉ ูพฺพุฑ merge rules apply ฺฉุฑุชุง ",
			explain: "ูฺบุ  ุทุฑู ฺฉุงุฑ ุงฺฉ ูุฎุชูู ูนูฺฉูุงุฆุฒุดู ุงูฺฏูุฑุชฺพู ฺฉุง "
		}
	]}
/>

