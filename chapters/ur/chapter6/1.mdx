# ุชุนุงุฑู[[introduction]]

<CourseFloatingBanner
    chapter={6}
    classNames="absolute z-10 right-0 top-0"
/>

[ุจุงุจ 3](/course/chapter3) ูฺบุ ู ู ุงุณ ุจุงุช ฺฉุง ุฌุงุฆุฒ ูุง ฺฉ ฺฉุณ ูุฎุตูุต ฺฉุงู ูพุฑ ูุงฺู ฺฉู fine-tune ฺฉุณ ฺฉุง ุฌุงุชุง  ุฌุจ ู ุงุณุง ฺฉุฑุช ฺบ ุชู ู ู tokenizer ุงุณุชุนูุงู ฺฉุฑุช ฺบ ุฌุณ ูพุฑ ูุงฺู ฺฉู ูพู ุณ ุชุฑุจุช ุฏ ฺฏุฆ ูุช  โ ูฺฉู ุฌุจ ู ุตูุฑ ุณ ูุงฺู ฺฉ ุชุฑุจุช ฺฉุฑูุง ฺุงุช ฺบ ุชู ฺฉุง ฺฉุฑฺบุ ุงุณ ุตูุฑุชูฺบ ูฺบุ ฺฉุณ ุฏูุณุฑ ฺููู ุง ุฒุจุงู ฺฉ corpus ูพุฑ ูพู ุณ ุชุฑุจุช ุงูุช tokenizer ฺฉุง ุงุณุชุนูุงู ุนูููุงู ุบุฑ ูุคุซุฑ ุซุงุจุช ูุชุง  ูุซุงู ฺฉ ุทูุฑ ูพุฑุ ุงฺฏุฑ ุงฺฉ tokenizer ฺฉู ุงูฺฏุฑุฒ corpus ูพุฑ ุชุฑุจุช ุฏ ฺฏุฆ ู ุชู ู ุฌุงูพุงู texts ฺฉ corpus ูพุฑ ุฎุฑุงุจ ฺฉุงุฑฺฉุฑุฏฺฏ ุฏฺฉฺพุงุฆ ฺฏุง ฺฉููฺฉ ุฏูููฺบ ุฒุจุงููฺบ ูฺบ spaces ุงูุฑ punctuation ฺฉุง ุงุณุชุนูุงู ฺฉุงู ูุฎุชูู ูุชุง 

ุงุณ ุจุงุจ ูฺบุ ุขูพ ุณฺฉฺพฺบ ฺฏ ฺฉ ฺฉุณ ุทุฑุญ ุงฺฉ ูุง tokenizer texts ฺฉ corpus ูพุฑ ุชุฑุจุช ุฏ ุฌุงุฆุ ุชุงฺฉ ุงุณ language model ฺฉ pretraining ฺฉ ู ุงุณุชุนูุงู ฺฉุง ุฌุง ุณฺฉ  ุณุจ ฺฉุงู [๐ค Tokenizers](https://github.com/huggingface/tokenizers) ูุงุฆุจุฑุฑ ฺฉ ูุฏุฏ ุณ ฺฉุง ุฌุงุฆ ฺฏุงุ ุฌู [๐ค Transformers](https://github.com/huggingface/transformers) ูุงุฆุจุฑุฑ ูฺบ "ูุงุณูน" tokenizers ูุฑุงู ฺฉุฑุช  ู ุงุณ ูุงุฆุจุฑุฑ ฺฉ ูุฑุงู ฺฉุฑุฏ ุฎุตูุตุงุช ฺฉุง ูุฑุจ ุณ ุฌุงุฆุฒ ูฺบ ฺฏ ุงูุฑ  ุฏุฑุงูุช ฺฉุฑฺบ ฺฏ ฺฉ ูุงุณูน tokenizers "ุณูู" ูุฑฺูุฒ ุณ ฺฉุณ ูุฎุชูู ฺบ

ู ุฏุฑุฌ ุฐู ููุถูุนุงุช ูพุฑ ุจุงุช ฺฉุฑฺบ ฺฏ:

* ฺฉุณ ุทุฑุญ ุงฺฉ ูุง tokenizer ุชุฑุจุช ุฏฺบ ุฌู ฺฉุณ ุฏ ฺฏุฆ checkpoint ฺฉ ุงุณุชุนูุงู ฺฉุฑุฏ tokenizer ฺฉ ููุงุซู ู ูฺฉู ูุฆ texts ฺฉ corpus ูพุฑ ู
* ูุงุณูน tokenizers ฺฉ ุฎุงุต ุฎุตูุตุงุช
* NLP ูฺบ ุขุฌ ุงุณุชุนูุงู ูู ูุงู ุชู ุงู subword tokenization algorithms ฺฉ ุฏุฑูุงู ูุฑู
* ๐ค Tokenizers ูุงุฆุจุฑุฑ ฺฉุง ุงุณุชุนูุงู ฺฉุฑุช ูุฆ ุตูุฑ ุณ tokenizer ุจูุงูุง ุงูุฑ ุงุณ ฺูนุง ูพุฑ ุชุฑุจุช ุฏูุง

ุงุณ ุจุงุจ ูฺบ ูุชุนุงุฑู ฺฉุฑุงุฆ ุฌุงู ูุงู ุชฺฉูฺฉฺบ ุขูพ ฺฉู [ุจุงุจ 7](/course/chapter7/6) ฺฉ ุงุณ ุญุต ฺฉ ู ุชุงุฑ ฺฉุฑฺบ ฺฏ ุฌุงฺบ ู Python source code ฺฉ ู language model ุชุฎูู ฺฉุฑู ูพุฑ ุบูุฑ ฺฉุฑฺบ ฺฏ ุขุฆฺบ ูพู  ุฏฺฉฺพุช ฺบ ฺฉ tokenizer ฺฉู "train" ฺฉุฑู ฺฉุง ฺฉุง ูุทูุจ 