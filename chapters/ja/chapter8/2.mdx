# ã‚¨ãƒ©ãƒ¼ã‚’è¦‹ã¤ã‘ãŸæ™‚ã«æœ€åˆã«ã™ã‚‹ã“ã¨

<CourseFloatingBanner chapter={8}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/ja/chapter8/section2.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/ja/chapter8/section2.ipynb"},
]} />

ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ã€æ–°ã—ããƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸTransformerãƒ¢ãƒ‡ãƒ«ã‹ã‚‰äºˆæ¸¬ã‚’ç”Ÿæˆã—ã‚ˆã†ã¨ã™ã‚‹ã¨ãã«èµ·ã“ã‚‹äº‹ãŒã§ãã‚‹ã€ã„ãã¤ã‹ã®ä¸€èˆ¬çš„ãªã‚¨ãƒ©ãƒ¼ã«ã¤ã„ã¦è¦‹ã¦ã„ãã¾ã—ã‚‡ã†ã€‚ã“ã‚Œã¯[ã‚»ã‚¯ã‚·ãƒ§ãƒ³4](/course/chapter8/section4)ã®æº–å‚™ã¨ãªã‚Šã€å­¦ç¿’æ®µéšã‚’ãƒ‡ãƒãƒƒã‚°ã™ã‚‹æ–¹æ³•ã‚’è¦‹ã¦ã„ãã¾ã—ã‚‡ã†ã€‚

<Youtube id="DQ-CpJn6Rc4"/>

ã“ã®ç« ã®ç‚ºã«[ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ¬ãƒã‚¸ãƒˆãƒªãƒ¼](https://huggingface.co/lewtun/distilbert-base-uncased-finetuned-squad-d5716d28)ã‚’ç”¨æ„ã—ã¾ã—ãŸã€‚ã“ã®ç« ã®ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã—ãŸã„å ´åˆã¯ã€ã¾ãšãƒ¢ãƒ‡ãƒ«ã‚’[ãƒã‚®ãƒ³ã‚°ãƒ•ã‚§ã‚¤ã‚¹ãƒãƒ–ï¼ˆHugging Face Hubï¼‰](https://huggingface.co)ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã«ã‚³ãƒ”ãƒ¼ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã¾ãšJupyterNotebookã§ãƒ­ã‚°ã‚¤ãƒ³ã—ã¾ã—ã‚‡ã†

```python
from huggingface_hub import notebook_login

notebook_login()
```

ãã‚Œã¨ã‚‚ã€ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã‚’ä½¿ã„ãªãŒã‚‰:

```bash
huggingface-cli login
```

ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¨ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã™ã‚‹ç”»é¢ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚Authentification token ãŒ *~/.cache/huggingface/*ã®ä¸­ã«ã‚»ãƒ¼ãƒ–ã•ã‚Œã¾ã™ã€‚ãƒ­ã‚°ã‚¤ãƒ³ã—ãŸå¾Œã«ä»¥ä¸‹ã®æ©Ÿèƒ½ã§ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚³ãƒ”ãƒ¼ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™

```python
from distutils.dir_util import copy_tree
from huggingface_hub import Repository, snapshot_download, create_repo, get_full_repo_name


def copy_repository_template():
    # Clone the repo and extract the local path
    template_repo_id = "lewtun/distilbert-base-uncased-finetuned-squad-d5716d28"
    commit_hash = "be3eaffc28669d7932492681cd5f3e8905e358b4"
    template_repo_dir = snapshot_download(template_repo_id, revision=commit_hash)
    # Create an empty repo on the Hub
    model_name = template_repo_id.split("/")[1]
    create_repo(model_name, exist_ok=True)
    # Clone the empty repo
    new_repo_id = get_full_repo_name(model_name)
    new_repo_dir = model_name
    repo = Repository(local_dir=new_repo_dir, clone_from=new_repo_id)
    # Copy files
    copy_tree(template_repo_dir, new_repo_dir)
    # Push to Hub
    repo.push_to_hub()
```

`copy_repository_template()`æ©Ÿèƒ½ã¯ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ¬ãƒã‚¸ãƒˆãƒªãƒ¼ã‚’ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã«ã‚³ãƒ”ãƒ¼ã—ã¾ã™ã€‚

## ğŸ¤— Transformersã€€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ãƒ‡ãƒã‚°

Transformerãƒ¢ãƒ‡ãƒ«ã¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ãƒ‡ãƒãƒƒã‚°ã¨ã„ã†ç´ æ™´ã‚‰ã—ã„ä¸–ç•Œã¸ã®æ—…ã‚’å§‹ã‚ã‚‹ã«ã‚ãŸã‚Šã€æ¬¡ã®ã‚ˆã†ãªã‚·ãƒŠãƒªã‚ªã‚’è€ƒãˆã¦ã¿ã¾ã—ã‚‡ã†ã€‚ã‚ãªãŸã¯åŒåƒšã¨ä¸€ç·’ã«ã€ã‚ã‚‹eã‚³ãƒãƒ¼ã‚¹ã‚µã‚¤ãƒˆã«é–¢ã™ã‚‹ãŠå®¢ã•ã‚“ã®ç­”ãˆã‚’è¦‹ã¤ã‘ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ã€'Question Answering'ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«å–ã‚Šçµ„ã‚“ã§ã„ã¾ã™ã€‚ã‚ãªãŸã®åŒåƒšã¯ã“ã‚“ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ã‚Šã¾ã—ãŸã€‚

> ã©ã†ã‚‚! å…ˆã»ã©ã€ã€ç¬¬7ç« ã€‘(/course/chapter7/7)ã€€ã®ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã‚’ä½¿ã£ã¦å®Ÿé¨“ã‚’ã—ãŸã¨ã“ã‚ã€SQuADãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ç´ æ™´ã‚‰ã—ã„çµæœãŒå¾—ã‚‰ã‚Œã¾ã—ãŸ!Hubä¸Šã®ãƒ¢ãƒ‡ãƒ«IDã¯"lewtun/distilbert-base-uncased-finetuned-squad-d5716d28"ã§ã™ã€‚ã“ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãœã²ãƒ†ã‚¹ãƒˆã—ã¦ã¿ã¾ã—ã‚‡ã†!

ã•ã¦ã€ğŸ¤— Transformers ã§ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãŸã‚ã«ã€€ `pipeline` ã‚’ä½¿ã„ã¾ã—ã‚‡ã†ï¼

```python
from transformers import pipeline

model_checkpoint = get_full_repo_name("distillbert-base-uncased-finetuned-squad-d5716d28")
reader = pipeline("question-answering", model=model_checkpoint)
```

```python out
"""
OSError: Can't load config for 'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28'. Make sure that:

- 'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28' is a correct model identifier listed on 'https://huggingface.co/models'

- or 'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28' is the correct path to a directory containing a config.json file
"""
```

æ®‹å¿µï¼ã©ã†ã—ã¦ã‚‚ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ãŒåˆã‚ã¦ã®æ–¹ã¯ã“ã‚“ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯æ€–ãã†ã«è¦‹ãˆã¾ã™ã€‚(`OSError`ã¯ä½•ï¼Ÿ)ã€‚ã“ã®ã‚ˆã†ãªã‚¨ãƒ©ãƒ¼ã¯ã€_Python traceback_ ã¨å‘¼ã°ã‚Œã‚‹ã€ã‚ˆã‚Šå¤§ããªã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã®æœ€å¾Œã®éƒ¨åˆ†ã§ã™ã€‚ã“ã®ã‚¨ãƒ©ãƒ¼ã¯ã€Google Colabã§å®Ÿè¡Œã—ãŸå ´åˆã«ã¯ã€æ¬¡ã®ã‚ˆã†ãªç”»åƒãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter8/traceback.png" alt="A Python traceback." width="100%"/>
</div>

ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã«ã¯å¤šãã®æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã®ã§ã€ä¸»è¦ãªéƒ¨åˆ†ã‚’ä¸€ç·’ã«è¦‹ã¦ã„ãã¾ã—ã‚‡ã†ã€‚ã¾ãšæ³¨æ„ã™ã¹ãã¯ã€ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯ã¯ä¸‹ã‹ã‚‰ä¸Šã¸èª­ã‚€ã¨ã„ã†ã“ã¨ã§ã™ï¼ˆæ—¥æœ¬èªã®é€†ã®èª­ã¿æ–¹ã§ã™ã­ï¼ï¼‰ã€‚ã“ã‚Œã¯ã€ã‚¨ãƒ©ãƒ¼ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯ãŒã€ãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ãã« `pipeline` ãŒè¡Œã†ä¸€é€£ã®é–¢æ•°å‘¼ã³å‡ºã—ã‚’åæ˜ ã—ã¦ã„ã¾ã™ã„ã¾ã™ï¼ˆè©³ã—ãã¯[ç¬¬ï¼’ç« ](/course/chapter2)ï¼‰ã‚’ã”è¦§ä¸‹ã•ã„ã€‚

<Tip>

ğŸš¨ Google Colabã®ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯ã§ã€ã€Œ6framesã€ã®ã‚ãŸã‚Šã«é’ã„æ ãŒã‚ã‚‹ã®ãŒè¦‹ãˆã¾ã™ã‹ï¼Ÿã“ã‚Œã¯Colabã®ç‰¹åˆ¥ãªæ©Ÿèƒ½ã§ã€ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚’ "ãƒ•ãƒ¬ãƒ¼ãƒ  "ã«åœ§ç¸®ã—ã¦ã„ã‚‹ã®ã§ã™ã€‚ã‚‚ã—ã‚¨ãƒ©ãƒ¼ã®åŸå› ãŒè©³ã—ãè¦‹ã¤ã‹ã‚‰ãªã„ã‚ˆã†ã§ã‚ã‚Œã°ã€ã“ã®2ã¤ã®å°ã•ãªçŸ¢å°ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã€ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯ã®å…¨å®¹ã‚’æ‹¡å¤§ã—ã¦ã¿ã¦ãã ã•ã„ã€‚

</Tip>

ã“ã‚Œã¯ã€ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯ã®æœ€å¾Œã®è¡ŒãŒã€ç™ºç”Ÿã—ãŸã‚¨ãƒ©ãƒ¼ã®åå‰ã‚’ä¸ãˆã‚‹ã“ã¨ã‚’ã—ã¾ã™ã€‚ã‚¨ãƒ©ãƒ¼ã®ã‚¿ã‚¤ãƒ—ã¯ `OSError` ã§ã€ã“ã‚Œã¯ã‚·ã‚¹ãƒ†ãƒ é–¢é€£ã®ã‚¨ãƒ©ãƒ¼ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ä»˜å±ã®ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’èª­ã‚€ã¨ã€ãƒ¢ãƒ‡ãƒ«ã® *config.json* ãƒ•ã‚¡ã‚¤ãƒ«ã«å•é¡ŒãŒã‚ã‚‹ã‚ˆã†ã§ã€ãã‚Œã‚’ä¿®æ­£ã™ã‚‹ãŸã‚ã®2ã¤ã®ææ¡ˆã‚’ä¸ãˆã‚‰ã‚Œã¦ã„ã¾ã™ã€‚
```python out
"""
Make sure that:

- 'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28' is a correct model identifier listed on 'https://huggingface.co/models'

- or 'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28' is the correct path to a directory containing a config.json file
"""
```

<Tip>

ğŸ’¡ ç†è§£ã—ãŒãŸã„ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¡¨ç¤ºã•ã‚ŒãŸå ´åˆã¯ã€ãã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦Google ã¾ãŸã¯ [Stack Overflow](https://stackoverflow.com/) ã®æ¤œç´¢ãƒãƒ¼ã«è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„ï¼ã€€ãã®ã‚¨ãƒ©ãƒ¼ã«é­é‡ã—ãŸã®ã¯ã‚ãªãŸãŒåˆã‚ã¦ã§ã¯ãªã„å¯èƒ½æ€§ãŒé«˜ã„ã§ã™ã—ã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®ä»–ã®äººãŒæŠ•ç¨¿ã—ãŸè§£æ±ºç­–ã‚’è¦‹ã¤ã‘ã‚‹è‰¯ã„æ–¹æ³•ã§ã™ã€‚ä¾‹ãˆã°ã€`OSError: Can't load config for` ã‚’ Stack Overflow ã§æ¤œç´¢ã™ã‚‹ã¨ã€ã„ãã¤ã‹ã® [ãƒ’ãƒ³ãƒˆ](https://stackoverflow.com/search?q=OSError%3A+Can%27t+load+config+for+) ãŒè¦‹ä»˜ã‘ã‚‰ã‚Œã¾ã™ã€‚ã“ã‚Œã¯ã€å•é¡Œè§£æ±ºã®å‡ºç™ºç‚¹ã¨ã—ã¦ä½¿ã†ã“ã¨ãŒã§ãã¾ã™ã€‚
</Tip>

æœ€åˆã®ææ¡ˆã¯ã€ãƒ¢ãƒ‡ãƒ«IDãŒå®Ÿéš›ã«æ­£ã—ã„ã‹ã©ã†ã‹ã‚’ç¢ºèªã™ã‚‹ã‚ˆã†æ±‚ã‚ã¦ã„ã‚‹ã®ã§ã€ã¾ãšã€è­˜åˆ¥å­ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦Hubã®æ¤œç´¢ãƒãƒ¼ã«è²¼ã‚Šä»˜ã‘ã¾ã—ã‚‡ã†ã€‚

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter8/wrong-model-id.png" alt="The wrong model name." width="100%"/>
</div>

ã†ãƒ¼ã‚“ã€ç¢ºã‹ã«åŒåƒšã®ãƒ¢ãƒ‡ãƒ«ã¯ãƒãƒ–ã«ãªã„ã‚ˆã†ã ...ã—ã‹ã—ã€ãƒ¢ãƒ‡ãƒ«ã®åå‰ã«ã‚¿ã‚¤ãƒ—ãƒŸã‚¹ãŒã‚ã‚‹! DistilBERTã®åå‰ã«ã¯ã€Œlã€ãŒ1ã¤ã—ã‹ãªã„ã®ã§ã€ãã‚Œã‚’ç›´ã—ã¦ã€ä»£ã‚ã‚Šã«ã€Œlewtun/distilbert-base-uncased-finetuned-squad-d5716d28ã€ã‚’æ¢ãã†ï¼
<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter8/true-model-id.png" alt="The right model name." width="100%"/>
</div>

ã•ã¦ã€ã“ã‚Œã§ãƒ’ãƒƒãƒˆã—ã¾ã—ãŸã€‚ã§ã¯ã€æ­£ã—ã„ãƒ¢ãƒ‡ãƒ«IDã§å†åº¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚

```python
model_checkpoint = get_full_repo_name("distilbert-base-uncased-finetuned-squad-d5716d28")
reader = pipeline("question-answering", model=model_checkpoint)
```

```python out
"""
OSError: Can't load config for 'lewtun/distilbert-base-uncased-finetuned-squad-d5716d28'. Make sure that:

- 'lewtun/distilbert-base-uncased-finetuned-squad-d5716d28' is a correct model identifier listed on 'https://huggingface.co/models'

- or 'lewtun/distilbert-base-uncased-finetuned-squad-d5716d28' is the correct path to a directory containing a config.json file
"""
```

ã‚ã‚ã€ã¾ãŸå¤±æ•—ã ã€‚æ©Ÿæ¢°å­¦ç¿’ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã®æ—¥å¸¸ã¸ã‚ˆã†ã“ãï¼ ãƒ¢ãƒ‡ãƒ«IDã¯ä¿®æ­£ã§ããŸã®ã§ã€å•é¡Œã¯ãƒªãƒã‚¸ãƒˆãƒªè‡ªä½“ã«ã‚ã‚‹ã¯ãšã§ã™ã€‚ğŸ¤— Hubä¸Šã®ãƒªãƒã‚¸ãƒˆãƒªã®å†…å®¹ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ç°¡å˜ãªæ–¹æ³•ã¯ã€`huggingface_hub`ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã® `list_repo_files()` é–¢æ•°ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã™ã€‚

```python
from huggingface_hub import list_repo_files

list_repo_files(repo_id=model_checkpoint)
```

```python out
['.gitattributes', 'README.md', 'pytorch_model.bin', 'special_tokens_map.json', 'tokenizer_config.json', 'training_args.bin', 'vocab.txt']
```

ãƒªãƒã‚¸ãƒˆãƒªã«ã¯ *config.json* ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„ã‚ˆã†ã§ã™! ã©ã†ã‚Šã§ `pipeline` ãŒãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚ãªã„ã‚ã‘ã§ã™ã€‚åŒåƒšãŒã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Hubã«ãƒ—ãƒƒã‚·ãƒ¥ã™ã‚‹ã®ã‚’å¿˜ã‚ŒãŸã«é•ã„ã‚ã‚Šã¾ã›ã‚“ã€‚ã“ã®å ´åˆã€å•é¡Œã‚’è§£æ±ºã™ã‚‹ã®ã¯ç°¡å˜ã§ã™ã€‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½åŠ ã™ã‚‹ã‚ˆã†ã«ä¾é ¼ã™ã‚‹ã‹ã€ãƒ¢ãƒ‡ãƒ«IDã‹ã‚‰ä½¿ç”¨ã•ã‚ŒãŸäº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒ[`distilbert-base-uncased`](https://huggingface.co/distilbert-base-uncased)ã§ã‚ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã®ã§ã€ãã®ãƒ¢ãƒ‡ãƒ«ã®configï¼ˆè¨­å®šï¼‰ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€æˆ‘ã€…ã®ãƒªãƒã‚¸ãƒˆãƒªã«ãƒ—ãƒƒã‚·ãƒ¥ã—ã¦å•é¡ŒãŒè§£æ±ºã™ã‚‹ã‹ç¢ºèªã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ãã‚Œã§ã¯è©¦ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚[ç¬¬2ç« ](/course/chapter2)ã§å­¦ã‚“ã ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã‚’ä½¿ã£ã¦ã€`AutoConfig`ã‚¯ãƒ©ã‚¹ã§ãƒ¢ãƒ‡ãƒ«ã®è¨­å®šã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

```python
from transformers import AutoConfig

pretrained_checkpoint = "distilbert-base-uncased"
config = AutoConfig.from_pretrained(pretrained_checkpoint)
```

<Tip warning={true}>

ğŸš¨ åŒåƒšã¯ `distilbert-base-uncased` ã®è¨­å®šã‚’é–“é•ãˆã¦ã„ã˜ã£ãŸã‹ã‚‚ã—ã‚Œãªã„ã§ã™ã€‚å®Ÿéš›ã®ã¨ã“ã‚ã€ç§ãŸã¡ã¯ã¾ãšå½¼ã‚‰ã«ç¢ºèªã—ãŸã„ã¨ã“ã‚ã§ã™ãŒã€ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ç›®çš„ã§ã¯ã€å½¼ã‚‰ãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®è¨­å®šã‚’ä½¿ç”¨ã—ãŸã¨ä»®å®šã™ã‚‹ã“ã¨ã«ã—ã¾ã™ã€‚
</Tip>


ãã‚Œã§`push_to_hub()`ã€€æ©Ÿèƒ½ã§ãƒ¢ãƒ‡ãƒ«ã®è¨­å®šã‚’ãƒªãƒã‚¸ãƒˆãƒªã«ãƒ—ãƒƒã‚·ãƒ¥ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚


```python
config.push_to_hub(model_checkpoint, commit_message="Add config.json")
```

ãã—ã¦ã¯ã€æœ€æ–°ã®ã‚³ãƒŸãƒƒãƒˆã‚’ `main` ãƒ–ãƒ©ãƒ³ãƒã‹ã‚‰èª­ã¿è¾¼ã“ã‚“ã§ã¿ã¾ã—ã‚‡ã†ã€‚

```python
reader = pipeline("question-answering", model=model_checkpoint, revision="main")

context = r"""
Extractive Question Answering is the task of extracting an answer from a text
given a question. An example of a question answering dataset is the SQuAD
dataset, which is entirely based on that task. If you would like to fine-tune a
model on a SQuAD task, you may leverage the
examples/pytorch/question-answering/run_squad.py script.

ğŸ¤— Transformers is interoperable with the PyTorch, TensorFlow, and JAX
frameworks, so you can use your favourite tools for a wide variety of tasks!
"""

question = "What is extractive question answering?"
reader(question=question, context=context)
```

```python out
{'score': 0.38669535517692566,
 'start': 34,
 'end': 95,
 'answer': 'the task of extracting an answer from a text given a question'}
```

ã‚„ã£ãŸã­ï¼ ã“ã‚Œã§ã€ãŠç–²ã‚Œæ§˜ã§ã—ãŸã€‚ä»Šã¾ã§ã®ã“ã¨ã‚’ä¸€ç·’ã«æŒ¯ã‚Šè¿”ã£ã¦ã¿ã¾ã—ã‚‡ã†ã€‚

- Pythonã®ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯ã€€__traceback__ã€€ã¨å‘¼ã°ã‚Œã€ä¸‹ã‹ã‚‰ä¸Šã¸ã¨èª­ã¿ä¸Šã’ã‚‰ã‚Œã¾ã™ã€‚ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æœ€å¾Œã®è¡Œã¯ä¸€ç•ªå¿…è¦ãªæƒ…å ±ã‚’å«ã‚“ã§ã„ã¾ã™ã€‚
- ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¤‡é›‘ãªå ´åˆã¯ã€__traceback__ã€€ã‚’èª­ã¿ä¸Šã’ãªãŒã‚‰ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«åã‚„è¡Œç•ªå·ã‚’æŒ‡å®šã—ã¦ã€ã‚¨ãƒ©ãƒ¼ã®åŸå› ã‚’èª­ã¿å–ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
- ãã®å ´åˆã§ã‚‚ãƒ‡ãƒã‚°ã™ã‚‹ã“ã¨ãŒã§ããªã„ãªã‚‰ã€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆä¸Šã«ã‚’æ¤œç´¢ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚
- `huggingface_hub` ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¯ã€Hubã®ãƒªãƒã‚¸ãƒˆãƒªã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ä¸€é€£ã®ãƒ„ãƒ¼ãƒ«ã‚’æä¾›ã—ã¾ã™ã€‚ãƒ‡ãƒãƒƒã‚°ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã§ãã‚‹ã®ãƒ„ãƒ¼ãƒ«ã‚‚å«ã‚ã¦ã„ã¾ã™ã€‚

ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ãƒ‡ãƒãƒƒã‚°æ–¹æ³•ãŒã‚ã‹ã£ãŸã¨ã“ã‚ã§ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹ã§é›£ã—ã„ä¾‹ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚

## ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹ã‚’ãƒ‡ãƒãƒƒã‚°

æ™‚ã«ã¯ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ã‚¸ãƒƒãƒˆã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼ˆä¾‹ãˆã°ã€ã‚«ã‚¹ã‚¿ãƒ ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½¿ã„ãŸã„å ´åˆã§ï¼‰ã€‚ã“ã®ã‚ˆã†ãªå ´åˆã€ä½•ãŒå•é¡Œã«ãªã‚‹ã‹ã‚’çŸ¥ã‚‹ãŸã‚ã«ã€ã¾ãš `pipeline` ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’å–å¾—ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚

```python
tokenizer = reader.tokenizer
model = reader.model
```

æ¬¡ã«å¿…è¦ãªã®ã¯ã€ãŠæ°—ã«å…¥ã‚Šã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ã‹ã©ã†ã‹ã¨ã„ã†è³ªå•ã§ã™ã€‚

```python
question = "Which frameworks can I use?"
```

[ç¬¬7ç« ](/course/chapter7)ã§è¦‹ãŸã‚ˆã†ã«ã€é€šå¸¸å¿…è¦ãªã‚¹ãƒ†ãƒƒãƒ—ã¯ã€å…¥åŠ›ã®ãƒˆãƒ¼ã‚¯ãƒ³ã€é–‹å§‹ã¨çµ‚äº†ãƒˆãƒ¼ã‚¯ãƒ³ã®ãƒ­ã‚¸ãƒƒãƒˆã€ãã—ã¦è§£ç­”ã‚¹ãƒ‘ãƒ³ã®ãƒ‡ã‚³ãƒ¼ãƒ‰ã§ã™ã€‚

```python
import torch

inputs = tokenizer(question, context, add_special_tokens=True)
input_ids = inputs["input_ids"][0]
outputs = model(**inputs)
answer_start_scores = outputs.start_logits
answer_end_scores = outputs.end_logits
# Get the most likely beginning of answer with the argmax of the score
answer_start = torch.argmax(answer_start_scores)
# Get the most likely end of answer with the argmax of the score
answer_end = torch.argmax(answer_end_scores) + 1
answer = tokenizer.convert_tokens_to_string(
    tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end])
)
print(f"Question: {question}")
print(f"Answer: {answer}")
```

```python out
"""
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
/var/folders/28/k4cy5q7s2hs92xq7_h89_vgm0000gn/T/ipykernel_75743/2725838073.py in <module>
      1 inputs = tokenizer(question, text, add_special_tokens=True)
      2 input_ids = inputs["input_ids"]
----> 3 outputs = model(**inputs)
      4 answer_start_scores = outputs.start_logits
      5 answer_end_scores = outputs.end_logits

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)
   1049         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
   1050                 or _global_forward_hooks or _global_forward_pre_hooks):
-> 1051             return forward_call(*input, **kwargs)
   1052         # Do not call functions when jit is used
   1053         full_backward_hooks, non_full_backward_hooks = [], []

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py in forward(self, input_ids, attention_mask, head_mask, inputs_embeds, start_positions, end_positions, output_attentions, output_hidden_states, return_dict)
    723         return_dict = return_dict if return_dict is not None else self.config.use_return_dict
    724
--> 725         distilbert_output = self.distilbert(
    726             input_ids=input_ids,
    727             attention_mask=attention_mask,

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)
   1049         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
   1050                 or _global_forward_hooks or _global_forward_pre_hooks):
-> 1051             return forward_call(*input, **kwargs)
   1052         # Do not call functions when jit is used
   1053         full_backward_hooks, non_full_backward_hooks = [], []

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py in forward(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)
    471             raise ValueError("You cannot specify both input_ids and inputs_embeds at the same time")
    472         elif input_ids is not None:
--> 473             input_shape = input_ids.size()
    474         elif inputs_embeds is not None:
    475             input_shape = inputs_embeds.size()[:-1]

AttributeError: 'list' object has no attribute 'size'
"""
```

ãŠã‚„ãŠã‚„ã€ã©ã†ã‚„ã‚‰ã‚³ãƒ¼ãƒ‰ã«ãƒã‚°ãŒã‚ã‚‹ã‚ˆã†ã§ã™ã­ã€‚ã§ã‚‚ã€ã¡ã‚‡ã£ã¨ã—ãŸãƒ‡ãƒãƒƒã‚°ã¯æ€–ãã‚ã‚Šã¾ã›ã‚“ã€‚Pythonã®ãƒ‡ãƒãƒƒã‚¬ã‚’ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ä½¿ã†ã“ã¨ãŒã§ãã‚‹ã®ã§ã™ã€‚

<Youtube id="rSPyvPw0p9k"/>

ãã‚Œã¨ã‚‚ã€ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ãƒ‡ãƒãƒƒã‚°ã‚’è¡Œã†ã“ã¨ãŒã§ãã¾ã™:

<Youtube id="5PkZ4rbHL6c"/>

ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’èª­ã‚€ã¨ã€ `'list' object has no attribute 'size'` ã¨ã€ `-->` çŸ¢å°ãŒ `model(**inputs)` ã®ä¸­ã§å•é¡ŒãŒç™ºç”Ÿã—ãŸè¡Œã‚’æŒ‡ã—ã¦ã„ã‚‹ã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã™ã€‚Pythonãƒ‡ãƒãƒƒã‚¬ã‚’ä½¿ã£ã¦ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã«ãƒ‡ãƒãƒƒã‚°ã§ãã¾ã™ãŒã€ä»Šã¯å˜ã« `inputs` ã®ã‚¹ãƒ©ã‚¤ã‚¹ã‚’è¡¨ç¤ºã—ã¦ä½•ãŒã‚ã‚‹ã‹è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚

```python
inputs["input_ids"][:5]
```

```python out
[101, 2029, 7705, 2015, 2064]
```

ã“ã‚Œã¯ç¢ºã‹ã«æ™®é€šã®Pythonã® `list` ã®ã‚ˆã†ã«è¦‹ãˆã¾ã™ãŒã€å†ç¢ºèªã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚
```python
type(inputs["input_ids"])
```

```python out
list
```

ã“ã‚Œã¯ç¢ºã‹ã«Pythonã®`list`ã§ã™ã­ã€‚ã§ã¯ä½•ãŒã„ã‘ãªã‹ã£ãŸã®ã‹ï¼Ÿ[ç¬¬2ç« ](/course/chapter2)ã§ã€ğŸ¤— Transformersã® `AutoModelForXxx` ã‚¯ãƒ©ã‚¹ã¯ _tensor_ (PyTorch ã¾ãŸã¯ TensorFlow ã®ã„ãšã‚Œã‹)ã‚’ä½¿ã„ãªãŒã‚‰ã€ä¾‹ãˆã°PyTorchã® `Tensor.size()`æ©Ÿèƒ½ã‚’å‘¼ã³å‡ºã—ã¦ã„ã¾ã™ã€‚ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚’ã‚‚ã†ä¸€åº¦è¦‹ã¦ã€ã©ã®è¡Œã§ä¾‹å¤–ãŒç™ºç”Ÿã—ãŸã‹ã‚’ç¢ºèªã—ã¾ã—ã‚‡ã†ã€‚

```
~/miniconda3/envs/huggingface/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py in forward(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)
    471             raise ValueError("You cannot specify both input_ids and inputs_embeds at the same time")
    472         elif input_ids is not None:
--> 473             input_shape = input_ids.size()
    474         elif inputs_embeds is not None:
    475             input_shape = inputs_embeds.size()[:-1]

AttributeError: 'list' object has no attribute 'size'
```

ç§ãŸã¡ã®ã‚³ãƒ¼ãƒ‰ã¯ `input_ids.size()` ã‚’å‘¼ã³å‡ºãã†ã¨ã—ãŸã‚ˆã†ã§ã™ãŒã€ã“ã‚Œã¯æ˜ã‚‰ã‹ã«Pythonã® `list` ã«å¯¾ã—ã¦å‹•ä½œã—ã¾ã›ã‚“ã€‚ã©ã†ã™ã‚Œã°ã“ã®å•é¡Œã‚’è§£æ±ºã§ãã‚‹ã§ã—ã‚‡ã†ã‹ï¼ŸStack Overflowã§ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ¤œç´¢ã™ã‚‹ã¨ã€é–¢é€£ã™ã‚‹[ãƒ’ãƒ³ãƒˆ](https://stackoverflow.com/search?q=AttributeError%3A+%27list%27+object+has+no+attribute+%27size%27&s=c15ec54c-63cb-481d-a749-408920073e8f) ãŒã‹ãªã‚Šè¦‹ã¤ã‹ã‚Šã¾ã™ã€‚

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter8/stack-overflow.png" alt="An answer from Stack Overflow." width="100%"/>
</div>

å›ç­”ã§ã¯ã€ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã« `return_tensors='pt'` ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ãŒæ¨å¥¨ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€ã“ã‚ŒãŒã†ã¾ãã„ãã‹ã©ã†ã‹è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚

```python out
inputs = tokenizer(question, context, add_special_tokens=True, return_tensors="pt")
input_ids = inputs["input_ids"][0]
outputs = model(**inputs)
answer_start_scores = outputs.start_logits
answer_end_scores = outputs.end_logits
# Get the most likely beginning of answer with the argmax of the score
answer_start = torch.argmax(answer_start_scores)
# Get the most likely end of answer with the argmax of the score
answer_end = torch.argmax(answer_end_scores) + 1
answer = tokenizer.convert_tokens_to_string(
    tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end])
)
print(f"Question: {question}")
print(f"Answer: {answer}")
```

```python out
"""
Question: Which frameworks can I use?
Answer: pytorch, tensorflow, and jax
"""
```

Stack OverflowãŒã„ã‹ã«æœ‰ç”¨ã§ã‚ã‚‹ã‹ã‚’ç¤ºã™ç´ æ™´ã‚‰ã—ã„ä¾‹ã§ã™ã€‚åŒæ§˜ã®å•é¡Œã‚’ç‰¹å®šã™ã‚‹ã“ã¨ã§ã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®ä»–ã®äººã€…ã®çµŒé¨“ã‹ã‚‰æ©æµã‚’å—ã‘ã‚‹ã“ã¨ãŒã§ãã¾ã—ãŸã€‚ã—ã‹ã—ã€ã“ã®ã‚ˆã†ãªæ¤œç´¢ã§ã¯ã€å¸¸ã«é©åˆ‡ãªå›ç­”ãŒå¾—ã‚‰ã‚Œã‚‹ã¨ã¯é™ã‚Šã¾ã›ã‚“ã€‚ã§ã¯ã€ã“ã®ã‚ˆã†ãªå ´åˆã€ã©ã†ã™ã‚Œã°ã„ã„ã®ã§ã—ã‚‡ã†ã‹ï¼Ÿå¹¸ã„ã€[ãƒã‚®ãƒ³ã‚°ãƒ•ã‚§ã‚¤ã‚¹ãƒ•ã‚©ãƒ¼ãƒ©ãƒ ï¼ˆHugging Face forumsï¼‰](https://discuss.huggingface.co/)ã«ã¯ã€é–‹ç™ºè€…ãŸã¡ã®æ­“è¿ã™ã‚‹ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãŒã‚ã‚Šã€ã‚ãªãŸã‚’åŠ©ã‘ã¦ãã‚Œã‚‹ã§ã—ã‚‡ã†ã€‚æ¬¡ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ã€å›ç­”ãŒå¾—ã‚‰ã‚Œã‚‹å¯èƒ½æ€§ã®é«˜ã„ã€è‰¯ã„ãƒ•ã‚©ãƒ¼ãƒ©ãƒ ã®è³ªå•ã‚’ä½œæˆã™ã‚‹æ–¹æ³•ã‚’è¦‹ã¦ã„ãã¾ã™ã€‚