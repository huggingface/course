# 開催されたイベントの紹介

Chapter 2のコース後, Chapter 3のFine-tuningのコースの前に、2日間のトークライブイベントが開催されました。
詳細については以下のページから見ることが出来ます。


## 1日目: Transformersの学習方法を俯瞰する

**Thomas Wolf:** *転移学習とTransformersライブラリの誕生*

<p align="center">
    <a href="https://www.youtube.com/watch?v=wCYVeahJES0">
        <img src="https://img.youtube.com/vi/wCYVeahJES0/0.jpg" alt="ThomasによるトークのYoutubeリンク" width="80%"/>
    </a>
</p>


<p align="center">
    <img src="https://i.imgur.com/9eq8oUi.png" alt="Thomasによるトークの概要図" width="80%"/>
</p>

Thomas Wolfは、Hugging Faceの共同設立者であり、主任研究員です。
彼とHugging Faceチームが作成したツールは、Facebook人工知能研究所、Googleリサーチ、DeepMind、Amazonリサーチ、Apple、アレン人工知能研究所、および多くの大学を含む5,000以上の研究機関に使用されています。
Thomas Wolfは人工知能の分野における最大の研究機関の創始者であり、[BigScience](https://bigscience.huggingface.co)をはじめとする、世界で広く利用されている[ライブラリやツール](https://github.com/huggingface/)の開発者です。
加えて、人工知能と自然言語処理の分野におけるリーダーであり、世界中のカンファレンスに定期的に招待されるスピーカーです。[https://thomwolf.io](https://thomwolf.io).


**Jay Alammar:** *Transformersのモデルの視覚的な紹介*

<p align="center">
    <a href="https://www.youtube.com/watch?v=VzvG23gmcYU">
        <img src="https://img.youtube.com/vi/VzvG23gmcYU/0.jpg" alt="JayによるトークのYoutubeリンク" width="80%"/>
    </a>
</p>

<p align="center">
    <img src="https://i.imgur.com/rOZAuE9.png" alt="Jayによるトークの概要図" width="80%"/>
</p>

Jay Alammarは機械学習ツールやコンセプトを基本的なもの（NumPyやPandasのドキュメントで終わる）から最先端のもの（Transformers、BERT、GPT-3）まで視覚的に理解できるようなブログを書いています。

**Margaret Mitchell:** *機械学習開発における価値観*

<p align="center">
    <a href="https://www.youtube.com/watch?v=8j9HRMjh_s8">
        <img src="https://img.youtube.com/vi/8j9HRMjh_s8/0.jpg" alt="MargaretによるトークのYoutubeリンク" width="80%"/>
    </a>
</p>

<p align="center">
    <img src="https://i.imgur.com/NuIsnY3.png" alt="Margaretによるトークの概要図" width="80%"/>
</p>

Margaret Mitchellは、Ethical AIの研究者であり、現在、企業におけるAI開発の倫理的な観点に焦点をあてて研究しています。
彼女は自然言語生成、支援技術、コンピュータビジョン、およびAI倫理に関する50以上の論文を発表し、会話生成と感情分類の分野で複数の特許を保有しています。
以前はGoogle AIにリサーチサイエンティストとして勤務しており、Google&#39;s Ethical AIグループを設立、リーダーとしてAI倫理の基礎研究およびGoogle内部でのAI倫理の運用に注力していました。
Google入社以前は、Microsoft Researchで画像からの言語生成に焦点を当てた研究員、ジョンズ・ホプキンズ大学でベイズモデリングと情報抽出に焦点を当てたポスドクを務めていました。
アバディーン大学でコンピュータサイエンスの博士号を、ワシントン大学で計算言語学の修士号を取得しています。
学位を取得する傍ら、2005年から2012年まで、オレゴン健康科学大学で機械学習、神経障害、支援技術に関する研究に従事していました。
彼女は多様性やコンピュータサイエンス、倫理などの多くの分野でワークショップや活動を率先して行ってきました。
彼女の研究は、アッシュ・カーター国防長官や米国盲人財団から表彰され、複数のテクノロジー企業で導入されています。
ちなみに彼女はガーデニングと犬、猫が好きです。

**Matthew Watson and Chen Qian:** *Keraによる自然言語処理のワークフロー*

<p align="center">
    <a href="https://www.youtube.com/watch?v=gZIP-_2XYMM">
        <img src="https://img.youtube.com/vi/gZIP-_2XYMM/0.jpg" alt="MatthewとChenによるトークのYoutubeリンク" width="80%"/>
    </a>
</p>

<p align="center">
    <img src="https://i.imgur.com/1vD2az8.png" alt="MatthewとChenによるトークの概要図" width="80%"/>
</p>

Matthew Watsonは、Kerasチームの機械学習エンジニアで、ハイレベルのモデリングAPIの開発を行っています。
学部ではコンピュータグラフィックスを専攻し、スタンフォード大学で修士号を取得しました。
彼はもともと英語を専攻していましたが、コンピュータサイエンスに転向ました。
分野を超えて仕事をし、より多くの人が自然言語処理にアクセスできるようにすることに情熱を傾けています。

Chen QianはKerasチームのソフトウェアエンジニアで、彼もハイレベルのモデリングAPIの開発を行っています。
スタンフォード大学で電気工学の修士号を取得しました。
機械学習タスクのコード実装の簡素化と大規模機械学習に特に興味を持っています。

**Mark Saroufim:** *Pytorchでモデルを学習させる方法*

<p align="center">
    <a href="https://www.youtube.com/watch?v=KmvPlW2cbIo">
        <img src="https://img.youtube.com/vi/KmvPlW2cbIo/0.jpg" alt="MarkによるトークのYoutubeリンク" width="80%"/>
    </a>
</p>

<p align="center">
    <img src="https://i.imgur.com/TPmlkm8.png" alt="Markによるトークの概要図" width="80%"/>
</p>

In his past lives, Mark was an Applied Scientist and Product Manager at Graphcore, [yuri.ai](http://yuri.ai/), Microsoft and NASA's JPL.
Mark SaroufimはPytorchのパートナーエンジニアで、TorchServeやPytorch Enterpriseを含むOSSの開発に携わっています。
以前はGraphcore, [yuri.ai](http://yuri.ai/), Microsoft, NASAのジェット推進研究所で応用科学者、プロダクトマネージャーを務めた。
プログラミングをもっと楽しくすることに情熱を注いでいます。


**Jakob Uszkoreit:** *It Ain't Broke So <del>Don't Fix</del> Let's Break It*

<p align="center">
<img src="https://i.imgur.com/5dWQeNB.png" alt="A visual summary of Jakob's talk" width="80%"/>
</p>

Jakob Uszkoreit is the co-founder of Inceptive. Inceptive designs RNA molecules for vaccines and therapeutics using large-scale deep learning in a tight loop with high throughput experiments with the goal of making RNA-based medicines more accessible, more effective and more broadly applicable. Previously, Jakob worked at Google for more than a decade, leading research and development teams in Google Brain, Research and Search working on deep learning fundamentals, computer vision, language understanding and machine translation.


Translate to Japanese (event Day 1)


## Day 2: The tools to use

**Lewis Tunstall:** *Simple Training with the 🤗 Transformers Trainer*


Lewis is a machine learning engineer at Hugging Face, focused on developing open-source tools and making them accessible to the wider community. He is also a co-author of the O’Reilly book [Natural Language Processing with Transformers](https://www.oreilly.com/library/view/natural-language-processing/9781098103231/). You can follow him on Twitter (@_lewtun) for NLP tips and tricks!

**Matthew Carrigan:** *New TensorFlow Features for 🤗 Transformers and 🤗 Datasets*


Matt is responsible for TensorFlow maintenance at Transformers, and will eventually lead a coup against the incumbent PyTorch faction which will likely be co-ordinated via his Twitter account @carrigmat.

**Lysandre Debut:** *The Hugging Face Hub as a means to collaborate on and share Machine Learning projects*


<p align="center">
<img src="https://i.imgur.com/TarIPCz.png" alt="A visual summary of Lysandre's talk" width="80%"/>
</p>

Lysandre is a Machine Learning Engineer at Hugging Face where he is involved in many open source projects. His aim is to make Machine Learning accessible to everyone by developing powerful tools with a very simple API.

**Lucile Saulnier:** *Get your own tokenizer with 🤗 Transformers & 🤗 Tokenizers*


Lucile is a machine learning engineer at Hugging Face, developing and supporting the use of open source tools. She is also actively involved in many research projects in the field of Natural Language Processing such as collaborative training and BigScience.

**Sylvain Gugger:** *Supercharge your PyTorch training loop with 🤗 Accelerate*

Sylvain is a Research Engineer at Hugging Face and one of the core maintainers of 🤗 Transformers and the developer behind 🤗 Accelerate. He likes making model training more accessible.

**Merve Noyan:** *Showcase your model demos with 🤗 Spaces*

Merve is a developer advocate at Hugging Face, working on developing tools and building content around them to democratize machine learning for everyone.

**Abubakar Abid:** *Building Machine Learning Applications Fast*


<p align="center">
<img src="https://i.imgur.com/qWIFeiF.png" alt="A visual summary of Abubakar's talk" width="80%"/>
</p>

Abubakar Abid is the CEO of [Gradio](www.gradio.app). He received his Bachelor's of Science in Electrical Engineering and Computer Science from MIT in 2015, and his PhD in Applied Machine Learning from Stanford in 2021. In his role as the CEO of Gradio, Abubakar works on making machine learning models easier to demo, debug, and deploy.

**Mathieu Desvé:** *AWS ML Vision: Making Machine Learning Accessible to all Customers*


<p align="center">
<img src="https://i.imgur.com/oLdZTKy.png" alt="A visual summary of Mathieu's talk" width="80%"/>
</p>

Technology enthusiast, maker on my free time. I like challenges and solving problem of clients and users, and work with talented people to learn every day. Since 2004, I work in multiple positions switching from frontend, backend, infrastructure, operations and managements. Try to solve commons technical and managerial issues in agile manner.

**Philipp Schmid:** *Managed Training with Amazon SageMaker and 🤗 Transformers*


Philipp Schmid is a Machine Learning Engineer and Tech Lead at Hugging Face, where he leads the collaboration with the Amazon SageMaker team. He is passionate about democratizing and productionizing cutting-edge NLP models and improving the ease of use for Deep Learning.
