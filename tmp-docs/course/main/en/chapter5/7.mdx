---
local: datasets
title: 🤗 Datasets，回顾！
---
<script lang="ts">
import {onMount} from "svelte";
import Tip from "$lib/Tip.svelte";
import Youtube from "$lib/Youtube.svelte";
import Docstring from "$lib/Docstring.svelte";
import CodeBlock from "$lib/CodeBlock.svelte";
import CodeBlockFw from "$lib/CodeBlockFw.svelte";
import DocNotebookDropdown from "$lib/DocNotebookDropdown.svelte";
import IconCopyLink from "$lib/IconCopyLink.svelte";
import FrameworkContent from "$lib/FrameworkContent.svelte";
import Markdown from "$lib/Markdown.svelte";
import Question from "$lib/Question.svelte";
import FrameworkSwitchCourse from "$lib/FrameworkSwitchCourse.svelte";
import InferenceApi from "$lib/InferenceApi.svelte";
import TokenizersLanguageContent from "$lib/TokenizersLanguageContent.svelte";
import ExampleCodeBlock from "$lib/ExampleCodeBlock.svelte";
let fw: "pt" | "tf" = "pt";
onMount(() => {
    const urlParams = new URLSearchParams(window.location.search);
    fw = urlParams.get("fw") || "pt";
});
</script>
<svelte:head>
  <meta name="hf:doc:metadata" content={JSON.stringify(metadata)} >
</svelte:head>
<h1 id="datasets">🤗 Datasets，回顾！</h1>

&amp;lt;CourseFloatingBanner
    chapter=&amp;lcub;5}
    classNames="absolute z-10 right-0 top-0"
/>

这是对 🤗 Datasets 库的一次完整游览——祝贺你走到这一步！凭借从本章中获得的知识，您应该能够：

- 从任何地方加载数据集，无论是 Hugging Face Hub、您的笔记本电脑还是您公司的远程服务器。
- 混合使用Dataset.map()和Dataset.filter()函数来整理数据。
- 使用`Dataset.set_format()`在 Pandas 和 NumPy 等数据格式之间快速切换.
- 创建您自己的数据集并将其推送到 Hugging Face Hub。.
- 使用 Transformer 模型为您的文档创建词嵌入，并使用 FAISS 构建语义搜索引擎。.

在[第七章](/course/chapter7)，当我们深入研究 Transformer 模型非常适合的核心 NLP 任务时，我们将充分利用所有这些。