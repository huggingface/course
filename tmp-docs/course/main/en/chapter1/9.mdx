---
local: ''
title: 总结
---
<script lang="ts">
import {onMount} from "svelte";
import Tip from "$lib/Tip.svelte";
import Youtube from "$lib/Youtube.svelte";
import Docstring from "$lib/Docstring.svelte";
import CodeBlock from "$lib/CodeBlock.svelte";
import CodeBlockFw from "$lib/CodeBlockFw.svelte";
import DocNotebookDropdown from "$lib/DocNotebookDropdown.svelte";
import IconCopyLink from "$lib/IconCopyLink.svelte";
import FrameworkContent from "$lib/FrameworkContent.svelte";
import Markdown from "$lib/Markdown.svelte";
import Question from "$lib/Question.svelte";
import FrameworkSwitchCourse from "$lib/FrameworkSwitchCourse.svelte";
import InferenceApi from "$lib/InferenceApi.svelte";
import TokenizersLanguageContent from "$lib/TokenizersLanguageContent.svelte";
import ExampleCodeBlock from "$lib/ExampleCodeBlock.svelte";
let fw: "pt" | "tf" = "pt";
onMount(() => {
    const urlParams = new URLSearchParams(window.location.search);
    fw = urlParams.get("fw") || "pt";
});
</script>
<svelte:head>
  <meta name="hf:doc:metadata" content={JSON.stringify(metadata)} >
</svelte:head>
<h1 id="">总结</h1>

&amp;lt;CourseFloatingBanner
    chapter=&amp;lcub;1}
    classNames="absolute z-10 right-0 top-0"
/>

在本章中，您了解了如何使用来自🤗Transformers的函数pipeline()处理不同的NLP任务。您还了解了如何在模型中心（hub）中搜索和使用模型，以及如何使用推理API直接在浏览器中测试模型。

我们讨论了Transformer模型如何在应用层上工作，并讨论了迁移学习和微调的重要性。您可以使用完整的体系结构，也可以仅使用编码器或解码器，具体取决于您要解决的任务类型。下表总结了这一点：

|  模型   | 示例  | 任务|
|  ----  | ----  |----|
| 编码器  | ALBERT, BERT, DistilBERT, ELECTRA, RoBERTa	|句子分类、命名实体识别、从文本中提取答案|
| 解码器  | CTRL, GPT, GPT-2, Transformer XL	 |文本生成|
| 编码器-解码器  | BART, T5, Marian, mBART	 |文本摘要、翻译、生成问题的回答|